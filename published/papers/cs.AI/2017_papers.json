[
    {
        "url": "https://arxiv.org/abs/1701.00287",
        "title": "STRIPS Planning in Infinite Domains",
        "authors": [
            "Caelan Reed Garrett",
            "Tom\u00e1s Lozano-P\u00e9rez",
            "Leslie Pack Kaelbling"
        ],
        "abstract": "Many robotic planning applications involve continuous actions with highly non-linear constraints, which cannot be modeled using modern planners that construct a propositional representation. We introduce STRIPStream: an extension of the STRIPS language which can model these domains by supporting the specification of blackbox generators to handle complex constraints. The outputs of these generators interact with actions through possibly infinite streams of objects and static predicates. We provide two algorithms which both reduce STRIPStream problems to a sequence of finite-domain planning problems. The representation and algorithms are entirely domain independent. We demonstrate our framework on simple illustrative domains, and then on a high-dimensional, continuous robotic task and motion planning domain.\n    ",
        "submission_date": "2017-01-01T00:00:00",
        "last_modified_date": "2017-05-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.00349",
        "title": "An affective computational model for machine consciousness",
        "authors": [
            "Rohitash Chandra"
        ],
        "abstract": "In the past, several models of consciousness have become popular and have led to the development of models for machine consciousness with varying degrees of success and challenges for simulation and implementations. Moreover, affective computing attributes that involve emotions, behavior and personality have not been the focus of models of consciousness as they lacked motivation for deployment in software applications and robots. The affective attributes are important factors for the future of machine consciousness with the rise of technologies that can assist humans. Personality and affection hence can give an additional flavor for the computational model of consciousness in humanoid robotics. Recent advances in areas of machine learning with a focus on deep learning can further help in developing aspects of machine consciousness in areas that can better replicate human sensory perceptions such as speech recognition and vision. With such advancements, one encounters further challenges in developing models that can synchronize different aspects of affective computing. In this paper, we review some existing models of consciousnesses and present an affective computational model that would enable the human touch and feel for robotic systems.\n    ",
        "submission_date": "2017-01-02T00:00:00",
        "last_modified_date": "2017-01-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.00464",
        "title": "Conceptual Spaces for Cognitive Architectures: A Lingua Franca for Different Levels of Representation",
        "authors": [
            "Antonio Lieto",
            "Antonio Chella",
            "Marcello Frixione"
        ],
        "abstract": "During the last decades, many cognitive architectures (CAs) have been realized adopting different assumptions about the organization and the representation of their knowledge level. Some of them (e.g. SOAR [Laird (2012)]) adopt a classical symbolic approach, some (e.g. LEABRA [O'Reilly and Munakata (2000)]) are based on a purely connectionist model, while others (e.g. CLARION [Sun (2006)] adopt a hybrid approach combining connectionist and symbolic representational levels. Additionally, some attempts (e.g. biSOAR) trying to extend the representational capacities of CAs by integrating diagrammatical representations and reasoning are also available [Kurup and Chandrasekaran (2007)]. In this paper we propose a reflection on the role that Conceptual Spaces, a framework developed by Peter G\u007f\u00e4rdenfors [G\u007f\u00e4rdenfors (2000)] more than fifteen years ago, can play in the current development of the Knowledge Level in Cognitive Systems and Architectures. In particular, we claim that Conceptual Spaces offer a lingua franca that allows to unify and generalize many aspects of the symbolic, sub-symbolic and diagrammatic approaches (by overcoming some of their typical problems) and to integrate them on a common ground. In doing so we extend and detail some of the arguments explored by G\u007f\u00e4rdenfors [G\u007f\u00e4rdenfors (1997)] for defending the need of a conceptual, intermediate, representation level between the symbolic and the sub-symbolic one.\n    ",
        "submission_date": "2017-01-02T00:00:00",
        "last_modified_date": "2017-01-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.00642",
        "title": "Finding Risk-Averse Shortest Path with Time-dependent Stochastic Costs",
        "authors": [
            "Dajian Li",
            "Paul Weng",
            "Orkun Karabasoglu"
        ],
        "abstract": "In this paper, we tackle the problem of risk-averse route planning in a transportation network with time-dependent and stochastic costs. To solve this problem, we propose an adaptation of the A* algorithm that accommodates any risk measure or decision criterion that is monotonic with first-order stochastic dominance. We also present a case study of our algorithm on the Manhattan, NYC, transportation network.\n    ",
        "submission_date": "2017-01-03T00:00:00",
        "last_modified_date": "2017-01-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.00646",
        "title": "From Preference-Based to Multiobjective Sequential Decision-Making",
        "authors": [
            "Paul Weng"
        ],
        "abstract": "In this paper, we present a link between preference-based and multiobjective sequential decision-making. While transforming a multiobjective problem to a preference-based one is quite natural, the other direction is a bit less obvious. We present how this transformation (from preference-based to multiobjective) can be done under the classic condition that preferences over histories can be represented by additively decomposable utilities and that the decision criterion to evaluate policies in a state is based on expectation. This link yields a new source of multiobjective sequential decision-making problems (i.e., when reward values are unknown) and justifies the use of solving methods developed in one setting in the other one.\n    ",
        "submission_date": "2017-01-03T00:00:00",
        "last_modified_date": "2017-01-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.00696",
        "title": "A pre-semantics for counterfactual conditionals and similar logics",
        "authors": [
            "Karl Schlechta"
        ],
        "abstract": "The elegant Stalnaker/Lewis semantics for counterfactual conditonals works with distances between models. But human beings certainly have no tables of models and distances in their head. We begin here an investigation using a more realistic picture, based on findings in neuroscience. We call it a pre-semantics, as its meaning is not a description of the world, but of the brain, whose structure is (partly) determined by the world it reasons about. In the final section, we reconsider the components, and postulate that there are no atomic pictures, we can always look inside.\n    ",
        "submission_date": "2016-12-06T00:00:00",
        "last_modified_date": "2017-04-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.00833",
        "title": "Fuzzy finite element model updating using metaheuristic optimization algorithms",
        "authors": [
            "I. Boulkaibet",
            "T. Marwala",
            "M.I. Friswell",
            "H. Haddad Khodaparast",
            "S. Adhikari"
        ],
        "abstract": "In this paper, a non-probabilistic method based on fuzzy logic is used to update finite element models (FEMs). Model updating techniques use the measured data to improve the accuracy of numerical models of structures. However, the measured data are contaminated with experimental noise and the models are inaccurate due to randomness in the parameters. This kind of aleatory uncertainty is irreducible, and may decrease the accuracy of the finite element model updating process. However, uncertainty quantification methods can be used to identify the uncertainty in the updating parameters. In this paper, the uncertainties associated with the modal parameters are defined as fuzzy membership functions, while the model updating procedure is defined as an optimization problem at each {\\alpha}-cut level. To determine the membership functions of the updated parameters, an objective function is defined and minimized using two metaheuristic optimization algorithms: ant colony optimization (ACO) and particle swarm optimization (PSO). A structural example is used to investigate the accuracy of the fuzzy model updating strategy using the PSO and ACO algorithms. Furthermore, the results obtained by the fuzzy finite element model updating are compared with the Bayesian model updating results.\n    ",
        "submission_date": "2017-01-03T00:00:00",
        "last_modified_date": "2017-01-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.00867",
        "title": "A K-fold Method for Baseline Estimation in Policy Gradient Algorithms",
        "authors": [
            "Nithyanand Kota",
            "Abhishek Mishra",
            "Sunil Srinivasa",
            "Chen",
            "Pieter Abbeel"
        ],
        "abstract": "The high variance issue in unbiased policy-gradient methods such as VPG and REINFORCE is typically mitigated by adding a baseline. However, the baseline fitting itself suffers from the underfitting or the overfitting problem. In this paper, we develop a K-fold method for baseline estimation in policy gradient algorithms. The parameter K is the baseline estimation hyperparameter that can adjust the bias-variance trade-off in the baseline estimates. We demonstrate the usefulness of our approach via two state-of-the-art policy gradient algorithms on three MuJoCo locomotive control tasks.\n    ",
        "submission_date": "2017-01-03T00:00:00",
        "last_modified_date": "2017-01-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.00877",
        "title": "On the Usability of Probably Approximately Correct Implication Bases",
        "authors": [
            "Daniel Borchmann",
            "Tom Hanika",
            "Sergei Obiedkov"
        ],
        "abstract": "We revisit the notion of probably approximately correct implication bases from the literature and present a first formulation in the language of formal concept analysis, with the goal to investigate whether such bases represent a suitable substitute for exact implication bases in practical use-cases. To this end, we quantitatively examine the behavior of probably approximately correct implication bases on artificial and real-world data sets and compare their precision and recall with respect to their corresponding exact implication bases. Using a small example, we also provide qualitative insight that implications from probably approximately correct bases can still represent meaningful knowledge from a given data set.\n    ",
        "submission_date": "2017-01-04T00:00:00",
        "last_modified_date": "2017-01-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.01048",
        "title": "Stochastic Planning and Lifted Inference",
        "authors": [
            "Roni Khardon",
            "Scott Sanner"
        ],
        "abstract": "Lifted probabilistic inference (Poole, 2003) and symbolic dynamic programming for lifted stochastic planning (Boutilier et al, 2001) were introduced around the same time as algorithmic efforts to use abstraction in stochastic systems. Over the years, these ideas evolved into two distinct lines of research, each supported by a rich literature. Lifted probabilistic inference focused on efficient arithmetic operations on template-based graphical models under a finite domain assumption while symbolic dynamic programming focused on supporting sequential decision-making in rich quantified logical action models and on open domain reasoning. Given their common motivation but different focal points, both lines of research have yielded highly complementary innovations. In this chapter, we aim to help close the gap between these two research areas by providing an overview of lifted stochastic planning from the perspective of probabilistic inference, showing strong connections to other chapters in this book. This also allows us to define Generalized Lifted Inference as a paradigm that unifies these areas and elucidates open problems for future research that can benefit both lifted inference and stochastic planning.\n    ",
        "submission_date": "2017-01-04T00:00:00",
        "last_modified_date": "2017-01-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.01302",
        "title": "Toward negotiable reinforcement learning: shifting priorities in Pareto optimal sequential decision-making",
        "authors": [
            "Andrew Critch"
        ],
        "abstract": "Existing multi-objective reinforcement learning (MORL) algorithms do not account for objectives that arise from players with differing beliefs. Concretely, consider two players with different beliefs and utility functions who may cooperate to build a machine that takes actions on their behalf. A representation is needed for how much the machine's policy will prioritize each player's interests over time. Assuming the players have reached common knowledge of their situation, this paper derives a recursion that any Pareto optimal policy must satisfy. Two qualitative observations can be made from the recursion: the machine must (1) use each player's own beliefs in evaluating how well an action will serve that player's utility function, and (2) shift the relative priority it assigns to each player's expected utilities over time, by a factor proportional to how well that player's beliefs predict the machine's inputs. Observation (2) represents a substantial divergence from na\u00efve linear utility aggregation (as in Harsanyi's utilitarian theorem, and existing MORL algorithms), which is shown here to be inadequate for Pareto optimal sequential decision-making on behalf of players with different beliefs.\n    ",
        "submission_date": "2017-01-05T00:00:00",
        "last_modified_date": "2017-05-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.01487",
        "title": "Designing a Safe Autonomous Artificial Intelligence Agent based on Human Self-Regulation",
        "authors": [
            "Mark Muraven"
        ],
        "abstract": "There is a growing focus on how to design safe artificial intelligent (AI) agents. As systems become more complex, poorly specified goals or control mechanisms may cause AI agents to engage in unwanted and harmful outcomes. Thus it is necessary to design AI agents that follow initial programming intentions as the program grows in complexity. How to specify these initial intentions has also been an obstacle to designing safe AI agents. Finally, there is a need for the AI agent to have redundant safety mechanisms to ensure that any programming errors do not cascade into major problems. Humans are autonomous intelligent agents that have avoided these problems and the present manuscript argues that by understanding human self-regulation and goal setting, we may be better able to design safe AI agents. Some general principles of human self-regulation are outlined and specific guidance for AI design is given.\n    ",
        "submission_date": "2017-01-05T00:00:00",
        "last_modified_date": "2017-01-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.01497",
        "title": "Learning local trajectories for high precision robotic tasks : application to KUKA LBR iiwa Cartesian positioning",
        "authors": [
            "Joris Guerin",
            "Olivier Gibaru",
            "Eric Nyiri",
            "Stephane Thiery"
        ],
        "abstract": "To ease the development of robot learning in industry, two conditions need to be fulfilled. Manipulators must be able to learn high accuracy and precision tasks while being safe for workers in the factory. In this paper, we extend previously submitted work which consists in rapid learning of local high accuracy behaviors. By exploration and regression, linear and quadratic models are learnt for respectively the dynamics and cost function. Iterative Linear Quadratic Gaussian Regulator combined with cost quadratic regression can converge rapidly in the final stages towards high accuracy behavior as the cost function is modelled quite precisely. In this paper, both a different cost function and a second order improvement method are implemented within this framework. We also propose an analysis of the algorithm parameters through simulation for a positioning task. Finally, an experimental validation on a KUKA LBR iiwa robot is carried out. This collaborative robot manipulator can be easily programmed into safety mode, which makes it qualified for the second industry constraint stated above.\n    ",
        "submission_date": "2017-01-05T00:00:00",
        "last_modified_date": "2017-01-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.01724",
        "title": "DeepStack: Expert-Level Artificial Intelligence in No-Limit Poker",
        "authors": [
            "Matej Morav\u010d\u00edk",
            "Martin Schmid",
            "Neil Burch",
            "Viliam Lis\u00fd",
            "Dustin Morrill",
            "Nolan Bard",
            "Trevor Davis",
            "Kevin Waugh",
            "Michael Johanson",
            "Michael Bowling"
        ],
        "abstract": "Artificial intelligence has seen several breakthroughs in recent years, with games often serving as milestones. A common feature of these games is that players have perfect information. Poker is the quintessential game of imperfect information, and a longstanding challenge problem in artificial intelligence. We introduce DeepStack, an algorithm for imperfect information settings. It combines recursive reasoning to handle information asymmetry, decomposition to focus computation on the relevant decision, and a form of intuition that is automatically learned from self-play using deep learning. In a study involving 44,000 hands of poker, DeepStack defeated with statistical significance professional poker players in heads-up no-limit Texas hold'em. The approach is theoretically sound and is shown to produce more difficult to exploit strategies than prior approaches.\n    ",
        "submission_date": "2017-01-06T00:00:00",
        "last_modified_date": "2017-03-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.02163",
        "title": "Just an Update on PMING Distance for Web-based Semantic Similarity in Artificial Intelligence and Data Mining",
        "authors": [
            "Valentina Franzoni"
        ],
        "abstract": "One of the main problems that emerges in the classic approach to semantics is the difficulty in acquisition and maintenance of ontologies and semantic annotations. On the other hand, the Internet explosion and the massive diffusion of mobile smart devices lead to the creation of a worldwide system, which information is daily checked and fueled by the contribution of millions of users who interacts in a collaborative way. Search engines, continually exploring the Web, are a natural source of information on which to base a modern approach to semantic annotation. A promising idea is that it is possible to generalize the semantic similarity, under the assumption that semantically similar terms behave similarly, and define collaborative proximity measures based on the indexing information returned by search engines. The PMING Distance is a proximity measure used in data mining and information retrieval, which collaborative information express the degree of relationship between two terms, using only the number of documents returned as result for a query on a search engine. In this work, the PMINIG Distance is updated, providing a novel formal algebraic definition, which corrects previous works. The novel point of view underlines the features of the PMING to be a locally normalized linear combination of the Pointwise Mutual Information and Normalized Google Distance. The analyzed measure dynamically reflects the collaborative change made on the web resources.\n    ",
        "submission_date": "2017-01-09T00:00:00",
        "last_modified_date": "2017-01-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.02388",
        "title": "Stoic Ethics for Artificial Agents",
        "authors": [
            "Gabriel Murray"
        ],
        "abstract": "We present a position paper advocating the notion that Stoic philosophy and ethics can inform the development of ethical A.I. systems. This is in sharp contrast to most work on building ethical A.I., which has focused on Utilitarian or Deontological ethical theories. We relate ethical A.I. to several core Stoic notions, including the dichotomy of control, the four cardinal virtues, the ideal Sage, Stoic practices, and Stoic perspectives on emotion or affect. More generally, we put forward an ethical view of A.I. that focuses more on internal states of the artificial agent rather than on external actions of the agent. We provide examples relating to near-term A.I. systems as well as hypothetical superintelligent agents.\n    ",
        "submission_date": "2017-01-09T00:00:00",
        "last_modified_date": "2017-03-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.02543",
        "title": "Predicting Citywide Crowd Flows Using Deep Spatio-Temporal Residual Networks",
        "authors": [
            "Junbo Zhang",
            "Yu Zheng",
            "Dekang Qi",
            "Ruiyuan Li",
            "Xiuwen Yi",
            "Tianrui Li"
        ],
        "abstract": "Forecasting the flow of crowds is of great importance to traffic management and public safety, and very challenging as it is affected by many complex factors, including spatial dependencies (nearby and distant), temporal dependencies (closeness, period, trend), and external conditions (e.g., weather and events). We propose a deep-learning-based approach, called ST-ResNet, to collectively forecast two types of crowd flows (i.e. inflow and outflow) in each and every region of a city. We design an end-to-end structure of ST-ResNet based on unique properties of spatio-temporal data. More specifically, we employ the residual neural network framework to model the temporal closeness, period, and trend properties of crowd traffic. For each property, we design a branch of residual convolutional units, each of which models the spatial properties of crowd traffic. ST-ResNet learns to dynamically aggregate the output of the three residual neural networks based on data, assigning different weights to different branches and regions. The aggregation is further combined with external factors, such as weather and day of the week, to predict the final traffic of crowds in each and every region. We have developed a real-time system based on Microsoft Azure Cloud, called UrbanFlow, providing the crowd flow monitoring and forecasting in Guiyang City of China. In addition, we present an extensive experimental evaluation using two types of crowd flows in Beijing and New York City (NYC), where ST-ResNet outperforms nine well-known baselines.\n    ",
        "submission_date": "2017-01-10T00:00:00",
        "last_modified_date": "2017-01-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.02545",
        "title": "IoFClime: The fuzzy logic and the Internet of Things to control indoor temperature regarding the outdoor ambient conditions",
        "authors": [
            "Daniel Meana-Llori\u00e1n",
            "Cristian Gonz\u00e1lez Garc\u00eda",
            "B. Cristina Pelayo G-Bustelo",
            "Juan Manuel Cueva Lovelle",
            "Nestor Garcia-Fernandez"
        ],
        "abstract": "The Internet of Things is arriving to our homes or cities through fields already known like Smart Homes, Smart Cities, or Smart Towns. The monitoring of environmental conditions of cities can help to adapt the indoor locations of the cities in order to be more comfortable for people who stay there. A way to improve the indoor conditions is an efficient temperature control, however, it depends on many factors like the different combinations of outdoor temperature and humidity. Therefore, adjusting the indoor temperature is not setting a value according to other value. There are many more factors to take into consideration, hence the traditional logic based in binary states cannot be used. Many problems cannot be solved with a set of binary solutions and we need a new way of development. Fuzzy logic is able to interpret many states, more than two states, giving to computers the capacity to react in a similar way to people. In this paper we will propose a new approach to control the temperature using the Internet of Things together its platforms and fuzzy logic regarding not only the indoor temperature but also the outdoor temperature and humidity in order to save energy and to set a more comfortable environment for their users. Finally, we will conclude that the fuzzy approach allows us to achieve an energy saving around 40% and thus, save money.\n    ",
        "submission_date": "2017-01-10T00:00:00",
        "last_modified_date": "2017-01-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.03000",
        "title": "A Framework for Knowledge Management and Automated Reasoning Applied on Intelligent Transport Systems",
        "authors": [
            "Aneta Vulgarakis Feljan",
            "Athanasios Karapantelakis",
            "Leonid Mokrushin",
            "Hongxin Liang",
            "Rafia Inam",
            "Elena Fersman",
            "Carlos R.B. Azevedo",
            "Klaus Raizer",
            "Ricardo S. Souza"
        ],
        "abstract": "Cyber-Physical Systems in general, and Intelligent Transport Systems (ITS) in particular use heterogeneous data sources combined with problem solving expertise in order to make critical decisions that may lead to some form of actions e.g., driver notifications, change of traffic light signals and braking to prevent an accident. Currently, a major part of the decision process is done by human domain experts, which is time-consuming, tedious and error-prone. Additionally, due to the intrinsic nature of knowledge possession this decision process cannot be easily replicated or reused. Therefore, there is a need for automating the reasoning processes by providing computational systems a formal representation of the domain knowledge and a set of methods to process that knowledge. In this paper, we propose a knowledge model that can be used to express both declarative knowledge about the systems' components, their relations and their current state, as well as procedural knowledge representing possible system behavior. In addition, we introduce a framework for knowledge management and automated reasoning (KMARF). The idea behind KMARF is to automatically select an appropriate problem solver based on formalized reasoning expertise in the knowledge base, and convert a problem definition to the corresponding format. This approach automates reasoning, thus reducing operational costs, and enables reusability of knowledge and methods across different domains. We illustrate the approach on a transportation planning use case.\n    ",
        "submission_date": "2017-01-11T00:00:00",
        "last_modified_date": "2017-01-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.03037",
        "title": "Towards Smart Proof Search for Isabelle",
        "authors": [
            "Yutaka Nagashima"
        ],
        "abstract": "Despite the recent progress in automatic theorem provers, proof engineers are still suffering from the lack of powerful proof automation. In this position paper we first report our proof strategy language based on a meta-tool approach. Then, we propose an AI-based approach to drastically improve proof automation for Isabelle, while identifying three major challenges we plan to address for this objective.\n    ",
        "submission_date": "2017-01-10T00:00:00",
        "last_modified_date": "2017-01-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.03322",
        "title": "From First-Order Logic to Assertional Logic",
        "authors": [
            "Yi Zhou"
        ],
        "abstract": "First-Order Logic (FOL) is widely regarded as one of the most important foundations for knowledge representation. Nevertheless, in this paper, we argue that FOL has several critical issues for this purpose. Instead, we propose an alternative called assertional logic, in which all syntactic objects are categorized as set theoretic constructs including individuals, concepts and operators, and all kinds of knowledge are formalized by equality assertions. We first present a primitive form of assertional logic that uses minimal assumed knowledge and constructs. Then, we show how to extend it by definitions, which are special kinds of knowledge, i.e., assertions. We argue that assertional logic, although simpler, is more expressive and extensible than FOL. As a case study, we show how assertional logic can be used to unify logic and probability, and more building blocks in AI.\n    ",
        "submission_date": "2017-01-12T00:00:00",
        "last_modified_date": "2017-04-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.03500",
        "title": "A Savage-Like Axiomatization for Nonstandard Expected Utility",
        "authors": [
            "Grant Molnar"
        ],
        "abstract": "Since Leonard Savage's epoch-making \"Foundations of Statistics\", Subjective Expected Utility Theory has been the presumptive model for decision-making. Savage provided an act-based axiomatization of standard expected utility theory. In this article, we provide a Savage-like axiomatization of nonstandard expected utility theory. It corresponds to a weakening of Savage's 6th axiom.\n    ",
        "submission_date": "2017-01-12T00:00:00",
        "last_modified_date": "2018-02-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.03571",
        "title": "Fuzzy Clustering Data Given in the Ordinal Scale",
        "authors": [
            "Zhengbing Hu",
            "Yevgeniy V. Bodyanskiy",
            "Oleksii K. Tyshchenko",
            "Viktoriia O. Samitova"
        ],
        "abstract": "A fuzzy clustering algorithm for multidimensional data is proposed in this article. The data is described by vectors whose components are linguistic variables defined in an ordinal scale. The obtained results confirm the efficiency of the proposed approach.\n    ",
        "submission_date": "2017-01-13T00:00:00",
        "last_modified_date": "2017-01-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.03714",
        "title": "On the links between argumentation-based reasoning and nonmonotonic reasoning",
        "authors": [
            "Zimi Li",
            "Nir Oren",
            "Simon Parsons"
        ],
        "abstract": "In this paper we investigate the links between instantiated argumentation systems and the axioms for non-monotonic reasoning described in [9] with the aim of characterising the nature of argument based reasoning. In doing so, we consider two possible interpretations of the consequence relation, and describe which axioms are met by ASPIC+ under each of these interpretations. We then consider the links between these axioms and the rationality postulates. Our results indicate that argument based reasoning as characterised by ASPIC+ is - according to the axioms of [9] - non-cumulative and non-monotonic, and therefore weaker than the weakest non-monotonic reasoning systems they considered possible. This weakness underpins ASPIC+'s success in modelling other reasoning systems, and we conclude by considering the relationship between ASPIC+ and other weak logical systems.\n    ",
        "submission_date": "2017-01-13T00:00:00",
        "last_modified_date": "2017-01-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.03866",
        "title": "Long Timescale Credit Assignment in NeuralNetworks with External Memory",
        "authors": [
            "Steven Stenberg Hansen"
        ],
        "abstract": "Credit assignment in traditional recurrent neural networks usually involves back-propagating through a long chain of tied weight matrices. The length of this chain scales linearly with the number of time-steps as the same network is run at each time-step. This creates many problems, such as vanishing gradients, that have been well studied. In contrast, a NNEM's architecture recurrent activity doesn't involve a long chain of activity (though some architectures such as the NTM do utilize a traditional recurrent architecture as a controller). Rather, the externally stored embedding vectors are used at each time-step, but no messages are passed from previous time-steps. This means that vanishing gradients aren't a problem, as all of the necessary gradient paths are short. However, these paths are extremely numerous (one per embedding vector in memory) and reused for a very long time (until it leaves the memory). Thus, the forward-pass information of each memory must be stored for the entire duration of the memory. This is problematic as this additional storage far surpasses that of the actual memories, to the extent that large memories on infeasible to back-propagate through in high dimensional settings. One way to get around the need to hold onto forward-pass information is to recalculate the forward-pass whenever gradient information is available. However, if the observations are too large to store in the domain of interest, direct reinstatement of a forward pass cannot occur. Instead, we rely on a learned autoencoder to reinstate the observation, and then use the embedding network to recalculate the forward-pass. Since the recalculated embedding vector is unlikely to perfectly match the one stored in memory, we try out 2 approximations to utilize error gradient w.r.t. the vector in memory.\n    ",
        "submission_date": "2017-01-14T00:00:00",
        "last_modified_date": "2017-01-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.03868",
        "title": "Minimally Naturalistic Artificial Intelligence",
        "authors": [
            "Steven Stenberg Hansen"
        ],
        "abstract": "The rapid advancement of machine learning techniques has re-energized research into general artificial intelligence. While the idea of domain-agnostic meta-learning is appealing, this emerging field must come to terms with its relationship to human cognition and the statistics and structure of the tasks humans perform. The position of this article is that only by aligning our agents' abilities and environments with those of humans do we stand a chance at developing general artificial intelligence (GAI). A broad reading of the famous 'No Free Lunch' theorem is that there is no universally optimal inductive bias or, equivalently, bias-free learning is impossible. This follows from the fact that there are an infinite number of ways to extrapolate data, any of which might be the one used by the data generating environment; an inductive bias prefers some of these extrapolations to others, which lowers performance in environments using these adversarial extrapolations. We may posit that the optimal GAI is the one that maximally exploits the statistics of its environment to create its inductive bias; accepting the fact that this agent is guaranteed to be extremely sub-optimal for some alternative environments. This trade-off appears benign when thinking about the environment as being the physical universe, as performance on any fictive universe is obviously irrelevant. But, we should expect a sharper inductive bias if we further constrain our environment. Indeed, we implicitly do so by defining GAI in terms of accomplishing that humans consider useful. One common version of this is need the for 'common-sense reasoning', which implicitly appeals to the statistics of physical universe as perceived by humans.\n    ",
        "submission_date": "2017-01-14T00:00:00",
        "last_modified_date": "2017-01-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.03937",
        "title": "Hedera: Scalable Indexing and Exploring Entities in Wikipedia Revision History",
        "authors": [
            "Tuan Tran",
            "Tu Ngoc Nguyen"
        ],
        "abstract": "Much of work in semantic web relying on Wikipedia as the main source of knowledge often work on static snapshots of the dataset. The full history of Wikipedia revisions, while contains much more useful information, is still difficult to access due to its exceptional volume. To enable further research on this collection, we developed a tool, named Hedera, that efficiently extracts semantic information from Wikipedia revision history datasets. Hedera exploits Map-Reduce paradigm to achieve rapid extraction, it is able to handle one entire Wikipedia articles revision history within a day in a medium-scale cluster, and supports flexible data structures for various kinds of semantic web study.\n    ",
        "submission_date": "2017-01-14T00:00:00",
        "last_modified_date": "2017-01-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.04569",
        "title": "Multiobjective Optimization of Solar Powered Irrigation System with Fuzzy Type-2 Noise Modelling",
        "authors": [
            "T.Ganesan",
            "P.Vasant",
            "I.Elamvazuthi"
        ],
        "abstract": "Optimization is becoming a crucial element in industrial applications involving sustainable alternative energy systems. During the design of such systems, the engineer/decision maker would often encounter noise factors (e.g. solar insolation and ambient temperature fluctuations) when their system interacts with the environment. In this chapter, the sizing and design optimization of the solar powered irrigation system was considered. This problem is multivariate, noisy, nonlinear and multiobjective. This design problem was tackled by first using the Fuzzy Type II approach to model the noise factors. Consequently, the Bacterial Foraging Algorithm (BFA) (in the context of a weighted sum framework) was employed to solve this multiobjective fuzzy design problem. This method was then used to construct the approximate Pareto frontier as well as to identify the best solution option in a fuzzy setting. Comprehensive analyses and discussions were performed on the generated numerical results with respect to the implemented solution methods.\n    ",
        "submission_date": "2017-01-17T00:00:00",
        "last_modified_date": "2017-01-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.04645",
        "title": "Une mesure d'expertise pour le crowdsourcing",
        "authors": [
            "Hosna Ouni",
            "Arnaud Martin",
            "Laetitia Gros",
            "Mouloud Kharoune",
            "Zoltan Miklos"
        ],
        "abstract": "Crowdsourcing, a major economic issue, is the fact that the firm outsources internal task to the crowd. It is a form of digital subcontracting for the general public. The evaluation of the participants work quality is a major issue in crowdsourcing. Indeed, contributions must be controlled to ensure the effectiveness and relevance of the campaign. We are particularly interested in small, fast and not automatable tasks. Several methods have been proposed to solve this problem, but they are applicable when the \"golden truth\" is not always known. This work has the particularity to propose a method for calculating the degree of expertise in the presence of gold data in crowdsourcing. This method is based on the belief function theory and proposes a structuring of data using graphs. The proposed approach will be assessed and applied to the data.\n    ",
        "submission_date": "2017-01-17T00:00:00",
        "last_modified_date": "2017-01-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.04663",
        "title": "Intrinsically Motivated Acquisition of Modular Slow Features for Humanoids in Continuous and Non-Stationary Environments",
        "authors": [
            "Varun Raj Kompella",
            "Laurenz Wiskott"
        ],
        "abstract": "A compact information-rich representation of the environment, also called a feature abstraction, can simplify a robot's task of mapping its raw sensory inputs to useful action sequences. However, in environments that are non-stationary and only partially observable, a single abstraction is probably not sufficient to encode most variations. Therefore, learning multiple sets of spatially or temporally local, modular abstractions of the inputs would be beneficial. How can a robot learn these local abstractions without a teacher? More specifically, how can it decide from where and when to start learning a new abstraction? A recently proposed algorithm called Curious Dr. MISFA addresses this problem. The algorithm is based on two underlying learning principles called artificial curiosity and slowness. The former is used to make the robot self-motivated to explore by rewarding itself whenever it makes progress learning an abstraction; the later is used to update the abstraction by extracting slowly varying components from raw sensory inputs. Curious Dr. MISFA's application is, however, limited to discrete domains constrained by a pre-defined state space and has design limitations that make it unstable in certain situations. This paper presents a significant improvement that is applicable to continuous environments, is computationally less expensive, simpler to use with fewer hyper parameters, and stable in certain non-stationary environments. We demonstrate the efficacy and stability of our method in a vision-based robot simulator.\n    ",
        "submission_date": "2017-01-17T00:00:00",
        "last_modified_date": "2017-01-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.04895",
        "title": "Unknowable Manipulators: Social Network Curator Algorithms",
        "authors": [
            "Samuel Albanie",
            "Hillary Shakespeare",
            "Tom Gunter"
        ],
        "abstract": "For a social networking service to acquire and retain users, it must find ways to keep them engaged. By accurately gauging their preferences, it is able to serve them with the subset of available content that maximises revenue for the site. Without the constraints of an appropriate regulatory framework, we argue that a sufficiently sophisticated curator algorithm tasked with performing this process may choose to explore curation strategies that are detrimental to users. In particular, we suggest that such an algorithm is capable of learning to manipulate its users, for several qualitative reasons: 1. Access to vast quantities of user data combined with ongoing breakthroughs in the field of machine learning are leading to powerful but uninterpretable strategies for decision making at scale. 2. The availability of an effective feedback mechanism for assessing the short and long term user responses to curation strategies. 3. Techniques from reinforcement learning have allowed machines to learn automated and highly successful strategies at an abstract level, often resulting in non-intuitive yet nonetheless highly appropriate action selection. In this work, we consider the form that these strategies for user manipulation might take and scrutinise the role that regulation should play in the design of such systems.\n    ",
        "submission_date": "2017-01-17T00:00:00",
        "last_modified_date": "2017-01-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.05059",
        "title": "Ontology based system to guide internship assignment process",
        "authors": [
            "Abir M 'Baya",
            "Jannik Laval",
            "Nejib Moalla",
            "Yacine Ouzrout",
            "Abdelaziz Bouras"
        ],
        "abstract": "Internship assignment is a complicated process for universities since it is necessary to take into account a multiplicity of variables to establish a compromise between companies' requirements and student competencies acquired during the university training. These variables build up a complex relations map that requires the formulation of an exhaustive and rigorous conceptual scheme. In this research a domain ontological model is presented as support to the student's decision making for opportunities of University studies level of the University Lumiere Lyon 2 (ULL) education system. The ontology is designed and created using methodological approach offering the possibility of improving the progressive creation, capture and knowledge articulation. In this paper, we draw a balance taking the demands of the companies across the capabilities of the students. This will be done through the establishment of an ontological model of an educational learners' profile and the internship postings which are written in a free text and using uncontrolled vocabulary. Furthermore, we outline the process of semantic matching which improves the quality of query results.\n    ",
        "submission_date": "2017-01-18T00:00:00",
        "last_modified_date": "2017-01-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.05130",
        "title": "On the Performance of Network Parallel Training in Artificial Neural Networks",
        "authors": [
            "Ludvig Ericson",
            "Rendani Mbuvha"
        ],
        "abstract": "Artificial Neural Networks (ANNs) have received increasing attention in recent years with applications that span a wide range of disciplines including vital domains such as medicine, network security and autonomous transportation. However, neural network architectures are becoming increasingly complex and with an increasing need to obtain real-time results from such models, it has become pivotal to use parallelization as a mechanism for speeding up network training and deployment. In this work we propose an implementation of Network Parallel Training through Cannon's Algorithm for matrix multiplication. We show that increasing the number of processes speeds up training until the point where process communication costs become prohibitive; this point varies by network complexity. We also show through empirical efficiency calculations that the speedup obtained is superlinear.\n    ",
        "submission_date": "2017-01-18T00:00:00",
        "last_modified_date": "2017-01-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.05226",
        "title": "Reasoning in Non-Probabilistic Uncertainty: Logic Programming and Neural-Symbolic Computing as Examples",
        "authors": [
            "Tarek R. Besold",
            "Artur d'Avila Garcez",
            "Keith Stenning",
            "Leendert van der Torre",
            "Michiel van Lambalgen"
        ],
        "abstract": "This article aims to achieve two goals: to show that probability is not the only way of dealing with uncertainty (and even more, that there are kinds of uncertainty which are for principled reasons not addressable with probabilistic means); and to provide evidence that logic-based methods can well support reasoning with uncertainty. For the latter claim, two paradigmatic examples are presented: Logic Programming with Kleene semantics for modelling reasoning from information in a discourse, to an interpretation of the state of affairs of the intended model, and a neural-symbolic implementation of Input/Output logic for dealing with uncertainty in dynamic normative contexts.\n    ",
        "submission_date": "2017-01-18T00:00:00",
        "last_modified_date": "2017-03-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.05291",
        "title": "Heterogeneous Information Network Embedding for Meta Path based Proximity",
        "authors": [
            "Zhipeng Huang",
            "Nikos Mamoulis"
        ],
        "abstract": "A network embedding is a representation of a large graph in a low-dimensional space, where vertices are modeled as vectors. The objective of a good embedding is to preserve the proximity between vertices in the original graph. This way, typical search and mining methods can be applied in the embedded space with the help of off-the-shelf multidimensional indexing approaches. Existing network embedding techniques focus on homogeneous networks, where all vertices are considered to belong to a single class.\n    ",
        "submission_date": "2017-01-19T00:00:00",
        "last_modified_date": "2017-01-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.05334",
        "title": "Fuzzy Ontology-Based Sentiment Analysis of Transportation and City Feature Reviews for Safe Traveling",
        "authors": [
            "Farman Ali",
            "D. Kwak",
            "Pervez Khan",
            "S.M. Riazul Islam",
            "K.H. Kim",
            "K.S. Kwak"
        ],
        "abstract": "Traffic congestion is rapidly increasing in urban areas, particularly in mega cities. To date, there exist a few sensor network based systems to address this problem. However, these techniques are not suitable enough in terms of monitoring an entire transportation system and delivering emergency services when needed. These techniques require real-time data and intelligent ways to quickly determine traffic activity from useful information. In addition, these existing systems and websites on city transportation and travel rely on rating scores for different factors (e.g., safety, low crime rate, cleanliness, etc.). These rating scores are not efficient enough to deliver precise information, whereas reviews or tweets are significant, because they help travelers and transportation administrators to know about each aspect of the city. However, it is difficult for travelers to read, and for transportation systems to process, all reviews and tweets to obtain expressive sentiments regarding the needs of the city. The optimum solution for this kind of problem is analyzing the information available on social network platforms and performing sentiment analysis. On the other hand, crisp ontology-based frameworks cannot extract blurred information from tweets and reviews; therefore, they produce inadequate results. In this regard, this paper proposes fuzzy ontology-based sentiment analysis and SWRL rule-based decision-making to monitor transportation activities and to make a city- feature polarity map for travelers. This system retrieves reviews and tweets related to city features and transportation activities. The feature opinions are extracted from these retrieved data, and then fuzzy ontology is used to determine the transportation and city-feature polarity. A fuzzy ontology and an intelligent system prototype are developed by using Prot\u00e9g\u00e9 OWL and Java, respectively.\n    ",
        "submission_date": "2017-01-19T00:00:00",
        "last_modified_date": "2017-01-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.05724",
        "title": "Logical Inferences with Contexts of RDF Triples",
        "authors": [
            "Vinh Nguyen",
            "Amit Sheth"
        ],
        "abstract": "Logical inference, an integral feature of the Semantic Web, is the process of deriving new triples by applying entailment rules on knowledge bases. The entailment rules are determined by the model-theoretic semantics. Incorporating context of an RDF triple (e.g., provenance, time, and location) into the inferencing process requires the formal semantics to be capable of describing the context of RDF triples also in the form of triples, or in other words, RDF contextual triples about triples. The formal semantics should also provide the rules that could entail new contextual triples about triples. In this paper, we propose the first inferencing mechanism that allows context of RDF triples, represented in the form of RDF triples about triples, to be the first-class citizens in the model-theoretic semantics and in the logical rules. Our inference mechanism is well-formalized with all new concepts being captured in the model-theoretic semantics. This formal semantics also allows us to derive a new set of entailment rules that could entail new contextual triples about triples. To demonstrate the feasibility and the scalability of the proposed mechanism, we implement a new tool in which we transform the existing knowledge bases to our representation of RDF triples about triples and provide the option for this tool to compute the inferred triples for the proposed rules. We evaluate the computation of the proposed rules on a large scale using various real-world knowledge bases such as Bio2RDF NCBI Genes and DBpedia. The results show that the computation of the inferred triples can be highly scalable. On average, one billion inferred triples adds 5-6 minutes to the overall transformation process. NCBI Genes, with 20 billion triples in total, took only 232 minutes for the transformation of 12 billion triples and added 42 minutes for inferring 8 billion triples to the overall process.\n    ",
        "submission_date": "2017-01-20T00:00:00",
        "last_modified_date": "2017-01-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.06049",
        "title": "Interactive Learning from Policy-Dependent Human Feedback",
        "authors": [
            "James MacGlashan",
            "Mark K Ho",
            "Robert Loftin",
            "Bei Peng",
            "Guan Wang",
            "David Roberts",
            "Matthew E. Taylor",
            "Michael L. Littman"
        ],
        "abstract": "This paper investigates the problem of interactively learning behaviors communicated by a human teacher using positive and negative feedback. Much previous work on this problem has made the assumption that people provide feedback for decisions that is dependent on the behavior they are teaching and is independent from the learner's current policy. We present empirical results that show this assumption to be false -- whether human trainers give a positive or negative feedback for a decision is influenced by the learner's current policy. Based on this insight, we introduce {\\em Convergent Actor-Critic by Humans} (COACH), an algorithm for learning from policy-dependent feedback that converges to a local optimum. Finally, we demonstrate that COACH can successfully learn multiple behaviors on a physical robot.\n    ",
        "submission_date": "2017-01-21T00:00:00",
        "last_modified_date": "2023-01-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.06167",
        "title": "Binary Matrix Guessing Problem",
        "authors": [
            "\u00c7a\u011fr\u0131 Latifo\u011flu"
        ],
        "abstract": "We introduce the Binary Matrix Guessing Problem and provide two algorithms to solve this problem. The first algorithm we introduce is Elementwise Probing Algorithm (EPA) which is very fast under a score which utilizes Frobenius Distance. The second algorithm is Additive Reinforcement Learning Algorithm which combines ideas from perceptron algorithm and reinforcement learning algorithm. This algorithm is significantly slower compared to first one, but less restrictive and generalizes better. We compare computational performance of both algorithms and provide numerical results.\nreason for withdrawal: Paper will be rewritten with experiments replicated on verified and validated hardware and software.\n    ",
        "submission_date": "2017-01-22T00:00:00",
        "last_modified_date": "2018-10-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.06388",
        "title": "Constraint programming for planning test campaigns of communications satellites",
        "authors": [
            "Emmanuel H\u00e9brard",
            "Marie-Jos\u00e9 Huguet",
            "Daniel Veysseire",
            "Ludivine Sauvan",
            "Bertrand Cabon"
        ],
        "abstract": "The payload of communications satellites must go through a series of tests to assert their ability to survive in space. Each test involves some equipment of the payload to be active, which has an impact on the temperature of the payload. Sequencing these tests in a way that ensures the thermal stability of the payload and minimizes the overall duration of the test campaign is a very important objective for satellite manufacturers. The problem can be decomposed in two sub-problems corresponding to two objectives: First, the number of distinct configurations necessary to run the tests must be minimized. This can be modeled as packing the tests into configurations, and we introduce a set of implied constraints to improve the lower bound of the model. Second, tests must be sequenced so that the number of times an equipment unit has to be switched on or off is minimized. We model this aspect using the constraint Switch, where a buffer with limited capacity represents the currently active equipment units, and we introduce an improvement of the propagation algorithm for this constraint. We then introduce a search strategy in which we sequentially solve the sub-problems (packing and sequencing). Experiments conducted on real and random instances show the respective interest of our contributions.\n    ",
        "submission_date": "2017-01-23T00:00:00",
        "last_modified_date": "2017-01-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.06635",
        "title": "Space-Time Graph Modeling of Ride Requests Based on Real-World Data",
        "authors": [
            "Abhinav Jauhri",
            "Brian Foo",
            "Jerome Berclaz",
            "Chih Chi Hu",
            "Radek Grzeszczuk",
            "Vasu Parameswaran",
            "John Paul Shen"
        ],
        "abstract": "This paper focuses on modeling ride requests and their variations over location and time, based on analyzing extensive real-world data from a ride-sharing service. We introduce a graph model that captures the spatial and temporal variability of ride requests and the potentials for ride pooling. We discover these ride request graphs exhibit a well known property called densification power law often found in real graphs modelling human behaviors. We show the pattern of ride requests and the potential of ride pooling for a city can be characterized by the densification factor of the ride request graphs. Previous works have shown that it is possible to automatically generate synthetic versions of these graphs that exhibit a given densification factor. We present an algorithm for automatic generation of synthetic ride request graphs that match quite well the densification factor of ride request graphs from actual ride request data.\n    ",
        "submission_date": "2017-01-23T00:00:00",
        "last_modified_date": "2017-01-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.06699",
        "title": "Imitating Driver Behavior with Generative Adversarial Networks",
        "authors": [
            "Alex Kuefler",
            "Jeremy Morton",
            "Tim Wheeler",
            "Mykel Kochenderfer"
        ],
        "abstract": "The ability to accurately predict and simulate human driving behavior is critical for the development of intelligent transportation systems. Traditional modeling methods have employed simple parametric models and behavioral cloning. This paper adopts a method for overcoming the problem of cascading errors inherent in prior approaches, resulting in realistic behavior that is robust to trajectory perturbations. We extend Generative Adversarial Imitation Learning to the training of recurrent policies, and we demonstrate that our model outperforms rule-based controllers and maximum likelihood models in realistic highway simulations. Our model both reproduces emergent behavior of human drivers, such as lane change rate, while maintaining realistic control over long time horizons.\n    ",
        "submission_date": "2017-01-24T00:00:00",
        "last_modified_date": "2017-01-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.06972",
        "title": "Deep Network Guided Proof Search",
        "authors": [
            "Sarah Loos",
            "Geoffrey Irving",
            "Christian Szegedy",
            "Cezary Kaliszyk"
        ],
        "abstract": "Deep learning techniques lie at the heart of several significant AI advances in recent years including object recognition and detection, image captioning, machine translation, speech recognition and synthesis, and playing the game of Go. Automated first-order theorem provers can aid in the formalization and verification of mathematical theorems and play a crucial role in program analysis, theory reasoning, security, interpolation, and system verification. Here we suggest deep learning based guidance in the proof search of the theorem prover E. We train and compare several deep neural network models on the traces of existing ATP proofs of Mizar statements and use them to select processed clauses during proof search. We give experimental evidence that with a hybrid, two-phase approach, deep learning based guidance can significantly reduce the average number of proof search steps while increasing the number of theorems proved. Using a few proof guidance strategies that leverage deep neural networks, we have found first-order proofs of 7.36% of the first-order logic translations of the Mizar Mathematical Library theorems that did not previously have ATP generated proofs. This increases the ratio of statements in the corpus with ATP generated proofs from 56% to 59%.\n    ",
        "submission_date": "2017-01-24T00:00:00",
        "last_modified_date": "2017-01-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.07103",
        "title": "Artificial Intelligence Approaches To UCAV Autonomy",
        "authors": [
            "Amir Husain",
            "Bruce Porter"
        ],
        "abstract": "This paper covers a number of approaches that leverage Artificial Intelligence algorithms and techniques to aid Unmanned Combat Aerial Vehicle (UCAV) autonomy. An analysis of current approaches to autonomous control is provided followed by an exploration of how these techniques can be extended and enriched with AI techniques including Artificial Neural Networks (ANN), Ensembling and Reinforcement Learning (RL) to evolve control strategies for UCAVs.\n    ",
        "submission_date": "2017-01-24T00:00:00",
        "last_modified_date": "2017-01-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.07232",
        "title": "Learn&Fuzz: Machine Learning for Input Fuzzing",
        "authors": [
            "Patrice Godefroid",
            "Hila Peleg",
            "Rishabh Singh"
        ],
        "abstract": "Fuzzing consists of repeatedly testing an application with modified, or fuzzed, inputs with the goal of finding security vulnerabilities in input-parsing code. In this paper, we show how to automate the generation of an input grammar suitable for input fuzzing using sample inputs and neural-network-based statistical machine-learning techniques. We present a detailed case study with a complex input format, namely PDF, and a large complex security-critical parser for this format, namely, the PDF parser embedded in Microsoft's new Edge browser. We discuss (and measure) the tension between conflicting learning and fuzzing goals: learning wants to capture the structure of well-formed inputs, while fuzzing wants to break that structure in order to cover unexpected code paths and find bugs. We also present a new algorithm for this learn&fuzz challenge which uses a learnt input probability distribution to intelligently guide where to fuzz inputs.\n    ",
        "submission_date": "2017-01-25T00:00:00",
        "last_modified_date": "2017-01-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.07657",
        "title": "Operationalizing Declarative and Procedural Knowledge: a Benchmark on Logic Programming Petri Nets (LPPNs)",
        "authors": [
            "Giovanni Sileno"
        ],
        "abstract": "Modelling, specifying and reasoning about complex systems requires to process in an integrated fashion declarative and procedural aspects of the target domain. The paper reports on an experiment conducted with a propositional version of Logic Programming Petri Nets (LPPNs), a notation extending Petri Nets with logic programming constructs. Two semantics are presented: a denotational semantics that fully maps the notation to ASP via Event Calculus; and a hybrid operational semantics that process separately the causal mechanisms via Petri nets, and the constraints associated to objects and to events via Answer Set Programming (ASP). These two alternative specifications enable an empirical evaluation in terms of computational efficiency. Experimental results show that the hybrid semantics is more efficient w.r.t. sequences, whereas the two semantics follows the same behaviour w.r.t. branchings (although the denotational one performs better in absolute terms).\n    ",
        "submission_date": "2017-01-26T00:00:00",
        "last_modified_date": "2020-07-31T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.07696",
        "title": "Identifying Consistent Statements about Numerical Data with Dispersion-Corrected Subgroup Discovery",
        "authors": [
            "Mario Boley",
            "Bryan R. Goldsmith",
            "Luca M. Ghiringhelli",
            "Jilles Vreeken"
        ],
        "abstract": "Existing algorithms for subgroup discovery with numerical targets do not optimize the error or target variable dispersion of the groups they find. This often leads to unreliable or inconsistent statements about the data, rendering practical applications, especially in scientific domains, futile. Therefore, we here extend the optimistic estimator framework for optimal subgroup discovery to a new class of objective functions: we show how tight estimators can be computed efficiently for all functions that are determined by subgroup size (non-decreasing dependence), the subgroup median value, and a dispersion measure around the median (non-increasing dependence). In the important special case when dispersion is measured using the average absolute deviation from the median, this novel approach yields a linear time algorithm. Empirical evaluation on a wide range of datasets shows that, when used within branch-and-bound search, this approach is highly efficient and indeed discovers subgroups with much smaller errors.\n    ",
        "submission_date": "2017-01-26T00:00:00",
        "last_modified_date": "2017-04-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.07756",
        "title": "Dynamic time warping distance for message propagation classification in Twitter",
        "authors": [
            "Siwar Jendoubi",
            "Arnaud Martin",
            "Ludovic Li\u00e9tard",
            "Boutheina Ben Yaghlane",
            "Hend Ben Hadji"
        ],
        "abstract": "Social messages classification is a research domain that has attracted the attention of many researchers in these last years. Indeed, the social message is different from ordinary text because it has some special characteristics like its shortness. Then the development of new approaches for the processing of the social message is now essential to make its classification more efficient. In this paper, we are mainly interested in the classification of social messages based on their spreading on online social networks (OSN). We proposed a new distance metric based on the Dynamic Time Warping distance and we use it with the probabilistic and the evidential k Nearest Neighbors (k-NN) classifiers to classify propagation networks (PrNets) of messages. The propagation network is a directed acyclic graph (DAG) that is used to record propagation traces of the message, the traversed links and their types. We tested the proposed metric with the chosen k-NN classifiers on real world propagation traces that were collected from Twitter social network and we got good classification accuracies.\n    ",
        "submission_date": "2017-01-26T00:00:00",
        "last_modified_date": "2017-01-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.07769",
        "title": "Ethical Considerations in Artificial Intelligence Courses",
        "authors": [
            "Emanuelle Burton",
            "Judy Goldsmith",
            "Sven Koenig",
            "Benjamin Kuipers",
            "Nicholas Mattei",
            "Toby Walsh"
        ],
        "abstract": "The recent surge in interest in ethics in artificial intelligence may leave many educators wondering how to address moral, ethical, and philosophical issues in their AI courses. As instructors we want to develop curriculum that not only prepares students to be artificial intelligence practitioners, but also to understand the moral, ethical, and philosophical impacts that artificial intelligence will have on society. In this article we provide practical case studies and links to resources for use by AI educators. We also provide concrete suggestions on how to integrate AI ethics into a general artificial intelligence course and how to teach a stand-alone artificial intelligence ethics course.\n    ",
        "submission_date": "2017-01-26T00:00:00",
        "last_modified_date": "2017-01-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.08096",
        "title": "Efficiently Summarising Event Sequences with Rich Interleaving Patterns",
        "authors": [
            "Apratim Bhattacharyya",
            "Jilles Vreeken"
        ],
        "abstract": "Discovering the key structure of a database is one of the main goals of data mining. In pattern set mining we do so by discovering a small set of patterns that together describe the data well. The richer the class of patterns we consider, and the more powerful our description language, the better we will be able to summarise the data. In this paper we propose \\ourmethod, a novel greedy MDL-based method for summarising sequential data using rich patterns that are allowed to interleave. Experiments show \\ourmethod is orders of magnitude faster than the state of the art, results in better models, as well as discovers meaningful semantics in the form patterns that identify multiple choices of values.\n    ",
        "submission_date": "2017-01-27T00:00:00",
        "last_modified_date": "2017-01-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.08100",
        "title": "The Causal Frame Problem: An Algorithmic Perspective",
        "authors": [
            "Ardavan Salehi Nobandegani",
            "Ioannis N. Psaromiligkos"
        ],
        "abstract": "The Frame Problem (FP) is a puzzle in philosophy of mind and epistemology, articulated by the Stanford Encyclopedia of Philosophy as follows: \"How do we account for our apparent ability to make decisions on the basis only of what is relevant to an ongoing situation without having explicitly to consider all that is not relevant?\" In this work, we focus on the causal variant of the FP, the Causal Frame Problem (CFP). Assuming that a reasoner's mental causal model can be (implicitly) represented by a causal Bayes net, we first introduce a notion called Potential Level (PL). PL, in essence, encodes the relative position of a node with respect to its neighbors in a causal Bayes net. Drawing on the psychological literature on causal judgment, we substantiate the claim that PL may bear on how time is encoded in the mind. Using PL, we propose an inference framework, called the PL-based Inference Framework (PLIF), which permits a boundedly-rational approach to the CFP to be formally articulated at Marr's algorithmic level of analysis. We show that our proposed framework, PLIF, is consistent with a wide range of findings in causal judgment literature, and that PL and PLIF make a number of predictions, some of which are already supported by existing findings.\n    ",
        "submission_date": "2017-01-26T00:00:00",
        "last_modified_date": "2017-01-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.08190",
        "title": "Comparative Study Of Data Mining Query Languages",
        "authors": [
            "Mohamed Anis Bach Tobji"
        ],
        "abstract": "Since formulation of Inductive Database (IDB) problem, several Data Mining (DM) languages have been proposed, confirming that KDD process could be supported via inductive queries (IQ) answering. This paper reviews the existing DM languages. We are presenting important primitives of the DM language and classifying our languages according to primitives' satisfaction. In addition, we presented languages' syntaxes and tried to apply each one to a database sample to test a set of KDD operations. This study allows us to highlight languages capabilities and limits, which is very useful for future work and perspectives.\n    ",
        "submission_date": "2017-01-27T00:00:00",
        "last_modified_date": "2017-01-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.08191",
        "title": "Incremental Maintenance Of Association Rules Under Support Threshold Change",
        "authors": [
            "Mohamed Anis Bach Tobji",
            "Mohamed Salah Gouider"
        ],
        "abstract": "Maintenance of association rules is an interesting problem. Several incremental maintenance algorithms were proposed since the work of (Cheung et al, 1996). The majority of these algorithms maintain rule bases assuming that support threshold doesn't change. In this paper, we present incremental maintenance algorithm under support threshold change. This solution allows user to maintain its rule base under any support threshold.\n    ",
        "submission_date": "2017-01-27T00:00:00",
        "last_modified_date": "2017-01-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.08301",
        "title": "Pure Rough Mereology and Counting",
        "authors": [
            "A. Mani"
        ],
        "abstract": "The study of mereology (parts and wholes) in the context of formal approaches to vagueness can be approached in a number of ways. In the context of rough sets, mereological concepts with a set-theoretic or valuation based ontology acquire complex and diverse behavior. In this research a general rough set framework called granular operator spaces is extended and the nature of parthood in it is explored from a minimally intrusive point of view. This is used to develop counting strategies that help in classifying the framework. The developed methodologies would be useful for drawing involved conclusions about the nature of data (and validity of assumptions about it) from antichains derived from context. The problem addressed is also about whether counting procedures help in confirming that the approximations involved in formation of data are indeed rough approximations?\n    ",
        "submission_date": "2017-01-28T00:00:00",
        "last_modified_date": "2017-01-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.08302",
        "title": "A Study of FOSS'2013 Survey Data Using Clustering Techniques",
        "authors": [
            "Mani A",
            "Rebeka Mukherjee"
        ],
        "abstract": "FOSS is an acronym for Free and Open Source Software. The FOSS 2013 survey primarily targets FOSS contributors and relevant anonymized dataset is publicly available under CC by SA license. In this study, the dataset is analyzed from a critical perspective using statistical and clustering techniques (especially multiple correspondence analysis) with a strong focus on women contributors towards discovering hidden trends and facts. Important inferences are drawn about development practices and other facets of the free software and OSS worlds.\n    ",
        "submission_date": "2017-01-28T00:00:00",
        "last_modified_date": "2017-01-31T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.08306",
        "title": "Practical Reasoning with Norms for Autonomous Software Agents (Full Edition)",
        "authors": [
            "Zohreh Shams",
            "Marina De Vos",
            "Julian Padget",
            "Wamberto W. Vasconcelos"
        ],
        "abstract": "Autonomous software agents operating in dynamic environments need to constantly reason about actions in pursuit of their goals, while taking into consideration norms which might be imposed on those actions. Normative practical reasoning supports agents making decisions about what is best for them to (not) do in a given situation. What makes practical reasoning challenging is the interplay between goals that agents are pursuing and the norms that the agents are trying to uphold. We offer a formalisation to allow agents to plan for multiple goals and norms in the presence of durative actions that can be executed concurrently. We compare plans based on decision-theoretic notions (i.e. utility) such that the utility gain of goals and utility loss of norm violations are the basis for this comparison. The set of optimal plans consists of plans that maximise the overall utility, each of which can be chosen by the agent to execute. We provide an implementation of our proposal in Answer Set Programming, thus allowing us to state the original problem in terms of a logic program that can be queried for solutions with specific properties. The implementation is proven to be sound and complete.\n    ",
        "submission_date": "2017-01-28T00:00:00",
        "last_modified_date": "2017-01-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.08317",
        "title": "Plan Explanations as Model Reconciliation: Moving Beyond Explanation as Soliloquy",
        "authors": [
            "Tathagata Chakraborti",
            "Sarath Sreedharan",
            "Yu Zhang",
            "Subbarao Kambhampati"
        ],
        "abstract": "When AI systems interact with humans in the loop, they are often called on to provide explanations for their plans and behavior. Past work on plan explanations primarily involved the AI system explaining the correctness of its plan and the rationale for its decision in terms of its own model. Such soliloquy is wholly inadequate in most realistic scenarios where the humans have domain and task models that differ significantly from that used by the AI system. We posit that the explanations are best studied in light of these differing models. In particular, we show how explanation can be seen as a \"model reconciliation problem\" (MRP), where the AI system in effect suggests changes to the human's model, so as to make its plan be optimal with respect to that changed human model. We will study the properties of such explanations, present algorithms for automatically computing them, and evaluate the performance of the algorithms.\n    ",
        "submission_date": "2017-01-28T00:00:00",
        "last_modified_date": "2017-05-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.08343",
        "title": "Rhythm Transcription of Polyphonic Piano Music Based on Merged-Output HMM for Multiple Voices",
        "authors": [
            "Eita Nakamura",
            "Kazuyoshi Yoshii",
            "Shigeki Sagayama"
        ],
        "abstract": "In a recent conference paper, we have reported a rhythm transcription method based on a merged-output hidden Markov model (HMM) that explicitly describes the multiple-voice structure of polyphonic music. This model solves a major problem of conventional methods that could not properly describe the nature of multiple voices as in polyrhythmic scores or in the phenomenon of loose synchrony between voices. In this paper we present a complete description of the proposed model and develop an inference technique, which is valid for any merged-output HMMs for which output probabilities depend on past events. We also examine the influence of the architecture and parameters of the method in terms of accuracies of rhythm transcription and voice separation and perform comparative evaluations with six other algorithms. Using MIDI recordings of classical piano pieces, we found that the proposed model outperformed other methods by more than 12 points in the accuracy for polyrhythmic performances and performed almost as good as the best one for non-polyrhythmic performances. This reveals the state-of-the-art methods of rhythm transcription for the first time in the literature. Publicly available source codes are also provided for future comparisons.\n    ",
        "submission_date": "2017-01-29T00:00:00",
        "last_modified_date": "2017-01-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.08546",
        "title": "Survey on Models and Techniques for Root-Cause Analysis",
        "authors": [
            "Marc Sol\u00e9",
            "Victor Munt\u00e9s-Mulero",
            "Annie Ibrahim Rana",
            "Giovani Estrada"
        ],
        "abstract": "Automation and computer intelligence to support complex human decisions becomes essential to manage large and distributed systems in the Cloud and IoT era. Understanding the root cause of an observed symptom in a complex system has been a major problem for decades. As industry dives into the IoT world and the amount of data generated per year grows at an amazing speed, an important question is how to find appropriate mechanisms to determine root causes that can handle huge amounts of data or may provide valuable feedback in real-time. While many survey papers aim at summarizing the landscape of techniques for modelling system behavior and infering the root cause of a problem based in the resulting models, none of those focuses on analyzing how the different techniques in the literature fit growing requirements in terms of performance and scalability. In this survey, we provide a review of root-cause analysis, focusing on these particular aspects. We also provide guidance to choose the best root-cause analysis strategy depending on the requirements of a particular system and application.\n    ",
        "submission_date": "2017-01-30T00:00:00",
        "last_modified_date": "2017-07-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.08661",
        "title": "Credal Networks under Epistemic Irrelevance",
        "authors": [
            "Jasper De Bock"
        ],
        "abstract": "A credal network under epistemic irrelevance is a generalised type of Bayesian network that relaxes its two main building blocks. On the one hand, the local probabilities are allowed to be partially specified. On the other hand, the assessments of independence do not have to hold exactly. Conceptually, these two features turn credal networks under epistemic irrelevance into a powerful alternative to Bayesian networks, offering a more flexible approach to graph-based multivariate uncertainty modelling. However, in practice, they have long been perceived as very hard to work with, both theoretically and computationally.\n",
        "submission_date": "2017-01-27T00:00:00",
        "last_modified_date": "2017-03-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.08665",
        "title": "Redefinition of the concept of fuzzy set based on vague partition from the perspective of axiomatization",
        "authors": [
            "Xiaodong Pan",
            "Yang Xu"
        ],
        "abstract": "Based on the in-depth analysis of the essence and features of vague phenomena, this paper focuses on establishing the axiomatical foundation of membership degree theory for vague phenomena, presents an axiomatic system to govern membership degrees and their interconnections. On this basis, the concept of vague partition is introduced, further, the concept of fuzzy set introduced by Zadeh in 1965 is redefined based on vague partition from the perspective of axiomatization. The thesis defended in this paper is that the relationship among vague attribute values should be the starting point to recognize and model vague phenomena from a quantitative view.\n    ",
        "submission_date": "2017-01-27T00:00:00",
        "last_modified_date": "2017-01-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.08709",
        "title": "Diversification Methods for Zero-One Optimization",
        "authors": [
            "Fred Glover"
        ],
        "abstract": "We introduce new diversification methods for zero-one optimization that significantly extend strategies previously introduced in the setting of metaheuristic search. Our methods incorporate easily implemented strategies for partitioning assignments of values to variables, accompanied by processes called augmentation and shifting which create greater flexibility and generality. We then show how the resulting collection of diversified solutions can be further diversified by means of permutation mappings, which equally can be used to generate diversified collections of permutations for applications such as scheduling and routing. These methods can be applied to non-binary vectors by the use of binarization procedures and by Diversification-Based Learning (DBL) procedures which also provide connections to applications in clustering and machine learning. Detailed pseudocode and numerical illustrations are provided to show the operation of our methods and the collections of solutions they create.\n    ",
        "submission_date": "2017-01-30T00:00:00",
        "last_modified_date": "2017-03-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.08832",
        "title": "Expert Level control of Ramp Metering based on Multi-task Deep Reinforcement Learning",
        "authors": [
            "Francois Belletti",
            "Daniel Haziza",
            "Gabriel Gomes",
            "Alexandre M. Bayen"
        ],
        "abstract": "This article shows how the recent breakthroughs in Reinforcement Learning (RL) that have enabled robots to learn to play arcade video games, walk or assemble colored bricks, can be used to perform other tasks that are currently at the core of engineering cyberphysical systems. We present the first use of RL for the control of systems modeled by discretized non-linear Partial Differential Equations (PDEs) and devise a novel algorithm to use non-parametric control techniques for large multi-agent systems. We show how neural network based RL enables the control of discretized PDEs whose parameters are unknown, random, and time-varying. We introduce an algorithm of Mutual Weight Regularization (MWR) which alleviates the curse of dimensionality of multi-agent control schemes by sharing experience between agents while giving each agent the opportunity to specialize its action policy so as to tailor it to the local parameters of the part of the system it is located in.\n    ",
        "submission_date": "2017-01-30T00:00:00",
        "last_modified_date": "2017-01-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.08868",
        "title": "Interaction Information for Causal Inference: The Case of Directed Triangle",
        "authors": [
            "AmirEmad Ghassami",
            "Negar Kiyavash"
        ],
        "abstract": "Interaction information is one of the multivariate generalizations of mutual information, which expresses the amount information shared among a set of variables, beyond the information, which is shared in any proper subset of those variables. Unlike (conditional) mutual information, which is always non-negative, interaction information can be negative. We utilize this property to find the direction of causal influences among variables in a triangle topology under some mild assumptions.\n    ",
        "submission_date": "2017-01-30T00:00:00",
        "last_modified_date": "2017-01-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.09000",
        "title": "On the Semantics and Complexity of Probabilistic Logic Programs",
        "authors": [
            "Fabio Gagliardi Cozman",
            "Denis Deratani Mau\u00e1"
        ],
        "abstract": "We examine the meaning and the complexity of probabilistic logic programs that consist of a set of rules and a set of independent probabilistic facts (that is, programs based on Sato's distribution semantics). We focus on two semantics, respectively based on stable and on well-founded models. We show that the semantics based on stable models (referred to as the \"credal semantics\") produces sets of probability models that dominate infinitely monotone Choquet capacities, we describe several useful consequences of this result. We then examine the complexity of inference with probabilistic logic programs. We distinguish between the complexity of inference when a probabilistic program and a query are given (the inferential complexity), and the complexity of inference when the probabilistic program is fixed and the query is given (the query complexity, akin to data complexity as used in database theory). We obtain results on the inferential and query complexity for acyclic, stratified, and cyclic propositional and relational programs, complexity reaches various levels of the counting hierarchy and even exponential levels.\n    ",
        "submission_date": "2017-01-31T00:00:00",
        "last_modified_date": "2017-01-31T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.00020",
        "title": "Towards \"AlphaChem\": Chemical Synthesis Planning with Tree Search and Deep Neural Network Policies",
        "authors": [
            "Marwin Segler",
            "Mike Preu\u00df",
            "Mark P. Waller"
        ],
        "abstract": "Retrosynthesis is a technique to plan the chemical synthesis of organic molecules, for example drugs, agro- and fine chemicals. In retrosynthesis, a search tree is built by analysing molecules recursively and dissecting them into simpler molecular building blocks until one obtains a set of known building blocks. The search space is intractably large, and it is difficult to determine the value of retrosynthetic positions. Here, we propose to model retrosynthesis as a Markov Decision Process. In combination with a Deep Neural Network policy learned from essentially the complete published knowledge of chemistry, Monte Carlo Tree Search (MCTS) can be used to evaluate positions. In exploratory studies, we demonstrate that MCTS with neural network policies outperforms the traditionally used best-first search with hand-coded heuristics.\n    ",
        "submission_date": "2017-01-31T00:00:00",
        "last_modified_date": "2017-01-31T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.00137",
        "title": "Blue Sky Ideas in Artificial Intelligence Education from the EAAI 2017 New and Future AI Educator Program",
        "authors": [
            "Eric Eaton",
            "Sven Koenig",
            "Claudia Schulz",
            "Francesco Maurelli",
            "John Lee",
            "Joshua Eckroth",
            "Mark Crowley",
            "Richard G. Freedman",
            "Rogelio E. Cardona-Rivera",
            "Tiago Machado",
            "Tom Williams"
        ],
        "abstract": "The 7th Symposium on Educational Advances in Artificial Intelligence (EAAI'17, co-chaired by Sven Koenig and Eric Eaton) launched the EAAI New and Future AI Educator Program to support the training of early-career university faculty, secondary school faculty, and future educators (PhD candidates or postdocs who intend a career in academia). As part of the program, awardees were asked to address one of the following \"blue sky\" questions:\n",
        "submission_date": "2017-02-01T00:00:00",
        "last_modified_date": "2017-02-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.00159",
        "title": "Robust Order Scheduling in the Fashion Industry: A Multi-Objective Optimization Approach",
        "authors": [
            "Wei Du",
            "Yang Tang",
            "Sunney Yung Sun Leung",
            "Le Tong",
            "Athanasios V. Vasilakos",
            "Feng Qian"
        ],
        "abstract": "In the fashion industry, order scheduling focuses on the assignment of production orders to appropriate production lines. In reality, before a new order can be put into production, a series of activities known as pre-production events need to be completed. In addition, in real production process, owing to various uncertainties, the daily production quantity of each order is not always as expected. In this research, by considering the pre-production events and the uncertainties in the daily production quantity, robust order scheduling problems in the fashion industry are investigated with the aid of a multi-objective evolutionary algorithm (MOEA) called nondominated sorting adaptive differential evolution (NSJADE). The experimental results illustrate that it is of paramount importance to consider pre-production events in order scheduling problems in the fashion industry. We also unveil that the existence of the uncertainties in the daily production quantity heavily affects the order scheduling.\n    ",
        "submission_date": "2017-02-01T00:00:00",
        "last_modified_date": "2017-02-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.00318",
        "title": "A Hybrid Evolutionary Algorithm Based on Solution Merging for the Longest Arc-Preserving Common Subsequence Problem",
        "authors": [
            "Christian Blum",
            "Maria J. Blesa"
        ],
        "abstract": "The longest arc-preserving common subsequence problem is an NP-hard combinatorial optimization problem from the field of computational biology. This problem finds applications, in particular, in the comparison of arc-annotated Ribonucleic acid (RNA) sequences. In this work we propose a simple, hybrid evolutionary algorithm to tackle this problem. The most important feature of this algorithm concerns a crossover operator based on solution merging. In solution merging, two or more solutions to the problem are merged, and an exact technique is used to find the best solution within this union. It is experimentally shown that the proposed algorithm outperforms a heuristic from the literature.\n    ",
        "submission_date": "2017-02-01T00:00:00",
        "last_modified_date": "2017-02-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.00539",
        "title": "Procedural Content Generation via Machine Learning (PCGML)",
        "authors": [
            "Adam Summerville",
            "Sam Snodgrass",
            "Matthew Guzdial",
            "Christoffer Holmg\u00e5rd",
            "Amy K. Hoover",
            "Aaron Isaksen",
            "Andy Nealen",
            "Julian Togelius"
        ],
        "abstract": "This survey explores Procedural Content Generation via Machine Learning (PCGML), defined as the generation of game content using machine learning models trained on existing content. As the importance of PCG for game development increases, researchers explore new avenues for generating high-quality content with or without human involvement; this paper addresses the relatively new paradigm of using machine learning (in contrast with search-based, solver-based, and constructive methods). We focus on what is most often considered functional game content such as platformer levels, game maps, interactive fiction stories, and cards in collectible card games, as opposed to cosmetic content such as sprites and sound effects. In addition to using PCG for autonomous generation, co-creativity, mixed-initiative design, and compression, PCGML is suited for repair, critique, and content analysis because of its focus on modeling existing content. We discuss various data sources and representations that affect the resulting generated content. Multiple PCGML methods are covered, including neural networks, long short-term memory (LSTM) networks, autoencoders, and deep convolutional networks; Markov models, $n$-grams, and multi-dimensional Markov chains; clustering; and matrix factorization. Finally, we discuss open problems in the application of PCGML, including learning from small datasets, lack of training data, multi-layered learning, style-transfer, parameter tuning, and PCG as a game mechanic.\n    ",
        "submission_date": "2017-02-02T00:00:00",
        "last_modified_date": "2018-05-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.00780",
        "title": "Two forms of minimality in ASPIC+",
        "authors": [
            "Zimi Li",
            "Andrea Cohen",
            "Simon Parsons"
        ],
        "abstract": "Many systems of structured argumentation explicitly require that the facts and rules that make up the argument for a conclusion be the minimal set required to derive the conclusion. ASPIC+ does not place such a requirement on arguments, instead requiring that every rule and fact that are part of an argument be used in its construction. Thus ASPIC+ arguments are minimal in the sense that removing any element of the argument would lead to a structure that is not an argument. In this brief note we discuss these two types of minimality and show how the first kind of minimality can, if desired, be recovered in ASPIC+.\n    ",
        "submission_date": "2017-02-02T00:00:00",
        "last_modified_date": "2017-02-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.00858",
        "title": "The Value of Inferring the Internal State of Traffic Participants for Autonomous Freeway Driving",
        "authors": [
            "Zachary Sunberg",
            "Christopher Ho",
            "Mykel Kochenderfer"
        ],
        "abstract": "Safe interaction with human drivers is one of the primary challenges for autonomous vehicles. In order to plan driving maneuvers effectively, the vehicle's control system must infer and predict how humans will behave based on their latent internal state (e.g., intentions and aggressiveness). This research uses a simple model for human behavior with unknown parameters that make up the internal states of the traffic participants and presents a method for quantifying the value of estimating these states and planning with their uncertainty explicitly modeled. An upper performance bound is established by an omniscient Monte Carlo Tree Search (MCTS) planner that has perfect knowledge of the internal states. A baseline lower bound is established by planning with MCTS assuming that all drivers have the same internal state. MCTS variants are then used to solve a partially observable Markov decision process (POMDP) that models the internal state uncertainty to determine whether inferring the internal state offers an advantage over the baseline. Applying this method to a freeway lane changing scenario reveals that there is a significant performance gap between the upper bound and baseline. POMDP planning techniques come close to closing this gap, especially when important hidden model parameters are correlated with measurable parameters.\n    ",
        "submission_date": "2017-02-02T00:00:00",
        "last_modified_date": "2017-02-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.01135",
        "title": "Reluplex: An Efficient SMT Solver for Verifying Deep Neural Networks",
        "authors": [
            "Guy Katz",
            "Clark Barrett",
            "David Dill",
            "Kyle Julian",
            "Mykel Kochenderfer"
        ],
        "abstract": "Deep neural networks have emerged as a widely used and effective means for tackling complex, real-world problems. However, a major obstacle in applying them to safety-critical systems is the great difficulty in providing formal guarantees about their behavior. We present a novel, scalable, and efficient technique for verifying properties of deep neural networks (or providing counter-examples). The technique is based on the simplex method, extended to handle the non-convex Rectified Linear Unit (ReLU) activation function, which is a crucial ingredient in many modern neural networks. The verification procedure tackles neural networks as a whole, without making any simplifying assumptions. We evaluated our technique on a prototype deep neural network implementation of the next-generation airborne collision avoidance system for unmanned aircraft (ACAS Xu). Results show that our technique can successfully prove properties of networks that are an order of magnitude larger than the largest networks verified using existing methods.\n    ",
        "submission_date": "2017-02-03T00:00:00",
        "last_modified_date": "2017-05-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.01205",
        "title": "Traffic Lights with Auction-Based Controllers: Algorithms and Real-World Data",
        "authors": [
            "Shumeet Baluja",
            "Michele Covell",
            "Rahul Sukthankar"
        ],
        "abstract": "Real-time optimization of traffic flow addresses important practical problems: reducing a driver's wasted time, improving city-wide efficiency, reducing gas emissions and improving air quality. Much of the current research in traffic-light optimization relies on extending the capabilities of traffic lights to either communicate with each other or communicate with vehicles. However, before such capabilities become ubiquitous, opportunities exist to improve traffic lights by being more responsive to current traffic situations within the current, already deployed, infrastructure. In this paper, we introduce a traffic light controller that employs bidding within micro-auctions to efficiently incorporate traffic sensor information; no other outside sources of information are assumed. We train and test traffic light controllers on large-scale data collected from opted-in Android cell-phone users over a period of several months in Mountain View, California and the River North neighborhood of Chicago, Illinois. The learned auction-based controllers surpass (in both the relevant metrics of road-capacity and mean travel time) the currently deployed lights, optimized static-program lights, and longer-term planning approaches, in both cities, measured using real user driving data.\n    ",
        "submission_date": "2017-02-03T00:00:00",
        "last_modified_date": "2017-02-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.01332",
        "title": "Manyopt: An Extensible Tool for Mixed, Non-Linear Optimization Through SMT Solving",
        "authors": [
            "Andrea Callia D'Iddio",
            "Michael Huth"
        ],
        "abstract": "Optimization of Mixed-Integer Non-Linear Programming (MINLP) supports important decisions in applications such as Chemical Process Engineering. But current solvers have limited ability for deductive reasoning or the use of domain-specific theories, and the management of integrality constraints does not yet exploit automated reasoning tools such as SMT solvers. This seems to limit both scalability and reach of such tools in practice. We therefore present a tool, ManyOpt, for MINLP optimization that enables experimentation with reduction techniques which transform a MINLP problem to feasibility checking realized by an SMT solver. ManyOpt is similar to the SAT solver ManySAT in that it runs a specified number of such reduction techniques in parallel to get the strongest result on a given MINLP problem. The tool is implemented in layers, which we may see as features and where reduction techniques are feature vectors. Some of these features are inspired by known MINLP techniques whereas others are novel and specific to SMT. Our experimental results on standard benchmarks demonstrate the benefits of this approach. The tool supports a variety of SMT solvers and is easily extensible with new features, courtesy of its layered structure. For example, logical formulas for deductive reasoning are easily added to constrain further the optimization of a MINLP problem of interest.\n    ",
        "submission_date": "2017-02-04T00:00:00",
        "last_modified_date": "2017-02-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.01510",
        "title": "Survey of modern Fault Diagnosis methods in networks",
        "authors": [
            "Zi Jian Yang",
            "Yong Wang"
        ],
        "abstract": "With the advent of modern computer networks, fault diagnosis has been a focus of research activity. This paper reviews the history of fault diagnosis in networks and discusses the main methods in information gathering section, information analyzing section and diagnosing and revolving section of fault diagnosis in networks. Emphasis will be placed upon knowledge-based methods with discussing the advantages and shortcomings of the different methods. The survey is concluded with a description of some open problems.\n    ",
        "submission_date": "2017-02-06T00:00:00",
        "last_modified_date": "2017-02-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.01601",
        "title": "Exploring the bidimensional space: A dynamic logic point of view",
        "authors": [
            "Philippe Balbiani",
            "David Fern\u00e1ndez-Duque",
            "Emiliano Lorini"
        ],
        "abstract": "We present a family of logics for reasoning about agents' positions and motion in the plane which have several potential applications in the area of multi-agent systems (MAS), such as multi-agent planning and robotics. The most general logic includes (i) atomic formulas for representing the truth of a given fact or the presence of a given agent at a certain position of the plane, (ii) atomic programs corresponding to the four basic orientations in the plane (up, down, left, right) as well as the four program constructs of propositional dynamic logic (sequential composition, nondeterministic composition, iteration and test). As this logic is not computably enumerable, we study some interesting decidable and axiomatizable fragments of it. We also present a decidable extension of the iteration-free fragment of the logic by special programs representing motion of agents in the plane.\n    ",
        "submission_date": "2017-02-06T00:00:00",
        "last_modified_date": "2017-02-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.01795",
        "title": "ASHACL: Alternative Shapes Constraint Language",
        "authors": [
            "Peter F. Patel-Schneider"
        ],
        "abstract": "ASHACL, a variant of the W3C Shapes Constraint Language, is designed to determine whether an RDF graph meets some conditions. These conditions are grouped into shapes, which validate whether particular RDF terms each meet the constraints of the shape. Shapes are themselves expressed as RDF triples in an RDF graph, called a shapes graph.\n    ",
        "submission_date": "2017-02-06T00:00:00",
        "last_modified_date": "2017-03-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.01886",
        "title": "Extracting Lifted Mutual Exclusion Invariants from Temporal Planning Domains",
        "authors": [
            "Sara Bernardini",
            "Fabio Fagnani",
            "David E. Smith"
        ],
        "abstract": "We present a technique for automatically extracting mutual exclusion invariants from temporal planning instances. It first identifies a set of invariant templates by inspecting the lifted representation of the domain and then checks these templates against properties that assure invariance. Our technique builds on other approaches to invariant synthesis presented in the literature, but departs from their limited focus on instantaneous actions by addressing temporal domains. To deal with time, we formulate invariance conditions that account for the entire structure of the actions and the possible concurrent interactions between them. As a result, we construct a significantly more comprehensive technique than previous methods, which is able to find not only invariants for temporal domains, but also a broader set of invariants for non-temporal domains. The experimental results reported in this paper provide evidence that identifying a broader set of invariants results in the generation of fewer multi-valued state variables with larger domains. We show that, in turn, this reduction in the number of variables reflects positively on the performance of a number of temporal planners that use a variable/value representation by significantly reducing their running time.\n    ",
        "submission_date": "2017-02-07T00:00:00",
        "last_modified_date": "2017-02-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.02302",
        "title": "Autonomous Braking System via Deep Reinforcement Learning",
        "authors": [
            "Hyunmin Chae",
            "Chang Mook Kang",
            "ByeoungDo Kim",
            "Jaekyum Kim",
            "Chung Choo Chung",
            "Jun Won Choi"
        ],
        "abstract": "In this paper, we propose a new autonomous braking system based on deep reinforcement learning. The proposed autonomous braking system automatically decides whether to apply the brake at each time step when confronting the risk of collision using the information on the obstacle obtained by the sensors. The problem of designing brake control is formulated as searching for the optimal policy in Markov decision process (MDP) model where the state is given by the relative position of the obstacle and the vehicle's speed, and the action space is defined as whether brake is stepped or not. The policy used for brake control is learned through computer simulations using the deep reinforcement learning method called deep Q-network (DQN). In order to derive desirable braking policy, we propose the reward function which balances the damage imposed to the obstacle in case of accident and the reward achieved when the vehicle runs out of risk as soon as possible. DQN is trained for the scenario where a vehicle is encountered with a pedestrian crossing the urban road. Experiments show that the control agent exhibits desirable control behavior and avoids collision without any mistake in various uncertain environments.\n    ",
        "submission_date": "2017-02-08T00:00:00",
        "last_modified_date": "2017-04-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.02470",
        "title": "Propagation via Kernelization: The Vertex Cover Constraint",
        "authors": [
            "Cl\u00e9ment Carbonnel",
            "Emmanuel H\u00e9brard"
        ],
        "abstract": "The technique of kernelization consists in extracting, from an instance of a problem, an essentially equivalent instance whose size is bounded in a parameter k. Besides being the basis for efficient param-eterized algorithms, this method also provides a wealth of information to reason about in the context of constraint programming. We study the use of kernelization for designing propagators through the example of the Vertex Cover constraint. Since the classic kernelization rules often correspond to dominance rather than consistency, we introduce the notion of \"loss-less\" kernel. While our preliminary experimental results show the potential of the approach, they also show some of its limits. In particular, this method is more effective for vertex covers of large and sparse graphs, as they tend to have, relatively, smaller kernels.\n    ",
        "submission_date": "2017-02-07T00:00:00",
        "last_modified_date": "2017-02-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.02628",
        "title": "Optimal Detection of Faulty Traffic Sensors Used in Route Planning",
        "authors": [
            "Amin Ghafouri",
            "Aron Laszka",
            "Abhishek Dubey",
            "Xenofon Koutsoukos"
        ],
        "abstract": "In a smart city, real-time traffic sensors may be deployed for various applications, such as route planning. Unfortunately, sensors are prone to failures, which result in erroneous traffic data. Erroneous data can adversely affect applications such as route planning, and can cause increased travel time. To minimize the impact of sensor failures, we must detect them promptly and accurately. However, typical detection algorithms may lead to a large number of false positives (i.e., false alarms) and false negatives (i.e., missed detections), which can result in suboptimal route planning. In this paper, we devise an effective detector for identifying faulty traffic sensors using a prediction model based on Gaussian Processes. Further, we present an approach for computing the optimal parameters of the detector which minimize losses due to false-positive and false-negative errors. We also characterize critical sensors, whose failure can have high impact on the route planning application. Finally, we implement our method and evaluate it numerically using a real-world dataset and the route planning platform OpenTripPlanner.\n    ",
        "submission_date": "2017-02-08T00:00:00",
        "last_modified_date": "2017-03-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.03274",
        "title": "Hybrid Code Networks: practical and efficient end-to-end dialog control with supervised and reinforcement learning",
        "authors": [
            "Jason D. Williams",
            "Kavosh Asadi",
            "Geoffrey Zweig"
        ],
        "abstract": "End-to-end learning of recurrent neural networks (RNNs) is an attractive solution for dialog systems; however, current techniques are data-intensive and require thousands of dialogs to learn simple behaviors. We introduce Hybrid Code Networks (HCNs), which combine an RNN with domain-specific knowledge encoded as software and system action templates. Compared to existing end-to-end approaches, HCNs considerably reduce the amount of training data required, while retaining the key benefit of inferring a latent representation of dialog state. In addition, HCNs can be optimized with supervised learning, reinforcement learning, or a mixture of both. HCNs attain state-of-the-art performance on the bAbI dialog dataset, and outperform two commercially deployed customer-facing dialog systems.\n    ",
        "submission_date": "2017-02-10T00:00:00",
        "last_modified_date": "2017-04-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.03401",
        "title": "A Minimax Algorithm Better Than Alpha-beta?: No and Yes",
        "authors": [
            "Aske Plaat",
            "Jonathan Schaeffer",
            "Wim Pijls",
            "Arie de Bruin"
        ],
        "abstract": "This paper has three main contributions to our understanding of fixed-depth minimax search: (A) A new formulation for Stockman's SSS* algorithm, based on Alpha-Beta, is presented. It solves all the perceived drawbacks of SSS*, finally transforming it into a practical algorithm. In effect, we show that SSS* = alpha-beta + ransposition tables. The crucial step is the realization that transposition tables contain so-called solution trees, structures that are used in best-first search algorithms like SSS*. Having created a practical version, we present performance measurements with tournament game-playing programs for three different minimax games, yielding results that contradict a number of publications. (B) Based on the insights gained in our attempts at understanding SSS*, we present a framework that facilitates the construction of several best-first fixed- depth game-tree search algorithms, known and new. The framework is based on depth-first null-window Alpha-Beta search, enhanced with storage to allow for the refining of previous search results. It focuses attention on the essential differences between algorithms. (C) We present a new instance of the framework, MTD(f). It is well-suited for use with iterative deepening, and performs better than algorithms that are currently used in most state-of-the-art game-playing programs. We provide experimental evidence to explain why MTD(f) performs better than the other fixed-depth minimax algorithms.\n    ",
        "submission_date": "2017-02-11T00:00:00",
        "last_modified_date": "2017-02-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.03488",
        "title": "Octopus: A Framework for Cost-Quality-Time Optimization in Crowdsourcing",
        "authors": [
            "Karan Goel",
            "Shreya Rajpal",
            "Mausam"
        ],
        "abstract": "We present Octopus, an AI agent to jointly balance three conflicting task objectives on a micro-crowdsourcing marketplace - the quality of work, total cost incurred, and time to completion. Previous control agents have mostly focused on cost-quality, or cost-time tradeoffs, but not on directly controlling all three in concert. A naive formulation of three-objective optimization is intractable; Octopus takes a hierarchical POMDP approach, with three different components responsible for setting the pay per task, selecting the next task, and controlling task-level quality. We demonstrate that Octopus significantly outperforms existing state-of-the-art approaches on real experiments. We also deploy Octopus on Amazon Mechanical Turk, showing its ability to manage tasks in a real-world dynamic setting.\n    ",
        "submission_date": "2017-02-12T00:00:00",
        "last_modified_date": "2017-08-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.03584",
        "title": "Similarity Preserving Representation Learning for Time Series Clustering",
        "authors": [
            "Qi Lei",
            "Jinfeng Yi",
            "Roman Vaculin",
            "Lingfei Wu",
            "Inderjit S. Dhillon"
        ],
        "abstract": "A considerable amount of clustering algorithms take instance-feature matrices as their inputs. As such, they cannot directly analyze time series data due to its temporal nature, usually unequal lengths, and complex properties. This is a great pity since many of these algorithms are effective, robust, efficient, and easy to use. In this paper, we bridge this gap by proposing an efficient representation learning framework that is able to convert a set of time series with various lengths to an instance-feature matrix. In particular, we guarantee that the pairwise similarities between time series are well preserved after the transformation, thus the learned feature representation is particularly suitable for the time series clustering task. Given a set of $n$ time series, we first construct an $n\\times n$ partially-observed similarity matrix by randomly sampling $\\mathcal{O}(n \\log n)$ pairs of time series and computing their pairwise similarities. We then propose an efficient algorithm that solves a non-convex and NP-hard problem to learn new features based on the partially-observed similarity matrix. By conducting extensive empirical studies, we show that the proposed framework is more effective, efficient, and flexible, compared to other state-of-the-art time series clustering methods.\n    ",
        "submission_date": "2017-02-12T00:00:00",
        "last_modified_date": "2019-06-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.03592",
        "title": "Graph Neural Networks and Boolean Satisfiability",
        "authors": [
            "Benedikt B\u00fcnz",
            "Matthew Lamm"
        ],
        "abstract": "In this paper we explore whether or not deep neural architectures can learn to classify Boolean satisfiability (SAT). We devote considerable time to discussing the theoretical properties of SAT. Then, we define a graph representation for Boolean formulas in conjunctive normal form, and train neural classifiers over general graph structures called Graph Neural Networks, or GNNs, to recognize features of satisfiability. To the best of our knowledge this has never been tried before. Our preliminary findings are potentially profound. In a weakly-supervised setting, that is, without problem specific feature engineering, Graph Neural Networks can learn features of satisfiability.\n    ",
        "submission_date": "2017-02-12T00:00:00",
        "last_modified_date": "2017-02-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.03594",
        "title": "Genetic and Memetic Algorithm with Diversity Equilibrium based on Greedy Diversification",
        "authors": [
            "Andr\u00e9s Herrera-Poyatos",
            "Francisco Herrera"
        ],
        "abstract": "The lack of diversity in a genetic algorithm's population may lead to a bad performance of the genetic operators since there is not an equilibrium between exploration and exploitation. In those cases, genetic algorithms present a fast and unsuitable convergence.\n",
        "submission_date": "2017-02-12T00:00:00",
        "last_modified_date": "2017-02-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.03724",
        "title": "On Seeking Consensus Between Document Similarity Measures",
        "authors": [
            "Mieczys\u0142aw K\u0142opotek"
        ],
        "abstract": "This paper investigates the application of consensus clustering and meta-clustering to the set of all possible partitions of a data set. We show that when using a \"complement\" of Rand Index as a measure of cluster similarity, the total-separation partition, putting each element in a separate set, is chosen.\n    ",
        "submission_date": "2017-02-13T00:00:00",
        "last_modified_date": "2017-02-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.03814",
        "title": "Bilateral Multi-Perspective Matching for Natural Language Sentences",
        "authors": [
            "Zhiguo Wang",
            "Wael Hamza",
            "Radu Florian"
        ],
        "abstract": "Natural language sentence matching is a fundamental technology for a variety of tasks. Previous approaches either match sentences from a single direction or only apply single granular (word-by-word or sentence-by-sentence) matching. In this work, we propose a bilateral multi-perspective matching (BiMPM) model under the \"matching-aggregation\" framework. Given two sentences $P$ and $Q$, our model first encodes them with a BiLSTM encoder. Next, we match the two encoded sentences in two directions $P \\rightarrow Q$ and $P \\leftarrow Q$. In each matching direction, each time step of one sentence is matched against all time-steps of the other sentence from multiple perspectives. Then, another BiLSTM layer is utilized to aggregate the matching results into a fix-length matching vector. Finally, based on the matching vector, the decision is made through a fully connected layer. We evaluate our model on three tasks: paraphrase identification, natural language inference and answer sentence selection. Experimental results on standard benchmark datasets show that our model achieves the state-of-the-art performance on all tasks.\n    ",
        "submission_date": "2017-02-13T00:00:00",
        "last_modified_date": "2017-07-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.04047",
        "title": "Constraint Answer Set Solver EZCSP and Why Integration Schemas Matter",
        "authors": [
            "Marcello Balduccini",
            "Yuliya Lierler"
        ],
        "abstract": "Researchers in answer set programming and constraint programming have spent significant efforts in the development of hybrid languages and solving algorithms combining the strengths of these traditionally separate fields. These efforts resulted in a new research area: constraint answer set programming. Constraint answer set programming languages and systems proved to be successful at providing declarative, yet efficient solutions to problems involving hybrid reasoning tasks. One of the main contributions of this paper is the first comprehensive account of the constraint answer set language and solver EZCSP, a mainstream representative of this research area that has been used in various successful applications. We also develop an extension of the transition systems proposed by Nieuwenhuis et al. in 2006 to capture Boolean satisfiability solvers. We use this extension to describe the EZCSP algorithm and prove formal claims about it. The design and algorithmic details behind EZCSP clearly demonstrate that the development of the hybrid systems of this kind is challenging. Many questions arise when one faces various design choices in an attempt to maximize system's benefits. One of the key decisions that a developer of a hybrid solver makes is settling on a particular integration schema within its implementation. Thus, another important contribution of this paper is a thorough case study based on EZCSP, focused on the various integration schemas that it provides.\n",
        "submission_date": "2017-02-14T00:00:00",
        "last_modified_date": "2017-12-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.04282",
        "title": "T-SKIRT: Online Estimation of Student Proficiency in an Adaptive Learning System",
        "authors": [
            "Chaitanya Ekanadham",
            "Yan Karklin"
        ],
        "abstract": "We develop T-SKIRT: a temporal, structured-knowledge, IRT-based method for predicting student responses online. By explicitly accounting for student learning and employing a structured, multidimensional representation of student proficiencies, the model outperforms standard IRT-based methods on an online response prediction task when applied to real responses collected from students interacting with diverse pools of educational content.\n    ",
        "submission_date": "2017-02-14T00:00:00",
        "last_modified_date": "2017-02-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.04389",
        "title": "Entropy Non-increasing Games for the Improvement of Dataflow Programming",
        "authors": [
            "Norbert B\u00e1tfai",
            "Ren\u00e1t\u00f3 Besenczi",
            "Gerg\u0151 Bogacsovics",
            "Fanny Monori"
        ],
        "abstract": "In this article, we introduce a new conception of a family of esport games called Samu Entropy to try to improve dataflow program graphs like the ones that are based on Google's TensorFlow. Currently, the Samu Entropy project specifies only requirements for new esport games to be developed with particular attention to the investigation of the relationship between esport and artificial intelligence. It is quite obvious that there is a very close and natural relationship between esport games and artificial intelligence. Furthermore, the project Samu Entropy focuses not only on using artificial intelligence, but on creating AI in a new way. We present a reference game called Face Battle that implements the Samu Entropy requirements.\n    ",
        "submission_date": "2017-02-14T00:00:00",
        "last_modified_date": "2017-02-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.04584",
        "title": "Developing an ontology for the access to the contents of an archival fonds: the case of the Catasto Gregoriano",
        "authors": [
            "Lina Antonietta Coppola"
        ],
        "abstract": "The research was proposed to exploit and extend the relational and contextual nature of the information assets of the Catasto Gregoriano, kept at the Archivio di Stato in Rome. Developed within the MODEUS project (Making Open Data Effectively Usable), this study originates from the following key ideas of MODEUS: to require Open Data to be expressed in terms of an ontology, and to include such an ontology as a documentation of the data themselves. Thus, Open Data are naturally linked by means of the ontology, which meets the requirements of the Linked Open Data vision.\n    ",
        "submission_date": "2017-02-15T00:00:00",
        "last_modified_date": "2017-02-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.04594",
        "title": "Local Search for Minimum Weight Dominating Set with Two-Level Configuration Checking and Frequency Based Scoring Function",
        "authors": [
            "Yiyuan Wang",
            "Shaowei Cai",
            "Minghao Yin"
        ],
        "abstract": "The Minimum Weight Dominating Set (MWDS) problem is an important generalization of the Minimum Dominating Set (MDS) problem with extensive applications. This paper proposes a new local search algorithm for the MWDS problem, which is based on two new ideas. The first idea is a heuristic called two-level configuration checking (CC2), which is a new variant of a recent powerful configuration checking strategy (CC) for effectively avoiding the recent search paths. The second idea is a novel scoring function based on the frequency of being uncovered of vertices. Our algorithm is called CC2FS, according to the names of the two ideas. The experimental results show that, CC2FS performs much better than some state-of-the-art algorithms in terms of solution quality on a broad range of MWDS benchmarks.\n    ",
        "submission_date": "2017-02-15T00:00:00",
        "last_modified_date": "2017-02-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.04638",
        "title": "A Spacetime Approach to Generalized Cognitive Reasoning in Multi-scale Learning",
        "authors": [
            "Mark Burgess"
        ],
        "abstract": "In modern machine learning, pattern recognition replaces realtime semantic reasoning. The mapping from input to output is learned with fixed semantics by training outcomes deliberately. This is an expensive and static approach which depends heavily on the availability of a very particular kind of prior raining data to make inferences in a single step. Conventional semantic network approaches, on the other hand, base multi-step reasoning on modal logics and handcrafted ontologies, which are ad hoc, expensive to construct, and fragile to inconsistency. Both approaches may be enhanced by a hybrid approach, which completely separates reasoning from pattern recognition. In this report, a quasi-linguistic approach to knowledge representation is discussed, motivated by spacetime structure. Tokenized patterns from diverse sources are integrated to build a lightly constrained and approximately scale-free network. This is then be parsed with very simple recursive algorithms to generate `brainstorming' sets of reasoned knowledge.\n    ",
        "submission_date": "2017-02-12T00:00:00",
        "last_modified_date": "2017-08-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.05376",
        "title": "Towards a Unified Taxonomy of Biclustering Methods",
        "authors": [
            "Dmitry I. Ignatov",
            "Bruce W. Watson"
        ],
        "abstract": "Being an unsupervised machine learning and data mining technique, biclustering and its multimodal extensions are becoming popular tools for analysing object-attribute data in different domains. Apart from conventional clustering techniques, biclustering is searching for homogeneous groups of objects while keeping their common description, e.g., in binary setting, their shared attributes. In bioinformatics, biclustering is used to find genes, which are active in a subset of situations, thus being candidates for biomarkers. However, the authors of those biclustering techniques that are popular in gene expression analysis, may overlook the existing methods. For instance, BiMax algorithm is aimed at finding biclusters, which are well-known for decades as formal concepts. Moreover, even if bioinformatics classify the biclustering methods according to reasonable domain-driven criteria, their classification taxonomies may be different from survey to survey and not full as well. So, in this paper we propose to use concept lattices as a tool for taxonomy building (in the biclustering domain) and attribute exploration as means for cross-domain taxonomy completion.\n    ",
        "submission_date": "2017-02-17T00:00:00",
        "last_modified_date": "2017-02-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.05383",
        "title": "Theorem Proving Based on Semantics of DNA Strand Graph",
        "authors": [
            "Kumar S. Ray",
            "Mandrita Mondal"
        ],
        "abstract": "Because of several technological limitations of traditional silicon based computing, for past few years a paradigm shift, from silicon to carbon, is occurring in computational world. DNA computing has been considered to be quite promising in solving computational and reasoning problems by using DNA strands. Resolution, an important aspect of automated theorem proving and mathematical logic, is a rule of inference which leads to proof by contradiction technique for sentences in propositional logic and first-order logic. This can also be called refutation theorem-proving. In this paper we have shown how the theorem proving with resolution refutation by DNA computation can be represented by the semantics of process calculus and strand graph.\n    ",
        "submission_date": "2017-02-15T00:00:00",
        "last_modified_date": "2017-02-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.05515",
        "title": "Overview: Generalizations of Multi-Agent Path Finding to Real-World Scenarios",
        "authors": [
            "Hang Ma",
            "Sven Koenig",
            "Nora Ayanian",
            "Liron Cohen",
            "Wolfgang Hoenig",
            "T. K. Satish Kumar",
            "Tansel Uras",
            "Hong Xu",
            "Craig Tovey",
            "Guni Sharon"
        ],
        "abstract": "Multi-agent path finding (MAPF) is well-studied in artificial intelligence, robotics, theoretical computer science and operations research. We discuss issues that arise when generalizing MAPF methods to real-world scenarios and four research directions that address them. We emphasize the importance of addressing these issues as opposed to developing faster methods for the standard formulation of the MAPF problem.\n    ",
        "submission_date": "2017-02-17T00:00:00",
        "last_modified_date": "2017-02-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.05778",
        "title": "The Absent-Minded Driver Problem Redux",
        "authors": [
            "Subhash Kak"
        ],
        "abstract": "This paper reconsiders the problem of the absent-minded driver who must choose between alternatives with different payoff with imperfect recall and varying degrees of knowledge of the system. The classical absent-minded driver problem represents the case with limited information and it has bearing on the general area of communication and learning, social choice, mechanism design, auctions, theories of knowledge, belief, and rational agency. Within the framework of extensive games, this problem has applications to many artificial intelligence scenarios. It is obvious that the performance of the agent improves as information available increases. It is shown that a non-uniform assignment strategy for successive choices does better than a fixed probability strategy. We consider both classical and quantum approaches to the problem. We argue that the superior performance of quantum decisions with access to entanglement cannot be fairly compared to a classical algorithm. If the cognitive systems of agents are taken to have access to quantum resources, or have a quantum mechanical basis, then that can be leveraged into superior performance.\n    ",
        "submission_date": "2017-02-19T00:00:00",
        "last_modified_date": "2017-02-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.06000",
        "title": "'Viral' Turing Machines, Computation from Noise and Combinatorial Hierarchies",
        "authors": [
            "T. E. Raptis"
        ],
        "abstract": "The interactive computation paradigm is reviewed and a particular example is extended to form the stochastic analog of a computational process via a transcription of a minimal Turing Machine into an equivalent asynchronous Cellular Automaton with an exponential waiting times distribution of effective transitions. Furthermore, a special toolbox for analytic derivation of recursive relations of important statistical and other quantities is introduced in the form of an Inductive Combinatorial Hierarchy.\n    ",
        "submission_date": "2017-01-31T00:00:00",
        "last_modified_date": "2017-01-31T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.06199",
        "title": "The Dialog State Tracking Challenge with Bayesian Approach",
        "authors": [
            "Quan Nguyen"
        ],
        "abstract": "Generative model has been one of the most common approaches for solving the Dialog State Tracking Problem with the capabilities to model the dialog hypotheses in an explicit manner. The most important task in such Bayesian networks models is constructing the most reliable user models by learning and reflecting the training data into the probability distribution of user actions conditional on networks states. This paper provides an overall picture of the learning process in a Bayesian framework with an emphasize on the state-of-the-art theoretical analyses of the Expectation Maximization learning algorithm.\n    ",
        "submission_date": "2017-02-20T00:00:00",
        "last_modified_date": "2017-02-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.06238",
        "title": "Sample Efficient Policy Search for Optimal Stopping Domains",
        "authors": [
            "Karan Goel",
            "Christoph Dann",
            "Emma Brunskill"
        ],
        "abstract": "Optimal stopping problems consider the question of deciding when to stop an observation-generating process in order to maximize a return. We examine the problem of simultaneously learning and planning in such domains, when data is collected directly from the environment. We propose GFSE, a simple and flexible model-free policy search method that reuses data for sample efficiency by leveraging problem structure. We bound the sample complexity of our approach to guarantee uniform convergence of policy value estimates, tightening existing PAC bounds to achieve logarithmic dependence on horizon length for our setting. We also examine the benefit of our method against prevalent model-based and model-free approaches on 3 domains taken from diverse fields.\n    ",
        "submission_date": "2017-02-21T00:00:00",
        "last_modified_date": "2017-05-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.06329",
        "title": "Towards a Common Implementation of Reinforcement Learning for Multiple Robotic Tasks",
        "authors": [
            "Angel Mart\u00ednez-Tenor",
            "Juan Antonio Fern\u00e1ndez-Madrigal",
            "Ana Cruz-Mart\u00edn",
            "Javier Gonz\u00e1lez-Jim\u00e9nez"
        ],
        "abstract": "Mobile robots are increasingly being employed for performing complex tasks in dynamic environments. Reinforcement learning (RL) methods are recognized to be promising for specifying such tasks in a relatively simple manner. However, the strong dependency between the learning method and the task to learn is a well-known problem that restricts practical implementations of RL in robotics, often requiring major modifications of parameters and adding other techniques for each particular task. In this paper we present a practical core implementation of RL which enables the learning process for multiple robotic tasks with minimal per-task tuning or none. Based on value iteration methods, this implementation includes a novel approach for action selection, called Q-biased softmax regression (QBIASSR), which avoids poor performance of the learning process when the robot reaches new unexplored states. Our approach takes advantage of the structure of the state space by attending the physical variables involved (e.g., distances to obstacles, X,Y,{\\theta} pose, etc.), thus experienced sets of states may favor the decision-making process of unexplored or rarely-explored states. This improvement has a relevant role in reducing the tuning of the algorithm for particular tasks. Experiments with real and simulated robots, performed with the software framework also introduced here, show that our implementation is effectively able to learn different robotic tasks without tuning the learning method. Results also suggest that the combination of true online SARSA({\\lambda}) with QBIASSR can outperform the existing RL core algorithms in low-dimensional robotic tasks.\n    ",
        "submission_date": "2017-02-21T00:00:00",
        "last_modified_date": "2017-02-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.06404",
        "title": "Delving Deeper into MOOC Student Dropout Prediction",
        "authors": [
            "Jacob Whitehill",
            "Kiran Mohan",
            "Daniel Seaton",
            "Yigal Rosen",
            "Dustin Tingley"
        ],
        "abstract": "In order to obtain reliable accuracy estimates for automatic MOOC dropout predictors, it is important to train and test them in a manner consistent with how they will be used in practice. Yet most prior research on MOOC dropout prediction has measured test accuracy on the same course used for training the classifier, which can lead to overly optimistic accuracy estimates. In order to understand better how accuracy is affected by the training+testing regime, we compared the accuracy of a standard dropout prediction architecture (clickstream features + logistic regression) across 4 different training paradigms. Results suggest that (1) training and testing on the same course (\"post-hoc\") can overestimate accuracy by several percentage points; (2) dropout classifiers trained on proxy labels based on students' persistence are surprisingly competitive with post-hoc training (87.33% versus 90.20% AUC averaged over 8 weeks of 40 HarvardX MOOCs); and (3) classifier performance does not vary significantly with the academic discipline. Finally, we also research new dropout prediction architectures based on deep, fully-connected, feed-forward neural networks and find that (4) networks with as many as 5 hidden layers can statistically significantly increase test accuracy over that of logistic regression.\n    ",
        "submission_date": "2017-02-21T00:00:00",
        "last_modified_date": "2017-02-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.06662",
        "title": "An Integer Programming Model for Binary Knapsack Problem with Value-Related Dependencies among Elements",
        "authors": [
            "Davoud Mougouei",
            "David M. W. Powers",
            "Asghar Moeini"
        ],
        "abstract": "Binary Knapsack Problem (BKP) is to select a subset of an element (item) set with the highest value while keeping the total weight within the capacity of the knapsack. This paper presents an integer programming model for a variation of BKP where the value of each element may depend on selecting or ignoring other elements. Strengths of such Value-Related Dependencies are assumed to be imprecise and hard to specify. To capture this imprecision, we have proposed modeling value-related dependencies using fuzzy graphs and their algebraic structure.\n    ",
        "submission_date": "2017-02-22T00:00:00",
        "last_modified_date": "2017-02-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.06879",
        "title": "Knowledge Graph Completion via Complex Tensor Factorization",
        "authors": [
            "Th\u00e9o Trouillon",
            "Christopher R. Dance",
            "Johannes Welbl",
            "Sebastian Riedel",
            "\u00c9ric Gaussier",
            "Guillaume Bouchard"
        ],
        "abstract": "In statistical relational learning, knowledge graph completion deals with automatically understanding the structure of large knowledge graphs---labeled directed graphs---and predicting missing relationships---labeled edges. State-of-the-art embedding models propose different trade-offs between modeling expressiveness, and time and space complexity. We reconcile both expressiveness and complexity through the use of complex-valued embeddings and explore the link between such complex-valued embeddings and unitary diagonalization. We corroborate our approach theoretically and show that all real square matrices---thus all possible relation/adjacency matrices---are the real part of some unitarily diagonalizable matrix. This results opens the door to a lot of other applications of square matrices factorization. Our approach based on complex embeddings is arguably simple, as it only involves a Hermitian dot product, the complex counterpart of the standard dot product between real vectors, whereas other methods resort to more and more complicated composition functions to increase their expressiveness. The proposed complex embeddings are scalable to large data sets as it remains linear in both space and time, while consistently outperforming alternative approaches on standard link prediction benchmarks.\n    ",
        "submission_date": "2017-02-22T00:00:00",
        "last_modified_date": "2017-11-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.06915",
        "title": "Solving DCOPs with Distributed Large Neighborhood Search",
        "authors": [
            "Ferdinando Fioretto",
            "Agostino Dovier",
            "Enrico Pontelli",
            "William Yeoh",
            "Roie Zivan"
        ],
        "abstract": "The field of Distributed Constraint Optimization has gained momentum in recent years, thanks to its ability to address various applications related to multi-agent cooperation. Nevertheless, solving Distributed Constraint Optimization Problems (DCOPs) optimally is NP-hard. Therefore, in large-scale, complex applications, incomplete DCOP algorithms are necessary. Current incomplete DCOP algorithms suffer of one or more of the following limitations: they (a) find local minima without providing quality guarantees; (b) provide loose quality assessment; or (c) are unable to benefit from the structure of the problem, such as domain-dependent knowledge and hard constraints. Therefore, capitalizing on strategies from the centralized constraint solving community, we propose a Distributed Large Neighborhood Search (D-LNS) framework to solve DCOPs. The proposed framework (with its novel repair phase) provides guarantees on solution quality, refining upper and lower bounds during the iterative process, and can exploit domain-dependent structures. Our experimental results show that D-LNS outperforms other incomplete DCOP algorithms on both structured and unstructured problem instances.\n    ",
        "submission_date": "2017-02-22T00:00:00",
        "last_modified_date": "2017-02-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.06934",
        "title": "Realization of Ontology Web Search Engine",
        "authors": [
            "Olegs Verhodubs"
        ],
        "abstract": "This paper describes the realization of the Ontology Web Search Engine. The Ontology Web Search Engine is realizable as independent project and as a part of other projects. The main purpose of this paper is to present the Ontology Web Search Engine realization details as the part of the Semantic Web Expert System and to present the results of the Ontology Web Search Engine functioning. It is expected that the Semantic Web Expert System will be able to process ontologies from the Web, generate rules from these ontologies and develop its knowledge base.\n    ",
        "submission_date": "2017-02-22T00:00:00",
        "last_modified_date": "2017-02-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.06970",
        "title": "A Realistic Dataset for the Smart Home Device Scheduling Problem for DCOPs",
        "authors": [
            "William Kluegel",
            "Muhammad Aamir Iqbal",
            "Ferdinando Fioretto",
            "William Yeoh",
            "Enrico Pontelli"
        ],
        "abstract": "The field of Distributed Constraint Optimization has gained momentum in recent years thanks to its ability to address various applications related to multi-agent cooperation. While techniques to solve Distributed Constraint Optimization Problems (DCOPs) are abundant and have matured substantially since the field inception, the number of DCOP realistic applications and benchmark used to asses the performance of DCOP algorithms is lagging behind. To contrast this background we (i) introduce the Smart Home Device Scheduling (SHDS) problem, which describe the problem of coordinating smart devices schedules across multiple homes as a multi-agent system, (ii) detail the physical models adopted to simulate smart sensors, smart actuators, and homes environments, and (iii) introduce a DCOP realistic benchmark for SHDS problems.\n    ",
        "submission_date": "2017-02-22T00:00:00",
        "last_modified_date": "2017-02-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.07001",
        "title": "Theoretical and Experimental Analysis of the Canadian Traveler Problem",
        "authors": [
            "Doron Zarchy"
        ],
        "abstract": "Devising an optimal strategy for navigation in a partially observable environment is one of the key objectives in AI. One of the problem in this context is the Canadian Traveler Problem (CTP). CTP is a navigation problem where an agent is tasked to travel from source to target in a partially observable weighted graph, whose edge might be blocked with a certain probability and observing such blockage occurs only when reaching upon one of the edges end points. The goal is to find a strategy that minimizes the expected travel cost. The problem is known to be P$\\#$ hard. In this work we study the CTP theoretically and empirically. First, we study the Dep-CTP, a CTP variant we introduce which assumes dependencies between the edges status. We show that Dep-CTP is intractable, and further we analyze two of its subclasses on disjoint paths graph. Second, we develop a general algorithm Gen-PAO that optimally solve the CTP. Gen-PAO is capable of solving two other types of CTP called Sensing-CTP and Expensive-Edges CTP. Since the CTP is intractable, Gen-PAO use some pruning methods to reduce the space search for the optimal solution. We also define some variants of Gen-PAO, compare their performance and show some benefits of Gen-PAO over existing work.\n    ",
        "submission_date": "2017-02-22T00:00:00",
        "last_modified_date": "2017-02-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.07168",
        "title": "A DIKW Paradigm to Cognitive Engineering",
        "authors": [
            "Amit Kumar Mishra"
        ],
        "abstract": "Though the word cognitive has a wide range of meanings we define cognitive engineering as learning from brain to bolster engineering solutions. However, giving an achievable framework to the process towards this has been a difficult task. In this work we take the classic data information knowledge wisdom (DIKW) framework to set some achievable goals and sub-goals towards cognitive engineering. A layered framework like DIKW aligns nicely with the layered structure of pre-frontal cortex. And breaking the task into sub-tasks based on the layers also makes it easier to start developmental endeavours towards achieving the final goal of a brain-inspired system.\n    ",
        "submission_date": "2017-02-23T00:00:00",
        "last_modified_date": "2017-02-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.07193",
        "title": "Ontologies in System Engineering: a Field Report",
        "authors": [
            "Marco Menapace",
            "Armando Tacchella"
        ],
        "abstract": "In recent years ontologies enjoyed a growing popularity outside specialized AI communities. System engineering is no exception to this trend, with ontologies being proposed as a basis for several tasks in complex industrial implements, including system design, monitoring and diagnosis. In this paper, we consider four different contributions to system engineering wherein ontologies are instrumental to provide enhancements over traditional ad-hoc techniques. For each application, we briefly report the methodologies, the tools and the results obtained with the goal to provide an assessment of merits and limits of ontologies in such domains.\n    ",
        "submission_date": "2017-02-23T00:00:00",
        "last_modified_date": "2017-02-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.07281",
        "title": "A Probabilistic Framework for Location Inference from Social Media",
        "authors": [
            "Yujie Qian",
            "Jie Tang",
            "Zhilin Yang",
            "Binxuan Huang",
            "Wei Wei",
            "Kathleen M. Carley"
        ],
        "abstract": "We study the extent to which we can infer users' geographical locations from social media. Location inference from social media can benefit many applications, such as disaster management, targeted advertising, and news content tailoring. The challenges, however, lie in the limited amount of labeled data and the large scale of social networks. In this paper, we formalize the problem of inferring location from social media into a semi-supervised factor graph model (SSFGM). The model provides a probabilistic framework in which various sources of information (e.g., content and social network) can be combined together. We design a two-layer neural network to learn feature representations, and incorporate the learned latent features into SSFGM. To deal with the large-scale problem, we propose a Two-Chain Sampling (TCS) algorithm to learn SSFGM. The algorithm achieves a good trade-off between accuracy and efficiency. Experiments on Twitter and Weibo show that the proposed TCS algorithm for SSFGM can substantially improve the inference accuracy over several state-of-the-art methods. More importantly, TCS achieves over 100x speedup comparing with traditional propagation-based methods (e.g., loopy belief propagation).\n    ",
        "submission_date": "2017-02-23T00:00:00",
        "last_modified_date": "2019-05-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.07543",
        "title": "Embedding Knowledge Graphs Based on Transitivity and Antisymmetry of Rules",
        "authors": [
            "Mengya Wang",
            "Hankui Zhuo",
            "Huiling Zhu"
        ],
        "abstract": "Representation learning of knowledge graphs encodes entities and relation types into a continuous low-dimensional vector space, learns embeddings of entities and relation types. Most existing methods only concentrate on knowledge triples, ignoring logic rules which contain rich background knowledge. Although there has been some work aiming at leveraging both knowledge triples and logic rules, they ignore the transitivity and antisymmetry of logic rules. In this paper, we propose a novel approach to learn knowledge representations with entities and ordered relations in knowledges and logic rules. The key idea is to integrate knowledge triples and logic rules, and approximately order the relation types in logic rules to utilize the transitivity and antisymmetry of logic rules. All entries of the embeddings of relation types are constrained to be non-negative. We translate the general constrained optimization problem into an unconstrained optimization problem to solve the non-negative matrix factorization. Experimental results show that our model significantly outperforms other baselines on knowledge graph completion task. It indicates that our model is capable of capturing the transitivity and antisymmetry information, which is significant when learning embeddings of knowledge graphs.\n    ",
        "submission_date": "2017-02-24T00:00:00",
        "last_modified_date": "2017-04-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.07826",
        "title": "Rationalization: A Neural Machine Translation Approach to Generating Natural Language Explanations",
        "authors": [
            "Upol Ehsan",
            "Brent Harrison",
            "Larry Chan",
            "Mark O. Riedl"
        ],
        "abstract": "We introduce AI rationalization, an approach for generating explanations of autonomous system behavior as if a human had performed the behavior. We describe a rationalization technique that uses neural machine translation to translate internal state-action representations of an autonomous agent into natural language. We evaluate our technique in the Frogger game environment, training an autonomous game playing agent to rationalize its action choices using natural language. A natural language training corpus is collected from human players thinking out loud as they play the game. We motivate the use of rationalization as an approach to explanation generation and show the results of two experiments evaluating the effectiveness of rationalization. Results of these evaluations show that neural machine translation is able to accurately generate rationalizations that describe agent behavior, and that rationalizations are more satisfying to humans than other alternative methods of explanation.\n    ",
        "submission_date": "2017-02-25T00:00:00",
        "last_modified_date": "2017-12-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.07983",
        "title": "Maximum-Likelihood Augmented Discrete Generative Adversarial Networks",
        "authors": [
            "Tong Che",
            "Yanran Li",
            "Ruixiang Zhang",
            "R Devon Hjelm",
            "Wenjie Li",
            "Yangqiu Song",
            "Yoshua Bengio"
        ],
        "abstract": "Despite the successes in capturing continuous distributions, the application of generative adversarial networks (GANs) to discrete settings, like natural language tasks, is rather restricted. The fundamental reason is the difficulty of back-propagation through discrete random variables combined with the inherent instability of the GAN training objective. To address these problems, we propose Maximum-Likelihood Augmented Discrete Generative Adversarial Networks. Instead of directly optimizing the GAN objective, we derive a novel and low-variance objective using the discriminator's output that follows corresponds to the log-likelihood. Compared with the original, the new objective is proved to be consistent in theory and beneficial in practice. The experimental results on various discrete datasets demonstrate the effectiveness of the proposed approach.\n    ",
        "submission_date": "2017-02-26T00:00:00",
        "last_modified_date": "2017-02-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.08039",
        "title": "Criticality & Deep Learning I: Generally Weighted Nets",
        "authors": [
            "Dan Oprisa",
            "Peter Toth"
        ],
        "abstract": "Motivated by the idea that criticality and universality of phase transitions might play a crucial role in achieving and sustaining learning and intelligent behaviour in biological and artificial networks, we analyse a theoretical and a pragmatic experimental set up for critical phenomena in deep learning. On the theoretical side, we use results from statistical physics to carry out critical point calculations in feed-forward/fully connected networks, while on the experimental side we set out to find traces of criticality in deep neural networks. This is our first step in a series of upcoming investigations to map out the relationship between criticality and learning in deep networks.\n    ",
        "submission_date": "2017-02-26T00:00:00",
        "last_modified_date": "2017-05-31T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.08222",
        "title": "Synergistic Team Composition",
        "authors": [
            "Ewa Andrejczuk",
            "Juan A. Rodriguez-Aguilar",
            "Carme Roig",
            "Carles Sierra"
        ],
        "abstract": "Effective teams are crucial for organisations, especially in environments that require teams to be constantly created and dismantled, such as software development, scientific experiments, crowd-sourcing, or the classroom. Key factors influencing team performance are competences and personality of team members. Hence, we present a computational model to compose proficient and congenial teams based on individuals' personalities and their competences to perform tasks of different nature. With this purpose, we extend Wilde's post-Jungian method for team composition, which solely employs individuals' personalities. The aim of this study is to create a model to partition agents into teams that are balanced in competences, personality and gender. Finally, we present some preliminary empirical results that we obtained when analysing student performance. Results show the benefits of a more informed team composition that exploits individuals' competences besides information about their personalities.\n    ",
        "submission_date": "2017-02-27T00:00:00",
        "last_modified_date": "2017-02-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.08367",
        "title": "Differentiable Learning of Logical Rules for Knowledge Base Reasoning",
        "authors": [
            "Fan Yang",
            "Zhilin Yang",
            "William W. Cohen"
        ],
        "abstract": "We study the problem of learning probabilistic first-order logical rules for knowledge base reasoning. This learning problem is difficult because it requires learning the parameters in a continuous space as well as the structure in a discrete space. We propose a framework, Neural Logic Programming, that combines the parameter and structure learning of first-order logical rules in an end-to-end differentiable model. This approach is inspired by a recently-developed differentiable logic called TensorLog, where inference tasks can be compiled into sequences of differentiable operations. We design a neural controller system that learns to compose these operations. Empirically, our method outperforms prior work on multiple knowledge base benchmark datasets, including Freebase and WikiMovies.\n    ",
        "submission_date": "2017-02-27T00:00:00",
        "last_modified_date": "2017-11-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.08441",
        "title": "Monte Carlo Action Programming",
        "authors": [
            "Lenz Belzner"
        ],
        "abstract": "This paper proposes Monte Carlo Action Programming, a programming language framework for autonomous systems that act in large probabilistic state spaces with high branching factors. It comprises formal syntax and semantics of a nondeterministic action programming language. The language is interpreted stochastically via Monte Carlo Tree Search. Effectiveness of the approach is shown empirically.\n    ",
        "submission_date": "2017-02-25T00:00:00",
        "last_modified_date": "2017-02-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.08495",
        "title": "Don't Fear the Reaper: Refuting Bostrom's Superintelligence Argument",
        "authors": [
            "Sebastian Benthall"
        ],
        "abstract": "In recent years prominent intellectuals have raised ethical concerns about the consequences of artificial intelligence. One concern is that an autonomous agent might modify itself to become \"superintelligent\" and, in supremely effective pursuit of poorly specified goals, destroy all of humanity. This paper considers and rejects the possibility of this outcome. We argue that this scenario depends on an agent's ability to rapidly improve its ability to predict its environment through self-modification. Using a Bayesian model of a reasoning agent, we show that there are important limitations to how an agent may improve its predictive ability through self-modification alone. We conclude that concern about this artificial intelligence outcome is misplaced and better directed at policy questions around data access and storage.\n    ",
        "submission_date": "2017-02-27T00:00:00",
        "last_modified_date": "2017-03-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.08745",
        "title": "Optimal Categorical Attribute Transformation for Granularity Change in Relational Databases for Binary Decision Problems in Educational Data Mining",
        "authors": [
            "Paulo J. L. Adeodato",
            "F\u00e1bio C. Pereira",
            "Rosalvo F. Oliveira Neto"
        ],
        "abstract": "This paper presents an approach for transforming data granularity in hierarchical databases for binary decision problems by applying regression to categorical attributes at the lower grain levels. Attributes from a lower hierarchy entity in the relational database have their information content optimized through regression on the categories histogram trained on a small exclusive labelled sample, instead of the usual mode category of the distribution. The paper validates the approach on a binary decision task for assessing the quality of secondary schools focusing on how logistic regression transforms the students and teachers attributes into school attributes. Experiments were carried out on Brazilian schools public datasets via 10-fold cross-validation comparison of the ranking score produced also by logistic regression. The proposed approach achieved higher performance than the usual distribution mode transformation and equal to the expert weighing approach measured by the maximum Kolmogorov-Smirnov distance and the area under the ROC curve at 0.01 significance level.\n    ",
        "submission_date": "2017-02-28T00:00:00",
        "last_modified_date": "2017-02-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.08887",
        "title": "Stabilising Experience Replay for Deep Multi-Agent Reinforcement Learning",
        "authors": [
            "Jakob Foerster",
            "Nantas Nardelli",
            "Gregory Farquhar",
            "Triantafyllos Afouras",
            "Philip H. S. Torr",
            "Pushmeet Kohli",
            "Shimon Whiteson"
        ],
        "abstract": "Many real-world problems, such as network packet routing and urban traffic control, are naturally modeled as multi-agent reinforcement learning (RL) problems. However, existing multi-agent RL methods typically scale poorly in the problem size. Therefore, a key challenge is to translate the success of deep learning on single-agent RL to the multi-agent setting. A major stumbling block is that independent Q-learning, the most popular multi-agent RL method, introduces nonstationarity that makes it incompatible with the experience replay memory on which deep Q-learning relies. This paper proposes two methods that address this problem: 1) using a multi-agent variant of importance sampling to naturally decay obsolete data and 2) conditioning each agent's value function on a fingerprint that disambiguates the age of the data sampled from the replay memory. Results on a challenging decentralised variant of StarCraft unit micromanagement confirm that these methods enable the successful combination of experience replay with multi-agent RL.\n    ",
        "submission_date": "2017-02-28T00:00:00",
        "last_modified_date": "2018-05-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.08892",
        "title": "Bridging the Gap Between Value and Policy Based Reinforcement Learning",
        "authors": [
            "Ofir Nachum",
            "Mohammad Norouzi",
            "Kelvin Xu",
            "Dale Schuurmans"
        ],
        "abstract": "We establish a new connection between value and policy based reinforcement learning (RL) based on a relationship between softmax temporal value consistency and policy optimality under entropy regularization. Specifically, we show that softmax consistent action values correspond to optimal entropy regularized policy probabilities along any action sequence, regardless of provenance. From this observation, we develop a new RL algorithm, Path Consistency Learning (PCL), that minimizes a notion of soft consistency error along multi-step action sequences extracted from both on- and off-policy traces. We examine the behavior of PCL in different scenarios and show that PCL can be interpreted as generalizing both actor-critic and Q-learning algorithms. We subsequently deepen the relationship by showing how a single model can be used to represent both a policy and the corresponding softmax state values, eliminating the need for a separate critic. The experimental evaluation demonstrates that PCL significantly outperforms strong actor-critic and Q-learning baselines across several benchmarks.\n    ",
        "submission_date": "2017-02-28T00:00:00",
        "last_modified_date": "2017-11-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.00247",
        "title": "Learning A Physical Long-term Predictor",
        "authors": [
            "Sebastien Ehrhardt",
            "Aron Monszpart",
            "Niloy J. Mitra",
            "Andrea Vedaldi"
        ],
        "abstract": "Evolution has resulted in highly developed abilities in many natural intelligences to quickly and accurately predict mechanical phenomena. Humans have successfully developed laws of physics to abstract and model such mechanical phenomena. In the context of artificial intelligence, a recent line of work has focused on estimating physical parameters based on sensory data and use them in physical simulators to make long-term predictions. In contrast, we investigate the effectiveness of a single neural network for end-to-end long-term prediction of mechanical phenomena. Based on extensive evaluation, we demonstrate that such networks can outperform alternate approaches having even access to ground-truth physical simulators, especially when some physical parameters are unobserved or not known a-priori. Further, our network outputs a distribution of outcomes to capture the inherent uncertainty in the data. Our approach demonstrates for the first time the possibility of making actionable long-term predictions from sensor data without requiring to explicitly model the underlying physical laws.\n    ",
        "submission_date": "2017-03-01T00:00:00",
        "last_modified_date": "2017-03-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.00391",
        "title": "A Hypercat-enabled Semantic Internet of Things Data Hub: Technical Report",
        "authors": [
            "Ilias Tachmazidis",
            "Sotiris Batsakis",
            "John Davies",
            "Alistair Duke",
            "Mauro Vallati",
            "Grigoris Antoniou",
            "Sandra Stincic Clarke"
        ],
        "abstract": "An increasing amount of information is generated from the rapidly increasing number of sensor networks and smart devices. A wide variety of sources generate and publish information in different formats, thus highlighting interoperability as one of the key prerequisites for the success of Internet of Things (IoT). The BT Hypercat Data Hub provides a focal point for the sharing and consumption of available datasets from a wide range of sources. In this work, we propose a semantic enrichment of the BT Hypercat Data Hub, using well-accepted Semantic Web standards and tools. We propose an ontology that captures the semantics of the imported data and present the BT SPARQL Endpoint by means of a mapping between SPARQL and SQL queries. Furthermore, federated SPARQL queries allow queries over multiple hub-based and external data sources. Finally, we provide two use cases in order to illustrate the advantages afforded by our semantic approach.\n    ",
        "submission_date": "2017-03-01T00:00:00",
        "last_modified_date": "2017-03-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.00426",
        "title": "HolStep: A Machine Learning Dataset for Higher-order Logic Theorem Proving",
        "authors": [
            "Cezary Kaliszyk",
            "Fran\u00e7ois Chollet",
            "Christian Szegedy"
        ],
        "abstract": "Large computer-understandable proofs consist of millions of intermediate logical steps. The vast majority of such steps originate from manually selected and manually guided heuristics applied to intermediate goals. So far, machine learning has generally not been used to filter or generate these steps. In this paper, we introduce a new dataset based on Higher-Order Logic (HOL) proofs, for the purpose of developing new machine learning-based theorem-proving strategies. We make this dataset publicly available under the BSD license. We propose various machine learning tasks that can be performed on this dataset, and discuss their significance for theorem proving. We also benchmark a set of simple baseline machine learning models suited for the tasks (including logistic regression, convolutional neural networks and recurrent neural networks). The results of our baseline models show the promise of applying machine learning to HOL theorem proving.\n    ",
        "submission_date": "2017-03-01T00:00:00",
        "last_modified_date": "2017-03-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.00674",
        "title": "Adaptive Matching for Expert Systems with Uncertain Task Types",
        "authors": [
            "Virag Shah",
            "Lennart Gulikers",
            "Laurent Massoulie",
            "Milan Vojnovic"
        ],
        "abstract": "A matching in a two-sided market often incurs an externality: a matched resource may become unavailable to the other side of the market, at least for a while. This is especially an issue in online platforms involving human experts as the expert resources are often scarce. The efficient utilization of experts in these platforms is made challenging by the fact that the information available about the parties involved is usually limited.\n",
        "submission_date": "2017-03-02T00:00:00",
        "last_modified_date": "2018-10-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.00760",
        "title": "Sampling Variations of Lead Sheets",
        "authors": [
            "Pierre Roy",
            "Alexandre Papadopoulos",
            "Fran\u00e7ois Pachet"
        ],
        "abstract": "Machine-learning techniques have been recently used with spectacular results to generate artefacts such as music or text. However, these techniques are still unable to capture and generate artefacts that are convincingly structured. In this paper we present an approach to generate structured musical sequences. We introduce a mechanism for sampling efficiently variations of musical sequences. Given a input sequence and a statistical model, this mechanism samples a set of sequences whose distance to the input sequence is approximately within specified bounds. This mechanism is implemented as an extension of belief propagation, and uses local fields to bias the generation. We show experimentally that sampled sequences are indeed closely correlated to the standard musical similarity measure defined by Mongeau and Sankoff. We then show how this mechanism can used to implement composition strategies that enforce arbitrary structure on a musical lead sheet generation problem.\n    ",
        "submission_date": "2017-03-02T00:00:00",
        "last_modified_date": "2017-03-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.00838",
        "title": "SLIM: Semi-Lazy Inference Mechanism for Plan Recognition",
        "authors": [
            "Retuh Mirsky",
            "Ya'akov"
        ],
        "abstract": "Plan Recognition algorithms require to recognize a complete hierarchy explaining the agent's actions and goals. While the output of such algorithms is informative to the recognizer, the cost of its calculation is high in run-time, space, and completeness. Moreover, performing plan recognition online requires the observing agent to reason about future actions that have not yet been seen and maintain a set of hypotheses to support all possible options. This paper presents a new and efficient algorithm for online plan recognition called SLIM (Semi-Lazy Inference Mechanism). It combines both a bottom-up and top-down parsing processes, which allow it to commit only to the minimum necessary actions in real-time, but still provide complete hypotheses post factum. We show both theoretically and empirically that although the computational cost of this process is still exponential, there is a significant improvement in run-time when compared to a state of the art of plan recognition algorithm.\n    ",
        "submission_date": "2017-03-02T00:00:00",
        "last_modified_date": "2017-03-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.01026",
        "title": "Unsupervised Basis Function Adaptation for Reinforcement Learning",
        "authors": [
            "Edward W. Barker",
            "Charl J. Ras"
        ],
        "abstract": "When using reinforcement learning (RL) algorithms to evaluate a policy it is common, given a large state space, to introduce some form of approximation architecture for the value function (VF). The exact form of this architecture can have a significant effect on the accuracy of the VF estimate, however, and determining a suitable approximation architecture can often be a highly complex task. Consequently there is a large amount of interest in the potential for allowing RL algorithms to adaptively generate approximation architectures.\n",
        "submission_date": "2017-03-03T00:00:00",
        "last_modified_date": "2017-03-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.01083",
        "title": "Sequential Plan Recognition",
        "authors": [
            "Reuth Mirsky",
            "Roni Stern",
            "Ya'akov",
            "Meir Kalech"
        ],
        "abstract": "Plan recognition algorithms infer agents' plans from their observed actions. Due to imperfect knowledge about the agent's behavior and the environment, it is often the case that there are multiple hypotheses about an agent's plans that are consistent with the observations, though only one of these hypotheses is correct. This paper addresses the problem of how to disambiguate between hypotheses, by querying the acting agent about whether a candidate plan in one of the hypotheses matches its intentions. This process is performed sequentially and used to update the set of possible hypotheses during the recognition process. The paper defines the sequential plan recognition process (SPRP), which seeks to reduce the number of hypotheses using a minimal number of queries. We propose a number of policies for the SPRP which use maximum likelihood and information gain to choose which plan to query. We show this approach works well in practice on two domains from the literature, significantly reducing the number of hypotheses using fewer queries than a baseline approach. Our results can inform the design of future plan recognition systems that interleave the recognition process with intelligent interventions of their users.\n    ",
        "submission_date": "2017-03-03T00:00:00",
        "last_modified_date": "2017-03-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.01161",
        "title": "FeUdal Networks for Hierarchical Reinforcement Learning",
        "authors": [
            "Alexander Sasha Vezhnevets",
            "Simon Osindero",
            "Tom Schaul",
            "Nicolas Heess",
            "Max Jaderberg",
            "David Silver",
            "Koray Kavukcuoglu"
        ],
        "abstract": "We introduce FeUdal Networks (FuNs): a novel architecture for hierarchical reinforcement learning. Our approach is inspired by the feudal reinforcement learning proposal of Dayan and Hinton, and gains power and efficacy by decoupling end-to-end learning across multiple levels -- allowing it to utilise different resolutions of time. Our framework employs a Manager module and a Worker module. The Manager operates at a lower temporal resolution and sets abstract goals which are conveyed to and enacted by the Worker. The Worker generates primitive actions at every tick of the environment. The decoupled structure of FuN conveys several benefits -- in addition to facilitating very long timescale credit assignment it also encourages the emergence of sub-policies associated with different goals set by the Manager. These properties allow FuN to dramatically outperform a strong baseline agent on tasks that involve long-term credit assignment or memorisation. We demonstrate the performance of our proposed system on a range of tasks from the ATARI suite and also from a 3D DeepMind Lab environment.\n    ",
        "submission_date": "2017-03-03T00:00:00",
        "last_modified_date": "2017-03-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.01274",
        "title": "Actor-Critic Reinforcement Learning with Simultaneous Human Control and Feedback",
        "authors": [
            "Kory W. Mathewson",
            "Patrick M. Pilarski"
        ],
        "abstract": "This paper contributes a first study into how different human users deliver simultaneous control and feedback signals during human-robot interaction. As part of this work, we formalize and present a general interactive learning framework for online cooperation between humans and reinforcement learning agents. In many human-machine interaction settings, there is a growing gap between the degrees-of-freedom of complex semi-autonomous systems and the number of human control channels. Simple human control and feedback mechanisms are required to close this gap and allow for better collaboration between humans and machines on complex tasks. To better inform the design of concurrent control and feedback interfaces, we present experimental results from a human-robot collaborative domain wherein the human must simultaneously deliver both control and feedback signals to interactively train an actor-critic reinforcement learning robot. We compare three experimental conditions: 1) human delivered control signals, 2) reward-shaping feedback signals, and 3) simultaneous control and feedback. Our results suggest that subjects provide less feedback when simultaneously delivering feedback and control signals and that control signal quality is not significantly diminished. Our data suggest that subjects may also modify when and how they provide feedback. Through algorithmic development and tuning informed by this study, we expect semi-autonomous actions of robotic agents can be better shaped by human feedback, allowing for seamless collaboration and improved performance in difficult interactive domains.\n    ",
        "submission_date": "2017-03-03T00:00:00",
        "last_modified_date": "2017-03-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.01310",
        "title": "Count-Based Exploration with Neural Density Models",
        "authors": [
            "Georg Ostrovski",
            "Marc G. Bellemare",
            "Aaron van den Oord",
            "Remi Munos"
        ],
        "abstract": "Bellemare et al. (2016) introduced the notion of a pseudo-count, derived from a density model, to generalize count-based exploration to non-tabular reinforcement learning. This pseudo-count was used to generate an exploration bonus for a DQN agent and combined with a mixed Monte Carlo update was sufficient to achieve state of the art on the Atari 2600 game Montezuma's Revenge. We consider two questions left open by their work: First, how important is the quality of the density model for exploration? Second, what role does the Monte Carlo update play in exploration? We answer the first question by demonstrating the use of PixelCNN, an advanced neural density model for images, to supply a pseudo-count. In particular, we examine the intrinsic difficulties in adapting Bellemare et al.'s approach when assumptions about the model are violated. The result is a more practical and general algorithm requiring no special apparatus. We combine PixelCNN pseudo-counts with different agent architectures to dramatically improve the state of the art on several hard Atari games. One surprising finding is that the mixed Monte Carlo update is a powerful facilitator of exploration in the sparsest of settings, including Montezuma's Revenge.\n    ",
        "submission_date": "2017-03-03T00:00:00",
        "last_modified_date": "2017-06-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.01327",
        "title": "Multi-step Reinforcement Learning: A Unifying Algorithm",
        "authors": [
            "Kristopher De Asis",
            "J. Fernando Hernandez-Garcia",
            "G. Zacharias Holland",
            "Richard S. Sutton"
        ],
        "abstract": "Unifying seemingly disparate algorithmic ideas to produce better performing algorithms has been a longstanding goal in reinforcement learning. As a primary example, TD($\\lambda$) elegantly unifies one-step TD prediction with Monte Carlo methods through the use of eligibility traces and the trace-decay parameter $\\lambda$. Currently, there are a multitude of algorithms that can be used to perform TD control, including Sarsa, $Q$-learning, and Expected Sarsa. These methods are often studied in the one-step case, but they can be extended across multiple time steps to achieve better performance. Each of these algorithms is seemingly distinct, and no one dominates the others for all problems. In this paper, we study a new multi-step action-value algorithm called $Q(\\sigma)$ which unifies and generalizes these existing algorithms, while subsuming them as special cases. A new parameter, $\\sigma$, is introduced to allow the degree of sampling performed by the algorithm at each step during its backup to be continuously varied, with Sarsa existing at one extreme (full sampling), and Expected Sarsa existing at the other (pure expectation). $Q(\\sigma)$ is generally applicable to both on- and off-policy learning, but in this work we focus on experiments in the on-policy case. Our results show that an intermediate value of $\\sigma$, which results in a mixture of the existing algorithms, performs better than either extreme. The mixture can also be varied dynamically which can result in even greater performance.\n    ",
        "submission_date": "2017-03-03T00:00:00",
        "last_modified_date": "2018-06-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.01333",
        "title": "Towards Monetary Incentives in Social Q&A Services",
        "authors": [
            "Steve T.K. Jan",
            "Chun Wang",
            "Qing Zhang",
            "Gang Wang"
        ],
        "abstract": "Community-based question answering (CQA) services are facing key challenges to motivate domain experts to provide timely answers. Recently, CQA services are exploring new incentive models to engage experts and celebrities by allowing them to set a price on their answers. In this paper, we perform a data-driven analysis on two emerging payment-based CQA systems: Fenda (China) and Whale (US). By analyzing a large dataset of 220K questions (worth 1 million USD collectively), we examine how monetary incentives affect different players in the system. We find that, while monetary incentive enables quick answers from experts, it also drives certain users to aggressively game the system for profits. In addition, in this supplier-driven marketplace, users need to proactively adjust their price to make profits. Famous people are unwilling to lower their price, which in turn hurts their income and engagement over time. Finally, we discuss the key implications to future CQA design.\n    ",
        "submission_date": "2017-03-03T00:00:00",
        "last_modified_date": "2017-04-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.01347",
        "title": "Contextual Linear Bandits under Noisy Features: Towards Bayesian Oracles",
        "authors": [
            "Jung-hun Kim",
            "Se-Young Yun",
            "Minchan Jeong",
            "Jun Hyun Nam",
            "Jinwoo Shin",
            "Richard Combes"
        ],
        "abstract": "We study contextual linear bandit problems under feature uncertainty, where the features are noisy and have missing entries. To address the challenges posed by this noise, we analyze Bayesian oracles given the observed noisy features. Our Bayesian analysis reveals that the optimal hypothesis can significantly deviate from the underlying realizability function, depending on the noise characteristics. These deviations are highly non-intuitive and do not occur in classical noiseless setups. This implies that classical approaches cannot guarantee a non-trivial regret bound. Therefore, we propose an algorithm that aims to approximate the Bayesian oracle based on the observed information under this model, achieving $\\tilde{O}(d\\sqrt{T})$ regret bound when there is a large number of arms. We demonstrate the proposed algorithm using synthetic and real-world datasets.\n    ",
        "submission_date": "2017-03-03T00:00:00",
        "last_modified_date": "2024-10-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.01358",
        "title": "Generalised Discount Functions applied to a Monte-Carlo AImu Implementation",
        "authors": [
            "Sean Lamont",
            "John Aslanides",
            "Jan Leike",
            "Marcus Hutter"
        ],
        "abstract": "In recent years, work has been done to develop the theory of General Reinforcement Learning (GRL). However, there are few examples demonstrating these results in a concrete way. In particular, there are no examples demonstrating the known results regarding gener- alised discounting. We have added to the GRL simulation platform AIXIjs the functionality to assign an agent arbitrary discount functions, and an environment which can be used to determine the effect of discounting on an agent's policy. Using this, we investigate how geometric, hyperbolic and power discounting affect an informed agent in a simple MDP. We experimentally reproduce a number of theoretical results, and discuss some related subtleties. It was found that the agent's behaviour followed what is expected theoretically, assuming appropriate parameters were chosen for the Monte-Carlo Tree Search (MCTS) planning algorithm.\n    ",
        "submission_date": "2017-03-03T00:00:00",
        "last_modified_date": "2017-03-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.01671",
        "title": "Controlling for Unobserved Confounds in Classification Using Correlational Constraints",
        "authors": [
            "Virgile Landeiro",
            "Aron Culotta"
        ],
        "abstract": "As statistical classifiers become integrated into real-world applications, it is important to consider not only their accuracy but also their robustness to changes in the data distribution. In this paper, we consider the case where there is an unobserved confounding variable $z$ that influences both the features $\\mathbf{x}$ and the class variable $y$. When the influence of $z$ changes from training to testing data, we find that the classifier accuracy can degrade rapidly. In our approach, we assume that we can predict the value of $z$ at training time with some error. The prediction for $z$ is then fed to Pearl's back-door adjustment to build our model. Because of the attenuation bias caused by measurement error in $z$, standard approaches to controlling for $z$ are ineffective. In response, we propose a method to properly control for the influence of $z$ by first estimating its relationship with the class variable $y$, then updating predictions for $z$ to match that estimated relationship. By adjusting the influence of $z$, we show that we can build a model that exceeds competing baselines on accuracy as well as on robustness over a range of confounding relationships.\n    ",
        "submission_date": "2017-03-05T00:00:00",
        "last_modified_date": "2018-01-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.01697",
        "title": "Principles and Examples of Plausible Reasoning and Propositional Plausible Logic",
        "authors": [
            "David Billington"
        ],
        "abstract": "Plausible reasoning concerns situations whose inherent lack of precision is not quantified; that is, there are no degrees or levels of precision, and hence no use of numbers like probabilities. A hopefully comprehensive set of principles that clarifies what it means for a formal logic to do plausible reasoning is presented. A new propositional logic, called Propositional Plausible Logic (PPL), is defined and applied to some important examples. PPL is the only non-numeric non-monotonic logic we know of that satisfies all the principles and correctly reasons with all the examples. Some important results about PPL are proved.\n    ",
        "submission_date": "2017-03-06T00:00:00",
        "last_modified_date": "2017-04-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.01893",
        "title": "Approximate Muscle Guided Beam Search for Three-Index Assignment Problem",
        "authors": [
            "He Jiang",
            "Shuwei Zhang",
            "Zhilei Ren",
            "Xiaochen Lai",
            "Yong Piao"
        ],
        "abstract": "As a well-known NP-hard problem, the Three-Index Assignment Problem (AP3) has attracted lots of research efforts for developing heuristics. However, existing heuristics either obtain less competitive solutions or consume too much time. In this paper, a new heuristic named Approximate Muscle guided Beam Search (AMBS) is developed to achieve a good trade-off between solution quality and running time. By combining the approximate muscle with beam search, the solution space size can be significantly decreased, thus the time for searching the solution can be sharply reduced. Extensive experimental results on the benchmark indicate that the new algorithm is able to obtain solutions with competitive quality and it can be employed on instances with largescale. Work of this paper not only proposes a new efficient heuristic, but also provides a promising method to improve the efficiency of beam search.\n    ",
        "submission_date": "2017-03-06T00:00:00",
        "last_modified_date": "2017-03-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.01908",
        "title": "A proposal for ethically traceable artificial intelligence",
        "authors": [
            "Christopher A. Tucker"
        ],
        "abstract": "Although the problem of a critique of robotic behavior in near-unanimous agreement to human norms seems intractable, a starting point of such an ambition is a framework of the collection of knowledge a priori and experience a posteriori categorized as a set of synthetical judgments available to the intelligence, translated into computer code. If such a proposal were successful, an algorithm with ethically traceable behavior and cogent equivalence to human cognition is established. This paper will propose the application of Kant's critique of reason to current programming constructs of an autonomous intelligent system.\n    ",
        "submission_date": "2017-03-06T00:00:00",
        "last_modified_date": "2017-05-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.01924",
        "title": "Exchangeable choice functions",
        "authors": [
            "Arthur Van Camp",
            "Gert de Cooman"
        ],
        "abstract": "We investigate how to model exchangeability with choice functions. Exchangeability is a structural assessment on a sequence of uncertain variables. We show how such assessments are a special indifference assessment, and how that leads to a counterpart of de Finetti's Representation Theorem, both in a finite and a countable context.\n    ",
        "submission_date": "2017-03-06T00:00:00",
        "last_modified_date": "2017-03-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.01963",
        "title": "A new belief Markov chain model and its application in inventory prediction",
        "authors": [
            "Zichang He",
            "Wen Jiang"
        ],
        "abstract": "Markov chain model is widely applied in many fields, especially the field of prediction. The classical Discrete-time Markov chain(DTMC) is a widely used method for prediction. However, the classical DTMC model has some limitation when the system is complex with uncertain information or state space is not discrete. To address it, a new belief Markov chain model is proposed by combining Dempster-Shafer evidence theory with Markov chain. In our model, the uncertain data is allowed to be handle in the form of interval number and the basic probability assignment(BPA) is generated based on the distance between interval numbers. The new belief Markov chain model overcomes the shortcomings of classical Markov chain and has an efficient ability in dealing with uncertain information. Moreover, an example of inventory prediction and the comparison between our model and classical DTMC model can show the effectiveness and rationality of our proposed model.\n    ",
        "submission_date": "2017-03-06T00:00:00",
        "last_modified_date": "2017-03-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.01971",
        "title": "Evidential supplier selection based on interval data fusion",
        "authors": [
            "Zichang He",
            "Wen Jiang"
        ],
        "abstract": "Supplier selection is a typical multi-criteria decision making (MCDM) problem and lots of uncertain information exist inevitably. To address this issue, a new method was proposed based on interval data fusion. Our method follows the original way to generate classical basic probability assignment(BPA) determined by the distance among the evidences. However, the weights of criteria are kept as interval numbers to generate interval BPAs and do the fusion of interval BPAs. Finally, the order is ranked and the decision is made according to the obtained interval BPAs. In this paper, a numerical example of supplier selection is applied to verify the feasibility and validity of our method. The new method is presented aiming at solving multiple-criteria decision-making problems in which the weights of criteria or experts are described in fuzzy data like linguistic terms or interval data.\n    ",
        "submission_date": "2017-03-06T00:00:00",
        "last_modified_date": "2017-03-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.02192",
        "title": "A Gentle Introduction to Epistemic Planning: The DEL Approach",
        "authors": [
            "Thomas Bolander"
        ],
        "abstract": "Epistemic planning can be used for decision making in multi-agent situations with distributed knowledge and capabilities. Dynamic Epistemic Logic (DEL) has been shown to provide a very natural and expressive framework for epistemic planning. In this paper, we aim to give an accessible introduction to DEL-based epistemic planning. The paper starts with the most classical framework for planning, STRIPS, and then moves towards epistemic planning in a number of smaller steps, where each step is motivated by the need to be able to model more complex planning scenarios.\n    ",
        "submission_date": "2017-03-07T00:00:00",
        "last_modified_date": "2017-03-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.02196",
        "title": "Cooperative Epistemic Multi-Agent Planning for Implicit Coordination",
        "authors": [
            "Thorsten Engesser",
            "Thomas Bolander",
            "Robert Mattm\u00fcller",
            "Bernhard Nebel"
        ],
        "abstract": "Epistemic planning can be used for decision making in multi-agent situations with distributed knowledge and capabilities. Recently, Dynamic Epistemic Logic (DEL) has been shown to provide a very natural and expressive framework for epistemic planning. We extend the DEL-based epistemic planning framework to include perspective shifts, allowing us to define new notions of sequential and conditional planning with implicit coordination. With these, it is possible to solve planning tasks with joint goals in a decentralized manner without the agents having to negotiate about and commit to a joint policy at plan time. First we define the central planning notions and sketch the implementation of a planning system built on those notions. Afterwards we provide some case studies in order to evaluate the planner empirically and to show that the concept is useful for multi-agent systems in practice.\n    ",
        "submission_date": "2017-03-07T00:00:00",
        "last_modified_date": "2017-03-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.02239",
        "title": "Functions that Emerge through End-to-End Reinforcement Learning - The Direction for Artificial General Intelligence -",
        "authors": [
            "Katsunari Shibata"
        ],
        "abstract": "Recently, triggered by the impressive results in TV-games or game of Go by Google DeepMind, end-to-end reinforcement learning (RL) is collecting attentions. Although little is known, the author's group has propounded this framework for around 20 years and already has shown various functions that emerge in a neural network (NN) through RL. In this paper, they are introduced again at this timing.\n",
        "submission_date": "2017-03-07T00:00:00",
        "last_modified_date": "2017-05-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.02245",
        "title": "Design of the Artificial: lessons from the biological roots of general intelligence",
        "authors": [
            "Nima Dehghani"
        ],
        "abstract": "Our fascination with intelligent machines goes back to ancient times with the mythical automaton Talos, Aristotle's mode of mechanical thought (syllogism) and Heron of Alexandria's mechanical machines. However, the quest for Artificial General Intelligence (AGI) has been troubled with repeated failures. Recently, there has been a shift towards bio-inspired software and hardware, but their singular design focus makes them inefficient in achieving AGI. Which set of requirements have to be met in the design of AGI? What are the limits in the design of the artificial? A careful examination of computation in biological systems suggests that evolutionary tinkering of contextual processing of information enabled by a hierarchical architecture is key to building AGI.\n    ",
        "submission_date": "2017-03-07T00:00:00",
        "last_modified_date": "2023-06-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.02310",
        "title": "Deep Robust Kalman Filter",
        "authors": [
            "Shirli Di-Castro Shashua",
            "Shie Mannor"
        ],
        "abstract": "A Robust Markov Decision Process (RMDP) is a sequential decision making model that accounts for uncertainty in the parameters of dynamic systems. This uncertainty introduces difficulties in learning an optimal policy, especially for environments with large state spaces. We propose two algorithms, RTD-DQN and Deep-RoK, for solving large-scale RMDPs using nonlinear approximation schemes such as deep neural networks. The RTD-DQN algorithm incorporates the robust Bellman temporal difference error into a robust loss function, yielding robust policies for the agent. The Deep-RoK algorithm is a robust Bayesian method, based on the Extended Kalman Filter (EKF), that accounts for both the uncertainty in the weights of the approximated value function and the uncertainty in the transition probabilities, improving the robustness of the agent. We provide theoretical results for our approach and test the proposed algorithms on a continuous state domain.\n    ",
        "submission_date": "2017-03-07T00:00:00",
        "last_modified_date": "2017-03-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.02386",
        "title": "A quantum dynamic belief decision making model",
        "authors": [
            "Zichang He",
            "Wen Jiang"
        ],
        "abstract": "The sure thing principle and the law of total probability are basic laws in classic probability theory. A disjunction fallacy leads to the violation of these two classical probability laws. In this paper, a new quantum dynamic belief decision making model based on quantum dynamic modelling and Dempster-Shafer (D-S) evidence theory is proposed to address this issue and model the real human decision-making process. Some mathematical techniques are borrowed from quantum mathematics. Generally, belief and action are two parts in a decision making process. The uncertainty in belief part is represented by a superposition of certain states. The uncertainty in actions is represented as an extra uncertainty state. The interference effect is produced due to the entanglement between beliefs and actions. Basic probability assignment (BPA) of decisions is generated by quantum dynamic modelling. Then BPA of the extra uncertain state and an entanglement degree defined by an entropy function named Deng entropy are used to measure the interference effect. Compared the existing model, the number of free parameters is less in our model. Finally, a classical categorization decision-making experiment is illustrated to show the effectiveness of our model.\n    ",
        "submission_date": "2017-03-06T00:00:00",
        "last_modified_date": "2017-03-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.02645",
        "title": "Cost-Optimal Learning of Causal Graphs",
        "authors": [
            "Murat Kocaoglu",
            "Alexandros G. Dimakis",
            "Sriram Vishwanath"
        ],
        "abstract": "We consider the problem of learning a causal graph over a set of variables with interventions. We study the cost-optimal causal graph learning problem: For a given skeleton (undirected version of the causal graph), design the set of interventions with minimum total cost, that can uniquely identify any causal graph with the given skeleton. We show that this problem is solvable in polynomial time. Later, we consider the case when the number of interventions is limited. For this case, we provide polynomial time algorithms when the skeleton is a tree or a clique tree. For a general chordal skeleton, we develop an efficient greedy algorithm, which can be improved when the causal graph skeleton is an interval graph.\n    ",
        "submission_date": "2017-03-08T00:00:00",
        "last_modified_date": "2017-03-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.02810",
        "title": "An Integrated and Scalable Platform for Proactive Event-Driven Traffic Management",
        "authors": [
            "Alain Kibangou",
            "Alexander Artikis",
            "Evangelos Michelioudakis",
            "Georgios Paliouras",
            "Marius Schmitt",
            "John Lygeros",
            "Chris Baber",
            "Natan Morar",
            "Fabiana Fournier",
            "Inna Skarbovsky"
        ],
        "abstract": "Traffic on freeways can be managed by means of ramp meters from Road Traffic Control rooms. Human operators cannot efficiently manage a network of ramp meters. To support them, we present an intelligent platform for traffic management which includes a new ramp metering coordination scheme in the decision making module, an efficient dashboard for interacting with human operators, machine learning tools for learning event definitions and Complex Event Processing tools able to deal with uncertainties inherent to the traffic use case. Unlike the usual approach, the devised event-driven platform is able to predict a congestion up to 4 minutes before it really happens. Proactive decision making can then be established leading to significant improvement of traffic conditions.\n    ",
        "submission_date": "2017-03-08T00:00:00",
        "last_modified_date": "2017-03-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.02883",
        "title": "Memory Enriched Big Bang Big Crunch Optimization Algorithm for Data Clustering",
        "authors": [
            "Kayvan Bijari",
            "Hadi Zare",
            "Hadi Veisi",
            "Hossein Bobarshad"
        ],
        "abstract": "Cluster analysis plays an important role in decision making process for many knowledge-based systems. There exist a wide variety of different approaches for clustering applications including the heuristic techniques, probabilistic models, and traditional hierarchical algorithms. In this paper, a novel heuristic approach based on big bang-big crunch algorithm is proposed for clustering problems. The proposed method not only takes advantage of heuristic nature to alleviate typical clustering algorithms such as k-means, but it also benefits from the memory based scheme as compared to its similar heuristic techniques. Furthermore, the performance of the proposed algorithm is investigated based on several benchmark test functions as well as on the well-known datasets. The experimental results show the significant superiority of the proposed method over the similar algorithms.\n    ",
        "submission_date": "2017-03-08T00:00:00",
        "last_modified_date": "2017-03-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.02894",
        "title": "A quantum dynamic belief model to explain the interference effects of categorization on decision making",
        "authors": [
            "Zichang He",
            "Wen Jiang"
        ],
        "abstract": "Categorization is necessary for many decision making tasks. However, the categorization process may interfere the decision making result and the law of total probability can be violated in some situations. To predict the interference effect of categorization, some model based on quantum probability has been proposed. In this paper, a new quantum dynamic belief (QDB) model is proposed. Considering the precise decision may not be made during the process, the concept of uncertainty is introduced in our model to simulate real human thinking process. Then the interference effect categorization can be predicted by handling the uncertain information. The proposed model is applied to a categorization decision-making experiment to explain the interference effect of categorization. Compared with other models, our model is relatively more succinct and the result shows the correctness and effectiveness of our model.\n    ",
        "submission_date": "2017-03-06T00:00:00",
        "last_modified_date": "2017-03-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.02949",
        "title": "Learning Invariant Feature Spaces to Transfer Skills with Reinforcement Learning",
        "authors": [
            "Abhishek Gupta",
            "Coline Devin",
            "YuXuan Liu",
            "Pieter Abbeel",
            "Sergey Levine"
        ],
        "abstract": "People can learn a wide range of tasks from their own experience, but can also learn from observing other creatures. This can accelerate acquisition of new skills even when the observed agent differs substantially from the learning agent in terms of morphology. In this paper, we examine how reinforcement learning algorithms can transfer knowledge between morphologically different agents (e.g., different robots). We introduce a problem formulation where two agents are tasked with learning multiple skills by sharing information. Our method uses the skills that were learned by both agents to train invariant feature spaces that can then be used to transfer other skills from one agent to another. The process of learning these invariant feature spaces can be viewed as a kind of \"analogy making\", or implicit learning of partial correspondences between two distinct domains. We evaluate our transfer learning algorithm in two simulated robotic manipulation skills, and illustrate that we can transfer knowledge between simulated robotic arms with different numbers of links, as well as simulated arms with different actuation mechanisms, where one robot is torque-driven while the other is tendon-driven.\n    ",
        "submission_date": "2017-03-08T00:00:00",
        "last_modified_date": "2017-03-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.03193",
        "title": "Embedding Tarskian Semantics in Vector Spaces",
        "authors": [
            "Taisuke Sato"
        ],
        "abstract": "We propose a new linear algebraic approach to the computation of Tarskian semantics in logic. We embed a finite model M in first-order logic with N entities in N-dimensional Euclidean space R^N by mapping entities of M to N dimensional one-hot vectors and k-ary relations to order-k adjacency tensors (multi-way arrays). Second given a logical formula F in prenex normal form, we compile F into a set Sigma_F of algebraic formulas in multi-linear algebra with a nonlinear operation. In this compilation, existential quantifiers are compiled into a specific type of tensors, e.g., identity matrices in the case of quantifying two occurrences of a variable. It is shown that a systematic evaluation of Sigma_F in R^N gives the truth value, 1(true) or 0(false), of F in M. Based on this framework, we also propose an unprecedented way of computing the least models defined by Datalog programs in linear spaces via matrix equations and empirically show its effectiveness compared to state-of-the-art approaches.\n    ",
        "submission_date": "2017-03-09T00:00:00",
        "last_modified_date": "2017-03-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.03233",
        "title": "Modeling the Ellsberg Paradox by Argument Strength",
        "authors": [
            "Niki Pfeifer",
            "Hanna Pankka"
        ],
        "abstract": "We present a formal measure of argument strength, which combines the ideas that conclusions of strong arguments are (i) highly probable and (ii) their uncertainty is relatively precise. Likewise, arguments are weak when their conclusion probability is low or when it is highly imprecise. We show how the proposed measure provides a new model of the Ellsberg paradox. Moreover, we further substantiate the psychological plausibility of our approach by an experiment (N = 60). The data show that the proposed measure predicts human inferences in the original Ellsberg task and in corresponding argument strength tasks. Finally, we report qualitative data taken from structured interviews on folk psychological conceptions on what argument strength means.\n    ",
        "submission_date": "2017-03-09T00:00:00",
        "last_modified_date": "2017-03-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.03254",
        "title": "Abductive, Causal, and Counterfactual Conditionals Under Incomplete Probabilistic Knowledge",
        "authors": [
            "Niki Pfeifer",
            "Leena Tulkki"
        ],
        "abstract": "We study abductive, causal, and non-causal conditionals in indicative and counterfactual formulations using probabilistic truth table tasks under incomplete probabilistic knowledge (N = 80). We frame the task as a probability-logical inference problem. The most frequently observed response type across all conditions was a class of conditional event interpretations of conditionals; it was followed by conjunction interpretations. An interesting minority of participants neglected some of the relevant imprecision involved in the premises when inferring lower or upper probability bounds on the target conditional/counterfactual (\"halfway responses\"). We discuss the results in the light of coherence-based probability logic and the new paradigm psychology of reasoning.\n    ",
        "submission_date": "2017-03-09T00:00:00",
        "last_modified_date": "2017-03-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.03255",
        "title": "Counterfactuals, indicative conditionals, and negation under uncertainty: Are there cross-cultural differences?",
        "authors": [
            "Niki Pfeifer",
            "Hiroshi Yama"
        ],
        "abstract": "In this paper we study selected argument forms involving counterfactuals and indicative conditionals under uncertainty. We selected argument forms to explore whether people with an Eastern cultural background reason differently about conditionals compared to Westerners, because of the differences in the location of negations. In a 2x2 between-participants design, 63 Japanese university students were allocated to four groups, crossing indicative conditionals and counterfactuals, and each presented in two random task orders. The data show close agreement between the responses of Easterners and Westerners. The modal responses provide strong support for the hypothesis that conditional probability is the best predictor for counterfactuals and indicative conditionals. Finally, the grand majority of the responses are probabilistically coherent, which endorses the psychological plausibility of choosing coherence-based probability logic as a rationality framework for psychological reasoning research.\n    ",
        "submission_date": "2017-03-09T00:00:00",
        "last_modified_date": "2017-03-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.03429",
        "title": "What can you do with a rock? Affordance extraction via word embeddings",
        "authors": [
            "Nancy Fulda",
            "Daniel Ricks",
            "Ben Murdoch",
            "David Wingate"
        ],
        "abstract": "Autonomous agents must often detect affordances: the set of behaviors enabled by a situation. Affordance detection is particularly helpful in domains with large action spaces, allowing the agent to prune its search space by avoiding futile behaviors. This paper presents a method for affordance extraction via word embeddings trained on a Wikipedia corpus. The resulting word vectors are treated as a common knowledge database which can be queried using linear algebra. We apply this method to a reinforcement learning agent in a text-only environment and show that affordance-based action selection improves performance most of the time. Our method increases the computational complexity of each learning step but significantly reduces the total number of steps needed. In addition, the agent's action selections begin to resemble those a human would choose.\n    ",
        "submission_date": "2017-03-09T00:00:00",
        "last_modified_date": "2017-03-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.03453",
        "title": "Using Options and Covariance Testing for Long Horizon Off-Policy Policy Evaluation",
        "authors": [
            "Zhaohan Daniel Guo",
            "Philip S. Thomas",
            "Emma Brunskill"
        ],
        "abstract": "Evaluating a policy by deploying it in the real world can be risky and costly. Off-policy policy evaluation (OPE) algorithms use historical data collected from running a previous policy to evaluate a new policy, which provides a means for evaluating a policy without requiring it to ever be deployed. Importance sampling is a popular OPE method because it is robust to partial observability and works with continuous states and actions. However, the amount of historical data required by importance sampling can scale exponentially with the horizon of the problem: the number of sequential decisions that are made. We propose using policies over temporally extended actions, called options, and show that combining these policies with importance sampling can significantly improve performance for long-horizon problems. In addition, we can take advantage of special cases that arise due to options-based policies to further improve the performance of importance sampling. We further generalize these special cases to a general covariance testing rule that can be used to decide which weights to drop in an IS estimate, and derive a new IS algorithm called Incremental Importance Sampling that can provide significantly more accurate estimates for a broad class of domains.\n    ",
        "submission_date": "2017-03-09T00:00:00",
        "last_modified_date": "2017-12-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.03543",
        "title": "Communications that Emerge through Reinforcement Learning Using a (Recurrent) Neural Network",
        "authors": [
            "Katsunari Shibata"
        ],
        "abstract": "Communication is not only an action of choosing a signal, but needs to consider the context and sensor signals. It also needs to decide what information is communicated and how it is represented in or understood from signals. Therefore, communication should be realized comprehensively together with its purpose and other functions.\n",
        "submission_date": "2017-03-10T00:00:00",
        "last_modified_date": "2017-05-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.03693",
        "title": "On Quantum Decision Trees",
        "authors": [
            "Subhash Kak"
        ],
        "abstract": "Quantum decision systems are being increasingly considered for use in artificial intelligence applications. Classical and quantum nodes can be distinguished based on certain correlations in their states. This paper investigates some properties of the states obtained in a decision tree structure. How these correlations may be mapped to the decision tree is considered. Classical tree representations and approximations to quantum states are provided.\n    ",
        "submission_date": "2017-03-08T00:00:00",
        "last_modified_date": "2017-03-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.03868",
        "title": "Front-to-End Bidirectional Heuristic Search with Near-Optimal Node Expansions",
        "authors": [
            "Jingwei Chen",
            "Robert C. Holte",
            "Sandra Zilles",
            "Nathan R. Sturtevant"
        ],
        "abstract": "It is well-known that any admissible unidirectional heuristic search algorithm must expand all states whose $f$-value is smaller than the optimal solution cost when using a consistent heuristic. Such states are called \"surely expanded\" (s.e.). A recent study characterized s.e. pairs of states for bidirectional search with consistent heuristics: if a pair of states is s.e. then at least one of the two states must be expanded. This paper derives a lower bound, VC, on the minimum number of expansions required to cover all s.e. pairs, and present a new admissible front-to-end bidirectional heuristic search algorithm, Near-Optimal Bidirectional Search (NBS), that is guaranteed to do no more than 2VC expansions. We further prove that no admissible front-to-end algorithm has a worst case better than 2VC. Experimental results show that NBS competes with or outperforms existing bidirectional search algorithms, and often outperforms A* as well.\n    ",
        "submission_date": "2017-03-10T00:00:00",
        "last_modified_date": "2017-05-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.03916",
        "title": "Axioms in Model-based Planners",
        "authors": [
            "Shuwa Miura",
            "Alex Fukunaga"
        ],
        "abstract": "Axioms can be used to model derived predicates in domain- independent planning models. Formulating models which use axioms can sometimes result in problems with much smaller search spaces and shorter plans than the original model. Previous work on axiom-aware planners focused solely on state- space search planners. We propose axiom-aware planners based on answer set programming and integer programming. We evaluate them on PDDL domains with axioms and show that they can exploit additional expressivity of axioms.\n    ",
        "submission_date": "2017-03-11T00:00:00",
        "last_modified_date": "2017-06-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.03933",
        "title": "Micro-Objective Learning : Accelerating Deep Reinforcement Learning through the Discovery of Continuous Subgoals",
        "authors": [
            "Sungtae Lee",
            "Sang-Woo Lee",
            "Jinyoung Choi",
            "Dong-Hyun Kwak",
            "Byoung-Tak Zhang"
        ],
        "abstract": "Recently, reinforcement learning has been successfully applied to the logical game of Go, various Atari games, and even a 3D game, Labyrinth, though it continues to have problems in sparse reward settings. It is difficult to explore, but also difficult to exploit, a small number of successes when learning policy. To solve this issue, the subgoal and option framework have been proposed. However, discovering subgoals online is too expensive to be used to learn options in large state spaces. We propose Micro-objective learning (MOL) to solve this problem. The main idea is to estimate how important a state is while training and to give an additional reward proportional to its importance. We evaluated our algorithm in two Atari games: Montezuma's Revenge and Seaquest. With three experiments to each game, MOL significantly improved the baseline scores. Especially in Montezuma's Revenge, MOL achieved two times better results than the previous state-of-the-art model.\n    ",
        "submission_date": "2017-03-11T00:00:00",
        "last_modified_date": "2017-03-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.04115",
        "title": "BetaRun Soccer Simulation League Team: Variety, Complexity, and Learning",
        "authors": [
            "Olivia Michael",
            "Oliver Obst"
        ],
        "abstract": "RoboCup offers a set of benchmark problems for Artificial Intelligence in form of official world championships since 1997. The most tactical advanced and richest in terms of behavioural complexity of these is the 2D Soccer Simulation League, a simulated robotic soccer competition. BetaRun is a new attempt combining both machine learning and manual programming approaches, with the ultimate goal to arrive at a team that is trained entirely from observing and playing games, and a new development based on agent2D.\n    ",
        "submission_date": "2017-03-12T00:00:00",
        "last_modified_date": "2017-08-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.04159",
        "title": "Any-Angle Pathfinding for Multiple Agents Based on SIPP Algorithm",
        "authors": [
            "Konstantin Yakovlev",
            "Anton Andreychuk"
        ],
        "abstract": "The problem of finding conflict-free trajectories for multiple agents of identical circular shape, operating in shared 2D workspace, is addressed in the paper and decoupled, e.g., prioritized, approach is used to solve this problem. Agents' workspace is tessellated into the square grid on which any-angle moves are allowed, e.g. each agent can move into an arbitrary direction as long as this move follows the straight line segment whose endpoints are tied to the distinct grid elements. A novel any-angle planner based on Safe Interval Path Planning (SIPP) algorithm is proposed to find trajectories for an agent moving amidst dynamic obstacles (other agents) on a grid. This algorithm is then used as part of a prioritized multi-agent planner AA-SIPP(m). On the theoretical, side we show that AA-SIPP(m) is complete under well-defined conditions. On the experimental side, in simulation tests with up to 200 agents involved, we show that our planner finds much better solutions in terms of cost (up to 20%) compared to the planners relying on cardinal moves only.\n    ",
        "submission_date": "2017-03-12T00:00:00",
        "last_modified_date": "2017-03-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.04232",
        "title": "Numerical Integration and Dynamic Discretization in Heuristic Search Planning over Hybrid Domains",
        "authors": [
            "Miquel Ramirez",
            "Enrico Scala",
            "Patrik Haslum",
            "Sylvie Thiebaux"
        ],
        "abstract": "In this paper we look into the problem of planning over hybrid domains, where change can be both discrete and instantaneous, or continuous over time. In addition, it is required that each state on the trajectory induced by the execution of plans complies with a given set of global constraints. We approach the computation of plans for such domains as the problem of searching over a deterministic state model. In this model, some of the successor states are obtained by solving numerically the so-called initial value problem over a set of ordinary differential equations (ODE) given by the current plan prefix. These equations hold over time intervals whose duration is determined dynamically, according to whether zero crossing events take place for a set of invariant conditions. The resulting planner, FS+, incorporates these features together with effective heuristic guidance. FS+ does not impose any of the syntactic restrictions on process effects often found on the existing literature on Hybrid Planning. A key concept of our approach is that a clear separation is struck between planning and simulation time steps. The former is the time allowed to observe the evolution of a given dynamical system before committing to a future course of action, whilst the later is part of the model of the environment. FS+ is shown to be a robust planner over a diverse set of hybrid domains, taken from the existing literature on hybrid planning and systems.\n    ",
        "submission_date": "2017-03-13T00:00:00",
        "last_modified_date": "2017-03-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.04361",
        "title": "Toward a Formal Model of Cognitive Synergy",
        "authors": [
            "Ben Goertzel"
        ],
        "abstract": "\"Cognitive synergy\" refers to a dynamic in which multiple cognitive processes, cooperating to control the same cognitive system, assist each other in overcoming bottlenecks encountered during their internal processing. Cognitive synergy has been posited as a key feature of real-world general intelligence, and has been used explicitly in the design of the OpenCog cognitive architecture. Here category theory and related concepts are used to give a formalization of the cognitive synergy concept.\n",
        "submission_date": "2017-03-13T00:00:00",
        "last_modified_date": "2017-03-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.04368",
        "title": "Symbol Grounding via Chaining of Morphisms",
        "authors": [
            "Ruiting Lian",
            "Ben Goertzel",
            "Linas Vepstas",
            "David Hanson",
            "Changle Zhou"
        ],
        "abstract": "A new model of symbol grounding is presented, in which the structures of natural language, logical semantics, perception and action are represented categorically, and symbol grounding is modeled via the composition of morphisms between the relevant categories. This model gives conceptual insight into the fundamentally systematic nature of symbol grounding, and also connects naturally to practical real-world AI systems in current research and commercial use. Specifically, it is argued that the structure of linguistic syntax can be modeled as a certain asymmetric monoidal category, as e.g. implicit in the link grammar formalism; the structure of spatiotemporal relationships and action plans can be modeled similarly using \"image grammars\" and \"action grammars\"; and common-sense logical semantic structure can be modeled using dependently-typed lambda calculus with uncertain truth values. Given these formalisms, the grounding of linguistic descriptions in spatiotemporal perceptions and coordinated actions consists of following morphisms from language to logic through to spacetime and body (for comprehension), and vice versa (for generation). The mapping is indicated between the spatial relationships in the Region Connection Calculus and Allen Interval Algebra and corresponding entries in the link grammar syntax parsing dictionary. Further, the abstractions introduced here are shown to naturally model the structures and systems currently being deployed in the context of using the OpenCog cognitive architecture to control Hanson Robotics humanoid robots.\n    ",
        "submission_date": "2017-03-13T00:00:00",
        "last_modified_date": "2017-03-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.04382",
        "title": "Cost-Based Intuitionist Probabilities on Spaces of Graphs, Hypergraphs and Theorems",
        "authors": [
            "Ben Goertzel"
        ],
        "abstract": "A novel partial order is defined on the space of digraphs or hypergraphs, based on assessing the cost of producing a graph via a sequence of elementary transformations. Leveraging work by Knuth and Skilling on the foundations of inference, and the structure of Heyting algebras on graph space, this partial order is used to construct an intuitionistic probability measure that applies to either digraphs or hypergraphs. As logical inference steps can be represented as transformations on hypergraphs representing logical statements, this also yields an intuitionistic probability measure on spaces of theorems. The central result is also extended to yield intuitionistic probabilities based on more general weighted rule systems defined over bicartesian closed categories.\n    ",
        "submission_date": "2017-03-13T00:00:00",
        "last_modified_date": "2017-03-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.04587",
        "title": "Minimizing Maximum Regret in Commitment Constrained Sequential Decision Making",
        "authors": [
            "Qi Zhang",
            "Satinder Singh",
            "Edmund Durfee"
        ],
        "abstract": "In cooperative multiagent planning, it can often be beneficial for an agent to make commitments about aspects of its behavior to others, allowing them in turn to plan their own behaviors without taking the agent's detailed behavior into account. Extending previous work in the Bayesian setting, we consider instead a worst-case setting in which the agent has a set of possible environments (MDPs) it could be in, and develop a commitment semantics that allows for probabilistic guarantees on the agent's behavior in any of the environments it could end up facing. Crucially, an agent receives observations (of reward and state transitions) that allow it to potentially eliminate possible environments and thus obtain higher utility by adapting its policy to the history of observations. We develop algorithms and provide theory and some preliminary empirical results showing that they ensure an agent meets its commitments with history-dependent policies while minimizing maximum regret over the possible environments.\n    ",
        "submission_date": "2017-03-14T00:00:00",
        "last_modified_date": "2017-03-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.04741",
        "title": "Towards Moral Autonomous Systems",
        "authors": [
            "Vicky Charisi",
            "Louise Dennis",
            "Michael Fisher",
            "Robert Lieck",
            "Andreas Matthias",
            "Marija Slavkovik",
            "Janina Sombetzki",
            "Alan F. T. Winfield",
            "Roman Yampolskiy"
        ],
        "abstract": "Both the ethics of autonomous systems and the problems of their technical implementation have by now been studied in some detail. Less attention has been given to the areas in which these two separate concerns meet. This paper, written by both philosophers and engineers of autonomous systems, addresses a number of issues in machine ethics that are located at precisely the intersection between ethics and engineering. We first discuss the main challenges which, in our view, machine ethics posses to moral philosophy. We them consider different approaches towards the conceptual design of autonomous systems and their implications on the ethics implementation in such systems. Then we examine problematic areas regarding the specification and verification of ethical behavior in autonomous systems, particularly with a view towards the requirements of future legislation. We discuss transparency and accountability issues that will be crucial for any future wide deployment of autonomous systems in society. Finally we consider the, often overlooked, possibility of intentional misuse of AI systems and the possible dangers arising out of deliberately unethical design, implementation, and use of autonomous robots.\n    ",
        "submission_date": "2017-03-14T00:00:00",
        "last_modified_date": "2017-10-31T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.04862",
        "title": "Exploring the Combination Rules of D Numbers From a Perspective of Conflict Redistribution",
        "authors": [
            "Xinyang Deng",
            "Wen Jiang"
        ],
        "abstract": "Dempster-Shafer theory of evidence is widely applied to uncertainty modelling and knowledge reasoning because of its advantages in dealing with uncertain information. But some conditions or requirements, such as exclusiveness hypothesis and completeness constraint, limit the development and application of that theory to a large extend. To overcome the shortcomings and enhance its capability of representing the uncertainty, a novel model, called D numbers, has been proposed recently. However, many key issues, for example how to implement the combination of D numbers, remain unsolved. In the paper, we have explored the combination of D Numbers from a perspective of conflict redistribution, and proposed two combination rules being suitable for different situations for the fusion of two D numbers. The proposed combination rules can reduce to the classical Dempster's rule in Dempster-Shafer theory under a certain conditions. Numerical examples and discussion about the proposed rules are also given in the paper.\n    ",
        "submission_date": "2017-03-15T00:00:00",
        "last_modified_date": "2017-03-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.04908",
        "title": "Emergence of Grounded Compositional Language in Multi-Agent Populations",
        "authors": [
            "Igor Mordatch",
            "Pieter Abbeel"
        ],
        "abstract": "By capturing statistical patterns in large corpora, machine learning has enabled significant advances in natural language processing, including in machine translation, question answering, and sentiment analysis. However, for agents to intelligently interact with humans, simply capturing the statistical patterns is insufficient. In this paper we investigate if, and how, grounded compositional language can emerge as a means to achieve goals in multi-agent populations. Towards this end, we propose a multi-agent learning environment and learning methods that bring about emergence of a basic compositional language. This language is represented as streams of abstract discrete symbols uttered by agents over time, but nonetheless has a coherent structure that possesses a defined vocabulary and syntax. We also observe emergence of non-verbal communication such as pointing and guiding when language communication is unavailable.\n    ",
        "submission_date": "2017-03-15T00:00:00",
        "last_modified_date": "2018-07-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.04912",
        "title": "Syntax-Preserving Belief Change Operators for Logic Programs",
        "authors": [
            "Sebastian Binnewies",
            "Zhiqiang Zhuang",
            "Kewen Wang",
            "Bela Stantic"
        ],
        "abstract": "Recent methods have adapted the well-established AGM and belief base frameworks for belief change to cover belief revision in logic programs. In this study here, we present two new sets of belief change operators for logic programs. They focus on preserving the explicit relationships expressed in the rules of a program, a feature that is missing in purely semantic approaches that consider programs only in their entirety. In particular, operators of the latter class fail to satisfy preservation and support, two important properties for belief change in logic programs required to ensure intuitive results.\n",
        "submission_date": "2017-03-15T00:00:00",
        "last_modified_date": "2017-03-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.04990",
        "title": "Neural Programming by Example",
        "authors": [
            "Chengxun Shu",
            "Hongyu Zhang"
        ],
        "abstract": "Programming by Example (PBE) targets at automatically inferring a computer program for accomplishing a certain task from sample input and output. In this paper, we propose a deep neural networks (DNN) based PBE model called Neural Programming by Example (NPBE), which can learn from input-output strings and induce programs that solve the string manipulation problems. Our NPBE model has four neural network based components: a string encoder, an input-output analyzer, a program generator, and a symbol selector. We demonstrate the effectiveness of NPBE by training it end-to-end to solve some common string manipulation problems in spreadsheet systems. The results show that our model can induce string manipulation programs effectively. Our work is one step towards teaching DNN to generate computer programs.\n    ",
        "submission_date": "2017-03-15T00:00:00",
        "last_modified_date": "2017-03-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.05201",
        "title": "Fuzzy Rankings: Properties and Applications",
        "authors": [
            "Ji\u0159\u00ed Mazurek"
        ],
        "abstract": "In practice, a ranking of objects with respect to given set of criteria is of considerable importance. However, due to lack of knowledge, information of time pressure, decision makers might not be able to provide a (crisp) ranking of objects from the top to the bottom. Instead, some objects might be ranked equally, or better than other objects only to some degree. In such cases, a generalization of crisp rankings to fuzzy rankings can be more useful. The aim of the article is to introduce the notion of a fuzzy ranking and to discuss its several properties, namely orderings, similarity and indecisiveness. The proposed approach can be used both for group decision making or multiple criteria decision making when uncertainty is involved.\n    ",
        "submission_date": "2017-03-15T00:00:00",
        "last_modified_date": "2017-03-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.05204",
        "title": "On Inconsistency Indices and Inconsistency Axioms in Pairwise Comparisons",
        "authors": [
            "Jiri Mazurek"
        ],
        "abstract": "Pairwise comparisons are an important tool of modern (multiple criteria) decision making. Since human judgments are often inconsistent, many studies focused on the ways how to express and measure this inconsistency, and several inconsistency indices were proposed as an alternative to Saaty inconsistency index and inconsistency ratio for reciprocal pairwise comparisons matrices. This paper aims to: firstly, introduce a new measure of inconsistency of pairwise comparisons and to prove its basic properties; secondly, to postulate an additional axiom, an upper boundary axiom, to an existing set of axioms; and the last, but not least, the paper provides proofs of satisfaction of this additional axiom by selected inconsistency indices as well as it provides their numerical comparison.\n    ",
        "submission_date": "2017-03-15T00:00:00",
        "last_modified_date": "2017-04-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.05376",
        "title": "Finite Sample Analysis of Two-Timescale Stochastic Approximation with Applications to Reinforcement Learning",
        "authors": [
            "Gal Dalal",
            "Balazs Szorenyi",
            "Gugan Thoppe",
            "Shie Mannor"
        ],
        "abstract": "Two-timescale Stochastic Approximation (SA) algorithms are widely used in Reinforcement Learning (RL). Their iterates have two parts that are updated using distinct stepsizes. In this work, we develop a novel recipe for their finite sample analysis. Using this, we provide a concentration bound, which is the first such result for a two-timescale SA. The type of bound we obtain is known as `lock-in probability'. We also introduce a new projection scheme, in which the time between successive projections increases exponentially. This scheme allows one to elegantly transform a lock-in probability into a convergence rate result for projected two-timescale SA. From this latter result, we then extract key insights on stepsize selection. As an application, we finally obtain convergence rates for the projected two-timescale RL algorithms GTD(0), GTD2, and TDC.\n    ",
        "submission_date": "2017-03-15T00:00:00",
        "last_modified_date": "2018-06-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.05452",
        "title": "Efficient Online Learning for Optimizing Value of Information: Theory and Application to Interactive Troubleshooting",
        "authors": [
            "Yuxin Chen",
            "Jean-Michel Renders",
            "Morteza Haghir Chehreghani",
            "Andreas Krause"
        ],
        "abstract": "We consider the optimal value of information (VoI) problem, where the goal is to sequentially select a set of tests with a minimal cost, so that one can efficiently make the best decision based on the observed outcomes. Existing algorithms are either heuristics with no guarantees, or scale poorly (with exponential run time in terms of the number of available tests). Moreover, these methods assume a known distribution over the test outcomes, which is often not the case in practice. We propose an efficient sampling-based online learning framework to address the above issues. First, assuming the distribution over hypotheses is known, we propose a dynamic hypothesis enumeration strategy, which allows efficient information gathering with strong theoretical guarantees. We show that with sufficient amount of samples, one can identify a near-optimal decision with high probability. Second, when the parameters of the hypotheses distribution are unknown, we propose an algorithm which learns the parameters progressively via posterior sampling in an online fashion. We further establish a rigorous bound on the expected regret. We demonstrate the effectiveness of our approach on a real-world interactive troubleshooting application and show that one can efficiently make high-quality decisions with low cost.\n    ",
        "submission_date": "2017-03-16T00:00:00",
        "last_modified_date": "2017-07-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.05614",
        "title": "ParaGraphE: A Library for Parallel Knowledge Graph Embedding",
        "authors": [
            "Xiao-Fan Niu",
            "Wu-Jun Li"
        ],
        "abstract": "Knowledge graph embedding aims at translating the knowledge graph into numerical representations by transforming the entities and relations into continuous low-dimensional vectors. Recently, many methods [1, 5, 3, 2, 6] have been proposed to deal with this problem, but existing single-thread implementations of them are time-consuming for large-scale knowledge graphs. Here, we design a unified parallel framework to parallelize these methods, which achieves a significant time reduction without influencing the accuracy. We name our framework as ParaGraphE, which provides a library for parallel knowledge graph embedding. The source code can be downloaded from ",
        "submission_date": "2017-03-16T00:00:00",
        "last_modified_date": "2017-04-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.06042",
        "title": "A Visual Web Tool to Perform What-If Analysis of Optimization Approaches",
        "authors": [
            "Sascha Van Cauwelaert",
            "Michele Lombardi",
            "Pierre Schaus"
        ],
        "abstract": "In Operation Research, practical evaluation is essential to validate the efficacy of optimization approaches. This paper promotes the usage of performance profiles as a standard practice to visualize and analyze experimental results. It introduces a Web tool to construct and export performance profiles as SVG or HTML files. In addition, the application relies on a methodology to estimate the benefit of hypothetical solver improvements. Therefore, the tool allows one to employ what-if analysis to screen possible research directions, and identify those having the best potential. The approach is showcased on two Operation Research technologies: Constraint Programming and Mixed Integer Linear Programming.\n    ",
        "submission_date": "2017-03-16T00:00:00",
        "last_modified_date": "2017-03-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.06045",
        "title": "Approximation Complexity of Maximum A Posteriori Inference in Sum-Product Networks",
        "authors": [
            "Diarmaid Conaty",
            "Denis D. Mau\u00e1",
            "Cassio P. de Campos"
        ],
        "abstract": "We discuss the computational complexity of approximating maximum a posteriori inference in sum-product networks. We first show NP-hardness in trees of height two by a reduction from maximum independent set; this implies non-approximability within a sublinear factor. We show that this is a tight bound, as we can find an approximation within a linear factor in networks of height two. We then show that, in trees of height three, it is NP-hard to approximate the problem within a factor $2^{f(n)}$ for any sublinear function $f$ of the size of the input $n$. Again, this bound is tight, as we prove that the usual max-product algorithm finds (in any network) approximations within factor $2^{c \\cdot n}$ for some constant $c < 1$. Last, we present a simple algorithm, and show that it provably produces solutions at least as good as, and potentially much better than, the max-product algorithm. We empirically analyze the proposed algorithm against max-product using synthetic and realistic networks.\n    ",
        "submission_date": "2017-03-17T00:00:00",
        "last_modified_date": "2017-09-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.06207",
        "title": "Cooperating with Machines",
        "authors": [
            "Jacob W. Crandall",
            "Mayada Oudah",
            "Tennom",
            "Fatimah Ishowo-Oloko",
            "Sherief Abdallah",
            "Jean-Fran\u00e7ois Bonnefon",
            "Manuel Cebrian",
            "Azim Shariff",
            "Michael A. Goodrich",
            "Iyad Rahwan"
        ],
        "abstract": "Since Alan Turing envisioned Artificial Intelligence (AI) [1], a major driving force behind technical progress has been competition with human cognition. Historical milestones have been frequently associated with computers matching or outperforming humans in difficult cognitive tasks (e.g. face recognition [2], personality classification [3], driving cars [4], or playing video games [5]), or defeating humans in strategic zero-sum encounters (e.g. Chess [6], Checkers [7], Jeopardy! [8], Poker [9], or Go [10]). In contrast, less attention has been given to developing autonomous machines that establish mutually cooperative relationships with people who may not share the machine's preferences. A main challenge has been that human cooperation does not require sheer computational power, but rather relies on intuition [11], cultural norms [12], emotions and signals [13, 14, 15, 16], and pre-evolved dispositions toward cooperation [17], common-sense mechanisms that are difficult to encode in machines for arbitrary contexts. Here, we combine a state-of-the-art machine-learning algorithm with novel mechanisms for generating and acting on signals to produce a new learning algorithm that cooperates with people and other machines at levels that rival human cooperation in a variety of two-player repeated stochastic games. This is the first general-purpose algorithm that is capable, given a description of a previously unseen game environment, of learning to cooperate with people within short timescales in scenarios previously unanticipated by algorithm designers. This is achieved without complex opponent modeling or higher-order theories of mind, thus showing that flexible, fast, and general human-machine cooperation is computationally achievable using a non-trivial, but ultimately simple, set of algorithmic mechanisms.\n    ",
        "submission_date": "2017-03-17T00:00:00",
        "last_modified_date": "2018-02-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.06275",
        "title": "Evolving Game Skill-Depth using General Video Game AI Agents",
        "authors": [
            "Jialin Liu",
            "Julian Togelius",
            "Diego Perez-Liebana",
            "Simon M. Lucas"
        ],
        "abstract": "Most games have, or can be generalised to have, a number of parameters that may be varied in order to provide instances of games that lead to very different player experiences. The space of possible parameter settings can be seen as a search space, and we can therefore use a Random Mutation Hill Climbing algorithm or other search methods to find the parameter settings that induce the best games. One of the hardest parts of this approach is defining a suitable fitness function. In this paper we explore the possibility of using one of a growing set of General Video Game AI agents to perform automatic play-testing. This enables a very general approach to game evaluation based on estimating the skill-depth of a game. Agent-based play-testing is computationally expensive, so we compare two simple but efficient optimisation algorithms: the Random Mutation Hill-Climber and the Multi-Armed Bandit Random Mutation Hill-Climber. For the test game we use a space-battle game in order to provide a suitable balance between simulation speed and potential skill-depth. Results show that both algorithms are able to rapidly evolve game versions with significant skill-depth, but that choosing a suitable resampling number is essential in order to combat the effects of noise.\n    ",
        "submission_date": "2017-03-18T00:00:00",
        "last_modified_date": "2017-03-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.06321",
        "title": "Solving the Goddard problem by an influence diagram",
        "authors": [
            "Ji\u0159\u00ed Vomlel",
            "V\u00e1clav Kratochv\u00edl"
        ],
        "abstract": "Influence diagrams are a decision-theoretic extension of probabilistic graphical models. In this paper we show how they can be used to solve the Goddard problem. We present results of numerical experiments with this problem and compare the solutions provided by influence diagrams with the optimal solution.\n    ",
        "submission_date": "2017-03-18T00:00:00",
        "last_modified_date": "2017-03-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.06354",
        "title": "Goal Conflict in Designing an Autonomous Artificial System",
        "authors": [
            "Mark Muraven"
        ],
        "abstract": "Research on human self-regulation has shown that people hold many goals simultaneously and have complex self-regulation mechanisms to deal with this goal conflict. Artificial autonomous systems may also need to find ways to cope with conflicting goals. Indeed, the intricate interplay among different goals may be critical to the design as well as long-term safety and stability of artificial autonomous systems. I discuss some of the critical features of the human self-regulation system and how it might be applied to an artificial system. Furthermore, the implications of goal conflict for the reliability and stability of artificial autonomous systems and ensuring their alignment with human goals and ethics is examined.\n    ",
        "submission_date": "2017-03-18T00:00:00",
        "last_modified_date": "2017-03-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.06471",
        "title": "Multi-Timescale, Gradient Descent, Temporal Difference Learning with Linear Options",
        "authors": [
            "Peeyush Kumar",
            "Doina Precup"
        ],
        "abstract": "Deliberating on large or continuous state spaces have been long standing challenges in reinforcement learning. Temporal Abstraction have somewhat made this possible, but efficiently planing using temporal abstraction still remains an issue. Moreover using spatial abstractions to learn policies for various situations at once while using temporal abstraction models is an open problem. We propose here an efficient algorithm which is convergent under linear function approximation while planning using temporally abstract actions. We show how this algorithm can be used along with randomly generated option models over multiple time scales to plan agents which need to act real time. Using these randomly generated option models over multiple time scales are shown to reduce number of decision epochs required to solve the given task, hence effectively reducing the time needed for deliberation.\n    ",
        "submission_date": "2017-03-19T00:00:00",
        "last_modified_date": "2017-03-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.06565",
        "title": "Evidence Updating for Stream-Processing in Big-Data: Robust Conditioning in Soft and Hard Fusion Environments",
        "authors": [
            "Thanuka Wickramarathne"
        ],
        "abstract": "Robust belief revision methods are crucial in streaming data situations for updating existing knowledge or beliefs with new incoming evidence. Bayes conditioning is the primary mechanism in use for belief revision in data fusion systems that use probabilistic inference. However, traditional conditioning methods face several challenges due to inherent data/source imperfections in big-data environments that harness soft (i.e., human or human-based) sources in addition to hard (i.e., physics-based) sensors. The objective of this paper is to investigate the most natural extension of Bayes conditioning that is suitable for evidence updating in the presence of such uncertainties. By viewing the evidence updating process as a thought experiment, an elegant strategy is derived for robust evidence updating in the presence of extreme uncertainties that are characteristic of big-data environments. In particular, utilizing the Fagin-Halpern conditional notions, a natural extension to Bayes conditioning is derived for evidence that takes the form of a general belief function. The presented work differs fundamentally from the Conditional Update Equation (CUE) and authors own extensions of it. An overview of this development is provided via illustrative examples. Furthermore, insights into parameter selection under various fusion contexts are also provided.\n    ",
        "submission_date": "2017-03-20T00:00:00",
        "last_modified_date": "2017-06-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.06597",
        "title": "Artificial Intelligence and Economic Theories",
        "authors": [
            "Tshilidzi Marwala",
            "Evan Hurwitz"
        ],
        "abstract": "The advent of artificial intelligence has changed many disciplines such as engineering, social science and economics. Artificial intelligence is a computational technique which is inspired by natural intelligence such as the swarming of birds, the working of the brain and the pathfinding of the ants. These techniques have impact on economic theories. This book studies the impact of artificial intelligence on economic theories, a subject that has not been extensively studied. The theories that are considered are: demand and supply, asymmetrical information, pricing, rational choice, rational expectation, game theory, efficient market hypotheses, mechanism design, prospect, bounded rationality, portfolio theory, rational counterfactual and causality. The benefit of this book is that it evaluates existing theories of economics and update them based on the developments in artificial intelligence field.\n    ",
        "submission_date": "2017-03-20T00:00:00",
        "last_modified_date": "2017-03-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.06642",
        "title": "Towards a Quantum World Wide Web",
        "authors": [
            "Diederik Aerts",
            "Jonito Aerts Arguelles",
            "Lester Beltran",
            "Lyneth Beltran",
            "Isaac Distrito",
            "Massimiliano Sassoli de Bianchi",
            "Sandro Sozzo",
            "Tomas Veloz"
        ],
        "abstract": "We elaborate a quantum model for the meaning associated with corpora of written documents, like the pages forming the World Wide Web. To that end, we are guided by how physicists constructed quantum theory for microscopic entities, which unlike classical objects cannot be fully represented in our spatial theater. We suggest that a similar construction needs to be carried out by linguists and computational scientists, to capture the full meaning carried by collections of documental entities. More precisely, we show how to associate a quantum-like 'entity of meaning' to a 'language entity formed by printed documents', considering the latter as the collection of traces that are left by the former, in specific results of search actions that we describe as measurements. In other words, we offer a perspective where a collection of documents, like the Web, is described as the space of manifestation of a more complex entity - the QWeb - which is the object of our modeling, drawing its inspiration from previous studies on operational-realistic approaches to quantum physics and quantum modeling of human cognition and decision-making. We emphasize that a consistent QWeb model needs to account for the observed correlations between words appearing in printed documents, e.g., co-occurrences, as the latter would depend on the 'meaning connections' existing between the concepts that are associated with these words. In that respect, we show that both 'context and interference (quantum) effects' are required to explain the probabilities calculated by counting the relative number of documents containing certain words and co-ocurrrences of words.\n    ",
        "submission_date": "2017-03-20T00:00:00",
        "last_modified_date": "2018-01-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.06692",
        "title": "QMDP-Net: Deep Learning for Planning under Partial Observability",
        "authors": [
            "Peter Karkus",
            "David Hsu",
            "Wee Sun Lee"
        ],
        "abstract": "This paper introduces the QMDP-net, a neural network architecture for planning under partial observability. The QMDP-net combines the strengths of model-free learning and model-based planning. It is a recurrent policy network, but it represents a policy for a parameterized set of tasks by connecting a model with a planning algorithm that solves the model, thus embedding the solution structure of planning in a network learning architecture. The QMDP-net is fully differentiable and allows for end-to-end training. We train a QMDP-net on different tasks so that it can generalize to new ones in the parameterized task set and \"transfer\" to other similar tasks beyond the set. In preliminary experiments, QMDP-net showed strong performance on several robotic tasks in simulation. Interestingly, while QMDP-net encodes the QMDP algorithm, it sometimes outperforms the QMDP algorithm in the experiments, as a result of end-to-end learning.\n    ",
        "submission_date": "2017-03-20T00:00:00",
        "last_modified_date": "2017-11-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.06815",
        "title": "Foundations for a Probabilistic Event Calculus",
        "authors": [
            "Fabio Aurelio D'Asaro",
            "Antonis Bikakis",
            "Luke Dickens",
            "Rob Miller"
        ],
        "abstract": "We present PEC, an Event Calculus (EC) style action language for reasoning about probabilistic causal and narrative information. It has an action language style syntax similar to that of the EC variant Modular-E. Its semantics is given in terms of possible worlds which constitute possible evolutions of the domain, and builds on that of EFEC, an epistemic extension of EC. We also describe an ASP implementation of PEC and show the sense in which this is sound and complete.\n    ",
        "submission_date": "2017-03-20T00:00:00",
        "last_modified_date": "2017-06-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.06939",
        "title": "Distributed Constraint Problems for Utilitarian Agents with Privacy Concerns, Recast as POMDPs",
        "authors": [
            "Julien Savaux",
            "Julien Vion",
            "Sylvain Piechowiak",
            "Ren\u00e9 Mandiau",
            "Toshihiro Matsui",
            "Katsutoshi Hirayama",
            "Makoto Yokoo",
            "Shakre Elmane",
            "Marius Silaghi"
        ],
        "abstract": "Privacy has traditionally been a major motivation for distributed problem solving. Distributed Constraint Satisfaction Problem (DisCSP) as well as Distributed Constraint Optimization Problem (DCOP) are fundamental models used to solve various families of distributed problems. Even though several approaches have been proposed to quantify and preserve privacy in such problems, none of them is exempt from limitations. Here we approach the problem by assuming that computation is performed among utilitarian agents. We introduce a utilitarian approach where the utility of each state is estimated as the difference between the reward for reaching an agreement on assignments of shared variables and the cost of privacy loss. We investigate extensions to solvers where agents integrate the utility function to guide their search and decide which action to perform, defining thereby their policy. We show that these extended solvers succeed in significantly reducing privacy loss without significant degradation of the solution quality.\n    ",
        "submission_date": "2017-03-20T00:00:00",
        "last_modified_date": "2017-03-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.07075",
        "title": "Pseudorehearsal in value function approximation",
        "authors": [
            "Vladimir Marochko",
            "Leonard Johard",
            "Manuel Mazzara"
        ],
        "abstract": "Catastrophic forgetting is of special importance in reinforcement learning, as the data distribution is generally non-stationary over time. We study and compare several pseudorehearsal approaches for Q-learning with function approximation in a pole balancing task. We have found that pseudorehearsal seems to assist learning even in such very simple problems, given proper initialization of the rehearsal parameters.\n    ",
        "submission_date": "2017-03-21T00:00:00",
        "last_modified_date": "2017-03-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.07326",
        "title": "One-Shot Imitation Learning",
        "authors": [
            "Yan Duan",
            "Marcin Andrychowicz",
            "Bradly C. Stadie",
            "Jonathan Ho",
            "Jonas Schneider",
            "Ilya Sutskever",
            "Pieter Abbeel",
            "Wojciech Zaremba"
        ],
        "abstract": "Imitation learning has been commonly applied to solve different tasks in isolation. This usually requires either careful feature engineering, or a significant number of samples. This is far from what we desire: ideally, robots should be able to learn from very few demonstrations of any given task, and instantly generalize to new situations of the same task, without requiring task-specific engineering. In this paper, we propose a meta-learning framework for achieving such capability, which we call one-shot imitation learning.\n",
        "submission_date": "2017-03-21T00:00:00",
        "last_modified_date": "2017-12-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.07469",
        "title": "RobustFill: Neural Program Learning under Noisy I/O",
        "authors": [
            "Jacob Devlin",
            "Jonathan Uesato",
            "Surya Bhupatiraju",
            "Rishabh Singh",
            "Abdel-rahman Mohamed",
            "Pushmeet Kohli"
        ],
        "abstract": "The problem of automatically generating a computer program from some specification has been studied since the early days of AI. Recently, two competing approaches for automatic program learning have received significant attention: (1) neural program synthesis, where a neural network is conditioned on input/output (I/O) examples and learns to generate a program, and (2) neural program induction, where a neural network generates new outputs directly using a latent program representation.\n",
        "submission_date": "2017-03-21T00:00:00",
        "last_modified_date": "2017-03-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.07726",
        "title": "\\$1 Today or \\$2 Tomorrow? The Answer is in Your Facebook Likes",
        "authors": [
            "Tao Ding",
            "Warren K. Bickel",
            "Shimei Pan"
        ],
        "abstract": "In economics and psychology, delay discounting is often used to characterize how individuals choose between a smaller immediate reward and a larger delayed reward. People with higher delay discounting rate (DDR) often choose smaller but more immediate rewards (a \"today person\"). In contrast, people with a lower discounting rate often choose a larger future rewards (a \"tomorrow person\"). Since the ability to modulate the desire of immediate gratification for long term rewards plays an important role in our decision-making, the lower discounting rate often predicts better social, academic and health outcomes. In contrast, the higher discounting rate is often associated with problematic behaviors such as alcohol/drug abuse, pathological gambling and credit card default. Thus, research on understanding and moderating delay discounting has the potential to produce substantial societal benefits.\n    ",
        "submission_date": "2017-03-22T00:00:00",
        "last_modified_date": "2017-03-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.07929",
        "title": "Diversification-Based Learning in Computing and Optimization",
        "authors": [
            "Fred Glover",
            "Jin-Kao Hao"
        ],
        "abstract": "Diversification-Based Learning (DBL) derives from a collection of principles and methods introduced in the field of metaheuristics that have broad applications in computing and optimization. We show that the DBL framework goes significantly beyond that of the more recent Opposition-based learning (OBL) framework introduced in Tizhoosh (2005), which has become the focus of numerous research initiatives in machine learning and metaheuristic optimization. We unify and extend earlier proposals in metaheuristic search (Glover, 1997, Glover and Laguna, 1997) to give a collection of approaches that are more flexible and comprehensive than OBL for creating intensification and diversification strategies in metaheuristic search. We also describe potential applications of DBL to various subfields of machine learning and optimization.\n    ",
        "submission_date": "2017-03-23T00:00:00",
        "last_modified_date": "2017-03-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.08144",
        "title": "Note Value Recognition for Piano Transcription Using Markov Random Fields",
        "authors": [
            "Eita Nakamura",
            "Kazuyoshi Yoshii",
            "Simon Dixon"
        ],
        "abstract": "This paper presents a statistical method for use in music transcription that can estimate score times of note onsets and offsets from polyphonic MIDI performance signals. Because performed note durations can deviate largely from score-indicated values, previous methods had the problem of not being able to accurately estimate offset score times (or note values) and thus could only output incomplete musical scores. Based on observations that the pitch context and onset score times are influential on the configuration of note values, we construct a context-tree model that provides prior distributions of note values using these features and combine it with a performance model in the framework of Markov random fields. Evaluation results show that our method reduces the average error rate by around 40 percent compared to existing/simple methods. We also confirmed that, in our model, the score model plays a more important role than the performance model, and it automatically captures the voice structure by unsupervised learning.\n    ",
        "submission_date": "2017-03-23T00:00:00",
        "last_modified_date": "2017-07-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.08383",
        "title": "Smart Augmentation - Learning an Optimal Data Augmentation Strategy",
        "authors": [
            "Joseph Lemley",
            "Shabab Bazrafkan",
            "Peter Corcoran"
        ],
        "abstract": "A recurring problem faced when training neural networks is that there is typically not enough data to maximize the generalization capability of deep neural networks(DNN). There are many techniques to address this, including data augmentation, dropout, and transfer learning. In this paper, we introduce an additional method which we call Smart Augmentation and we show how to use it to increase the accuracy and reduce overfitting on a target network. Smart Augmentation works by creating a network that learns how to generate augmented data during the training process of a target network in a way that reduces that networks loss. This allows us to learn augmentations that minimize the error of that network.\n",
        "submission_date": "2017-03-24T00:00:00",
        "last_modified_date": "2017-03-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.08397",
        "title": "Reasoning by Cases in Structured Argumentation",
        "authors": [
            "Mathieu Beirlaen",
            "Jesse Heyninck",
            "Christian Stra\u00dfer"
        ],
        "abstract": "We extend the $ASPIC^+$ framework for structured argumentation so as to allow applications of the reasoning by cases inference scheme for defeasible arguments. Given an argument with conclusion `$A$ or $B$', an argument based on $A$ with conclusion $C$, and an argument based on $B$ with conclusion $C$, we allow the construction of an argument with conclusion $C$. We show how our framework leads to different results than other approaches in non-monotonic logic for dealing with disjunctive information, such as disjunctive default theory or approaches based on the OR-rule (which allows to derive a defeasible rule `If ($A$ or $B$) then $C$', given two defeasible rules `If $A$ then $C$' and `If $B$ then $C$'). We raise new questions regarding the subtleties of reasoning defeasibly with disjunctive information, and show that its formalization is more intricate than one would presume.\n    ",
        "submission_date": "2017-03-24T00:00:00",
        "last_modified_date": "2017-03-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.08762",
        "title": "Team Formation for Scheduling Educational Material in Massive Online Classes",
        "authors": [
            "Sanaz Bahargam",
            "D\u00f3ra Erdos",
            "Azer Bestavros",
            "Evimaria Terzi"
        ],
        "abstract": "Whether teaching in a classroom or a Massive Online Open Course it is crucial to present the material in a way that benefits the audience as a whole. We identify two important tasks to solve towards this objective, 1 group students so that they can maximally benefit from peer interaction and 2 find an optimal schedule of the educational material for each group. Thus, in this paper, we solve the problem of team formation and content scheduling for education. Given a time frame d, a set of students S with their required need to learn different activities T and given k as the number of desired groups, we study the problem of finding k group of students. The goal is to teach students within time frame d such that their potential for learning is maximized and find the best schedule for each group. We show this problem to be NP-hard and develop a polynomial algorithm for it. We show our algorithm to be effective both on synthetic as well as a real data set. For our experiments, we use real data on students' grades in a Computer Science department. As part of our contribution, we release a semi-synthetic dataset that mimics the properties of the real data.\n    ",
        "submission_date": "2017-03-26T00:00:00",
        "last_modified_date": "2017-03-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.08922",
        "title": "On Automating the Doctrine of Double Effect",
        "authors": [
            "Naveen Sundar Govindarajulu",
            "Selmer Bringsjord"
        ],
        "abstract": "The doctrine of double effect ($\\mathcal{DDE}$) is a long-studied ethical principle that governs when actions that have both positive and negative effects are to be allowed. The goal in this paper is to automate $\\mathcal{DDE}$. We briefly present $\\mathcal{DDE}$, and use a first-order modal logic, the deontic cognitive event calculus, as our framework to formalize the doctrine. We present formalizations of increasingly stronger versions of the principle, including what is known as the doctrine of triple effect. We then use our framework to simulate successfully scenarios that have been used to test for the presence of the principle in human subjects. Our framework can be used in two different modes: One can use it to build $\\mathcal{DDE}$-compliant autonomous systems from scratch, or one can use it to verify that a given AI system is $\\mathcal{DDE}$-compliant, by applying a $\\mathcal{DDE}$ layer on an existing system or model. For the latter mode, the underlying AI system can be built using any architecture (planners, deep neural networks, bayesian networks, knowledge-representation systems, or a hybrid); as long as the system exposes a few parameters in its model, such verification is possible. The role of the $\\mathcal{DDE}$ layer here is akin to a (dynamic or static) software verifier that examines existing software modules. Finally, we end by presenting initial work on how one can apply our $\\mathcal{DDE}$ layer to the STRIPS-style planning model, and to a modified POMDP ",
        "submission_date": "2017-03-27T00:00:00",
        "last_modified_date": "2017-07-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.09368",
        "title": "Learning and inference in knowledge-based probabilistic model for medical diagnosis",
        "authors": [
            "Jingchi Jiang",
            "Chao Zhao",
            "Yi Guan",
            "Qiubin Yu"
        ],
        "abstract": "Based on a weighted knowledge graph to represent first-order knowledge and combining it with a probabilistic model, we propose a methodology for the creation of a medical knowledge network (MKN) in medical diagnosis. When a set of symptoms is activated for a specific patient, we can generate a ground medical knowledge network composed of symptom nodes and potential disease nodes. By Incorporating a Boltzmann machine into the potential function of a Markov network, we investigated the joint probability distribution of the MKN. In order to deal with numerical symptoms, a multivariate inference model is presented that uses conditional probability. In addition, the weights for the knowledge graph were efficiently learned from manually annotated Chinese Electronic Medical Records (CEMRs). In our experiments, we found numerically that the optimum choice of the quality of disease node and the expression of symptom variable can improve the effectiveness of medical diagnosis. Our experimental results comparing a Markov logic network and the logistic regression algorithm on an actual CEMR database indicate that our method holds promise and that MKN can facilitate studies of intelligent diagnosis.\n    ",
        "submission_date": "2017-03-28T00:00:00",
        "last_modified_date": "2017-03-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.09513",
        "title": "Mining Best Closed Itemsets for Projection-antimonotonic Constraints in Polynomial Time",
        "authors": [
            "Aleksey Buzmakov",
            "Sergei O. Kuznetsov",
            "Amedeo Napoli"
        ],
        "abstract": "The exponential explosion of the set of patterns is one of the main challenges in pattern mining. This challenge is approached by introducing a constraint for pattern selection. One of the first constraints proposed in pattern mining is support (frequency) of a pattern in a dataset. Frequency is an anti-monotonic function, i.e., given an infrequent pattern, all its superpatterns are not frequent. However, many other constraints for pattern selection are neither monotonic nor anti-monotonic, which makes it difficult to generate patterns satisfying these constraints.\n",
        "submission_date": "2017-03-28T00:00:00",
        "last_modified_date": "2017-03-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.09620",
        "title": "Universal Reasoning, Rational Argumentation and Human-Machine Interaction",
        "authors": [
            "Christoph Benzm\u00fcller"
        ],
        "abstract": "Classical higher-order logic, when utilized as a meta-logic in which various other (classical and non-classical) logics can be shallowly embedded, is well suited for realising a universal logic reasoning approach. Universal logic reasoning in turn, as envisioned already by Leibniz, may support the rigorous formalisation and deep logical analysis of rational arguments within machines. A respective universal logic reasoning framework is described and a range of exemplary applications are discussed. In the future, universal logic reasoning in combination with appropriate, controlled forms of rational argumentation may serve as a communication layer between humans and intelligent machines.\n    ",
        "submission_date": "2017-03-28T00:00:00",
        "last_modified_date": "2017-03-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.09923",
        "title": "On Convergence Property of Implicit Self-paced Objective",
        "authors": [
            "Zilu Ma",
            "Shiqi Liu",
            "Deyu Meng"
        ],
        "abstract": "Self-paced learning (SPL) is a new methodology that simulates the learning principle of humans/animals to start learning easier aspects of a learning task, and then gradually take more complex examples into training. This new-coming learning regime has been empirically substantiated to be effective in various computer vision and pattern recognition tasks. Recently, it has been proved that the SPL regime has a close relationship to a implicit self-paced objective function. While this implicit objective could provide helpful interpretations to the effectiveness, especially the robustness, insights under the SPL paradigms, there are still no theoretical results strictly proved to verify such relationship. To this issue, in this paper, we provide some convergence results on this implicit objective of SPL. Specifically, we prove that the learning process of SPL always converges to critical points of this implicit objective under some mild conditions. This result verifies the intrinsic relationship between SPL and this implicit objective, and makes the previous robustness analysis on SPL complete and theoretically rational.\n    ",
        "submission_date": "2017-03-29T00:00:00",
        "last_modified_date": "2017-03-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.09962",
        "title": "Spaceprint: a Mobility-based Fingerprinting Scheme for Public Spaces",
        "authors": [
            "Mitra Baratchi",
            "Geert Heijenk",
            "Maarten van Steen"
        ],
        "abstract": "In this paper, we address the problem of how automated situation-awareness can be achieved by learning real-world situations from ubiquitously generated mobility data. Without semantic input about the time and space where situations take place, this turns out to be a fundamental challenging problem. Uncertainties also introduce technical challenges when data is generated in irregular time intervals, being mixed with noise, and errors. Purely relying on temporal patterns observable in mobility data, in this paper, we propose Spaceprint, a fully automated algorithm for finding the repetitive pattern of similar situations in spaces. We evaluate this technique by showing how the latent variables describing the category, and the actual identity of a space can be discovered from the extracted situation patterns. Doing so, we use different real-world mobility datasets with data about the presence of mobile entities in a variety of spaces. We also evaluate the performance of this technique by showing its robustness against uncertainties.\n    ",
        "submission_date": "2017-03-29T00:00:00",
        "last_modified_date": "2017-03-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.10069",
        "title": "Multiagent Bidirectionally-Coordinated Nets: Emergence of Human-level Coordination in Learning to Play StarCraft Combat Games",
        "authors": [
            "Peng Peng",
            "Ying Wen",
            "Yaodong Yang",
            "Quan Yuan",
            "Zhenkun Tang",
            "Haitao Long",
            "Jun Wang"
        ],
        "abstract": "Many artificial intelligence (AI) applications often require multiple intelligent agents to work in a collaborative effort. Efficient learning for intra-agent communication and coordination is an indispensable step towards general AI. In this paper, we take StarCraft combat game as a case study, where the task is to coordinate multiple agents as a team to defeat their enemies. To maintain a scalable yet effective communication protocol, we introduce a Multiagent Bidirectionally-Coordinated Network (BiCNet ['bIknet]) with a vectorised extension of actor-critic formulation. We show that BiCNet can handle different types of combats with arbitrary numbers of AI agents for both sides. Our analysis demonstrates that without any supervisions such as human demonstrations or labelled data, BiCNet could learn various types of advanced coordination strategies that have been commonly used by experienced game players. In our experiments, we evaluate our approach against multiple baselines under different scenarios; it shows state-of-the-art performance, and possesses potential values for large-scale real-world applications.\n    ",
        "submission_date": "2017-03-29T00:00:00",
        "last_modified_date": "2017-09-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.10098",
        "title": "Rational Choice and Artificial Intelligence",
        "authors": [
            "Tshilidzi Marwala"
        ],
        "abstract": "The theory of rational choice assumes that when people make decisions they do so in order to maximize their utility. In order to achieve this goal they ought to use all the information available and consider all the choices available to choose an optimal choice. This paper investigates what happens when decisions are made by artificially intelligent machines in the market rather than human beings. Firstly, the expectations of the future are more consistent if they are made by an artificially intelligent machine and the decisions are more rational and thus marketplace becomes more rational.\n    ",
        "submission_date": "2017-03-29T00:00:00",
        "last_modified_date": "2017-03-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.10284",
        "title": "Enter the Matrix: Safely Interruptible Autonomous Systems via Virtualization",
        "authors": [
            "Mark O. Riedl",
            "Brent Harrison"
        ],
        "abstract": "Autonomous systems that operate around humans will likely always rely on kill switches that stop their execution and allow them to be remote-controlled for the safety of humans or to prevent damage to the system. It is theoretically possible for an autonomous system with sufficient sensor and effector capability that learn online using reinforcement learning to discover that the kill switch deprives it of long-term reward and thus learn to disable the switch or otherwise prevent a human operator from using the switch. This is referred to as the big red button problem. We present a technique that prevents a reinforcement learning agent from learning to disable the kill switch. We introduce an interruption process in which the agent's sensors and effectors are redirected to a virtual simulation where it continues to believe it is receiving reward. We illustrate our technique in a simple grid world environment.\n    ",
        "submission_date": "2017-03-30T00:00:00",
        "last_modified_date": "2018-11-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.10316",
        "title": "Efficient Parallel Translating Embedding For Knowledge Graphs",
        "authors": [
            "Denghui Zhang",
            "Manling Li",
            "Yantao Jia",
            "Yuanzhuo Wang",
            "Xueqi Cheng"
        ],
        "abstract": "Knowledge graph embedding aims to embed entities and relations of knowledge graphs into low-dimensional vector spaces. Translating embedding methods regard relations as the translation from head entities to tail entities, which achieve the state-of-the-art results among knowledge graph embedding methods. However, a major limitation of these methods is the time consuming training process, which may take several days or even weeks for large knowledge graphs, and result in great difficulty in practical applications. In this paper, we propose an efficient parallel framework for translating embedding methods, called ParTrans-X, which enables the methods to be paralleled without locks by utilizing the distinguished structures of knowledge graphs. Experiments on two datasets with three typical translating embedding methods, i.e., TransE [3], TransH [17], and a more efficient variant TransE- AdaGrad [10] validate that ParTrans-X can speed up the training process by more than an order of magnitude.\n    ",
        "submission_date": "2017-03-30T00:00:00",
        "last_modified_date": "2018-01-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.10342",
        "title": "Efficient Benchmarking of Algorithm Configuration Procedures via Model-Based Surrogates",
        "authors": [
            "Katharina Eggensperger",
            "Marius Lindauer",
            "Holger H. Hoos",
            "Frank Hutter",
            "Kevin Leyton-Brown"
        ],
        "abstract": "The optimization of algorithm (hyper-)parameters is crucial for achieving peak performance across a wide range of domains, ranging from deep neural networks to solvers for hard combinatorial problems. The resulting algorithm configuration (AC) problem has attracted much attention from the machine learning community. However, the proper evaluation of new AC procedures is hindered by two key hurdles. First, AC benchmarks are hard to set up. Second and even more significantly, they are computationally expensive: a single run of an AC procedure involves many costly runs of the target algorithm whose performance is to be optimized in a given AC benchmark scenario. One common workaround is to optimize cheap-to-evaluate artificial benchmark functions (e.g., Branin) instead of actual algorithms; however, these have different properties than realistic AC problems. Here, we propose an alternative benchmarking approach that is similarly cheap to evaluate but much closer to the original AC problem: replacing expensive benchmarks by surrogate benchmarks constructed from AC benchmarks. These surrogate benchmarks approximate the response surface corresponding to true target algorithm performance using a regression model, and the original and surrogate benchmark share the same (hyper-)parameter space. In our experiments, we construct and evaluate surrogate benchmarks for hyperparameter optimization as well as for AC problems that involve performance optimization of solvers for hard combinatorial problems, drawing training data from the runs of existing AC procedures. We show that our surrogate benchmarks capture overall important characteristics of the AC scenarios, such as high- and low-performing regions, from which they were derived, while being much easier to use and orders of magnitude cheaper to evaluate.\n    ",
        "submission_date": "2017-03-30T00:00:00",
        "last_modified_date": "2017-03-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.10429",
        "title": "An Empirical Approach for Modeling Fuzzy Geographical Descriptors",
        "authors": [
            "Alejandro Ramos-Soto",
            "Jose M. Alonso",
            "Ehud Reiter",
            "Kees van Deemter",
            "Albert Gatt"
        ],
        "abstract": "We present a novel heuristic approach that defines fuzzy geographical descriptors using data gathered from a survey with human subjects. The participants were asked to provide graphical interpretations of the descriptors `north' and `south' for the Galician region (Spain). Based on these interpretations, our approach builds fuzzy descriptors that are able to compute membership degrees for geographical locations. We evaluated our approach in terms of efficiency and precision. The fuzzy descriptors are meant to be used as the cornerstones of a geographical referring expression generation algorithm that is able to linguistically characterize geographical locations and regions. This work is also part of a general research effort that intends to establish a methodology which reunites the empirical studies traditionally practiced in data-to-text and the use of fuzzy sets to model imprecision and vagueness in words and expressions for text generation purposes.\n    ",
        "submission_date": "2017-03-30T00:00:00",
        "last_modified_date": "2017-03-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.10579",
        "title": "Evaluating Complex Task through Crowdsourcing: Multiple Views Approach",
        "authors": [
            "Lingyu Lyu",
            "Mehmed Kantardzic"
        ],
        "abstract": "With the popularity of massive open online courses, grading through crowdsourcing has become a prevalent approach towards large scale classes. However, for getting grades for complex tasks, which require specific skills and efforts for grading, crowdsourcing encounters a restriction of insufficient knowledge of the workers from the crowd. Due to knowledge limitation of the crowd graders, grading based on partial perspectives becomes a big challenge for evaluating complex tasks through crowdsourcing. Especially for those tasks which not only need specific knowledge for grading, but also should be graded as a whole instead of being decomposed into smaller and simpler subtasks. We propose a framework for grading complex tasks via multiple views, which are different grading perspectives defined by experts for the task, to provide uniformity. Aggregation algorithm based on graders variances are used to combine the grades for each view. We also detect bias patterns of the graders, and debias them regarding each view of the task. Bias pattern determines how the behavior is biased among graders, which is detected by a statistical technique. The proposed approach is analyzed on a synthetic data set. We show that our model gives more accurate results compared to the grading approaches without different views and debiasing algorithm.\n    ",
        "submission_date": "2017-03-30T00:00:00",
        "last_modified_date": "2017-03-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.10970",
        "title": "Diversity of preferences can increase collective welfare in sequential exploration problems",
        "authors": [
            "Pantelis P. Analytis",
            "Hrvoje Stojic",
            "Alexandros Gelastopoulos",
            "Mehdi Moussa\u00efd"
        ],
        "abstract": "In search engines, online marketplaces and other human-computer interfaces large collectives of individuals sequentially interact with numerous alternatives of varying quality. In these contexts, trial and error (exploration) is crucial for uncovering novel high-quality items or solutions, but entails a high cost for individual users. Self-interested decision makers, are often better off imitating the choices of individuals who have already incurred the costs of exploration. Although imitation makes sense at the individual level, it deprives the group of additional information that could have been gleaned by individual explorers. In this paper we show that in such problems, preference diversity can function as a welfare enhancing mechanism. It leads to a consistent increase in the quality of the consumed alternatives that outweighs the increased cost of search for the users.\n    ",
        "submission_date": "2017-03-28T00:00:00",
        "last_modified_date": "2017-04-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.00045",
        "title": "Comparison of ontology alignment systems across single matching task via the McNemar's test",
        "authors": [
            "Majid Mohammadi",
            "Amir Ahooye Atashin",
            "Wout Hofman",
            "Yao-Hua Tan"
        ],
        "abstract": "Ontology alignment is widely-used to find the correspondences between different ontologies in diverse ",
        "submission_date": "2017-03-29T00:00:00",
        "last_modified_date": "2018-04-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.00325",
        "title": "Structured Parallel Programming for Monte Carlo Tree Search",
        "authors": [
            "S. Ali Mirsoleimani",
            "Aske Plaat",
            "Jaap van den Herik",
            "Jos Vermaseren"
        ],
        "abstract": "In this paper, we present a new algorithm for parallel Monte Carlo tree search (MCTS). It is based on the pipeline pattern and allows flexible management of the control flow of the operations in parallel MCTS. The pipeline pattern provides for the first structured parallel programming approach to MCTS. Moreover, we propose a new lock-free tree data structure for parallel MCTS which removes synchronization overhead. The Pipeline Pattern for Parallel MCTS algorithm (called 3PMCTS), scales very well to higher numbers of cores when compared to the existing methods.\n    ",
        "submission_date": "2017-04-02T00:00:00",
        "last_modified_date": "2017-04-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.00783",
        "title": "Brief Notes on Hard Takeoff, Value Alignment, and Coherent Extrapolated Volition",
        "authors": [
            "Gopal P. Sarma"
        ],
        "abstract": "I make some basic observations about hard takeoff, value alignment, and coherent extrapolated volition, concepts which have been central in analyses of superintelligent AI systems.\n    ",
        "submission_date": "2017-04-03T00:00:00",
        "last_modified_date": "2018-04-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.00795",
        "title": "Design and development of a software system for swarm intelligence based research studies",
        "authors": [
            "Utku Kose"
        ],
        "abstract": "This paper introduce a software system including widely-used Swarm Intelligence algorithms or approaches to be used for the related scientific research studies associated with the subject area. The programmatic infrastructure of the system allows working on a fast, easy-to-use, interactive platform to perform Swarm Intelligence based studies in a more effective, efficient and accurate way. In this sense, the system employs all of the necessary controls for the algorithms and it ensures an interactive platform on which computer users can perform studies on a wide spectrum of solution approaches associated with simple and also more advanced problems.\n    ",
        "submission_date": "2017-04-03T00:00:00",
        "last_modified_date": "2017-04-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.00797",
        "title": "On the idea of a new artificial intelligence based optimization algorithm inspired from the nature of vortex",
        "authors": [
            "Utku Kose",
            "Ahmet Arslan"
        ],
        "abstract": "In this paper, the idea of a new artificial intelligence based optimization algorithm, which is inspired from the nature of vortex, has been provided briefly. As also a bio-inspired computation algorithm, the idea is generally focused on a typical vortex flow / behavior in nature and inspires from some dynamics that are occurred in the sense of vortex nature. Briefly, the algorithm is also a swarm-oriented evolutional problem solution approach; because it includes many methods related to elimination of weak swarm members and trying to improve the solution process by supporting the solution space via new swarm members. In order have better idea about success of the algorithm; it has been tested via some benchmark functions. At this point, the obtained results show that the algorithm can be an alternative to the literature in terms of single-objective optimization solution ways. Vortex Optimization Algorithm (VOA) is the name suggestion by the authors; for this new idea of intelligent optimization approach.\n    ",
        "submission_date": "2017-04-03T00:00:00",
        "last_modified_date": "2017-04-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.00853",
        "title": "A History of Metaheuristics",
        "authors": [
            "Kenneth Sorensen",
            "Marc Sevaux",
            "Fred Glover"
        ],
        "abstract": "This chapter describes the history of metaheuristics in five distinct periods, starting long before the first use of the term and ending a long time in the future.\n    ",
        "submission_date": "2017-04-04T00:00:00",
        "last_modified_date": "2017-04-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.00961",
        "title": "Adaptive Motion Gaming AI for Health Promotion",
        "authors": [
            "Pujana Paliyawan",
            "Takahiro Kusano",
            "Yuto Nakagawa",
            "Tomohiro Harada",
            "Ruck Thawonmas"
        ],
        "abstract": "This paper presents a design of a non-player character (AI) for promoting balancedness in use of body segments when engaging in full-body motion gaming. In our experiment, we settle a battle between the proposed AI and a player by using FightingICE, a fighting game platform for AI development. A middleware called UKI is used to allow the player to control the game by using body motion instead of the keyboard and mouse. During gameplay, the proposed AI analyze health states of the player; it determines its next action by predicting how each candidate action, recommended by a Monte-Carlo tree search algorithm, will induce the player to move, and how the player's health tends to be affected. Our result demonstrates successful improvement in balancedness in use of body segments on 4 out of 5 subjects.\n    ",
        "submission_date": "2017-04-04T00:00:00",
        "last_modified_date": "2017-04-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.01006",
        "title": "Ontology based Scene Creation for the Development of Automated Vehicles",
        "authors": [
            "Gerrit Bagschik",
            "Till Menzel",
            "Markus Maurer"
        ],
        "abstract": "The introduction of automated vehicles without permanent human supervision demands a functional system description, including functional system boundaries and a comprehensive safety analysis. These inputs to the technical development can be identified and analyzed by a scenario-based approach. Furthermore, to establish an economical test and release process, a large number of scenarios must be identified to obtain meaningful test results. Experts are doing well to identify scenarios that are difficult to handle or unlikely to happen. However, experts are unlikely to identify all scenarios possible based on the knowledge they have on hand. Expert knowledge modeled for computer aided processing may help for the purpose of providing a wide range of scenarios. This contribution reviews ontologies as knowledge-based systems in the field of automated vehicles, and proposes a generation of traffic scenes in natural language as a basis for a scenario creation.\n    ",
        "submission_date": "2017-03-29T00:00:00",
        "last_modified_date": "2018-04-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.01014",
        "title": "An Ontological Architecture for Orbital Debris Data",
        "authors": [
            "Robert J. Rovetto"
        ],
        "abstract": "The orbital debris problem presents an opportunity for inter-agency and international cooperation toward the mutually beneficial goals of debris prevention, mitigation, remediation, and improved space situational awareness (SSA). Achieving these goals requires sharing orbital debris and other SSA data. Toward this, I present an ontological architecture for the orbital debris domain, taking steps in the creation of an orbital debris ontology (ODO). The purpose of this ontological system is to (I) represent general orbital debris and SSA domain knowledge, (II) structure, and standardize where needed, orbital data and terminology, and (III) foster semantic interoperability and data-sharing. In doing so I hope to (IV) contribute to solving the orbital debris problem, improving peaceful global SSA, and ensuring safe space travel for future generations.\n    ",
        "submission_date": "2017-04-01T00:00:00",
        "last_modified_date": "2021-12-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.01049",
        "title": "A simulated annealing approach to optimal storing in a multi-level warehouse",
        "authors": [
            "Alexander Eckrot",
            "Carina Geldhauser",
            "Jan Jurczyk"
        ],
        "abstract": "We propose a simulated annealing algorithm specifically tailored to optimise total retrieval times in a multi-level warehouse under complex pre-batched picking constraints. Experiments on real data from a picker-to-parts order picking process in the warehouse of a European manufacturer show that optimal storage assignments do not necessarily display features presumed in heuristics, such as clustering of positively correlated items or ordering of items by picking frequency.\n",
        "submission_date": "2017-03-25T00:00:00",
        "last_modified_date": "2017-03-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.01087",
        "title": "Probabilistic Search for Structured Data via Probabilistic Programming and Nonparametric Bayes",
        "authors": [
            "Feras Saad",
            "Leonardo Casarsa",
            "Vikash Mansinghka"
        ],
        "abstract": "Databases are widespread, yet extracting relevant data can be difficult. Without substantial domain knowledge, multivariate search queries often return sparse or uninformative results. This paper introduces an approach for searching structured data based on probabilistic programming and nonparametric Bayes. Users specify queries in a probabilistic language that combines standard SQL database search operators with an information theoretic ranking function called predictive relevance. Predictive relevance can be calculated by a fast sparse matrix algorithm based on posterior samples from CrossCat, a nonparametric Bayesian model for high-dimensional, heterogeneously-typed data tables. The result is a flexible search technique that applies to a broad class of information retrieval problems, which we integrate into BayesDB, a probabilistic programming platform for probabilistic data analysis. This paper demonstrates applications to databases of US colleges, global macroeconomic indicators of public health, and classic cars. We found that human evaluators often prefer the results from probabilistic search to results from a standard baseline.\n    ",
        "submission_date": "2017-04-04T00:00:00",
        "last_modified_date": "2017-04-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.01161",
        "title": "Finite Sample Analyses for TD(0) with Function Approximation",
        "authors": [
            "Gal Dalal",
            "Bal\u00e1zs Sz\u00f6r\u00e9nyi",
            "Gugan Thoppe",
            "Shie Mannor"
        ],
        "abstract": "TD(0) is one of the most commonly used algorithms in reinforcement learning. Despite this, there is no existing finite sample analysis for TD(0) with function approximation, even for the linear case. Our work is the first to provide such results. Existing convergence rates for Temporal Difference (TD) methods apply only to somewhat modified versions, e.g., projected variants or ones where stepsizes depend on unknown problem parameters. Our analyses obviate these artificial alterations by exploiting strong properties of TD(0). We provide convergence rates both in expectation and with high-probability. The two are obtained via different approaches that use relatively unknown, recently developed stochastic approximation techniques.\n    ",
        "submission_date": "2017-04-04T00:00:00",
        "last_modified_date": "2017-12-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.01399",
        "title": "Geracao Automatica de Paineis de Controle para Analise de Mobilidade Urbana Utilizando Redes Complexas",
        "authors": [
            "Victor Dantas",
            "Henrique Santos",
            "Carlos Caminha",
            "Vasco Furtado"
        ],
        "abstract": "In this paper we describe an automatic generator to support the data scientist to construct, in a user-friendly way, dashboards from data represented as networks. The generator called SBINet (Semantic for Business Intelligence from Networks) has a semantic layer that, through ontologies, describes the data that represents a network as well as the possible metrics to be calculated in the network. Thus, with SBINet, the stages of the dashboard constructing process that uses complex network metrics are facilitated and can be done by users who do not necessarily know about complex networks.\n    ",
        "submission_date": "2017-04-04T00:00:00",
        "last_modified_date": "2017-04-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.01407",
        "title": "Embodied Artificial Intelligence through Distributed Adaptive Control: An Integrated Framework",
        "authors": [
            "Cl\u00e9ment Moulin-Frier",
            "Jordi-Ysard Puigb\u00f2",
            "Xerxes D. Arsiwalla",
            "Mart\u00ec Sanchez-Fibla",
            "Paul F. M. J. Verschure"
        ],
        "abstract": "In this paper, we argue that the future of Artificial Intelligence research resides in two keywords: integration and embodiment. We support this claim by analyzing the recent advances of the field. Regarding integration, we note that the most impactful recent contributions have been made possible through the integration of recent Machine Learning methods (based in particular on Deep Learning and Recurrent Neural Networks) with more traditional ones (e.g. Monte-Carlo tree search, goal babbling exploration or addressable memory systems). Regarding embodiment, we note that the traditional benchmark tasks (e.g. visual classification or board games) are becoming obsolete as state-of-the-art learning algorithms approach or even surpass human performance in most of them, having recently encouraged the development of first-person 3D game platforms embedding realistic physics. Building upon this analysis, we first propose an embodied cognitive architecture integrating heterogenous sub-fields of Artificial Intelligence into a unified framework. We demonstrate the utility of our approach by showing how major contributions of the field can be expressed within the proposed framework. We then claim that benchmarking environments need to reproduce ecologically-valid conditions for bootstrapping the acquisition of increasingly complex cognitive skills through the concept of a cognitive arms race between embodied agents.\n    ",
        "submission_date": "2017-04-05T00:00:00",
        "last_modified_date": "2017-09-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.01742",
        "title": "Transferrable Plausibility Model - A Probabilistic Interpretation of Mathematical Theory of Evidence",
        "authors": [
            "Mieczys\u0142aw K\u0142opotek"
        ],
        "abstract": "This paper suggests a new interpretation of the Dempster-Shafer theory in terms of probabilistic interpretation of plausibility. A new rule of combination of independent evidence is shown and its preservation of interpretation is demonstrated.\n    ",
        "submission_date": "2017-04-06T00:00:00",
        "last_modified_date": "2017-04-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.01785",
        "title": "Geometry of Policy Improvement",
        "authors": [
            "Guido Montufar",
            "Johannes Rauh"
        ],
        "abstract": "We investigate the geometry of optimal memoryless time independent decision making in relation to the amount of information that the acting agent has about the state of the system. We show that the expected long term reward, discounted or per time step, is maximized by policies that randomize among at most $k$ actions whenever at most $k$ world states are consistent with the agent's observation. Moreover, we show that the expected reward per time step can be studied in terms of the expected discounted reward. Our main tool is a geometric version of the policy improvement lemma, which identifies a polyhedral cone of policy changes in which the state value function increases for all states.\n    ",
        "submission_date": "2017-04-06T00:00:00",
        "last_modified_date": "2017-04-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.01802",
        "title": "Contextual Data Collection for Smart Cities",
        "authors": [
            "Henrique Santos",
            "Vasco Furtado",
            "Paulo Pinheiro",
            "Deborah L. McGuinness"
        ],
        "abstract": "As part of Smart Cities initiatives, national, regional and local governments all over the globe are under the mandate of being more open regarding how they share their data. Under this mandate, many of these governments are publishing data under the umbrella of open government data, which includes measurement data from city-wide sensor networks. Furthermore, many of these data are published in so-called data portals as documents that may be spreadsheets, comma-separated value (CSV) data files, or plain documents in PDF or Word documents. The sharing of these documents may be a convenient way for the data provider to convey and publish data but it is not the ideal way for data consumers to reuse the data. For example, the problems of reusing the data may range from difficulty opening a document that is provided in any format that is not plain text, to the actual problem of understanding the meaning of each piece of knowledge inside of the document. Our proposal tackles those challenges by identifying metadata that has been regarded to be relevant for measurement data and providing a schema for this metadata. We further leverage the Human-Aware Sensor Network Ontology (HASNetO) to build an architecture for data collected in urban environments. We discuss the use of HASNetO and the supporting infrastructure to manage both data and metadata in support of the City of Fortaleza, a large metropolitan area in Brazil.\n    ",
        "submission_date": "2017-04-06T00:00:00",
        "last_modified_date": "2017-04-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.01806",
        "title": "Human-Aware Sensor Network Ontology: Semantic Support for Empirical Data Collection",
        "authors": [
            "Paulo Pinheiro",
            "Deborah L. McGuinness",
            "Henrique Santos"
        ],
        "abstract": "Significant efforts have been made to understand and document knowledge related to scientific measurements. Many of those efforts resulted in one or more high-quality ontologies that describe some aspects of scientific measurements, but not in a comprehensive and coherently integrated manner. For instance, we note that many of these high-quality ontologies are not properly aligned, and more challenging, that they have different and often conflicting concepts and approaches for encoding knowledge about empirical measurements. As a result of this lack of an integrated view, it is often challenging for scientists to determine whether any two scientific measurements were taken in semantically compatible manners, thus making it difficult to decide whether measurements should be analyzed in combination or not. In this paper, we present the Human-Aware Sensor Network Ontology that is a comprehensive alignment and integration of a sensing infrastructure ontology and a provenance ontology. HASNetO has been under development for more than one year, and has been reviewed, shared and used by multiple scientific communities. The ontology has been in use to support the data management of a number of large-scale ecological monitoring activities (observations) and empirical experiments.\n    ",
        "submission_date": "2017-04-06T00:00:00",
        "last_modified_date": "2017-04-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.01855",
        "title": "A Service-Oriented Architecture for Assisting the Authoring of Semantic Crowd Maps",
        "authors": [
            "Henrique Santos",
            "Vasco Furtado"
        ],
        "abstract": "Although there are increasingly more initiatives for the generation of semantic knowledge based on user participation, there is still a shortage of platforms for regular users to create applications on which semantic data can be exploited and generated automatically. We propose an architecture, called Semantic Maps (SeMaps), for assisting the authoring and hosting of applications in which the maps combine the aggregation of a Geographic Information System and crowd-generated content (called here crowd maps). In these systems, the digital map works as a blackboard for accommodating stories told by people about events they want to share with others typically participating in their social networks. SeMaps offers an environment for the creation and maintenance of sites based on crowd maps with the possibility for the user to characterize semantically that which s/he intends to mark on the map. The designer of a crowd map, by informing a linguistic expression that designates what has to be marked on the maps, is guided in a process that aims to associate a concept from a common-sense base to this linguistic expression. Thus, the crowd maps start to have dominion over common-sense inferential relations that define the meaning of the marker, and are able to make inferences about the network of linked data. This makes it possible to generate maps that have the power to perform inferences and access external sources (such as DBpedia) that constitute information that is useful and appropriate to the context of the map. In this paper we describe the architecture of SeMaps and how it was applied in a crowd map authoring tool.\n    ",
        "submission_date": "2017-04-06T00:00:00",
        "last_modified_date": "2017-04-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.01944",
        "title": "The quality of priority ratios estimation in relation to a selected prioritization procedure and consistency measure for a Pairwise Comparison Matrix",
        "authors": [
            "Paul Thaddeus Kazibudzki"
        ],
        "abstract": "An overview of current debates and contemporary research devoted to the modeling of decision making processes and their facilitation directs attention to the Analytic Hierarchy Process (AHP). At the core of the AHP are various prioritization procedures (PPs) and consistency measures (CMs) for a Pairwise Comparison Matrix (PCM) which, in a sense, reflects preferences of decision makers. Certainly, when judgments about these preferences are perfectly consistent (cardinally transitive), all PPs coincide and the quality of the priority ratios (PRs) estimation is exemplary. However, human judgments are very rarely consistent, thus the quality of PRs estimation may significantly vary. The scale of these variations depends on the applied PP and utilized CM for a PCM. This is why it is important to find out which PPs and which CMs for a PCM lead directly to an improvement of the PRs estimation accuracy. The main goal of this research is realized through the properly designed, coded and executed seminal and sophisticated simulation algorithms in Wolfram Mathematica 8.0. These research results convince that the embedded in the AHP and commonly applied, both genuine PP and CM for PCM may significantly deteriorate the quality of PRs estimation; however, solutions proposed in this paper can significantly improve the methodology.\n    ",
        "submission_date": "2017-04-06T00:00:00",
        "last_modified_date": "2017-06-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.01946",
        "title": "From Data to City Indicators: A Knowledge Graph for Supporting Automatic Generation of Dashboards",
        "authors": [
            "Henrique Santos",
            "Victor Dantas",
            "Vasco Furtado",
            "Paulo Pinheiro",
            "Deborah L. McGuinness"
        ],
        "abstract": "In the context of Smart Cities, indicator definitions have been used to calculate values that enable the comparison among different cities. The calculation of an indicator values has challenges as the calculation may need to combine some aspects of quality while addressing different levels of abstraction. Knowledge graphs (KGs) have been used successfully to support flexible representation, which can support improved understanding and data analysis in similar settings. This paper presents an operational description for a city KG, an indicator ontology that support indicator discovery and data visualization and an application capable of performing metadata analysis to automatically build and display dashboards according to discovered indicators. We describe our implementation in an urban mobility setting.\n    ",
        "submission_date": "2017-04-06T00:00:00",
        "last_modified_date": "2017-04-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.02114",
        "title": "Improving content marketing processes with the approaches by artificial intelligence",
        "authors": [
            "Utku Kose",
            "Selcuk Sert"
        ],
        "abstract": "Content marketing is todays one of the most remarkable approaches in the context of marketing processes of companies. Value of this kind of marketing has improved in time, thanks to the latest developments regarding to computer and communication technologies. Nowadays, especially social media based platforms have a great importance on enabling companies to design multimedia oriented, interactive content. But on the other hand, there is still something more to do for improved content marketing approaches. In this context, objective of this study is to focus on intelligent content marketing, which can be done by using artificial intelligence. Artificial Intelligence is todays one of the most remarkable research fields and it can be used easily as multidisciplinary. So, this study has aimed to discuss about its potential on improving content marketing. In detail, the study has enabled readers to improve their awareness about the intersection point of content marketing and artificial intelligence. Furthermore, the authors have introduced some example models of intelligent content marketing, which can be achieved by using current Web technologies and artificial intelligence techniques.\n    ",
        "submission_date": "2017-04-07T00:00:00",
        "last_modified_date": "2017-04-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.02254",
        "title": "Recurrent Environment Simulators",
        "authors": [
            "Silvia Chiappa",
            "S\u00e9bastien Racaniere",
            "Daan Wierstra",
            "Shakir Mohamed"
        ],
        "abstract": "Models that can simulate how environments change in response to actions can be used by agents to plan and act efficiently. We improve on previous environment simulators from high-dimensional pixel observations by introducing recurrent neural networks that are able to make temporally and spatially coherent predictions for hundreds of time-steps into the future. We present an in-depth analysis of the factors affecting performance, providing the most extensive attempt to advance the understanding of the properties of these models. We address the issue of computationally inefficiency with a model that does not need to generate a high-dimensional image at each time-step. We show that our approach can be used to improve exploration and is adaptable to many diverse environments, namely 10 Atari games, a 3D car racing environment, and complex 3D mazes.\n    ",
        "submission_date": "2017-04-07T00:00:00",
        "last_modified_date": "2017-04-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.02468",
        "title": "Basic Formal Properties of A Relational Model of The Mathematical Theory of Evidence",
        "authors": [
            "Mieczys\u0142aw A. K\u0142opotek",
            "S\u0142awomir T. Wierzcho\u0144"
        ],
        "abstract": "The paper presents a novel view of the Dempster-Shafer belief function as a measure of diversity in relational data bases. It is demonstrated that under the interpretation The Dempster rule of evidence combination corresponds to the join operator of the relational database theory. This rough-set based interpretation is qualitative in nature and can represent a number of belief function operators.\n",
        "submission_date": "2017-04-08T00:00:00",
        "last_modified_date": "2017-04-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.02621",
        "title": "Mixed Graphical Models for Causal Analysis of Multi-modal Variables",
        "authors": [
            "Andrew J Sedgewick",
            "Joseph D. Ramsey",
            "Peter Spirtes",
            "Clark Glymour",
            "Panayiotis V. Benos"
        ],
        "abstract": "Graphical causal models are an important tool for knowledge discovery because they can represent both the causal relations between variables and the multivariate probability distributions over the data. Once learned, causal graphs can be used for classification, feature selection and hypothesis generation, while revealing the underlying causal network structure and thus allowing for arbitrary likelihood queries over the data. However, current algorithms for learning sparse directed graphs are generally designed to handle only one type of data (continuous-only or discrete-only), which limits their applicability to a large class of multi-modal biological datasets that include mixed type variables. To address this issue, we developed new methods that modify and combine existing methods for finding undirected graphs with methods for finding directed graphs. These hybrid methods are not only faster, but also perform better than the directed graph estimation methods alone for a variety of parameter settings and data set sizes. Here, we describe a new conditional independence test for learning directed graphs over mixed data types and we compare performances of different graph learning strategies on synthetic data.\n    ",
        "submission_date": "2017-04-09T00:00:00",
        "last_modified_date": "2017-04-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.02716",
        "title": "Formal approaches to a definition of agents",
        "authors": [
            "Martin Biehl"
        ],
        "abstract": "This thesis contributes to the formalisation of the notion of an agent within the class of finite multivariate Markov chains. Agents are seen as entities that act, perceive, and are goal-directed.\n",
        "submission_date": "2017-04-10T00:00:00",
        "last_modified_date": "2017-04-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.02882",
        "title": "Dynamic Safe Interruptibility for Decentralized Multi-Agent Reinforcement Learning",
        "authors": [
            "El Mahdi El Mhamdi",
            "Rachid Guerraoui",
            "Hadrien Hendrikx",
            "Alexandre Maurer"
        ],
        "abstract": "In reinforcement learning, agents learn by performing actions and observing their outcomes. Sometimes, it is desirable for a human operator to \\textit{interrupt} an agent in order to prevent dangerous situations from happening. Yet, as part of their learning process, agents may link these interruptions, that impact their reward, to specific states and deliberately avoid them. The situation is particularly challenging in a multi-agent context because agents might not only learn from their own past interruptions, but also from those of other agents. Orseau and Armstrong defined \\emph{safe interruptibility} for one learner, but their work does not naturally extend to multi-agent systems. This paper introduces \\textit{dynamic safe interruptibility}, an alternative definition more suited to decentralized learning problems, and studies this notion in two learning frameworks: \\textit{joint action learners} and \\textit{independent learners}. We give realistic sufficient conditions on the learning algorithm to enable dynamic safe interruptibility in the case of joint action learners, yet show that these conditions are not sufficient for independent learners. We show however that if agents can detect interruptions, it is possible to prune the observations to ensure dynamic safe interruptibility even for independent learners.\n    ",
        "submission_date": "2017-04-10T00:00:00",
        "last_modified_date": "2017-05-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.03012",
        "title": "Stochastic Neural Networks for Hierarchical Reinforcement Learning",
        "authors": [
            "Carlos Florensa",
            "Yan Duan",
            "Pieter Abbeel"
        ],
        "abstract": "Deep reinforcement learning has achieved many impressive results in recent years. However, tasks with sparse rewards or long horizons continue to pose significant challenges. To tackle these important problems, we propose a general framework that first learns useful skills in a pre-training environment, and then leverages the acquired skills for learning faster in downstream tasks. Our approach brings together some of the strengths of intrinsic motivation and hierarchical methods: the learning of useful skill is guided by a single proxy reward, the design of which requires very minimal domain knowledge about the downstream tasks. Then a high-level policy is trained on top of these skills, providing a significant improvement of the exploration and allowing to tackle sparse rewards in the downstream tasks. To efficiently pre-train a large span of skills, we use Stochastic Neural Networks combined with an information-theoretic regularizer. Our experiments show that this combination is effective in learning a wide span of interpretable skills in a sample-efficient way, and can significantly boost the learning performance uniformly across a wide range of downstream tasks.\n    ",
        "submission_date": "2017-04-10T00:00:00",
        "last_modified_date": "2017-04-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.03048",
        "title": "Matching Media Contents with User Profiles by means of the Dempster-Shafer Theory",
        "authors": [
            "Luigi Troiano",
            "Irene D\u00edaz",
            "Ciro Gaglione"
        ],
        "abstract": "The media industry is increasingly personalizing the offering of contents in attempt to better target the audience. This requires to analyze the relationships that goes established between users and content they enjoy, looking at one side to the content characteristics and on the other to the user profile, in order to find the best match between the two. In this paper we suggest to build that relationship using the Dempster-Shafer's Theory of Evidence, proposing a reference model and illustrating its properties by means of a toy example. Finally we suggest possible applications of the model for tasks that are common in the modern media industry.\n    ",
        "submission_date": "2017-04-10T00:00:00",
        "last_modified_date": "2017-04-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.03342",
        "title": "Beliefs and Probability in Bacchus' l.p. Logic: A~3-Valued Logic Solution to Apparent Counter-intuition",
        "authors": [
            "Mieczys\u0142aw A. K\u0142opotek"
        ],
        "abstract": "Fundamental discrepancy between first order logic and statistical inference (global versus local properties of universe) is shown to be the obstacle for integration of logic and probability in L.p. logic of Bacchus. To overcome the counterintuitiveness of L.p. behaviour, a 3-valued logic is proposed.\n    ",
        "submission_date": "2017-04-11T00:00:00",
        "last_modified_date": "2017-04-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.03396",
        "title": "Source-Sensitive Belief Change",
        "authors": [
            "Shahab Ebrahimi"
        ],
        "abstract": "The AGM model is the most remarkable framework for modeling belief revision. However, it is not perfect in all aspects. Paraconsistent belief revision, multi-agent belief revision and non-prioritized belief revision are three different extensions to AGM to address three important criticisms applied to it. In this article, we propose a framework based on AGM that takes a position in each of these categories. Also, we discuss some features of our framework and study the satisfiability of AGM postulates in this new context.\n    ",
        "submission_date": "2017-04-11T00:00:00",
        "last_modified_date": "2017-05-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.03402",
        "title": "Next Generation Business Intelligence and Analytics: A Survey",
        "authors": [
            "Quoc Duy Vo",
            "Jaya Thomas",
            "Shinyoung Cho",
            "Pradipta De",
            "Bong Jun Choi",
            "Lee Sael"
        ],
        "abstract": "Business Intelligence and Analytics (BI&A) is the process of extracting and predicting business-critical insights from data. Traditional BI focused on data collection, extraction, and organization to enable efficient query processing for deriving insights from historical data. With the rise of big data and cloud computing, there are many challenges and opportunities for the BI. Especially with the growing number of data sources, traditional BI\\&A are evolving to provide intelligence at different scales and perspectives - operational BI, situational BI, self-service BI. In this survey, we review the evolution of business intelligence systems in full scale from back-end architecture to and front-end applications. We focus on the changes in the back-end architecture that deals with the collection and organization of the data. We also review the changes in the front-end applications, where analytic services and visualization are the core components. Using a uses case from BI in Healthcare, which is one of the most complex enterprises, we show how BI\\&A will play an important role beyond the traditional usage. The survey provides a holistic view of Business Intelligence and Analytics for anyone interested in getting a complete picture of the different pieces in the emerging next generation BI\\&A solutions.\n    ",
        "submission_date": "2017-04-11T00:00:00",
        "last_modified_date": "2017-04-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.03574",
        "title": "CASP Solutions for Planning in Hybrid Domains",
        "authors": [
            "Marcello Balduccini",
            "Daniele Magazzeni",
            "Marco Maratea",
            "Emily LeBlanc"
        ],
        "abstract": "CASP is an extension of ASP that allows for numerical constraints to be added in the rules. PDDL+ is an extension of the PDDL standard language of automated planning for modeling mixed discrete-continuous dynamics.\n",
        "submission_date": "2017-04-12T00:00:00",
        "last_modified_date": "2018-06-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.03612",
        "title": "Finding Modes by Probabilistic Hypergraphs Shifting",
        "authors": [
            "Yang Wang",
            "Lin Wu"
        ],
        "abstract": "In this paper, we develop a novel paradigm, namely hypergraph shift, to find robust graph modes by probabilistic voting strategy, which are semantically sound besides the self-cohesiveness requirement in forming graph modes. Unlike the existing techniques to seek graph modes by shifting vertices based on pair-wise edges (i.e, an edge with $2$ ends), our paradigm is based on shifting high-order edges (hyperedges) to deliver graph modes. Specifically, we convert the problem of seeking graph modes as the problem of seeking maximizers of a novel objective function with the aim to generate good graph modes based on sifting edges in hypergraphs. As a result, the generated graph modes based on dense subhypergraphs may more accurately capture the object semantics besides the self-cohesiveness requirement. We also formally prove that our technique is always convergent. Extensive empirical studies on synthetic and real world data sets are conducted on clustering and graph matching. They demonstrate that our techniques significantly outperform the existing techniques.\n    ",
        "submission_date": "2017-04-12T00:00:00",
        "last_modified_date": "2017-04-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.03667",
        "title": "Stigmergy-based modeling to discover urban activity patterns from positioning data",
        "authors": [
            "Antonio L. Alfeo",
            "Mario G. C. A. Cimino",
            "Sara Egidi",
            "Bruno Lepri",
            "Alex Pentland",
            "Gigliola Vaglini"
        ],
        "abstract": "Positioning data offer a remarkable source of information to analyze crowds urban dynamics. However, discovering urban activity patterns from the emergent behavior of crowds involves complex system modeling. An alternative approach is to adopt computational techniques belonging to the emergent paradigm, which enables self-organization of data and allows adaptive analysis. Specifically, our approach is based on stigmergy. By using stigmergy each sample position is associated with a digital pheromone deposit, which progressively evaporates and aggregates with other deposits according to their spatiotemporal proximity. Based on this principle, we exploit positioning data to identify high density areas (hotspots) and characterize their activity over time. This characterization allows the comparison of dynamics occurring in different days, providing a similarity measure exploitable by clustering techniques. Thus, we cluster days according to their activity behavior, discovering unexpected urban activity patterns. As a case study, we analyze taxi traces in New York City during 2015.\n    ",
        "submission_date": "2017-04-12T00:00:00",
        "last_modified_date": "2019-01-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.03723",
        "title": "Beliefs in Markov Trees - From Local Computations to Local Valuation",
        "authors": [
            "Mieczys\u0142aw A. K\u0142opotek"
        ],
        "abstract": "This paper is devoted to expressiveness of hypergraphs for which uncertainty propagation by local computations via Shenoy/Shafer method applies. It is demonstrated that for this propagation method for a given joint belief distribution no valuation of hyperedges of a hypergraph may provide with simpler hypergraph structure than valuation of hyperedges by conditional distributions. This has vital implication that methods recovering belief networks from data have no better alternative for finding the simplest hypergraph structure for belief propagation. A method for recovery tree-structured belief networks has been developed and specialized for Dempster-Shafer belief functions\n    ",
        "submission_date": "2017-04-12T00:00:00",
        "last_modified_date": "2017-04-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.03732",
        "title": "Deep Q-learning from Demonstrations",
        "authors": [
            "Todd Hester",
            "Matej Vecerik",
            "Olivier Pietquin",
            "Marc Lanctot",
            "Tom Schaul",
            "Bilal Piot",
            "Dan Horgan",
            "John Quan",
            "Andrew Sendonaris",
            "Gabriel Dulac-Arnold",
            "Ian Osband",
            "John Agapiou",
            "Joel Z. Leibo",
            "Audrunas Gruslys"
        ],
        "abstract": "Deep reinforcement learning (RL) has achieved several high profile successes in difficult decision-making problems. However, these algorithms typically require a huge amount of data before they reach reasonable performance. In fact, their performance during learning can be extremely poor. This may be acceptable for a simulator, but it severely limits the applicability of deep RL to many real-world tasks, where the agent must learn in the real environment. In this paper we study a setting where the agent may access data from previous control of the system. We present an algorithm, Deep Q-learning from Demonstrations (DQfD), that leverages small sets of demonstration data to massively accelerate the learning process even from relatively small amounts of demonstration data and is able to automatically assess the necessary ratio of demonstration data while learning thanks to a prioritized replay mechanism. DQfD works by combining temporal difference updates with supervised classification of the demonstrator's actions. We show that DQfD has better initial performance than Prioritized Dueling Double Deep Q-Networks (PDD DQN) as it starts with better scores on the first million steps on 41 of 42 games and on average it takes PDD DQN 83 million steps to catch up to DQfD's performance. DQfD learns to out-perform the best demonstration given in 14 of 42 games. In addition, DQfD leverages human demonstrations to achieve state-of-the-art results for 11 games. Finally, we show that DQfD performs better than three related algorithms for incorporating demonstration data into DQN.\n    ",
        "submission_date": "2017-04-12T00:00:00",
        "last_modified_date": "2017-11-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.03738",
        "title": "Counterexample Guided Inductive Optimization",
        "authors": [
            "Rodrigo F. Araujo",
            "Higo F. Albuquerque",
            "Iury V. de Bessa",
            "Lucas C. Cordeiro",
            "Joao Edgar C. Filho"
        ],
        "abstract": "This paper describes three variants of a counterexample guided inductive optimization (CEGIO) approach based on Satisfiability Modulo Theories (SMT) solvers. In particular, CEGIO relies on iterative executions to constrain a verification procedure, in order to perform inductive generalization, based on counterexamples extracted from SMT solvers. CEGIO is able to successfully optimize a wide range of functions, including non-linear and non-convex optimization problems based on SMT solvers, in which data provided by counterexamples are employed to guide the verification engine, thus reducing the optimization domain. The present algorithms are evaluated using a large set of benchmarks typically employed for evaluating optimization techniques. Experimental results show the efficiency and effectiveness of the proposed algorithms, which find the optimal solution in all evaluated benchmarks, while traditional techniques are usually trapped by local minima.\n    ",
        "submission_date": "2017-04-11T00:00:00",
        "last_modified_date": "2017-04-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.03952",
        "title": "Virtual to Real Reinforcement Learning for Autonomous Driving",
        "authors": [
            "Xinlei Pan",
            "Yurong You",
            "Ziyan Wang",
            "Cewu Lu"
        ],
        "abstract": "Reinforcement learning is considered as a promising direction for driving policy learning. However, training autonomous driving vehicle with reinforcement learning in real environment involves non-affordable trial-and-error. It is more desirable to first train in a virtual environment and then transfer to the real environment. In this paper, we propose a novel realistic translation network to make model trained in virtual environment be workable in real world. The proposed network can convert non-realistic virtual image input into a realistic one with similar scene structure. Given realistic frames as input, driving policy trained by reinforcement learning can nicely adapt to real world driving. Experiments show that our proposed virtual to real (VR) reinforcement learning (RL) works pretty well. To our knowledge, this is the first successful case of driving policy trained by reinforcement learning that can adapt to real world driving data.\n    ",
        "submission_date": "2017-04-13T00:00:00",
        "last_modified_date": "2017-09-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.04000",
        "title": "Dempster-Shafer Belief Function - A New Interpretation",
        "authors": [
            "Mieczys\u0142aw K\u0142opotek"
        ],
        "abstract": "We develop our interpretation of the joint belief distribution and of evidential updating that matches the following basic requirements:\n",
        "submission_date": "2017-04-13T00:00:00",
        "last_modified_date": "2017-04-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.04110",
        "title": "DeepAR: Probabilistic Forecasting with Autoregressive Recurrent Networks",
        "authors": [
            "David Salinas",
            "Valentin Flunkert",
            "Jan Gasthaus"
        ],
        "abstract": "Probabilistic forecasting, i.e. estimating the probability distribution of a time series' future given its past, is a key enabler for optimizing business processes. In retail businesses, for example, forecasting demand is crucial for having the right inventory available at the right time at the right place. In this paper we propose DeepAR, a methodology for producing accurate probabilistic forecasts, based on training an auto regressive recurrent network model on a large number of related time series. We demonstrate how by applying deep learning techniques to forecasting, one can overcome many of the challenges faced by widely-used classical approaches to the problem. We show through extensive empirical evaluation on several real-world forecasting data sets accuracy improvements of around 15% compared to state-of-the-art methods.\n    ",
        "submission_date": "2017-04-13T00:00:00",
        "last_modified_date": "2019-02-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.04327",
        "title": "Deep API Programmer: Learning to Program with APIs",
        "authors": [
            "Surya Bhupatiraju",
            "Rishabh Singh",
            "Abdel-rahman Mohamed",
            "Pushmeet Kohli"
        ],
        "abstract": "We present DAPIP, a Programming-By-Example system that learns to program with APIs to perform data transformation tasks. We design a domain-specific language (DSL) that allows for arbitrary concatenations of API outputs and constant strings. The DSL consists of three family of APIs: regular expression-based APIs, lookup APIs, and transformation APIs. We then present a novel neural synthesis algorithm to search for programs in the DSL that are consistent with a given set of examples. The search algorithm uses recently introduced neural architectures to encode input-output examples and to model the program search in the DSL. We show that synthesis algorithm outperforms baseline methods for synthesizing programs on both synthetic and real-world benchmarks.\n    ",
        "submission_date": "2017-04-14T00:00:00",
        "last_modified_date": "2017-04-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.04341",
        "title": "Environment-Independent Task Specifications via GLTL",
        "authors": [
            "Michael L. Littman",
            "Ufuk Topcu",
            "Jie Fu",
            "Charles Isbell",
            "Min Wen",
            "James MacGlashan"
        ],
        "abstract": "We propose a new task-specification language for Markov decision processes that is designed to be an improvement over reward functions by being environment independent. The language is a variant of Linear Temporal Logic (LTL) that is extended to probabilistic specifications in a way that permits approximations to be learned in finite time. We provide several small environments that demonstrate the advantages of our geometric LTL (GLTL) language and illustrate how it can be used to specify standard reinforcement-learning tasks straightforwardly.\n    ",
        "submission_date": "2017-04-14T00:00:00",
        "last_modified_date": "2017-04-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.04408",
        "title": "Incremental learning of high-level concepts by imitation",
        "authors": [
            "Mina Alibeigi",
            "Majid Nili Ahmadabadi",
            "Babak Nadjar Araabi"
        ],
        "abstract": "Nowadays, robots become a companion in everyday life. To be well-accepted by humans, robots should efficiently understand meanings of their partners' motions and body language, and respond accordingly. Learning concepts by imitation brings them this ability in a user-friendly way.\n",
        "submission_date": "2017-04-14T00:00:00",
        "last_modified_date": "2017-04-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.04651",
        "title": "The Reactor: A fast and sample-efficient Actor-Critic agent for Reinforcement Learning",
        "authors": [
            "Audrunas Gruslys",
            "Will Dabney",
            "Mohammad Gheshlaghi Azar",
            "Bilal Piot",
            "Marc Bellemare",
            "Remi Munos"
        ],
        "abstract": "In this work we present a new agent architecture, called Reactor, which combines multiple algorithmic and architectural contributions to produce an agent with higher sample-efficiency than Prioritized Dueling DQN (Wang et al., 2016) and Categorical DQN (Bellemare et al., 2017), while giving better run-time performance than A3C (Mnih et al., 2016). Our first contribution is a new policy evaluation algorithm called Distributional Retrace, which brings multi-step off-policy updates to the distributional reinforcement learning setting. The same approach can be used to convert several classes of multi-step policy evaluation algorithms designed for expected value evaluation into distributional ones. Next, we introduce the \\b{eta}-leave-one-out policy gradient algorithm which improves the trade-off between variance and bias by using action values as a baseline. Our final algorithmic contribution is a new prioritized replay algorithm for sequences, which exploits the temporal locality of neighboring observations for more efficient replay prioritization. Using the Atari 2600 benchmarks, we show that each of these innovations contribute to both the sample efficiency and final agent performance. Finally, we demonstrate that Reactor reaches state-of-the-art performance after 200 million frames and less than a day of training.\n    ",
        "submission_date": "2017-04-15T00:00:00",
        "last_modified_date": "2018-06-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.04664",
        "title": "Online Spatial Concept and Lexical Acquisition with Simultaneous Localization and Mapping",
        "authors": [
            "Akira Taniguchi",
            "Yoshinobu Hagiwara",
            "Tadahiro Taniguchi",
            "Tetsunari Inamura"
        ],
        "abstract": "In this paper, we propose an online learning algorithm based on a Rao-Blackwellized particle filter for spatial concept acquisition and mapping. We have proposed a nonparametric Bayesian spatial concept acquisition model (SpCoA). We propose a novel method (SpCoSLAM) integrating SpCoA and FastSLAM in the theoretical framework of the Bayesian generative model. The proposed method can simultaneously learn place categories and lexicons while incrementally generating an environmental map. Furthermore, the proposed method has scene image features and a language model added to SpCoA. In the experiments, we tested online learning of spatial concepts and environmental maps in a novel environment of which the robot did not have a map. Then, we evaluated the results of online learning of spatial concepts and lexical acquisition. The experimental results demonstrated that the robot was able to more accurately learn the relationships between words and the place in the environmental map incrementally by using the proposed method.\n    ",
        "submission_date": "2017-04-15T00:00:00",
        "last_modified_date": "2018-03-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.04719",
        "title": "FML-based Prediction Agent and Its Application to Game of Go",
        "authors": [
            "Chang-Shing Lee",
            "Mei-Hui Wang",
            "Chia-Hsiu Kao",
            "Sheng-Chi Yang",
            "Yusuke Nojima",
            "Ryosuke Saga",
            "Nan Shuo",
            "Naoyuki Kubota"
        ],
        "abstract": "In this paper, we present a robotic prediction agent including a darkforest Go engine, a fuzzy markup language (FML) assessment engine, an FML-based decision support engine, and a robot engine for game of Go application. The knowledge base and rule base of FML assessment engine are constructed by referring the information from the darkforest Go engine located in NUTN and OPU, for example, the number of MCTS simulations and winning rate prediction. The proposed robotic prediction agent first retrieves the database of Go competition website, and then the FML assessment engine infers the winning possibility based on the information generated by darkforest Go engine. The FML-based decision support engine computes the winning possibility based on the partial game situation inferred by FML assessment engine. Finally, the robot engine combines with the human-friendly robot partner PALRO, produced by Fujisoft incorporated, to report the game situation to human Go players. Experimental results show that the FML-based prediction agent can work effectively.\n    ",
        "submission_date": "2017-04-16T00:00:00",
        "last_modified_date": "2017-04-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.04775",
        "title": "Approximating the Backbone in the Weighted Maximum Satisfiability Problem",
        "authors": [
            "He Jiang",
            "Jifeng Xuan",
            "Yan Hu"
        ],
        "abstract": "The weighted Maximum Satisfiability problem (weighted MAX-SAT) is a NP-hard problem with numerous applications arising in artificial intelligence. As an efficient tool for heuristic design, the backbone has been applied to heuristics design for many NP-hard problems. In this paper, we investigated the computational complexity for retrieving the backbone in weighted MAX-SAT and developed a new algorithm for solving this problem. We showed that it is intractable to retrieve the full backbone under the assumption that . Moreover, it is intractable to retrieve a fixed fraction of the backbone as well. And then we presented a backbone guided local search (BGLS) with Walksat operator for weighted MAX-SAT. BGLS consists of two phases: the first phase samples the backbone information from local optima and the backbone phase conducts local search under the guideline of backbone. Extensive experimental results on the benchmark showed that BGLS outperforms the existing heuristics in both solution quality and runtime.\n    ",
        "submission_date": "2017-04-16T00:00:00",
        "last_modified_date": "2017-04-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.04912",
        "title": "Pseudorehearsal in actor-critic agents",
        "authors": [
            "Marochko Vladimir",
            "Leonard Johard",
            "Manuel Mazzara"
        ],
        "abstract": "Catastrophic forgetting has a serious impact in reinforcement learning, as the data distribution is generally sparse and non-stationary over time. The purpose of this study is to investigate whether pseudorehearsal can increase performance of an actor-critic agent with neural-network based policy selection and function approximation in a pole balancing task and compare different pseudorehearsal approaches. We expect that pseudorehearsal assists learning even in such very simple problems, given proper initialization of the rehearsal parameters.\n    ",
        "submission_date": "2017-04-17T00:00:00",
        "last_modified_date": "2017-04-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.04977",
        "title": "Probabilistic programs for inferring the goals of autonomous agents",
        "authors": [
            "Marco F. Cusumano-Towner",
            "Alexey Radul",
            "David Wingate",
            "Vikash K. Mansinghka"
        ],
        "abstract": "Intelligent systems sometimes need to infer the probable goals of people, cars, and robots, based on partial observations of their motion. This paper introduces a class of probabilistic programs for formulating and solving these problems. The formulation uses randomized path planning algorithms as the basis for probabilistic models of the process by which autonomous agents plan to achieve their goals. Because these path planning algorithms do not have tractable likelihood functions, new inference algorithms are needed. This paper proposes two Monte Carlo techniques for these \"likelihood-free\" models, one of which can use likelihood estimates from neural networks to accelerate inference. The paper demonstrates efficacy on three simple examples, each using under 50 lines of probabilistic code.\n    ",
        "submission_date": "2017-04-17T00:00:00",
        "last_modified_date": "2017-04-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.05017",
        "title": "Morpheo: Traceable Machine Learning on Hidden data",
        "authors": [
            "Mathieu Galtier",
            "Camille Marini"
        ],
        "abstract": "Morpheo is a transparent and secure machine learning platform collecting and analysing large datasets. It aims at building state-of-the art prediction models in various fields where data are sensitive. Indeed, it offers strong privacy of data and algorithm, by preventing anyone to read the data, apart from the owner and the chosen algorithms. Computations in Morpheo are orchestrated by a blockchain infrastructure, thus offering total traceability of operations. Morpheo aims at building an attractive economic ecosystem around data prediction by channelling crypto-money from prediction requests to useful data and algorithms providers. Morpheo is designed to handle multiple data sources in a transfer learning approach in order to mutualize knowledge acquired from large datasets for applications with smaller but similar datasets.\n    ",
        "submission_date": "2017-04-17T00:00:00",
        "last_modified_date": "2017-04-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.05295",
        "title": "Semantic Similarity from Natural Language and Ontology Analysis",
        "authors": [
            "S\u00e9bastien Harispe",
            "Sylvie Ranwez",
            "Stefan Janaqi",
            "Jacky Montmain"
        ],
        "abstract": "Artificial Intelligence federates numerous scientific fields in the aim of developing machines able to assist human operators performing complex treatments -- most of which demand high cognitive skills (e.g. learning or decision processes). Central to this quest is to give machines the ability to estimate the likeness or similarity between things in the way human beings estimate the similarity between stimuli.\n",
        "submission_date": "2017-04-18T00:00:00",
        "last_modified_date": "2017-04-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.05325",
        "title": "Anomaly detection and motif discovery in symbolic representations of time series",
        "authors": [
            "Fabio Guigou",
            "Pierre Collet",
            "Pierre Parrend"
        ],
        "abstract": "The advent of the Big Data hype and the consistent recollection of event logs and real-time data from sensors, monitoring software and machine configuration has generated a huge amount of time-varying data in about every sector of the industry. Rule-based processing of such data has ceased to be relevant in many scenarios where anomaly detection and pattern mining have to be entirely accomplished by the machine. Since the early 2000s, the de-facto standard for representing time series has been the Symbolic Aggregate approXimation (SAX).In this document, we present a few algorithms using this representation for anomaly detection and motif discovery, also known as pattern mining, in such data. We propose a benchmark of anomaly detection algorithms using data from Cloud monitoring software.\n    ",
        "submission_date": "2017-04-18T00:00:00",
        "last_modified_date": "2017-04-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.05356",
        "title": "Understanding Negations in Information Processing: Learning from Replicating Human Behavior",
        "authors": [
            "Nicolas Pr\u00f6llochs",
            "Stefan Feuerriegel",
            "Dirk Neumann"
        ],
        "abstract": "Information systems experience an ever-growing volume of unstructured data, particularly in the form of textual materials. This represents a rich source of information from which one can create value for people, organizations and businesses. For instance, recommender systems can benefit from automatically understanding preferences based on user reviews or social media. However, it is difficult for computer programs to correctly infer meaning from narrative content. One major challenge is negations that invert the interpretation of words and sentences. As a remedy, this paper proposes a novel learning strategy to detect negations: we apply reinforcement learning to find a policy that replicates the human perception of negations based on an exogenous response, such as a user rating for reviews. Our method yields several benefits, as it eliminates the former need for expensive and subjective manual labeling in an intermediate stage. Moreover, the inferred policy can be used to derive statistical inferences and implications regarding how humans process and act on negations.\n    ",
        "submission_date": "2017-04-18T00:00:00",
        "last_modified_date": "2017-04-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.05392",
        "title": "Synergy of all-purpose static solver and temporal reasoning tools in dynamic integrated expert systems",
        "authors": [
            "Galina Rybina",
            "Alexey Mozgachev",
            "Dmitry Demidov"
        ],
        "abstract": "The paper discusses scientific and technological problems of dynamic integrated expert systems development. Extensions of problem-oriented methodology for dynamic integrated expert systems development are considered. Attention is paid to the temporal knowledge representation and processing.\n    ",
        "submission_date": "2017-04-16T00:00:00",
        "last_modified_date": "2017-04-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.05495",
        "title": "Investigating Recurrence and Eligibility Traces in Deep Q-Networks",
        "authors": [
            "Jean Harb",
            "Doina Precup"
        ],
        "abstract": "Eligibility traces in reinforcement learning are used as a bias-variance trade-off and can often speed up training time by propagating knowledge back over time-steps in a single update. We investigate the use of eligibility traces in combination with recurrent networks in the Atari domain. We illustrate the benefits of both recurrent nets and eligibility traces in some Atari games, and highlight also the importance of the optimization used in the training.\n    ",
        "submission_date": "2017-04-18T00:00:00",
        "last_modified_date": "2017-04-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.05539",
        "title": "Beating Atari with Natural Language Guided Reinforcement Learning",
        "authors": [
            "Russell Kaplan",
            "Christopher Sauer",
            "Alexander Sosa"
        ],
        "abstract": "We introduce the first deep reinforcement learning agent that learns to beat Atari games with the aid of natural language instructions. The agent uses a multimodal embedding between environment observations and natural language to self-monitor progress through a list of English instructions, granting itself reward for completing instructions in addition to increasing the game score. Our agent significantly outperforms Deep Q-Networks (DQNs), Asynchronous Advantage Actor-Critic (A3C) agents, and the best agents posted to OpenAI Gym on what is often considered the hardest Atari 2600 environment: Montezuma's Revenge.\n    ",
        "submission_date": "2017-04-18T00:00:00",
        "last_modified_date": "2017-04-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.05569",
        "title": "Using Contexts and Constraints for Improved Geotagging of Human Trafficking Webpages",
        "authors": [
            "Rahul Kapoor",
            "Mayank Kejriwal",
            "Pedro Szekely"
        ],
        "abstract": "Extracting geographical tags from webpages is a well-motivated application in many domains. In illicit domains with unusual language models, like human trafficking, extracting geotags with both high precision and recall is a challenging problem. In this paper, we describe a geotag extraction framework in which context, constraints and the openly available Geonames knowledge base work in tandem in an Integer Linear Programming (ILP) model to achieve good performance. In preliminary empirical investigations, the framework improves precision by 28.57% and F-measure by 36.9% on a difficult human trafficking geotagging task compared to a machine learning-based baseline. The method is already being integrated into an existing knowledge base construction system widely used by US law enforcement agencies to combat human trafficking.\n    ",
        "submission_date": "2017-04-19T00:00:00",
        "last_modified_date": "2017-04-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.05572",
        "title": "Answering Complex Questions Using Open Information Extraction",
        "authors": [
            "Tushar Khot",
            "Ashish Sabharwal",
            "Peter Clark"
        ],
        "abstract": "While there has been substantial progress in factoid question-answering (QA), answering complex questions remains challenging, typically requiring both a large body of knowledge and inference techniques. Open Information Extraction (Open IE) provides a way to generate semi-structured knowledge for QA, but to date such knowledge has only been used to answer simple questions with retrieval-based methods. We overcome this limitation by presenting a method for reasoning with Open IE knowledge, allowing more complex questions to be handled. Using a recently proposed support graph optimization framework for QA, we develop a new inference model for Open IE, in particular one that can work effectively with multiple short facts, noise, and the relational structure of tuples. Our model significantly outperforms a state-of-the-art structured solver on complex questions of varying difficulty, while also removing the reliance on manually curated knowledge.\n    ",
        "submission_date": "2017-04-19T00:00:00",
        "last_modified_date": "2017-04-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.05692",
        "title": "A multi-method simulation of a high-frequency bus line using AnyLogic",
        "authors": [
            "Thierry van der Spek"
        ],
        "abstract": "In this work a mixed agent-based and discrete event simulation model is developed for a high frequency bus route in the Netherlands. With this model, different passenger growth scenarios can be easily evaluated. This simulation model helps policy makers to predict changes that have to be made to bus routes and planned travel times before problems occur. The model is validated using several performance indicators, showing that under some model assumptions, it can realistically simulate real-life situations. The simulation's workings are illustrated by two use cases.\n    ",
        "submission_date": "2017-04-19T00:00:00",
        "last_modified_date": "2017-04-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.05904",
        "title": "Realizing an optimization approach inspired from Piagets theory on cognitive development",
        "authors": [
            "Utku Kose",
            "Ahmet Arslan"
        ],
        "abstract": "The objective of this paper is to introduce an artificial intelligence based optimization approach, which is inspired from Piagets theory on cognitive development. The approach has been designed according to essential processes that an individual may experience while learning something new or improving his / her knowledge. These processes are associated with the Piagets ideas on an individuals cognitive development. The approach expressed in this paper is a simple algorithm employing swarm intelligence oriented tasks in order to overcome single-objective optimization problems. For evaluating effectiveness of this early version of the algorithm, test operations have been done via some benchmark functions. The obtained results show that the approach / algorithm can be an alternative to the literature in terms of single-objective optimization. The authors have suggested the name: Cognitive Development Optimization Algorithm (CoDOA) for the related intelligent optimization approach.\n    ",
        "submission_date": "2017-04-03T00:00:00",
        "last_modified_date": "2017-04-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.06084",
        "title": "Knowledge Fusion via Embeddings from Text, Knowledge Graphs, and Images",
        "authors": [
            "Steffen Thoma",
            "Achim Rettinger",
            "Fabian Both"
        ],
        "abstract": "We present a baseline approach for cross-modal knowledge fusion. Different basic fusion methods are evaluated on existing embedding approaches to show the potential of joining knowledge about certain concepts across modalities in a fused concept representation.\n    ",
        "submission_date": "2017-04-20T00:00:00",
        "last_modified_date": "2017-04-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.06096",
        "title": "The Dependent Doors Problem: An Investigation into Sequential Decisions without Feedback",
        "authors": [
            "Amos Korman",
            "Yoav Rodeh"
        ],
        "abstract": "We introduce the dependent doors problem as an abstraction for situations in which one must perform a sequence of possibly dependent decisions, without receiving  feedback information on the effectiveness of previously made actions. Informally, the problem considers a set of $d$ doors that are initially closed, and the aim is to open all of them as fast as possible. To open a door, the algorithm knocks on it and it might open or not according to some probability distribution. This distribution may depend on which other doors are currently open, as well as on which other doors were open during each of the previous knocks on that door. The algorithm aims to minimize the expected time until all doors open. Crucially, it must act at any time without knowing whether or which other doors have already opened. In this work, we focus on scenarios where  dependencies between doors are both positively correlated and ",
        "submission_date": "2017-04-20T00:00:00",
        "last_modified_date": "2017-04-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.06131",
        "title": "Learning to Acquire Information",
        "authors": [
            "Yewen Pu",
            "Leslie P Kaelbling",
            "Armando Solar-Lezama"
        ],
        "abstract": "We consider the problem of diagnosis where a set of simple observations are used to infer a potentially complex hidden hypothesis. Finding the optimal subset of observations is intractable in general, thus we focus on the problem of active diagnosis, where the agent selects the next most-informative observation based on the results of previous observations. We show that under the assumption of uniform observation entropy, one can build an implication model which directly predicts the outcome of the potential next observation conditioned on the results of past observations, and selects the observation with the maximum entropy. This approach enjoys reduced computation complexity by bypassing the complicated hypothesis space, and can be trained on observation data alone, learning how to query without knowledge of the hidden hypothesis.\n    ",
        "submission_date": "2017-04-20T00:00:00",
        "last_modified_date": "2017-07-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.06300",
        "title": "A Reinforcement Learning Approach to Weaning of Mechanical Ventilation in Intensive Care Units",
        "authors": [
            "Niranjani Prasad",
            "Li-Fang Cheng",
            "Corey Chivers",
            "Michael Draugelis",
            "Barbara E Engelhardt"
        ],
        "abstract": "The management of invasive mechanical ventilation, and the regulation of sedation and analgesia during ventilation, constitutes a major part of the care of patients admitted to intensive care units. Both prolonged dependence on mechanical ventilation and premature extubation are associated with increased risk of complications and higher hospital costs, but clinical opinion on the best protocol for weaning patients off of a ventilator varies. This work aims to develop a decision support tool that uses available patient information to predict time-to-extubation readiness and to recommend a personalized regime of sedation dosage and ventilator support. To this end, we use off-policy reinforcement learning algorithms to determine the best action at a given patient state from sub-optimal historical ICU data. We compare treatment policies from fitted Q-iteration with extremely randomized trees and with feedforward neural networks, and demonstrate that the policies learnt show promise in recommending weaning protocols with improved outcomes, in terms of minimizing rates of reintubation and regulating physiological stability.\n    ",
        "submission_date": "2017-04-20T00:00:00",
        "last_modified_date": "2017-04-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.06498",
        "title": "Time Series Prediction for Graphs in Kernel and Dissimilarity Spaces",
        "authors": [
            "Benjamin Paa\u00dfen",
            "Christina G\u00f6pfert",
            "Barbara Hammer"
        ],
        "abstract": "Graph models are relevant in many fields, such as distributed computing, intelligent tutoring systems or social network analysis. In many cases, such models need to take changes in the graph structure into account, i.e. a varying number of nodes or edges. Predicting such changes within graphs can be expected to yield important insight with respect to the underlying dynamics, e.g. with respect to user behaviour. However, predictive techniques in the past have almost exclusively focused on single edges or nodes. In this contribution, we attempt to predict the future state of a graph as a whole. We propose to phrase time series prediction as a regression problem and apply dissimilarity- or kernel-based regression techniques, such as 1-nearest neighbor, kernel regression and Gaussian process regression, which can be applied to graphs via graph kernels. The output of the regression is a point embedded in a pseudo-Euclidean space, which can be analyzed using subsequent dissimilarity- or kernel-based processing methods. We discuss strategies to speed up Gaussian Processes regression from cubic to linear time and evaluate our approach on two well-established theoretical models of graph evolution as well as two real data sets from the domain of intelligent tutoring systems. We find that simple regression methods, such as kernel regression, are sufficient to capture the dynamics in the theoretical models, but that Gaussian process regression significantly improves the prediction error for real-world data.\n    ",
        "submission_date": "2017-04-21T00:00:00",
        "last_modified_date": "2017-08-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.06616",
        "title": "Accurately and Efficiently Interpreting Human-Robot Instructions of Varying Granularities",
        "authors": [
            "Dilip Arumugam",
            "Siddharth Karamcheti",
            "Nakul Gopalan",
            "Lawson L.S. Wong",
            "Stefanie Tellex"
        ],
        "abstract": "Humans can ground natural language commands to tasks at both abstract and fine-grained levels of specificity. For instance, a human forklift operator can be instructed to perform a high-level action, like \"grab a pallet\" or a low-level action like \"tilt back a little bit.\" While robots are also capable of grounding language commands to tasks, previous methods implicitly assume that all commands and tasks reside at a single, fixed level of abstraction. Additionally, methods that do not use multiple levels of abstraction encounter inefficient planning and execution times as they solve tasks at a single level of abstraction with large, intractable state-action spaces closely resembling real world complexity. In this work, by grounding commands to all the tasks or subtasks available in a hierarchical planning framework, we arrive at a model capable of interpreting language at multiple levels of specificity ranging from coarse to more granular. We show that the accuracy of the grounding procedure is improved when simultaneously inferring the degree of abstraction in language used to communicate the task. Leveraging hierarchy also improves efficiency: our proposed approach enables a robot to respond to a command within one second on 90% of our tasks, while baselines take over twenty seconds on half the tasks. Finally, we demonstrate that a real, physical robot can ground commands at multiple levels of abstraction allowing it to efficiently plan different subtasks within the same planning hierarchy.\n    ",
        "submission_date": "2017-04-21T00:00:00",
        "last_modified_date": "2018-06-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.06621",
        "title": "A hybrid spatial data mining approach based on fuzzy topological relations and MOSES evolutionary algorithm",
        "authors": [
            "Amir Hossein Goudarzi",
            "Nasser Ghadiri"
        ],
        "abstract": "Making high-quality decisions in strategic spatial planning is heavily dependent on extracting knowledge from vast amounts of data. Although many decision-making problems like developing urban areas require such perception and reasoning, existing methods in this field usually neglect the deep knowledge mined from geographic databases and are based on pure statistical methods. Due to the large volume of data gathered in spatial databases, and the uncertainty of spatial objects, mining association rules for high-level knowledge representation is a challenging task. Few algorithms manage geographical and non-geographical data using topological relations. In this paper, a novel approach for spatial data mining based on the MOSES evolutionary framework is presented which improves the classic genetic programming approach. A hybrid architecture called GGeo is proposed to apply the MOSES mining rules considering fuzzy topological relations from spatial data. The uncertainty and fuzziness aspects are addressed using an enriched model of topological relations by fuzzy region connection calculus. Moreover, to overcome the problem of time-consuming fuzzy topological relationships calculations, this a novel data pre-processing method is offered. GGeo analyses and learns from geographical and non-geographical data and uses topological and distance parameters, and returns a series of arithmetic-spatial formulas as classification rules. The proposed approach is resistant to noisy data, and all its stages run in parallel to increase speed. This approach may be used in different spatial data classification problems as well as representing an appropriate method of data analysis and economic policy making.\n    ",
        "submission_date": "2017-04-21T00:00:00",
        "last_modified_date": "2017-04-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.06654",
        "title": "Governing Governance: A Formal Framework for Analysing Institutional Design and Enactment Governance",
        "authors": [
            "Thomas C. King"
        ],
        "abstract": "This dissertation is motivated by the need, in today's globalist world, for a precise way to enable governments, organisations and other regulatory bodies to evaluate the constraints they place on themselves and others. An organisation's modus operandi is enacting and fulfilling contracts between itself and its participants. Yet, organisational contracts should respect external laws, such as those setting out data privacy rights and liberties. Contracts can only be enacted by following contract law processes, which often require bilateral agreement and consideration. Governments need to legislate whilst understanding today's context of national and international governance hierarchy where law makers shun isolationism and seek to influence one another. Governments should avoid punishment by respecting constraints from international treaties and human rights charters. Governments can only enact legislation by following their own, pre-existing, law making procedures. In other words, institutions, such as laws and contracts are designed and enacted under constraints.\n    ",
        "submission_date": "2017-04-21T00:00:00",
        "last_modified_date": "2017-04-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.06676",
        "title": "Modular Multi-Objective Deep Reinforcement Learning with Decision Values",
        "authors": [
            "Tomasz Tajmajer"
        ],
        "abstract": "In this work we present a method for using Deep Q-Networks (DQNs) in multi-objective environments. Deep Q-Networks provide remarkable performance in single objective problems learning from high-level visual state representations. However, in many scenarios (e.g in robotics, games), the agent needs to pursue multiple objectives simultaneously. We propose an architecture in which separate DQNs are used to control the agent's behaviour with respect to particular objectives. In this architecture we introduce decision values to improve the scalarization of multiple DQNs into a single action. Our architecture enables the decomposition of the agent's behaviour into controllable and replaceable sub-behaviours learned by distinct modules. Moreover, it allows to change the priorities of particular objectives post-learning, while preserving the overall performance of the agent. To evaluate our solution we used a game-like simulator in which an agent - provided with high-level visual input - pursues multiple objectives in a 2D world.\n    ",
        "submission_date": "2017-04-21T00:00:00",
        "last_modified_date": "2018-02-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.06942",
        "title": "Population Seeding Techniques for Rolling Horizon Evolution in General Video Game Playing",
        "authors": [
            "Rauca D. Gaina",
            "Simon M. Lucas",
            "Diego Perez-Liebana"
        ],
        "abstract": "While Monte Carlo Tree Search and closely related methods have dominated General Video Game Playing, recent research has demonstrated the promise of Rolling Horizon Evolutionary Algorithms as an interesting alternative. However, there is little attention paid to population initialization techniques in the setting of general real-time video games. Therefore, this paper proposes the use of population seeding to improve the performance of Rolling Horizon Evolution and presents the results of two methods, One Step Look Ahead and Monte Carlo Tree Search, tested on 20 games of the General Video Game AI corpus with multiple evolution parameter values (population size and individual length). An in-depth analysis is carried out between the results of the seeding methods and the vanilla Rolling Horizon Evolution. In addition, the paper presents a comparison to a Monte Carlo Tree Search algorithm. The results are promising, with seeding able to boost performance significantly over baseline evolution and even match the high level of play obtained by the Monte Carlo Tree Search.\n    ",
        "submission_date": "2017-04-23T00:00:00",
        "last_modified_date": "2017-04-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.06945",
        "title": "General Video Game AI: Learning from Screen Capture",
        "authors": [
            "Kamolwan Kunanusont",
            "Simon M. Lucas",
            "Diego Perez-Liebana"
        ],
        "abstract": "General Video Game Artificial Intelligence is a general game playing framework for Artificial General Intelligence research in the video-games domain. In this paper, we propose for the first time a screen capture learning agent for General Video Game AI framework. A Deep Q-Network algorithm was applied and improved to develop an agent capable of learning to play different games in the framework. After testing this algorithm using various games of different categories and difficulty levels, the results suggest that our proposed screen capture learning agent has the potential to learn many different games using only a single learning algorithm.\n    ",
        "submission_date": "2017-04-23T00:00:00",
        "last_modified_date": "2017-04-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.07069",
        "title": "Evaluating and Modelling Hanabi-Playing Agents",
        "authors": [
            "Joseph Walton-Rivers",
            "Piers R. Williams",
            "Richard Bartle",
            "Diego Perez-Liebana",
            "Simon M. Lucas"
        ],
        "abstract": "Agent modelling involves considering how other agents will behave, in order to influence your own actions. In this paper, we explore the use of agent modelling in the hidden-information, collaborative card game Hanabi. We implement a number of rule-based agents, both from the literature and of our own devising, in addition to an Information Set Monte Carlo Tree Search (IS-MCTS) agent. We observe poor results from IS-MCTS, so construct a new, predictor version that uses a model of the agents with which it is paired. We observe a significant improvement in game-playing strength from this agent in comparison to IS-MCTS, resulting from its consideration of what the other agents in a game would do. In addition, we create a flawed rule-based agent to highlight the predictor's capabilities with such an agent.\n    ",
        "submission_date": "2017-04-24T00:00:00",
        "last_modified_date": "2017-04-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.07075",
        "title": "Analysis of Vanilla Rolling Horizon Evolution Parameters in General Video Game Playing",
        "authors": [
            "Raluca D. Gaina",
            "Jialin Liu",
            "Simon M. Lucas",
            "Diego Perez-Liebana"
        ],
        "abstract": "Monte Carlo Tree Search techniques have generally dominated General Video Game Playing, but recent research has started looking at Evolutionary Algorithms and their potential at matching Tree Search level of play or even outperforming these methods. Online or Rolling Horizon Evolution is one of the options available to evolve sequences of actions for planning in General Video Game Playing, but no research has been done up to date that explores the capabilities of the vanilla version of this algorithm in multiple games. This study aims to critically analyse the different configurations regarding population size and individual length in a set of 20 games from the General Video Game AI corpus. Distinctions are made between deterministic and stochastic games, and the implications of using superior time budgets are studied. Results show that there is scope for the use of these techniques, which in some configurations outperform Monte Carlo Tree Search, and also suggest that further research in these methods could boost their performance.\n    ",
        "submission_date": "2017-04-24T00:00:00",
        "last_modified_date": "2017-04-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.07183",
        "title": "Stochastic Constraint Programming as Reinforcement Learning",
        "authors": [
            "Steven Prestwich",
            "Roberto Rossi",
            "Armagan Tarim"
        ],
        "abstract": "Stochastic Constraint Programming (SCP) is an extension of Constraint Programming (CP) used for modelling and solving problems involving constraints and uncertainty. SCP inherits excellent modelling abilities and filtering algorithms from CP, but so far it has not been applied to large problems. Reinforcement Learning (RL) extends Dynamic Programming to large stochastic problems, but is problem-specific and has no generic solvers. We propose a hybrid combining the scalability of RL with the modelling and constraint filtering methods of CP. We implement a prototype in a CP system and demonstrate its usefulness on SCP problems.\n    ",
        "submission_date": "2017-04-24T00:00:00",
        "last_modified_date": "2017-04-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.07466",
        "title": "Learning from Ontology Streams with Semantic Concept Drift",
        "authors": [
            "Freddy Lecue",
            "Jiaoyan Chen",
            "Jeff Pan",
            "Huajun Chen"
        ],
        "abstract": "Data stream learning has been largely studied for extracting knowledge structures from continuous and rapid data records. In the semantic Web, data is interpreted in ontologies and its ordered sequence is represented as an ontology stream. Our work exploits the semantics of such streams to tackle the problem of concept drift i.e., unexpected changes in data distribution, causing most of models to be less accurate as time passes. To this end we revisited (i) semantic inference in the context of supervised stream learning, and (ii) models with semantic embeddings. The experiments show accurate prediction with data from Dublin and Beijing.\n    ",
        "submission_date": "2017-04-24T00:00:00",
        "last_modified_date": "2017-04-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.07498",
        "title": "Leveraging Patient Similarity and Time Series Data in Healthcare Predictive Models",
        "authors": [
            "Mohammad Amin Morid",
            "Olivia R. Liu Sheng",
            "Samir Abdelrahman"
        ],
        "abstract": "Patient time series classification faces challenges in high degrees of dimensionality and missingness. In light of patient similarity theory, this study explores effective temporal feature engineering and reduction, missing value imputation, and change point detection methods that can afford similarity-based classification models with desirable accuracy enhancement. We select a piecewise aggregation approximation method to extract fine-grain temporal features and propose a minimalist method to impute missing values in temporal features. For dimensionality reduction, we adopt a gradient descent search method for feature weight assignment. We propose new patient status and directional change definitions based on medical knowledge or clinical guidelines about the value ranges for different patient status levels, and develop a method to detect change points indicating positive or negative patient status changes. We evaluate the effectiveness of the proposed methods in the context of early Intensive Care Unit mortality prediction. The evaluation results show that the k-Nearest Neighbor algorithm that incorporates methods we select and propose significantly outperform the relevant benchmarks for early ICU mortality prediction. This study makes contributions to time series classification and early ICU mortality prediction via identifying and enhancing temporal feature engineering and reduction methods for similarity-based time series classification.\n    ",
        "submission_date": "2017-04-25T00:00:00",
        "last_modified_date": "2017-04-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.07503",
        "title": "Learning of Human-like Algebraic Reasoning Using Deep Feedforward Neural Networks",
        "authors": [
            "Cheng-Hao Cai",
            "Dengfeng Ke",
            "Yanyan Xu",
            "Kaile Su"
        ],
        "abstract": "There is a wide gap between symbolic reasoning and deep learning. In this research, we explore the possibility of using deep learning to improve symbolic reasoning. Briefly, in a reasoning system, a deep feedforward neural network is used to guide rewriting processes after learning from algebraic reasoning examples produced by humans. To enable the neural network to recognise patterns of algebraic expressions with non-deterministic sizes, reduced partial trees are used to represent the expressions. Also, to represent both top-down and bottom-up information of the expressions, a centralisation technique is used to improve the reduced partial trees. Besides, symbolic association vectors and rule application records are used to improve the rewriting processes. Experimental results reveal that the algebraic reasoning examples can be accurately learnt only if the feedforward neural network has enough hidden layers. Also, the centralisation technique, the symbolic association vectors and the rule application records can reduce error rates of reasoning. In particular, the above approaches have led to 4.6% error rate of reasoning on a dataset of linear equations, differentials and integrals.\n    ",
        "submission_date": "2017-04-25T00:00:00",
        "last_modified_date": "2017-04-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.07538",
        "title": "Path Planning with Kinematic Constraints for Robot Groups",
        "authors": [
            "Wolfgang H\u00f6nig",
            "T. K. Satish Kumar",
            "Liron Cohen",
            "Hang Ma",
            "Sven Koenig",
            "Nora Ayanian"
        ],
        "abstract": "Path planning for multiple robots is well studied in the AI and robotics communities. For a given discretized environment, robots need to find collision-free paths to a set of specified goal locations. Robots can be fully anonymous, non-anonymous, or organized in groups. Although powerful solvers for this abstract problem exist, they make simplifying assumptions by ignoring kinematic constraints, making it difficult to use the resulting plans on actual robots. In this paper, we present a solution which takes kinematic constraints, such as maximum velocities, into account, while guaranteeing a user-specified minimum safety distance between robots. We demonstrate our approach in simulation and on real robots in 2D and 3D environments.\n    ",
        "submission_date": "2017-04-25T00:00:00",
        "last_modified_date": "2017-04-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.07548",
        "title": "Semi-supervised Bayesian Deep Multi-modal Emotion Recognition",
        "authors": [
            "Changde Du",
            "Changying Du",
            "Jinpeng Li",
            "Wei-long Zheng",
            "Bao-liang Lu",
            "Huiguang He"
        ],
        "abstract": "In emotion recognition, it is difficult to recognize human's emotional states using just a single modality. Besides, the annotation of physiological emotional data is particularly expensive. These two aspects make the building of effective emotion recognition model challenging. In this paper, we first build a multi-view deep generative model to simulate the generative process of multi-modality emotional data. By imposing a mixture of Gaussians assumption on the posterior approximation of the latent variables, our model can learn the shared deep representation from multiple modalities. To solve the labeled-data-scarcity problem, we further extend our multi-view model to semi-supervised learning scenario by casting the semi-supervised classification problem as a specialized missing data imputation task. Our semi-supervised multi-view deep generative framework can leverage both labeled and unlabeled data from multiple modalities, where the weight factor for each modality can be learned automatically. Compared with previous emotion recognition methods, our method is more robust and flexible. The experiments conducted on two real multi-modal emotion datasets have demonstrated the superiority of our framework over a number of competitors.\n    ",
        "submission_date": "2017-04-25T00:00:00",
        "last_modified_date": "2017-04-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.07555",
        "title": "Molecular De Novo Design through Deep Reinforcement Learning",
        "authors": [
            "Marcus Olivecrona",
            "Thomas Blaschke",
            "Ola Engkvist",
            "Hongming Chen"
        ],
        "abstract": "This work introduces a method to tune a sequence-based generative model for molecular de novo design that through augmented episodic likelihood can learn to generate structures with certain specified desirable properties. We demonstrate how this model can execute a range of tasks such as generating analogues to a query structure and generating compounds predicted to be active against a biological target. As a proof of principle, the model is first trained to generate molecules that do not contain sulphur. As a second example, the model is trained to generate analogues to the drug Celecoxib, a technique that could be used for scaffold hopping or library expansion starting from a single molecule. Finally, when tuning the model towards generating compounds predicted to be active against the dopamine receptor type 2, the model generates structures of which more than 95% are predicted to be active, including experimentally confirmed actives that have not been included in either the generative model nor the activity prediction model.\n    ",
        "submission_date": "2017-04-25T00:00:00",
        "last_modified_date": "2017-08-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.07575",
        "title": "Sharing deep generative representation for perceived image reconstruction from human brain activity",
        "authors": [
            "Changde Du",
            "Changying Du",
            "Huiguang He"
        ],
        "abstract": "Decoding human brain activities via functional magnetic resonance imaging (fMRI) has gained increasing attention in recent years. While encouraging results have been reported in brain states classification tasks, reconstructing the details of human visual experience still remains difficult. Two main challenges that hinder the development of effective models are the perplexing fMRI measurement noise and the high dimensionality of limited data instances. Existing methods generally suffer from one or both of these issues and yield dissatisfactory results. In this paper, we tackle this problem by casting the reconstruction of visual stimulus as the Bayesian inference of missing view in a multiview latent variable model. Sharing a common latent representation, our joint generative model of external stimulus and brain response is not only \"deep\" in extracting nonlinear features from visual images, but also powerful in capturing correlations among voxel activities of fMRI recordings. The nonlinearity and deep structure endow our model with strong representation ability, while the correlations of voxel activities are critical for suppressing noise and improving prediction. We devise an efficient variational Bayesian method to infer the latent variables and the model parameters. To further improve the reconstruction accuracy, the latent representations of testing instances are enforced to be close to that of their neighbours from the training set via posterior regularization. Experiments on three fMRI recording datasets demonstrate that our approach can more accurately reconstruct visual stimuli.\n    ",
        "submission_date": "2017-04-25T00:00:00",
        "last_modified_date": "2017-07-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.07626",
        "title": "Taxonomy Induction using Hypernym Subsequences",
        "authors": [
            "Amit Gupta",
            "R\u00e9mi Lebret",
            "Hamza Harkous",
            "Karl Aberer"
        ],
        "abstract": "We propose a novel, semi-supervised approach towards domain taxonomy induction from an input vocabulary of seed terms. Unlike all previous approaches, which typically extract direct hypernym edges for terms, our approach utilizes a novel probabilistic framework to extract hypernym subsequences. Taxonomy induction from extracted subsequences is cast as an instance of the minimumcost flow problem on a carefully designed directed graph. Through experiments, we demonstrate that our approach outperforms stateof- the-art taxonomy induction approaches across four languages. Importantly, we also show that our approach is robust to the presence of noise in the input vocabulary. To the best of our knowledge, no previous approaches have been empirically proven to manifest noise-robustness in the input vocabulary.\n    ",
        "submission_date": "2017-04-25T00:00:00",
        "last_modified_date": "2017-09-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.07899",
        "title": "Reinforcement Learning-based Thermal Comfort Control for Vehicle Cabins",
        "authors": [
            "James Brusey",
            "Diana Hintea",
            "Elena Gaura",
            "Neil Beloe"
        ],
        "abstract": "Vehicle climate control systems aim to keep passengers thermally comfortable. However, current systems control temperature rather than thermal comfort and tend to be energy hungry, which is of particular concern when considering electric vehicles. This paper poses energy-efficient vehicle comfort control as a Markov Decision Process, which is then solved numerically using Sarsa({\\lambda}) and an empirically validated, single-zone, 1D thermal model of the cabin. The resulting controller was tested in simulation using 200 randomly selected scenarios and found to exceed the performance of bang-bang, proportional, simple fuzzy logic, and commercial controllers with 23%, 43%, 40%, 56% increase, respectively. Compared to the next best performing controller, energy consumption is reduced by 13% while the proportion of time spent thermally comfortable is increased by 23%. These results indicate that this is a viable approach that promises to translate into substantial comfort and energy improvements in the car.\n    ",
        "submission_date": "2017-04-25T00:00:00",
        "last_modified_date": "2017-09-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.07926",
        "title": "From Language to Programs: Bridging Reinforcement Learning and Maximum Marginal Likelihood",
        "authors": [
            "Kelvin Guu",
            "Panupong Pasupat",
            "Evan Zheran Liu",
            "Percy Liang"
        ],
        "abstract": "Our goal is to learn a semantic parser that maps natural language utterances into executable programs when only indirect supervision is available: examples are labeled with the correct execution result, but not the program itself. Consequently, we must search the space of programs for those that output the correct result, while not being misled by spurious programs: incorrect programs that coincidentally output the correct result. We connect two common learning paradigms, reinforcement learning (RL) and maximum marginal likelihood (MML), and then present a new learning algorithm that combines the strengths of both. The new algorithm guards against spurious programs by combining the systematic search traditionally employed in MML with the randomized exploration of RL, and by updating parameters such that probability is spread more evenly across consistent programs. We apply our learning algorithm to a new neural semantic parser and show significant gains over existing state-of-the-art results on a recent context-dependent semantic parsing task.\n    ",
        "submission_date": "2017-04-25T00:00:00",
        "last_modified_date": "2017-04-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.07950",
        "title": "Structured Production System (extended abstract)",
        "authors": [
            "Yi Zhou"
        ],
        "abstract": "In this extended abstract, we propose Structured Production Systems (SPS), which extend traditional production systems with well-formed syntactic structures. Due to the richness of structures, structured production systems significantly enhance the expressive power as well as the flexibility of production systems, for instance, to handle uncertainty. We show that different rule application strategies can be reduced into the basic one by utilizing structures. Also, many fundamental approaches in computer science, including automata, grammar and logic, can be captured by structured production systems.\n    ",
        "submission_date": "2017-04-26T00:00:00",
        "last_modified_date": "2017-04-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.08111",
        "title": "A Popperian Falsification of Artificial Intelligence -- Lighthill Defended",
        "authors": [
            "Steven Meyer"
        ],
        "abstract": "The area of computation called artificial intelligence (AI) is falsified by describing a previous 1972 falsification of AI by British mathematical physicist James Lighthill. How Lighthill's arguments continue to apply to current AI is explained. It is argued that AI should use the Popperian scientific method in which it is the duty of scientists to attempt to falsify theories and if theories are falsified to replace or modify them. The paper describes the Popperian method and discusses Paul Nurse's application of the method to cell biology that also involves questions of mechanism and behavior. It is shown how Lighthill's falsifying arguments especially combinatorial explosion continue to apply to modern AI. Various skeptical arguments against the assumptions of AI mostly by physicists especially against Hilbert's philosophical programme that defined knowledge and truth as provable formal sentences. John von Neumann's arguments from natural complexity against neural networks and evolutionary algorithms are discussed. Next the game of chess is discussed to show how modern chess experts have reacted to computer chess programs. It is shown that currently chess masters can defeat any chess program using Kasperov's arguments from his 1997 Deep Blue match and aftermath. The game of 'go' and climate models are discussed to show computer applications where combinatorial explosion may not apply. The paper concludes by advocating studying computation as Peter Naur's Dataology.\n    ",
        "submission_date": "2017-04-23T00:00:00",
        "last_modified_date": "2020-04-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.08119",
        "title": "Using a new parsimonious AHP methodology combined with the Choquet integral: An application for evaluating social housing initiatives",
        "authors": [
            "Francesca Abastante",
            "Salvatore Corrente",
            "Salvatore Greco",
            "Alessio Ishizaka",
            "Isabella Lami"
        ],
        "abstract": "We propose a development of the Analytic Hierarchy Process (AHP) permitting to use the methodology also in cases of decision problems with a very large number of alternatives evaluated with respect to several criteria. While the application of the original AHP method involves many pairwise comparisons between alternatives and criteria, our proposal is composed of three steps: (i) direct evaluation of the alternatives at hand on the considered criteria, (ii) selection of some reference evaluations; (iii) application of the original AHP method to reference evaluations; (iv) revision of the direct evaluation on the basis of the prioritization supplied by AHP on reference evaluations. The new proposal has been tested and validated in an experiment conducted on a sample of university students. The new methodology has been therefore applied to a real world problem involving the evaluation of 21 Social Housing initiatives sited in the Piedmont region (Italy). To take into account interaction between criteria, the Choquet integral preference model has been considered within a Non Additive Robust Ordinal Regression approach.\n    ",
        "submission_date": "2017-04-24T00:00:00",
        "last_modified_date": "2017-04-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.08350",
        "title": "The MacGyver Test - A Framework for Evaluating Machine Resourcefulness and Creative Problem Solving",
        "authors": [
            "Vasanth Sarathy",
            "Matthias Scheutz"
        ],
        "abstract": "Current measures of machine intelligence are either difficult to evaluate or lack the ability to test a robot's problem-solving capacity in open worlds. We propose a novel evaluation framework based on the formal notion of MacGyver Test which provides a practical way for assessing the resilience and resourcefulness of artificial agents.\n    ",
        "submission_date": "2017-04-26T00:00:00",
        "last_modified_date": "2017-04-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.08389",
        "title": "Tweeting AI: Perceptions of AI-Tweeters (AIT) vs Expert AI-Tweeters (EAIT)",
        "authors": [
            "Lydia Manikonda",
            "Cameron Dudley",
            "Subbarao Kambhampati"
        ],
        "abstract": "With the recent advancements in Artificial Intelligence (AI), various organizations and individuals started debating about the progress of AI as a blessing or a curse for the future of the society. This paper conducts an investigation on how the public perceives the progress of AI by utilizing the data shared on Twitter. Specifically, this paper performs a comparative analysis on the understanding of users from two categories -- general AI-Tweeters (AIT) and the expert AI-Tweeters (EAIT) who share posts about AI on Twitter. Our analysis revealed that users from both the categories express distinct emotions and interests towards AI. Users from both the categories regard AI as positive and are optimistic about the progress of AI but the experts are more negative than the general AI-Tweeters. Characterization of users manifested that `London' is the popular location of users from where they tweet about AI. Tweets posted by AIT are highly retweeted than posts made by EAIT that reveals greater diffusion of information from AIT.\n    ",
        "submission_date": "2017-04-27T00:00:00",
        "last_modified_date": "2017-09-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.08464",
        "title": "Consensus measure of rankings",
        "authors": [
            "Zhiwei Lin",
            "Yi Li",
            "Xiaolian Guo"
        ],
        "abstract": "A ranking is an ordered sequence of items, in which an item with higher ranking score is more preferred than the items with lower ranking scores. In many information systems, rankings are widely used to represent the preferences over a set of items or candidates. The consensus measure of rankings is the problem of how to evaluate the degree to which the rankings agree. The consensus measure can be used to evaluate rankings in many information systems, as quite often there is not ground truth available for evaluation.\n",
        "submission_date": "2017-04-27T00:00:00",
        "last_modified_date": "2017-09-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.08588",
        "title": "Modeling Events as Machines",
        "authors": [
            "Sabah Al-Fedaghi"
        ],
        "abstract": "The notion of events has occupied a central role in modeling and has an influence in computer science and philosophy. Recent developments in diagrammatic modeling have made it possible to examine conceptual representation of events. This paper explores some aspects of the notion of events that are produced by applying a new diagrammatic methodology with a focus on the interaction of events with such concepts as time and space, objects. The proposed description applies to abstract machines where events form the dynamic phases of a system. The results of this nontechnical research can be utilized in many fields where the notion of an event is typically used in interdisciplinary application.\n    ",
        "submission_date": "2017-04-26T00:00:00",
        "last_modified_date": "2017-04-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.08950",
        "title": "Intelligent Personal Assistant with Knowledge Navigation",
        "authors": [
            "Amit Kumar",
            "Rahul Dutta",
            "Harbhajan Rai"
        ],
        "abstract": "An Intelligent Personal Agent (IPA) is an agent that has the purpose of helping the user to gain information through reliable resources with the help of knowledge navigation techniques and saving time to search the best content. The agent is also responsible for responding to the chat-based queries with the help of Conversation Corpus. We will be testing different methods for optimal query generation. To felicitate the ease of usage of the application, the agent will be able to accept the input through Text (Keyboard), Voice (Speech Recognition) and Server (Facebook) and output responses using the same method. Existing chat bots reply by making changes in the input, but we will give responses based on multiple SRT files. The model will learn using the human dialogs dataset and will be able respond human-like. Responses to queries about famous things (places, people, and words) can be provided using web scraping which will enable the bot to have knowledge navigation features. The agent will even learn from its past experiences supporting semi-supervised learning.\n    ",
        "submission_date": "2017-04-28T00:00:00",
        "last_modified_date": "2017-04-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.00047",
        "title": "Kiwi - A Minimalist CP Solver",
        "authors": [
            "Renaud Hartert"
        ],
        "abstract": "Kiwi is a minimalist and extendable Constraint Programming (CP) solver specifically designed for education. The particularities of Kiwi stand in its generic trailing state restoration mechanism and its modulable use of variables. By developing Kiwi, the author does not aim to provide an alternative to full featured constraint solvers but rather to provide readers with a basic architecture that will (hopefully) help them to understand the core mechanisms hidden under the hood of constraint solvers, to develop their own extended constraint solver, or to test innovative ideas.\n    ",
        "submission_date": "2017-04-28T00:00:00",
        "last_modified_date": "2017-05-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.00154",
        "title": "Classical Planning in Deep Latent Space: Bridging the Subsymbolic-Symbolic Boundary",
        "authors": [
            "Masataro Asai",
            "Alex Fukunaga"
        ],
        "abstract": "Current domain-independent, classical planners require symbolic models of the problem domain and instance as input, resulting in a knowledge acquisition bottleneck. Meanwhile, although deep learning has achieved significant success in many fields, the knowledge is encoded in a subsymbolic representation which is incompatible with symbolic systems such as planners. We propose LatPlan, an unsupervised architecture combining deep learning and classical planning. Given only an unlabeled set of image pairs showing a subset of transitions allowed in the environment (training inputs), and a pair of images representing the initial and the goal states (planning inputs), LatPlan finds a plan to the goal state in a symbolic latent space and returns a visualized plan execution. The contribution of this paper is twofold: (1) State Autoencoder, which finds a propositional state representation of the environment using a Variational Autoencoder. It generates a discrete latent vector from the images, based on which a PDDL model can be constructed and then solved by an off-the-shelf planner. (2) Action Autoencoder / Discriminator, a neural architecture which jointly finds the action symbols and the implicit action models (preconditions/effects), and provides a successor function for the implicit graph search. We evaluate LatPlan using image-based versions of 3 planning domains: 8-puzzle, Towers of Hanoi and LightsOut.\n    ",
        "submission_date": "2017-04-29T00:00:00",
        "last_modified_date": "2017-12-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.00211",
        "title": "Two Algorithms for Deciding Coincidence In Double Temporal Recurrence of Eventuality Sequences",
        "authors": [
            "Babatunde Opeoluwa Akinkunmi",
            "Adesoji A. Adegbola"
        ],
        "abstract": "Let two sequences of eventualities x (signifying the sequence, x0,x1, x2,...,xn-1) and y (signifying the sequence, y0, y1, y2,..,yn-1) both recur over the same time interval and it is required to determine whether or not a subinterval exists within the said interval which is a common subinterval of the intervals of occurrence of xp and yq. This paper presents two algorithms for solving the problem. the first explores an arbitrary cycle of the double recurrence for the existence of such an interval. its worst case running time is quadratic. The other algorithm is based on the novel notion of gcd-partitions and has a linear worst case running time. If the eventuality sequence pair (W,z) is a gcd-partition for the double recurrence (x, y),then, from a certain property of gcd-partitions, within any cycle of the double recurrence, there exists r and s such that intervals of occurrence of xp and yq are non-disjoint with the interval of co-occurrence of wr and zs. As such, a coincidence between xp and yq occurs within a cycle of the double recurrence if and only if such r and s exist so that the interval of co-occurrence of wr and zs shares a common interval with the common interval of occurrences of xp and yq. The algorithm systematically reduces the number of wr and zs pairs to be explored in the process of finding the existence of the coincidence.\n    ",
        "submission_date": "2017-04-29T00:00:00",
        "last_modified_date": "2022-11-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.00303",
        "title": "Defense semantics of argumentation: encoding reasons for accepting arguments",
        "authors": [
            "Beishui Liao",
            "Leendert van der Torre"
        ],
        "abstract": "In this paper we show how the defense relation among abstract arguments can be used to encode the reasons for accepting arguments. After introducing a novel notion of defenses and defense graphs, we propose a defense semantics together with a new notion of defense equivalence of argument graphs, and compare defense equivalence with standard equivalence and strong equivalence, respectively. Then, based on defense semantics, we define two kinds of reasons for accepting arguments, i.e., direct reasons and root reasons, and a notion of root equivalence of argument graphs. Finally, we show how the notion of root equivalence can be used in argumentation summarization.\n    ",
        "submission_date": "2017-04-30T00:00:00",
        "last_modified_date": "2017-08-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.00321",
        "title": "Tree-Structured Neural Machine for Linguistics-Aware Sentence Generation",
        "authors": [
            "Ganbin Zhou",
            "Ping Luo",
            "Rongyu Cao",
            "Yijun Xiao",
            "Fen Lin",
            "Bo Chen",
            "Qing He"
        ],
        "abstract": "Different from other sequential data, sentences in natural language are structured by linguistic grammars. Previous generative conversational models with chain-structured decoder ignore this structure in human language and might generate plausible responses with less satisfactory relevance and fluency. In this study, we aim to incorporate the results from linguistic analysis into the process of sentence generation for high-quality conversation generation. Specifically, we use a dependency parser to transform each response sentence into a dependency tree and construct a training corpus of sentence-tree pairs. A tree-structured decoder is developed to learn the mapping from a sentence to its tree, where different types of hidden states are used to depict the local dependencies from an internal tree node to its children. For training acceleration, we propose a tree canonicalization method, which transforms trees into equivalent ternary trees. Then, with a proposed tree-structured search method, the model is able to generate the most probable responses in the form of dependency trees, which are finally flattened into sequences as the system output. Experimental results demonstrate that the proposed X2Tree framework outperforms baseline methods over 11.15% increase of acceptance ratio.\n    ",
        "submission_date": "2017-04-30T00:00:00",
        "last_modified_date": "2018-01-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.00594",
        "title": "A System for Accessible Artificial Intelligence",
        "authors": [
            "Randal S. Olson",
            "Moshe Sipper",
            "William La Cava",
            "Sharon Tartarone",
            "Steven Vitale",
            "Weixuan Fu",
            "Patryk Orzechowski",
            "Ryan J. Urbanowicz",
            "John H. Holmes",
            "Jason H. Moore"
        ],
        "abstract": "While artificial intelligence (AI) has become widespread, many commercial AI systems are not yet accessible to individual researchers nor the general public due to the deep knowledge of the systems required to use them. We believe that AI has matured to the point where it should be an accessible technology for everyone. We present an ongoing project whose ultimate goal is to deliver an open source, user-friendly AI system that is specialized for machine learning analysis of complex data in the biomedical and health care domains. We discuss how genetic programming can aid in this endeavor, and highlight specific examples where genetic programming has automated machine learning analyses in previous projects.\n    ",
        "submission_date": "2017-05-01T00:00:00",
        "last_modified_date": "2017-08-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.00673",
        "title": "MACA: A Modular Architecture for Conversational Agents",
        "authors": [
            "Hoai Phuoc Truong",
            "Prasanna Parthasarathi",
            "Joelle Pineau"
        ],
        "abstract": "We propose a software architecture designed to ease the implementation of dialogue systems. The Modular Architecture for Conversational Agents (MACA) uses a plug-n-play style that allows quick prototyping, thereby facilitating the development of new techniques and the reproduction of previous work. The architecture separates the domain of the conversation from the agent's dialogue strategy, and as such can be easily extended to multiple domains. MACA provides tools to host dialogue agents on Amazon Mechanical Turk (mTurk) for data collection and allows processing of other sources of training data. The current version of the framework already incorporates several domains and existing dialogue strategies from the recent literature.\n    ",
        "submission_date": "2017-05-01T00:00:00",
        "last_modified_date": "2017-05-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.00969",
        "title": "The Problem of Coincidence in A Theory of Temporal Multiple Recurrence",
        "authors": [
            "B.O. Akinkunmi"
        ],
        "abstract": "Logical theories have been developed which have allowed temporal reasoning about eventualities (a la Galton) such as states, processes, actions, events, processes and complex eventualities such as sequences and recurrences of other eventualities. This paper presents the problem of coincidence within the framework of a first order logical theory formalising temporal multiple recurrence of two sequences of fixed duration eventualities and presents a solution to it The coincidence problem is described as: if two complex eventualities (or eventuality sequences) consisting respectively of component eventualities x0, x1,....,xr and y0, y1, ..,ys both recur over an interval k and all eventualities are of fixed durations, is there a sub-interval of k over which the incidence xt and yu for t between 0..r and s between 0..s coincide. The solution presented here formalises the intuition that a solution can be found by temporal projection over a cycle of the multiple recurrence of both sequences.\n    ",
        "submission_date": "2017-04-29T00:00:00",
        "last_modified_date": "2017-04-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.01076",
        "title": "An improved Ant Colony System for the Sequential Ordering Problem",
        "authors": [
            "Rafa\u0142 Skinderowicz"
        ],
        "abstract": "It is not rare that the performance of one metaheuristic algorithm can be improved by incorporating ideas taken from another. In this article we present how Simulated Annealing (SA) can be used to improve the efficiency of the Ant Colony System (ACS) and Enhanced ACS when solving the Sequential Ordering Problem (SOP). Moreover, we show how the very same ideas can be applied to improve the convergence of a dedicated local search, i.e. the SOP-3-exchange algorithm. A statistical analysis of the proposed algorithms both in terms of finding suitable parameter values and the quality of the generated solutions is presented based on a series of computational experiments conducted on SOP instances from the well-known TSPLIB and SOPLIB2006 repositories. The proposed ACS-SA and EACS-SA algorithms often generate solutions of better quality than the ACS and EACS, respectively. Moreover, the EACS-SA algorithm combined with the proposed SOP-3-exchange-SA local search was able to find 10 new best solutions for the SOP instances from the SOPLIB2006 repository, thus improving the state-of-the-art results as known from the literature. Overall, the best known or improved solutions were found in 41 out of 48 cases.\n    ",
        "submission_date": "2017-05-02T00:00:00",
        "last_modified_date": "2017-05-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.01080",
        "title": "The N-Tuple Bandit Evolutionary Algorithm for Automatic Game Improvement",
        "authors": [
            "Kamolwan Kunanusont",
            "Raluca D. Gaina",
            "Jialin Liu",
            "Diego Perez-Liebana",
            "Simon M. Lucas"
        ],
        "abstract": "This paper describes a new evolutionary algorithm that is especially well suited to AI-Assisted Game Design. The approach adopted in this paper is to use observations of AI agents playing the game to estimate the game's quality. Some of best agents for this purpose are General Video Game AI agents, since they can be deployed directly on a new game without game-specific tuning; these agents tend to be based on stochastic algorithms which give robust but noisy results and tend to be expensive to run. This motivates the main contribution of the paper: the development of the novel N-Tuple Bandit Evolutionary Algorithm, where a model is used to estimate the fitness of unsampled points and a bandit approach is used to balance exploration and exploitation of the search space. Initial results on optimising a Space Battle game variant suggest that the algorithm offers far more robust results than the Random Mutation Hill Climber and a Biased Mutation variant, which are themselves known to offer competitive performance across a range of problems. Subjective observations are also given by human players on the nature of the evolved games, which indicate a preference towards games generated by the N-Tuple algorithm.\n    ",
        "submission_date": "2017-03-18T00:00:00",
        "last_modified_date": "2017-03-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.01172",
        "title": "Imagining Probabilistic Belief Change as Imaging (Technical Report)",
        "authors": [
            "Gavin Rens",
            "Thomas Meyer"
        ],
        "abstract": "Imaging is a form of probabilistic belief change which could be employed for both revision and update. In this paper, we propose a new framework for probabilistic belief change based on imaging, called Expected Distance Imaging (EDI). EDI is sufficiently general to define Bayesian conditioning and other forms of imaging previously defined in the literature. We argue that, and investigate how, EDI can be used for both revision and update. EDI's definition depends crucially on a weight function whose properties are studied and whose effect on belief change operations is analysed. Finally, four EDI instantiations are proposed, two for revision and two for update, and probabilistic rationality postulates are suggested for their analysis.\n    ",
        "submission_date": "2017-05-02T00:00:00",
        "last_modified_date": "2017-05-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.01196",
        "title": "Navigating Occluded Intersections with Autonomous Vehicles using Deep Reinforcement Learning",
        "authors": [
            "David Isele",
            "Reza Rahimi",
            "Akansel Cosgun",
            "Kaushik Subramanian",
            "Kikuo Fujimura"
        ],
        "abstract": "Providing an efficient strategy to navigate safely through unsignaled intersections is a difficult task that requires determining the intent of other drivers. We explore the effectiveness of Deep Reinforcement Learning to handle intersection problems. Using recent advances in Deep RL, we are able to learn policies that surpass the performance of a commonly-used heuristic approach in several metrics including task completion time and goal success rate and have limited ability to generalize. We then explore a system's ability to learn active sensing behaviors to enable navigating safely in the case of occlusions. Our analysis, provides insight into the intersection handling problem, the solutions learned by the network point out several shortcomings of current rule-based methods, and the failures of our current deep reinforcement learning system point to future research directions.\n    ",
        "submission_date": "2017-05-02T00:00:00",
        "last_modified_date": "2018-02-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.01208",
        "title": "A Rule-Based Computational Model of Cognitive Arithmetic",
        "authors": [
            "Ashis Pati",
            "Kantwon Rogers",
            "Hanqing Zhu"
        ],
        "abstract": "Cognitive arithmetic studies the mental processes used in solving math problems. This area of research explores the retrieval mechanisms and strategies used by people during a common cognitive task. Past research has shown that human performance in arithmetic operations is correlated to the numerical size of the problem. Past research on cognitive arithmetic has pinpointed this trend to either retrieval strength, error checking, or strategy-based approaches when solving equations. This paper describes a rule-based computational model that performs the four major arithmetic operations (addition, subtraction, multiplication and division) on two operands. We then evaluated our model to probe its validity in representing the prevailing concepts observed in psychology experiments from the related works. The experiments specifically explore the problem size effect, an activation-based model for fact retrieval, backup strategies when retrieval fails, and finally optimization strategies when faced with large operands. From our experimental results, we concluded that our model's response times were comparable to results observed when people performed similar tasks during psychology experiments. The fit of our model in reproducing these results and incorporating accuracy into our model are discussed.\n    ",
        "submission_date": "2017-05-03T00:00:00",
        "last_modified_date": "2017-05-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.01399",
        "title": "Answer Set Programming for Non-Stationary Markov Decision Processes",
        "authors": [
            "Leonardo A. Ferreira",
            "Reinaldo A. C. Bianchi",
            "Paulo E. Santos",
            "Ramon Lopez de Mantaras"
        ],
        "abstract": "Non-stationary domains, where unforeseen changes happen, present a challenge for agents to find an optimal policy for a sequential decision making problem. This work investigates a solution to this problem that combines Markov Decision Processes (MDP) and Reinforcement Learning (RL) with Answer Set Programming (ASP) in a method we call ASP(RL). In this method, Answer Set Programming is used to find the possible trajectories of an MDP, from where Reinforcement Learning is applied to learn the optimal policy of the problem. Results show that ASP(RL) is capable of efficiently finding the optimal solution of an MDP representing non-stationary domains.\n    ",
        "submission_date": "2017-05-03T00:00:00",
        "last_modified_date": "2017-05-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.01681",
        "title": "Tramp Ship Scheduling Problem with Berth Allocation Considerations and Time-dependent Constraints",
        "authors": [
            "Francisco L\u00f3pez-Ramos",
            "Armando Guarnaschelli",
            "Jos\u00e9-Fernando Camacho-Vallejo",
            "Laura Hervert-Escobar",
            "Rosa G. Gonz\u00e1lez-Ram\u00edrez"
        ],
        "abstract": "This work presents a model for the Tramp Ship Scheduling problem including berth allocation considerations, motivated by a real case of a shipping company. The aim is to determine the travel schedule for each vessel considering multiple docking and multiple time windows at the berths. This work is innovative due to the consideration of both spatial and temporal attributes during the scheduling process. The resulting model is formulated as a mixed-integer linear programming problem, and a heuristic method to deal with multiple vessel schedules is also presented. Numerical experimentation is performed to highlight the benefits of the proposed approach and the applicability of the heuristic. Conclusions and recommendations for further research are provided.\n    ",
        "submission_date": "2017-05-04T00:00:00",
        "last_modified_date": "2017-05-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.01817",
        "title": "A Reasoning System for a First-Order Logic of Limited Belief",
        "authors": [
            "Christoph Schwering"
        ],
        "abstract": "Logics of limited belief aim at enabling computationally feasible reasoning in highly expressive representation languages. These languages are often dialects of first-order logic with a weaker form of logical entailment that keeps reasoning decidable or even tractable. While a number of such logics have been proposed in the past, they tend to remain for theoretical analysis only and their practical relevance is very limited. In this paper, we aim to go beyond the theory. Building on earlier work by Liu, Lakemeyer, and Levesque, we develop a logic of limited belief that is highly expressive while remaining decidable in the first-order and tractable in the propositional case and exhibits some characteristics that make it attractive for an implementation. We introduce a reasoning system that employs this logic as representation language and present experimental results that showcase the benefit of limited belief.\n    ",
        "submission_date": "2017-05-04T00:00:00",
        "last_modified_date": "2017-05-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.02175",
        "title": "Distributed Online Learning of Event Definitions",
        "authors": [
            "Nikos Katzouris",
            "Alexander Artikis",
            "Georgios Paliouras"
        ],
        "abstract": "Logic-based event recognition systems infer occurrences of events in time using a set of event definitions in the form of first-order rules. The Event Calculus is a temporal logic that has been used as a basis in event recognition applications, providing among others, direct connections to machine learning, via Inductive Logic Programming (ILP). OLED is a recently proposed ILP system that learns event definitions in the form of Event Calculus theories, in a single pass over a data stream. In this work we present a version of OLED that allows for distributed, online learning. We evaluate our approach on a benchmark activity recognition dataset and show that we can significantly reduce training times, exchanging minimal information between processing nodes.\n    ",
        "submission_date": "2017-05-05T00:00:00",
        "last_modified_date": "2017-05-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.02210",
        "title": "SLDR-DL: A Framework for SLD-Resolution with Deep Learning",
        "authors": [
            "Cheng-Hao Cai"
        ],
        "abstract": "This paper introduces an SLD-resolution technique based on deep learning. This technique enables neural networks to learn from old and successful resolution processes and to use learnt experiences to guide new resolution processes. An implementation of this technique is named SLDR-DL. It includes a Prolog library of deep feedforward neural networks and some essential functions of resolution. In the SLDR-DL framework, users can define logical rules in the form of definite clauses and teach neural networks to use the rules in reasoning processes.\n    ",
        "submission_date": "2017-05-05T00:00:00",
        "last_modified_date": "2017-05-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.02476",
        "title": "PANFIS++: A Generalized Approach to Evolving Learning",
        "authors": [
            "Mahardhika Pratama"
        ],
        "abstract": "The concept of evolving intelligent system (EIS) provides an effective avenue for data stream mining because it is capable of coping with two prominent issues: online learning and rapidly changing environments. We note at least three uncharted territories of existing EISs: data uncertainty, temporal system dynamic, redundant data streams. This book chapter aims at delivering a concrete solution of this problem with the algorithmic development of a novel learning algorithm, namely PANFIS++. PANFIS++ is a generalized version of the PANFIS by putting forward three important components: 1) An online active learning scenario is developed to overcome redundant data streams. This module allows to actively select data streams for the training process, thereby expediting execution time and enhancing generalization performance, 2) PANFIS++ is built upon an interval type-2 fuzzy system environment, which incorporates the so-called footprint of uncertainty. This component provides a degree of tolerance for data uncertainty. 3) PANFIS++ is structured under a recurrent network architecture with a self-feedback loop. This is meant to tackle the temporal system dynamic. The efficacy of the PANFIS++ has been numerically validated through numerous real-world and synthetic case studies, where it delivers the highest predictive accuracy while retaining the lowest complexity.\n    ",
        "submission_date": "2017-05-06T00:00:00",
        "last_modified_date": "2017-05-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.02477",
        "title": "Metacognitive Learning Approach for Online Tool Condition Monitoring",
        "authors": [
            "Mahardhika Pratama",
            "Eric Dimla",
            "Chow Yin Lai",
            "Edwin Lughofer"
        ],
        "abstract": "As manufacturing processes become increasingly automated, so should tool condition monitoring (TCM) as it is impractical to have human workers monitor the state of the tools continuously. Tool condition is crucial to ensure the good quality of products: Worn tools affect not only the surface quality but also the dimensional accuracy, which means higher reject rate of the products. Therefore, there is an urgent need to identify tool failures before it occurs on the fly. While various versions of intelligent tool condition monitoring have been proposed, most of them suffer from a cognitive nature of traditional machine learning algorithms. They focus on the how to learn process without paying attention to other two crucial issues: what to learn, and when to learn. The what to learn and the when to learn provide self regulating mechanisms to select the training samples and to determine time instants to train a model. A novel tool condition monitoring approach based on a psychologically plausible concept, namely the metacognitive scaffolding theory, is proposed and built upon a recently published algorithm, recurrent classifier (rClass). The learning process consists of three phases: what to learn, how to learn, when to learn and makes use of a generalized recurrent network structure as a cognitive component. Experimental studies with real-world manufacturing data streams were conducted where rClass demonstrated the highest accuracy while retaining the lowest complexity over its counterparts.\n    ",
        "submission_date": "2017-05-06T00:00:00",
        "last_modified_date": "2017-05-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.02518",
        "title": "Exploring Latent Semantic Factors to Find Useful Product Reviews",
        "authors": [
            "Subhabrata Mukherjee",
            "Kashyap Popat",
            "Gerhard Weikum"
        ],
        "abstract": "Online reviews provided by consumers are a valuable asset for e-Commerce platforms, influencing potential consumers in making purchasing decisions. However, these reviews are of varying quality, with the useful ones buried deep within a heap of non-informative reviews. In this work, we attempt to automatically identify review quality in terms of its helpfulness to the end consumers. In contrast to previous works in this domain exploiting a variety of syntactic and community-level features, we delve deep into the semantics of reviews as to what makes them useful, providing interpretable explanation for the same. We identify a set of consistency and semantic factors, all from the text, ratings, and timestamps of user-generated reviews, making our approach generalizable across all communities and domains. We explore review semantics in terms of several latent factors like the expertise of its author, his judgment about the fine-grained facets of the underlying product, and his writing style. These are cast into a Hidden Markov Model -- Latent Dirichlet Allocation (HMM-LDA) based model to jointly infer: (i) reviewer expertise, (ii) item facets, and (iii) review helpfulness. Large-scale experiments on five real-world datasets from Amazon show significant improvement over state-of-the-art baselines in predicting and ranking useful reviews.\n    ",
        "submission_date": "2017-05-06T00:00:00",
        "last_modified_date": "2017-05-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.02519",
        "title": "Item Recommendation with Evolving User Preferences and Experience",
        "authors": [
            "Subhabrata Mukherjee",
            "Hemank Lamba",
            "Gerhard Weikum"
        ],
        "abstract": "Current recommender systems exploit user and item similarities by collaborative filtering. Some advanced methods also consider the temporal evolution of item ratings as a global background process. However, all prior methods disregard the individual evolution of a user's experience level and how this is expressed in the user's writing in a review community. In this paper, we model the joint evolution of user experience, interest in specific item facets, writing style, and rating behavior. This way we can generate individual recommendations that take into account the user's maturity level (e.g., recommending art movies rather than blockbusters for a cinematography expert). As only item ratings and review texts are observables, we capture the user's experience and interests in a latent model learned from her reviews, vocabulary and writing style. We develop a generative HMM-LDA model to trace user evolution, where the Hidden Markov Model (HMM) traces her latent experience progressing over time -- with solely user reviews and ratings as observables over time. The facets of a user's interest are drawn from a Latent Dirichlet Allocation (LDA) model derived from her reviews, as a function of her (again latent) experience level. In experiments with five real-world datasets, we show that our model improves the rating prediction over state-of-the-art baselines, by a substantial margin. We also show, in a use-case study, that our model performs well in the assessment of user experience levels.\n    ",
        "submission_date": "2017-05-06T00:00:00",
        "last_modified_date": "2017-05-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.02522",
        "title": "People on Drugs: Credibility of User Statements in Health Communities",
        "authors": [
            "Subhabrata Mukherjee",
            "Gerhard Weikum",
            "Cristian Danescu-Niculescu-Mizil"
        ],
        "abstract": "Online health communities are a valuable source of information for patients and physicians. However, such user-generated resources are often plagued by inaccuracies and misinformation. In this work we propose a method for automatically establishing the credibility of user-generated medical statements and the trustworthiness of their authors by exploiting linguistic cues and distant supervision from expert sources. To this end we introduce a probabilistic graphical model that jointly learns user trustworthiness, statement credibility, and language objectivity. We apply this methodology to the task of extracting rare or unknown side-effects of medical drugs --- this being one of the problems where large scale non-expert data has the potential to complement expert medical knowledge. We show that our method can reliably extract side-effects and filter out false statements, while identifying trustworthy users that are likely to contribute valuable medical information.\n    ",
        "submission_date": "2017-05-06T00:00:00",
        "last_modified_date": "2017-05-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.02553",
        "title": "Experimental results : Reinforcement Learning of POMDPs using Spectral Methods",
        "authors": [
            "Kamyar Azizzadenesheli",
            "Alessandro Lazaric",
            "Animashree Anandkumar"
        ],
        "abstract": "We propose a new reinforcement learning algorithm for partially observable Markov decision processes (POMDP) based on spectral decomposition methods. While spectral methods have been previously employed for consistent learning of (passive) latent variable models such as hidden Markov models, POMDPs are more challenging since the learner interacts with the environment and possibly changes the future observations in the process. We devise a learning algorithm running through epochs, in each epoch we employ spectral techniques to learn the POMDP parameters from a trajectory generated by a fixed policy. At the end of the epoch, an optimization oracle returns the optimal memoryless planning policy which maximizes the expected reward based on the estimated POMDP model. We prove an order-optimal regret bound with respect to the optimal memoryless policy and efficient scaling with respect to the dimensionality of observation and action spaces.\n    ",
        "submission_date": "2017-05-07T00:00:00",
        "last_modified_date": "2017-05-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.02620",
        "title": "A New Medical Diagnosis Method Based on Z-Numbers",
        "authors": [
            "Dong Wu",
            "Xiang Liu",
            "Feng Xue",
            "Hanqing Zheng",
            "Yehang Shou",
            "Wen Jiang"
        ],
        "abstract": "How to handle uncertainty in medical diagnosis is an open issue. In this paper, a new decision making methodology based on Z-numbers is presented. Firstly, the experts' opinions are represented by Z-numbers. Z-number is an ordered pair of fuzzy numbers denoted as Z = (A, B). Then, a new method for ranking fuzzy numbers is proposed. And based on the proposed fuzzy number ranking method, a novel method is presented to transform the Z-numbers into Basic Probability Assignment (BPA). As a result, the information from different sources is combined by the Dempster' combination rule. The final decision making is more reasonable due to the advantage of information fusion. Finally, two experiments, risk analysis and medical diagnosis, are illustrated to show the efficiency of the proposed methodology.\n    ",
        "submission_date": "2017-05-07T00:00:00",
        "last_modified_date": "2017-05-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.02667",
        "title": "People on Media: Jointly Identifying Credible News and Trustworthy Citizen Journalists in Online Communities",
        "authors": [
            "Subhabrata Mukherjee",
            "Gerhard Weikum"
        ],
        "abstract": "Media seems to have become more partisan, often providing a biased coverage of news catering to the interest of specific groups. It is therefore essential to identify credible information content that provides an objective narrative of an event. News communities such as digg, reddit, or newstrust offer recommendations, reviews, quality ratings, and further insights on journalistic works. However, there is a complex interaction between different factors in such online communities: fairness and style of reporting, language clarity and objectivity, topical perspectives (like political viewpoint), expertise and bias of community members, and more. This paper presents a model to systematically analyze the different interactions in a news community between users, news, and sources. We develop a probabilistic graphical model that leverages this joint interaction to identify 1) highly credible news articles, 2) trustworthy news sources, and 3) expert users who perform the role of \"citizen journalists\" in the community. Our method extends CRF models to incorporate real-valued ratings, as some communities have very fine-grained scales that cannot be easily discretized without losing information. To the best of our knowledge, this paper is the first full-fledged analysis of credibility, trust, and expertise in news communities.\n    ",
        "submission_date": "2017-05-07T00:00:00",
        "last_modified_date": "2017-05-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.02668",
        "title": "Credible Review Detection with Limited Information using Consistency Analysis",
        "authors": [
            "Subhabrata Mukherjee",
            "Sourav Dutta",
            "Gerhard Weikum"
        ],
        "abstract": "Online reviews provide viewpoints on the strengths and shortcomings of products/services, influencing potential customers' purchasing decisions. However, the proliferation of non-credible reviews -- either fake (promoting/ demoting an item), incompetent (involving irrelevant aspects), or biased -- entails the problem of identifying credible reviews. Prior works involve classifiers harnessing rich information about items/users -- which might not be readily available in several domains -- that provide only limited interpretability as to why a review is deemed non-credible. This paper presents a novel approach to address the above issues. We utilize latent topic models leveraging review texts, item ratings, and timestamps to derive consistency features without relying on item/user histories, unavailable for \"long-tail\" items/users. We develop models, for computing review credibility scores to provide interpretable evidence for non-credible reviews, that are also transferable to other domains -- addressing the scarcity of labeled data. Experiments on real-world datasets demonstrate improvements over state-of-the-art baselines.\n    ",
        "submission_date": "2017-05-07T00:00:00",
        "last_modified_date": "2017-05-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.02669",
        "title": "Item Recommendation with Continuous Experience Evolution of Users using Brownian Motion",
        "authors": [
            "Subhabrata Mukherjee",
            "Stephan Guennemann",
            "Gerhard Weikum"
        ],
        "abstract": "Online review communities are dynamic as users join and leave, adopt new vocabulary, and adapt to evolving trends. Recent work has shown that recommender systems benefit from explicit consideration of user experience. However, prior work assumes a fixed number of discrete experience levels, whereas in reality users gain experience and mature continuously over time. This paper presents a new model that captures the continuous evolution of user experience, and the resulting language model in reviews and other posts. Our model is unsupervised and combines principles of Geometric Brownian Motion, Brownian Motion, and Latent Dirichlet Allocation to trace a smooth temporal progression of user experience and language model respectively. We develop practical algorithms for estimating the model parameters from data and for inference with our model (e.g., to recommend items). Extensive experiments with five real-world datasets show that our model not only fits data better than discrete-model baselines, but also outperforms state-of-the-art methods for predicting item ratings.\n    ",
        "submission_date": "2017-05-07T00:00:00",
        "last_modified_date": "2017-08-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.02843",
        "title": "Block-Parallel IDA* for GPUs (Extended Manuscript)",
        "authors": [
            "Satoru Horie",
            "Alex Fukunaga"
        ],
        "abstract": "We investigate GPU-based parallelization of Iterative-Deepening A* (IDA*). We show that straightforward thread-based parallelization techniques which were previously proposed for massively parallel SIMD processors perform poorly due to warp divergence and load imbalance. We propose Block-Parallel IDA* (BPIDA*), which assigns the search of a subtree to a block (a group of threads with access to fast shared memory) rather than a thread. On the 15-puzzle, BPIDA* on a NVIDIA GRID K520 with 1536 CUDA cores achieves a speedup of 4.98 compared to a highly optimized sequential IDA* implementation on a Xeon E5-2670 core.\n    ",
        "submission_date": "2017-05-08T00:00:00",
        "last_modified_date": "2017-05-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.02908",
        "title": "Machine Learning with World Knowledge: The Position and Survey",
        "authors": [
            "Yangqiu Song",
            "Dan Roth"
        ],
        "abstract": "Machine learning has become pervasive in multiple domains, impacting a wide variety of applications, such as knowledge discovery and data mining, natural language processing, information retrieval, computer vision, social and health informatics, ubiquitous computing, etc. Two essential problems of machine learning are how to generate features and how to acquire labels for machines to learn. Particularly, labeling large amount of data for each domain-specific problem can be very time consuming and costly. It has become a key obstacle in making learning protocols realistic in applications. In this paper, we will discuss how to use the existing general-purpose world knowledge to enhance machine learning processes, by enriching the features or reducing the labeling work. We start from the comparison of world knowledge with domain-specific knowledge, and then introduce three key problems in using world knowledge in learning processes, i.e., explicit and implicit feature representation, inference for knowledge linking and disambiguation, and learning with direct or indirect supervision. Finally we discuss the future directions of this research topic.\n    ",
        "submission_date": "2017-05-08T00:00:00",
        "last_modified_date": "2017-05-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.02955",
        "title": "Safe and Nested Subgame Solving for Imperfect-Information Games",
        "authors": [
            "Noam Brown",
            "Tuomas Sandholm"
        ],
        "abstract": "In imperfect-information games, the optimal strategy in a subgame may depend on the strategy in other, unreached subgames. Thus a subgame cannot be solved in isolation and must instead consider the strategy for the entire game as a whole, unlike perfect-information games. Nevertheless, it is possible to first approximate a solution for the whole game and then improve it by solving individual subgames. This is referred to as subgame solving. We introduce subgame-solving techniques that outperform prior methods both in theory and practice. We also show how to adapt them, and past subgame-solving techniques, to respond to opponent actions that are outside the original action abstraction; this significantly outperforms the prior state-of-the-art approach, action translation. Finally, we show that subgame solving can be repeated as the game progresses down the game tree, leading to far lower exploitability. These techniques were a key component of Libratus, the first AI to defeat top humans in heads-up no-limit Texas hold'em poker.\n    ",
        "submission_date": "2017-05-08T00:00:00",
        "last_modified_date": "2017-11-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.03078",
        "title": "An Anthropic Argument against the Future Existence of Superintelligent Artificial Intelligence",
        "authors": [
            "Toby Pereira"
        ],
        "abstract": "This paper uses anthropic reasoning to argue for a reduced likelihood that superintelligent AI will come into existence in the future. To make this argument, a new principle is introduced: the Super-Strong Self-Sampling Assumption (SSSSA), building on the Self-Sampling Assumption (SSA) and the Strong Self-Sampling Assumption (SSSA). SSA uses as its sample the relevant observers, whereas SSSA goes further by using observer-moments. SSSSA goes further still and weights each sample proportionally, according to the size of a mind in cognitive terms. SSSSA is required for human observer-samples to be typical, given by how much non-human animals outnumber humans. Given SSSSA, the assumption that humans experience typical observer-samples relies on a future where superintelligent AI does not dominate, which in turn reduces the likelihood of it being created at all.\n    ",
        "submission_date": "2017-05-08T00:00:00",
        "last_modified_date": "2017-05-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.03260",
        "title": "Evidence for the size principle in semantic and perceptual domains",
        "authors": [
            "Joshua C. Peterson",
            "Thomas L. Griffiths"
        ],
        "abstract": "Shepard's Universal Law of Generalization offered a compelling case for the first physics-like law in cognitive science that should hold for all intelligent agents in the universe. Shepard's account is based on a rational Bayesian model of generalization, providing an answer to the question of why such a law should emerge. Extending this account to explain how humans use multiple examples to make better generalizations requires an additional assumption, called the size principle: hypotheses that pick out fewer objects should make a larger contribution to generalization. The degree to which this principle warrants similarly law-like status is far from conclusive. Typically, evaluating this principle has not been straightforward, requiring additional assumptions. We present a new method for evaluating the size principle that is more direct, and apply this method to a diverse array of datasets. Our results provide support for the broad applicability of the size principle.\n    ",
        "submission_date": "2017-05-09T00:00:00",
        "last_modified_date": "2017-05-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.03290",
        "title": "Improving drug sensitivity predictions in precision medicine through active expert knowledge elicitation",
        "authors": [
            "Iiris Sundin",
            "Tomi Peltola",
            "Muntasir Mamun Majumder",
            "Pedram Daee",
            "Marta Soare",
            "Homayun Afrabandpey",
            "Caroline Heckman",
            "Samuel Kaski",
            "Pekka Marttinen"
        ],
        "abstract": "Predicting the efficacy of a drug for a given individual, using high-dimensional genomic measurements, is at the core of precision medicine. However, identifying features on which to base the predictions remains a challenge, especially when the sample size is small. Incorporating expert knowledge offers a promising alternative to improve a prediction model, but collecting such knowledge is laborious to the expert if the number of candidate features is very large. We introduce a probabilistic model that can incorporate expert feedback about the impact of genomic measurements on the sensitivity of a cancer cell for a given drug. We also present two methods to intelligently collect this feedback from the expert, using experimental design and multi-armed bandit models. In a multiple myeloma blood cancer data set (n=51), expert knowledge decreased the prediction error by 8%. Furthermore, the intelligent approaches can be used to reduce the workload of feedback collection to less than 30% on average compared to a naive approach.\n    ",
        "submission_date": "2017-05-09T00:00:00",
        "last_modified_date": "2017-05-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.03352",
        "title": "Composition of Credal Sets via Polyhedral Geometry",
        "authors": [
            "Ji\u0159ina Vejnarov\u00e1",
            "V\u00e1clav Kratochv\u00edl"
        ],
        "abstract": "Recently introduced composition operator for credal sets is an analogy of such operators in probability, possibility, evidence and valuation-based systems theories. It was designed to construct multidimensional models (in the framework of credal sets) from a system of low- dimensional credal sets. In this paper we study its potential from the computational point of view utilizing methods of polyhedral geometry.\n    ",
        "submission_date": "2017-05-05T00:00:00",
        "last_modified_date": "2017-05-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.03381",
        "title": "A note on the uniqueness of models in social abstract argumentation",
        "authors": [
            "Leila Amgoud",
            "Elise Bonzon",
            "Marco Correia",
            "Jorge Cruz",
            "J\u00e9r\u00f4me Delobelle",
            "S\u00e9bastien Konieczny",
            "Jo\u00e3o Leite",
            "Alexis Martin",
            "Nicolas Maudet",
            "Srdjan Vesic"
        ],
        "abstract": "Social abstract argumentation is a principled way to assign values to conflicting (weighted) arguments. In this note we discuss the important property of the uniqueness of the model.\n    ",
        "submission_date": "2017-05-09T00:00:00",
        "last_modified_date": "2017-05-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.03392",
        "title": "Asynchronous Announcements",
        "authors": [
            "Philippe Balbiani",
            "Hans van Ditmarsch",
            "Sa\u00fal Fern\u00e1ndez Gonz\u00e1lez"
        ],
        "abstract": "We propose a multi-agent epistemic logic of asynchronous announcements, where truthful announcements are publicly sent but individually received by agents, and in the order in which they were sent. Additional to epistemic modalities the logic contains dynamic modalities for making announcements and for receiving them. What an agent believes is a function of her initial uncertainty and of the announcements she has received. Beliefs need not be truthful, because announcements already made may not yet have been received. As announcements are true when sent, certain message sequences can be ruled out, just like inconsistent cuts in distributed computing.\n",
        "submission_date": "2017-05-08T00:00:00",
        "last_modified_date": "2021-01-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.03451",
        "title": "Proceedings of the Workshop on Data Mining for Oil and Gas",
        "authors": [
            "Alipio Jorge",
            "German Larrazabal",
            "Pablo Guillen",
            "Rui L. Lopes"
        ],
        "abstract": "The process of exploring and exploiting Oil and Gas (O&G) generates a lot of data that can bring more efficiency to the industry. The opportunities for using data mining techniques in the \"digital oil-field\" remain largely unexplored or uncharted. With the high rate of data expansion, companies are scrambling to develop ways to develop near-real-time predictive analytics, data mining and machine learning capabilities, and are expanding their data storage infrastructure and resources. With these new goals, come the challenges of managing data growth, integrating intelligence tools, and analyzing the data to glean useful insights. Oil and Gas companies need data solutions to economically extract value from very large volumes of a wide variety of data generated from exploration, well drilling and production devices and sensors.\n",
        "submission_date": "2017-05-09T00:00:00",
        "last_modified_date": "2017-05-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.03520",
        "title": "Policy Iterations for Reinforcement Learning Problems in Continuous Time and Space -- Fundamental Theory and Methods",
        "authors": [
            "Jaeyoung Lee",
            "Richard S. Sutton"
        ],
        "abstract": "Policy iteration (PI) is a recursive process of policy evaluation and improvement for solving an optimal decision-making/control problem, or in other words, a reinforcement learning (RL) problem. PI has also served as the fundamental for developing RL methods. In this paper, we propose two PI methods, called differential PI (DPI) and integral PI (IPI), and their variants, for a general RL framework in continuous time and space (CTS), where the environment is modeled by a system of ordinary differential equations (ODEs). The proposed methods inherit the current ideas of PI in classical RL and optimal control and theoretically support the existing RL algorithms in CTS: TD-learning and value-gradient-based (VGB) greedy policy update. We also provide case studies including 1) discounted RL and 2) optimal control tasks. Fundamental mathematical properties -- admissibility, uniqueness of the solution to the Bellman equation (BE), monotone improvement, convergence, and optimality of the solution to the Hamilton-Jacobi-Bellman equation (HJBE) -- are all investigated in-depth and improved from the existing theory, along with the general and case studies. Finally, the proposed ones are simulated with an inverted-pendulum model and their model-based and partially model-free implementations to support the theory and further investigate them beyond.\n    ",
        "submission_date": "2017-05-09T00:00:00",
        "last_modified_date": "2020-10-31T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.03597",
        "title": "Solving Multi-Objective MDP with Lexicographic Preference: An application to stochastic planning with multiple quantile objective",
        "authors": [
            "Yan Li",
            "Zhaohan Sun"
        ],
        "abstract": "In most common settings of Markov Decision Process (MDP), an agent evaluate a policy based on expectation of (discounted) sum of rewards. However in many applications this criterion might not be suitable from two perspective: first, in risk aversion situation expectation of accumulated rewards is not robust enough, this is the case when distribution of accumulated reward is heavily skewed; another issue is that many applications naturally take several objective into consideration when evaluating a policy, for instance in autonomous driving an agent needs to balance speed and safety when choosing appropriate decision. In this paper, we consider evaluating a policy based on a sequence of quantiles it induces on a set of target states, our idea is to reformulate the original problem into a multi-objective MDP problem with lexicographic preference naturally defined. For computation of finding an optimal policy, we proposed an algorithm \\textbf{FLMDP} that could solve general multi-objective MDP with lexicographic reward preference.\n    ",
        "submission_date": "2017-05-10T00:00:00",
        "last_modified_date": "2017-05-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.03669",
        "title": "Mind the Gap: A Well Log Data Analysis",
        "authors": [
            "Rui L. Lopes",
            "Al\u00edpio Jorge"
        ],
        "abstract": "The main task in oil and gas exploration is to gain an understanding of the distribution and nature of rocks and fluids in the subsurface. Well logs are records of petro-physical data acquired along a borehole, providing direct information about what is in the subsurface. The data collected by logging wells can have significant economic consequences, due to the costs inherent to drilling wells, and the potential return of oil deposits. In this paper, we describe preliminary work aimed at building a general framework for well log prediction.\n",
        "submission_date": "2017-05-10T00:00:00",
        "last_modified_date": "2017-05-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.03751",
        "title": "A Survey of Distant Supervision Methods using PGMs",
        "authors": [
            "Gagan Madan"
        ],
        "abstract": "Relation Extraction refers to the task of populating a database with tuples of the form $r(e_1, e_2)$, where $r$ is a relation and $e_1$, $e_2$ are entities. Distant supervision is one such technique which tries to automatically generate training examples based on an existing KB such as Freebase. This paper is a survey of some of the techniques in distant supervision which primarily rely on Probabilistic Graphical Models (PGMs).\n    ",
        "submission_date": "2017-05-10T00:00:00",
        "last_modified_date": "2017-05-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.03773",
        "title": "Flexible and Creative Chinese Poetry Generation Using Neural Memory",
        "authors": [
            "Jiyuan Zhang",
            "Yang Feng",
            "Dong Wang",
            "Yang Wang",
            "Andrew Abel",
            "Shiyue Zhang",
            "Andi Zhang"
        ],
        "abstract": "It has been shown that Chinese poems can be successfully generated by sequence-to-sequence neural models, particularly with the attention mechanism. A potential problem of this approach, however, is that neural models can only learn abstract rules, while poem generation is a highly creative process that involves not only rules but also innovations for which pure statistical models are not appropriate in principle. This work proposes a memory-augmented neural model for Chinese poem generation, where the neural model and the augmented memory work together to balance the requirements of linguistic accordance and aesthetic innovation, leading to innovative generations that are still rule-compliant. In addition, it is found that the memory mechanism provides interesting flexibility that can be used to generate poems with different styles.\n    ",
        "submission_date": "2017-05-10T00:00:00",
        "last_modified_date": "2017-05-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.03821",
        "title": "Context Attentive Bandits: Contextual Bandit with Restricted Context",
        "authors": [
            "Djallel Bouneffouf",
            "Irina Rish",
            "Guillermo A. Cecchi",
            "Raphael Feraud"
        ],
        "abstract": "We consider a novel formulation of the multi-armed bandit model, which we call the contextual bandit with restricted context, where only a limited number of features can be accessed by the learner at every iteration. This novel formulation is motivated by different online problems arising in clinical trials, recommender systems and attention modeling. Herein, we adapt the standard multi-armed bandit algorithm known as Thompson Sampling to take advantage of our restricted context setting, and propose two novel algorithms, called the Thompson Sampling with Restricted Context(TSRC) and the Windows Thompson Sampling with Restricted Context(WTSRC), for handling stationary and nonstationary environments, respectively. Our empirical results demonstrate advantages of the proposed approaches on several real-life datasets\n    ",
        "submission_date": "2017-05-10T00:00:00",
        "last_modified_date": "2017-06-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.04119",
        "title": "Memetic search for identifying critical nodes in sparse graphs",
        "authors": [
            "Yangming Zhou",
            "Jin-Kao Hao",
            "Fred Glover"
        ],
        "abstract": "Critical node problems involve identifying a subset of critical nodes from an undirected graph whose removal results in optimizing a pre-defined measure over the residual graph. As useful models for a variety of practical applications, these problems are computational challenging. In this paper, we study the classic critical node problem (CNP) and introduce an effective memetic algorithm for solving CNP. The proposed algorithm combines a double backbone-based crossover operator (to generate promising offspring solutions), a component-based neighborhood search procedure (to find high-quality local optima) and a rank-based pool updating strategy (to guarantee a healthy population). Specially, the component-based neighborhood search integrates two key techniques, i.e., two-phase node exchange strategy and node weighting scheme. The double backbone-based crossover extends the idea of general backbone-based crossovers. Extensive evaluations on 42 synthetic and real-world benchmark instances show that the proposed algorithm discovers 21 new upper bounds and matches 18 previous best-known upper bounds. We also demonstrate the relevance of our algorithm for effectively solving a variant of the classic CNP, called the cardinality-constrained critical node problem. Finally, we investigate the usefulness of each key algorithmic component.\n    ",
        "submission_date": "2017-05-11T00:00:00",
        "last_modified_date": "2017-10-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.04146",
        "title": "Program Induction by Rationale Generation : Learning to Solve and Explain Algebraic Word Problems",
        "authors": [
            "Wang Ling",
            "Dani Yogatama",
            "Chris Dyer",
            "Phil Blunsom"
        ],
        "abstract": "Solving algebraic word problems requires executing a series of arithmetic operations---a program---to obtain a final answer. However, since programs can be arbitrarily complicated, inducing them directly from question-answer pairs is a formidable challenge. To make this task more feasible, we solve these problems by generating answer rationales, sequences of natural language and human-readable mathematical expressions that derive the final answer through a series of small steps. Although rationales do not explicitly specify programs, they provide a scaffolding for their structure via intermediate milestones. To evaluate our approach, we have created a new 100,000-sample dataset of questions, answers and rationales. Experimental results show that indirect supervision of program learning via answer rationales is a promising strategy for inducing arithmetic programs.\n    ",
        "submission_date": "2017-05-11T00:00:00",
        "last_modified_date": "2017-10-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.04185",
        "title": "A First Empirical Study of Emphatic Temporal Difference Learning",
        "authors": [
            "Sina Ghiassian",
            "Banafsheh Rafiee",
            "Richard S. Sutton"
        ],
        "abstract": "In this paper we present the first empirical study of the emphatic temporal-difference learning algorithm (ETD), comparing it with conventional temporal-difference learning, in particular, with linear TD(0), on on-policy and off-policy variations of the Mountain Car problem. The initial motivation for developing ETD was that it has good convergence properties under off-policy training (Sutton, Mahmood and White 2016), but it is also a new algorithm for the on-policy case. In both our on-policy and off-policy experiments, we found that each method converged to a characteristic asymptotic level of error, with ETD better than TD(0). TD(0) achieved a still lower error level temporarily before falling back to its higher asymptote, whereas ETD never showed this kind of \"bounce\". In the off-policy case (in which TD(0) is not guaranteed to converge), ETD was significantly slower.\n    ",
        "submission_date": "2017-05-11T00:00:00",
        "last_modified_date": "2017-05-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.04351",
        "title": "A rational analysis of curiosity",
        "authors": [
            "Rachit Dubey",
            "Thomas L. Griffiths"
        ],
        "abstract": "We present a rational analysis of curiosity, proposing that people's curiosity is driven by seeking stimuli that maximize their ability to make appropriate responses in the future. This perspective offers a way to unify previous theories of curiosity into a single framework. Experimental results confirm our model's predictions, showing how the relationship between curiosity and confidence can change significantly depending on the nature of the environment. Please refer to ",
        "submission_date": "2017-05-11T00:00:00",
        "last_modified_date": "2020-08-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.04530",
        "title": "A Survey of Question Answering for Math and Science Problem",
        "authors": [
            "Arindam Bhattacharya"
        ],
        "abstract": "Turing test was long considered the measure for artificial intelligence. But with the advances in AI, it has proved to be insufficient measure. We can now aim to mea- sure machine intelligence like we measure human intelligence. One of the widely accepted measure of intelligence is standardized math and science test. In this paper, we explore the progress we have made towards the goal of making a machine smart enough to pass the standardized test. We see the challenges and opportunities posed by the domain, and note that we are quite some ways from actually making a system as smart as a even a middle school scholar.\n    ",
        "submission_date": "2017-05-10T00:00:00",
        "last_modified_date": "2017-05-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.04569",
        "title": "Clingcon: The Next Generation",
        "authors": [
            "Mutsunori Banbara",
            "Benjamin Kaufmann",
            "Max Ostrowski",
            "Torsten Schaub"
        ],
        "abstract": "We present the third generation of the constraint answer set system clingcon, combining Answer Set Programming (ASP) with finite domain constraint processing (CP). While its predecessors rely on a black-box approach to hybrid solving by integrating the CP solver gecode, the new clingcon system pursues a lazy approach using dedicated constraint propagators to extend propagation in the underlying ASP solver clasp. No extension is needed for parsing and grounding clingcon's hybrid modeling language since both can be accommodated by the new generic theory handling capabilities of the ASP grounder gringo. As a whole, clingcon 3 is thus an extension of the ASP system clingo 5, which itself relies on the grounder gringo and the solver clasp. The new approach of clingcon offers a seamless integration of CP propagation into ASP solving that benefits from the whole spectrum of clasp's reasoning modes, including for instance multi-shot solving and advanced optimization techniques. This is accomplished by a lazy approach that unfolds the representation of constraints and adds it to that of the logic program only when needed. Although the unfolding is usually dictated by the constraint propagators during solving, it can already be partially (or even totally) done during preprocessing. Moreover, clingcon's constraint preprocessing and propagation incorporate several well established CP techniques that greatly improve its performance. We demonstrate this via an extensive empirical evaluation contrasting, first, the various techniques in the context of CSP solving and, second, the new clingcon system with other hybrid ASP systems. Under consideration in Theory and Practice of Logic Programming (TPLP)\n    ",
        "submission_date": "2017-05-12T00:00:00",
        "last_modified_date": "2017-05-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.04665",
        "title": "A Formal Characterization of the Local Search Topology of the Gap Heuristic",
        "authors": [
            "Richard Anthony Valenzano",
            "Danniel Sihui Yang"
        ],
        "abstract": "The pancake puzzle is a classic optimization problem that has become a standard benchmark for heuristic search algorithms. In this paper, we provide full proofs regarding the local search topology of the gap heuristic for the pancake puzzle. First, we show that in any non-goal state in which there is no move that will decrease the number of gaps, there is a move that will keep the number of gaps constant. We then classify any state in which the number of gaps cannot be decreased in a single action into two groups: those requiring 2 actions to decrease the number of gaps, and those which require 3 actions to decrease the number of gaps.\n    ",
        "submission_date": "2017-05-12T00:00:00",
        "last_modified_date": "2017-05-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.04712",
        "title": "Progression of Decomposed Local-Effect Action Theories",
        "authors": [
            "Denis Ponomaryov",
            "Mikhail Soutchanski"
        ],
        "abstract": "In many tasks related to reasoning about consequences of a logical theory, it is desirable to decompose the theory into a number of weakly-related or independent components. However, a theory may represent knowledge that is subject to change, as a result of executing actions that have effects on some of the initial properties mentioned in the theory. Having once computed a decomposition of a theory, it is advantageous to know whether a decomposition has to be computed again in the newly-changed theory (obtained from taking into account changes resulting from execution of an action). In the paper, we address this problem in the scope of the situation calculus, where a change of an initial theory is related to the notion of progression. Progression provides a form of forward reasoning; it relies on forgetting values of those properties, which are subject to change, and computing new values for them. We consider decomposability and inseparability, two component properties known from the literature, and contribute by 1) studying the conditions when these properties are preserved and 2) when they are lost wrt progression and the related operation of forgetting. To show the latter, we demonstrate the boundaries using a number of negative examples. To show the former, we identify cases when these properties are preserved under forgetting and progression of initial theories in local-effect basic action theories of the situation calculus. Our paper contributes to bridging two different communities in Knowledge Representation, namely research on modularity and research on reasoning about actions.\n    ",
        "submission_date": "2017-05-12T00:00:00",
        "last_modified_date": "2017-05-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.04719",
        "title": "On the Complexity of Semantic Integration of OWL Ontologies",
        "authors": [
            "Yevgeny Kazakov",
            "Denis Ponomaryov"
        ],
        "abstract": "We propose a new mechanism for integration of OWL ontologies using semantic import relations. In contrast to the standard OWL importing, we do not require all axioms of the imported ontologies to be taken into account for reasoning tasks, but only their logical implications over a chosen signature. This property comes natural in many ontology integration scenarios, especially when the number of ontologies is large. In this paper, we study the complexity of reasoning over ontologies with semantic import relations and establish a range of tight complexity bounds for various fragments of OWL.\n    ",
        "submission_date": "2017-05-12T00:00:00",
        "last_modified_date": "2017-05-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.04885",
        "title": "Awareness improves problem-solving performance",
        "authors": [
            "Jos\u00e9 F. Fontanari"
        ],
        "abstract": "The brain's self-monitoring of activities, including internal activities -- a functionality that we refer to as awareness -- has been suggested as a key element of consciousness. Here we investigate whether the presence of an inner-eye-like process (monitor) that supervises the activities of a number of subsystems (operative agents) engaged in the solution of a problem can improve the problem-solving efficiency of the system. The problem is to find the global maximum of a NK fitness landscape and the performance is measured by the time required to find that maximum. The operative agents explore blindly the fitness landscape and the monitor provides them with feedback on the quality (fitness) of the proposed solutions. This feedback is then used by the operative agents to bias their searches towards the fittest regions of the landscape. We find that a weak feedback between the monitor and the operative agents improves the performance of the system, regardless of the difficulty of the problem, which is gauged by the number of local maxima in the landscape. For easy problems (i.e., landscapes without local maxima), the performance improves monotonically as the feedback strength increases, but for difficult problems, there is an optimal value of the feedback strength beyond which the system performance degrades very rapidly.\n    ",
        "submission_date": "2017-05-13T00:00:00",
        "last_modified_date": "2017-05-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.05098",
        "title": "Quantifying Aspect Bias in Ordinal Ratings using a Bayesian Approach",
        "authors": [
            "Lahari Poddar",
            "Wynne Hsu",
            "Mong Li Lee"
        ],
        "abstract": "User opinions expressed in the form of ratings can influence an individual's view of an item. However, the true quality of an item is often obfuscated by user biases, and it is not obvious from the observed ratings the importance different users place on different aspects of an item. We propose a probabilistic modeling of the observed aspect ratings to infer (i) each user's aspect bias and (ii) latent intrinsic quality of an item. We model multi-aspect ratings as ordered discrete data and encode the dependency between different aspects by using a latent Gaussian structure. We handle the Gaussian-Categorical non-conjugacy using a stick-breaking formulation coupled with P\u00f3lya-Gamma auxiliary variable augmentation for a simple, fully Bayesian inference. On two real world datasets, we demonstrate the predictive ability of our model and its effectiveness in learning explainable user biases to provide insights towards a more reliable product quality estimation.\n    ",
        "submission_date": "2017-05-15T00:00:00",
        "last_modified_date": "2017-05-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.05254",
        "title": "Strategically knowing how",
        "authors": [
            "Raul Fervari",
            "Andreas Herzig",
            "Yanjun Li",
            "Yanjing Wang"
        ],
        "abstract": "In this paper, we propose a single-agent logic of goal-directed knowing how extending the standard epistemic logic of knowing that with a new knowing how operator. The semantics of the new operator is based on the idea that knowing how to achieve $\\phi$ means that there exists a (uniform) strategy such that the agent knows that it can make sure $\\phi$. We give an intuitive axiomatization of our logic and prove the soundness, completeness, and decidability of the logic. The crucial axioms relating knowing that and knowing how illustrate our understanding of knowing how in this setting. This logic can be used in representing both knowledge-that and knowledge-how.\n    ",
        "submission_date": "2017-05-15T00:00:00",
        "last_modified_date": "2017-05-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.05316",
        "title": "Exploiting the Pruning Power of Strong Local Consistencies Through Parallelization",
        "authors": [
            "Minas Dasygenis",
            "Kostas Stergiou"
        ],
        "abstract": "Local consistencies stronger than arc consistency have received a lot of attention since the early days of CSP research. %because of the strong pruning they can achieve. However, they have not been widely adopted by CSP solvers. This is because applying such consistencies can sometimes result in considerably smaller search tree sizes and therefore in important speed-ups, but in other cases the search space reduction may be small, causing severe run time penalties. Taking advantage of recent advances in parallelization, we propose a novel approach for the application of strong local consistencies (SLCs) that can improve their performance by largely preserving the speed-ups they offer in cases where they are successful, and eliminating the run time penalties in cases where they are unsuccessful. This approach is presented in the form of two search algorithms. Both algorithms consist of a master search process, which is a typical CSP solver, and a number of slave processes, with each one implementing a SLC method. The first algorithm runs the different SLCs synchronously at each node of the search tree explored in the master process, while the second one can run them asynchronously at different nodes of the search tree. Experimental results demonstrate the benefits of the proposed method.\n    ",
        "submission_date": "2017-05-15T00:00:00",
        "last_modified_date": "2017-05-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.05326",
        "title": "Constrained Bayesian Networks: Theory, Optimization, and Applications",
        "authors": [
            "Paul Beaumont",
            "Michael Huth"
        ],
        "abstract": "We develop the theory and practice of an approach to modelling and probabilistic inference in causal networks that is suitable when application-specific or analysis-specific constraints should inform such inference or when little or no data for the learning of causal network structure or probability values at nodes are available. Constrained Bayesian Networks generalize a Bayesian Network such that probabilities can be symbolic, arithmetic expressions and where the meaning of the network is constrained by finitely many formulas from the theory of the reals. A formal semantics for constrained Bayesian Networks over first-order logic of the reals is given, which enables non-linear and non-convex optimisation algorithms that rely on decision procedures for this logic, and supports the composition of several constrained Bayesian Networks. A non-trivial case study in arms control, where few or no data are available to assess the effectiveness of an arms inspection process, evaluates our approach. An open-access prototype implementation of these foundations and their algorithms uses the SMT solver Z3 as decision procedure, leverages an open-source package for Bayesian inference to symbolic computation, and is evaluated experimentally.\n    ",
        "submission_date": "2017-05-15T00:00:00",
        "last_modified_date": "2017-05-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.05427",
        "title": "Repeated Inverse Reinforcement Learning",
        "authors": [
            "Kareem Amin",
            "Nan Jiang",
            "Satinder Singh"
        ],
        "abstract": "We introduce a novel repeated Inverse Reinforcement Learning problem: the agent has to act on behalf of a human in a sequence of tasks and wishes to minimize the number of tasks that it surprises the human by acting suboptimally with respect to how the human would have acted. Each time the human is surprised, the agent is provided a demonstration of the desired behavior by the human. We formalize this problem, including how the sequence of tasks is chosen, in a few different ways and provide some foundational results.\n    ",
        "submission_date": "2017-05-15T00:00:00",
        "last_modified_date": "2017-11-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.05515",
        "title": "A Method for Determining Weights of Criterias and Alternative of Fuzzy Group Decision Making Problem",
        "authors": [
            "Jon JaeGyong",
            "Mun JongHui",
            "Ryang GyongIl"
        ],
        "abstract": "In this paper, we constructed a model to determine weights of criterias and presented a solution for determining the optimal alternative by using the constructed model and relationship analysis between criterias in fuzzy group decision-making problem with different forms of preference information of decision makers on criterias.\n    ",
        "submission_date": "2017-05-16T00:00:00",
        "last_modified_date": "2017-05-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.05524",
        "title": "Learning Hard Alignments with Variational Inference",
        "authors": [
            "Dieterich Lawson",
            "Chung-Cheng Chiu",
            "George Tucker",
            "Colin Raffel",
            "Kevin Swersky",
            "Navdeep Jaitly"
        ],
        "abstract": "There has recently been significant interest in hard attention models for tasks such as object recognition, visual captioning and speech recognition. Hard attention can offer benefits over soft attention such as decreased computational cost, but training hard attention models can be difficult because of the discrete latent variables they introduce. Previous work used REINFORCE and Q-learning to approach these issues, but those methods can provide high-variance gradient estimates and be slow to train. In this paper, we tackle the problem of learning hard attention for a sequential task using variational inference methods, specifically the recently introduced VIMCO and NVIL. Furthermore, we propose a novel baseline that adapts VIMCO to this setting. We demonstrate our method on a phoneme recognition task in clean and noisy environments and show that our method outperforms REINFORCE, with the difference being greater for a more complicated task.\n    ",
        "submission_date": "2017-05-16T00:00:00",
        "last_modified_date": "2017-11-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.05551",
        "title": "New Reinforcement Learning Using a Chaotic Neural Network for Emergence of \"Thinking\" - \"Exploration\" Grows into \"Thinking\" through Learning -",
        "authors": [
            "Katsunari Shibata",
            "Yuki Goto"
        ],
        "abstract": "Expectation for the emergence of higher functions is getting larger in the framework of end-to-end reinforcement learning using a recurrent neural network. However, the emergence of \"thinking\" that is a typical higher function is difficult to realize because \"thinking\" needs non fixed-point, flow-type attractors with both convergence and transition dynamics. Furthermore, in order to introduce \"inspiration\" or \"discovery\" in \"thinking\", not completely random but unexpected transition should be also required.\n",
        "submission_date": "2017-05-16T00:00:00",
        "last_modified_date": "2017-05-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.05637",
        "title": "Text-based Adventures of the Golovin AI Agent",
        "authors": [
            "Bartosz Kostka",
            "Jaroslaw Kwiecien",
            "Jakub Kowalski",
            "Pawel Rychlikowski"
        ],
        "abstract": "The domain of text-based adventure games has been recently established as a new challenge of creating the agent that is both able to understand natural language, and acts intelligently in text-described environments.\n",
        "submission_date": "2017-05-16T00:00:00",
        "last_modified_date": "2017-05-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.05742",
        "title": "Know-Evolve: Deep Temporal Reasoning for Dynamic Knowledge Graphs",
        "authors": [
            "Rakshit Trivedi",
            "Hanjun Dai",
            "Yichen Wang",
            "Le Song"
        ],
        "abstract": "The availability of large scale event data with time stamps has given rise to dynamically evolving knowledge graphs that contain temporal information for each edge. Reasoning over time in such dynamic knowledge graphs is not yet well understood. To this end, we present Know-Evolve, a novel deep evolutionary knowledge network that learns non-linearly evolving entity representations over time. The occurrence of a fact (edge) is modeled as a multivariate point process whose intensity function is modulated by the score for that fact computed based on the learned entity embeddings. We demonstrate significantly improved performance over various relational learning approaches on two large scale real-world datasets. Further, our method effectively predicts occurrence or recurrence time of a fact which is novel compared to prior reasoning approaches in multi-relational setting.\n    ",
        "submission_date": "2017-05-16T00:00:00",
        "last_modified_date": "2017-06-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.05756",
        "title": "All-relevant feature selection using multidimensional filters with exhaustive search",
        "authors": [
            "Krzysztof Mnich",
            "Witold R. Rudnicki"
        ],
        "abstract": "This paper describes a method for identification of the informative variables in the information system with discrete decision variables. It is targeted specifically towards discovery of the variables that are non-informative when considered alone, but are informative when the synergistic interactions between multiple variables are considered. To this end, the mutual entropy of all possible k-tuples of variables with decision variable is computed. Then, for each variable the maximal information gain due to interactions with other variables is obtained. For non-informative variables this quantity conforms to the well known statistical distributions. This allows for discerning truly informative variables from non-informative ones. For demonstration of the approach, the method is applied to several synthetic datasets that involve complex multidimensional interactions between variables. It is capable of identifying most important informative variables, even in the case when the dimensionality of the analysis is smaller than the true dimensionality of the problem. What is more, the high sensitivity of the algorithm allows for detection of the influence of nuisance variables on the response variable.\n    ",
        "submission_date": "2017-05-16T00:00:00",
        "last_modified_date": "2017-05-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.05765",
        "title": "Online Article Ranking as a Constrained, Dynamic, Multi-Objective Optimization Problem",
        "authors": [
            "Jeya Balaji Balasubramanian",
            "Akshay Soni",
            "Yashar Mehdad",
            "Nikolay Laptev"
        ],
        "abstract": "The content ranking problem in a social news website, is typically a function that maximizes a scalar metric of interest like dwell-time. However, like in most real-world applications we are interested in more than one metric---for instance simultaneously maximizing click-through rate, monetization metrics, dwell-time---and also satisfy the traffic requirements promised to different publishers. All this needs to be done on online data and under the settings where the objective function and the constraints can dynamically change; this could happen if for instance new publishers are added, some contracts are adjusted, or if some contracts are over.\n",
        "submission_date": "2017-05-16T00:00:00",
        "last_modified_date": "2017-05-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.05769",
        "title": "Multiobjective Programming for Type-2 Hierarchical Fuzzy Inference Trees",
        "authors": [
            "Varun Kumar Ojha",
            "Vaclav Snasel",
            "Ajith Abraham"
        ],
        "abstract": "This paper proposes a design of hierarchical fuzzy inference tree (HFIT). An HFIT produces an optimum treelike structure, i.e., a natural hierarchical structure that accommodates simplicity by combining several low-dimensional fuzzy inference systems (FISs). Such a natural hierarchical structure provides a high degree of approximation accuracy. The construction of HFIT takes place in two phases. Firstly, a nondominated sorting based multiobjective genetic programming (MOGP) is applied to obtain a simple tree structure (a low complexity model) with a high accuracy. Secondly, the differential evolution algorithm is applied to optimize the obtained tree's parameters. In the derived tree, each node acquires a different input's combination, where the evolutionary process governs the input's combination. Hence, HFIT nodes are heterogeneous in nature, which leads to a high diversity among the rules generated by the HFIT. Additionally, the HFIT provides an automatic feature selection because it uses MOGP for the tree's structural optimization that accepts inputs only relevant to the knowledge contained in data. The HFIT was studied in the context of both type-1 and type-2 FISs, and its performance was evaluated through six application problems. Moreover, the proposed multiobjective HFIT was compared both theoretically and empirically with recently proposed FISs methods from the literature, such as McIT2FIS, TSCIT2FNN, SIT2FNN, RIT2FNS-WB, eT2FIS, MRIT2NFS, IT2FNN-SVR, etc. From the obtained results, it was found that the HFIT provided less complex and highly accurate models compared to the models produced by the most of other methods. Hence, the proposed HFIT is an efficient and competitive alternative to the other FISs for function approximation and feature selection.\n    ",
        "submission_date": "2017-05-16T00:00:00",
        "last_modified_date": "2017-05-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.05785",
        "title": "Demystifying Relational Latent Representations",
        "authors": [
            "Sebastijan Duman\u010di\u0107",
            "Hendrik Blockeel"
        ],
        "abstract": "Latent features learned by deep learning approaches have proven to be a powerful tool for machine learning. They serve as a data abstraction that makes learning easier by capturing regularities in data explicitly. Their benefits motivated their adaptation to relational learning context. In our previous work, we introduce an approach that learns relational latent features by means of clustering instances and their relations. The major drawback of latent representations is that they are often black-box and difficult to interpret. This work addresses these issues and shows that (1) latent features created by clustering are interpretable and capture interesting properties of data; (2) they identify local regions of instances that match well with the label, which partially explains their benefit; and (3) although the number of latent features generated by this approach is large, often many of them are highly redundant and can be removed without hurting performance much.\n    ",
        "submission_date": "2017-05-16T00:00:00",
        "last_modified_date": "2017-09-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.05983",
        "title": "AI, Native Supercomputing and The Revival of Moore's Law",
        "authors": [
            "Chien-Ping Lu"
        ],
        "abstract": "Based on Alan Turing's proposition on AI and computing machinery, which shaped Computing as we know it today, the new AI computing machinery should comprise a universal computer and a universal learning machine. The later should understand linear algebra natively to overcome the slowdown of Moore's law. In such a universal learnig machine, a computing unit does not need to keep the legacy of a universal computing core. The data can be distributed to the computing units, and the results can be collected from them through Collective Streaming, reminiscent of Collective Communication in Supercomputing. It is not necessary to use a GPU-like deep memory hierarchy, nor a TPU-like fine-grain mesh.\n    ",
        "submission_date": "2017-05-17T00:00:00",
        "last_modified_date": "2017-05-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.05986",
        "title": "REMIX: Automated Exploration for Interactive Outlier Detection",
        "authors": [
            "Yanjie Fu",
            "Charu Aggarwal",
            "Srinivasan Parthasarathy",
            "Deepak S. Turaga",
            "Hui Xiong"
        ],
        "abstract": "Outlier detection is the identification of points in a dataset that do not conform to the norm. Outlier detection is highly sensitive to the choice of the detection algorithm and the feature subspace used by the algorithm. Extracting domain-relevant insights from outliers needs systematic exploration of these choices since diverse outlier sets could lead to complementary insights. This challenge is especially acute in an interactive setting, where the choices must be explored in a time-constrained manner. In this work, we present REMIX, the first system to address the problem of outlier detection in an interactive setting. REMIX uses a novel mixed integer programming (MIP) formulation for automatically selecting and executing a diverse set of outlier detectors within a time limit. This formulation incorporates multiple aspects such as (i) an upper limit on the total execution time of detectors (ii) diversity in the space of algorithms and features, and (iii) meta-learning for evaluating the cost and utility of detectors. REMIX provides two distinct ways for the analyst to consume its results: (i) a partitioning of the detectors explored by REMIX into perspectives through low-rank non-negative matrix factorization; each perspective can be easily visualized as an intuitive heatmap of experiments versus outliers, and (ii) an ensembled set of outliers which combines outlier scores from all detectors. We demonstrate the benefits of REMIX through extensive empirical validation on real-world data.\n    ",
        "submission_date": "2017-05-17T00:00:00",
        "last_modified_date": "2017-05-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.06058",
        "title": "Pitfalls and Best Practices in Algorithm Configuration",
        "authors": [
            "Katharina Eggensperger",
            "Marius Lindauer",
            "Frank Hutter"
        ],
        "abstract": "Good parameter settings are crucial to achieve high performance in many areas of artificial intelligence (AI), such as propositional satisfiability solving, AI planning, scheduling, and machine learning (in particular deep learning). Automated algorithm configuration methods have recently received much attention in the AI community since they replace tedious, irreproducible and error-prone manual parameter tuning and can lead to new state-of-the-art performance. However, practical applications of algorithm configuration are prone to several (often subtle) pitfalls in the experimental design that can render the procedure ineffective. We identify several common issues and propose best practices for avoiding them. As one possibility for automatically handling as many of these as possible, we also propose a tool called GenericWrapper4AC.\n    ",
        "submission_date": "2017-05-17T00:00:00",
        "last_modified_date": "2019-03-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.06342",
        "title": "Identification and Off-Policy Learning of Multiple Objectives Using Adaptive Clustering",
        "authors": [
            "Thommen George Karimpanal",
            "Erik Wilhelm"
        ],
        "abstract": "In this work, we present a methodology that enables an agent to make efficient use of its exploratory actions by autonomously identifying possible objectives in its environment and learning them in parallel. The identification of objectives is achieved using an online and unsupervised adaptive clustering algorithm. The identified objectives are learned (at least partially) in parallel using Q-learning. Using a simulated agent and environment, it is shown that the converged or partially converged value function weights resulting from off-policy learning can be used to accumulate knowledge about multiple objectives without any additional exploration. We claim that the proposed approach could be useful in scenarios where the objectives are initially unknown or in real world scenarios where exploration is typically a time and energy intensive process. The implications and possible extensions of this work are also briefly discussed.\n    ",
        "submission_date": "2017-05-17T00:00:00",
        "last_modified_date": "2017-05-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.06390",
        "title": "Scalable Exact Parent Sets Identification in Bayesian Networks Learning with Apache Spark",
        "authors": [
            "Subhadeep Karan",
            "Jaroslaw Zola"
        ],
        "abstract": "In Machine Learning, the parent set identification problem is to find a set of random variables that best explain selected variable given the data and some predefined scoring function. This problem is a critical component to structure learning of Bayesian networks and Markov blankets discovery, and thus has many practical applications, ranging from fraud detection to clinical decision support. In this paper, we introduce a new distributed memory approach to the exact parent sets assignment problem. To achieve scalability, we derive theoretical bounds to constraint the search space when MDL scoring function is used, and we reorganize the underlying dynamic programming such that the computational density is increased and fine-grain synchronization is eliminated. We then design efficient realization of our approach in the Apache Spark platform. Through experimental results, we demonstrate that the method maintains strong scalability on a 500-core standalone Spark cluster, and it can be used to efficiently process data sets with 70 variables, far beyond the reach of the currently available solutions.\n    ",
        "submission_date": "2017-05-18T00:00:00",
        "last_modified_date": "2017-10-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.06564",
        "title": "Stepwise Debugging of Answer-Set Programs",
        "authors": [
            "Johannes Oetsch",
            "J\u00f6rg P\u00fchrer",
            "Hans Tompits"
        ],
        "abstract": "We introduce a stepping methodology for answer-set programming (ASP) that allows for debugging answer-set programs and is based on the stepwise application of rules. Similar to debugging in imperative languages, where the behaviour of a program is observed during a step-by-step execution, stepping for ASP allows for observing the effects that rule applications have in the computation of an answer set. While the approach is inspired from debugging in imperative programming, it is conceptually different to stepping in other paradigms due to non-determinism and declarativity that are inherent to ASP. In particular, unlike statements in an imperative program that are executed following a strict control flow, there is no predetermined order in which to consider rules in ASP during a computation. In our approach, the user is free to decide which rule to consider active in the next step following his or her intuition. This way, one can focus on interesting parts of the debugging search space. Bugs are detected during stepping by revealing differences between the actual semantics of the program and the expectations of the user. As a solid formal basis for stepping, we develop a framework of computations for answer-set programs. For fully supporting different solver languages, we build our framework on an abstract ASP language that is sufficiently general to capture different solver languages. To this end, we make use of abstract constraints as an established abstraction for popular language constructs such as aggregates. Stepping has been implemented in SeaLion, an integrated development environment for ASP. We illustrate stepping using an example scenario and discuss the stepping plugin of SeaLion. Moreover, we elaborate on methodological aspects and the embedding of stepping in the ASP development process.\n    ",
        "submission_date": "2017-05-18T00:00:00",
        "last_modified_date": "2017-05-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.06578",
        "title": "An evidential Markov decision making model",
        "authors": [
            "Zichang He",
            "Wen Jiang"
        ],
        "abstract": "The sure thing principle and the law of total probability are basic laws in classic probability theory. A disjunction fallacy leads to the violation of these two classical laws. In this paper, an Evidential Markov (EM) decision making model based on Dempster-Shafer (D-S) evidence theory and Markov modelling is proposed to address this issue and model the real human decision-making process. In an evidential framework, the states are extended by introducing an uncertain state which represents the hesitance of a decision maker. The classical Markov model can not produce the disjunction effect, which assumes that a decision has to be certain at one time. However, the state is allowed to be uncertain in the EM model before the final decision is made. An extra uncertainty degree parameter is defined by a belief entropy, named Deng entropy, to assignment the basic probability assignment of the uncertain state, which is the key to predict the disjunction effect. A classical categorization decision-making experiment is used to illustrate the effectiveness and validity of EM model. The disjunction effect can be well predicted and the free parameters are less compared with the existing models.\n    ",
        "submission_date": "2017-05-10T00:00:00",
        "last_modified_date": "2017-05-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.06840",
        "title": "The Conference Paper Assignment Problem: Using Order Weighted Averages to Assign Indivisible Goods",
        "authors": [
            "Jing Wu Lian",
            "Nicholas Mattei",
            "Renee Noble",
            "Toby Walsh"
        ],
        "abstract": "Motivated by the common academic problem of allocating papers to referees for conference reviewing we propose a novel mechanism for solving the assignment problem when we have a two sided matching problem with preferences from one side (the agents/reviewers) over the other side (the objects/papers) and both sides have capacity constraints. The assignment problem is a fundamental problem in both computer science and economics with application in many areas including task and resource allocation. We draw inspiration from multi-criteria decision making and voting and use order weighted averages (OWAs) to propose a novel and flexible class of algorithms for the assignment problem. We show an algorithm for finding a $\\Sigma$-OWA assignment in polynomial time, in contrast to the NP-hardness of finding an egalitarian assignment. Inspired by this setting we observe an interesting connection between our model and the classic proportional multi-winner election problem in social choice.\n    ",
        "submission_date": "2017-05-19T00:00:00",
        "last_modified_date": "2017-05-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.06927",
        "title": "Foundations of Declarative Data Analysis Using Limit Datalog Programs",
        "authors": [
            "Mark Kaminski",
            "Bernardo Cuenca Grau",
            "Egor V. Kostylev",
            "Boris Motik",
            "Ian Horrocks"
        ],
        "abstract": "Motivated by applications in declarative data analysis, we study $\\mathit{Datalog}_{\\mathbb{Z}}$---an extension of positive Datalog with arithmetic functions over integers. This language is known to be undecidable, so we propose two fragments. In $\\mathit{limit}~\\mathit{Datalog}_{\\mathbb{Z}}$ predicates are axiomatised to keep minimal/maximal numeric values, allowing us to show that fact entailment is coNExpTime-complete in combined, and coNP-complete in data complexity. Moreover, an additional $\\mathit{stability}$ requirement causes the complexity to drop to ExpTime and PTime, respectively. Finally, we show that stable $\\mathit{Datalog}_{\\mathbb{Z}}$ can express many useful data analysis tasks, and so our results provide a sound foundation for the development of advanced information systems.\n    ",
        "submission_date": "2017-05-19T00:00:00",
        "last_modified_date": "2017-11-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.07095",
        "title": "Induction of Interpretable Possibilistic Logic Theories from Relational Data",
        "authors": [
            "Ondrej Kuzelka",
            "Jesse Davis",
            "Steven Schockaert"
        ],
        "abstract": "The field of Statistical Relational Learning (SRL) is concerned with learning probabilistic models from relational data. Learned SRL models are typically represented using some kind of weighted logical formulas, which make them considerably more interpretable than those obtained by e.g. neural networks. In practice, however, these models are often still difficult to interpret correctly, as they can contain many formulas that interact in non-trivial ways and weights do not always have an intuitive meaning. To address this, we propose a new SRL method which uses possibilistic logic to encode relational models. Learned models are then essentially stratified classical theories, which explicitly encode what can be derived with a given level of certainty. Compared to Markov Logic Networks (MLNs), our method is faster and produces considerably more interpretable models.\n    ",
        "submission_date": "2017-05-19T00:00:00",
        "last_modified_date": "2017-05-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.07105",
        "title": "The Bag Semantics of Ontology-Based Data Access",
        "authors": [
            "Charalampos Nikolaou",
            "Egor V. Kostylev",
            "George Konstantinidis",
            "Mark Kaminski",
            "Bernardo Cuenca Grau",
            "Ian Horrocks"
        ],
        "abstract": "Ontology-based data access (OBDA) is a popular approach for integrating and querying multiple data sources by means of a shared ontology. The ontology is linked to the sources using mappings, which assign views over the data to ontology predicates. Motivated by the need for OBDA systems supporting database-style aggregate queries, we propose a bag semantics for OBDA, where duplicate tuples in the views defined by the mappings are retained, as is the case in standard databases. We show that bag semantics makes conjunctive query answering in OBDA coNP-hard in data complexity. To regain tractability, we consider a rather general class of queries and show its rewritability to a generalisation of the relational calculus to bags.\n    ",
        "submission_date": "2017-05-19T00:00:00",
        "last_modified_date": "2017-05-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.07177",
        "title": "Model-Based Planning with Discrete and Continuous Actions",
        "authors": [
            "Mikael Henaff",
            "William F. Whitney",
            "Yann LeCun"
        ],
        "abstract": "Action planning using learned and differentiable forward models of the world is a general approach which has a number of desirable properties, including improved sample complexity over model-free RL methods, reuse of learned models across different tasks, and the ability to perform efficient gradient-based optimization in continuous action spaces. However, this approach does not apply straightforwardly when the action space is discrete. In this work, we show that it is in fact possible to effectively perform planning via backprop in discrete action spaces, using a simple paramaterization of the actions vectors on the simplex combined with input noise when training the forward model. Our experiments show that this approach can match or outperform model-free RL and discrete planning methods on gridworld navigation tasks in terms of performance and/or planning time while using limited environment interactions, and can additionally be used to perform model-based control in a challenging new task where the action space combines discrete and continuous actions. We furthermore propose a policy distillation approach which yields a fast policy network which can be used at inference time, removing the need for an iterative planning procedure.\n    ",
        "submission_date": "2017-05-19T00:00:00",
        "last_modified_date": "2018-04-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.07215",
        "title": "On Convergence and Stability of GANs",
        "authors": [
            "Naveen Kodali",
            "Jacob Abernethy",
            "James Hays",
            "Zsolt Kira"
        ],
        "abstract": "We propose studying GAN training dynamics as regret minimization, which is in contrast to the popular view that there is consistent minimization of a divergence between real and generated distributions. We analyze the convergence of GAN training from this new point of view to understand why mode collapse happens. We hypothesize the existence of undesirable local equilibria in this non-convex game to be responsible for mode collapse. We observe that these local equilibria often exhibit sharp gradients of the discriminator function around some real data points. We demonstrate that these degenerate local equilibria can be avoided with a gradient penalty scheme called DRAGAN. We show that DRAGAN enables faster training, achieves improved stability with fewer mode collapses, and leads to generator networks with better modeling performance across a variety of architectures and objective functions.\n    ",
        "submission_date": "2017-05-19T00:00:00",
        "last_modified_date": "2017-12-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.07226",
        "title": "RankPL: A Qualitative Probabilistic Programming Language",
        "authors": [
            "Tjitze Rienstra"
        ],
        "abstract": "In this paper we introduce RankPL, a modeling language that can be thought of as a qualitative variant of a probabilistic programming language with a semantics based on Spohn's ranking theory. Broadly speaking, RankPL can be used to represent and reason about processes that exhibit uncertainty expressible by distinguishing \"normal\" from\" surprising\" events. RankPL allows (iterated) revision of rankings over alternative program states and supports various types of reasoning, including abduction and causal inference. We present the language, its denotational semantics, and a number of practical examples. We also discuss an implementation of RankPL that is available for download.\n    ",
        "submission_date": "2017-05-19T00:00:00",
        "last_modified_date": "2017-05-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.07339",
        "title": "Combining tabu search and graph reduction to solve the maximum balanced biclique problem",
        "authors": [
            "Yi Zhou",
            "Jin-Kao Hao"
        ],
        "abstract": "The Maximum Balanced Biclique Problem is a well-known graph model with relevant applications in diverse domains. This paper introduces a novel algorithm, which combines an effective constraint-based tabu search procedure and two dedicated graph reduction techniques. We verify the effectiveness of the algorithm on 30 classical random benchmark graphs and 25 very large real-life sparse graphs from the popular Koblenz Network Collection (KONECT). The results show that the algorithm improves the best-known results (new lower bounds) for 10 classical benchmarks and obtains the optimal solutions for 14 KONECT instances.\n    ",
        "submission_date": "2017-05-20T00:00:00",
        "last_modified_date": "2017-05-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.07343",
        "title": "Why You Should Charge Your Friends for Borrowing Your Stuff",
        "authors": [
            "Kijung Shin",
            "Euiwoong Lee",
            "Dhivya Eswaran",
            "Ariel D. Procaccia"
        ],
        "abstract": "We consider goods that can be shared with k-hop neighbors (i.e., the set of nodes within k hops from an owner) on a social network. We examine incentives to buy such a good by devising game-theoretic models where each node decides whether to buy the good or free ride. First, we find that social inefficiency, specifically excessive purchase of the good, occurs in Nash equilibria. Second, the social inefficiency decreases as k increases and thus a good can be shared with more nodes. Third, and most importantly, the social inefficiency can also be significantly reduced by charging free riders an access cost and paying it to owners, leading to the conclusion that organizations and system designers should impose such a cost. These findings are supported by our theoretical analysis in terms of the price of anarchy and the price of stability; and by simulations based on synthetic and real social networks.\n    ",
        "submission_date": "2017-05-20T00:00:00",
        "last_modified_date": "2017-05-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.07381",
        "title": "Generalizing the Role of Determinization in Probabilistic Planning",
        "authors": [
            "Luis Pineda",
            "Shlomo Zilberstein"
        ],
        "abstract": "The stochastic shortest path problem (SSP) is a highly expressive model for probabilistic planning. The computational hardness of SSPs has sparked interest in determinization-based planners that can quickly solve large problems. However, existing methods employ a simplistic approach to determinization. In particular, they ignore the possibility of tailoring the determinization to the specific characteristics of the target domain. In this work we examine this question, by showing that learning a good determinization for a planning domain can be done efficiently and can improve performance. Moreover, we show how to directly incorporate probabilistic reasoning into the planning problem when a good determinization is not sufficient by itself. Based on these insights, we introduce a planner, FF-LAO*, that outperforms state-of-the-art probabilistic planners on several well-known competition benchmarks.\n    ",
        "submission_date": "2017-05-21T00:00:00",
        "last_modified_date": "2017-07-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.07429",
        "title": "Sketched Answer Set Programming",
        "authors": [
            "Sergey Paramonov",
            "Christian Bessiere",
            "Anton Dries",
            "Luc De Raedt"
        ],
        "abstract": "Answer Set Programming (ASP) is a powerful modeling formalism for combinatorial problems. However, writing ASP models is not trivial. We propose a novel method, called Sketched Answer Set Programming (SkASP), aiming at supporting the user in resolving this issue. The user writes an ASP program while marking uncertain parts open with question marks. In addition, the user provides a number of positive and negative examples of the desired program behaviour. The sketched model is rewritten into another ASP program, which is solved by traditional methods. As a result, the user obtains a functional and reusable ASP program modelling her problem. We evaluate our approach on 21 well known puzzles and combinatorial problems inspired by Karp's 21 NP-complete problems and demonstrate a use-case for a database application based on ASP.\n    ",
        "submission_date": "2017-05-21T00:00:00",
        "last_modified_date": "2018-08-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.07460",
        "title": "Experience enrichment based task independent reward model",
        "authors": [
            "Min Xu"
        ],
        "abstract": "For most reinforcement learning approaches, the learning is performed by maximizing an accumulative reward that is expectedly and manually defined for specific tasks. However, in real world, rewards are emergent phenomena from the complex interactions between agents and environments. In this paper, we propose an implicit generic reward model for reinforcement learning. Unlike those rewards that are manually defined for specific tasks, such implicit reward is task independent. It only comes from the deviation from the agents' previous experiences.\n    ",
        "submission_date": "2017-05-21T00:00:00",
        "last_modified_date": "2017-05-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.07461",
        "title": "Shallow Updates for Deep Reinforcement Learning",
        "authors": [
            "Nir Levine",
            "Tom Zahavy",
            "Daniel J. Mankowitz",
            "Aviv Tamar",
            "Shie Mannor"
        ],
        "abstract": "Deep reinforcement learning (DRL) methods such as the Deep Q-Network (DQN) have achieved state-of-the-art results in a variety of challenging, high-dimensional domains. This success is mainly attributed to the power of deep neural networks to learn rich domain representations for approximating the value function or policy. Batch reinforcement learning methods with linear representations, on the other hand, are more stable and require less hyper parameter tuning. Yet, substantial feature engineering is necessary to achieve good results. In this work we propose a hybrid approach -- the Least Squares Deep Q-Network (LS-DQN), which combines rich feature representations learned by a DRL algorithm with the stability of a linear least squares method. We do this by periodically re-training the last hidden layer of a DRL network with a batch least squares update. Key to our approach is a Bayesian regularization term for the least squares update, which prevents over-fitting to the more recent data. We tested LS-DQN on five Atari games and demonstrate significant improvement over vanilla DQN and Double-DQN. We also investigated the reasons for the superior performance of our method. Interestingly, we found that the performance improvement can be attributed to the large batch size used by the LS method when optimizing the last layer.\n    ",
        "submission_date": "2017-05-21T00:00:00",
        "last_modified_date": "2017-11-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.07615",
        "title": "AIXIjs: A Software Demo for General Reinforcement Learning",
        "authors": [
            "John Aslanides"
        ],
        "abstract": "Reinforcement learning is a general and powerful framework with which to study and implement artificial intelligence. Recent advances in deep learning have enabled RL algorithms to achieve impressive performance in restricted domains such as playing Atari video games (Mnih et al., 2015) and, recently, the board game Go (Silver et al., 2016). However, we are still far from constructing a generally intelligent agent. Many of the obstacles and open questions are conceptual: What does it mean to be intelligent? How does one explore and learn optimally in general, unknown environments? What, in fact, does it mean to be optimal in the general sense? The universal Bayesian agent AIXI (Hutter, 2005) is a model of a maximally intelligent agent, and plays a central role in the sub-field of general reinforcement learning (GRL). Recently, AIXI has been shown to be flawed in important ways; it doesn't explore enough to be asymptotically optimal (Orseau, 2010), and it can perform poorly with certain priors (Leike and Hutter, 2015). Several variants of AIXI have been proposed to attempt to address these shortfalls: among them are entropy-seeking agents (Orseau, 2011), knowledge-seeking agents (Orseau et al., 2013), Bayes with bursts of exploration (Lattimore, 2013), MDL agents (Leike, 2016a), Thompson sampling (Leike et al., 2016), and optimism (Sunehag and Hutter, 2015). We present AIXIjs, a JavaScript implementation of these GRL agents. This implementation is accompanied by a framework for running experiments against various environments, similar to OpenAI Gym (Brockman et al., 2016), and a suite of interactive demos that explore different properties of the agents, similar to REINFORCEjs (Karpathy, 2015). We use AIXIjs to present numerous experiments illustrating fundamental properties of, and differences between, these agents.\n    ",
        "submission_date": "2017-05-22T00:00:00",
        "last_modified_date": "2017-05-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.07874",
        "title": "A Unified Approach to Interpreting Model Predictions",
        "authors": [
            "Scott Lundberg",
            "Su-In Lee"
        ],
        "abstract": "Understanding why a model makes a certain prediction can be as crucial as the prediction's accuracy in many applications. However, the highest accuracy for large modern datasets is often achieved by complex models that even experts struggle to interpret, such as ensemble or deep learning models, creating a tension between accuracy and interpretability. In response, various methods have recently been proposed to help users interpret the predictions of complex models, but it is often unclear how these methods are related and when one method is preferable over another. To address this problem, we present a unified framework for interpreting predictions, SHAP (SHapley Additive exPlanations). SHAP assigns each feature an importance value for a particular prediction. Its novel components include: (1) the identification of a new class of additive feature importance measures, and (2) theoretical results showing there is a unique solution in this class with a set of desirable properties. The new class unifies six existing methods, notable because several recent methods in the class lack the proposed desirable properties. Based on insights from this unification, we present new methods that show improved computational performance and/or better consistency with human intuition than previous approaches.\n    ",
        "submission_date": "2017-05-22T00:00:00",
        "last_modified_date": "2017-11-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.07961",
        "title": "Compatible extensions and consistent closures: a fuzzy approach",
        "authors": [
            "Irina Georgescu"
        ],
        "abstract": "In this paper $\\ast$--compatible extensions of fuzzy relations are studied, generalizing some results obtained by Duggan in case of crisp relations. From this general result are obtained as particular cases fuzzy versions of some important extension theorems for crisp relations (Szpilrajn, Hansson, Suzumura). Two notions of consistent closure of a fuzzy relation are introduced.\n    ",
        "submission_date": "2017-05-22T00:00:00",
        "last_modified_date": "2017-05-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.07996",
        "title": "Living Together: Mind and Machine Intelligence",
        "authors": [
            "Neil D. Lawrence"
        ],
        "abstract": "In this paper we consider the nature of the machine intelligences we have created in the context of our human intelligence. We suggest that the fundamental difference between human and machine intelligence comes down to \\emph{embodiment factors}. We define embodiment factors as the ratio between an entity's ability to communicate information vs compute information. We speculate on the role of embodiment factors in driving our own intelligence and consciousness. We briefly review dual process models of cognition and cast machine intelligence within that framework, characterising it as a dominant System Zero, which can drive behaviour through interfacing with us subconsciously. Driven by concerns about the consequence of such a system we suggest prophylactic courses of action that could be considered. Our main conclusion is that it is \\emph{not} sentient intelligence we should fear but \\emph{non-sentient} intelligence.\n    ",
        "submission_date": "2017-05-22T00:00:00",
        "last_modified_date": "2017-05-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.08039",
        "title": "Poincar\u00e9 Embeddings for Learning Hierarchical Representations",
        "authors": [
            "Maximilian Nickel",
            "Douwe Kiela"
        ],
        "abstract": "Representation learning has become an invaluable approach for learning from symbolic data such as text and graphs. However, while complex symbolic datasets often exhibit a latent hierarchical structure, state-of-the-art methods typically learn embeddings in Euclidean vector spaces, which do not account for this property. For this purpose, we introduce a new approach for learning hierarchical representations of symbolic data by embedding them into hyperbolic space -- or more precisely into an n-dimensional Poincar\u00e9 ball. Due to the underlying hyperbolic geometry, this allows us to learn parsimonious representations of symbolic data by simultaneously capturing hierarchy and similarity. We introduce an efficient algorithm to learn the embeddings based on Riemannian optimization and show experimentally that Poincar\u00e9 embeddings outperform Euclidean embeddings significantly on data with latent hierarchies, both in terms of representation capacity and in terms of generalization ability.\n    ",
        "submission_date": "2017-05-22T00:00:00",
        "last_modified_date": "2017-05-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.08200",
        "title": "Logical Learning Through a Hybrid Neural Network with Auxiliary Inputs",
        "authors": [
            "Fang Wan",
            "Chaoyang Song"
        ],
        "abstract": "The human reasoning process is seldom a one-way process from an input leading to an output. Instead, it often involves a systematic deduction by ruling out other possible outcomes as a self-checking mechanism. In this paper, we describe the design of a hybrid neural network for logical learning that is similar to the human reasoning through the introduction of an auxiliary input, namely the indicators, that act as the hints to suggest logical outcomes. We generate these indicators by digging into the hidden information buried underneath the original training data for direct or indirect suggestions. We used the MNIST data to demonstrate the design and use of these indicators in a convolutional neural network. We trained a series of such hybrid neural networks with variations of the indicators. Our results show that these hybrid neural networks are very robust in generating logical outcomes with inherently higher prediction accuracy than the direct use of the original input and output in apparent models. Such improved predictability with reassured logical confidence is obtained through the exhaustion of all possible indicators to rule out all illogical outcomes, which is not available in the apparent models. Our logical learning process can effectively cope with the unknown unknowns using a full exploitation of all existing knowledge available for learning. The design and implementation of the hints, namely the indicators, become an essential part of artificial intelligence for logical learning. We also introduce an ongoing application setup for this hybrid neural network in an autonomous grasping robot, namely as_DeepClaw, aiming at learning an optimized grasping pose through logical learning.\n    ",
        "submission_date": "2017-05-23T00:00:00",
        "last_modified_date": "2017-05-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.08218",
        "title": "XOR-Sampling for Network Design with Correlated Stochastic Events",
        "authors": [
            "Xiaojian Wu",
            "Yexiang Xue",
            "Bart Selman",
            "Carla P. Gomes"
        ],
        "abstract": "Many network optimization problems can be formulated as stochastic network design problems in which edges are present or absent stochastically. Furthermore, protective actions can guarantee that edges will remain present. We consider the problem of finding the optimal protection strategy under a budget limit in order to maximize some connectivity measurements of the network. Previous approaches rely on the assumption that edges are independent. In this paper, we consider a more realistic setting where multiple edges are not independent due to natural disasters or regional events that make the states of multiple edges stochastically correlated. We use Markov Random Fields to model the correlation and define a new stochastic network design framework. We provide a novel algorithm based on Sample Average Approximation (SAA) coupled with a Gibbs or XOR sampler. The experimental results on real road network data show that the policies produced by SAA with the XOR sampler have higher quality and lower variance compared to SAA with Gibbs sampler.\n    ",
        "submission_date": "2017-05-23T00:00:00",
        "last_modified_date": "2017-05-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.08245",
        "title": "Enhanced Experience Replay Generation for Efficient Reinforcement Learning",
        "authors": [
            "Vincent Huang",
            "Tobias Ley",
            "Martha Vlachou-Konchylaki",
            "Wenfeng Hu"
        ],
        "abstract": "Applying deep reinforcement learning (RL) on real systems suffers from slow data sampling. We propose an enhanced generative adversarial network (EGAN) to initialize an RL agent in order to achieve faster learning. The EGAN utilizes the relation between states and actions to enhance the quality of data samples generated by a GAN. Pre-training the agent with the EGAN shows a steeper learning curve with a 20% improvement of training time in the beginning of learning, compared to no pre-training, and an improvement compared to training with GAN by about 5% with smaller variations. For real time systems with sparse and slow data sampling the EGAN could be used to speed up the early phases of the training process.\n    ",
        "submission_date": "2017-05-23T00:00:00",
        "last_modified_date": "2017-05-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.08320",
        "title": "Explaining Transition Systems through Program Induction",
        "authors": [
            "Svetlin Penkov",
            "Subramanian Ramamoorthy"
        ],
        "abstract": "Explaining and reasoning about processes which underlie observed black-box phenomena enables the discovery of causal mechanisms, derivation of suitable abstract representations and the formulation of more robust predictions. We propose to learn high level functional programs in order to represent abstract models which capture the invariant structure in the observed data. We introduce the $\\pi$-machine (program-induction machine) -- an architecture able to induce interpretable LISP-like programs from observed data traces. We propose an optimisation procedure for program learning based on backpropagation, gradient descent and A* search. We apply the proposed method to three problems: system identification of dynamical systems, explaining the behaviour of a DQN agent and learning by demonstration in a human-robot interaction scenario. Our experimental results show that the $\\pi$-machine can efficiently induce interpretable programs from individual data traces.\n    ",
        "submission_date": "2017-05-23T00:00:00",
        "last_modified_date": "2017-05-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.08417",
        "title": "Reinforcement Learning with a Corrupted Reward Channel",
        "authors": [
            "Tom Everitt",
            "Victoria Krakovna",
            "Laurent Orseau",
            "Marcus Hutter",
            "Shane Legg"
        ],
        "abstract": "No real-world reward function is perfect. Sensory errors and software bugs may result in RL agents observing higher (or lower) rewards than they should. For example, a reinforcement learning agent may prefer states where a sensory error gives it the maximum reward, but where the true reward is actually small. We formalise this problem as a generalised Markov Decision Problem called Corrupt Reward MDP. Traditional RL methods fare poorly in CRMDPs, even under strong simplifying assumptions and when trying to compensate for the possibly corrupt rewards. Two ways around the problem are investigated. First, by giving the agent richer data, such as in inverse reinforcement learning and semi-supervised reinforcement learning, reward corruption stemming from systematic sensory errors may sometimes be completely managed. Second, by using randomisation to blunt the agent's optimisation, reward corruption can be partially managed under some assumptions.\n    ",
        "submission_date": "2017-05-23T00:00:00",
        "last_modified_date": "2017-08-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.08439",
        "title": "Thinking Fast and Slow with Deep Learning and Tree Search",
        "authors": [
            "Thomas Anthony",
            "Zheng Tian",
            "David Barber"
        ],
        "abstract": "Sequential decision making problems, such as structured prediction, robotic control, and game playing, require a combination of planning policies and generalisation of those plans. In this paper, we present Expert Iteration (ExIt), a novel reinforcement learning algorithm which decomposes the problem into separate planning and generalisation tasks. Planning new policies is performed by tree search, while a deep neural network generalises those plans. Subsequently, tree search is improved by using the neural network policy to guide search, increasing the strength of new plans. In contrast, standard deep Reinforcement Learning algorithms rely on a neural network not only to generalise plans, but to discover them too. We show that ExIt outperforms REINFORCE for training a neural network to play the board game Hex, and our final tree search agent, trained tabula rasa, defeats MoHex 1.0, the most recent Olympiad Champion player to be publicly released.\n    ",
        "submission_date": "2017-05-23T00:00:00",
        "last_modified_date": "2017-12-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.08440",
        "title": "Knowledge Acquisition, Representation \\& Manipulation in Decision Support Systems",
        "authors": [
            "M.Michalewicz",
            "S.T.Wierzcho\u0144",
            "M.A. K\u0142opotek"
        ],
        "abstract": "In this paper we present a methodology and discuss some implementation issues for a project on statistical/expert approach to data analysis and knowledge acquisition. We discuss some general assumptions underlying the project. Further, the requirements for a user-friendly computer assistant are specified along with the nature of tools aiding the researcher. Next we show some aspects of belief network approach and Dempster-Shafer (DST) methodology introduced in practice to system SEAD. Specifically we present the application of DS methodology to belief revision problem. Further a concept of an interface to probabilistic and DS belief networks enabling a user to understand the communication with a belief network based reasoning system is presented\n    ",
        "submission_date": "2017-05-23T00:00:00",
        "last_modified_date": "2017-05-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.08492",
        "title": "Uplift Modeling with Multiple Treatments and General Response Types",
        "authors": [
            "Yan Zhao",
            "Xiao Fang",
            "David Simchi-Levi"
        ],
        "abstract": "Randomized experiments have been used to assist decision-making in many areas. They help people select the optimal treatment for the test population with certain statistical guarantee. However, subjects can show significant heterogeneity in response to treatments. The problem of customizing treatment assignment based on subject characteristics is known as uplift modeling, differential response analysis, or personalized treatment learning in literature. A key feature for uplift modeling is that the data is unlabeled. It is impossible to know whether the chosen treatment is optimal for an individual subject because response under alternative treatments is unobserved. This presents a challenge to both the training and the evaluation of uplift models. In this paper we describe how to obtain an unbiased estimate of the key performance metric of an uplift model, the expected response. We present a new uplift algorithm which creates a forest of randomized trees. The trees are built with a splitting criterion designed to directly optimize their uplift performance based on the proposed evaluation method. Both the evaluation method and the algorithm apply to arbitrary number of treatments and general response types. Experimental results on synthetic data and industry-provided data show that our algorithm leads to significant performance improvement over other applicable methods.\n    ",
        "submission_date": "2017-05-23T00:00:00",
        "last_modified_date": "2017-05-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.08509",
        "title": "Predictive Analytics for Enhancing Travel Time Estimation in Navigation Apps of Apple, Google, and Microsoft",
        "authors": [
            "Pouria Amirian",
            "Anahid Basiri",
            "Jeremy Morley"
        ],
        "abstract": "The explosive growth of the location-enabled devices coupled with the increasing use of Internet services has led to an increasing awareness of the importance and usage of geospatial information in many applications. The navigation apps (often called Maps), use a variety of available data sources to calculate and predict the travel time as well as several options for routing in public transportation, car or pedestrian modes. This paper evaluates the pedestrian mode of Maps apps in three major smartphone operating systems (Android, iOS and Windows Phone). In the paper, we will show that the Maps apps on iOS, Android and Windows Phone in pedestrian mode, predict travel time without learning from the individual's movement profile. In addition, we will exemplify that those apps suffer from a specific data quality issue which relates to the absence of information about location and type of pedestrian crossings. Finally, we will illustrate learning from movement profile of individuals using various predictive analytics models to improve the accuracy of travel time estimation.\n    ",
        "submission_date": "2017-05-23T00:00:00",
        "last_modified_date": "2017-05-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.08520",
        "title": "An effective algorithm for hyperparameter optimization of neural networks",
        "authors": [
            "Gonzalo Diaz",
            "Achille Fokoue",
            "Giacomo Nannicini",
            "Horst Samulowitz"
        ],
        "abstract": "A major challenge in designing neural network (NN) systems is to determine the best structure and parameters for the network given the data for the machine learning problem at hand. Examples of parameters are the number of layers and nodes, the learning rates, and the dropout rates. Typically, these parameters are chosen based on heuristic rules and manually fine-tuned, which may be very time-consuming, because evaluating the performance of a single parametrization of the NN may require several hours. This paper addresses the problem of choosing appropriate parameters for the NN by formulating it as a box-constrained mathematical optimization problem, and applying a derivative-free optimization tool that automatically and effectively searches the parameter space. The optimization tool employs a radial basis function model of the objective function (the prediction accuracy of the NN) to accelerate the discovery of configurations yielding high accuracy. Candidate configurations explored by the algorithm are trained to a small number of epochs, and only the most promising candidates receive full training. The performance of the proposed methodology is assessed on benchmark sets and in the context of predicting drug-drug interactions, showing promising results. The optimization tool used in this paper is open-source.\n    ",
        "submission_date": "2017-05-23T00:00:00",
        "last_modified_date": "2017-05-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.08690",
        "title": "Continual Learning with Deep Generative Replay",
        "authors": [
            "Hanul Shin",
            "Jung Kwon Lee",
            "Jaehong Kim",
            "Jiwon Kim"
        ],
        "abstract": "Attempts to train a comprehensive artificial intelligence capable of solving multiple tasks have been impeded by a chronic problem called catastrophic forgetting. Although simply replaying all previous data alleviates the problem, it requires large memory and even worse, often infeasible in real world applications where the access to past data is limited. Inspired by the generative nature of hippocampus as a short-term memory system in primate brain, we propose the Deep Generative Replay, a novel framework with a cooperative dual model architecture consisting of a deep generative model (\"generator\") and a task solving model (\"solver\"). With only these two models, training data for previous tasks can easily be sampled and interleaved with those for a new task. We test our methods in several sequential learning settings involving image classification tasks.\n    ",
        "submission_date": "2017-05-24T00:00:00",
        "last_modified_date": "2017-12-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.08807",
        "title": "When Will AI Exceed Human Performance? Evidence from AI Experts",
        "authors": [
            "Katja Grace",
            "John Salvatier",
            "Allan Dafoe",
            "Baobao Zhang",
            "Owain Evans"
        ],
        "abstract": "Advances in artificial intelligence (AI) will transform modern life by reshaping transportation, health, science, finance, and the military. To adapt public policy, we need to better anticipate these advances. Here we report the results from a large survey of machine learning researchers on their beliefs about progress in AI. Researchers predict AI will outperform humans in many activities in the next ten years, such as translating languages (by 2024), writing high-school essays (by 2026), driving a truck (by 2027), working in retail (by 2031), writing a bestselling book (by 2049), and working as a surgeon (by 2053). Researchers believe there is a 50% chance of AI outperforming humans in all tasks in 45 years and of automating all human jobs in 120 years, with Asian respondents expecting these dates much sooner than North Americans. These results will inform discussion amongst researchers and policymakers about anticipating and managing trends in AI.\n    ",
        "submission_date": "2017-05-24T00:00:00",
        "last_modified_date": "2018-05-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.08844",
        "title": "How a General-Purpose Commonsense Ontology can Improve Performance of Learning-Based Image Retrieval",
        "authors": [
            "Rodrigo Toro Icarte",
            "Jorge A. Baier",
            "Cristian Ruz",
            "Alvaro Soto"
        ],
        "abstract": "The knowledge representation community has built general-purpose ontologies which contain large amounts of commonsense knowledge over relevant aspects of the world, including useful visual information, e.g.: \"a ball is used by a football player\", \"a tennis player is located at a tennis court\". Current state-of-the-art approaches for visual recognition do not exploit these rule-based knowledge sources. Instead, they learn recognition models directly from training examples. In this paper, we study how general-purpose ontologies---specifically, MIT's ConceptNet ontology---can improve the performance of state-of-the-art vision systems. As a testbed, we tackle the problem of sentence-based image retrieval. Our retrieval approach incorporates knowledge from ConceptNet on top of a large pool of object detectors derived from a deep learning technique. In our experiments, we show that ConceptNet can improve performance on a common benchmark dataset. Key to our performance is the use of the ESPGAME dataset to select visually relevant relations from ConceptNet. Consequently, a main conclusion of this work is that general-purpose commonsense ontologies improve performance on visual reasoning tasks when properly filtered to select meaningful visual relations.\n    ",
        "submission_date": "2017-05-24T00:00:00",
        "last_modified_date": "2017-05-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.08926",
        "title": "Counterfactual Multi-Agent Policy Gradients",
        "authors": [
            "Jakob Foerster",
            "Gregory Farquhar",
            "Triantafyllos Afouras",
            "Nantas Nardelli",
            "Shimon Whiteson"
        ],
        "abstract": "Cooperative multi-agent systems can be naturally used to model many real world problems, such as network packet routing and the coordination of autonomous vehicles. There is a great need for new reinforcement learning methods that can efficiently learn decentralised policies for such systems. To this end, we propose a new multi-agent actor-critic method called counterfactual multi-agent (COMA) policy gradients. COMA uses a centralised critic to estimate the Q-function and decentralised actors to optimise the agents' policies. In addition, to address the challenges of multi-agent credit assignment, it uses a counterfactual baseline that marginalises out a single agent's action, while keeping the other agents' actions fixed. COMA also uses a critic representation that allows the counterfactual baseline to be computed efficiently in a single forward pass. We evaluate COMA in the testbed of StarCraft unit micromanagement, using a decentralised variant with significant partial observability. COMA significantly improves average performance over other multi-agent actor-critic methods in this setting, and the best performing agents are competitive with state-of-the-art centralised controllers that get access to the full state.\n    ",
        "submission_date": "2017-05-24T00:00:00",
        "last_modified_date": "2024-12-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.08961",
        "title": "Efficient, Safe, and Probably Approximately Complete Learning of Action Models",
        "authors": [
            "Roni Stern",
            "Brendan Juba"
        ],
        "abstract": "In this paper we explore the theoretical boundaries of planning in a setting where no model of the agent's actions is given. Instead of an action model, a set of successfully executed plans are given and the task is to generate a plan that is safe, i.e., guaranteed to achieve the goal without failing.\nTo this end, we show how to learn a conservative model of the world in which actions are guaranteed to be applicable. This conservative model is then given to an off-the-shelf classical planner, resulting in a plan that is guaranteed to achieve the goal. However, this reduction from a model-free planning to a model-based planning is not complete: in some cases a plan will not be found even when such exists. We analyze the relation between the number of observed plans and the likelihood that our conservative approach will indeed fail to solve a solvable problem. Our analysis show that the number of trajectories needed scales gracefully.\n    ",
        "submission_date": "2017-05-24T00:00:00",
        "last_modified_date": "2017-05-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.08968",
        "title": "Logic Tensor Networks for Semantic Image Interpretation",
        "authors": [
            "Ivan Donadello",
            "Luciano Serafini",
            "Artur d'Avila Garcez"
        ],
        "abstract": "Semantic Image Interpretation (SII) is the task of extracting structured semantic descriptions from images. It is widely agreed that the combined use of visual data and background knowledge is of great importance for SII. Recently, Statistical Relational Learning (SRL) approaches have been developed for reasoning under uncertainty and learning in the presence of data and rich knowledge. Logic Tensor Networks (LTNs) are an SRL framework which integrates neural networks with first-order fuzzy logic to allow (i) efficient learning from noisy data in the presence of logical constraints, and (ii) reasoning with logical formulas describing general properties of the data. In this paper, we develop and apply LTNs to two of the main tasks of SII, namely, the classification of an image's bounding boxes and the detection of the relevant part-of relations between objects. To the best of our knowledge, this is the first successful application of SRL to such SII tasks. The proposed approach is evaluated on a standard image processing benchmark. Experiments show that the use of background knowledge in the form of logical constraints can improve the performance of purely data-driven approaches, including the state-of-the-art Fast Region-based Convolutional Neural Networks (Fast R-CNN). Moreover, we show that the use of logical background knowledge adds robustness to the learning system when errors are present in the labels of the training data.\n    ",
        "submission_date": "2017-05-24T00:00:00",
        "last_modified_date": "2017-05-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.08997",
        "title": "State Space Decomposition and Subgoal Creation for Transfer in Deep Reinforcement Learning",
        "authors": [
            "Himanshu Sahni",
            "Saurabh Kumar",
            "Farhan Tejani",
            "Yannick Schroecker",
            "Charles Isbell"
        ],
        "abstract": "Typical reinforcement learning (RL) agents learn to complete tasks specified by reward functions tailored to their domain. As such, the policies they learn do not generalize even to similar domains. To address this issue, we develop a framework through which a deep RL agent learns to generalize policies from smaller, simpler domains to more complex ones using a recurrent attention mechanism. The task is presented to the agent as an image and an instruction specifying the goal. This meta-controller guides the agent towards its goal by designing a sequence of smaller subtasks on the part of the state space within the attention, effectively decomposing it. As a baseline, we consider a setup without attention as well. Our experiments show that the meta-controller learns to create subgoals within the attention.\n    ",
        "submission_date": "2017-05-24T00:00:00",
        "last_modified_date": "2017-05-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.09045",
        "title": "Cross-Domain Perceptual Reward Functions",
        "authors": [
            "Ashley D. Edwards",
            "Srijan Sood",
            "Charles L. Isbell Jr"
        ],
        "abstract": "In reinforcement learning, we often define goals by specifying rewards within desirable states. One problem with this approach is that we typically need to redefine the rewards each time the goal changes, which often requires some understanding of the solution in the agents environment. When humans are learning to complete tasks, we regularly utilize alternative sources that guide our understanding of the problem. Such task representations allow one to specify goals on their own terms, thus providing specifications that can be appropriately interpreted across various environments. This motivates our own work, in which we represent goals in environments that are different from the agents. We introduce Cross-Domain Perceptual Reward (CDPR) functions, learned rewards that represent the visual similarity between an agents state and a cross-domain goal image. We report results for learning the CDPRs with a deep neural network and using them to solve two tasks with deep reinforcement learning.\n    ",
        "submission_date": "2017-05-25T00:00:00",
        "last_modified_date": "2017-07-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.09058",
        "title": "An Empirical Analysis of Approximation Algorithms for the Euclidean Traveling Salesman Problem",
        "authors": [
            "Yihui He",
            "Ming Xiang"
        ],
        "abstract": "With applications to many disciplines, the traveling salesman problem (TSP) is a classical computer science optimization problem with applications to industrial engineering, theoretical computer science, bioinformatics, and several other disciplines. In recent years, there have been a plethora of novel approaches for approximate solutions ranging from simplistic greedy to cooperative distributed algorithms derived from artificial intelligence. In this paper, we perform an evaluation and analysis of cornerstone algorithms for the Euclidean TSP. We evaluate greedy, 2-opt, and genetic algorithms. We use several datasets as input for the algorithms including a small dataset, a mediumsized dataset representing cities in the United States, and a synthetic dataset consisting of 200 cities to test algorithm scalability. We discover that the greedy and 2-opt algorithms efficiently calculate solutions for smaller datasets. Genetic algorithm has the best performance for optimality for medium to large datasets, but generally have longer runtime. Our implementations is public available.\n    ",
        "submission_date": "2017-05-25T00:00:00",
        "last_modified_date": "2017-05-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.09218",
        "title": "Finding Robust Solutions to Stable Marriage",
        "authors": [
            "Begum Genc",
            "Mohamed Siala",
            "Barry O'Sullivan",
            "Gilles Simonin"
        ],
        "abstract": "We study the notion of robustness in stable matching problems. We first define robustness by introducing (a,b)-supermatches. An $(a,b)$-supermatch is a stable matching in which if $a$ pairs break up it is possible to find another stable matching by changing the partners of those $a$ pairs and at most $b$ other pairs. In this context, we define the most robust stable matching as a $(1,b)$-supermatch where b is minimum. We show that checking whether a given stable matching is a $(1,b)$-supermatch can be done in polynomial time. Next, we use this procedure to design a constraint programming model, a local search approach, and a genetic algorithm to find the most robust stable matching. Our empirical evaluation on large instances show that local search outperforms the other approaches.\n    ",
        "submission_date": "2017-05-24T00:00:00",
        "last_modified_date": "2017-10-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.09231",
        "title": "Neural Attribute Machines for Program Generation",
        "authors": [
            "Matthew Amodio",
            "Swarat Chaudhuri",
            "Thomas W. Reps"
        ],
        "abstract": "Recurrent neural networks have achieved remarkable success at generating sequences with complex structures, thanks to advances that include richer embeddings of input and cures for vanishing gradients. Trained only on sequences from a known grammar, though, they can still struggle to learn rules and constraints of the grammar. Neural Attribute Machines (NAMs) are equipped with a logical machine that represents the underlying grammar, which is used to teach the constraints to the neural machine by (i) augmenting the input sequence, and (ii) optimizing a custom loss function. Unlike traditional RNNs, NAMs are exposed to the grammar, as well as samples from the language of the grammar. During generation, NAMs make significantly fewer violations of the constraints of the underlying grammar than RNNs trained only on samples from the language of the grammar.\n    ",
        "submission_date": "2017-05-25T00:00:00",
        "last_modified_date": "2021-10-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.09349",
        "title": "Together We Know How to Achieve: An Epistemic Logic of Know-How",
        "authors": [
            "Pavel Naumov",
            "Jia Tao"
        ],
        "abstract": "The existence of a coalition strategy to achieve a goal does not necessarily mean that the coalition has enough information to know how to follow the strategy. Neither does it mean that the coalition knows that such a strategy exists. The article studies an interplay between the distributed knowledge, coalition strategies, and coalition \"know-how\" strategies. The main technical result is a sound and complete trimodal logical system that describes the properties of this interplay.\n    ",
        "submission_date": "2017-05-25T00:00:00",
        "last_modified_date": "2017-06-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.09439",
        "title": "Taste or Addiction?: Using Play Logs to Infer Song Selection Motivation",
        "authors": [
            "Kosetsu Tsukuda",
            "Masataka Goto"
        ],
        "abstract": "Online music services are increasing in popularity. They enable us to analyze people's music listening behavior based on play logs. Although it is known that people listen to music based on topic (e.g., rock or jazz), we assume that when a user is addicted to an artist, s/he chooses the artist's songs regardless of topic. Based on this assumption, in this paper, we propose a probabilistic model to analyze people's music listening behavior. Our main contributions are three-fold. First, to the best of our knowledge, this is the first study modeling music listening behavior by taking into account the influence of addiction to artists. Second, by using real-world datasets of play logs, we showed the effectiveness of our proposed model. Third, we carried out qualitative experiments and showed that taking addiction into account enables us to analyze music listening behavior from a new viewpoint in terms of how people listen to music according to the time of day, how an artist's songs are listened to by people, etc. We also discuss the possibility of applying the analysis results to applications such as artist similarity computation and song recommendation.\n    ",
        "submission_date": "2017-05-26T00:00:00",
        "last_modified_date": "2017-05-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.09545",
        "title": "Logical and Inequality Implications for Reducing the Size and Complexity of Quadratic Unconstrained Binary Optimization Problems",
        "authors": [
            "Fred Glover",
            "Mark Lewis",
            "Gary Kochenberger"
        ],
        "abstract": "The quadratic unconstrained binary optimization (QUBO) problem arises in diverse optimization applications ranging from Ising spin problems to classical problems in graph theory and binary discrete optimization. The use of preprocessing to transform the graph representing the QUBO problem into a smaller equivalent graph is important for improving solution quality and time for both exact and metaheuristic algorithms and is a step towards mapping large scale QUBO to hardware graphs used in quantum annealing computers. In an earlier paper (Lewis and Glover, 2016) a set of rules was introduced that achieved significant QUBO reductions as verified through computational testing. Here this work is extended with additional rules that provide further reductions that succeed in exactly solving 10% of the benchmark QUBO problems. An algorithm and associated data structures to efficiently implement the entire set of rules is detailed and computational experiments are reported that demonstrate their efficacy.\n    ",
        "submission_date": "2017-05-26T00:00:00",
        "last_modified_date": "2017-05-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.09811",
        "title": "Multi-shot ASP solving with clingo",
        "authors": [
            "Martin Gebser",
            "Roland Kaminski",
            "Benjamin Kaufmann",
            "Torsten Schaub"
        ],
        "abstract": "We introduce a new flexible paradigm of grounding and solving in Answer Set Programming (ASP), which we refer to as multi-shot ASP solving, and present its implementation in the ASP system clingo.\n",
        "submission_date": "2017-05-27T00:00:00",
        "last_modified_date": "2018-03-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.09844",
        "title": "Quadratic Unconstrained Binary Optimization Problem Preprocessing: Theory and Empirical Analysis",
        "authors": [
            "Mark Lewis",
            "Fred Glover"
        ],
        "abstract": "The Quadratic Unconstrained Binary Optimization problem (QUBO) has become a unifying model for representing a wide range of combinatorial optimization problems, and for linking a variety of disciplines that face these problems. A new class of quantum annealing computer that maps QUBO onto a physical qubit network structure with specific size and edge density restrictions is generating a growing interest in ways to transform the underlying QUBO structure into an equivalent graph having fewer nodes and edges. In this paper we present rules for reducing the size of the QUBO matrix by identifying variables whose value at optimality can be predetermined. We verify that the reductions improve both solution quality and time to solution and, in the case of metaheuristic methods where optimal solutions cannot be guaranteed, the quality of solutions obtained within reasonable time limits.\n",
        "submission_date": "2017-05-27T00:00:00",
        "last_modified_date": "2017-05-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.09879",
        "title": "Inexpensive Cost-Optimized Measurement Proposal for Sequential Model-Based Diagnosis",
        "authors": [
            "Patrick Rodler",
            "Wolfgang Schmid",
            "Konstantin Schekotihin"
        ],
        "abstract": "In this work we present strategies for (optimal) measurement selection in model-based sequential diagnosis. In particular, assuming a set of leading diagnoses being given, we show how queries (sets of measurements) can be computed and optimized along two dimensions: expected number of queries and cost per query. By means of a suitable decoupling of two optimizations and a clever search space reduction the computations are done without any inference engine calls. For the full search space, we give a method requiring only a polynomial number of inferences and guaranteeing query properties existing methods cannot provide. Evaluation results using real-world problems indicate that the new method computes (virtually) optimal queries instantly independently of the size and complexity of the considered diagnosis problems.\n    ",
        "submission_date": "2017-05-28T00:00:00",
        "last_modified_date": "2017-05-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.09922",
        "title": "Bayesian Unification of Gradient and Bandit-based Learning for Accelerated Global Optimisation",
        "authors": [
            "Ole-Christoffer Granmo"
        ],
        "abstract": "Bandit based optimisation has a remarkable advantage over gradient based approaches due to their global perspective, which eliminates the danger of getting stuck at local optima. However, for continuous optimisation problems or problems with a large number of actions, bandit based approaches can be hindered by slow learning. Gradient based approaches, on the other hand, navigate quickly in high-dimensional continuous spaces through local optimisation, following the gradient in fine grained steps. Yet, apart from being susceptible to local optima, these schemes are less suited for online learning due to their reliance on extensive trial-and-error before the optimum can be identified. In this paper, we propose a Bayesian approach that unifies the above two paradigms in one single framework, with the aim of combining their advantages. At the heart of our approach we find a stochastic linear approximation of the function to be optimised, where both the gradient and values of the function are explicitly captured. This allows us to learn from both noisy function and gradient observations, and predict these properties across the action space to support optimisation. We further propose an accompanying bandit driven exploration scheme that uses Bayesian credible bounds to trade off exploration against exploitation. Our empirical results demonstrate that by unifying bandit and gradient based learning, one obtains consistently improved performance across a wide spectrum of problem environments. Furthermore, even when gradient feedback is unavailable, the flexibility of our model, including gradient prediction, still allows us outperform competing approaches, although with a smaller margin. Due to the pervasiveness of bandit based optimisation, our scheme opens up for improved performance both in meta-optimisation and in applications where gradient related information is readily available.\n    ",
        "submission_date": "2017-05-28T00:00:00",
        "last_modified_date": "2017-05-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.09970",
        "title": "Probabilistic Program Abstractions",
        "authors": [
            "Steven Holtzen",
            "Todd Millstein",
            "Guy Van den Broeck"
        ],
        "abstract": "Abstraction is a fundamental tool for reasoning about complex systems. Program abstraction has been utilized to great effect for analyzing deterministic programs. At the heart of program abstraction is the relationship between a concrete program, which is difficult to analyze, and an abstract program, which is more tractable. Program abstractions, however, are typically not probabilistic. We generalize non-deterministic program abstractions to probabilistic program abstractions by explicitly quantifying the non-deterministic choices. Our framework upgrades key definitions and properties of abstractions to the probabilistic context. We also discuss preliminary ideas for performing inference on probabilistic abstractions and general probabilistic programs.\n    ",
        "submission_date": "2017-05-28T00:00:00",
        "last_modified_date": "2017-07-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.09990",
        "title": "Should Robots be Obedient?",
        "authors": [
            "Smitha Milli",
            "Dylan Hadfield-Menell",
            "Anca Dragan",
            "Stuart Russell"
        ],
        "abstract": "Intuitively, obedience -- following the order that a human gives -- seems like a good property for a robot to have. But, we humans are not perfect and we may give orders that are not best aligned to our preferences. We show that when a human is not perfectly rational then a robot that tries to infer and act according to the human's underlying preferences can always perform better than a robot that simply follows the human's literal order. Thus, there is a tradeoff between the obedience of a robot and the value it can attain for its owner. We investigate how this tradeoff is impacted by the way the robot infers the human's preferences, showing that some methods err more on the side of obedience than others. We then analyze how performance degrades when the robot has a misspecified model of the features that the human cares about or the level of rationality of the human. Finally, we study how robots can start detecting such model misspecification. Overall, our work suggests that there might be a middle ground in which robots intelligently decide when to obey human orders, but err on the side of obedience.\n    ",
        "submission_date": "2017-05-28T00:00:00",
        "last_modified_date": "2017-05-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.10044",
        "title": "Abstract Argumentation / Persuasion / Dynamics",
        "authors": [
            "Ryuta Arisaka",
            "Ken Satoh"
        ],
        "abstract": "The act of persuasion, a key component in rhetoric argumentation, may be viewed as a dynamics modifier. We extend Dung's frameworks with acts of persuasion among agents, and consider interactions among attack, persuasion and defence that have been largely unheeded so far. We characterise basic notions of admissibilities in this framework, and show a way of enriching them through, effectively, CTL (computation tree logic) encoding, which also permits importation of the theoretical results known to the logic into our argumentation frameworks. Our aim is to complement the growing interest in coordination of static and dynamic argumentation.\n    ",
        "submission_date": "2017-05-29T00:00:00",
        "last_modified_date": "2018-11-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.10201",
        "title": "Machine Learned Learning Machines",
        "authors": [
            "Leigh Sheneman",
            "Arend Hintze"
        ],
        "abstract": "There are two common approaches for optimizing the performance of a machine: genetic algorithms and machine learning. A genetic algorithm is applied over many generations whereas machine learning works by applying feedback until the system meets a performance threshold. Though these are methods that typically operate separately, we combine evolutionary adaptation and machine learning into one approach. Our focus is on machines that can learn during their lifetime, but instead of equipping them with a machine learning algorithm we aim to let them evolve their ability to learn by themselves. We use evolvable networks of probabilistic and deterministic logic gates, known as Markov Brains, as our computational model organism. The ability of Markov Brains to learn is augmented by a novel adaptive component that can change its computational behavior based on feedback. We show that Markov Brains can indeed evolve to incorporate these feedback gates to improve their adaptability to variable environments. By combining these two methods, we now also implemented a computational model that can be used to study the evolution of learning.\n    ",
        "submission_date": "2017-05-29T00:00:00",
        "last_modified_date": "2017-08-31T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.10217",
        "title": "Black-box Testing of First-Order Logic Ontologies Using WordNet",
        "authors": [
            "Javier \u00c1lvez",
            "Paqui Lucio",
            "German Rigau"
        ],
        "abstract": "Artificial Intelligence aims to provide computer programs with commonsense knowledge to reason about our world. This paper offers a new practical approach towards automated commonsense reasoning with first-order logic (FOL) ontologies. We propose a new black-box testing methodology of FOL SUMO-based ontologies by exploiting WordNet and its mapping into SUMO. Our proposal includes a method for the (semi-)automatic creation of a very large benchmark of competency questions and a procedure for its automated evaluation by using automated theorem provers (ATPs). Applying different quality criteria, our testing proposal enables a successful evaluation of a) the competency of several translations of SUMO into FOL and b) the performance of various automated ATPs. Finally, we also provide a fine-grained and complete analysis of the commonsense reasoning competency of current FOL SUMO-based ontologies.\n    ",
        "submission_date": "2017-05-29T00:00:00",
        "last_modified_date": "2018-03-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.10219",
        "title": "Automatic White-Box Testing of First-Order Logic Ontologies",
        "authors": [
            "Javier \u00c1lvez",
            "Montserrat Hermo",
            "Paqui Lucio",
            "German Rigau"
        ],
        "abstract": "Formal ontologies are axiomatizations in a logic-based formalism. The development of formal ontologies, and their important role in the Semantic Web area, is generating considerable research on the use of automated reasoning techniques and tools that help in ontology engineering. One of the main aims is to refine and to improve axiomatizations for enabling automated reasoning tools to efficiently infer reliable information. Defects in the axiomatization can not only cause wrong inferences, but can also hinder the inference of expected information, either by increasing the computational cost of, or even preventing, the inference. In this paper, we introduce a novel, fully automatic white-box testing framework for first-order logic ontologies. Our methodology is based on the detection of inference-based redundancies in the given axiomatization. The application of the proposed testing method is fully automatic since a) the automated generation of tests is guided only by the syntax of axioms and b) the evaluation of tests is performed by automated theorem provers. Our proposal enables the detection of defects and serves to certify the grade of suitability --for reasoning purposes-- of every axiom. We formally define the set of tests that are generated from any axiom and prove that every test is logically related to redundancies in the axiom from which the test has been generated. We have implemented our method and used this implementation to automatically detect several non-trivial defects that were hidden in various first-order logic ontologies. Throughout the paper we provide illustrative examples of these defects, explain how they were found, and how each proof --given by an automated theorem-prover-- provides useful hints on the nature of each defect. Additionally, by correcting all the detected defects, we have obtained an improved version of one of the tested ontologies: Adimen-SUMO.\n    ",
        "submission_date": "2017-05-29T00:00:00",
        "last_modified_date": "2019-01-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.10308",
        "title": "Learning Belief Network Structure From Data under Causal Insufficiency",
        "authors": [
            "Mieczys\u0142aw K\u0142opotek"
        ],
        "abstract": "Though a belief network (a representation of the joint probability distribution, see [3]) and a causal network (a representation of causal relationships [14]) are intended to mean different things, they are closely related. Both assume an underlying dag (directed acyclic graph) structure of relations among variables and if Markov condition and faithfulness condition [15] are met, then a causal network is in fact a belief network. The difference comes to appearance when we recover belief network and causal network structure from data.\n",
        "submission_date": "2017-05-29T00:00:00",
        "last_modified_date": "2017-05-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.10342",
        "title": "Deep Learning for Ontology Reasoning",
        "authors": [
            "Patrick Hohenecker",
            "Thomas Lukasiewicz"
        ],
        "abstract": "In this work, we present a novel approach to ontology reasoning that is based on deep learning rather than logic-based formal reasoning. To this end, we introduce a new model for statistical relational learning that is built upon deep recursive neural networks, and give experimental evidence that it can easily compete with, or even outperform, existing logic-based reasoners on the task of ontology reasoning. More precisely, we compared our implemented system with one of the best logic-based ontology reasoners at present, RDFox, on a number of large standard benchmark datasets, and found that our system attained high reasoning quality, while being up to two orders of magnitude faster.\n    ",
        "submission_date": "2017-05-29T00:00:00",
        "last_modified_date": "2017-05-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.10432",
        "title": "Fine-grained acceleration control for autonomous intersection management using deep reinforcement learning",
        "authors": [
            "Hamid Mirzaei",
            "Tony Givargis"
        ],
        "abstract": "Recent advances in combining deep learning and Reinforcement Learning have shown a promising path for designing new control agents that can learn optimal policies for challenging control tasks. These new methods address the main limitations of conventional Reinforcement Learning methods such as customized feature engineering and small action/state space dimension requirements. In this paper, we leverage one of the state-of-the-art Reinforcement Learning methods, known as Trust Region Policy Optimization, to tackle intersection management for autonomous vehicles. We show that using this method, we can perform fine-grained acceleration control of autonomous vehicles in a grid street plan to achieve a global design objective.\n    ",
        "submission_date": "2017-05-30T00:00:00",
        "last_modified_date": "2017-05-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.10443",
        "title": "MOBA: a New Arena for Game AI",
        "authors": [
            "Victor do Nascimento Silva",
            "Luiz Chaimowicz"
        ],
        "abstract": "Games have always been popular testbeds for Artificial Intelligence (AI). In the last decade, we have seen the rise of the Multiple Online Battle Arena (MOBA) games, which are the most played games nowadays. In spite of this, there are few works that explore MOBA as a testbed for AI Research. In this paper we present and discuss the main features and opportunities offered by MOBA games to Game AI Research. We describe the various challenges faced along the game and also propose a discrete model that can be used to better understand and explore the game. With this, we aim to encourage the use of MOBA as a novel research platform for Game AI.\n    ",
        "submission_date": "2017-05-30T00:00:00",
        "last_modified_date": "2017-05-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.10557",
        "title": "Universal Reinforcement Learning Algorithms: Survey and Experiments",
        "authors": [
            "John Aslanides",
            "Jan Leike",
            "Marcus Hutter"
        ],
        "abstract": "Many state-of-the-art reinforcement learning (RL) algorithms typically assume that the environment is an ergodic Markov Decision Process (MDP). In contrast, the field of universal reinforcement learning (URL) is concerned with algorithms that make as few assumptions as possible about the environment. The universal Bayesian agent AIXI and a family of related URL algorithms have been developed in this setting. While numerous theoretical optimality results have been proven for these agents, there has been no empirical investigation of their behavior to date. We present a short and accessible survey of these URL algorithms under a unified notation and framework, along with results of some experiments that qualitatively illustrate some properties of the resulting policies, and their relative performance on partially-observable gridworld environments. We also present an open-source reference implementation of the algorithms which we hope will facilitate further understanding of, and experimentation with, these ideas.\n    ",
        "submission_date": "2017-05-30T00:00:00",
        "last_modified_date": "2017-05-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.10701",
        "title": "Multi-Labelled Value Networks for Computer Go",
        "authors": [
            "Ti-Rong Wu",
            "I-Chen Wu",
            "Guan-Wun Chen",
            "Ting-han Wei",
            "Tung-Yi Lai",
            "Hung-Chun Wu",
            "Li-Cheng Lan"
        ],
        "abstract": "This paper proposes a new approach to a novel value network architecture for the game Go, called a multi-labelled (ML) value network. In the ML value network, different values (win rates) are trained simultaneously for different settings of komi, a compensation given to balance the initiative of playing first. The ML value network has three advantages, (a) it outputs values for different komi, (b) it supports dynamic komi, and (c) it lowers the mean squared error (MSE). This paper also proposes a new dynamic komi method to improve game-playing strength. This paper also performs experiments to demonstrate the merits of the architecture. First, the MSE of the ML value network is generally lower than the value network alone. Second, the program based on the ML value network wins by a rate of 67.6% against the program based on the value network alone. Third, the program with the proposed dynamic komi method significantly improves the playing strength over the baseline that does not use dynamic komi, especially for handicap games. To our knowledge, up to date, no handicap games have been played openly by programs using value networks. This paper provides these programs with a useful approach to playing handicap games.\n    ",
        "submission_date": "2017-05-30T00:00:00",
        "last_modified_date": "2017-05-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.10720",
        "title": "Low Impact Artificial Intelligences",
        "authors": [
            "Stuart Armstrong",
            "Benjamin Levinstein"
        ],
        "abstract": "There are many goals for an AI that could become dangerous if the AI becomes superintelligent or otherwise powerful. Much work on the AI control problem has been focused on constructing AI goals that are safe even for such AIs. This paper looks at an alternative approach: defining a general concept of `low impact'. The aim is to ensure that a powerful AI which implements low impact will not modify the world extensively, even if it is given a simple or dangerous goal. The paper proposes various ways of defining and grounding low impact, and discusses methods for ensuring that the AI can still be allowed to have a (desired) impact despite the restriction. The end of the paper addresses known issues with this approach and avenues for future research.\n    ",
        "submission_date": "2017-05-30T00:00:00",
        "last_modified_date": "2017-05-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.10726",
        "title": "Strength Factors: An Uncertainty System for a Quantified Modal Logic",
        "authors": [
            "Naveen Sundar Govindarajulu",
            "Selmer Bringsjord"
        ],
        "abstract": "We present a new system S for handling uncertainty in a quantified modal logic (first-order modal logic). The system is based on both probability theory and proof theory. The system is derived from Chisholm's epistemology. We concretize Chisholm's system by grounding his undefined and primitive (i.e. foundational) concept of reasonablenes in probability and proof theory. S can be useful in systems that have to interact with humans and provide justifications for their uncertainty. As a demonstration of the system, we apply the system to provide a solution to the lottery paradox. Another advantage of the system is that it can be used to provide uncertainty values for counterfactual statements. Counterfactuals are statements that an agent knows for sure are false. Among other cases, counterfactuals are useful when systems have to explain their actions to users. Uncertainties for counterfactuals fall out naturally from our system.\n",
        "submission_date": "2017-05-30T00:00:00",
        "last_modified_date": "2018-05-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.10742",
        "title": "Generating Steganographic Text with LSTMs",
        "authors": [
            "Tina Fang",
            "Martin Jaggi",
            "Katerina Argyraki"
        ],
        "abstract": "Motivated by concerns for user privacy, we design a steganographic system (\"stegosystem\") that enables two users to exchange encrypted messages without an adversary detecting that such an exchange is taking place. We propose a new linguistic stegosystem based on a Long Short-Term Memory (LSTM) neural network. We demonstrate our approach on the Twitter and Enron email datasets and show that it yields high-quality steganographic text while significantly improving capacity (encrypted bits per word) relative to the state-of-the-art.\n    ",
        "submission_date": "2017-05-30T00:00:00",
        "last_modified_date": "2017-05-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.10834",
        "title": "Experience Replay Using Transition Sequences",
        "authors": [
            "Thommen George Karimpanal",
            "Roland Bouffanais"
        ],
        "abstract": "Experience replay is one of the most commonly used approaches to improve the sample efficiency of reinforcement learning algorithms. In this work, we propose an approach to select and replay sequences of transitions in order to accelerate the learning of a reinforcement learning agent in an off-policy setting. In addition to selecting appropriate sequences, we also artificially construct transition sequences using information gathered from previous agent-environment interactions. These sequences, when replayed, allow value function information to trickle down to larger sections of the state/state-action space, thereby making the most of the agent's experience. We demonstrate our approach on modified versions of standard reinforcement learning tasks such as the mountain car and puddle world problems and empirically show that it enables better learning of value functions as compared to other forms of experience replay. Further, we briefly discuss some of the possible extensions to this work, as well as applications and situations where this approach could be particularly useful.\n    ",
        "submission_date": "2017-05-30T00:00:00",
        "last_modified_date": "2019-09-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.10868",
        "title": "Lifelong Multi-Agent Path Finding for Online Pickup and Delivery Tasks",
        "authors": [
            "Hang Ma",
            "Jiaoyang Li",
            "T. K. Satish Kumar",
            "Sven Koenig"
        ],
        "abstract": "The multi-agent path-finding (MAPF) problem has recently received a lot of attention. However, it does not capture important characteristics of many real-world domains, such as automated warehouses, where agents are constantly engaged with new tasks. In this paper, we therefore study a lifelong version of the MAPF problem, called the multi-agent pickup and delivery (MAPD) problem. In the MAPD problem, agents have to attend to a stream of delivery tasks in an online setting. One agent has to be assigned to each delivery task. This agent has to first move to a given pickup location and then to a given delivery location while avoiding collisions with other agents. We present two decoupled MAPD algorithms, Token Passing (TP) and Token Passing with Task Swaps (TPTS). Theoretically, we show that they solve all well-formed MAPD instances, a realistic subclass of MAPD instances. Experimentally, we compare them against a centralized strawman MAPD algorithm without this guarantee in a simulated warehouse system. TP can easily be extended to a fully distributed MAPD algorithm and is the best choice when real-time computation is of primary concern since it remains efficient for MAPD instances with hundreds of agents and tasks. TPTS requires limited communication among agents and balances well between TP and the centralized MAPD algorithm.\n    ",
        "submission_date": "2017-05-30T00:00:00",
        "last_modified_date": "2017-05-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.10898",
        "title": "Towards Learned Clauses Database Reduction Strategies Based on Dominance Relationship",
        "authors": [
            "Jerry Lonlac",
            "Engelbert Mephu Nguifo"
        ],
        "abstract": "Clause Learning is one of the most important components of a conflict driven clause learning (CDCL) SAT solver that is effective on industrial instances. Since the number of learned clauses is proved to be exponential in the worse case, it is necessary to identify the most relevant clauses to maintain and delete the irrelevant ones. As reported in the literature, several learned clauses deletion strategies have been proposed. However the diversity in both the number of clauses to be removed at each step of reduction and the results obtained with each strategy creates confusion to determine which criterion is better. Thus, the problem to select which learned clauses are to be removed during the search step remains very challenging. In this paper, we propose a novel approach to identify the most relevant learned clauses without favoring or excluding any of the proposed measures, but by adopting the notion of dominance relationship among those measures. Our approach bypasses the problem of the diversity of results and reaches a compromise between the assessments of these measures. Furthermore, the proposed approach also avoids another non-trivial problem which is the amount of clauses to be deleted at each reduction of the learned clause database.\n    ",
        "submission_date": "2017-05-31T00:00:00",
        "last_modified_date": "2017-05-31T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.10899",
        "title": "Propositional Knowledge Representation and Reasoning in Restricted Boltzmann Machines",
        "authors": [
            "Son N. Tran"
        ],
        "abstract": "While knowledge representation and reasoning are considered the keys for human-level artificial intelligence, connectionist networks have been shown successful in a broad range of applications due to their capacity for robust learning and flexible inference under uncertainty. The idea of representing symbolic knowledge in connectionist networks has been well-received and attracted much attention from research community as this can establish a foundation for integration of scalable learning and sound reasoning. In previous work, there exist a number of approaches that map logical inference rules with feed-forward propagation of artificial neural networks (ANN). However, the discriminative structure of an ANN requires the separation of input/output variables which makes it difficult for general reasoning where any variables should be inferable. Other approaches address this issue by employing generative models such as symmetric connectionist networks, however, they are difficult and convoluted. In this paper we propose a novel method to represent propositional formulas in restricted Boltzmann machines which is less complex, especially in the cases of logical implications and Horn clauses. An integration system is then developed and evaluated in real datasets which shows promising results.\n    ",
        "submission_date": "2017-05-31T00:00:00",
        "last_modified_date": "2018-05-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.10998",
        "title": "The Atari Grand Challenge Dataset",
        "authors": [
            "Vitaly Kurin",
            "Sebastian Nowozin",
            "Katja Hofmann",
            "Lucas Beyer",
            "Bastian Leibe"
        ],
        "abstract": "Recent progress in Reinforcement Learning (RL), fueled by its combination, with Deep Learning has enabled impressive results in learning to interact with complex virtual environments, yet real-world applications of RL are still scarce. A key limitation is data efficiency, with current state-of-the-art approaches requiring millions of training samples. A promising way to tackle this problem is to augment RL with learning from human demonstrations. However, human demonstration data is not yet readily available. This hinders progress in this direction. The present work addresses this problem as follows. We (i) collect and describe a large dataset of human Atari 2600 replays -- the largest and most diverse such data set publicly released to date, (ii) illustrate an example use of this dataset by analyzing the relation between demonstration quality and imitation learning performance, and (iii) outline possible research directions that are opened up by our work.\n    ",
        "submission_date": "2017-05-31T00:00:00",
        "last_modified_date": "2017-05-31T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.00037",
        "title": "A Diversified Multi-Start Algorithm for Unconstrained Binary Quadratic Problems Leveraging the Graphics Processor Unit",
        "authors": [
            "Mark W. Lewis"
        ],
        "abstract": "Multi-start algorithms are a common and effective tool for metaheuristic searches. In this paper we amplify multi-start capabilities by employing the parallel processing power of the graphics processer unit (GPU) to quickly generate a diverse starting set of solutions for the Unconstrained Binary Quadratic Optimization Problem which are evaluated and used to implement screening methods to select solutions for further optimization. This method is implemented as an initial high quality solution generation phase prior to a secondary steepest ascent search and a comparison of results to best known approaches on benchmark unconstrained binary quadratic problems demonstrates that GPU-enabled diversified multi-start with screening quickly yields very good results.\n    ",
        "submission_date": "2017-05-31T00:00:00",
        "last_modified_date": "2017-05-31T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.00066",
        "title": "Descriptions of Objectives and Processes of Mechanical Learning",
        "authors": [
            "Chuyu Xiong"
        ],
        "abstract": "In [1], we introduced mechanical learning and proposed 2 approaches to mechanical learning. Here, we follow one such approach to well describe the objects and the processes of learning. We discuss 2 kinds of patterns: objective and subjective pattern. Subjective pattern is crucial for learning machine. We prove that for any objective pattern we can find a proper subjective pattern based upon least base patterns to express the objective pattern well. X-form is algebraic expression for subjective pattern. Collection of X-forms form internal representation space, which is center of learning machine. We discuss learning by teaching and without teaching. We define data sufficiency by X-form. We then discussed some learning strategies. We show, in each strategy, with sufficient data, and with certain capabilities, learning machine indeed can learn any pattern (universal learning machine). In appendix, with knowledge of learning machine, we try to view deep learning from a different angle, i.e. its internal representation space and its learning dynamics.\n    ",
        "submission_date": "2017-05-31T00:00:00",
        "last_modified_date": "2017-05-31T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.00123",
        "title": "Diversified Top-k Partial MaxSAT Solving",
        "authors": [
            "Junping Zhou",
            "Huanyao Sun",
            "Feifei Ma",
            "Jian Gao",
            "Ke Xu",
            "Minghao Yin"
        ],
        "abstract": "We introduce a diversified top-k partial MaxSAT problem, a combination of partial MaxSAT problem and enumeration problem. Given a partial MaxSAT formula F and a positive integer k, the diversified top-k partial MaxSAT is to find k maximal solutions for F such that the k maximal solutions satisfy the maximum number of soft clauses of F. This problem can be widely used in many applications including community detection, sensor place, motif discovery, and combinatorial testing. We prove the problem is NP-hard and propose an approach for solving the problem. The concrete idea of the approach is to design an encoding EE which reduces diversified top-k partial MaxSAT problem into partial MaxSAT problem, and then solve the resulting problem with state-of-art solvers. In addition, we present an algorithm MEMKC exactly solving the diversified top-k partial MaxSAT. Through several experiments we show that our approach can be successfully applied to the interesting problem.\n    ",
        "submission_date": "2017-05-31T00:00:00",
        "last_modified_date": "2017-05-31T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.00355",
        "title": "Grounding Symbols in Multi-Modal Instructions",
        "authors": [
            "Yordan Hristov",
            "Svetlin Penkov",
            "Alex Lascarides",
            "Subramanian Ramamoorthy"
        ],
        "abstract": "As robots begin to cohabit with humans in semi-structured environments, the need arises to understand instructions involving rich variability---for instance, learning to ground symbols in the physical world. Realistically, this task must cope with small datasets consisting of a particular users' contextual assignment of meaning to terms. We present a method for processing a raw stream of cross-modal input---i.e., linguistic instructions, visual perception of a scene and a concurrent trace of 3D eye tracking fixations---to produce the segmentation of objects with a correspondent association to high-level concepts. To test our framework we present experiments in a table-top object manipulation scenario. Our results show our model learns the user's notion of colour and shape from a small number of physical demonstrations, generalising to identifying physical referents for novel combinations of the words.\n    ",
        "submission_date": "2017-06-01T00:00:00",
        "last_modified_date": "2017-06-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.00356",
        "title": "Enhancing workflow-nets with data for trace completion",
        "authors": [
            "Riccardo De Masellis",
            "Chiara Di Francescomarino",
            "Chiara Ghidini",
            "Sergio Tessaris"
        ],
        "abstract": "The growing adoption of IT-systems for modeling and executing (business) processes or services has thrust the scientific investigation towards techniques and tools which support more complex forms of process analysis. Many of them, such as conformance checking, process alignment, mining and enhancement, rely on complete observation of past (tracked and logged) executions. In many real cases, however, the lack of human or IT-support on all the steps of process execution, as well as information hiding and abstraction of model and data, result in incomplete log information of both data and activities. This paper tackles the issue of automatically repairing traces with missing information by notably considering not only activities but also data manipulated by them. Our technique recasts such a problem in a reachability problem and provides an encoding in an action language which allows to virtually use any state-of-the-art planning to return solutions.\n    ",
        "submission_date": "2017-06-01T00:00:00",
        "last_modified_date": "2017-06-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.00526",
        "title": "Knowledge Representation in Bicategories of Relations",
        "authors": [
            "Evan Patterson"
        ],
        "abstract": "We introduce the relational ontology log, or relational olog, a knowledge representation system based on the category of sets and relations. It is inspired by Spivak and Kent's olog, a recent categorical framework for knowledge representation. Relational ologs interpolate between ologs and description logic, the dominant formalism for knowledge representation today. In this paper, we investigate relational ologs both for their own sake and to gain insight into the relationship between the algebraic and logical approaches to knowledge representation. On a practical level, we show by example that relational ologs have a friendly and intuitive--yet fully precise--graphical syntax, derived from the string diagrams of monoidal categories. We explain several other useful features of relational ologs not possessed by most description logics, such as a type system and a rich, flexible notion of instance data. In a more theoretical vein, we draw on categorical logic to show how relational ologs can be translated to and from logical theories in a fragment of first-order logic. Although we make extensive use of categorical language, this paper is designed to be self-contained and has considerable expository content. The only prerequisites are knowledge of first-order logic and the rudiments of category theory.\n    ",
        "submission_date": "2017-06-02T00:00:00",
        "last_modified_date": "2017-11-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.00536",
        "title": "Modeling Latent Attention Within Neural Networks",
        "authors": [
            "Christopher Grimm",
            "Dilip Arumugam",
            "Siddharth Karamcheti",
            "David Abel",
            "Lawson L.S. Wong",
            "Michael L. Littman"
        ],
        "abstract": "Deep neural networks are able to solve tasks across a variety of domains and modalities of data. Despite many empirical successes, we lack the ability to clearly understand and interpret the learned internal mechanisms that contribute to such effective behaviors or, more critically, failure modes. In this work, we present a general method for visualizing an arbitrary neural network's inner mechanisms and their power and limitations. Our dataset-centric method produces visualizations of how a trained network attends to components of its inputs. The computed \"attention masks\" support improved interpretability by highlighting which input attributes are critical in determining output. We demonstrate the effectiveness of our framework on a variety of deep neural network architectures in domains from computer vision, natural language processing, and reinforcement learning. The primary contribution of our approach is an interpretable visualization of attention that provides unique insights into the network's underlying decision-making process irrespective of the data modality.\n    ",
        "submission_date": "2017-06-02T00:00:00",
        "last_modified_date": "2017-12-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.00585",
        "title": "Exception-Based Knowledge Updates",
        "authors": [
            "Martin Slota",
            "Joao Leite"
        ],
        "abstract": "Existing methods for dealing with knowledge updates differ greatly depending on the underlying knowledge representation formalism. When Classical Logic is used, updates are typically performed by manipulating the knowledge base on the model-theoretic level. On the opposite side of the spectrum stand the semantics for updating Answer-Set Programs that need to rely on rule syntax. Yet, a unifying perspective that could embrace both these branches of research is of great importance as it enables a deeper understanding of all involved methods and principles and creates room for their cross-fertilisation, ripening and further development.\n",
        "submission_date": "2017-06-02T00:00:00",
        "last_modified_date": "2017-06-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.00637",
        "title": "Joint Matrix-Tensor Factorization for Knowledge Base Inference",
        "authors": [
            "Prachi Jain",
            "Shikhar Murty",
            "Mausam",
            "Soumen Chakrabarti"
        ],
        "abstract": "While several matrix factorization (MF) and tensor factorization (TF) models have been proposed for knowledge base (KB) inference, they have rarely been compared across various datasets. Is there a single model that performs well across datasets? If not, what characteristics of a dataset determine the performance of MF and TF models? Is there a joint TF+MF model that performs robustly on all datasets? We perform an extensive evaluation to compare popular KB inference models across popular datasets in the literature. In addition to answering the questions above, we remove a limitation in the standard evaluation protocol for MF models, propose an extension to MF models so that they can better handle out-of-vocabulary (OOV) entity pairs, and develop a novel combination of TF and MF models. We also analyze and explain the results based on models and dataset characteristics. Our best model is robust, and obtains strong results across all datasets.\n    ",
        "submission_date": "2017-06-02T00:00:00",
        "last_modified_date": "2017-06-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.00638",
        "title": "ICABiDAS: Intuition Centred Architecture for Big Data Analysis and Synthesis",
        "authors": [
            "Amit Kumar Mishra"
        ],
        "abstract": "Humans are expert in the amount of sensory data they deal with each moment. Human brain not only analyses these data but also starts synthesizing new information from the existing data. The current age Big-data systems are needed not just to analyze data but also to come up new interpretation. We believe that the pivotal ability in human brain which enables us to do this is what is known as \"intuition\". Here, we present an intuition based architecture for big data analysis and synthesis.\n    ",
        "submission_date": "2017-06-02T00:00:00",
        "last_modified_date": "2017-06-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.01077",
        "title": "Actor-Critic for Linearly-Solvable Continuous MDP with Partially Known Dynamics",
        "authors": [
            "Tomoki Nishi",
            "Prashant Doshi",
            "Michael R. James",
            "Danil Prokhorov"
        ],
        "abstract": "In many robotic applications, some aspects of the system dynamics can be modeled accurately while others are difficult to obtain or model. We present a novel reinforcement learning (RL) method for continuous state and action spaces that learns with partial knowledge of the system and without active exploration. It solves linearly-solvable Markov decision processes (L-MDPs), which are well suited for continuous state and action spaces, based on an actor-critic architecture. Compared to previous RL methods for L-MDPs and path integral methods which are model based, the actor-critic learning does not need a model of the uncontrolled dynamics and, importantly, transition noise levels; however, it requires knowing the control dynamics for the problem. We evaluate our method on two synthetic test problems, and one real-world problem in simulation and using real traffic data. Our experiments demonstrate improved learning and policy performance.\n    ",
        "submission_date": "2017-06-04T00:00:00",
        "last_modified_date": "2017-06-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.01303",
        "title": "The Singularity May Be Near",
        "authors": [
            "Roman V. Yampolskiy"
        ],
        "abstract": "Toby Walsh in 'The Singularity May Never Be Near' gives six arguments to support his point of view that technological singularity may happen but that it is unlikely. In this paper, we provide analysis of each one of his arguments and arrive at similar conclusions, but with more weight given to the 'likely to happen' probability.\n    ",
        "submission_date": "2017-05-31T00:00:00",
        "last_modified_date": "2017-05-31T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.01320",
        "title": "3D Pathfinding and Collision Avoidance Using Uneven Search-space Quantization and Visual Cone Search",
        "authors": [
            "Diptangshu Pandit"
        ],
        "abstract": "Pathfinding is a very popular area in computer game development. While two-dimensional (2D) pathfinding is widely applied in most of the popular game engines, little implementation of real three-dimensional (3D) pathfinding can be found. This research presents a dynamic search space optimization algorithm which can be applied to tessellate 3D search space unevenly, significantly reducing the total number of resulting nodes. The algorithm can be used with popular pathfinding algorithms in 3D game engines. Furthermore, a simplified standalone 3D pathfinding algorithm is proposed in this paper. The proposed algorithm relies on ray-casting or line vision to generate a feasible path during runtime without requiring division of the search space into a 3D grid. Both of the proposed algorithms are simulated on Unreal Engine to show innerworkings and resultant path comparison with A*. The advantages and shortcomings of the proposed algorithms are also discussed along with future directions.\n    ",
        "submission_date": "2017-06-05T00:00:00",
        "last_modified_date": "2018-06-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.01417",
        "title": "A method for the online construction of the set of states of a Markov Decision Process using Answer Set Programming",
        "authors": [
            "Leonardo A. Ferreira",
            "Reinaldo A. C. Bianchi",
            "Paulo E. Santos",
            "Ramon Lopez de Mantaras"
        ],
        "abstract": "Non-stationary domains, that change in unpredicted ways, are a challenge for agents searching for optimal policies in sequential decision-making problems. This paper presents a combination of Markov Decision Processes (MDP) with Answer Set Programming (ASP), named {\\em Online ASP for MDP} (oASP(MDP)), which is a method capable of constructing the set of domain states while the agent interacts with a changing environment. oASP(MDP) updates previously obtained policies, learnt by means of Reinforcement Learning (RL), using rules that represent the domain changes observed by the agent. These rules represent a set of domain constraints that are processed as ASP programs reducing the search space. Results show that oASP(MDP) is capable of finding solutions for problems in non-stationary domains without interfering with the action-value function approximation process.\n    ",
        "submission_date": "2017-06-05T00:00:00",
        "last_modified_date": "2017-06-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.01443",
        "title": "Types of Cognition and its Implications for future High-Level Cognitive Machines",
        "authors": [
            "Camilo Miguel Signorelli"
        ],
        "abstract": "This work summarizes part of current knowledge on High-level Cognitive process and its relation with biological hardware. Thus, it is possible to identify some paradoxes which could impact the development of future technologies and artificial intelligence: we may make a High-level Cognitive Machine, sacrificing the principal attribute of a machine, its accuracy.\n    ",
        "submission_date": "2017-06-05T00:00:00",
        "last_modified_date": "2017-06-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.01991",
        "title": "Unsupervised Neural-Symbolic Integration",
        "authors": [
            "Son N. Tran"
        ],
        "abstract": "Symbolic has been long considered as a language of human intelligence while neural networks have advantages of robust computation and dealing with noisy data. The integration of neural-symbolic can offer better learning and reasoning while providing a means for interpretability through the representation of symbolic knowledge. Although previous works focus intensively on supervised feedforward neural networks, little has been done for the unsupervised counterparts. In this paper we show how to integrate symbolic knowledge into unsupervised neural networks. We exemplify our approach with knowledge in different forms, including propositional logic for DNA promoter prediction and first-order logic for understanding family relationship.\n    ",
        "submission_date": "2017-06-06T00:00:00",
        "last_modified_date": "2017-06-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.02048",
        "title": "Epistemic Logic with Functional Dependency Operator",
        "authors": [
            "Yifeng Ding"
        ],
        "abstract": "Epistemic logic with non-standard knowledge operators, especially the \"knowing-value\" operator, has recently gathered much attention. With the \"knowing-value\" operator, we can express knowledge of individual variables, but not of the relations between them in general. In this paper, we propose a new operator Kf to express knowledge of the functional dependencies between variables. The semantics of this Kf operator uses a function domain which imposes a constraint on what counts as a functional dependency relation. By adjusting this function domain, different interesting logics arise, and in this paper we axiomatize three such logics in a single agent setting. Then we show how these three logics can be unified by allowing the function domain to vary relative to different agents and possible worlds. A multiagent axiomatization is given in this case.\n    ",
        "submission_date": "2017-06-07T00:00:00",
        "last_modified_date": "2017-06-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.02246",
        "title": "Stochastic Global Optimization Algorithms: A Systematic Formal Approach",
        "authors": [
            "Jonatan Gomez"
        ],
        "abstract": "As we know, some global optimization problems cannot be solved using analytic methods, so numeric/algorithmic approaches are used to find near to the optimal solutions for them. A stochastic global optimization algorithm (SGoal) is an iterative algorithm that generates a new population (a set of candidate solutions) from a previous population using stochastic operations. Although some research works have formalized SGoals using Markov kernels, such formalization is not general and sometimes is blurred. In this paper, we propose a comprehensive and systematic formal approach for studying SGoals. First, we present the required theory of probability (\\sigma-algebras, measurable functions, kernel, markov chain, products, convergence and so on) and prove that some algorithmic functions like swapping and projection can be represented by kernels. Then, we introduce the notion of join-kernel as a way of characterizing the combination of stochastic methods. Next, we define the optimization space, a formal structure (a set with a \\sigma-algebra that contains strict \\epsilon-optimal states) for studying SGoals, and we develop kernels, like sort and permutation, on such structure. Finally, we present some popular SGoals in terms of the developed theory, we introduce sufficient conditions for convergence of a SGoal, and we prove convergence of some popular SGoals.\n    ",
        "submission_date": "2017-06-07T00:00:00",
        "last_modified_date": "2017-06-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.02274",
        "title": "Can Computers overcome Humans? Consciousness interaction and its implications",
        "authors": [
            "Camilo Miguel Signorelli"
        ],
        "abstract": "Can computers overcome human capabilities? This is a paradoxical and controversial question, particularly because there are many hidden assumptions. This article focuses on that issue putting on evidence some misconception related with future generations of machines and the understanding of the brain. It will be discussed to what extent computers might reach human capabilities, and how it could be possible only if the computer is a conscious machine. However, it will be shown that if the computer is conscious, an interference process due to consciousness would affect the information processing of the system. Therefore, it might be possible to make conscious machines to overcome human capabilities, which will have limitations as well as humans. In other words, trying to overcome human capabilities with computers implies the paradoxical conclusion that a computer will never overcome human capabilities at all, or if the computer does, it should not be considered as a computer anymore.\n    ",
        "submission_date": "2017-06-07T00:00:00",
        "last_modified_date": "2017-06-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.02423",
        "title": "Seamless Integration and Coordination of Cognitive Skills in Humanoid Robots: A Deep Learning Approach",
        "authors": [
            "Jungsik Hwang",
            "Jun Tani"
        ],
        "abstract": "This study investigates how adequate coordination among the different cognitive processes of a humanoid robot can be developed through end-to-end learning of direct perception of visuomotor stream. We propose a deep dynamic neural network model built on a dynamic vision network, a motor generation network, and a higher-level network. The proposed model was designed to process and to integrate direct perception of dynamic visuomotor patterns in a hierarchical model characterized by different spatial and temporal constraints imposed on each level. We conducted synthetic robotic experiments in which a robot learned to read human's intention through observing the gestures and then to generate the corresponding goal-directed actions. Results verify that the proposed model is able to learn the tutored skills and to generalize them to novel situations. The model showed synergic coordination of perception, action and decision making, and it integrated and coordinated a set of cognitive skills including visual perception, intention reading, attention switching, working memory, action preparation and execution in a seamless manner. Analysis reveals that coherent internal representations emerged at each level of the hierarchy. Higher-level representation reflecting actional intention developed by means of continuous integration of the lower-level visuo-proprioceptive stream.\n    ",
        "submission_date": "2017-06-08T00:00:00",
        "last_modified_date": "2017-06-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.02444",
        "title": "Predictive Coding-based Deep Dynamic Neural Network for Visuomotor Learning",
        "authors": [
            "Jungsik Hwang",
            "Jinhyung Kim",
            "Ahmadreza Ahmadi",
            "Minkyu Choi",
            "Jun Tani"
        ],
        "abstract": "This study presents a dynamic neural network model based on the predictive coding framework for perceiving and predicting the dynamic visuo-proprioceptive patterns. In our previous study [1], we have shown that the deep dynamic neural network model was able to coordinate visual perception and action generation in a seamless manner. In the current study, we extended the previous model under the predictive coding framework to endow the model with a capability of perceiving and predicting dynamic visuo-proprioceptive patterns as well as a capability of inferring intention behind the perceived visuomotor information through minimizing prediction error. A set of synthetic experiments were conducted in which a robot learned to imitate the gestures of another robot in a simulation environment. The experimental results showed that with given intention states, the model was able to mentally simulate the possible incoming dynamic visuo-proprioceptive patterns in a top-down process without the inputs from the external environment. Moreover, the results highlighted the role of minimizing prediction error in inferring underlying intention of the perceived visuo-proprioceptive patterns, supporting the predictive coding account of the mirror neuron systems. The results also revealed that minimizing prediction error in one modality induced the recall of the corresponding representation of another modality acquired during the consolidative learning of raw-level visuo-proprioceptive patterns.\n    ",
        "submission_date": "2017-06-08T00:00:00",
        "last_modified_date": "2017-06-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.02462",
        "title": "Regular Boardgames",
        "authors": [
            "Jakub Kowalski",
            "Maksymilian Mika",
            "Jakub Sutowicz",
            "Marek Szyku\u0142a"
        ],
        "abstract": "We propose a new General Game Playing (GGP) language called Regular Boardgames (RBG), which is based on the theory of regular languages. The objective of RBG is to join key properties as expressiveness, efficiency, and naturalness of the description in one GGP formalism, compensating certain drawbacks of the existing languages. This often makes RBG more suitable for various research and practical developments in GGP. While dedicated mostly for describing board games, RBG is universal for the class of all finite deterministic turn-based games with perfect information. We establish foundations of RBG, and analyze it theoretically and experimentally, focusing on the efficiency of reasoning. Regular Boardgames is the first GGP language that allows efficient encoding and playing games with complex rules and with large branching factor (e.g.\\ amazons, arimaa, large chess variants, go, international checkers, paper soccer).\n    ",
        "submission_date": "2017-06-08T00:00:00",
        "last_modified_date": "2018-11-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.02513",
        "title": "Responsible Autonomy",
        "authors": [
            "Virginia Dignum"
        ],
        "abstract": "As intelligent systems are increasingly making decisions that directly affect society, perhaps the most important upcoming research direction in AI is to rethink the ethical implications of their actions. Means are needed to integrate moral, societal and legal values with technological developments in AI, both during the design process as well as part of the deliberation algorithms employed by these systems. In this paper, we describe leading ethics theories and propose alternative ways to ensure ethical behavior by artificial systems. Given that ethics are dependent on the socio-cultural context and are often only implicit in deliberation processes, methodologies are needed to elicit the values held by designers and stakeholders, and to make these explicit leading to better understanding and trust on artificial autonomous systems.\n    ",
        "submission_date": "2017-06-08T00:00:00",
        "last_modified_date": "2017-06-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.02686",
        "title": "What Does a Belief Function Believe In ?",
        "authors": [
            "Andrzej Matuszewski",
            "Mieczys\u0142aw A. K\u0142opotek"
        ],
        "abstract": "The conditioning in the Dempster-Shafer Theory of Evidence has been defined (by Shafer \\cite{Shafer:90} as combination of a belief function and of an \"event\" via Dempster rule.\n",
        "submission_date": "2017-06-08T00:00:00",
        "last_modified_date": "2017-06-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.02780",
        "title": "Setting Players' Behaviors in World of Warcraft through Semi-Supervised Learning",
        "authors": [
            "Marcelo Souza Nery",
            "Roque Anderson Teixeira",
            "Victor do Nascimento Silva",
            "Adriano Alonso Veloso"
        ],
        "abstract": "Digital games are one of the major and most important fields on the entertainment domain, which also involves cinema and music. Numerous attempts have been done to improve the quality of the games including more realistic artistic production and computer science. Assessing the player's behavior, a task known as player modeling, is currently the need of the hour which leads to possible improvements in terms of: (i) better game interaction experience, (ii) better exploitation of the relationship between players, and (iii) increasing/maintaining the number of players interested in the game. In this paper we model players using the basic four behaviors proposed in \\cite{BartleArtigo}, namely: achiever, explorer, socializer and killer. Our analysis is carried out using data obtained from the game \"World of Warcraft\" over 3 years (2006 $-$ 2009). We employ a semi-supervised learning technique in order to find out characteristics that possibly impact player's behavior.\n    ",
        "submission_date": "2017-06-08T00:00:00",
        "last_modified_date": "2017-06-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.02789",
        "title": "On the Development of Intelligent Agents for MOBA Games",
        "authors": [
            "Victor do Nascimento Silva",
            "Luiz Chaimowicz"
        ],
        "abstract": "Multiplayer Online Battle Arena (MOBA) is one of the most played game genres nowadays. With the increasing growth of this genre, it becomes necessary to develop effective intelligent agents to play alongside or against human players. In this paper we address the problem of agent development for MOBA games. We implement a two-layered architecture agent that handles both navigation and game mechanics. This architecture relies on the use of Influence Maps, a widely used approach for tactical analysis. Several experiments were performed using {\\em League of Legends} as a testbed, and show promising results in this highly dynamic real-time context.\n    ",
        "submission_date": "2017-06-08T00:00:00",
        "last_modified_date": "2017-06-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.02792",
        "title": "The FastMap Algorithm for Shortest Path Computations",
        "authors": [
            "Liron Cohen",
            "Tansel Uras",
            "Shiva Jahangiri",
            "Aliyah Arunasalam",
            "Sven Koenig",
            "T.K. Satish Kumar"
        ],
        "abstract": "We present a new preprocessing algorithm for embedding the nodes of a given edge-weighted undirected graph into a Euclidean space. The Euclidean distance between any two nodes in this space approximates the length of the shortest path between them in the given graph. Later, at runtime, a shortest path between any two nodes can be computed with A* search using the Euclidean distances as heuristic. Our preprocessing algorithm, called FastMap, is inspired by the data mining algorithm of the same name and runs in near-linear time. Hence, FastMap is orders of magnitude faster than competing approaches that produce a Euclidean embedding using Semidefinite Programming. FastMap also produces admissible and consistent heuristics and therefore guarantees the generation of shortest paths. Moreover, FastMap applies to general undirected graphs for which many traditional heuristics, such as the Manhattan Distance heuristic, are not well defined. Empirically, we demonstrate that A* search using the FastMap heuristic is competitive with A* search using other state-of-the-art heuristics, such as the Differential heuristic.\n    ",
        "submission_date": "2017-06-08T00:00:00",
        "last_modified_date": "2017-12-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.02794",
        "title": "Rapid Randomized Restarts for Multi-Agent Path Finding Solvers",
        "authors": [
            "Liron Cohen",
            "Glenn Wagner",
            "T.K. Satish Kumar",
            "Howie Choset",
            "Sven Koenig"
        ],
        "abstract": "Multi-Agent Path Finding (MAPF) is an NP-hard problem well studied in artificial intelligence and robotics. It has many real-world applications for which existing MAPF solvers use various heuristics. However, these solvers are deterministic and perform poorly on \"hard\" instances typically characterized by many agents interfering with each other in a small region. In this paper, we enhance MAPF solvers with randomization and observe that they exhibit heavy-tailed distributions of runtimes on hard instances. This leads us to develop simple rapid randomized restart (RRR) strategies with the intuition that, given a hard instance, multiple short runs have a better chance of solving it compared to one long run. We validate this intuition through experiments and show that our RRR strategies indeed boost the performance of state-of-the-art MAPF solvers such as iECBS and M*.\n    ",
        "submission_date": "2017-06-08T00:00:00",
        "last_modified_date": "2017-06-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.02796",
        "title": "Dynamic Difficulty Adjustment on MOBA Games",
        "authors": [
            "Mirna Paula Silva",
            "Victor do Nascimento Silva",
            "Luiz Chaimowicz"
        ],
        "abstract": "This paper addresses the dynamic difficulty adjustment on MOBA games as a way to improve the player's entertainment. Although MOBA is currently one of the most played genres around the world, it is known as a game that offer less autonomy, more challenges and consequently more frustration. Due to these characteristics, the use of a mechanism that performs the difficulty balance dynamically seems to be an interesting alternative to minimize and/or avoid that players experience such frustrations. In this sense, this paper presents a dynamic difficulty adjustment mechanism for MOBA games. The main idea is to create a computer controlled opponent that adapts dynamically to the player performance, trying to offer to the player a better game experience. This is done by evaluating the performance of the player using a metric based on some game features and switching the difficulty of the opponent's artificial intelligence behavior accordingly. Quantitative and qualitative experiments were performed and the results showed that the system is capable of adapting dynamically to the opponent's skills. In spite of that, the qualitative experiments with users showed that the player's expertise has a greater influence on the perception of the difficulty level and dynamic adaptation.\n    ",
        "submission_date": "2017-06-08T00:00:00",
        "last_modified_date": "2017-06-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.02832",
        "title": "A Tutor Agent for MOBA Games",
        "authors": [
            "Victor do Nascimento Silva",
            "Luiz Chaimowicz"
        ],
        "abstract": "Digital games have become a key player in the entertainment industry, attracting millions of new players each year. In spite of that, novice players may have a hard time when playing certain types of games, such as MOBAs and MMORPGs, due to their steep learning curves and not so friendly online communities. In this paper, we present an approach to help novice players in MOBA games overcome these problems. An artificial intelligence agent plays alongside the player analyzing his/her performance and giving tips about the game. Experiments performed with the game {\\em League of Legends} show the potential of this approach.\n    ",
        "submission_date": "2017-06-09T00:00:00",
        "last_modified_date": "2017-06-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.02897",
        "title": "Bandit Models of Human Behavior: Reward Processing in Mental Disorders",
        "authors": [
            "Djallel Bouneffouf",
            "Irina Rish",
            "Guillermo A. Cecchi"
        ],
        "abstract": "Drawing an inspiration from behavioral studies of human decision making, we propose here a general parametric framework for multi-armed bandit problem, which extends the standard Thompson Sampling approach to incorporate reward processing biases associated with several neurological and psychiatric conditions, including Parkinson's and Alzheimer's diseases, attention-deficit/hyperactivity disorder (ADHD), addiction, and chronic pain. We demonstrate empirically that the proposed parametric approach can often outperform the baseline Thompson Sampling on a variety of datasets. Moreover, from the behavioral modeling perspective, our parametric framework can be viewed as a first step towards a unifying computational model capturing reward processing abnormalities across multiple mental conditions.\n    ",
        "submission_date": "2017-06-07T00:00:00",
        "last_modified_date": "2017-06-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.02929",
        "title": "Evidence Against Evidence Theory (?!)",
        "authors": [
            "Mieczys\u0142aw A. K\u0142opotek",
            "Andrzej Matuszewski"
        ],
        "abstract": "This paper is concerned with the apparent greatest weakness of the Mathematical Theory of Evidence (MTE) of Shafer \\cite{Shafer:76}, which has been strongly criticized by Wasserman \\cite{Wasserman:92ijar} - the relationship to frequencies.\n",
        "submission_date": "2017-06-08T00:00:00",
        "last_modified_date": "2017-06-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.02952",
        "title": "TIP: Typifying the Interpretability of Procedures",
        "authors": [
            "Amit Dhurandhar",
            "Vijay Iyengar",
            "Ronny Luss",
            "Karthikeyan Shanmugam"
        ],
        "abstract": "We provide a novel notion of what it means to be interpretable, looking past the usual association with human understanding. Our key insight is that interpretability is not an absolute concept and so we define it relative to a target model, which may or may not be a human. We define a framework that allows for comparing interpretable procedures by linking them to important practical aspects such as accuracy and robustness. We characterize many of the current state-of-the-art interpretable methods in our framework portraying its general applicability. Finally, principled interpretable strategies are proposed and empirically evaluated on synthetic data, as well as on the largest public olfaction dataset that was made recently available \\cite{olfs}. We also experiment on MNIST with a simple target model and different oracle models of varying complexity. This leads to the insight that the improvement in the target model is not only a function of the oracle model's performance, but also its relative complexity with respect to the target model. Further experiments on CIFAR-10, a real manufacturing dataset and FICO dataset showcase the benefit of our methods over Knowledge Distillation when the target models are simple and the complex model is a neural network.\n    ",
        "submission_date": "2017-06-09T00:00:00",
        "last_modified_date": "2018-10-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.03021",
        "title": "Ethical Artificial Intelligence - An Open Question",
        "authors": [
            "Alice Pavaloiu",
            "Utku Kose"
        ],
        "abstract": "Artificial Intelligence (AI) is an effective science which employs strong enough approaches, methods, and techniques to solve unsolvable real world based problems. Because of its unstoppable rise towards the future, there are also some discussions about its ethics and safety. Shaping an AI friendly environment for people and a people friendly environment for AI can be a possible answer for finding a shared context of values for both humans and robots. In this context, objective of this paper is to address the ethical issues of AI and explore the moral dilemmas that arise from ethical algorithms, from pre set or acquired values. In addition, the paper will also focus on the subject of AI safety. As general, the paper will briefly analyze the concerns and potential solutions to solving the ethical issues presented and increase readers awareness on AI safety as another related research interest.\n    ",
        "submission_date": "2017-05-16T00:00:00",
        "last_modified_date": "2017-05-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.03100",
        "title": "Decoupling Learning Rules from Representations",
        "authors": [
            "Philip S. Thomas",
            "Christoph Dann",
            "Emma Brunskill"
        ],
        "abstract": "In the artificial intelligence field, learning often corresponds to changing the parameters of a parameterized function. A learning rule is an algorithm or mathematical expression that specifies precisely how the parameters should be changed. When creating an artificial intelligence system, we must make two decisions: what representation should be used (i.e., what parameterized function should be used) and what learning rule should be used to search through the resulting set of representable functions. Using most learning rules, these two decisions are coupled in a subtle (and often unintentional) way. That is, using the same learning rule with two different representations that can represent the same sets of functions can result in two different outcomes. After arguing that this coupling is undesirable, particularly when using artificial neural networks, we present a method for partially decoupling these two decisions for a broad class of learning rules that span unsupervised learning, reinforcement learning, and supervised learning.\n    ",
        "submission_date": "2017-06-09T00:00:00",
        "last_modified_date": "2017-06-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.03122",
        "title": "Off The Beaten Lane: AI Challenges In MOBAs Beyond Player Control",
        "authors": [
            "Michael Cook",
            "Adam Summerville",
            "Simon Colton"
        ],
        "abstract": "MOBAs represent a huge segment of online gaming and are growing as both an eSport and a casual genre. The natural starting point for AI researchers interested in MOBAs is to develop an AI to play the game better than a human - but MOBAs have many more challenges besides adversarial AI. In this paper we introduce the reader to the wider context of MOBA culture, propose a range of challenges faced by the community today, and posit concrete AI projects that can be undertaken to begin solving them.\n    ",
        "submission_date": "2017-06-09T00:00:00",
        "last_modified_date": "2017-06-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.03144",
        "title": "A Focal Any-Angle Path-finding Algorithm Based on A* on Visibility Graphs",
        "authors": [
            "Pei Cao",
            "Zhaoyan Fan",
            "Robert X. Gao",
            "Jiong Tang"
        ],
        "abstract": "In this research, we investigate the subject of path-finding. A pruned version of visibility graph based on Candidate Vertices is formulated, followed by a new visibility check technique. Such combination enables us to quickly identify the useful vertices and thus find the optimal path more efficiently. The algorithm proposed is demonstrated on various path-finding cases. The performance of the new technique on visibility graphs is compared to the traditional A* on Grids, Theta* and A* on Visibility Graphs in terms of path length, number of nodes evaluated, as well as computational time. The key algorithmic contribution is that the new approach combines the merits of grid-based method and visibility graph-based method and thus yields better overall performance.\n    ",
        "submission_date": "2017-06-09T00:00:00",
        "last_modified_date": "2017-06-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.03207",
        "title": "Towards Statistical Reasoning in Description Logics over Finite Domains (Full Version)",
        "authors": [
            "Rafael Pe\u00f1aloza",
            "Nico Potyka"
        ],
        "abstract": "We present a probabilistic extension of the description logic $\\mathcal{ALC}$ for reasoning about statistical knowledge. We consider conditional statements over proportions of the domain and are interested in the probabilistic-logical consequences of these proportions. After introducing some general reasoning problems and analyzing their properties, we present first algorithms and complexity results for reasoning in some fragments of Statistical $\\mathcal{ALC}$.\n    ",
        "submission_date": "2017-06-10T00:00:00",
        "last_modified_date": "2017-06-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.03235",
        "title": "ACCNet: Actor-Coordinator-Critic Net for \"Learning-to-Communicate\" with Deep Multi-agent Reinforcement Learning",
        "authors": [
            "Hangyu Mao",
            "Zhibo Gong",
            "Yan Ni",
            "Zhen Xiao"
        ],
        "abstract": "Communication is a critical factor for the big multi-agent world to stay organized and productive. Typically, most previous multi-agent \"learning-to-communicate\" studies try to predefine the communication protocols or use technologies such as tabular reinforcement learning and evolutionary algorithm, which can not generalize to changing environment or large collection of agents.\n",
        "submission_date": "2017-06-10T00:00:00",
        "last_modified_date": "2017-10-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.03254",
        "title": "On Hash-Based Work Distribution Methods for Parallel Best-First Search",
        "authors": [
            "Yuu Jinnai",
            "Alex Fukunaga"
        ],
        "abstract": "Parallel best-first search algorithms such as Hash Distributed A* (HDA*) distribute work among the processes using a global hash function. We analyze the search and communication overheads of state-of-the-art hash-based parallel best-first search algorithms, and show that although Zobrist hashing, the standard hash function used by HDA*, achieves good load balance for many domains, it incurs significant communication overhead since almost all generated nodes are transferred to a different processor than their parents. We propose Abstract Zobrist hashing, a new work distribution method for parallel search which, instead of computing a hash value based on the raw features of a state, uses a feature projection function to generate a set of abstract features which results in a higher locality, resulting in reduced communications overhead. We show that Abstract Zobrist hashing outperforms previous methods on search domains using hand-coded, domain specific feature projection functions. We then propose GRAZHDA*, a graph-partitioning based approach to automatically generating feature projection functions. GRAZHDA* seeks to approximate the partitioning of the actual search space graph by partitioning the domain transition graph, an abstraction of the state space graph. We show that GRAZHDA* outperforms previous methods on domain-independent planning.\n    ",
        "submission_date": "2017-06-10T00:00:00",
        "last_modified_date": "2017-11-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.03304",
        "title": "Deep Optimization for Spectrum Repacking",
        "authors": [
            "Neil Newman",
            "Alexandre Fr\u00e9chette",
            "Kevin Leyton-Brown"
        ],
        "abstract": "Over 13 months in 2016-17 the FCC conducted an \"incentive auction\" to repurpose radio spectrum from broadcast television to wireless internet. In the end, the auction yielded $19.8 billion, $10.05 billion of which was paid to 175 broadcasters for voluntarily relinquishing their licenses across 14 UHF channels. Stations that continued broadcasting were assigned potentially new channels to fit as densely as possible into the channels that remained. The government netted more than $7 billion (used to pay down the national debt) after covering costs. A crucial element of the auction design was the construction of a solver, dubbed SATFC, that determined whether sets of stations could be \"repacked\" in this way; it needed to run every time a station was given a price quote. This paper describes the process by which we built SATFC. We adopted an approach we dub \"deep optimization\", taking a data-driven, highly parametric, and computationally intensive approach to solver design. More specifically, to build SATFC we designed software that could pair both complete and local-search SAT-encoded feasibility checking with a wide range of domain-specific techniques. We then used automatic algorithm configuration techniques to construct a portfolio of eight complementary algorithms to be run in parallel, aiming to achieve good performance on instances that arose in proprietary auction simulations. To evaluate the impact of our solver in this paper, we built an open-source reverse auction simulator. We found that within the short time budget required in practice, SATFC solved more than 95% of the problems it encountered. Furthermore, the incentive auction paired with SATFC produced nearly optimal allocations in a restricted setting and substantially outperformed other alternatives at national scale.\n    ",
        "submission_date": "2017-06-11T00:00:00",
        "last_modified_date": "2017-06-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.03469",
        "title": "Data-Efficient Policy Evaluation Through Behavior Policy Search",
        "authors": [
            "Josiah P. Hanna",
            "Philip S. Thomas",
            "Peter Stone",
            "Scott Niekum"
        ],
        "abstract": "We consider the task of evaluating a policy for a Markov decision process (MDP). The standard unbiased technique for evaluating a policy is to deploy the policy and observe its performance. We show that the data collected from deploying a different policy, commonly called the behavior policy, can be used to produce unbiased estimates with lower mean squared error than this standard technique. We derive an analytic expression for the optimal behavior policy --- the behavior policy that minimizes the mean squared error of the resulting estimates. Because this expression depends on terms that are unknown in practice, we propose a novel policy evaluation sub-problem, behavior policy search: searching for a behavior policy that reduces mean squared error. We present a behavior policy search algorithm and empirically demonstrate its effectiveness in lowering the mean squared error of policy performance estimates.\n    ",
        "submission_date": "2017-06-12T00:00:00",
        "last_modified_date": "2017-06-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.03576",
        "title": "Action and perception for spatiotemporal patterns",
        "authors": [
            "Martin Biehl",
            "Daniel Polani"
        ],
        "abstract": "This is a contribution to the formalization of the concept of agents in multivariate Markov chains. Agents are commonly defined as entities that act, perceive, and are goal-directed. In a multivariate Markov chain (e.g. a cellular automaton) the transition matrix completely determines the dynamics. This seems to contradict the possibility of acting entities within such a system. Here we present definitions of actions and perceptions within multivariate Markov chains based on entity-sets. Entity-sets represent a largely independent choice of a set of spatiotemporal patterns that are considered as all the entities within the Markov chain. For example, the entity-set can be chosen according to operational closure conditions or complete specific integration. Importantly, the perception-action loop also induces an entity-set and is a multivariate Markov chain. We then show that our definition of actions leads to non-heteronomy and that of perceptions specialize to the usual concept of perception in the perception-action loop.\n    ",
        "submission_date": "2017-06-12T00:00:00",
        "last_modified_date": "2017-06-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.03661",
        "title": "DAC-h3: A Proactive Robot Cognitive Architecture to Acquire and Express Knowledge About the World and the Self",
        "authors": [
            "Cl\u00e9ment Moulin-Frier",
            "Tobias Fischer",
            "Maxime Petit",
            "Gr\u00e9goire Pointeau",
            "Jordi-Ysard Puigbo",
            "Ugo Pattacini",
            "Sock Ching Low",
            "Daniel Camilleri",
            "Phuong Nguyen",
            "Matej Hoffmann",
            "Hyung Jin Chang",
            "Martina Zambelli",
            "Anne-Laure Mealier",
            "Andreas Damianou",
            "Giorgio Metta",
            "Tony J. Prescott",
            "Yiannis Demiris",
            "Peter Ford Dominey",
            "Paul F. M. J. Verschure"
        ],
        "abstract": "This paper introduces a cognitive architecture for a humanoid robot to engage in a proactive, mixed-initiative exploration and manipulation of its environment, where the initiative can originate from both the human and the robot. The framework, based on a biologically-grounded theory of the brain and mind, integrates a reactive interaction engine, a number of state-of-the-art perceptual and motor learning algorithms, as well as planning abilities and an autobiographical memory. The architecture as a whole drives the robot behavior to solve the symbol grounding problem, acquire language capabilities, execute goal-oriented behavior, and express a verbal narrative of its own experience in the world. We validate our approach in human-robot interaction experiments with the iCub humanoid robot, showing that the proposed cognitive architecture can be applied in real time within a realistic scenario and that it can be used with naive users.\n    ",
        "submission_date": "2017-06-12T00:00:00",
        "last_modified_date": "2017-09-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.03906",
        "title": "A New Probabilistic Algorithm for Approximate Model Counting",
        "authors": [
            "Cunjing Ge",
            "Feifei Ma",
            "Tian Liu",
            "Jian Zhang"
        ],
        "abstract": "Constrained counting is important in domains ranging from artificial intelligence to software analysis. There are already a few approaches for counting models over various types of constraints. Recently, hashing-based approaches achieve both theoretical guarantees and scalability, but still rely on solution enumeration. In this paper, a new probabilistic polynomial time approximate model counter is proposed, which is also a hashing-based universal framework, but with only satisfiability queries. A variant with a dynamic stopping criterion is also presented. Empirical evaluation over benchmarks on propositional logic formulas and SMT(BV) formulas shows that the approach is promising.\n    ",
        "submission_date": "2017-06-13T00:00:00",
        "last_modified_date": "2017-06-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.03930",
        "title": "Generative Models for Learning from Crowds",
        "authors": [
            "Chi Hong"
        ],
        "abstract": "In this paper, we propose generative probabilistic models for label aggregation. We use Gibbs sampling and a novel variational inference algorithm to perform the posterior inference. Empirical results show that our methods consistently outperform state-of-the-art methods.\n    ",
        "submission_date": "2017-06-13T00:00:00",
        "last_modified_date": "2017-10-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.03940",
        "title": "Fuzzy Recommendations in Marketing Campaigns",
        "authors": [
            "S. Podapati",
            "L. Lundberg",
            "L. Skold",
            "O. Rosander",
            "J. Sidorova"
        ],
        "abstract": "The population in Sweden is growing rapidly due to immigration. In this light, the issue of infrastructure upgrades to provide telecommunication services is of importance. New antennas can be installed at hot spots of user demand, which will require an investment, and/or the clientele expansion can be carried out in a planned manner to promote the exploitation of the infrastructure in the less loaded geographical zones. In this paper, we explore the second alternative. Informally speaking, the term Infrastructure-Stressing describes a user who stays in the zones of high demand, which are prone to produce service failures, if further loaded. We have studied the Infrastructure-Stressing population in the light of their correlation with geo-demographic segments. This is motivated by the fact that specific geo-demographic segments can be targeted via marketing campaigns. Fuzzy logic is applied to create an interface between big data, numeric methods for processing big data and a manager.\n    ",
        "submission_date": "2017-06-13T00:00:00",
        "last_modified_date": "2017-06-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.03944",
        "title": "Recommendations for Marketing Campaigns in Telecommunication Business based on the footprint analysis",
        "authors": [
            "J. Sidorova",
            "L. Skold",
            "O. Rosander",
            "L. Lundberg"
        ],
        "abstract": "A major investment made by a telecom operator goes into the infrastructure and its maintenance, while business revenues are proportional to how big and good the customer base is. We present a data-driven analytic strategy based on combinatorial optimization and analysis of historical data. The data cover historical mobility of the users in one region of Sweden during a week. Applying the proposed method to the case study, we have identified the optimal proportion of geo-demographic segments in the customer base, developed a functionality to assess the potential of a planned marketing campaign, and explored the problem of an optimal number and types of the geo-demographic segments to target through marketing campaigns. With the help of fuzzy logic, the conclusions of data analysis are automatically translated into comprehensible recommendations in a natural language.\n    ",
        "submission_date": "2017-06-13T00:00:00",
        "last_modified_date": "2017-06-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.04033",
        "title": "On Natural Language Generation of Formal Argumentation",
        "authors": [
            "Federico Cerutti",
            "Alice Toniolo",
            "Timothy J. Norman"
        ],
        "abstract": "In this paper we provide a first analysis of the research questions that arise when dealing with the problem of communicating pieces of formal argumentation through natural language interfaces. It is a generally held opinion that formal models of argumentation naturally capture human argument, and some preliminary studies have focused on justifying this view. Unfortunately, the results are not only inconclusive, but seem to suggest that explaining formal argumentation to humans is a rather articulated task. Graphical models for expressing argumentation-based reasoning are appealing, but often humans require significant training to use these tools effectively. We claim that natural language interfaces to formal argumentation systems offer a real alternative, and may be the way forward for systems that capture human argument.\n    ",
        "submission_date": "2017-06-13T00:00:00",
        "last_modified_date": "2017-06-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.04038",
        "title": "Meta learning Framework for Automated Driving",
        "authors": [
            "Ahmad El Sallab",
            "Mahmoud Saeed",
            "Omar Abdel Tawab",
            "Mohammed Abdou"
        ],
        "abstract": "The success of automated driving deployment is highly depending on the ability to develop an efficient and safe driving policy. The problem is well formulated under the framework of optimal control as a cost optimization problem. Model based solutions using traditional planning are efficient, but require the knowledge of the environment model. On the other hand, model free solutions suffer sample inefficiency and require too many interactions with the environment, which is infeasible in practice. Methods under the Reinforcement Learning framework usually require the notion of a reward function, which is not available in the real world. Imitation learning helps in improving sample efficiency by introducing prior knowledge obtained from the demonstrated behavior, on the risk of exact behavior cloning without generalizing to unseen environments. In this paper we propose a Meta learning framework, based on data set aggregation, to improve generalization of imitation learning algorithms. Under the proposed framework, we propose MetaDAgger, a novel algorithm which tackles the generalization issues in traditional imitation learning. We use The Open Race Car Simulator (TORCS) to test our algorithm. Results on unseen test tracks show significant improvement over traditional imitation learning algorithms, improving the learning time and sample efficiency in the same time. The results are also supported by visualization of the learnt features to prove generalization of the captured details.\n    ",
        "submission_date": "2017-06-11T00:00:00",
        "last_modified_date": "2017-06-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.04052",
        "title": "Beyond Monte Carlo Tree Search: Playing Go with Deep Alternative Neural Network and Long-Term Evaluation",
        "authors": [
            "Jinzhuo Wang",
            "Wenmin Wang",
            "Ronggang Wang",
            "Wen Gao"
        ],
        "abstract": "Monte Carlo tree search (MCTS) is extremely popular in computer Go which determines each action by enormous simulations in a broad and deep search tree. However, human experts select most actions by pattern analysis and careful evaluation rather than brute search of millions of future nteractions. In this paper, we propose a computer Go system that follows experts way of thinking and playing. Our system consists of two parts. The first part is a novel deep alternative neural network (DANN) used to generate candidates of next move. Compared with existing deep convolutional neural network (DCNN), DANN inserts recurrent layer after each convolutional layer and stacks them in an alternative manner. We show such setting can preserve more contexts of local features and its evolutions which are beneficial for move prediction. The second part is a long-term evaluation (LTE) module used to provide a reliable evaluation of candidates rather than a single probability from move predictor. This is consistent with human experts nature of playing since they can foresee tens of steps to give an accurate estimation of candidates. In our system, for each candidate, LTE calculates a cumulative reward after several future interactions when local variations are settled. Combining criteria from the two parts, our system determines the optimal choice of next move. For more comprehensive experiments, we introduce a new professional Go dataset (PGD), consisting of 253233 professional records. Experiments on GoGoD and PGD datasets show the DANN can substantially improve performance of move prediction over pure DCNN. When combining LTE, our system outperforms most relevant approaches and open engines based on MCTS.\n    ",
        "submission_date": "2017-06-13T00:00:00",
        "last_modified_date": "2017-06-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.04109",
        "title": "Technical Report: Implementation and Validation of a Smart Health Application",
        "authors": [
            "Fran Casino",
            "Constantinos Patsakis",
            "Antoni Martinez-Balleste",
            "Frederic Borras",
            "Edgar Batista"
        ],
        "abstract": "In this article, we explain in detail the internal structures and databases of a smart health application. Moreover, we describe how to generate a statistically sound synthetic dataset using real-world medical data.\n    ",
        "submission_date": "2017-06-13T00:00:00",
        "last_modified_date": "2017-06-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.04215",
        "title": "Identifying Spatial Relations in Images using Convolutional Neural Networks",
        "authors": [
            "Mandar Haldekar",
            "Ashwinkumar Ganesan",
            "Tim Oates"
        ],
        "abstract": "Traditional approaches to building a large scale knowledge graph have usually relied on extracting information (entities, their properties, and relations between them) from unstructured text (e.g. Dbpedia). Recent advances in Convolutional Neural Networks (CNN) allow us to shift our focus to learning entities and relations from images, as they build robust models that require little or no pre-processing of the images. In this paper, we present an approach to identify and extract spatial relations (e.g., The girl is standing behind the table) from images using CNNs. Our research addresses two specific challenges: providing insight into how spatial relations are learned by the network and which parts of the image are used to predict these relations. We use the pre-trained network VGGNet to extract features from an image and train a Multi-layer Perceptron (MLP) on a set of synthetic images and the sun09 dataset to extract spatial relations. The MLP predicts spatial relations without a bounding box around the objects or the space in the image depicting the relation. To understand how the spatial relations are represented in the network, a heatmap is overlayed on the image to show the regions that are deemed important by the network. Also, we analyze the MLP to show the relationship between the activation of consistent groups of nodes and the prediction of a spatial relation. We show how the loss of these groups affects the networks ability to identify relations.\n    ",
        "submission_date": "2017-06-13T00:00:00",
        "last_modified_date": "2017-06-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.04317",
        "title": "Schema Networks: Zero-shot Transfer with a Generative Causal Model of Intuitive Physics",
        "authors": [
            "Ken Kansky",
            "Tom Silver",
            "David A. M\u00e9ly",
            "Mohamed Eldawy",
            "Miguel L\u00e1zaro-Gredilla",
            "Xinghua Lou",
            "Nimrod Dorfman",
            "Szymon Sidor",
            "Scott Phoenix",
            "Dileep George"
        ],
        "abstract": "The recent adaptation of deep neural network-based methods to reinforcement learning and planning domains has yielded remarkable progress on individual tasks. Nonetheless, progress on task-to-task transfer remains limited. In pursuit of efficient and robust generalization, we introduce the Schema Network, an object-oriented generative physics simulator capable of disentangling multiple causes of events and reasoning backward through causes to achieve goals. The richly structured architecture of the Schema Network can learn the dynamics of an environment directly from data. We compare Schema Networks with Asynchronous Advantage Actor-Critic and Progressive Networks on a suite of Breakout variations, reporting results on training efficiency and zero-shot generalization, consistently demonstrating faster, more robust learning and better transfer. We argue that generalizing from limited data and learning causal relationships are essential abilities on the path toward generally intelligent systems.\n    ",
        "submission_date": "2017-06-14T00:00:00",
        "last_modified_date": "2017-08-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.04463",
        "title": "Simultaneous merging multiple grid maps using the robust motion averaging",
        "authors": [
            "Zutao Jiang",
            "Jihua Zhu",
            "Yaochen Li",
            "Zhongyu Li",
            "Huimin Lu"
        ],
        "abstract": "Mapping in the GPS-denied environment is an important and challenging task in the field of robotics. In the large environment, mapping can be significantly accelerated by multiple robots exploring different parts of the environment. Accordingly, a key problem is how to integrate these local maps built by different robots into a single global map. In this paper, we propose an approach for simultaneous merging of multiple grid maps by the robust motion averaging. The main idea of this approach is to recover all global motions for map merging from a set of relative motions. Therefore, it firstly adopts the pair-wise map merging method to estimate relative motions for grid map pairs. To obtain as many reliable relative motions as possible, a graph-based sampling scheme is utilized to efficiently remove unreliable relative motions obtained from the pair-wise map merging. Subsequently, the accurate global motions can be recovered from the set of reliable relative motions by the motion averaging. Experimental results carried on real robot data sets demonstrate that proposed approach can achieve simultaneous merging of multiple grid maps with good performances.\n    ",
        "submission_date": "2017-06-14T00:00:00",
        "last_modified_date": "2017-06-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.04582",
        "title": "Existence versus Exploitation: The Opacity of Backbones and Backdoors Under a Weak Assumption",
        "authors": [
            "Lane A. Hemaspaandra",
            "David E. Narv\u00e1ez"
        ],
        "abstract": "Backdoors and backbones of Boolean formulas are hidden structural properties. A natural goal, already in part realized, is that solver algorithms seek to obtain substantially better performance by exploiting these structures.\n",
        "submission_date": "2017-06-14T00:00:00",
        "last_modified_date": "2018-11-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.04721",
        "title": "Target Curricula via Selection of Minimum Feature Sets: a Case Study in Boolean Networks",
        "authors": [
            "Shannon Fenn",
            "Pablo Moscato"
        ],
        "abstract": "We consider the effect of introducing a curriculum of targets when training Boolean models on supervised Multi Label Classification (MLC) problems. In particular, we consider how to order targets in the absence of prior knowledge, and how such a curriculum may be enforced when using meta-heuristics to train discrete non-linear models.\n",
        "submission_date": "2017-06-15T00:00:00",
        "last_modified_date": "2017-11-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.04825",
        "title": "Towards Grounding Conceptual Spaces in Neural Representations",
        "authors": [
            "Lucas Bechberger",
            "Kai-Uwe K\u00fchnberger"
        ],
        "abstract": "The highly influential framework of conceptual spaces provides a geometric way of representing knowledge. It aims at bridging the gap between symbolic and subsymbolic processing. Instances are represented by points in a high-dimensional space and concepts are represented by convex regions in this space. In this paper, we present our approach towards grounding the dimensions of a conceptual space in latent spaces learned by an InfoGAN from unlabeled data.\n    ",
        "submission_date": "2017-06-15T00:00:00",
        "last_modified_date": "2017-11-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.05059",
        "title": "Conjunctions of Among Constraints",
        "authors": [
            "Victor Dalmau"
        ],
        "abstract": "Many existing global constraints can be encoded as a conjunction of among constraints. An among constraint holds if the number of the variables in its scope whose value belongs to a prespecified set, which we call its range, is within some given bounds. It is known that domain filtering algorithms can benefit from reasoning about the interaction of among constraints so that values can be filtered out taking into consideration several among constraints simultaneously. The present pa- per embarks into a systematic investigation on the circumstances under which it is possible to obtain efficient and complete domain filtering algorithms for conjunctions of among constraints. We start by observing that restrictions on both the scope and the range of the among constraints are necessary to obtain meaningful results. Then, we derive a domain flow-based filtering algorithm and present several applications. In particular, it is shown that the algorithm unifies and generalizes several previous existing results.\n    ",
        "submission_date": "2017-06-15T00:00:00",
        "last_modified_date": "2017-06-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.05064",
        "title": "Zero-Shot Task Generalization with Multi-Task Deep Reinforcement Learning",
        "authors": [
            "Junhyuk Oh",
            "Satinder Singh",
            "Honglak Lee",
            "Pushmeet Kohli"
        ],
        "abstract": "As a step towards developing zero-shot task generalization capabilities in reinforcement learning (RL), we introduce a new RL problem where the agent should learn to execute sequences of instructions after learning useful skills that solve subtasks. In this problem, we consider two types of generalizations: to previously unseen instructions and to longer sequences of instructions. For generalization over unseen instructions, we propose a new objective which encourages learning correspondences between similar subtasks by making analogies. For generalization over sequential instructions, we present a hierarchical architecture where a meta controller learns to use the acquired skills for executing the instructions. To deal with delayed reward, we propose a new neural architecture in the meta controller that learns when to update the subtask, which makes learning more efficient. Experimental results on a stochastic 3D domain show that the proposed ideas are crucial for generalization to longer instructions as well as unseen instructions.\n    ",
        "submission_date": "2017-06-15T00:00:00",
        "last_modified_date": "2017-11-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.05125",
        "title": "Deal or No Deal? End-to-End Learning for Negotiation Dialogues",
        "authors": [
            "Mike Lewis",
            "Denis Yarats",
            "Yann N. Dauphin",
            "Devi Parikh",
            "Dhruv Batra"
        ],
        "abstract": "Much of human dialogue occurs in semi-cooperative settings, where agents with different goals attempt to agree on common decisions. Negotiations require complex communication and reasoning skills, but success is easy to measure, making this an interesting task for AI. We gather a large dataset of human-human negotiations on a multi-issue bargaining task, where agents who cannot observe each other's reward functions must reach an agreement (or a deal) via natural language dialogue. For the first time, we show it is possible to train end-to-end models for negotiation, which must learn both linguistic and reasoning skills with no annotated dialogue states. We also introduce dialogue rollouts, in which the model plans ahead by simulating possible complete continuations of the conversation, and find that this technique dramatically improves performance. Our code and dataset are publicly available (",
        "submission_date": "2017-06-16T00:00:00",
        "last_modified_date": "2017-06-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.05171",
        "title": "Improving Scalability of Inductive Logic Programming via Pruning and Best-Effort Optimisation",
        "authors": [
            "Mishal Kazmi",
            "Peter Sch\u00fcller",
            "Y\u00fccel Sayg\u0131n"
        ],
        "abstract": "Inductive Logic Programming (ILP) combines rule-based and statistical artificial intelligence methods, by learning a hypothesis comprising a set of rules given background knowledge and constraints for the search space. We focus on extending the XHAIL algorithm for ILP which is based on Answer Set Programming and we evaluate our extensions using the Natural Language Processing application of sentence chunking. With respect to processing natural language, ILP can cater for the constant change in how we use language on a daily basis. At the same time, ILP does not require huge amounts of training examples such as other statistical methods and produces interpretable results, that means a set of rules, which can be analysed and tweaked if necessary. As contributions we extend XHAIL with (i) a pruning mechanism within the hypothesis generalisation algorithm which enables learning from larger datasets, (ii) a better usage of modern solver technology using recently developed optimisation methods, and (iii) a time budget that permits the usage of suboptimal results. We evaluate these improvements on the task of sentence chunking using three datasets from a recent SemEval competition. Results show that our improvements allow for learning on bigger datasets with results that are of similar quality to state-of-the-art systems on the same task. Moreover, we compare the hypotheses obtained on datasets to gain insights on the structure of each dataset.\n    ",
        "submission_date": "2017-06-16T00:00:00",
        "last_modified_date": "2017-06-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.05261",
        "title": "From Propositional Logic to Plausible Reasoning: A Uniqueness Theorem",
        "authors": [
            "Kevin S. Van Horn"
        ],
        "abstract": "We consider the question of extending propositional logic to a logic of plausible reasoning, and posit four requirements that any such extension should satisfy. Each is a requirement that some property of classical propositional logic be preserved in the extended logic; as such, the requirements are simpler and less problematic than those used in Cox's Theorem and its variants. As with Cox's Theorem, our requirements imply that the extended logic must be isomorphic to (finite-set) probability theory. We also obtain specific numerical values for the probabilities, recovering the classical definition of probability as a theorem, with truth assignments that satisfy the premise playing the role of the \"possible cases.\"\n    ",
        "submission_date": "2017-06-16T00:00:00",
        "last_modified_date": "2017-06-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.05296",
        "title": "Value-Decomposition Networks For Cooperative Multi-Agent Learning",
        "authors": [
            "Peter Sunehag",
            "Guy Lever",
            "Audrunas Gruslys",
            "Wojciech Marian Czarnecki",
            "Vinicius Zambaldi",
            "Max Jaderberg",
            "Marc Lanctot",
            "Nicolas Sonnerat",
            "Joel Z. Leibo",
            "Karl Tuyls",
            "Thore Graepel"
        ],
        "abstract": "We study the problem of cooperative multi-agent reinforcement learning with a single joint reward signal. This class of learning problems is difficult because of the often large combined action and observation spaces. In the fully centralized and decentralized approaches, we find the problem of spurious rewards and a phenomenon we call the \"lazy agent\" problem, which arises due to partial observability. We address these problems by training individual agents with a novel value decomposition network architecture, which learns to decompose the team value function into agent-wise value functions. We perform an experimental evaluation across a range of partially-observable multi-agent domains and show that learning such value-decompositions leads to superior results, in particular when combined with weight sharing, role information and information channels.\n    ",
        "submission_date": "2017-06-16T00:00:00",
        "last_modified_date": "2017-06-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.05518",
        "title": "Evaluating the quality of tourist agendas customized to different travel styles",
        "authors": [
            "Jes\u00fas Ib\u00e1\u00f1ez-Ruiz",
            "Laura Sebasti\u00e1",
            "Eva Onaindia"
        ],
        "abstract": "Many tourist applications provide a personalized tourist agenda with the list of recommended activities to the user. These applications must undoubtedly deal with the constraints and preferences that define the user interests. Among these preferences, we can find those that define the travel style of the user, such as the rhythm of the trip, the number of visits to include in the tour or the priority to visits of special interest for the user. In this paper, we deal with the task of creating a customized tourist agenda as a planning and scheduling application capable of conveniently scheduling the most appropriate goals (visits) so as to maximize the user satisfaction with the tourist route. This paper makes an analysis of the meaning of the travel style preferences and compares the quality of the solutions obtained by two different solvers, a PDDL-based planner and a Constraint Satisfaction Problem solver. We also define several quality metrics and perform extensive experiments in order to evaluate the results obtained with both solvers.\n    ",
        "submission_date": "2017-06-17T00:00:00",
        "last_modified_date": "2017-06-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.05637",
        "title": "The impact of Entropy and Solution Density on selected SAT heuristics",
        "authors": [
            "Dor Cohen",
            "Ofer Strichman"
        ],
        "abstract": "In a recent article [Oh'15], Oh examined the impact of various key heuristics (e.g., deletion strategy, restart policy, decay factor, database reduction) in competitive SAT solvers. His key findings are that their expected success depends on whether the input formula is satisfiable or not. To further investigate these findings, we focused on two properties of satisfiable formulas: the entropy of the formula, which approximates the freedom we have in assigning the variables, and the solution density, which is the number of solutions divided by the search space. We found that both predict better the effect of these heuristics, and that satisfiable formulas with small entropy `behave' similarly to unsatisfiable formulas.\n    ",
        "submission_date": "2017-06-18T00:00:00",
        "last_modified_date": "2017-06-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.05643",
        "title": "Entropy, neutro-entropy and anti-entropy for neutrosophic information",
        "authors": [
            "Vasile Patrascu"
        ],
        "abstract": "This approach presents a multi-valued representation of the neutrosophic information. It highlights the link between the bifuzzy information and neutrosophic one. The constructed deca-valued structure shows the neutrosophic information complexity. This deca-valued structure led to construction of two new concepts for the neutrosophic information: neutro-entropy and anti-entropy. These two concepts are added to the two existing: entropy and non-entropy. Thus, we obtained the following triad: entropy, neutro-entropy and anti-entropy.\n    ",
        "submission_date": "2017-06-18T00:00:00",
        "last_modified_date": "2017-06-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.05733",
        "title": "Data set operations to hide decision tree rules",
        "authors": [
            "Dimitris Kalles",
            "Vassilios S. Verykios",
            "Georgios Feretzakis",
            "Athanasios Papagelis"
        ],
        "abstract": "This paper focuses on preserving the privacy of sensitive patterns when inducing decision trees. We adopt a record augmentation approach for hiding sensitive classification rules in binary datasets. Such a hiding methodology is preferred over other heuristic solutions like output perturbation or cryptographic techniques - which restrict the usability of the data - since the raw data itself is readily available for public use. We show some key lemmas which are related to the hiding process and we also demonstrate the methodology with an example and an indicative experiment using a prototype hiding tool.\n    ",
        "submission_date": "2017-06-18T00:00:00",
        "last_modified_date": "2017-06-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.06051",
        "title": "Learning to Schedule Deadline- and Operator-Sensitive Tasks",
        "authors": [
            "Hanan Rosemarin",
            "John P. Dickerson",
            "Sarit Kraus"
        ],
        "abstract": "The use of semi-autonomous and autonomous robotic assistants to aid in care of the elderly is expected to ease the burden on human caretakers, with small-stage testing already occurring in a variety of countries. Yet, it is likely that these robots will need to request human assistance via teleoperation when domain expertise is needed for a specific task. As deployment of robotic assistants moves to scale, mapping these requests for human aid to the teleoperators themselves will be a difficult online optimization problem. In this paper, we design a system that allocates requests to a limited number of teleoperators, each with different specialities, in an online fashion. We generalize a recent model of online job scheduling with a worst-case competitive-ratio bound to our setting. Next, we design a scalable machine-learning-based teleoperator-aware task scheduling algorithm and show, experimentally, that it performs well when compared to an omniscient optimal scheduling algorithm.\n    ",
        "submission_date": "2017-06-19T00:00:00",
        "last_modified_date": "2017-06-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.06060",
        "title": "Consistent feature attribution for tree ensembles",
        "authors": [
            "Scott M. Lundberg",
            "Su-In Lee"
        ],
        "abstract": "Note that a newer expanded version of this paper is now available at: ",
        "submission_date": "2017-06-19T00:00:00",
        "last_modified_date": "2018-02-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.06133",
        "title": "Scalable Co-Optimization of Morphology and Control in Embodied Machines",
        "authors": [
            "Nick Cheney",
            "Josh Bongard",
            "Vytas SunSpiral",
            "Hod Lipson"
        ],
        "abstract": "Evolution sculpts both the body plans and nervous systems of agents together over time. In contrast, in AI and robotics, a robot's body plan is usually designed by hand, and control policies are then optimized for that fixed design. The task of simultaneously co-optimizing the morphology and controller of an embodied robot has remained a challenge. In psychology, the theory of embodied cognition posits that behavior arises from a close coupling between body plan and sensorimotor control, which suggests why co-optimizing these two subsystems is so difficult: most evolutionary changes to morphology tend to adversely impact sensorimotor control, leading to an overall decrease in behavioral performance. Here, we further examine this hypothesis and demonstrate a technique for \"morphological innovation protection\", which temporarily reduces selection pressure on recently morphologically-changed individuals, thus enabling evolution some time to \"readapt\" to the new morphology with subsequent control policy mutations. We show the potential for this method to avoid local optima and converge to similar highly fit morphologies across widely varying initial conditions, while sustaining fitness improvements further into optimization. While this technique is admittedly only the first of many steps that must be taken to achieve scalable optimization of embodied machines, we hope that theoretical insight into the cause of evolutionary stagnation in current methods will help to enable the automation of robot design and behavioral training -- while simultaneously providing a testbed to investigate the theory of embodied cognition.\n    ",
        "submission_date": "2017-06-19T00:00:00",
        "last_modified_date": "2017-12-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.06160",
        "title": "User Intent Classification using Memory Networks: A Comparative Analysis for a Limited Data Scenario",
        "authors": [
            "Arjun Bhardwaj",
            "Alexander Rudnicky"
        ],
        "abstract": "In this report, we provide a comparative analysis of different techniques for user intent classification towards the task of app recommendation. We analyse the performance of different models and architectures for multi-label classification over a dataset with a relative large number of classes and only a handful examples of each class. We focus, in particular, on memory network architectures, and compare how well the different versions perform under the task constraints. Since the classifier is meant to serve as a module in a practical dialog system, it needs to be able to work with limited training data and incorporate new data on the fly. We devise a 1-shot learning task to test the models under the above constraint. We conclude that relatively simple versions of memory networks perform better than other approaches. Although, for tasks with very limited data, simple non-parametric methods perform comparably, without needing the extra training data.\n    ",
        "submission_date": "2017-06-19T00:00:00",
        "last_modified_date": "2017-06-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.06243",
        "title": "The Complexity of Campaigning",
        "authors": [
            "Cory Siler",
            "Luke Harold Miles",
            "Judy Goldsmith"
        ],
        "abstract": "In \"The Logic of Campaigning\", Dean and Parikh consider a candidate making campaign statements to appeal to the voters. They model these statements as Boolean formulas over variables that represent stances on the issues, and study optimal candidate strategies under three proposed models of voter preferences based on the assignments that satisfy these formulas. We prove that voter utility evaluation is computationally hard under these preference models (in one case, #P-hard), along with certain problems related to candidate strategic reasoning. Our results raise questions about the desirable characteristics of a voter preference model and to what extent a polynomial-time-evaluable function can capture them.\n    ",
        "submission_date": "2017-06-20T00:00:00",
        "last_modified_date": "2017-07-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.06328",
        "title": "Session Analysis using Plan Recognition",
        "authors": [
            "Reuth Mirsky",
            "Ya'akov Gal",
            "David Tolpin"
        ],
        "abstract": "This paper presents preliminary results of our work with a major financial company, where we try to use methods of plan recognition in order to investigate the interactions of a costumer with the company's online interface. In this paper, we present the first steps of integrating a plan recognition algorithm in a real-world application for detecting and analyzing the interactions of a costumer. It uses a novel approach for plan recognition from bare-bone UI data, which reasons about the plan library at the lowest recognition level in order to define the relevancy of actions in our domain, and then uses it to perform plan recognition.\n",
        "submission_date": "2017-06-20T00:00:00",
        "last_modified_date": "2017-06-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.06366",
        "title": "A Thorough Formalization of Conceptual Spaces",
        "authors": [
            "Lucas Bechberger",
            "Kai-Uwe K\u00fchnberger"
        ],
        "abstract": "The highly influential framework of conceptual spaces provides a geometric way of representing knowledge. Instances are represented by points in a high-dimensional space and concepts are represented by convex regions in this space. After pointing out a problem with the convexity requirement, we propose a formalization of conceptual spaces based on fuzzy star-shaped sets. Our formalization uses a parametric definition of concepts and extends the original framework by adding means to represent correlations between different domains in a geometric way. Moreover, we define computationally efficient operations on concepts (intersection, union, and projection onto a subspace) and show that these operations can support both learning and reasoning processes.\n    ",
        "submission_date": "2017-06-20T00:00:00",
        "last_modified_date": "2017-09-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.06383",
        "title": "Programmable Agents",
        "authors": [
            "Misha Denil",
            "Sergio G\u00f3mez Colmenarejo",
            "Serkan Cabi",
            "David Saxton",
            "Nando de Freitas"
        ],
        "abstract": "We build deep RL agents that execute declarative programs expressed in formal language. The agents learn to ground the terms in this language in their environment, and can generalize their behavior at test time to execute new programs that refer to objects that were not referenced during training. The agents develop disentangled interpretable representations that allow them to generalize to a wide variety of zero-shot semantic tasks.\n    ",
        "submission_date": "2017-06-20T00:00:00",
        "last_modified_date": "2017-06-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.06643",
        "title": "Policy Gradient Methods for Reinforcement Learning with Function Approximation and Action-Dependent Baselines",
        "authors": [
            "Philip S. Thomas",
            "Emma Brunskill"
        ],
        "abstract": "We show how an action-dependent baseline can be used by the policy gradient theorem using function approximation, originally presented with action-independent baselines by (Sutton et al. 2000).\n    ",
        "submission_date": "2017-06-20T00:00:00",
        "last_modified_date": "2017-06-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.06827",
        "title": "Structure Learning in Motor Control:A Deep Reinforcement Learning Model",
        "authors": [
            "Ari Weinstein",
            "Matthew M. Botvinick"
        ],
        "abstract": "Motor adaptation displays a structure-learning effect: adaptation to a new perturbation occurs more quickly when the subject has prior exposure to perturbations with related structure. Although this `learning-to-learn' effect is well documented, its underlying computational mechanisms are poorly understood. We present a new model of motor structure learning, approaching it from the point of view of deep reinforcement learning. Previous work outside of motor control has shown how recurrent neural networks can account for learning-to-learn effects. We leverage this insight to address motor learning, by importing it into the setting of model-based reinforcement learning. We apply the resulting processing architecture to empirical findings from a landmark study of structure learning in target-directed reaching (Braun et al., 2009), and discuss its implications for a wider range of learning-to-learn phenomena.\n    ",
        "submission_date": "2017-06-21T00:00:00",
        "last_modified_date": "2017-07-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.06906",
        "title": "Expert and Non-Expert Opinion about Technological Unemployment",
        "authors": [
            "Toby Walsh"
        ],
        "abstract": "There is significant concern that technological advances, especially in Robotics and Artificial Intelligence (AI), could lead to high levels of unemployment in the coming decades. Studies have estimated that around half of all current jobs are at risk of automation. To look into this issue in more depth, we surveyed experts in Robotics and AI about the risk, and compared their views with those of non-experts. Whilst the experts predicted a significant number of occupations were at risk of automation in the next two decades, they were more cautious than people outside the field in predicting occupations at risk. Their predictions were consistent with their estimates for when computers might be expected to reach human level performance across a wide range of skills. These estimates were typically decades later than those of the non-experts. Technological barriers may therefore provide society with more time to prepare for an automated future than the public fear. In addition, public expectations may need to be dampened about the speed of progress to be expected in Robotics and AI.\n    ",
        "submission_date": "2017-06-21T00:00:00",
        "last_modified_date": "2017-06-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.06952",
        "title": "Ensemble Framework for Real-time Decision Making",
        "authors": [
            "Philip Rodgers",
            "John Levine"
        ],
        "abstract": "This paper introduces a new framework for real-time decision making in video games. An Ensemble agent is a compound agent composed of multiple agents, each with its own tasks or goals to achieve. Usually when dealing with real-time decision making, reactive agents are used; that is agents that return a decision based on the current state. While reactive agents are very fast, most games require more than just a rule-based agent to achieve good results. Deliberative agents---agents that use a forward model to search future states---are very useful in games with no hard time limit, such as Go or Backgammon, but generally take too long for real-time games. The Ensemble framework addresses this issue by allowing the agent to be both deliberative and reactive at the same time. This is achieved by breaking up the game-play into logical roles and having highly focused components for each role, with each component disregarding anything outwith its own role. Reactive agents can be used where a reactive agent is suited to the role, and where a deliberative approach is required, branching is kept to a minimum by the removal of all extraneous factors, enabling an informed decision to be made within a much smaller time-frame. An Arbiter is used to combine the component results, allowing high performing agents to be created from simple, efficient components.\n    ",
        "submission_date": "2017-06-21T00:00:00",
        "last_modified_date": "2017-06-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.06975",
        "title": "On the enumeration of sentences by compactness",
        "authors": [
            "Mark A. Stalzer"
        ],
        "abstract": "Presented is a Julia meta-program that discovers compact theories from data if they exist. It writes candidate theories in Julia and then validates: tossing the bad theories and keeping the good theories. Compactness is measured by a metric: such as the number of space-time derivatives. The underlying algorithm is applicable to a wide variety of combinatorics problems and compactness serves to cut down the search space.\n    ",
        "submission_date": "2017-06-15T00:00:00",
        "last_modified_date": "2017-06-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.07068",
        "title": "CAN: Creative Adversarial Networks, Generating \"Art\" by Learning About Styles and Deviating from Style Norms",
        "authors": [
            "Ahmed Elgammal",
            "Bingchen Liu",
            "Mohamed Elhoseiny",
            "Marian Mazzone"
        ],
        "abstract": "We propose a new system for generating art. The system generates art by looking at art and learning about style; and becomes creative by increasing the arousal potential of the generated art by deviating from the learned styles. We build over Generative Adversarial Networks (GAN), which have shown the ability to learn to generate novel images simulating a given distribution. We argue that such networks are limited in their ability to generate creative products in their original design. We propose modifications to its objective to make it capable of generating creative art by maximizing deviation from established styles and minimizing deviation from art distribution. We conducted experiments to compare the response of human subjects to the generated art with their response to art created by artists. The results show that human subjects could not distinguish art generated by the proposed system from art generated by contemporary artists and shown in top art fairs. Human subjects even rated the generated images higher on various scales.\n    ",
        "submission_date": "2017-06-21T00:00:00",
        "last_modified_date": "2017-06-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.07160",
        "title": "MAGIX: Model Agnostic Globally Interpretable Explanations",
        "authors": [
            "Nikaash Puri",
            "Piyush Gupta",
            "Pratiksha Agarwal",
            "Sukriti Verma",
            "Balaji Krishnamurthy"
        ],
        "abstract": "Explaining the behavior of a black box machine learning model at the instance level is useful for building trust. However, it is also important to understand how the model behaves globally. Such an understanding provides insight into both the data on which the model was trained and the patterns that it learned. We present here an approach that learns if-then rules to globally explain the behavior of black box machine learning models that have been used to solve classification problems. The approach works by first extracting conditions that were important at the instance level and then evolving rules through a genetic algorithm with an appropriate fitness function. Collectively, these rules represent the patterns followed by the model for decisioning and are useful for understanding its behavior. We demonstrate the validity and usefulness of the approach by interpreting black box models created using publicly available data sets as well as a private digital marketing data set.\n    ",
        "submission_date": "2017-06-22T00:00:00",
        "last_modified_date": "2018-06-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.07269",
        "title": "Explanation in Artificial Intelligence: Insights from the Social Sciences",
        "authors": [
            "Tim Miller"
        ],
        "abstract": "There has been a recent resurgence in the area of explainable artificial intelligence as researchers and practitioners seek to make their algorithms more understandable. Much of this research is focused on explicitly explaining decisions or actions to a human observer, and it should not be controversial to say that looking at how humans explain to each other can serve as a useful starting point for explanation in artificial intelligence. However, it is fair to say that most work in explainable artificial intelligence uses only the researchers' intuition of what constitutes a `good' explanation. There exists vast and valuable bodies of research in philosophy, psychology, and cognitive science of how people define, generate, select, evaluate, and present explanations, which argues that people employ certain cognitive biases and social expectations towards the explanation process. This paper argues that the field of explainable artificial intelligence should build on this existing research, and reviews relevant papers from philosophy, cognitive psychology/science, and social psychology, which study these topics. It draws out some important findings, and discusses ways that these can be infused with work on explainable artificial intelligence.\n    ",
        "submission_date": "2017-06-22T00:00:00",
        "last_modified_date": "2018-08-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.07351",
        "title": "An approach to reachability analysis for feed-forward ReLU neural networks",
        "authors": [
            "Alessio Lomuscio",
            "Lalit Maganti"
        ],
        "abstract": "We study the reachability problem for systems implemented as feed-forward neural networks whose activation function is implemented via ReLU functions. We draw a correspondence between establishing whether some arbitrary output can ever be outputed by a neural system and linear problems characterising a neural system of interest. We present a methodology to solve cases of practical interest by means of a state-of-the-art linear programs solver. We evaluate the technique presented by discussing the experimental results obtained by analysing reachability properties for a number of benchmarks in the literature.\n    ",
        "submission_date": "2017-06-22T00:00:00",
        "last_modified_date": "2017-06-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.07527",
        "title": "Model Selection with Nonlinear Embedding for Unsupervised Domain Adaptation",
        "authors": [
            "Hemanth Venkateswara",
            "Shayok Chakraborty",
            "Troy McDaniel",
            "Sethuraman Panchanathan"
        ],
        "abstract": "Domain adaptation deals with adapting classifiers trained on data from a source distribution, to work effectively on data from a target distribution. In this paper, we introduce the Nonlinear Embedding Transform (NET) for unsupervised domain adaptation. The NET reduces cross-domain disparity through nonlinear domain alignment. It also embeds the domain-aligned data such that similar data points are clustered together. This results in enhanced classification. To determine the parameters in the NET model (and in other unsupervised domain adaptation models), we introduce a validation procedure by sampling source data points that are similar in distribution to the target data. We test the NET and the validation procedure using popular image datasets and compare the classification results across competitive procedures for unsupervised domain adaptation.\n    ",
        "submission_date": "2017-06-23T00:00:00",
        "last_modified_date": "2017-06-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.07946",
        "title": "Justifications in Constraint Handling Rules for Logical Retraction in Dynamic Algorithms",
        "authors": [
            "Thom Fruehwirth"
        ],
        "abstract": "We present a straightforward source-to-source transformation that introduces justifications for user-defined constraints into the CHR programming language. Then a scheme of two rules suffices to allow for logical retraction (deletion, removal) of constraints during computation. Without the need to recompute from scratch, these rules remove not only the constraint but also undo all consequences of the rule applications that involved the constraint. We prove a confluence result concerning the rule scheme and show its correctness. When algorithms are written in CHR, constraints represent both data and operations. CHR is already incremental by nature, i.e. constraints can be added at runtime. Logical retraction adds decrementality. Hence any algorithm written in CHR with justifications will become fully dynamic. Operations can be undone and data can be removed at any point in the computation without compromising the correctness of the result. We present two classical examples of dynamic algorithms, written in our prototype implementation of CHR with justifications that is available online: maintaining the minimum of a changing set of numbers and shortest paths in a graph whose edges change.\n    ",
        "submission_date": "2017-06-24T00:00:00",
        "last_modified_date": "2017-09-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.08001",
        "title": "Temporal-related Convolutional-Restricted-Boltzmann-Machine capable of learning relational order via reinforcement learning procedure?",
        "authors": [
            "Zizhuang Wang"
        ],
        "abstract": "In this article, we extend the conventional framework of convolutional-Restricted-Boltzmann-Machine to learn highly abstract features among abitrary number of time related input maps by constructing a layer of multiplicative units, which capture the relations among inputs. In many cases, more than two maps are strongly related, so it is wise to make multiplicative unit learn relations among more input maps, in other words, to find the optimal relational-order of each unit. In order to enable our machine to learn relational order, we developed a reinforcement-learning method whose optimality is proven to train the network.\n    ",
        "submission_date": "2017-06-24T00:00:00",
        "last_modified_date": "2017-06-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.08089",
        "title": "Finding optimal finite biological sequences over finite alphabets: the OptiFin toolbox",
        "authors": [
            "R\u00e9gis Garnier",
            "Christophe Guyeux",
            "St\u00e9phane Chr\u00e9tien"
        ],
        "abstract": "In this paper, we present a toolbox for a specific optimization problem that frequently arises in bioinformatics or genomics. In this specific optimisation problem, the state space is a set of words of specified length over a finite alphabet. To each word is associated a score. The overall objective is to find the words which have the lowest possible score. This type of general optimization problem is encountered in e.g 3D conformation optimisation for protein structure prediction, or largest core genes subset discovery based on best supported phylogenetic tree for a set of species. In order to solve this problem, we propose a toolbox that can be easily launched using MPI and embeds 3 well-known metaheuristics. The toolbox is fully parametrized and well documented. It has been specifically designed to be easy modified and possibly improved by the user depending on the application, and does not require to be a computer scientist. We show that the toolbox performs very well on two difficult practical problems.\n    ",
        "submission_date": "2017-06-25T00:00:00",
        "last_modified_date": "2017-06-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.08090",
        "title": "Count-Based Exploration in Feature Space for Reinforcement Learning",
        "authors": [
            "Jarryd Martin",
            "Suraj Narayanan Sasikumar",
            "Tom Everitt",
            "Marcus Hutter"
        ],
        "abstract": "We introduce a new count-based optimistic exploration algorithm for Reinforcement Learning (RL) that is feasible in environments with high-dimensional state-action spaces. The success of RL algorithms in these domains depends crucially on generalisation from limited training experience. Function approximation techniques enable RL agents to generalise in order to estimate the value of unvisited states, but at present few methods enable generalisation regarding uncertainty. This has prevented the combination of scalable RL algorithms with efficient exploration strategies that drive the agent to reduce its uncertainty. We present a new method for computing a generalised state visit-count, which allows the agent to estimate the uncertainty associated with any state. Our \\phi-pseudocount achieves generalisation by exploiting same feature representation of the state space that is used for value function approximation. States that have less frequently observed features are deemed more uncertain. The \\phi-Exploration-Bonus algorithm rewards the agent for exploring in feature space rather than in the untransformed state space. The method is simpler and less computationally expensive than some previous proposals, and achieves near state-of-the-art results on high-dimensional RL benchmarks.\n    ",
        "submission_date": "2017-06-25T00:00:00",
        "last_modified_date": "2017-06-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.08100",
        "title": "Specifying Non-Markovian Rewards in MDPs Using LDL on Finite Traces (Preliminary Version)",
        "authors": [
            "Ronen Brafman",
            "Giuseppe De Giacomo",
            "Fabio Patrizi"
        ],
        "abstract": "In Markov Decision Processes (MDPs), the reward obtained in a state depends on the properties of the last state and action. This state dependency makes it difficult to reward more interesting long-term behaviors, such as always closing a door after it has been opened, or providing coffee only following a request. Extending MDPs to handle such non-Markovian reward function was the subject of two previous lines of work, both using variants of LTL to specify the reward function and then compiling the new model back into a Markovian model. Building upon recent progress in the theories of temporal logics over finite traces, we adopt LDLf for specifying non-Markovian rewards and provide an elegant automata construction for building a Markovian model, which extends that of previous work and offers strong minimality and compositionality guarantees.\n    ",
        "submission_date": "2017-06-25T00:00:00",
        "last_modified_date": "2017-06-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.08106",
        "title": "Random Forests for Industrial Device Functioning Diagnostics Using Wireless Sensor Networks",
        "authors": [
            "Wiem Elghazel",
            "Kamal Medjaher",
            "Nourredine Zerhouni",
            "Jacques Bahi",
            "Ahamd Farhat",
            "Christophe Guyeux",
            "Mourad Hakem"
        ],
        "abstract": "In this paper, random forests are proposed for operating devices diagnostics in the presence of a variable number of features. In various contexts, like large or difficult-to-access monitored areas, wired sensor networks providing features to achieve diagnostics are either very costly to use or totally impossible to spread out. Using a wireless sensor network can solve this problem, but this latter is more subjected to flaws. Furthermore, the networks' topology often changes, leading to a variability in quality of coverage in the targeted area. Diagnostics at the sink level must take into consideration that both the number and the quality of the provided features are not constant, and that some politics like scheduling or data aggregation may be developed across the network. The aim of this article is ($1$) to show that random forests are relevant in this context, due to their flexibility and robustness, and ($2$) to provide first examples of use of this method for diagnostics based on data provided by a wireless sensor network.\n    ",
        "submission_date": "2017-06-25T00:00:00",
        "last_modified_date": "2017-06-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.08317",
        "title": "Handling PDDL3.0 State Trajectory Constraints with Temporal Landmarks",
        "authors": [
            "Eliseo Marzal",
            "Mohannad Babli",
            "Eva Onaindia",
            "Laura Sebastia"
        ],
        "abstract": "Temporal landmarks have been proved to be a helpful mechanism to deal with temporal planning problems, specifically to improve planners performance and handle problems with deadline constraints. In this paper, we show the strength of using temporal landmarks to handle the state trajectory constraints of PDDL3.0. We analyze the formalism of TempLM, a temporal planner particularly aimed at solving planning problems with deadlines, and we present a detailed study that exploits the underlying temporal landmark-based mechanism of TempLM for representing and reasoning with trajectory constraints.\n    ",
        "submission_date": "2017-06-26T00:00:00",
        "last_modified_date": "2017-06-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.08439",
        "title": "Optimal choice: new machine learning problem and its solution",
        "authors": [
            "Marina Sapir"
        ],
        "abstract": "The task of learning to pick a single preferred example out a finite set of examples, an \"optimal choice problem\", is a supervised machine learning problem with complex, structured input. Problems of optimal choice emerge often in various practical applications. We formalize the problem, show that it does not satisfy the assumptions of statistical learning theory, yet it can be solved efficiently in some cases. We propose two approaches to solve the problem. Both of them reach good solutions on real life data from a signal processing application.\n    ",
        "submission_date": "2017-06-26T00:00:00",
        "last_modified_date": "2017-07-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.08611",
        "title": "Relating Complexity-theoretic Parameters with SAT Solver Performance",
        "authors": [
            "Edward Zulkoski",
            "Ruben Martins",
            "Christoph Wintersteiger",
            "Robert Robere",
            "Jia Liang",
            "Krzysztof Czarnecki",
            "Vijay Ganesh"
        ],
        "abstract": "Over the years complexity theorists have proposed many structural parameters to explain the surprising efficiency of conflict-driven clause-learning (CDCL) SAT solvers on a wide variety of large industrial Boolean instances. While some of these parameters have been studied empirically, until now there has not been a unified comparative study of their explanatory power on a comprehensive benchmark. We correct this state of affairs by conducting a large-scale empirical evaluation of CDCL SAT solver performance on nearly 7000 industrial and crafted formulas against several structural parameters such as backdoors, treewidth, backbones, and community structure.\n",
        "submission_date": "2017-06-26T00:00:00",
        "last_modified_date": "2017-06-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.08627",
        "title": "SUNNY-CP and the MiniZinc Challenge",
        "authors": [
            "Roberto Amadini",
            "Maurizio Gabbrielli",
            "Jacopo Mauro"
        ],
        "abstract": "In Constraint Programming (CP) a portfolio solver combines a variety of different constraint solvers for solving a given problem. This fairly recent approach enables to significantly boost the performance of single solvers, especially when multicore architectures are exploited. In this work we give a brief overview of the portfolio solver sunny-cp, and we discuss its performance in the MiniZinc Challenge---the annual international competition for CP solvers---where it won two gold medals in 2015 and 2016. Under consideration in Theory and Practice of Logic Programming (TPLP)\n    ",
        "submission_date": "2017-06-26T00:00:00",
        "last_modified_date": "2017-07-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.09007",
        "title": "Strategyproof Mechanisms for Additively Separable Hedonic Games and Fractional Hedonic Games",
        "authors": [
            "Michele Flammini",
            "Gianpiero Monaco",
            "Qiang Zhang"
        ],
        "abstract": "Additively separable hedonic games and fractional hedonic games have received considerable attention. They are coalition forming games of selfish agents based on their mutual preferences. Most of the work in the literature characterizes the existence and structure of stable outcomes (i.e., partitions in coalitions), assuming that preferences are given. However, there is little discussion on this assumption. In fact, agents receive different utilities if they belong to different partitions, and thus it is natural for them to declare their preferences strategically in order to maximize their benefit. In this paper we consider strategyproof mechanisms for additively separable hedonic games and fractional hedonic games, that is, partitioning methods without payments such that utility maximizing agents have no incentive to lie about their true preferences. We focus on social welfare maximization and provide several lower and upper bounds on the performance achievable by strategyproof mechanisms for general and specific additive functions. In most of the cases we provide tight or asymptotically tight results. All our mechanisms are simple and can be computed in polynomial time. Moreover, all the lower bounds are unconditional, that is, they do not rely on any computational or complexity assumptions.\n    ",
        "submission_date": "2017-06-27T00:00:00",
        "last_modified_date": "2017-06-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.09076",
        "title": "A Pig, an Angel and a Cactus Walk Into a Blender: A Descriptive Approach to Visual Blending",
        "authors": [
            "Jo\u00e3o M. Cunha",
            "Jo\u00e3o Gon\u00e7alves",
            "Pedro Martins",
            "Penousal Machado",
            "Am\u00edlcar Cardoso"
        ],
        "abstract": "A descriptive approach for automatic generation of visual blends is presented. The implemented system, the Blender, is composed of two components: the Mapper and the Visual Blender. The approach uses structured visual representations along with sets of visual relations which describe how the elements (in which the visual representation can be decomposed) relate among each other. Our system is a hybrid blender, as the blending process starts at the Mapper (conceptual level) and ends at the Visual Blender (visual representation level). The experimental results show that the Blender is able to create analogies from input mental spaces and produce well-composed blends, which follow the rules imposed by its base-analogy and its relations. The resulting blends are visually interesting and some can be considered as unexpected.\n    ",
        "submission_date": "2017-06-27T00:00:00",
        "last_modified_date": "2019-02-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.09152",
        "title": "Generative Bridging Network in Neural Sequence Prediction",
        "authors": [
            "Wenhu Chen",
            "Guanlin Li",
            "Shuo Ren",
            "Shujie Liu",
            "Zhirui Zhang",
            "Mu Li",
            "Ming Zhou"
        ],
        "abstract": "In order to alleviate data sparsity and overfitting problems in maximum likelihood estimation (MLE) for sequence prediction tasks, we propose the Generative Bridging Network (GBN), in which a novel bridge module is introduced to assist the training of the sequence prediction model (the generator network). Unlike MLE directly maximizing the conditional likelihood, the bridge extends the point-wise ground truth to a bridge distribution conditioned on it, and the generator is optimized to minimize their KL-divergence. Three different GBNs, namely uniform GBN, language-model GBN and coaching GBN, are proposed to penalize confidence, enhance language smoothness and relieve learning burden. Experiments conducted on two recognized sequence prediction tasks (machine translation and abstractive text summarization) show that our proposed GBNs can yield significant improvements over strong baselines. Furthermore, by analyzing samples drawn from different bridges, expected influences on the generator are verified.\n    ",
        "submission_date": "2017-06-28T00:00:00",
        "last_modified_date": "2018-11-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.09278",
        "title": "Learning Knowledge Graph Embeddings with Type Regularizer",
        "authors": [
            "Bhushan Kotnis",
            "Vivi Nastase"
        ],
        "abstract": "Learning relations based on evidence from knowledge bases relies on processing the available relation instances. Many relations, however, have clear domain and range, which we hypothesize could help learn a better, more generalizing, model. We include such information in the RESCAL model in the form of a regularization factor added to the loss function that takes into account the types (categories) of the entities that appear as arguments to relations in the knowledge base. We note increased performance compared to the baseline model in terms of mean reciprocal rank and hits@N, N = 1, 3, 10. Furthermore, we discover scenarios that significantly impact the effectiveness of the type regularizer.\n    ",
        "submission_date": "2017-06-28T00:00:00",
        "last_modified_date": "2018-03-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.09347",
        "title": "Path planning for Robotic Mobile Fulfillment Systems",
        "authors": [
            "Marius Merschformann",
            "Lin Xie",
            "Daniel Erdmann"
        ],
        "abstract": "This paper presents a collection of path planning algorithms for real-time movement of multiple robots across a Robotic Mobile Fulfillment System (RMFS). Robots are assigned to move storage units to pickers at working stations instead of requiring pickers to go to the storage area. Path planning algorithms aim to find paths for the robots to fulfill the requests without collisions or deadlocks. The state-of-the-art path planning algorithms, including WHCA*, FAR, BCP, OD&ID and CBS, were adapted to suit path planning in RMFS and integrated within a simulation tool to guide the robots from their starting points to their destinations during the storage and retrieval processes. Ten different layouts with a variety of numbers of robots, floors, pods, stations and the sizes of storage areas were considered in the simulation study. Performance metrics of throughput, path length and search time were monitored. Simulation results demonstrate the best algorithm based on each performance metric.\n    ",
        "submission_date": "2017-06-28T00:00:00",
        "last_modified_date": "2018-11-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.09393",
        "title": "Default Logic and Bounded Treewidth",
        "authors": [
            "Johannes K. Fichte",
            "Markus Hecher",
            "Irina Schindler"
        ],
        "abstract": "In this paper, we study Reiter's propositional default logic when the treewidth of a certain graph representation (semi-primal graph) of the input theory is bounded. We establish a dynamic programming algorithm on tree decompositions that decides whether a theory has a consistent stable extension (Ext). Our algorithm can even be used to enumerate all generating defaults (ExtEnum) that lead to stable extensions.\n",
        "submission_date": "2017-06-28T00:00:00",
        "last_modified_date": "2017-12-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.09597",
        "title": "Path Integral Networks: End-to-End Differentiable Optimal Control",
        "authors": [
            "Masashi Okada",
            "Luca Rigazio",
            "Takenobu Aoshima"
        ],
        "abstract": "In this paper, we introduce Path Integral Networks (PI-Net), a recurrent network representation of the Path Integral optimal control algorithm. The network includes both system dynamics and cost models, used for optimal control based planning. PI-Net is fully differentiable, learning both dynamics and cost models end-to-end by back-propagation and stochastic gradient descent. Because of this, PI-Net can learn to plan. PI-Net has several advantages: it can generalize to unseen states thanks to planning, it can be applied to continuous control tasks, and it allows for a wide variety learning schemes, including imitation and reinforcement learning. Preliminary experiment results show that PI-Net, trained by imitation learning, can mimic control demonstrations for two simulated problems; a linear system and a pendulum swing-up problem. We also show that PI-Net is able to learn dynamics and cost models latent in the demonstrations.\n    ",
        "submission_date": "2017-06-29T00:00:00",
        "last_modified_date": "2017-06-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.09737",
        "title": "Indoor UAV scheduling with Restful Task Assignment Algorithm",
        "authors": [
            "Yohanes Khosiawan",
            "Izabela Nielsen"
        ],
        "abstract": "Research in UAV scheduling has obtained an emerging interest from scientists in the optimization field. When the scheduling itself has established a strong root since the 19th century, works on UAV scheduling in indoor environment has come forth in the latest decade. Several works on scheduling UAV operations in indoor (two and three dimensional) and outdoor environments are reported. In this paper, a further study on UAV scheduling in three dimensional indoor environment is investigated. Dealing with indoor environment\\textemdash where humans, UAVs, and other elements or infrastructures are likely to coexist in the same space\\textemdash draws attention towards the safety of the operations. In relation to the battery level, a preserved battery level leads to safer operations, promoting the UAV to have a decent remaining power level. A methodology which consists of a heuristic approach based on Restful Task Assignment Algorithm, incorporated with Particle Swarm Optimization Algorithm, is proposed. The motivation is to preserve the battery level throughout the operations, which promotes less possibility in having failed UAVs on duty. This methodology is tested with 54 benchmark datasets stressing on 4 different aspects: geographical distance, number of tasks, number of predecessors, and slack time. The test results and their characteristics in regard to the proposed methodology are discussed and presented.\n    ",
        "submission_date": "2017-06-29T00:00:00",
        "last_modified_date": "2017-06-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.09767",
        "title": "Speaker Identification in each of the Neutral and Shouted Talking Environments based on Gender-Dependent Approach Using SPHMMs",
        "authors": [
            "Ismail Shahin"
        ],
        "abstract": "It is well known that speaker identification performs extremely well in the neutral talking environments; however, the identification performance is declined sharply in the shouted talking environments. This work aims at proposing, implementing and testing a new approach to enhance the declined performance in the shouted talking environments. The new proposed approach is based on gender-dependent speaker identification using Suprasegmental Hidden Markov Models (SPHMMs) as classifiers. This proposed approach has been tested on two different and separate speech databases: our collected database and the Speech Under Simulated and Actual Stress (SUSAS) database. The results of this work show that gender-dependent speaker identification based on SPHMMs outperforms gender-independent speaker identification based on the same models and gender-dependent speaker identification based on Hidden Markov Models (HMMs) by about 6% and 8%, respectively. The results obtained based on the proposed approach are close to those obtained in subjective evaluation by human judges.\n    ",
        "submission_date": "2017-06-29T00:00:00",
        "last_modified_date": "2017-06-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.10036",
        "title": "Providing Effective Real-time Feedback in Simulation-based Surgical Training",
        "authors": [
            "Xingjun Ma",
            "Sudanthi Wijewickrema",
            "Yun Zhou",
            "Shuo Zhou",
            "Stephen O'Leary",
            "James Bailey"
        ],
        "abstract": "Virtual reality simulation is becoming popular as a training platform in surgical education. However, one important aspect of simulation-based surgical training that has not received much attention is the provision of automated real-time performance feedback to support the learning process. Performance feedback is actionable advice that improves novice behaviour. In simulation, automated feedback is typically extracted from prediction models trained using data mining techniques. Existing techniques suffer from either low effectiveness or low efficiency resulting in their inability to be used in real-time. In this paper, we propose a random forest based method that finds a balance between effectiveness and efficiency. Experimental results in a temporal bone surgery simulation show that the proposed method is able to extract highly effective feedback at a high level of efficiency.\n    ",
        "submission_date": "2017-06-30T00:00:00",
        "last_modified_date": "2017-06-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.10117",
        "title": "Restricted Causal Inference Algorithm",
        "authors": [
            "Mieczys\u0142aw A. K\u0142opotek"
        ],
        "abstract": "This paper proposes a new algorithm for recovery of belief network structure from data handling hidden variables. It consists essentially in an extension of the CI algorithm of Spirtes et al. by restricting the number of conditional dependencies checked up to k variables and in an extension of the original CI by additional steps transforming so called partial including path graph into a belief network. Its correctness is demonstrated.\n    ",
        "submission_date": "2017-06-30T00:00:00",
        "last_modified_date": "2017-06-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.10240",
        "title": "Bridging the Gap between Probabilistic and Deterministic Models: A Simulation Study on a Variational Bayes Predictive Coding Recurrent Neural Network Model",
        "authors": [
            "Ahmadreza Ahmadi",
            "Jun Tani"
        ],
        "abstract": "The current paper proposes a novel variational Bayes predictive coding RNN model, which can learn to generate fluctuated temporal patterns from exemplars. The model learns to maximize the lower bound of the weighted sum of the regularization and reconstruction error terms. We examined how this weighting can affect development of different types of information processing while learning fluctuated temporal patterns. Simulation results show that strong weighting of the reconstruction term causes the development of deterministic chaos for imitating the randomness observed in target sequences, while strong weighting of the regularization term causes the development of stochastic dynamics imitating probabilistic processes observed in targets. Moreover, results indicate that the most generalized learning emerges between these two extremes. The paper concludes with implications in terms of the underlying neuronal mechanisms for autism spectrum disorder and for free action.\n    ",
        "submission_date": "2017-06-30T00:00:00",
        "last_modified_date": "2017-09-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.00112",
        "title": "A study of existing Ontologies in the IoT-domain",
        "authors": [
            "Garvita Bajaj",
            "Rachit Agarwal",
            "Pushpendra Singh",
            "Nikolaos Georgantas",
            "Valerie Issarny"
        ],
        "abstract": "Several domains have adopted the increasing use of IoT-based devices to collect sensor data for generating abstractions and perceptions of the real world. This sensor data is multi-modal and heterogeneous in nature. This heterogeneity induces interoperability issues while developing cross-domain applications, thereby restricting the possibility of reusing sensor data to develop new applications. As a solution to this, semantic approaches have been proposed in the literature to tackle problems related to interoperability of sensor data. Several ontologies have been proposed to handle different aspects of IoT-based sensor data collection, ranging from discovering the IoT sensors for data collection to applying reasoning on the collected sensor data for drawing inferences. In this paper, we survey these existing semantic ontologies to provide an overview of the recent developments in this field. We highlight the fundamental ontological concepts (e.g., sensor-capabilities and context-awareness) required for an IoT-based application, and survey the existing ontologies which include these concepts. Based on our study, we also identify the shortcomings of currently available ontologies, which serves as a stepping stone to state the need for a common unified ontology for the IoT domain.\n    ",
        "submission_date": "2017-07-01T00:00:00",
        "last_modified_date": "2017-07-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.00228",
        "title": "Modifying Optimal SAT-based Approach to Multi-agent Path-finding Problem to Suboptimal Variants",
        "authors": [
            "Pavel Surynek",
            "Ariel Felner",
            "Roni Stern",
            "Eli Boyarski"
        ],
        "abstract": "In multi-agent path finding (MAPF) the task is to find non-conflicting paths for multiple agents. In this paper we focus on finding suboptimal solutions for MAPF for the sum-of-costs variant. Recently, a SAT-based approached was developed to solve this problem and proved beneficial in many cases when compared to other search-based solvers. In this paper, we present SAT-based unbounded- and bounded-suboptimal algorithms and compare them to relevant algorithms. Experimental results show that in many case the SAT-based solver significantly outperforms the search-based solvers.\n    ",
        "submission_date": "2017-07-02T00:00:00",
        "last_modified_date": "2017-07-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.00614",
        "title": "A Roadmap for the Development of the \"SP Machine\" for Artificial Intelligence",
        "authors": [
            "J Gerard Wolff"
        ],
        "abstract": "This paper describes a roadmap for the development of the \"SP Machine\", based on the \"SP Theory of Intelligence\" and its realisation in the \"SP Computer Model\". The SP Machine will be developed initially as a software virtual machine with high levels of parallel processing, hosted on a high-performance computer. The system should help users visualise knowledge structures and processing. Research is needed into how the system may discover low-level features in speech and in images. Strengths of the SP System in the processing of natural language may be augmented, in conjunction with the further development of the SP System's strengths in unsupervised learning. Strengths of the SP System in pattern recognition may be developed for computer vision. Work is needed on the representation of numbers and the performance of arithmetic processes. A computer model is needed of \"SP-Neural\", the version of the SP Theory expressed in terms of neurons and their inter-connections. The SP Machine has potential in many areas of application, several of which may be realised on short-to-medium timescales.\n    ",
        "submission_date": "2017-06-28T00:00:00",
        "last_modified_date": "2018-12-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.00617",
        "title": "Submodular Function Maximization for Group Elevator Scheduling",
        "authors": [
            "Srikumar Ramalingam",
            "Arvind U. Raghunathan",
            "Daniel Nikovski"
        ],
        "abstract": "We propose a novel approach for group elevator scheduling by formulating it as the maximization of submodular function under a matroid constraint. In particular, we propose to model the total waiting time of passengers using a quadratic Boolean function. The unary and pairwise terms in the function denote the waiting time for single and pairwise allocation of passengers to elevators, respectively. We show that this objective function is submodular. The matroid constraints ensure that every passenger is allocated to exactly one elevator. We use a greedy algorithm to maximize the submodular objective function, and derive provable guarantees on the optimality of the solution. We tested our algorithm using Elevate 8, a commercial-grade elevator simulator that allows simulation with a wide range of elevator settings. We achieve significant improvement over the existing algorithms.\n    ",
        "submission_date": "2017-06-28T00:00:00",
        "last_modified_date": "2017-06-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.00627",
        "title": "A Reverse Hex Solver",
        "authors": [
            "Kenny Young",
            "Ryan B. Hayward"
        ],
        "abstract": "We present Solrex,an automated solver for the game of Reverse ",
        "submission_date": "2017-04-26T00:00:00",
        "last_modified_date": "2017-04-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.00724",
        "title": "Efficient Probabilistic Performance Bounds for Inverse Reinforcement Learning",
        "authors": [
            "Daniel S. Brown",
            "Scott Niekum"
        ],
        "abstract": "In the field of reinforcement learning there has been recent progress towards safety and high-confidence bounds on policy performance. However, to our knowledge, no practical methods exist for determining high-confidence policy performance bounds in the inverse reinforcement learning setting---where the true reward function is unknown and only samples of expert behavior are given. We propose a sampling method based on Bayesian inverse reinforcement learning that uses demonstrations to determine practical high-confidence upper bounds on the $\\alpha$-worst-case difference in expected return between any evaluation policy and the optimal policy under the expert's unknown reward function. We evaluate our proposed bound on both a standard grid navigation task and a simulated driving task and achieve tighter and more accurate bounds than a feature count-based baseline. We also give examples of how our proposed bound can be utilized to perform risk-aware policy selection and risk-aware policy improvement. Because our proposed bound requires several orders of magnitude fewer demonstrations than existing high-confidence bounds, it is the first practical method that allows agents that learn from demonstration to express confidence in the quality of their learned policy.\n    ",
        "submission_date": "2017-07-03T00:00:00",
        "last_modified_date": "2018-06-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.00790",
        "title": "OPEB: Open Physical Environment Benchmark for Artificial Intelligence",
        "authors": [
            "Hamid Mirzaei",
            "Mona Fathollahi",
            "Tony Givargis"
        ],
        "abstract": "Artificial Intelligence methods to solve continuous- control tasks have made significant progress in recent years. However, these algorithms have important limitations and still need significant improvement to be used in industry and real- world applications. This means that this area is still in an active research phase. To involve a large number of research groups, standard benchmarks are needed to evaluate and compare proposed algorithms. In this paper, we propose a physical environment benchmark framework to facilitate collaborative research in this area by enabling different research groups to integrate their designed benchmarks in a unified cloud-based repository and also share their actual implemented benchmarks via the cloud. We demonstrate the proposed framework using an actual implementation of the classical mountain-car example and present the results obtained using a Reinforcement Learning algorithm.\n    ",
        "submission_date": "2017-07-04T00:00:00",
        "last_modified_date": "2017-07-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.00791",
        "title": "Visualizing the Consequences of Evidence in Bayesian Networks",
        "authors": [
            "Clifford Champion",
            "Charles Elkan"
        ],
        "abstract": "This paper addresses the challenge of viewing and navigating Bayesian networks as their structural size and complexity grow. Starting with a review of the state of the art of visualizing Bayesian networks, an area which has largely been passed over, we improve upon existing visualizations in three ways. First, we apply a disciplined approach to the graphic design of the basic elements of the Bayesian network. Second, we propose a technique for direct, visual comparison of posterior distributions resulting from alternative evidence sets. Third, we leverage a central mathematical tool in information theory, to assist the user in finding variables of interest in the network, and to reduce visual complexity where unimportant. We present our methods applied to two modestly large Bayesian networks constructed from real-world data sets. Results suggest the new techniques can be a useful tool for discovering information flow phenomena, and also for qualitative comparisons of different evidence configurations, especially in large probabilistic networks.\n    ",
        "submission_date": "2017-07-04T00:00:00",
        "last_modified_date": "2017-07-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.00936",
        "title": "Window-of-interest based Multi-objective Evolutionary Search for Satisficing Concepts",
        "authors": [
            "Eliran Farhi",
            "Amiram Moshaiov"
        ],
        "abstract": "The set-based concept approach has been suggested as a means to simultaneously explore different design concepts, which are meaningful sub-sets of the entire set of solutions. Previous efforts concerning the suggested approach focused on either revealing the global front (s-Pareto front), of all the concepts, or on finding the concepts' fronts, within a relaxation zone. In contrast, here the aim is to reveal which of the concepts have at least one solution with a performance vector within a pre-defined window-of-interest (WOI). This paper provides the rational for this new concept-based exploration problem, and suggests a WOI-based rather than Pareto-based multi-objective evolutionary algorithm. The proposed algorithm, which simultaneously explores different concepts, is tested using a recently suggested concept-based benchmarking approach. The numerical study of this paper shows that the algorithm can cope with various numerical difficulties in a simultaneous way, which outperforms a sequential exploration approach.\n    ",
        "submission_date": "2017-07-04T00:00:00",
        "last_modified_date": "2017-07-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.01067",
        "title": "ELF: An Extensive, Lightweight and Flexible Research Platform for Real-time Strategy Games",
        "authors": [
            "Yuandong Tian",
            "Qucheng Gong",
            "Wenling Shang",
            "Yuxin Wu",
            "C. Lawrence Zitnick"
        ],
        "abstract": "In this paper, we propose ELF, an Extensive, Lightweight and Flexible platform for fundamental reinforcement learning research. Using ELF, we implement a highly customizable real-time strategy (RTS) engine with three game environments (Mini-RTS, Capture the Flag and Tower Defense). Mini-RTS, as a miniature version of StarCraft, captures key game dynamics and runs at 40K frame-per-second (FPS) per core on a Macbook Pro notebook. When coupled with modern reinforcement learning methods, the system can train a full-game bot against built-in AIs end-to-end in one day with 6 CPUs and 1 GPU. In addition, our platform is flexible in terms of environment-agent communication topologies, choices of RL methods, changes in game parameters, and can host existing C/C++-based game environments like Arcade Learning Environment. Using ELF, we thoroughly explore training parameters and show that a network with Leaky ReLU and Batch Normalization coupled with long-horizon training and progressive curriculum beats the rule-based built-in AI more than $70\\%$ of the time in the full game of Mini-RTS. Strong performance is also achieved on the other two games. In game replays, we show our agents learn interesting strategies. ELF, along with its RL platform, is open-sourced at ",
        "submission_date": "2017-07-04T00:00:00",
        "last_modified_date": "2017-11-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.01068",
        "title": "Maintaining cooperation in complex social dilemmas using deep reinforcement learning",
        "authors": [
            "Adam Lerer",
            "Alexander Peysakhovich"
        ],
        "abstract": "Social dilemmas are situations where individuals face a temptation to increase their payoffs at a cost to total welfare. Building artificially intelligent agents that achieve good outcomes in these situations is important because many real world interactions include a tension between selfish interests and the welfare of others. We show how to modify modern reinforcement learning methods to construct agents that act in ways that are simple to understand, nice (begin by cooperating), provokable (try to avoid being exploited), and forgiving (try to return to mutual cooperation). We show both theoretically and experimentally that such agents can maintain cooperation in Markov social dilemmas. Our construction does not require training methods beyond a modification of self-play, thus if an environment is such that good strategies can be constructed in the zero-sum case (eg. Atari) then we can construct agents that solve social dilemmas in this environment.\n    ",
        "submission_date": "2017-07-04T00:00:00",
        "last_modified_date": "2018-03-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.01154",
        "title": "Interpretable & Explorable Approximations of Black Box Models",
        "authors": [
            "Himabindu Lakkaraju",
            "Ece Kamar",
            "Rich Caruana",
            "Jure Leskovec"
        ],
        "abstract": "We propose Black Box Explanations through Transparent Approximations (BETA), a novel model agnostic framework for explaining the behavior of any black-box classifier by simultaneously optimizing for fidelity to the original model and interpretability of the explanation. To this end, we develop a novel objective function which allows us to learn (with optimality guarantees), a small number of compact decision sets each of which explains the behavior of the black box model in unambiguous, well-defined regions of feature space. Furthermore, our framework also is capable of accepting user input when generating these approximations, thus allowing users to interactively explore how the black-box model behaves in different subspaces that are of interest to the user. To the best of our knowledge, this is the first approach which can produce global explanations of the behavior of any given black box model through joint optimization of unambiguity, fidelity, and interpretability, while also allowing users to explore model behavior based on their preferences. Experimental evaluation with real-world datasets and user studies demonstrates that our approach can generate highly compact, easy-to-understand, yet accurate approximations of various kinds of predictive models compared to state-of-the-art baselines.\n    ",
        "submission_date": "2017-07-04T00:00:00",
        "last_modified_date": "2017-07-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.01283",
        "title": "SADA: A General Framework to Support Robust Causation Discovery with Theoretical Guarantee",
        "authors": [
            "Ruichu Cai",
            "Zhenjie Zhang",
            "Zhifeng Hao"
        ],
        "abstract": "Causation discovery without manipulation is considered a crucial problem to a variety of applications. The state-of-the-art solutions are applicable only when large numbers of samples are available or the problem domain is sufficiently small. Motivated by the observations of the local sparsity properties on causal structures, we propose a general Split-and-Merge framework, named SADA, to enhance the scalability of a wide class of causation discovery algorithms. In SADA, the variables are partitioned into subsets, by finding causal cut on the sparse causal structure over the variables. By running mainstream causation discovery algorithms as basic causal solvers on the subproblems, complete causal structure can be reconstructed by combining the partial results. SADA benefits from the recursive division technique, since each small subproblem generates more accurate result under the same number of samples. We theoretically prove that SADA always reduces the scales of problems without sacrifice on accuracy, under the condition of local causal sparsity and reliable conditional independence tests. We also present sufficient condition to accuracy enhancement by SADA, even when the conditional independence tests are vulnerable. Extensive experiments on both simulated and real-world datasets verify the improvements on scalability and accuracy by applying SADA together with existing causation discovery algorithms.\n    ",
        "submission_date": "2017-07-05T00:00:00",
        "last_modified_date": "2017-07-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.01310",
        "title": "Learning to Design Games: Strategic Environments in Reinforcement Learning",
        "authors": [
            "Haifeng Zhang",
            "Jun Wang",
            "Zhiming Zhou",
            "Weinan Zhang",
            "Ying Wen",
            "Yong Yu",
            "Wenxin Li"
        ],
        "abstract": "In typical reinforcement learning (RL), the environment is assumed given and the goal of the learning is to identify an optimal policy for the agent taking actions through its interactions with the environment. In this paper, we extend this setting by considering the environment is not given, but controllable and learnable through its interaction with the agent at the same time. This extension is motivated by environment design scenarios in the real-world, including game design, shopping space design and traffic signal design. Theoretically, we find a dual Markov decision process (MDP) w.r.t. the environment to that w.r.t. the agent, and derive a policy gradient solution to optimizing the parametrized environment. Furthermore, discontinuous environments are addressed by a proposed general generative framework. Our experiments on a Maze game design task show the effectiveness of the proposed algorithms in generating diverse and challenging Mazes against various agent settings.\n    ",
        "submission_date": "2017-07-05T00:00:00",
        "last_modified_date": "2019-10-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.01415",
        "title": "Machine Learning, Deepest Learning: Statistical Data Assimilation Problems",
        "authors": [
            "Henry Abarbanel",
            "Paul Rozdeba",
            "Sasha Shirman"
        ],
        "abstract": "We formulate a strong equivalence between machine learning, artificial intelligence methods and the formulation of statistical data assimilation as used widely in physical and biological sciences. The correspondence is that layer number in the artificial network setting is the analog of time in the data assimilation setting. Within the discussion of this equivalence we show that adding more layers (making the network deeper) is analogous to adding temporal resolution in a data assimilation framework.\n",
        "submission_date": "2017-07-05T00:00:00",
        "last_modified_date": "2017-07-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.01423",
        "title": "Model enumeration in propositional circumscription via unsatisfiable core analysis",
        "authors": [
            "Mario Alviano"
        ],
        "abstract": "Many practical problems are characterized by a preference relation over admissible solutions, where preferred solutions are minimal in some sense. For example, a preferred diagnosis usually comprises a minimal set of reasons that is sufficient to cause the observed anomaly. Alternatively, a minimal correction subset comprises a minimal set of reasons whose deletion is sufficient to eliminate the observed anomaly. Circumscription formalizes such preference relations by associating propositional theories with minimal models. The resulting enumeration problem is addressed here by means of a new algorithm taking advantage of unsatisfiable core analysis. Empirical evidence of the efficiency of the algorithm is given by comparing the performance of the resulting solver, CIRCUMSCRIPTINO, with HCLASP, CAMUS MCS, LBX and MCSLS on the enumeration of minimal models for problems originating from practical applications.\n",
        "submission_date": "2017-07-05T00:00:00",
        "last_modified_date": "2017-07-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.01450",
        "title": "The Complex Negotiation Dialogue Game",
        "authors": [
            "Romain Laroche"
        ],
        "abstract": "This position paper formalises an abstract model for complex negotiation dialogue. This model is to be used for the benchmark of optimisation algorithms ranging from Reinforcement Learning to Stochastic Games, through Transfer Learning, One-Shot Learning or others.\n    ",
        "submission_date": "2017-07-05T00:00:00",
        "last_modified_date": "2017-07-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.01489",
        "title": "Creative Robot Dance with Variational Encoder",
        "authors": [
            "Agnese Augello",
            "Emanuele Cipolla",
            "Ignazio Infantino",
            "Adriano Manfre",
            "Giovanni Pilato",
            "Filippo Vella"
        ],
        "abstract": "What we appreciate in dance is the ability of people to sponta- neously improvise new movements and choreographies, sur- rendering to the music rhythm, being inspired by the cur- rent perceptions and sensations and by previous experiences, deeply stored in their memory. Like other human abilities, this, of course, is challenging to reproduce in an artificial entity such as a robot. Recent generations of anthropomor- phic robots, the so-called humanoids, however, exhibit more and more sophisticated skills and raised the interest in robotic communities to design and experiment systems devoted to automatic dance generation. In this work, we highlight the importance to model a computational creativity behavior in dancing robots to avoid a mere execution of preprogrammed dances. In particular, we exploit a deep learning approach that allows a robot to generate in real time new dancing move- ments according to to the listened music.\n    ",
        "submission_date": "2017-07-05T00:00:00",
        "last_modified_date": "2017-07-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.01727",
        "title": "Application of Fuzzy Assessing for Reliability Decision Making",
        "authors": [
            "Shoele Jamali",
            "Mehrdad J. Bani"
        ],
        "abstract": "This paper proposes a new fuzzy assessing procedure with application in management decision making. The proposed fuzzy approach build the membership functions for system characteristics of a standby repairable system. This method is used to extract a family of conventional crisp intervals from the fuzzy repairable system for the desired system characteristics. This can be determined with a set of nonlinear parametric programing using the membership functions. When system characteristics are governed by the membership functions, more information is provided for use by management, and because the redundant system is extended to the fuzzy environment, general repairable systems are represented more accurately and the analytic results are more useful for designers and practitioners. Also beside standby, active redundancy systems are used in many cases so this article has many practical instances. Different from other studies, our model provides, a good estimated value based on uncertain environments, a comparison discussion of using fuzzy theory and conventional method and also a comparison between parallel (active redundancy) and series system in fuzzy world when we have standby redundancy. When the membership function intervals cannot be inverted explicitly, system management or designers can specify the system characteristics of interest, perform numerical calculations, examine the corresponding {\\alpha}-cuts, and use this information to develop or improve system processes.\n    ",
        "submission_date": "2017-07-06T00:00:00",
        "last_modified_date": "2017-07-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.01891",
        "title": "Trust-PCL: An Off-Policy Trust Region Method for Continuous Control",
        "authors": [
            "Ofir Nachum",
            "Mohammad Norouzi",
            "Kelvin Xu",
            "Dale Schuurmans"
        ],
        "abstract": "Trust region methods, such as TRPO, are often used to stabilize policy optimization algorithms in reinforcement learning (RL). While current trust region strategies are effective for continuous control, they typically require a prohibitively large amount of on-policy interaction with the environment. To address this problem, we propose an off-policy trust region method, Trust-PCL. The algorithm is the result of observing that the optimal policy and state values of a maximum reward objective with a relative-entropy regularizer satisfy a set of multi-step pathwise consistencies along any path. Thus, Trust-PCL is able to maintain optimization stability while exploiting off-policy data to improve sample efficiency. When evaluated on a number of continuous control tasks, Trust-PCL improves the solution quality and sample efficiency of TRPO.\n    ",
        "submission_date": "2017-07-06T00:00:00",
        "last_modified_date": "2018-02-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.01959",
        "title": "Well-Founded Operators for Normal Hybrid MKNF Knowledge Bases",
        "authors": [
            "Jianmin Ji",
            "Fangfang Liu",
            "Jia-Huai You"
        ],
        "abstract": "Hybrid MKNF knowledge bases have been considered one of the dominant approaches to combining open world ontology languages with closed world rule-based languages. Currently, the only known inference methods are based on the approach of guess-and-verify, while most modern SAT/ASP solvers are built under the DPLL architecture. The central impediment here is that it is not clear what constitutes a constraint propagator, a key component employed in any DPLL-based solver. In this paper, we address this problem by formulating the notion of unfounded sets for nondisjunctive hybrid MKNF knowledge bases, based on which we propose and study two new well-founded operators. We show that by employing a well-founded operator as a constraint propagator, a sound and complete DPLL search engine can be readily defined. We compare our approach with the operator based on the alternating fixpoint construction by Knorr et al [2011] and show that, when applied to arbitrary partial partitions, the new well-founded operators not only propagate more truth values but also circumvent the non-converging behavior of the latter. In addition, we study the possibility of simplifying a given hybrid MKNF knowledge base by employing a well-founded operator, and show that, out of the two operators proposed in this paper, the weaker one can be applied for this purpose and the stronger one cannot. These observations are useful in implementing a grounder for hybrid MKNF knowledge bases, which can be applied before the computation of MKNF models.\n",
        "submission_date": "2017-07-06T00:00:00",
        "last_modified_date": "2017-07-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.02286",
        "title": "Emergence of Locomotion Behaviours in Rich Environments",
        "authors": [
            "Nicolas Heess",
            "Dhruva TB",
            "Srinivasan Sriram",
            "Jay Lemmon",
            "Josh Merel",
            "Greg Wayne",
            "Yuval Tassa",
            "Tom Erez",
            "Ziyu Wang",
            "S. M. Ali Eslami",
            "Martin Riedmiller",
            "David Silver"
        ],
        "abstract": "The reinforcement learning paradigm allows, in principle, for complex behaviours to be learned directly from simple reward signals. In practice, however, it is common to carefully hand-design the reward function to encourage a particular solution, or to derive it from demonstration data. In this paper explore how a rich environment can help to promote the learning of complex behavior. Specifically, we train agents in diverse environmental contexts, and find that this encourages the emergence of robust behaviours that perform well across a suite of tasks. We demonstrate this principle for locomotion -- behaviours that are known for their sensitivity to the choice of reward. We train several simulated bodies on a diverse set of challenging terrains and obstacles, using a simple reward function based on forward progress. Using a novel scalable variant of policy gradient reinforcement learning, our agents learn to run, jump, crouch and turn as required by the environment without explicit reward-based guidance. A visual depiction of highlights of the learned behavior can be viewed following ",
        "submission_date": "2017-07-07T00:00:00",
        "last_modified_date": "2017-07-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.02292",
        "title": "Measuring Relations Between Concepts In Conceptual Spaces",
        "authors": [
            "Lucas Bechberger",
            "Kai-Uwe K\u00fchnberger"
        ],
        "abstract": "The highly influential framework of conceptual spaces provides a geometric way of representing knowledge. Instances are represented by points in a high-dimensional space and concepts are represented by regions in this space. Our recent mathematical formalization of this framework is capable of representing correlations between different domains in a geometric way. In this paper, we extend our formalization by providing quantitative mathematical definitions for the notions of concept size, subsethood, implication, similarity, and betweenness. This considerably increases the representational power of our formalization by introducing measurable ways of describing relations between concepts.\n    ",
        "submission_date": "2017-07-07T00:00:00",
        "last_modified_date": "2017-12-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.02363",
        "title": "Towards Zero-Shot Frame Semantic Parsing for Domain Scaling",
        "authors": [
            "Ankur Bapna",
            "Gokhan Tur",
            "Dilek Hakkani-Tur",
            "Larry Heck"
        ],
        "abstract": "State-of-the-art slot filling models for goal-oriented human/machine conversational language understanding systems rely on deep learning methods. While multi-task training of such models alleviates the need for large in-domain annotated datasets, bootstrapping a semantic parsing model for a new domain using only the semantic frame, such as the back-end API or knowledge graph schema, is still one of the holy grail tasks of language understanding for dialogue systems. This paper proposes a deep learning based approach that can utilize only the slot description in context without the need for any labeled or unlabeled in-domain examples, to quickly bootstrap a new domain. The main idea of this paper is to leverage the encoding of the slot names and descriptions within a multi-task deep learned slot filling model, to implicitly align slots across domains. The proposed approach is promising for solving the domain scaling problem and eliminating the need for any manually annotated data or explicit schema alignment. Furthermore, our experiments on multiple domains show that this approach results in significantly better slot-filling performance when compared to using only in-domain data, especially in the low data regime.\n    ",
        "submission_date": "2017-07-07T00:00:00",
        "last_modified_date": "2017-07-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.02515",
        "title": "A Fast Integrated Planning and Control Framework for Autonomous Driving via Imitation Learning",
        "authors": [
            "Liting Sun",
            "Cheng Peng",
            "Wei Zhan",
            "Masayoshi Tomizuka"
        ],
        "abstract": "For safe and efficient planning and control in autonomous driving, we need a driving policy which can achieve desirable driving quality in long-term horizon with guaranteed safety and feasibility. Optimization-based approaches, such as Model Predictive Control (MPC), can provide such optimal policies, but their computational complexity is generally unacceptable for real-time implementation. To address this problem, we propose a fast integrated planning and control framework that combines learning- and optimization-based approaches in a two-layer hierarchical structure. The first layer, defined as the \"policy layer\", is established by a neural network which learns the long-term optimal driving policy generated by MPC. The second layer, called the \"execution layer\", is a short-term optimization-based controller that tracks the reference trajecotries given by the \"policy layer\" with guaranteed short-term safety and feasibility. Moreover, with efficient and highly-representative features, a small-size neural network is sufficient in the \"policy layer\" to handle many complicated driving scenarios. This renders online imitation learning with Dataset Aggregation (DAgger) so that the performance of the \"policy layer\" can be improved rapidly and continuously online. Several exampled driving scenarios are demonstrated to verify the effectiveness and efficiency of the proposed framework.\n    ",
        "submission_date": "2017-07-09T00:00:00",
        "last_modified_date": "2017-07-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.02729",
        "title": "Best-Effort Inductive Logic Programming via Fine-grained Cost-based Hypothesis Generation",
        "authors": [
            "Peter Sch\u00fcller",
            "Mishal Benz"
        ],
        "abstract": "We describe the Inspire system which participated in the first competition on Inductive Logic Programming (ILP). Inspire is based on Answer Set Programming (ASP). The distinguishing feature of Inspire is an ASP encoding for hypothesis space generation: given a set of facts representing the mode bias, and a set of cost configuration parameters, each answer set of this encoding represents a single rule that is considered for finding a hypothesis that entails the given examples. Compared with state-of-the-art methods that use the length of the rule body as a metric for rule complexity, our approach permits a much more fine-grained specification of the shape of hypothesis candidate rules. The Inspire system iteratively increases the rule cost limit and thereby increases the search space until it finds a suitable hypothesis. The system searches for a hypothesis that entails a single example at a time, utilizing an ASP encoding derived from the encoding used in XHAIL. We perform experiments with the development and test set of the ILP competition. For comparison we also adapted the ILASP system to process competition instances. Experimental results show that the cost parameters for the hypothesis search space are an important factor for finding hypotheses to competition instances within tight resource bounds.\n    ",
        "submission_date": "2017-07-10T00:00:00",
        "last_modified_date": "2018-02-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.03069",
        "title": "Lexicographic choice functions",
        "authors": [
            "Arthur Van Camp",
            "Gert de Cooman",
            "Enrique Miranda"
        ],
        "abstract": "We investigate a generalisation of the coherent choice functions considered by Seidenfeld et al. (2010), by sticking to the convexity axiom but imposing no Archimedeanity condition. We define our choice functions on vector spaces of options, which allows us to incorporate as special cases both Seidenfeld et al.'s (2010) choice functions on horse lotteries and sets of desirable gambles (Quaeghebeur, 2014), and to investigate their connections. We show that choice functions based on sets of desirable options (gambles) satisfy Seidenfeld's convexity axiom only for very particular types of sets of desirable options, which are in a one-to-one relationship with the lexicographic probabilities. We call them lexicographic choice functions. Finally, we prove that these choice functions can be used to determine the most conservative convex choice function associated with a given binary relation.\n    ",
        "submission_date": "2017-07-10T00:00:00",
        "last_modified_date": "2017-07-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.03098",
        "title": "An Optimal Bayesian Network Based Solution Scheme for the Constrained Stochastic On-line Equi-Partitioning Problem",
        "authors": [
            "Sondre Glimsdal",
            "Ole-Christoffer Granmo"
        ],
        "abstract": "A number of intriguing decision scenarios revolve around partitioning a collection of objects to optimize some application specific objective function. This problem is generally referred to as the Object Partitioning Problem (OPP) and is known to be NP-hard. We here consider a particularly challenging version of OPP, namely, the Stochastic On-line Equi-Partitioning Problem (SO-EPP). In SO-EPP, the target partitioning is unknown and has to be inferred purely from observing an on-line sequence of object pairs. The paired objects belong to the same partition with probability $p$ and to different partitions with probability $1-p$, with $p$ also being unknown. As an additional complication, the partitions are required to be of equal cardinality. Previously, only sub-optimal solution strategies have been proposed for SO- EPP. In this paper, we propose the first optimal solution strategy. In brief, the scheme that we propose, BN-EPP, is founded on a Bayesian network representation of SO-EPP problems. Based on probabilistic reasoning, we are not only able to infer the underlying object partitioning with optimal accuracy. We are also able to simultaneously infer $p$, allowing us to accelerate learning as object pairs arrive. Furthermore, our scheme is the first to support arbitrary constraints on the partitioning (Constrained SO-EPP). Being optimal, BN-EPP provides superior performance compared to existing solution schemes. We additionally introduce Walk-BN-EPP, a novel WalkSAT inspired algorithm for solving large scale BN-EPP problems. Finally, we provide a BN-EPP based solution to the problem of order picking, a representative real-life application of BN-EPP.\n    ",
        "submission_date": "2017-07-11T00:00:00",
        "last_modified_date": "2017-07-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.03141",
        "title": "A Simple Neural Attentive Meta-Learner",
        "authors": [
            "Nikhil Mishra",
            "Mostafa Rohaninejad",
            "Xi Chen",
            "Pieter Abbeel"
        ],
        "abstract": "Deep neural networks excel in regimes with large amounts of data, but tend to struggle when data is scarce or when they need to adapt quickly to changes in the task. In response, recent work in meta-learning proposes training a meta-learner on a distribution of similar tasks, in the hopes of generalization to novel but related tasks by learning a high-level strategy that captures the essence of the problem it is asked to solve. However, many recent meta-learning approaches are extensively hand-designed, either using architectures specialized to a particular application, or hard-coding algorithmic components that constrain how the meta-learner solves the task. We propose a class of simple and generic meta-learner architectures that use a novel combination of temporal convolutions and soft attention; the former to aggregate information from past experience and the latter to pinpoint specific pieces of information. In the most extensive set of meta-learning experiments to date, we evaluate the resulting Simple Neural AttentIve Learner (or SNAIL) on several heavily-benchmarked tasks. On all tasks, in both supervised and reinforcement learning, SNAIL attains state-of-the-art performance by significant margins.\n    ",
        "submission_date": "2017-07-11T00:00:00",
        "last_modified_date": "2018-02-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.03184",
        "title": "A Survey on Resilient Machine Learning",
        "authors": [
            "Atul Kumar",
            "Sameep Mehta"
        ],
        "abstract": "Machine learning based system are increasingly being used for sensitive tasks such as security surveillance, guiding autonomous vehicle, taking investment decisions, detecting and blocking network intrusion and malware etc. However, recent research has shown that machine learning models are venerable to attacks by adversaries at all phases of machine learning (eg, training data collection, training, operation). All model classes of machine learning systems can be misled by providing carefully crafted inputs making them wrongly classify inputs. Maliciously created input samples can affect the learning process of a ML system by either slowing down the learning process, or affecting the performance of the learned mode, or causing the system make error(s) only in attacker's planned scenario. Because of these developments, understanding security of machine learning algorithms and systems is emerging as an important research area among computer security and machine learning researchers and practitioners. We present a survey of this emerging area in machine learning.\n    ",
        "submission_date": "2017-07-11T00:00:00",
        "last_modified_date": "2017-07-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.03191",
        "title": "Towards an automated method based on Iterated Local Search optimization for tuning the parameters of Support Vector Machines",
        "authors": [
            "Sergio Consoli",
            "Jacek Kustra",
            "Pieter Vos",
            "Monique Hendriks",
            "Dimitrios Mavroeidis"
        ],
        "abstract": "We provide preliminary details and formulation of an optimization strategy under current development that is able to automatically tune the parameters of a Support Vector Machine over new datasets. The optimization strategy is a heuristic based on Iterated Local Search, a modification of classic hill climbing which iterates calls to a local search routine.\n    ",
        "submission_date": "2017-07-11T00:00:00",
        "last_modified_date": "2017-07-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.03232",
        "title": "Deductive and Analogical Reasoning on a Semantically Embedded Knowledge Graph",
        "authors": [
            "Douglas Summers-Stay"
        ],
        "abstract": "Representing knowledge as high-dimensional vectors in a continuous semantic vector space can help overcome the brittleness and incompleteness of traditional knowledge bases. We present a method for performing deductive reasoning directly in such a vector space, combining analogy, association, and deduction in a straightforward way at each step in a chain of reasoning, drawing on knowledge from diverse sources and ontologies.\n    ",
        "submission_date": "2017-07-11T00:00:00",
        "last_modified_date": "2017-07-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.03300",
        "title": "The Intentional Unintentional Agent: Learning to Solve Many Continuous Control Tasks Simultaneously",
        "authors": [
            "Serkan Cabi",
            "Sergio G\u00f3mez Colmenarejo",
            "Matthew W. Hoffman",
            "Misha Denil",
            "Ziyu Wang",
            "Nando de Freitas"
        ],
        "abstract": "This paper introduces the Intentional Unintentional (IU) agent. This agent endows the deep deterministic policy gradients (DDPG) agent for continuous control with the ability to solve several tasks simultaneously. Learning to solve many tasks simultaneously has been a long-standing, core goal of artificial intelligence, inspired by infant development and motivated by the desire to build flexible robot manipulators capable of many diverse behaviours. We show that the IU agent not only learns to solve many tasks simultaneously but it also learns faster than agents that target a single task at-a-time. In some cases, where the single task DDPG method completely fails, the IU agent successfully solves the task. To demonstrate this, we build a playroom environment using the MuJoCo physics engine, and introduce a grounded formal language to automatically generate tasks.\n    ",
        "submission_date": "2017-07-11T00:00:00",
        "last_modified_date": "2017-07-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.03311",
        "title": "Similarity Search Over Graphs Using Localized Spectral Analysis",
        "authors": [
            "Yariv Aizenbud",
            "Amir Averbuch",
            "Gil Shabat",
            "Guy Ziv"
        ],
        "abstract": "This paper provides a new similarity detection algorithm. Given an input set of multi-dimensional data points, where each data point is assumed to be multi-dimensional, and an additional reference data point for similarity finding, the algorithm uses kernel method that embeds the data points into a low dimensional manifold. Unlike other kernel methods, which consider the entire data for the embedding, our method selects a specific set of kernel eigenvectors. The eigenvectors are chosen to separate between the data points and the reference data point so that similar data points can be easily identified as being distinct from most of the members in the dataset.\n    ",
        "submission_date": "2017-07-11T00:00:00",
        "last_modified_date": "2017-07-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.03333",
        "title": "Automated Game Design Learning",
        "authors": [
            "Joseph C Osborn",
            "Adam Summerville",
            "Michael Mateas"
        ],
        "abstract": "While general game playing is an active field of research, the learning of game design has tended to be either a secondary goal of such research or it has been solely the domain of humans. We propose a field of research, Automated Game Design Learning (AGDL), with the direct purpose of learning game designs directly through interaction with games in the mode that most people experience games: via play. We detail existing work that touches the edges of this field, describe current successful projects in AGDL and the theoretical foundations that enable them, point to promising applications enabled by AGDL, and discuss next steps for this exciting area of study. The key moves of AGDL are to use game programs as the ultimate source of truth about their own design, and to make these design properties available to other systems and avenues of inquiry.\n    ",
        "submission_date": "2017-07-11T00:00:00",
        "last_modified_date": "2017-07-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.03336",
        "title": "CHARDA: Causal Hybrid Automata Recovery via Dynamic Analysis",
        "authors": [
            "Adam Summerville",
            "Joseph Osborn",
            "Michael Mateas"
        ],
        "abstract": "We propose and evaluate a new technique for learning hybrid automata automatically by observing the runtime behavior of a dynamical system. Working from a sequence of continuous state values and predicates about the environment, CHARDA recovers the distinct dynamic modes, learns a model for each mode from a given set of templates, and postulates causal guard conditions which trigger transitions between modes. Our main contribution is the use of information-theoretic measures (1)~as a cost function for data segmentation and model selection to penalize over-fitting and (2)~to determine the likely causes of each transition. CHARDA is easily extended with different classes of model templates, fitting methods, or predicates. In our experiments on a complex videogame character, CHARDA successfully discovers a reasonable over-approximation of the character's true behaviors. Our results also compare favorably against recent work in automatically learning probabilistic timed automata in an aircraft domain: CHARDA exactly learns the modes of these simpler automata.\n    ",
        "submission_date": "2017-07-11T00:00:00",
        "last_modified_date": "2017-07-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.03377",
        "title": "Learning like humans with Deep Symbolic Networks",
        "authors": [
            "Qunzhi Zhang",
            "Didier Sornette"
        ],
        "abstract": "We introduce the Deep Symbolic Network (DSN) model, which aims at becoming the white-box version of Deep Neural Networks (DNN). The DSN model provides a simple, universal yet powerful structure, similar to DNN, to represent any knowledge of the world, which is transparent to humans. The conjecture behind the DSN model is that any type of real world objects sharing enough common features are mapped into human brains as a symbol. Those symbols are connected by links, representing the composition, correlation, causality, or other relationships between them, forming a deep, hierarchical symbolic network structure. Powered by such a structure, the DSN model is expected to learn like humans, because of its unique characteristics. First, it is universal, using the same structure to store any knowledge. Second, it can learn symbols from the world and construct the deep symbolic networks automatically, by utilizing the fact that real world objects have been naturally separated by singularities. Third, it is symbolic, with the capacity of performing causal deduction and generalization. Fourth, the symbols and the links between them are transparent to us, and thus we will know what it has learned or not - which is the key for the security of an AI system. Fifth, its transparency enables it to learn with relatively small data. Sixth, its knowledge can be accumulated. Last but not least, it is more friendly to unsupervised learning than DNN. We present the details of the model, the algorithm powering its automatic learning ability, and describe its usefulness in different use cases. The purpose of this paper is to generate broad interest to develop it within an open source project centered on the Deep Symbolic Network (DSN) model towards the development of general AI.\n    ",
        "submission_date": "2017-07-11T00:00:00",
        "last_modified_date": "2017-07-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.03471",
        "title": "Proceedings of the 2017 AdKDD & TargetAd Workshop",
        "authors": [
            "Abraham Bagherjeiran",
            "Nemanja Djuric",
            "Mihajlo Grbovic",
            "Kuang-Chih Lee",
            "Kun Liu",
            "Vladan Radosavljevic",
            "Suju Rajan"
        ],
        "abstract": "Proceedings of the 2017 AdKDD and TargetAd Workshop held in conjunction with the 23rd ACM SIGKDD Conference on Knowledge Discovery and Data Mining Halifax, Nova Scotia, Canada.\n    ",
        "submission_date": "2017-07-11T00:00:00",
        "last_modified_date": "2017-07-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.03497",
        "title": "Value Prediction Network",
        "authors": [
            "Junhyuk Oh",
            "Satinder Singh",
            "Honglak Lee"
        ],
        "abstract": "This paper proposes a novel deep reinforcement learning (RL) architecture, called Value Prediction Network (VPN), which integrates model-free and model-based RL methods into a single neural network. In contrast to typical model-based RL methods, VPN learns a dynamics model whose abstract states are trained to make option-conditional predictions of future values (discounted sum of rewards) rather than of future observations. Our experimental results show that VPN has several advantages over both model-free and model-based baselines in a stochastic environment where careful planning is required but building an accurate observation-prediction model is difficult. Furthermore, VPN outperforms Deep Q-Network (DQN) on several Atari games even with short-lookahead planning, demonstrating its potential as a new way of learning a good state representation.\n    ",
        "submission_date": "2017-07-11T00:00:00",
        "last_modified_date": "2017-11-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.03602",
        "title": "Using RDF Summary Graph For Keyword-based Semantic Searches",
        "authors": [
            "Serkan Ayvaz",
            "Mehmet Aydar"
        ],
        "abstract": "The Semantic Web began to emerge as its standards and technologies developed rapidly in the recent years. The continuing development of Semantic Web technologies has facilitated publishing explicit semantics with data on the Web in RDF data model. This study proposes a semantic search framework to support efficient keyword-based semantic search on RDF data utilizing near neighbor explorations. The framework augments the search results with the resources in close proximity by utilizing the entity type semantics. Along with the search results, the system generates a relevance confidence score measuring the inferred semantic relatedness of returned entities based on the degree of similarity. Furthermore, the evaluations assessing the effectiveness of the framework and the accuracy of the results are presented.\n    ",
        "submission_date": "2017-07-12T00:00:00",
        "last_modified_date": "2017-07-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.03739",
        "title": "Conflict Analysis for Pythagorean Fuzzy Information Systems with Group Decision Making",
        "authors": [
            "Guangming Lang"
        ],
        "abstract": "Pythagorean fuzzy sets provide stronger ability than intuitionistic fuzzy sets to model uncertainty information and knowledge, but little effort has been paid to conflict analysis of Pythagorean fuzzy information systems. In this paper, we present three types of positive, central, and negative alliances with different thresholds, and employ examples to illustrate how to construct the positive, central, and negative alliances. Then we study conflict analysis of Pythagorean fuzzy information systems based on Bayesian minimum risk theory. Finally, we investigate group conflict analysis of Pythagorean fuzzy information systems based on Bayesian minimum risk theory.\n    ",
        "submission_date": "2017-07-12T00:00:00",
        "last_modified_date": "2017-07-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.03743",
        "title": "Learning Macromanagement in StarCraft from Replays using Deep Learning",
        "authors": [
            "Niels Justesen",
            "Sebastian Risi"
        ],
        "abstract": "The real-time strategy game StarCraft has proven to be a challenging environment for artificial intelligence techniques, and as a result, current state-of-the-art solutions consist of numerous hand-crafted modules. In this paper, we show how macromanagement decisions in StarCraft can be learned directly from game replays using deep learning. Neural networks are trained on 789,571 state-action pairs extracted from 2,005 replays of highly skilled players, achieving top-1 and top-3 error rates of 54.6% and 22.9% in predicting the next build action. By integrating the trained network into UAlbertaBot, an open source StarCraft bot, the system can significantly outperform the game's built-in Terran bot, and play competitively against UAlbertaBot with a fixed rush strategy. To our knowledge, this is the first time macromanagement tasks are learned directly from replays in StarCraft. While the best hand-crafted strategies are still the state-of-the-art, the deep network approach is able to express a wide range of different strategies and thus improving the network's performance further with deep reinforcement learning is an immediately promising avenue for future research. Ultimately this approach could lead to strong StarCraft bots that are less reliant on hard-coded strategies.\n    ",
        "submission_date": "2017-07-12T00:00:00",
        "last_modified_date": "2017-07-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.03744",
        "title": "P-Tree Programming",
        "authors": [
            "Christian Oesch"
        ],
        "abstract": "We propose a novel method for automatic program synthesis. P-Tree Programming represents the program search space through a single probabilistic prototype tree. From this prototype tree we form program instances which we evaluate on a given problem. The error values from the evaluations are propagated through the prototype tree. We use them to update the probability distributions that determine the symbol choices of further instances. The iterative method is applied to several symbolic regression benchmarks from the literature. It outperforms standard Genetic Programming to a large extend. Furthermore, it relies on a concise set of parameters which are held constant for all problems. The algorithm can be employed for most of the typical computational intelligence tasks such as classification, automatic program induction, and symbolic regression.\n    ",
        "submission_date": "2017-07-12T00:00:00",
        "last_modified_date": "2017-07-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.03865",
        "title": "Mechanics Automatically Recognized via Interactive Observation: Jumping",
        "authors": [
            "Adam Summerville",
            "Joseph C. Osborn",
            "Christoffer Holmg\u00e5rd",
            "Daniel W. Zhang"
        ],
        "abstract": "Jumping has been an important mechanic since its introduction in Donkey Kong. It has taken a variety of forms and shown up in numerous games, with each jump having a different feel. In this paper, we use a modified Nintendo Entertainment System (NES) emulator to semi-automatically run experiments on a large subset (30%) of NES platform games. We use these experiments to build models of jumps from different developers, series, and games across the history of the console. We then examine these models to gain insights into different forms of jumping and their associated feel.\n    ",
        "submission_date": "2017-07-12T00:00:00",
        "last_modified_date": "2017-07-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.03872",
        "title": "Independence, Conditionality and Structure of Dempster-Shafer Belief Functions",
        "authors": [
            "Mieczys\u0142aw A. K\u0142opotek"
        ],
        "abstract": "Several approaches of structuring (factorization, decomposition) of Dempster-Shafer joint belief functions from literature are reviewed with special emphasis on their capability to capture independence from the point of view of the claim that belief functions generalize bayes notion of probability.\n",
        "submission_date": "2017-07-12T00:00:00",
        "last_modified_date": "2017-07-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.03881",
        "title": "Identification and Interpretation of Belief Structure in Dempster-Shafer Theory",
        "authors": [
            "Mieczys\u0142aw A. K\u0142opotek"
        ],
        "abstract": "Mathematical Theory of Evidence called also Dempster-Shafer Theory (DST) is known as a foundation for reasoning when knowledge is expressed at various levels of detail. Though much research effort has been committed to this theory since its foundation, many questions remain open. One of the most important open questions seems to be the relationship between frequencies and the Mathematical Theory of Evidence. The theory is blamed to leave frequencies outside (or aside of) its framework. The seriousness of this accusation is obvious: (1) no experiment may be run to compare the performance of DST-based models of real world processes against real world data, (2) data may not serve as foundation for construction of an appropriate belief model.\n",
        "submission_date": "2017-07-12T00:00:00",
        "last_modified_date": "2017-07-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.03886",
        "title": "A Formal Framework to Characterize Interpretability of Procedures",
        "authors": [
            "Amit Dhurandhar",
            "Vijay Iyengar",
            "Ronny Luss",
            "Karthikeyan Shanmugam"
        ],
        "abstract": "We provide a novel notion of what it means to be interpretable, looking past the usual association with human understanding. Our key insight is that interpretability is not an absolute concept and so we define it relative to a target model, which may or may not be a human. We define a framework that allows for comparing interpretable procedures by linking it to important practical aspects such as accuracy and robustness. We characterize many of the current state-of-the-art interpretable methods in our framework portraying its general applicability.\n    ",
        "submission_date": "2017-07-12T00:00:00",
        "last_modified_date": "2017-07-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.03902",
        "title": "Autoencoder-augmented Neuroevolution for Visual Doom Playing",
        "authors": [
            "Samuel Alvernaz",
            "Julian Togelius"
        ],
        "abstract": "Neuroevolution has proven effective at many reinforcement learning tasks, but does not seem to scale well to high-dimensional controller representations, which are needed for tasks where the input is raw pixel data. We propose a novel method where we train an autoencoder to create a comparatively low-dimensional representation of the environment observation, and then use CMA-ES to train neural network controllers acting on this input data. As the behavior of the agent changes the nature of the input data, the autoencoder training progresses throughout evolution. We test this method in the VizDoom environment built on the classic FPS Doom, where it performs well on a health-pack gathering task.\n    ",
        "submission_date": "2017-07-12T00:00:00",
        "last_modified_date": "2017-07-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.03908",
        "title": "Automatic Mapping of NES Games with Mappy",
        "authors": [
            "Joseph C. Osborn",
            "Adam Summerville",
            "Michael Mateas"
        ],
        "abstract": "Game maps are useful for human players, general-game-playing agents, and data-driven procedural content generation. These maps are generally made by hand-assembling manually-created screenshots of game levels. Besides being tedious and error-prone, this approach requires additional effort for each new game and level to be mapped. The results can still be hard for humans or computational systems to make use of, privileging visual appearance over semantic information. We describe a software system, Mappy, that produces a good approximation of a linked map of rooms given a Nintendo Entertainment System game program and a sequence of button inputs exploring its world. In addition to visual maps, Mappy outputs grids of tiles (and how they change over time), positions of non-tile objects, clusters of similar rooms that might in fact be the same room, and a set of links between these rooms. We believe this is a necessary step towards developing larger corpora of high-quality semantically-annotated maps for PCG via machine learning and other applications.\n    ",
        "submission_date": "2017-07-12T00:00:00",
        "last_modified_date": "2017-07-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.03979",
        "title": "A Brief Study of In-Domain Transfer and Learning from Fewer Samples using A Few Simple Priors",
        "authors": [
            "Marc Pickett",
            "Ayush Sekhari",
            "James Davidson"
        ],
        "abstract": "Domain knowledge can often be encoded in the structure of a network, such as convolutional layers for vision, which has been shown to increase generalization and decrease sample complexity, or the number of samples required for successful learning. In this study, we ask whether sample complexity can be reduced for systems where the structure of the domain is unknown beforehand, and the structure and parameters must both be learned from the data. We show that sample complexity reduction through learning structure is possible for at least two simple cases. In studying these cases, we also gain insight into how this might be done for more complex domains.\n    ",
        "submission_date": "2017-07-13T00:00:00",
        "last_modified_date": "2017-07-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.04016",
        "title": "Dependency Injection for Programming by Optimization",
        "authors": [
            "Zoltan A. Kocsis",
            "Jerry Swan"
        ],
        "abstract": "Programming by Optimization tools perform automatic software configuration according to the specification supplied by a software developer. Developers specify design spaces for program components, and the onerous task of determining which configuration best suits a given use case is determined using automated analysis tools and optimization heuristics. However, in current approaches to Programming by Optimization, design space specification and exploration relies on external configuration algorithms, executable wrappers and fragile, preprocessed programming language extensions.\n",
        "submission_date": "2017-07-13T00:00:00",
        "last_modified_date": "2017-07-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.04027",
        "title": "Constraints, Lazy Constraints, or Propagators in ASP Solving: An Empirical Analysis",
        "authors": [
            "Bernardo Cuteri",
            "Carmine Dodaro",
            "Francesco Ricca",
            "Peter Sch\u00fcller"
        ],
        "abstract": "Answer Set Programming (ASP) is a well-established declarative paradigm. One of the successes of ASP is the availability of efficient systems. State-of-the-art systems are based on the ground+solve approach. In some applications this approach is infeasible because the grounding of one or few constraints is expensive. In this paper, we systematically compare alternative strategies to avoid the instantiation of problematic constraints, that are based on custom extensions of the solver. Results on real and synthetic benchmarks highlight some strengths and weaknesses of the different strategies. (Under consideration for acceptance in TPLP, ICLP 2017 Special Issue.)\n    ",
        "submission_date": "2017-07-13T00:00:00",
        "last_modified_date": "2017-07-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.04053",
        "title": "Clingo goes Linear Constraints over Reals and Integers",
        "authors": [
            "Tomi Janhunen",
            "Roland Kaminski",
            "Max Ostrowski",
            "Torsten Schaub",
            "Sebastian Schellhorn",
            "Philipp Wanko"
        ],
        "abstract": "The recent series 5 of the ASP system clingo provides generic means to enhance basic Answer Set Programming (ASP) with theory reasoning capabilities. We instantiate this framework with different forms of linear constraints, discuss the respective implementations, and present techniques of how to use these constraints in a reactive context. More precisely, we introduce extensions to clingo with difference and linear constraints over integers and reals, respectively, and realize them in complementary ways. Finally, we empirically evaluate the resulting clingo derivatives clingo[dl] and clingo[lp] on common fragments and contrast them to related ASP systems.\n",
        "submission_date": "2017-07-13T00:00:00",
        "last_modified_date": "2017-07-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.04106",
        "title": "Armstrong's Axioms and Navigation Strategies",
        "authors": [
            "Kaya Deuser",
            "Pavel Naumov"
        ],
        "abstract": "The paper investigates navigability with imperfect information. It shows that the properties of navigability with perfect recall are exactly those captured by Armstrong's axioms from the database theory. If the assumption of perfect recall is omitted, then Armstrong's transitivity axiom is not valid, but it can be replaced by two new weaker principles. The main technical results are soundness and completeness theorems for the logical systems describing properties of navigability with and without perfect recall.\n    ",
        "submission_date": "2017-07-13T00:00:00",
        "last_modified_date": "2017-11-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.04244",
        "title": "Lithium NLP: A System for Rich Information Extraction from Noisy User Generated Text on Social Media",
        "authors": [
            "Preeti Bhargava",
            "Nemanja Spasojevic",
            "Guoning Hu"
        ],
        "abstract": "In this paper, we describe the Lithium Natural Language Processing (NLP) system - a resource-constrained, high- throughput and language-agnostic system for information extraction from noisy user generated text on social media. Lithium NLP extracts a rich set of information including entities, topics, hashtags and sentiment from text. We discuss several real world applications of the system currently incorporated in Lithium products. We also compare our system with existing commercial and academic NLP systems in terms of performance, information extracted and languages supported. We show that Lithium NLP is at par with and in some cases, outperforms state- of-the-art commercial NLP systems.\n    ",
        "submission_date": "2017-07-13T00:00:00",
        "last_modified_date": "2017-07-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.04277",
        "title": "On (Anti)Conditional Independence in Dempster-Shafer Theory",
        "authors": [
            "Mieczys\u0142aw A. K\u0142opotek"
        ],
        "abstract": "This paper verifies a result of {Shenoy:94} concerning graphoidal structure of Shenoy's notion of independence for Dempster-Shafer theory of belief functions. Shenoy proved that his notion of independence has graphoidal properties for positive normal valuations.\n",
        "submission_date": "2017-07-13T00:00:00",
        "last_modified_date": "2017-07-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.04298",
        "title": "Strategic Coalitions with Perfect Recall",
        "authors": [
            "Pavel Naumov",
            "Jia Tao"
        ],
        "abstract": "The paper proposes a bimodal logic that describes an interplay between distributed knowledge modality and coalition know-how modality. Unlike other similar systems, the one proposed here assumes perfect recall by all agents. Perfect recall is captured in the system by a single axiom. The main technical results are the soundness and the completeness theorems for the proposed logical system.\n    ",
        "submission_date": "2017-07-13T00:00:00",
        "last_modified_date": "2017-11-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.04327",
        "title": "Human-Level Intelligence or Animal-Like Abilities?",
        "authors": [
            "Adnan Darwiche"
        ],
        "abstract": "The vision systems of the eagle and the snake outperform everything that we can make in the laboratory, but snakes and eagles cannot build an eyeglass or a telescope or a microscope. (Judea Pearl)\n    ",
        "submission_date": "2017-07-13T00:00:00",
        "last_modified_date": "2017-07-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.04352",
        "title": "Advances in Artificial Intelligence Require Progress Across all of Computer Science",
        "authors": [
            "Gregory D. Hager",
            "Randal Bryant",
            "Eric Horvitz",
            "Maja Mataric",
            "Vasant Honavar"
        ],
        "abstract": "Advances in Artificial Intelligence require progress across all of computer science.\n    ",
        "submission_date": "2017-07-13T00:00:00",
        "last_modified_date": "2017-07-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.04489",
        "title": "Freeway Merging in Congested Traffic based on Multipolicy Decision Making with Passive Actor Critic",
        "authors": [
            "Tomoki Nishi",
            "Prashant Doshi",
            "Danil Prokhorov"
        ],
        "abstract": "Freeway merging in congested traffic is a significant challenge toward fully automated driving. Merging vehicles need to decide not only how to merge into a spot, but also where to merge. We present a method for the freeway merging based on multi-policy decision making with a reinforcement learning method called {\\em passive actor-critic} (pAC), which learns with less knowledge of the system and without active exploration. The method selects a merging spot candidate by using the state value learned with pAC. We evaluate our method using real traffic data. Our experiments show that pAC achieves 92\\% success rate to merge into a freeway, which is comparable to human decision making.\n    ",
        "submission_date": "2017-07-14T00:00:00",
        "last_modified_date": "2017-07-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.04506",
        "title": "Reliability Assessment of Distribution System Using Fuzzy Logic for Modelling of Transformer and Line Uncertainties",
        "authors": [
            "Ahmad Shokrollahi",
            "Hossein Sangrody",
            "Mahdi Motalleb",
            "Mandana Rezaeiahari",
            "Elham Foruzan",
            "Fattah Hassanzadeh"
        ],
        "abstract": "Reliability assessment of distribution system, based on historical data and probabilistic methods, leads to an unreliable estimation of reliability indices since the data for the distribution components are usually inaccurate or unavailable. Fuzzy logic is an efficient method to deal with the uncertainty in reliability inputs. In this paper, the ENS index along with other commonly used indices in reliability assessment are evaluated for the distribution system using fuzzy logic. Accordingly, the influential variables on the failure rate and outage duration time of the distribution components, which are natural or human-made, are explained using proposed fuzzy membership functions. The reliability indices are calculated and compared for different cases of the system operations by simulation on the IEEE RBTS Bus 2. The results of simulation show how utilities can significantly improve the reliability of their distribution system by considering the risk of the influential variables.\n    ",
        "submission_date": "2017-07-11T00:00:00",
        "last_modified_date": "2017-07-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.04584",
        "title": "Fast Restricted Causal Inference",
        "authors": [
            "Mieczys\u0142aw A. K\u0142opotek"
        ],
        "abstract": "Hidden variables are well known sources of disturbance when recovering belief networks from data based only on measurable variables. Hence models assuming existence of hidden variables are under development.\n",
        "submission_date": "2017-07-13T00:00:00",
        "last_modified_date": "2017-07-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.04775",
        "title": "AI Challenges in Human-Robot Cognitive Teaming",
        "authors": [
            "Tathagata Chakraborti",
            "Subbarao Kambhampati",
            "Matthias Scheutz",
            "Yu Zhang"
        ],
        "abstract": "Among the many anticipated roles for robots in the future is that of being a human teammate. Aside from all the technological hurdles that have to be overcome with respect to hardware and control to make robots fit to work with humans, the added complication here is that humans have many conscious and subconscious expectations of their teammates - indeed, we argue that teaming is mostly a cognitive rather than physical coordination activity. This introduces new challenges for the AI and robotics community and requires fundamental changes to the traditional approach to the design of autonomy. With this in mind, we propose an update to the classical view of the intelligent agent architecture, highlighting the requirements for mental modeling of the human in the deliberative process of the autonomous agent. In this article, we outline briefly the recent efforts of ours, and others in the community, towards developing cognitive teammates along these guidelines.\n    ",
        "submission_date": "2017-07-15T00:00:00",
        "last_modified_date": "2017-08-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.04828",
        "title": "FML-based Dynamic Assessment Agent for Human-Machine Cooperative System on Game of Go",
        "authors": [
            "Chang-Shing Lee",
            "Mei-Hui Wang",
            "Sheng-Chi Yang",
            "Pi-Hsia Hung",
            "Su-Wei Lin",
            "Nan Shuo",
            "Naoyuki Kubota",
            "Chun-Hsun Chou",
            "Ping-Chiang Chou",
            "Chia-Hsiu Kao"
        ],
        "abstract": "In this paper, we demonstrate the application of Fuzzy Markup Language (FML) to construct an FML-based Dynamic Assessment Agent (FDAA), and we present an FML-based Human-Machine Cooperative System (FHMCS) for the game of Go. The proposed FDAA comprises an intelligent decision-making and learning mechanism, an intelligent game bot, a proximal development agent, and an intelligent agent. The intelligent game bot is based on the open-source code of Facebook Darkforest, and it features a representational state transfer application programming interface mechanism. The proximal development agent contains a dynamic assessment mechanism, a GoSocket mechanism, and an FML engine with a fuzzy knowledge base and rule base. The intelligent agent contains a GoSocket engine and a summarization agent that is based on the estimated win rate, real-time simulation number, and matching degree of predicted moves. Additionally, the FML for player performance evaluation and linguistic descriptions for game results commentary are presented. We experimentally verify and validate the performance of the FDAA and variants of the FHMCS by testing five games in 2016 and 60 games of Google Master Go, a new version of the AlphaGo program, in January 2017. The experimental results demonstrate that the proposed FDAA can work effectively for Go applications.\n    ",
        "submission_date": "2017-07-16T00:00:00",
        "last_modified_date": "2017-07-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.04903",
        "title": "Tunnel Effects in Cognition: A new Mechanism for Scientific Discovery and Education",
        "authors": [
            "Antoine Cornu\u00e9jols",
            "Andr\u00e9e Tiberghien",
            "G\u00e9rard Collet"
        ],
        "abstract": "It is quite exceptional, if it ever happens, that a new conceptual domain be built from scratch. Usually, it is developed and mastered in interaction, both positive and negative, with other more operational existing domains. Few reasoning mechanisms have been proposed to account for the interplay of different conceptual domains and the transfer of information from one to another. Analogical reasoning is one, blending is another. This paper presents a new mechanism, called 'tunnel effect', that may explain, in part, how scientists and students reason while constructing a new conceptual domain. One experimental study with high school students and analyses from the history of science, particularly about the birth of classical thermodynamics, provide evidence and illustrate this mechanism. The knowledge organization, processes and conditions for its appearance are detailed and put into the perspective of a computational model. Specifically, we put forward the hypothesis that two levels of knowledge, notional and conceptual, cooperate in the scientific discovery process when a new conceptual domain is being built. The type of conceptual learning that can be associated with tunnel effect is discussed and a thorough comparison is made with analogical reasoning in order to underline the main features of the new proposed mechanism.\n    ",
        "submission_date": "2017-07-16T00:00:00",
        "last_modified_date": "2017-07-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.04943",
        "title": "Improving Naive Bayes for Regression with Optimised Artificial Surrogate Data",
        "authors": [
            "Michael Mayo",
            "Eibe Frank"
        ],
        "abstract": "Can we evolve better training data for machine learning algorithms? To investigate this question we use population-based optimisation algorithms to generate artificial surrogate training data for naive Bayes for regression. We demonstrate that the generalisation performance of naive Bayes for regression models is enhanced by training them on the artificial data as opposed to the real data. These results are important for two reasons. Firstly, naive Bayes models are simple and interpretable but frequently underperform compared to more complex \"black box\" models, and therefore new methods of enhancing accuracy are called for. Secondly, the idea of using the real training data indirectly in the construction of the artificial training data, as opposed to directly for model training, is a novel twist on the usual machine learning paradigm.\n    ",
        "submission_date": "2017-07-16T00:00:00",
        "last_modified_date": "2018-11-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.04957",
        "title": "Improving Adherence to Heart Failure Management Guidelines via Abductive Reasoning",
        "authors": [
            "Zhuo Chen",
            "Elmer Salazar",
            "Kyle Marple",
            "Gopal Gupta",
            "Lakshman Tamil",
            "Sandeep Das",
            "Alpesh Amin"
        ],
        "abstract": "Management of chronic diseases such as heart failure (HF) is a major public health problem. A standard approach to managing chronic diseases by medical community is to have a committee of experts develop guidelines that all physicians should follow. Due to their complexity, these guidelines are difficult to implement and are adopted slowly by the medical community at large. We have developed a physician advisory system that codes the entire set of clinical practice guidelines for managing HF using answer set programming(ASP). In this paper we show how abductive reasoning can be deployed to find missing symptoms and conditions that the patient must exhibit in order for a treatment prescribed by a physician to work effectively. Thus, if a physician does not make an appropriate recommendation or makes a non-adherent recommendation, our system will advise the physician about symptoms and conditions that must be in effect for that recommendation to apply. It is under consideration for acceptance in TPLP.\n    ",
        "submission_date": "2017-07-16T00:00:00",
        "last_modified_date": "2017-07-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.04987",
        "title": "Online Multi-Armed Bandit",
        "authors": [
            "Uma Roy",
            "Ashwath Thirmulai",
            "Joe Zurier"
        ],
        "abstract": "We introduce a novel variant of the multi-armed bandit problem, in which bandits are streamed one at a time to the player, and at each point, the player can either choose to pull the current bandit or move on to the next bandit. Once a player has moved on from a bandit, they may never visit it again, which is a crucial difference between our problem and classic multi-armed bandit problems. In this online context, we study Bernoulli bandits (bandits with payout Ber($p_i$) for some underlying mean $p_i$) with underlying means drawn i.i.d. from various distributions, including the uniform distribution, and in general, all distributions that have a CDF satisfying certain differentiability conditions near zero. In all cases, we suggest several strategies and investigate their expected performance. Furthermore, we bound the performance of any optimal strategy and show that the strategies we have suggested are indeed optimal up to a constant factor. We also investigate the case where the distribution from which the underlying means are drawn is not known ahead of time. We again, are able to suggest algorithms that are optimal up to a constant factor for this case, given certain mild conditions on the universe of distributions.\n    ",
        "submission_date": "2017-07-17T00:00:00",
        "last_modified_date": "2017-07-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.05001",
        "title": "Coalition formation for Multi-agent Pursuit based on Neural Network and AGRMF Model",
        "authors": [
            "Zhaoyi Pei",
            "Songhao Piao",
            "Mohammed Ei Souidi"
        ],
        "abstract": "An approach for coalition formation of multi-agent pursuit based on neural network and AGRMF model is ",
        "submission_date": "2017-07-17T00:00:00",
        "last_modified_date": "2017-07-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.05005",
        "title": "graph2vec: Learning Distributed Representations of Graphs",
        "authors": [
            "Annamalai Narayanan",
            "Mahinthan Chandramohan",
            "Rajasekar Venkatesan",
            "Lihui Chen",
            "Yang Liu",
            "Shantanu Jaiswal"
        ],
        "abstract": "Recent works on representation learning for graph structured data predominantly focus on learning distributed representations of graph substructures such as nodes and subgraphs. However, many graph analytics tasks such as graph classification and clustering require representing entire graphs as fixed length feature vectors. While the aforementioned approaches are naturally unequipped to learn such representations, graph kernels remain as the most effective way of obtaining them. However, these graph kernels use handcrafted features (e.g., shortest paths, graphlets, etc.) and hence are hampered by problems such as poor generalization. To address this limitation, in this work, we propose a neural embedding framework named graph2vec to learn data-driven distributed representations of arbitrary sized graphs. graph2vec's embeddings are learnt in an unsupervised manner and are task agnostic. Hence, they could be used for any downstream task such as graph classification, clustering and even seeding supervised representation learning approaches. Our experiments on several benchmark and large real-world datasets show that graph2vec achieves significant improvements in classification and clustering accuracies over substructure representation learning approaches and are competitive with state-of-the-art graph kernels.\n    ",
        "submission_date": "2017-07-17T00:00:00",
        "last_modified_date": "2017-07-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.05152",
        "title": "When You Must Forget: beyond strong persistence when forgetting in answer set programming",
        "authors": [
            "Ricardo Gon\u00e7alves",
            "Matthias Knorr",
            "Jo\u00e3o Leite",
            "Stefan Woltran"
        ],
        "abstract": "Among the myriad of desirable properties discussed in the context of forgetting in Answer Set Programming (ASP), strong persistence naturally captures its essence. Recently, it has been shown that it is not always possible to forget a set of atoms from a program while obeying this property, and a precise criterion regarding what can be forgotten has been presented, accompanied by a class of forgetting operators that return the correct result when forgetting is possible.\n",
        "submission_date": "2017-07-17T00:00:00",
        "last_modified_date": "2017-07-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.05165",
        "title": "A Comprehensive Implementation of Conceptual Spaces",
        "authors": [
            "Lucas Bechberger",
            "Kai-Uwe K\u00fchnberger"
        ],
        "abstract": "The highly influential framework of conceptual spaces provides a geometric way of representing knowledge. Instances are represented by points and concepts are represented by regions in a (potentially) high-dimensional space. Based on our recent formalization, we present a comprehensive implementation of the conceptual spaces framework that is not only capable of representing concepts with inter-domain correlations, but that also offers a variety of operations on these concepts.\n    ",
        "submission_date": "2017-07-14T00:00:00",
        "last_modified_date": "2018-04-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.05173",
        "title": "Trial without Error: Towards Safe Reinforcement Learning via Human Intervention",
        "authors": [
            "William Saunders",
            "Girish Sastry",
            "Andreas Stuhlmueller",
            "Owain Evans"
        ],
        "abstract": "AI systems are increasingly applied to complex tasks that involve interaction with humans. During training, such systems are potentially dangerous, as they haven't yet learned to avoid actions that could cause serious harm. How can an AI system explore and learn without making a single mistake that harms humans or otherwise causes serious damage? For model-free reinforcement learning, having a human \"in the loop\" and ready to intervene is currently the only way to prevent all catastrophes. We formalize human intervention for RL and show how to reduce the human labor required by training a supervised learner to imitate the human's intervention decisions. We evaluate this scheme on Atari games, with a Deep RL agent being overseen by a human for four hours. When the class of catastrophes is simple, we are able to prevent all catastrophes without affecting the agent's learning (whereas an RL baseline fails due to catastrophic forgetting). However, this scheme is less successful when catastrophes are more complex: it reduces but does not eliminate catastrophes and the supervised learner fails on adversarial examples found by the agent. Extrapolating to more challenging environments, we show that our implementation would not scale (due to the infeasible amount of human labor required). We outline extensions of the scheme that are necessary if we are to train model-free agents without a single catastrophe.\n    ",
        "submission_date": "2017-07-17T00:00:00",
        "last_modified_date": "2017-07-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.05176",
        "title": "Latent Relational Metric Learning via Memory-based Attention for Collaborative Ranking",
        "authors": [
            "Yi Tay",
            "Anh Tuan Luu",
            "Siu Cheung Hui"
        ],
        "abstract": "This paper proposes a new neural architecture for collaborative ranking with implicit feedback. Our model, LRML (\\textit{Latent Relational Metric Learning}) is a novel metric learning approach for recommendation. More specifically, instead of simple push-pull mechanisms between user and item pairs, we propose to learn latent relations that describe each user item interaction. This helps to alleviate the potential geometric inflexibility of existing metric learing approaches. This enables not only better performance but also a greater extent of modeling capability, allowing our model to scale to a larger number of interactions. In order to do so, we employ a augmented memory module and learn to attend over these memory blocks to construct latent relations. The memory-based attention module is controlled by the user-item interaction, making the learned relation vector specific to each user-item pair. Hence, this can be interpreted as learning an exclusive and optimal relational translation for each user-item interaction. The proposed architecture demonstrates the state-of-the-art performance across multiple recommendation benchmarks. LRML outperforms other metric learning models by $6\\%-7.5\\%$ in terms of Hits@10 and nDCG@10 on large datasets such as Netflix and MovieLens20M. Moreover, qualitative studies also demonstrate evidence that our proposed model is able to infer and encode explicit sentiment, temporal and attribute information despite being only trained on implicit feedback. As such, this ascertains the ability of LRML to uncover hidden relational structure within implicit datasets.\n    ",
        "submission_date": "2017-07-17T00:00:00",
        "last_modified_date": "2018-02-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.05300",
        "title": "Reverse Curriculum Generation for Reinforcement Learning",
        "authors": [
            "Carlos Florensa",
            "David Held",
            "Markus Wulfmeier",
            "Michael Zhang",
            "Pieter Abbeel"
        ],
        "abstract": "Many relevant tasks require an agent to reach a certain state, or to manipulate objects into a desired configuration. For example, we might want a robot to align and assemble a gear onto an axle or insert and turn a key in a lock. These goal-oriented tasks present a considerable challenge for reinforcement learning, since their natural reward function is sparse and prohibitive amounts of exploration are required to reach the goal and receive some learning signal. Past approaches tackle these problems by exploiting expert demonstrations or by manually designing a task-specific reward shaping function to guide the learning agent. Instead, we propose a method to learn these tasks without requiring any prior knowledge other than obtaining a single state in which the task is achieved. The robot is trained in reverse, gradually learning to reach the goal from a set of start states increasingly far from the goal. Our method automatically generates a curriculum of start states that adapts to the agent's performance, leading to efficient training on goal-oriented tasks. We demonstrate our approach on difficult simulated navigation and fine-grained manipulation problems, not solvable by state-of-the-art reinforcement learning methods.\n    ",
        "submission_date": "2017-07-17T00:00:00",
        "last_modified_date": "2018-07-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.05308",
        "title": "Knowledge will Propel Machine Understanding of Content: Extrapolating from Current Examples",
        "authors": [
            "Amit Sheth",
            "Sujan Perera",
            "Sanjaya Wijeratne",
            "Krishnaprasad Thirunarayan"
        ],
        "abstract": "Machine Learning has been a big success story during the AI resurgence. One particular stand out success relates to learning from a massive amount of data. In spite of early assertions of the unreasonable effectiveness of data, there is increasing recognition for utilizing knowledge whenever it is available or can be created purposefully. In this paper, we discuss the indispensable role of knowledge for deeper understanding of content where (i) large amounts of training data are unavailable, (ii) the objects to be recognized are complex, (e.g., implicit entities and highly subjective content), and (iii) applications need to use complementary or related data in multiple modalities/media. What brings us to the cusp of rapid progress is our ability to (a) create relevant and reliable knowledge and (b) carefully exploit knowledge to enhance ML/NLP techniques. Using diverse examples, we seek to foretell unprecedented progress in our ability for deeper understanding and exploitation of multimodal data and continued incorporation of knowledge in learning techniques.\n    ",
        "submission_date": "2017-07-14T00:00:00",
        "last_modified_date": "2017-07-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.05390",
        "title": "TensorLog: Deep Learning Meets Probabilistic DBs",
        "authors": [
            "William W. Cohen",
            "Fan Yang",
            "Kathryn Rivard Mazaitis"
        ],
        "abstract": "We present an implementation of a probabilistic first-order logic called TensorLog, in which classes of logical queries are compiled into differentiable functions in a neural-network infrastructure such as Tensorflow or Theano. This leads to a close integration of probabilistic logical reasoning with deep-learning infrastructure: in particular, it enables high-performance deep learning frameworks to be used for tuning the parameters of a probabilistic logic. Experimental results show that TensorLog scales to problems involving hundreds of thousands of knowledge-base triples and tens of thousands of examples.\n    ",
        "submission_date": "2017-07-17T00:00:00",
        "last_modified_date": "2017-07-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.05654",
        "title": "Eigenlogic: Interpretable Quantum Observables with applications to Fuzzy Behavior of Vehicular Robots",
        "authors": [
            "Zeno Toffano",
            "Fran\u00e7ois Dubois"
        ],
        "abstract": "This work proposes a formulation of propositional logic, named Eigenlogic, using quantum observables as propositions. The eigenvalues of these operators are the truth-values and the associated eigenvectors the interpretations of the propositional system. Fuzzy logic arises naturally when considering vectors outside the eigensystem, the fuzzy membership function is obtained by the Born rule of the logical ",
        "submission_date": "2017-07-17T00:00:00",
        "last_modified_date": "2017-07-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.05858",
        "title": "Logic Programming approaches for routing fault-free and maximally-parallel Wavelength Routed Optical Networks on Chip (Application paper)",
        "authors": [
            "Marco Gavanelli",
            "Maddalena Nonato",
            "Andrea Peano",
            "Davide Bertozzi"
        ],
        "abstract": "One promising trend in digital system integration consists of boosting on-chip communication performance by means of silicon photonics, thus materializing the so-called Optical Networks-on-Chip (ONoCs). Among them, wavelength routing can be used to route a signal to destination by univocally associating a routing path to the wavelength of the optical carrier. Such wavelengths should be chosen so to minimize interferences among optical channels and to avoid routing faults. As a result, physical parameter selection of such networks requires the solution of complex constrained optimization problems. In previous work, published in the proceedings of the International Conference on Computer-Aided Design, we proposed and solved the problem of computing the maximum parallelism obtainable in the communication between any two endpoints while avoiding misrouting of optical signals. The underlying technology, only quickly mentioned in that paper, is Answer Set Programming (ASP). In this work, we detail the ASP approach we used to solve such problem.\n",
        "submission_date": "2017-07-18T00:00:00",
        "last_modified_date": "2017-07-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.05904",
        "title": "Hybrid Conditional Planning using Answer Set Programming",
        "authors": [
            "Ibrahim Faruk Yalciner",
            "Ahmed Nouman",
            "Volkan Patoglu",
            "Esra Erdem"
        ],
        "abstract": "We introduce a parallel offline algorithm for computing hybrid conditional plans, called HCP-ASP, oriented towards robotics applications. HCP-ASP relies on modeling actuation actions and sensing actions in an expressive nonmonotonic language of answer set programming (ASP), and computation of the branches of a conditional plan in parallel using an ASP solver. In particular, thanks to external atoms, continuous feasibility checks (like collision checks) are embedded into formal representations of actuation actions and sensing actions in ASP; and thus each branch of a hybrid conditional plan describes a feasible execution of actions to reach their goals. Utilizing nonmonotonic constructs and nondeterministic choices, partial knowledge about states and nondeterministic effects of sensing actions can be explicitly formalized in ASP; and thus each branch of a conditional plan can be computed by an ASP solver without necessitating a conformant planner and an ordering of sensing actions in advance. We apply our method in a service robotics domain and report experimental evaluations. Furthermore, we present performance comparisons with other compilation based conditional planners on standardized benchmark domains. This paper is under consideration for acceptance in TPLP.\n    ",
        "submission_date": "2017-07-19T00:00:00",
        "last_modified_date": "2017-07-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.06170",
        "title": "Learning model-based planning from scratch",
        "authors": [
            "Razvan Pascanu",
            "Yujia Li",
            "Oriol Vinyals",
            "Nicolas Heess",
            "Lars Buesing",
            "Sebastien Racani\u00e8re",
            "David Reichert",
            "Th\u00e9ophane Weber",
            "Daan Wierstra",
            "Peter Battaglia"
        ],
        "abstract": "Conventional wisdom holds that model-based planning is a powerful approach to sequential decision-making. It is often very challenging in practice, however, because while a model can be used to evaluate a plan, it does not prescribe how to construct a plan. Here we introduce the \"Imagination-based Planner\", the first model-based, sequential decision-making agent that can learn to construct, evaluate, and execute plans. Before any action, it can perform a variable number of imagination steps, which involve proposing an imagined action and evaluating it with its model-based imagination. All imagined actions and outcomes are aggregated, iteratively, into a \"plan context\" which conditions future real and imagined actions. The agent can even decide how to imagine: testing out alternative imagined actions, chaining sequences of actions together, or building a more complex \"imagination tree\" by navigating flexibly among the previously imagined states using a learned policy. And our agent can learn to plan economically, jointly optimizing for external rewards and computational costs associated with using its imagination. We show that our architecture can learn to solve a challenging continuous control problem, and also learn elaborate planning strategies in a discrete maze-solving task. Our work opens a new direction toward learning the components of a model-based planning system and how to use them.\n    ",
        "submission_date": "2017-07-19T00:00:00",
        "last_modified_date": "2017-07-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.06194",
        "title": "Entropy-based Pruning for Learning Bayesian Networks using BIC",
        "authors": [
            "Cassio P. de Campos",
            "Mauro Scanagatta",
            "Giorgio Corani",
            "Marco Zaffalon"
        ],
        "abstract": "For decomposable score-based structure learning of Bayesian networks, existing approaches first compute a collection of candidate parent sets for each variable and then optimize over this collection by choosing one parent set for each variable without creating directed cycles while maximizing the total score. We target the task of constructing the collection of candidate parent sets when the score of choice is the Bayesian Information Criterion (BIC). We provide new non-trivial results that can be used to prune the search space of candidate parent sets of each node. We analyze how these new results relate to previous ideas in the literature both theoretically and empirically. We show in experiments with UCI data sets that gains can be significant. Since the new pruning rules are easy to implement and have low computational costs, they can be promptly integrated into all state-of-the-art methods for structure learning of Bayesian networks.\n    ",
        "submission_date": "2017-07-19T00:00:00",
        "last_modified_date": "2017-07-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.06325",
        "title": "Computing LPMLN Using ASP and MLN Solvers",
        "authors": [
            "Joohyung Lee",
            "Samidh Talsania",
            "Yi Wang"
        ],
        "abstract": "LPMLN is a recent addition to probabilistic logic programming languages. Its main idea is to overcome the rigid nature of the stable model semantics by assigning a weight to each rule in a way similar to Markov Logic is defined. We present two implementations of LPMLN, $\\text{LPMLN2ASP}$ and $\\text{LPMLN2MLN}$. System $\\text{LPMLN2ASP}$ translates LPMLN programs into the input language of answer set solver $\\text{CLINGO}$, and using weak constraints and stable model enumeration, it can compute most probable stable models as well as exact conditional and marginal probabilities. System $\\text{LPMLN2MLN}$ translates LPMLN programs into the input language of Markov Logic solvers, such as $\\text{ALCHEMY}$, $\\text{TUFFY}$, and $\\text{ROCKIT}$, and allows for performing approximate probabilistic inference on LPMLN programs. We also demonstrate the usefulness of the LPMLN systems for computing other languages, such as ProbLog and Pearl's Causal Models, that are shown to be translatable into LPMLN. (Under consideration for acceptance in TPLP)\n    ",
        "submission_date": "2017-07-19T00:00:00",
        "last_modified_date": "2017-11-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.06354",
        "title": "Pragmatic-Pedagogic Value Alignment",
        "authors": [
            "Jaime F. Fisac",
            "Monica A. Gates",
            "Jessica B. Hamrick",
            "Chang Liu",
            "Dylan Hadfield-Menell",
            "Malayandi Palaniappan",
            "Dhruv Malik",
            "S. Shankar Sastry",
            "Thomas L. Griffiths",
            "Anca D. Dragan"
        ],
        "abstract": "As intelligent systems gain autonomy and capability, it becomes vital to ensure that their objectives match those of their human users; this is known as the value-alignment problem. In robotics, value alignment is key to the design of collaborative robots that can integrate into human workflows, successfully inferring and adapting to their users' objectives as they go. We argue that a meaningful solution to value alignment must combine multi-agent decision theory with rich mathematical models of human cognition, enabling robots to tap into people's natural collaborative capabilities. We present a solution to the cooperative inverse reinforcement learning (CIRL) dynamic game based on well-established cognitive models of decision making and theory of mind. The solution captures a key reciprocity relation: the human will not plan her actions in isolation, but rather reason pedagogically about how the robot might learn from them; the robot, in turn, can anticipate this and interpret the human's actions pragmatically. To our knowledge, this work constitutes the first formal analysis of value alignment grounded in empirically validated cognitive models.\n    ",
        "submission_date": "2017-07-20T00:00:00",
        "last_modified_date": "2018-02-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.06387",
        "title": "Representing Hybrid Automata by Action Language Modulo Theories",
        "authors": [
            "Joohyung Lee",
            "Nikhil Loney",
            "Yunsong Meng"
        ],
        "abstract": "Both hybrid automata and action languages are formalisms for describing the evolution of dynamic systems. This paper establishes a formal relationship between them. We show how to succinctly represent hybrid automata in an action language which in turn is defined as a high-level notation for answer set programming modulo theories (ASPMT) --- an extension of answer set programs to the first-order level similar to the way satisfiability modulo theories (SMT) extends propositional satisfiability (SAT). We first show how to represent linear hybrid automata with convex invariants by an action language modulo theories. A further translation into SMT allows for computing them using SMT solvers that support arithmetic over reals. Next, we extend the representation to the general class of non-linear hybrid automata allowing even non-convex invariants. We represent them by an action language modulo ODE (Ordinary Differential Equations), which can be compiled into satisfiability modulo ODE. We developed a prototype system cplus2aspmt based on these translations, which allows for a succinct representation of hybrid transition systems that can be computed effectively by the state-of-the-art SMT solver dReal.\n    ",
        "submission_date": "2017-07-20T00:00:00",
        "last_modified_date": "2017-07-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.06446",
        "title": "Sequential Lifted Bayesian Filtering in Multiset Rewriting Systems",
        "authors": [
            "Max Schr\u00f6der",
            "Stefan L\u00fcdtke",
            "Sebastian Bader",
            "Frank Kr\u00fcger",
            "Thomas Kirste"
        ],
        "abstract": "Bayesian Filtering for plan and activity recognition is challenging for scenarios that contain many observation equivalent entities (i.e. entities that produce the same observations). This is due to the combinatorial explosion in the number of hypotheses that need to be tracked. However, this class of problems exhibits a certain symmetry that can be exploited for state space representation and inference. We analyze current state of the art methods and find that none of them completely fits the requirements arising in this problem class. We sketch a novel inference algorithm that provides a solution by incorporating concepts from Lifted Inference algorithms, Probabilistic Multiset Rewriting Systems, and Computational State Space Models. Two experiments confirm that this novel algorithm has the potential to perform efficient probabilistic inference on this problem class.\n    ",
        "submission_date": "2017-07-20T00:00:00",
        "last_modified_date": "2017-08-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.06607",
        "title": "Applying MAPP Algorithm for Cooperative Path Finding in Urban Environments",
        "authors": [
            "Anton Andreychuk",
            "Konstantin Yakovlev"
        ],
        "abstract": "The paper considers the problem of planning a set of non-conflict trajectories for the coalition of intelligent agents (mobile robots). Two divergent approaches, e.g. centralized and decentralized, are surveyed and analyzed. Decentralized planner - MAPP is described and applied to the task of finding trajectories for dozens UAVs performing nap-of-the-earth flight in urban environments. Results of the experimental studies provide an opportunity to claim that MAPP is a highly efficient planner for solving considered types of tasks.\n    ",
        "submission_date": "2017-07-20T00:00:00",
        "last_modified_date": "2017-07-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.06633",
        "title": "Acting Thoughts: Towards a Mobile Robotic Service Assistant for Users with Limited Communication Skills",
        "authors": [
            "Felix Burget",
            "Lukas Dominique Josef Fiederer",
            "Daniel Kuhner",
            "Martin V\u00f6lker",
            "Johannes Aldinger",
            "Robin Tibor Schirrmeister",
            "Chau Do",
            "Joschka Boedecker",
            "Bernhard Nebel",
            "Tonio Ball",
            "Wolfram Burgard"
        ],
        "abstract": "As autonomous service robots become more affordable and thus available also for the general public, there is a growing need for user friendly interfaces to control the robotic system. Currently available control modalities typically expect users to be able to express their desire through either touch, speech or gesture commands. While this requirement is fulfilled for the majority of users, paralyzed users may not be able to use such systems. In this paper, we present a novel framework, that allows these users to interact with a robotic service assistant in a closed-loop fashion, using only thoughts. The brain-computer interface (BCI) system is composed of several interacting components, i.e., non-invasive neuronal signal recording and decoding, high-level task planning, motion and manipulation planning as well as environment perception. In various experiments, we demonstrate its applicability and robustness in real world scenarios, considering fetch-and-carry tasks and tasks involving human-robot interaction. As our results demonstrate, our system is capable of adapting to frequent changes in the environment and reliably completing given tasks within a reasonable amount of time. Combined with high-level planning and autonomous robotic systems, interesting new perspectives open up for non-invasive BCI-based human-robot interactions.\n    ",
        "submission_date": "2017-07-20T00:00:00",
        "last_modified_date": "2018-06-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.06766",
        "title": "Outcome-Oriented Predictive Process Monitoring: Review and Benchmark",
        "authors": [
            "Irene Teinemaa",
            "Marlon Dumas",
            "Marcello La Rosa",
            "Fabrizio Maria Maggi"
        ],
        "abstract": "Predictive business process monitoring refers to the act of making predictions about the future state of ongoing cases of a business process, based on their incomplete execution traces and logs of historical (completed) traces. Motivated by the increasingly pervasive availability of fine-grained event data about business process executions, the problem of predictive process monitoring has received substantial attention in the past years. In particular, a considerable number of methods have been put forward to address the problem of outcome-oriented predictive process monitoring, which refers to classifying each ongoing case of a process according to a given set of possible categorical outcomes - e.g., Will the customer complain or not? Will an order be delivered, canceled or withdrawn? Unfortunately, different authors have used different datasets, experimental settings, evaluation measures and baselines to assess their proposals, resulting in poor comparability and an unclear picture of the relative merits and applicability of different methods. To address this gap, this article presents a systematic review and taxonomy of outcome-oriented predictive process monitoring methods, and a comparative experimental evaluation of eleven representative methods using a benchmark covering 24 predictive process monitoring tasks based on nine real-life event logs.\n    ",
        "submission_date": "2017-07-21T00:00:00",
        "last_modified_date": "2018-10-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.06895",
        "title": "Towards learning domain-independent planning heuristics",
        "authors": [
            "Pawel Gomoluch",
            "Dalal Alrajeh",
            "Alessandra Russo",
            "Antonio Bucchiarone"
        ],
        "abstract": "Automated planning remains one of the most general paradigms in Artificial Intelligence, providing means of solving problems coming from a wide variety of domains. One of the key factors restricting the applicability of planning is its computational complexity resulting from exponentially large search spaces. Heuristic approaches are necessary to solve all but the simplest problems. In this work, we explore the possibility of obtaining domain-independent heuristic functions using machine learning. This is a part of a wider research program whose objective is to improve practical applicability of planning in systems for which the planning domains evolve at run time. The challenge is therefore the learning of (corrections of) domain-independent heuristics that can be reused across different planning domains.\n    ",
        "submission_date": "2017-07-21T00:00:00",
        "last_modified_date": "2017-07-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.06959",
        "title": "A Framework for Easing the Development of Applications Embedding Answer Set Programming",
        "authors": [
            "Francesco Calimeri",
            "Davide Fusc\u00e0",
            "Stefano Germano",
            "Simona Perri",
            "Jessica Zangari"
        ],
        "abstract": "Answer Set Programming (ASP) is a well-established declarative problem solving paradigm which became widely used in AI and recognized as a powerful tool for knowledge representation and reasoning (KRR), especially for its high expressiveness and the ability to deal also with incomplete knowledge.\n",
        "submission_date": "2017-07-21T00:00:00",
        "last_modified_date": "2017-07-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.07298",
        "title": "Preference Reasoning in Matching Procedures: Application to the Admission Post-Baccalaureat Platform",
        "authors": [
            "Youssef Hamadi",
            "Souhila Kaci"
        ],
        "abstract": "Because preferences naturally arise and play an important role in many real-life decisions, they are at the backbone of various fields. In particular preferences are increasingly used in almost all matching procedures-based applications. In this work we highlight the benefit of using AI insights on preferences in a large scale application, namely the French Admission Post-Baccalaureat Platform (APB). Each year APB allocates hundreds of thousands first year applicants to universities. This is done automatically by matching applicants preferences to university seats. In practice, APB can be unable to distinguish between applicants which leads to the introduction of random selection. This has created frustration in the French public since randomness, even used as a last mean does not fare well with the republican egalitarian principle. In this work, we provide a solution to this problem. We take advantage of recent AI Preferences Theory results to show how to enhance APB in order to improve expressiveness of applicants preferences and reduce their exposure to random decisions.\n    ",
        "submission_date": "2017-07-23T00:00:00",
        "last_modified_date": "2019-03-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.07596",
        "title": "Adversarial Sets for Regularising Neural Link Predictors",
        "authors": [
            "Pasquale Minervini",
            "Thomas Demeester",
            "Tim Rockt\u00e4schel",
            "Sebastian Riedel"
        ],
        "abstract": "In adversarial training, a set of models learn together by pursuing competing goals, usually defined on single data instances. However, in relational learning and other non-i.i.d domains, goals can also be defined over sets of instances. For example, a link predictor for the is-a relation needs to be consistent with the transitivity property: if is-a(x_1, x_2) and is-a(x_2, x_3) hold, is-a(x_1, x_3) needs to hold as well. Here we use such assumptions for deriving an inconsistency loss, measuring the degree to which the model violates the assumptions on an adversarially-generated set of examples. The training objective is defined as a minimax problem, where an adversary finds the most offending adversarial examples by maximising the inconsistency loss, and the model is trained by jointly minimising a supervised loss and the inconsistency loss on the adversarial examples. This yields the first method that can use function-free Horn clauses (as in Datalog) to regularise any neural link predictor, with complexity independent of the domain size. We show that for several link prediction models, the optimisation problem faced by the adversary has efficient closed-form solutions. Experiments on link prediction benchmarks indicate that given suitable prior knowledge, our method can significantly improve neural link predictors on all relevant metrics.\n    ",
        "submission_date": "2017-07-24T00:00:00",
        "last_modified_date": "2017-07-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.07673",
        "title": "Evaluation of Semantic Web Technologies for Storing Computable Definitions of Electronic Health Records Phenotyping Algorithms",
        "authors": [
            "Vaclav Papez",
            "Spiros Denaxas",
            "Harry Hemingway"
        ],
        "abstract": "Electronic Health Records are electronic data generated during or as a byproduct of routine patient care. Structured, semi-structured and unstructured EHR offer researchers unprecedented phenotypic breadth and depth and have the potential to accelerate the development of precision medicine approaches at scale. A main EHR use-case is defining phenotyping algorithms that identify disease status, onset and severity. Phenotyping algorithms utilize diagnoses, prescriptions, laboratory tests, symptoms and other elements in order to identify patients with or without a specific trait. No common standardized, structured, computable format exists for storing phenotyping algorithms. The majority of algorithms are stored as human-readable descriptive text documents making their translation to code challenging due to their inherent complexity and hinders their sharing and re-use across the community. In this paper, we evaluate the two key Semantic Web Technologies, the Web Ontology Language and the Resource Description Framework, for enabling computable representations of EHR-driven phenotyping algorithms.\n    ",
        "submission_date": "2017-07-24T00:00:00",
        "last_modified_date": "2017-07-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.07763",
        "title": "Domain Recursion for Lifted Inference with Existential Quantifiers",
        "authors": [
            "Seyed Mehran Kazemi",
            "Angelika Kimmig",
            "Guy Van den Broeck",
            "David Poole"
        ],
        "abstract": "In recent work, we proved that the domain recursion inference rule makes domain-lifted inference possible on several relational probability models (RPMs) for which the best known time complexity used to be exponential. We also identified two classes of RPMs for which inference becomes domain lifted when using domain recursion. These two classes subsume the largest lifted classes that were previously known. In this paper, we show that domain recursion can also be applied to models with existential quantifiers. Currently, all lifted inference algorithms assume that existential quantifiers have been removed in pre-processing by Skolemization. We show that besides introducing potentially inconvenient negative weights, Skolemization may increase the time complexity of inference. We give two example models where domain recursion can replace Skolemization, avoids the need for dealing with negative numbers, and reduces the time complexity of inference. These two examples may be interesting from three theoretical aspects: 1- they provide a better and deeper understanding of domain recursion and, in general, (lifted) inference, 2- they may serve as evidence that there are larger classes of models for which domain recursion can satisfyingly replace Skolemization, and 3- they may serve as evidence that better Skolemization techniques exist.\n    ",
        "submission_date": "2017-07-24T00:00:00",
        "last_modified_date": "2017-07-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.07794",
        "title": "Relational Learning and Feature Extraction by Querying over Heterogeneous Information Networks",
        "authors": [
            "Parisa Kordjamshidi",
            "Sameer Singh",
            "Daniel Khashabi",
            "Christos Christodoulopoulos",
            "Mark Summons",
            "Saurabh Sinha",
            "Dan Roth"
        ],
        "abstract": "Many real world systems need to operate on heterogeneous information networks that consist of numerous interacting components of different types. Examples include systems that perform data analysis on biological information networks; social networks; and information extraction systems processing unstructured data to convert raw text to knowledge graphs. Many previous works describe specialized approaches to perform specific types of analysis, mining and learning on such networks. In this work, we propose a unified framework consisting of a data model -a graph with a first order schema along with a declarative language for constructing, querying and manipulating such networks in ways that facilitate relational and structured machine learning. In particular, we provide an initial prototype for a relational and graph traversal query language where queries are directly used as relational features for structured machine learning models. Feature extraction is performed by making declarative graph traversal queries. Learning and inference models can directly operate on this relational representation and augment it with new data and knowledge that, in turn, is integrated seamlessly into the relational structure to support new predictions. We demonstrate this system's capabilities by showcasing tasks in natural language processing and computational biology domains.\n    ",
        "submission_date": "2017-07-25T00:00:00",
        "last_modified_date": "2017-07-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.07907",
        "title": "Mutual Alignment Transfer Learning",
        "authors": [
            "Markus Wulfmeier",
            "Ingmar Posner",
            "Pieter Abbeel"
        ],
        "abstract": "Training robots for operation in the real world is a complex, time consuming and potentially expensive task. Despite significant success of reinforcement learning in games and simulations, research in real robot applications has not been able to match similar progress. While sample complexity can be reduced by training policies in simulation, such policies can perform sub-optimally on the real platform given imperfect calibration of model dynamics. We present an approach -- supplemental to fine tuning on the real robot -- to further benefit from parallel access to a simulator during training and reduce sample requirements on the real robot. The developed approach harnesses auxiliary rewards to guide the exploration for the real world agent based on the proficiency of the agent in simulation and vice versa. In this context, we demonstrate empirically that the reciprocal alignment for both agents provides further benefit as the agent in simulation can adjust to optimize its behaviour for states commonly visited by the real-world agent.\n    ",
        "submission_date": "2017-07-25T00:00:00",
        "last_modified_date": "2017-09-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.07999",
        "title": "Evidence combination for a large number of sources",
        "authors": [
            "Kuang Zhou",
            "Arnaud Martin",
            "Quan Pan"
        ],
        "abstract": "The theory of belief functions is an effective tool to deal with the  multiple uncertain information. In recent years, many evidence combination rules have been proposed in this framework, such as the conjunctive rule, the cautious rule, the PCR (Proportional Conflict Redistribution) rules and so on. These rules can be adopted for different types of sources. However, most of these rules are not applicable when the number of sources is large. This is due to either the complexity  or the  existence of an absorbing element (such as the total conflict mass function for the conjunctive-based rules when applied on unreliable evidence). In this paper, based on the assumption that the majority of sources are reliable, a combination rule for a large number of sources, named LNS (stands for Large Number of Sources), is proposed on the basis of a simple idea: the more common ideas one source shares with others, the morereliable the source is. This rule is adaptable for aggregating  a large number of sources among which some are unreliable. It will keep the spirit of the conjunctive rule to reinforce the belief on the focal elements with which the sources are in agreement. The mass on the empty set will  be kept as an indicator of the conflict. Moreover, it can be used to elicit the major opinion among the experts. The experimental results on synthetic mass functionsverify that  the rule  can be effectively used to combine a large number of mass functions and to elicit the major opinion.\n    ",
        "submission_date": "2017-07-25T00:00:00",
        "last_modified_date": "2017-07-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.08000",
        "title": "Un mod\u00e8le pour la repr\u00e9sentation des connaissances temporelles dans les documents historiques",
        "authors": [
            "Sahar Aljalbout",
            "Gilles Falquet"
        ],
        "abstract": "Processing and publishing the data of the historical sciences in the semantic web is an interesting challenge in which the representation of temporal aspects plays a key role. We propose in this paper a model of temporal knowledge representation adapted to work on historical documents. This model is based on the notion of fluent that is represented in RDF graphs. We show how this model allows to represent the knowledge necessary to the historians and how it can be used to reason on this knowledge using the  SWRL and SPARQL languages. This model is being used in a project to digitize, study and publish the manuscripts of linguist Ferdinand de Saussure.\n    ",
        "submission_date": "2017-07-25T00:00:00",
        "last_modified_date": "2017-07-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.08151",
        "title": "Speeding-up ProbLog's Parameter Learning",
        "authors": [
            "Francisco H. O. V. de Faria",
            "Arthur C. Gusm\u00e3o",
            "Fabio G. Cozman",
            "Denis D. Mau\u00e1"
        ],
        "abstract": "ProbLog is a state-of-art combination of logic programming and probabilities; in particular ProbLog offers parameter learning through a variant of the EM algorithm. However, the resulting learning algorithm is rather slow, even when the data are complete. In this short paper we offer some insights that lead to orders of magnitude improvements in ProbLog's parameter learning speed with complete data.\n    ",
        "submission_date": "2017-07-25T00:00:00",
        "last_modified_date": "2017-08-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.08212",
        "title": "Physical problem solving: Joint planning with symbolic, geometric, and dynamic constraints",
        "authors": [
            "Ilker Yildirim",
            "Tobias Gerstenberg",
            "Basil Saeed",
            "Marc Toussaint",
            "Josh Tenenbaum"
        ],
        "abstract": "In this paper, we present a new task that investigates how people interact with and make judgments about towers of blocks. In Experiment~1, participants in the lab solved a series of problems in which they had to re-configure three blocks from an initial to a final configuration. We recorded whether they used one hand or two hands to do so. In Experiment~2, we asked participants online to judge whether they think the person in the lab used one or two hands. The results revealed a close correspondence between participants' actions in the lab, and the mental simulations of participants online. To explain participants' actions and mental simulations, we develop a model that plans over a symbolic representation of the situation, executes the plan using a geometric solver, and checks the plan's feasibility by taking into account the physical constraints of the scene. Our model explains participants' actions and judgments to a high degree of quantitative accuracy.\n    ",
        "submission_date": "2017-07-25T00:00:00",
        "last_modified_date": "2017-07-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.08234",
        "title": "Closed-Loop Policies for Operational Tests of Safety-Critical Systems",
        "authors": [
            "Jeremy Morton",
            "Tim A. Wheeler",
            "Mykel J. Kochenderfer"
        ],
        "abstract": "Manufacturers of safety-critical systems must make the case that their product is sufficiently safe for public deployment. Much of this case often relies upon critical event outcomes from real-world testing, requiring manufacturers to be strategic about how they allocate testing resources in order to maximize their chances of demonstrating system safety. This work frames the partially observable and belief-dependent problem of test scheduling as a Markov decision process, which can be solved efficiently to yield closed-loop manufacturer testing policies. By solving for policies over a wide range of problem formulations, we are able to provide high-level guidance for manufacturers and regulators on issues relating to the testing of safety-critical systems. This guidance spans an array of topics, including circumstances under which manufacturers should continue testing despite observed incidents, when manufacturers should test aggressively, and when regulators should increase or reduce the real-world testing requirements for an autonomous vehicle.\n    ",
        "submission_date": "2017-07-25T00:00:00",
        "last_modified_date": "2018-05-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.08255",
        "title": "Navigability with Imperfect Information",
        "authors": [
            "Kaya Deuser",
            "Pavel Naumov"
        ],
        "abstract": "The article studies navigability of an autonomous agent in a maze where some rooms may be indistinguishable. In a previous work the authors have shown that the properties of navigability in such a setting depend on whether an agent has perfect recall. Navigability by an agent with perfect recall is a transitive relation and without is not transitive.\n",
        "submission_date": "2017-07-26T00:00:00",
        "last_modified_date": "2017-07-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.08316",
        "title": "Learning Sparse Representations in Reinforcement Learning with Sparse Coding",
        "authors": [
            "Lei Le",
            "Raksha Kumaraswamy",
            "Martha White"
        ],
        "abstract": "A variety of representation learning approaches have been investigated for reinforcement learning; much less attention, however, has been given to investigating the utility of sparse coding. Outside of reinforcement learning, sparse coding representations have been widely used, with non-convex objectives that result in discriminative representations. In this work, we develop a supervised sparse coding objective for policy evaluation. Despite the non-convexity of this objective, we prove that all local minima are global minima, making the approach amenable to simple optimization strategies. We empirically show that it is key to use a supervised objective, rather than the more straightforward unsupervised sparse coding approach. We compare the learned representations to a canonical fixed sparse representation, called tile-coding, demonstrating that the sparse coding representation outperforms a wide variety of tilecoding representations.\n    ",
        "submission_date": "2017-07-26T00:00:00",
        "last_modified_date": "2017-07-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.08342",
        "title": "Declarative Sequential Pattern Mining of Care Pathways",
        "authors": [
            "Thomas Guyet",
            "Andr\u00e9 Happe",
            "Yann Dauxais"
        ],
        "abstract": "Sequential pattern mining algorithms are widely used to explore care pathways database, but they generate a deluge of patterns, mostly redundant or useless. Clinicians need tools to express complex mining queries in order to generate less but more significant patterns. These algorithms are not versatile enough to answer complex clinician queries. This article proposes to apply a declarative pattern mining approach based on Answer Set Programming paradigm. It is exemplified by a pharmaco-epidemiological study investigating the possible association between hospitalization for seizure and antiepileptic drug switch from a french medico-administrative database.\n    ",
        "submission_date": "2017-07-26T00:00:00",
        "last_modified_date": "2017-07-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.08418",
        "title": "The Advantage of Evidential Attributes in Social Networks",
        "authors": [
            "Salma Ben Dhaou",
            "Kuang Zhou",
            "Mouloud Kharoune",
            "Arnaud Martin",
            "Boutheina Ben Yaghlane"
        ],
        "abstract": "Nowadays, there are many approaches designed for the task of detecting communities in social networks. Among them, some methods only consider the topological graph structure, while others take use of both the graph structure and the node attributes. In real-world networks, there are many uncertain and noisy attributes in the graph. In this paper, we will present how we detect communities in graphs with uncertain attributes in the first step. The numerical, probabilistic as well as evidential attributes are generated according to the graph structure. In the second step, some noise will be added to the attributes. We perform experiments on graphs with different types of attributes and compare the detection results in terms of the Normalized Mutual Information (NMI) values. The experimental results show that the clustering with evidential attributes gives better results comparing to those with probabilistic and numerical attributes. This illustrates the advantages of evidential attributes.\n    ",
        "submission_date": "2017-07-26T00:00:00",
        "last_modified_date": "2017-09-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.08468",
        "title": "A Decidable Very Expressive Description Logic for Databases (Extended Version)",
        "authors": [
            "Alessandro Artale",
            "Enrico Franconi",
            "Rafael Pe\u00f1aloza",
            "Francesco Sportelli"
        ],
        "abstract": "We introduce $\\mathcal{DLR}^+$, an extension of the n-ary propositionally closed description logic $\\mathcal{DLR}$ to deal with attribute-labelled tuples (generalising the positional notation), projections of relations, and global and local objectification of relations, able to express inclusion, functional, key, and external uniqueness dependencies. The logic is equipped with both TBox and ABox axioms. We show how a simple syntactic restriction on the appearance of projections sharing common attributes in a $\\mathcal{DLR}^+$ knowledge base makes reasoning in the language decidable with the same computational complexity as $\\mathcal{DLR}$. The obtained $\\mathcal{DLR}^\\pm$ n-ary description logic is able to encode more thoroughly conceptual data models such as EER, UML, and ORM.\n    ",
        "submission_date": "2017-07-25T00:00:00",
        "last_modified_date": "2017-07-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.08476",
        "title": "Guidelines for Artificial Intelligence Containment",
        "authors": [
            "James Babcock",
            "Janos Kramar",
            "Roman V. Yampolskiy"
        ],
        "abstract": "With almost daily improvements in capabilities of artificial intelligence it is more important than ever to develop safety software for use by the AI research community. Building on our previous work on AI Containment Problem we propose a number of guidelines which should help AI safety researchers to develop reliable sandboxing software for intelligent programs of all levels. Such safety container software will make it possible to study and analyze intelligent artificial agent while maintaining certain level of safety against information leakage, social engineering attacks and cyberattacks from within the container.\n    ",
        "submission_date": "2017-07-24T00:00:00",
        "last_modified_date": "2017-07-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.08616",
        "title": "Guiding Reinforcement Learning Exploration Using Natural Language",
        "authors": [
            "Brent Harrison",
            "Upol Ehsan",
            "Mark O. Riedl"
        ],
        "abstract": "In this work we present a technique to use natural language to help reinforcement learning generalize to unseen environments. This technique uses neural machine translation, specifically the use of encoder-decoder networks, to learn associations between natural language behavior descriptions and state-action information. We then use this learned model to guide agent exploration using a modified version of policy shaping to make it more effective at learning in unseen environments. We evaluate this technique using the popular arcade game, Frogger, under ideal and non-ideal conditions. This evaluation shows that our modified policy shaping algorithm improves over a Q-learning agent as well as a baseline version of policy shaping.\n    ",
        "submission_date": "2017-07-26T00:00:00",
        "last_modified_date": "2017-09-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.08668",
        "title": "A Tale of Two DRAGGNs: A Hybrid Approach for Interpreting Action-Oriented and Goal-Oriented Instructions",
        "authors": [
            "Siddharth Karamcheti",
            "Edward C. Williams",
            "Dilip Arumugam",
            "Mina Rhee",
            "Nakul Gopalan",
            "Lawson L. S. Wong",
            "Stefanie Tellex"
        ],
        "abstract": "Robots operating alongside humans in diverse, stochastic environments must be able to accurately interpret natural language commands. These instructions often fall into one of two categories: those that specify a goal condition or target state, and those that specify explicit actions, or how to perform a given task. Recent approaches have used reward functions as a semantic representation of goal-based commands, which allows for the use of a state-of-the-art planner to find a policy for the given task. However, these reward functions cannot be directly used to represent action-oriented commands. We introduce a new hybrid approach, the Deep Recurrent Action-Goal Grounding Network (DRAGGN), for task grounding and execution that handles natural language from either category as input, and generalizes to unseen environments. Our robot-simulation results demonstrate that a system successfully interpreting both goal-oriented and action-oriented task specifications brings us closer to robust natural language understanding for human-robot interaction.\n    ",
        "submission_date": "2017-07-26T00:00:00",
        "last_modified_date": "2017-07-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.08704",
        "title": "Anytime Exact Belief Propagation",
        "authors": [
            "Gabriel Azevedo Ferreira",
            "Quentin Bertrand",
            "Charles Maussion",
            "Rodrigo de Salvo Braz"
        ],
        "abstract": "Statistical Relational Models and, more recently, Probabilistic Programming, have been making strides towards an integration of logic and probabilistic reasoning. A natural expectation for this project is that a probabilistic logic reasoning algorithm reduces to a logic reasoning algorithm when provided a model that only involves 0-1 probabilities, exhibiting all the advantages of logic reasoning such as short-circuiting, intelligibility, and the ability to provide proof trees for a query answer. In fact, we can take this further and require that these characteristics be present even for probabilistic models with probabilities \\emph{near} 0 and 1, with graceful degradation as the model becomes more uncertain. We also seek inference that has amortized constant time complexity on a model's size (even if still exponential in the induced width of a more directly relevant portion of it) so that it can be applied to huge knowledge bases of which only a relatively small portion is relevant to typical queries. We believe that, among the probabilistic reasoning algorithms, Belief Propagation is the most similar to logic reasoning: messages are propagated among neighboring variables, and the paths of message-passing are similar to proof trees. However, Belief Propagation is either only applicable to tree models, or approximate (and without guarantees) for precision and convergence. In this paper we present work in progress on an Anytime Exact Belief Propagation algorithm that is very similar to Belief Propagation but is exact even for graphical models with cycles, while exhibiting soft short-circuiting, amortized constant time complexity in the model size, and which can provide probabilistic proof trees.\n    ",
        "submission_date": "2017-07-27T00:00:00",
        "last_modified_date": "2017-07-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.08736",
        "title": "Relaxing Exclusive Control in Boolean Games",
        "authors": [
            "Francesco Belardinelli",
            "Umberto Grandi",
            "Andreas Herzig",
            "Dominique Longin",
            "Emiliano Lorini",
            "Arianna Novaro",
            "Laurent Perrussel"
        ],
        "abstract": "In the typical framework for boolean games (BG) each player can change the truth value of some propositional atoms, while attempting to make her goal true. In standard BG goals are propositional formulas, whereas in iterated BG goals are formulas of Linear Temporal Logic. Both notions of BG are characterised by the fact that agents have exclusive control over their set of atoms, meaning that no two agents can control the same atom. In the present contribution we drop the exclusivity assumption and explore structures where an atom can be controlled by multiple agents. We introduce Concurrent Game Structures with Shared Propositional Control (CGS-SPC) and show that they ac- count for several classes of repeated games, including iterated boolean games, influence games, and aggregation games. Our main result shows that, as far as verification is concerned, CGS-SPC can be reduced to concurrent game structures with exclusive control. This result provides a polynomial reduction for the model checking problem of specifications in Alternating-time Temporal Logic on CGS-SPC.\n\n    ",
        "submission_date": "2017-07-27T00:00:00",
        "last_modified_date": "2017-07-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.08740",
        "title": "Preservation of Semantic Properties during the Aggregation of Abstract Argumentation Frameworks",
        "authors": [
            "Weiwei Chen",
            "Ulle Endriss"
        ],
        "abstract": "An abstract argumentation framework can be used to model the argumentative stance of an agent at a high level of abstraction, by indicating for every pair of arguments that is being considered in a debate whether the first attacks the second. When modelling a group of agents engaged in a debate, we may wish to aggregate their individual argumentation frameworks to obtain a single such framework that reflects the consensus of the group. Even when agents disagree on many details, there may well be high-level agreement on important semantic properties, such as the acceptability of a given argument. Using techniques from social choice theory, we analyse under what circumstances such semantic properties agreed upon by the individual agents can be preserved under aggregation.  \n    ",
        "submission_date": "2017-07-27T00:00:00",
        "last_modified_date": "2017-07-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.08759",
        "title": "Together We Know How to Achieve: An Epistemic Logic of Know-How (Extended Abstract)",
        "authors": [
            "Pavel Naumov",
            "Jia Tao"
        ],
        "abstract": "The existence of a coalition strategy to achieve a goal does not necessarily mean that the coalition has enough information to know how to follow the strategy. Neither does it mean that the coalition knows that such a strategy exists. The paper studies an interplay between the distributed knowledge, coalition strategies, and coalition \"know-how\" strategies. The main technical result is a sound and complete trimodal logical system that describes the properties of this interplay.\n    ",
        "submission_date": "2017-07-27T00:00:00",
        "last_modified_date": "2017-07-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.08762",
        "title": "Argument-based Belief in Topological Structures",
        "authors": [
            "Chenwei Shi",
            "Sonja Smets",
            "Fernando R. Vel\u00e1zquez-Quesada"
        ],
        "abstract": "This paper combines two studies: a topological semantics for epistemic notions and abstract argumentation theory. In our combined setting, we use a topological semantics to represent the structure of an agent's collection of evidence, and we use argumentation theory to single out the relevant sets of evidence through which a notion of beliefs grounded on arguments is defined. We discuss the formal properties of this newly defined notion, providing also a formal language with a matching modality together with a sound and complete axiom system for it. Despite the fact that our agent can combine her evidence in a 'rational' way (captured via the topological structure), argument-based beliefs are not closed under conjunction. This illustrates the difference between an agent's reasoning abilities (i.e. the way she is able to combine her available evidence) and the closure properties of her beliefs. We use this point to argue for why the failure of closure under conjunction of belief should not bear the burden of the failure of rationality.\n    ",
        "submission_date": "2017-07-27T00:00:00",
        "last_modified_date": "2017-07-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.08763",
        "title": "Reconciling Bayesian Epistemology and Narration-based Approaches to Judiciary Fact-finding",
        "authors": [
            "Rafal Urbaniak"
        ],
        "abstract": "Legal probabilism (LP) claims the  degrees of conviction in juridical fact-finding  are to be modeled exactly the way degrees of beliefs are modeled in standard bayesian epistemology. Classical legal probabilism (CLP) adds that the conviction is justified if the credence in guilt given the evidence is above an appropriate guilt probability threshold.  The views are challenged on various counts, especially by the proponents of the so-called narrative approach, on which the fact-finders' decision is the result of a dynamic interplay between competing narratives of what happened.  I develop a way a bayesian epistemologist can make sense of the narrative approach. I do so by formulating a probabilistic framework for evaluating  competing narrations in terms of formal  explications of the informal evaluation criteria used in the narrative approach.\n    ",
        "submission_date": "2017-07-27T00:00:00",
        "last_modified_date": "2017-07-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.08764",
        "title": "A New Modal Framework for Epistemic Logic",
        "authors": [
            "Yanjing Wang"
        ],
        "abstract": "Recent years witnessed a growing interest in non-standard epistemic logics of knowing whether, knowing how, knowing what, knowing why and so on. The new epistemic modalities introduced in those logics all share, in their semantics, the general schema of $\\exists x \\Box \\phi$, e.g., knowing how to achieve $\\phi$ roughly means that there exists a way such that you know that it is a way to ensure that $\\phi$. Moreover, the resulting logics are  decidable. Inspired by those particular logics, in this work, we propose a very general and powerful framework based on quantifier-free predicate language extended by a new modality $\\Box^x$, which packs exactly $\\exists x \\Box$ together. We show that the resulting language, though much more expressive, shares many good properties of the basic propositional modal logic over arbitrary models, such as finite-tree-model property and van Benthem-like characterization w.r.t.\\ first-order modal logic. We axiomatize the logic over S5 frames with intuitive axioms to capture the interaction between $\\Box^x$ and know-that operator in an epistemic setting.\n    ",
        "submission_date": "2017-07-27T00:00:00",
        "last_modified_date": "2017-07-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.08817",
        "title": "Leveraging Demonstrations for Deep Reinforcement Learning on Robotics Problems with Sparse Rewards",
        "authors": [
            "Mel Vecerik",
            "Todd Hester",
            "Jonathan Scholz",
            "Fumin Wang",
            "Olivier Pietquin",
            "Bilal Piot",
            "Nicolas Heess",
            "Thomas Roth\u00f6rl",
            "Thomas Lampe",
            "Martin Riedmiller"
        ],
        "abstract": "We propose a general and model-free approach for Reinforcement Learning (RL) on real robotics with sparse rewards. We build upon the Deep Deterministic Policy Gradient (DDPG) algorithm to use demonstrations. Both demonstrations and actual interactions are used to fill a replay buffer and the sampling ratio between demonstrations and transitions is automatically tuned via a prioritized replay mechanism. Typically, carefully engineered shaping rewards are required to enable the agents to efficiently explore on high dimensional control problems such as robotics. They are also required for model-based acceleration methods relying on local solvers such as iLQG (e.g. Guided Policy Search and Normalized Advantage Function). The demonstrations replace the need for carefully engineered rewards, and reduce the exploration problem encountered by classical RL approaches in these domains. Demonstrations are collected by a robot kinesthetically force-controlled by a human demonstrator. Results on four simulated insertion tasks show that DDPG from demonstrations out-performs DDPG, and does not require engineered rewards. Finally, we demonstrate the method on a real robotics task consisting of inserting a clip (flexible object) into a rigid object.\n    ",
        "submission_date": "2017-07-27T00:00:00",
        "last_modified_date": "2018-10-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.08879",
        "title": "Non-Count Symmetries in Boolean & Multi-Valued Prob. Graphical Models",
        "authors": [
            "Ankit Anand",
            "Ritesh Noothigattu",
            "Parag Singla",
            "Mausam"
        ],
        "abstract": "Lifted inference algorithms commonly exploit symmetries in a probabilistic graphical model (PGM) for efficient inference. However, existing algorithms for Boolean-valued domains can identify only those pairs of states as symmetric, in which the number of ones and zeros match exactly (count symmetries). Moreover, algorithms for lifted inference in multi-valued domains also compute a multi-valued extension of count symmetries only. These algorithms miss many symmetries in a domain. In this paper, we present first algorithms to compute non-count symmetries in both Boolean-valued and multi-valued domains. Our methods can also find symmetries between multi-valued variables that have different domain cardinalities. The key insight in the algorithms is that they change the unit of symmetry computation from a variable to a variable-value (VV) pair. Our experiments find that exploiting these symmetries in MCMC can obtain substantial computational gains over existing algorithms.\n    ",
        "submission_date": "2017-07-27T00:00:00",
        "last_modified_date": "2017-07-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.08901",
        "title": "Providing Self-Aware Systems with Reflexivity",
        "authors": [
            "Alessandro Valitutti",
            "Giuseppe Trautteur"
        ],
        "abstract": "We propose a new type of self-aware systems inspired by ideas from higher-order theories of consciousness. First, we discussed the crucial distinction between introspection and reflexion. Then, we focus on computational reflexion as a mechanism by which a computer program can inspect its own code at every stage of the computation. Finally, we provide a formal definition and a proof-of-concept implementation of computational reflexion, viewed as an enriched form of program interpretation and a way to dynamically \"augment\" a computational process.\n    ",
        "submission_date": "2017-07-27T00:00:00",
        "last_modified_date": "2017-07-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.09079",
        "title": "Learning to Teach Reinforcement Learning Agents",
        "authors": [
            "Anestis Fachantidis",
            "Matthew E. Taylor",
            "Ioannis Vlahavas"
        ],
        "abstract": "In this article we study the transfer learning model of action advice under a budget. We focus on reinforcement learning teachers providing action advice to heterogeneous students playing the game of Pac-Man under a limited advice budget. First, we examine several critical factors affecting advice quality in this setting, such as the average performance of the teacher, its variance and the importance of reward discounting in advising. The experiments show the non-trivial importance of the coefficient of variation (CV) as a statistic for choosing policies that generate advice. The CV statistic relates variance to the corresponding mean. Second, the article studies policy learning for distributing advice under a budget. Whereas most methods in the relevant literature rely on heuristics for advice distribution we formulate the problem as a learning one and propose a novel RL algorithm capable of learning when to advise, adapting to the student and the task at hand. Furthermore, we argue that learning to advise under a budget is an instance of a more generic learning problem: Constrained Exploitation Reinforcement Learning.\n    ",
        "submission_date": "2017-07-28T00:00:00",
        "last_modified_date": "2017-07-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.09095",
        "title": "Toward the Starting Line: A Systems Engineering Approach to Strong AI",
        "authors": [
            "Tansu Alpcan",
            "Sarah M. Erfani",
            "Christopher Leckie"
        ],
        "abstract": "Artificial General Intelligence (AGI) or Strong AI aims to create machines with human-like or human-level intelligence, which is still a very ambitious goal when compared to the existing computing and AI systems. After many hype cycles and lessons from AI history, it is clear that a big conceptual leap is needed for crossing the starting line to kick-start mainstream AGI research. This position paper aims to make a small conceptual contribution toward reaching that starting line. After a broad analysis of the AGI problem from different perspectives, a system-theoretic and engineering-based research approach is introduced, which builds upon the existing mainstream AI and systems foundations. Several promising cross-fertilization opportunities between systems disciplines and AI research are identified. Specific potential research directions are discussed.\n    ",
        "submission_date": "2017-07-28T00:00:00",
        "last_modified_date": "2017-10-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.09098",
        "title": "MEMEN: Multi-layer Embedding with Memory Networks for Machine Comprehension",
        "authors": [
            "Boyuan Pan",
            "Hao Li",
            "Zhou Zhao",
            "Bin Cao",
            "Deng Cai",
            "Xiaofei He"
        ],
        "abstract": "Machine comprehension(MC) style question answering is a representative problem in natural language processing. Previous methods rarely spend time on the improvement of encoding layer, especially the embedding of syntactic information and name entity of the words, which are very crucial to the quality of encoding. Moreover, existing attention methods represent each query word as a vector or use a single vector to represent the whole query sentence, neither of them can handle the proper weight of the key words in query sentence. In this paper, we introduce a novel neural network architecture called Multi-layer Embedding with Memory Network(MEMEN) for machine reading task. In the encoding layer, we employ classic skip-gram model to the syntactic and semantic information of the words to train a new kind of embedding layer. We also propose a memory network of full-orientation matching of the query and passage to catch more pivotal information. Experiments show that our model has competitive results both from the perspectives of precision and efficiency in Stanford Question Answering Dataset(SQuAD) among all published results and achieves the state-of-the-art results on TriviaQA dataset.\n    ",
        "submission_date": "2017-07-28T00:00:00",
        "last_modified_date": "2017-07-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.09324",
        "title": "Empirical Evaluation of Abstract Argumentation: Supporting the Need for Bipolar and Probabilistic Approaches",
        "authors": [
            "Sylwia Polberg",
            "Anthony Hunter"
        ],
        "abstract": "In dialogical argumentation it is often assumed that the involved parties always correctly identify the intended statements posited by each other, realize all of the associated relations, conform to the three acceptability states (accepted, rejected, undecided), adjust their views when new and correct information comes in, and that a framework handling only attack relations is sufficient to represent their opinions. Although it is natural to make these assumptions as a starting point for further research, removing them or even acknowledging that such removal should happen is more challenging for some of these concepts than for others. Probabilistic argumentation is one of the approaches that can be harnessed for more accurate user modelling. The epistemic approach allows us to represent how much a given argument is believed by a given person, offering us the possibility to express more than just three agreement states. It is equipped with a wide range of postulates, including those that do not make any restrictions concerning how initial arguments should be viewed, thus potentially being more adequate for handling beliefs of the people that have not fully disclosed their opinions in comparison to Dung's semantics. The constellation approach can be used to represent the views of different people concerning the structure of the framework we are dealing with, including cases in which not all relations are acknowledged or when they are seen differently than intended. Finally, bipolar argumentation frameworks can be used to express both positive and negative relations between arguments. In this paper we describe the results of an experiment in which participants judged dialogues in terms of agreement and structure. We compare our findings with the aforementioned assumptions as well as with the constellation and epistemic approaches to probabilistic argumentation and bipolar argumentation.\n    ",
        "submission_date": "2017-07-28T00:00:00",
        "last_modified_date": "2017-12-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.09457",
        "title": "Men Also Like Shopping: Reducing Gender Bias Amplification using Corpus-level Constraints",
        "authors": [
            "Jieyu Zhao",
            "Tianlu Wang",
            "Mark Yatskar",
            "Vicente Ordonez",
            "Kai-Wei Chang"
        ],
        "abstract": "Language is increasingly being used to define rich visual recognition problems with supporting image collections sourced from the web. Structured prediction models are used in these tasks to take advantage of correlations between co-occurring labels and visual input but risk inadvertently encoding social biases found in web corpora. In this work, we study data and models associated with multilabel object classification and visual semantic role labeling. We find that (a) datasets for these tasks contain significant gender bias and (b) models trained on these datasets further amplify existing bias. For example, the activity cooking is over 33% more likely to involve females than males in a training set, and a trained model further amplifies the disparity to 68% at test time. We propose to inject corpus-level constraints for calibrating existing structured prediction models and design an algorithm based on Lagrangian relaxation for collective inference. Our method results in almost no performance loss for the underlying recognition task but decreases the magnitude of bias amplification by 47.5% and 40.5% for multilabel classification and visual semantic role labeling, respectively.\n    ",
        "submission_date": "2017-07-29T00:00:00",
        "last_modified_date": "2017-07-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.09627",
        "title": "Learning to Infer Graphics Programs from Hand-Drawn Images",
        "authors": [
            "Kevin Ellis",
            "Daniel Ritchie",
            "Armando Solar-Lezama",
            "Joshua B. Tenenbaum"
        ],
        "abstract": "We introduce a model that learns to convert simple hand drawings into graphics programs written in a subset of \\LaTeX. The model combines techniques from deep learning and program synthesis. We learn a convolutional neural network that proposes plausible drawing primitives that explain an image. These drawing primitives are like a trace of the set of primitive commands issued by a graphics program. We learn a model that uses program synthesis techniques to recover a graphics program from that trace. These programs have constructs like variable bindings, iterative loops, or simple kinds of conditionals. With a graphics program in hand, we can correct errors made by the deep network, measure similarity between drawings by use of similar high-level geometric structures, and extrapolate drawings. Taken together these results are a step towards agents that induce useful, human-readable programs from perceptual input.\n    ",
        "submission_date": "2017-07-30T00:00:00",
        "last_modified_date": "2018-10-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.09661",
        "title": "A Vision For Continuous Automated Game Design",
        "authors": [
            "Michael Cook"
        ],
        "abstract": "ANGELINA is an automated game design system which has previously been built as a single software block which designs games from start to finish. In this paper we outline a roadmap for the development of a new version of ANGELINA, designed to iterate on games in different ways to produce a continuous creative process that will improve the quality of its work, but more importantly improve the perception of the software as being an independently creative piece of software. We provide an initial report of the system's structure here as well as results from the first working module of the system.\n    ",
        "submission_date": "2017-07-30T00:00:00",
        "last_modified_date": "2017-07-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.09704",
        "title": "Cost and Actual Causation",
        "authors": [
            "Liang Zhou"
        ],
        "abstract": "I propose the purpose our concept of actual causation serves is minimizing various cost in intervention practice. Actual causation has three features: nonredundant sufficiency, continuity and abnormality; these features correspond to the minimization of exploitative cost, exploratory cost and risk cost in intervention practice. Incorporating these three features, a definition of actual causation is given. I test the definition in 66 causal cases from actual causation literature and show that this definition's application fit intuition better than some other causal modelling based definitions.\n    ",
        "submission_date": "2017-07-31T00:00:00",
        "last_modified_date": "2017-07-31T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.09706",
        "title": "Developing Knowledge-enhanced Chronic Disease Risk Prediction Models from Regional EHR Repositories",
        "authors": [
            "Jing Mei",
            "Eryu Xia",
            "Xiang Li",
            "Guotong Xie"
        ],
        "abstract": "Precision medicine requires the precision disease risk prediction models. In literature, there have been a lot well-established (inter-)national risk models, but when applying them into the local population, the prediction performance becomes unsatisfactory. To address the localization issue, this paper exploits the way to develop knowledge-enhanced localized risk models. On the one hand, we tune models by learning from regional Electronic Health Record (EHR) repositories, and on the other hand, we propose knowledge injection into the EHR data learning process. For experiments, we leverage the Pooled Cohort Equations (PCE, as recommended in ACC/AHA guidelines to estimate the risk of ASCVD) to develop a localized ASCVD risk prediction model in diabetes. The experimental results show that, if directly using the PCE algorithm on our cohort, the AUC is only 0.653, while our knowledge-enhanced localized risk model can achieve higher prediction performance with AUC of 0.723 (improved by 10.7%).\n    ",
        "submission_date": "2017-07-31T00:00:00",
        "last_modified_date": "2017-07-31T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.09790",
        "title": "Evaluating Music Recommender Systems for Groups",
        "authors": [
            "Zsolt Mezei",
            "Carsten Eickhoff"
        ],
        "abstract": "Recommendation to groups of users is a challenging and currently only passingly studied task. Especially the evaluation aspect often appears ad-hoc and instead of truly evaluating on groups of users, synthesizes groups by merging individual preferences.\n",
        "submission_date": "2017-07-31T00:00:00",
        "last_modified_date": "2017-07-31T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.00102",
        "title": "Advantages and Limitations of using Successor Features for Transfer in Reinforcement Learning",
        "authors": [
            "Lucas Lehnert",
            "Stefanie Tellex",
            "Michael L. Littman"
        ],
        "abstract": "One question central to Reinforcement Learning is how to learn a feature representation that supports algorithm scaling and re-use of learned information from different tasks. Successor Features approach this problem by learning a feature representation that satisfies a temporal constraint. We present an implementation of an approach that decouples the feature representation from the reward function, making it suitable for transferring knowledge between domains. We then assess the advantages and limitations of using Successor Features for transfer.\n    ",
        "submission_date": "2017-07-31T00:00:00",
        "last_modified_date": "2017-07-31T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.00109",
        "title": "A Labelling Framework for Probabilistic Argumentation",
        "authors": [
            "Regis Riveret",
            "Pietro Baroni",
            "Yang Gao",
            "Guido Governatori",
            "Antonino Rotolo",
            "Giovanni Sartor"
        ],
        "abstract": "The combination of argumentation and probability paves the way to new accounts of qualitative and quantitative uncertainty, thereby offering new theoretical and applicative opportunities. Due to a variety of interests, probabilistic argumentation is approached in the literature with different frameworks, pertaining to structured and abstract argumentation, and with respect to diverse types of uncertainty, in particular the uncertainty on the credibility of the premises, the uncertainty about which arguments to consider, and the uncertainty on the acceptance status of arguments or statements. Towards a general framework for probabilistic argumentation, we investigate a labelling-oriented framework encompassing a basic setting for rule-based argumentation and its (semi-) abstract account, along with diverse types of uncertainty. Our framework provides a systematic treatment of various kinds of uncertainty and of their relationships and allows us to back or question assertions from the literature.\n    ",
        "submission_date": "2017-08-01T00:00:00",
        "last_modified_date": "2018-03-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.00376",
        "title": "Using Program Induction to Interpret Transition System Dynamics",
        "authors": [
            "Svetlin Penkov",
            "Subramanian Ramamoorthy"
        ],
        "abstract": "Explaining and reasoning about processes which underlie observed black-box phenomena enables the discovery of causal mechanisms, derivation of suitable abstract representations and the formulation of more robust predictions. We propose to learn high level functional programs in order to represent abstract models which capture the invariant structure in the observed data. We introduce the $\\pi$-machine (program-induction machine) -- an architecture able to induce interpretable LISP-like programs from observed data traces. We propose an optimisation procedure for program learning based on backpropagation, gradient descent and A* search. We apply the proposed method to two problems: system identification of dynamical systems and explaining the behaviour of a DQN agent. Our results show that the $\\pi$-machine can efficiently induce interpretable programs from individual data traces.\n    ",
        "submission_date": "2017-07-26T00:00:00",
        "last_modified_date": "2017-07-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.00463",
        "title": "Hierarchical Subtask Discovery With Non-Negative Matrix Factorization",
        "authors": [
            "Adam C. Earle",
            "Andrew M. Saxe",
            "Benjamin Rosman"
        ],
        "abstract": "Hierarchical reinforcement learning methods offer a powerful means of planning flexible behavior in complicated domains. However, learning an appropriate hierarchical decomposition of a domain into subtasks remains a substantial challenge. We present a novel algorithm for subtask discovery, based on the recently introduced multitask linearly-solvable Markov decision process (MLMDP) framework. The MLMDP can perform never-before-seen tasks by representing them as a linear combination of a previously learned basis set of tasks. In this setting, the subtask discovery problem can naturally be posed as finding an optimal low-rank approximation of the set of tasks the agent will face in a domain. We use non-negative matrix factorization to discover this minimal basis set of tasks, and show that the technique learns intuitive decompositions in a variety of domains. Our method has several qualitatively desirable features: it is not limited to learning subtasks with single goal states, instead learning distributed patterns of preferred states; it learns qualitatively different hierarchical decompositions in the same domain depending on the ensemble of tasks the agent will face; and it may be straightforwardly iterated to obtain deeper hierarchical decompositions.\n    ",
        "submission_date": "2017-08-01T00:00:00",
        "last_modified_date": "2017-08-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.00543",
        "title": "Balancing Explicability and Explanation in Human-Aware Planning",
        "authors": [
            "Tathagata Chakraborti",
            "Sarath Sreedharan",
            "Subbarao Kambhampati"
        ],
        "abstract": "Human aware planning requires an agent to be aware of the intentions, capabilities and mental model of the human in the loop during its decision process. This can involve generating plans that are explicable to a human observer as well as the ability to provide explanations when such plans cannot be generated. This has led to the notion \"multi-model planning\" which aim to incorporate effects of human expectation in the deliberative process of a planner - either in the form of explicable task planning or explanations produced thereof. In this paper, we bring these two concepts together and show how a planner can account for both these needs and achieve a trade-off during the plan generation process itself by means of a model-space search method MEGA. This in effect provides a comprehensive perspective of what it means for a decision making agent to be \"human-aware\" by bringing together existing principles of planning under the umbrella of a single plan generation process. We situate our discussion specifically keeping in mind the recent work on explicable planning and explanation generation, and illustrate these concepts in modified versions of two well known planning domains, as well as a demonstration on a robot involved in a typical search and reconnaissance task with an external supervisor.\n    ",
        "submission_date": "2017-08-01T00:00:00",
        "last_modified_date": "2018-02-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.00588",
        "title": "Hidden Physics Models: Machine Learning of Nonlinear Partial Differential Equations",
        "authors": [
            "Maziar Raissi",
            "George Em Karniadakis"
        ],
        "abstract": "While there is currently a lot of enthusiasm about \"big data\", useful data is usually \"small\" and expensive to acquire. In this paper, we present a new paradigm of learning partial differential equations from {\\em small} data. In particular, we introduce \\emph{hidden physics models}, which are essentially data-efficient learning machines capable of leveraging the underlying laws of physics, expressed by time dependent and nonlinear partial differential equations, to extract patterns from high-dimensional data generated from experiments. The proposed methodology may be applied to the problem of learning, system identification, or data-driven discovery of partial differential equations. Our framework relies on Gaussian processes, a powerful tool for probabilistic inference over functions, that enables us to strike a balance between model complexity and data fitting. The effectiveness of the proposed approach is demonstrated through a variety of canonical problems, spanning a number of scientific domains, including the Navier-Stokes, Schr\u00f6dinger, Kuramoto-Sivashinsky, and time dependent linear fractional equations. The methodology provides a promising new direction for harnessing the long-standing developments of classical methods in applied mathematics and mathematical physics to design learning machines with the ability to operate in complex domains without requiring large quantities of data.\n    ",
        "submission_date": "2017-08-02T00:00:00",
        "last_modified_date": "2017-08-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.00667",
        "title": "Deep Reinforcement Learning for Inquiry Dialog Policies with Logical Formula Embeddings",
        "authors": [
            "Takuya Hiraoka",
            "Masaaki Tsuchida",
            "Yotaro Watanabe"
        ],
        "abstract": "This paper is the first attempt to learn the policy of an inquiry dialog system (IDS) by using deep reinforcement learning (DRL). Most IDS frameworks represent dialog states and dialog acts with logical formulae. In order to make learning inquiry dialog policies more effective, we introduce a logical formula embedding framework based on a recursive neural network. The results of experiments to evaluate the effect of 1) the DRL and 2) the logical formula embedding framework show that the combination of the two are as effective or even better than existing rule-based methods for inquiry dialog policies.\n    ",
        "submission_date": "2017-08-02T00:00:00",
        "last_modified_date": "2017-08-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.00730",
        "title": "Helping AI to Play Hearthstone: AAIA'17 Data Mining Challenge",
        "authors": [
            "Andrzej Janusz",
            "Maciej \u015awiechowski",
            "Tomasz Tajmajer"
        ],
        "abstract": "This paper summarizes the AAIA'17 Data Mining Challenge: Helping AI to Play Hearthstone which was held between March 23, and May 15, 2017 at the Knowledge Pit platform. We briefly describe the scope and background of this competition in the context of a more general project related to the development of an AI engine for video games, called Grail. We also discuss the outcomes of this challenge and demonstrate how predictive models for the assessment of player's winning chances can be utilized in a construction of an intelligent agent for playing Hearthstone. Finally, we show a few selected machine learning approaches for modeling state and action values in Hearthstone. We provide evaluation for a few promising solutions that may be used to create more advanced types of agents, especially in conjunction with Monte Carlo Tree Search algorithms.\n    ",
        "submission_date": "2017-08-02T00:00:00",
        "last_modified_date": "2017-08-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.00754",
        "title": "Fairness-aware machine learning: a perspective",
        "authors": [
            "Indre Zliobaite"
        ],
        "abstract": "Algorithms learned from data are increasingly used for deciding many aspects in our life: from movies we see, to prices we pay, or medicine we get. Yet there is growing evidence that decision making by inappropriately trained algorithms may unintentionally discriminate people. For example, in automated matching of candidate CVs with job descriptions, algorithms may capture and propagate ethnicity related biases. Several repairs for selected algorithms have already been proposed, but the underlying mechanisms how such discrimination happens from the computational perspective are not yet scientifically understood. We need to develop theoretical understanding how algorithms may become discriminatory, and establish fundamental machine learning principles for prevention. We need to analyze machine learning process as a whole to systematically explain the roots of discrimination occurrence, which will allow to devise global machine learning optimization criteria for guaranteed prevention, as opposed to pushing empirical constraints into existing algorithms case-by-case. As a result, the state-of-the-art will advance from heuristic repairing, to proactive and theoretically supported prevention. This is needed not only because law requires to protect vulnerable people. Penetration of big data initiatives will only increase, and computer science needs to provide solid explanations and accountability to the public, before public concerns lead to unnecessarily restrictive regulations against machine learning.\n    ",
        "submission_date": "2017-08-02T00:00:00",
        "last_modified_date": "2017-08-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.01035",
        "title": "Detection of Abnormal Input-Output Associations",
        "authors": [
            "Charmgil Hong",
            "Siqi Liu",
            "Milos Hauskrecht"
        ],
        "abstract": "We study a novel outlier detection problem that aims to identify abnormal input-output associations in data, whose instances consist of multi-dimensional input (context) and output (responses) pairs. We present our approach that works by analyzing data in the conditional (input--output) relation space, captured by a decomposable probabilistic model. Experimental results demonstrate the ability of our approach in identifying multivariate conditional outliers.\n    ",
        "submission_date": "2017-08-03T00:00:00",
        "last_modified_date": "2017-08-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.01104",
        "title": "A glass-box interactive machine learning approach for solving NP-hard problems with the human-in-the-loop",
        "authors": [
            "Andreas Holzinger",
            "Markus Plass",
            "Katharina Holzinger",
            "Gloria Cerasela Crisan",
            "Camelia-M. Pintea",
            "Vasile Palade"
        ],
        "abstract": "The goal of Machine Learning to automatically learn from data, extract knowledge and to make decisions without any human intervention. Such automatic (aML) approaches show impressive success. Recent results even demonstrate intriguingly that deep learning applied for automatic classification of skin lesions is on par with the performance of dermatologists, yet outperforms the average. As human perception is inherently limited, such approaches can discover patterns, e.g. that two objects are similar, in arbitrarily high-dimensional spaces what no human is able to do. Humans can deal only with limited amounts of data, whilst big data is beneficial for aML; however, in health informatics, we are often confronted with a small number of data sets, where aML suffer of insufficient training samples and many problems are computationally hard. Here, interactive machine learning (iML) may be of help, where a human-in-the-loop contributes to reduce the complexity of NP-hard problems. A further motivation for iML is that standard black-box approaches lack transparency, hence do not foster trust and acceptance of ML among end-users. Rising legal and privacy aspects, e.g. with the new European General Data Protection Regulations, make black-box approaches difficult to use, because they often are not able to explain why a decision has been made. In this paper, we present some experiments to demonstrate the effectiveness of the human-in-the-loop approach, particularly in opening the black-box to a glass-box and thus enabling a human directly to interact with an learning algorithm. We selected the Ant Colony Optimization framework, and applied it on the Traveling Salesman Problem, which is a good example, due to its relevance for health informatics, e.g. for the study of protein folding. From studies of how humans extract so much from so little data, fundamental ML-research also may benefit.\n    ",
        "submission_date": "2017-08-03T00:00:00",
        "last_modified_date": "2017-08-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.01791",
        "title": "Thompson Sampling Guided Stochastic Searching on the Line for Deceptive Environments with Applications to Root-Finding Problems",
        "authors": [
            "Sondre Glimsdal",
            "Ole-Christoffer Granmo"
        ],
        "abstract": "The multi-armed bandit problem forms the foundation for solving a wide range of on-line stochastic optimization problems through a simple, yet effective mechanism. One simply casts the problem as a gambler that repeatedly pulls one out of N slot machine arms, eliciting random rewards. Learning of reward probabilities is then combined with reward maximization, by carefully balancing reward exploration against reward exploitation. In this paper, we address a particularly intriguing variant of the multi-armed bandit problem, referred to as the {\\it Stochastic Point Location (SPL) Problem}. The gambler is here only told whether the optimal arm (point) lies to the \"left\" or to the \"right\" of the arm pulled, with the feedback being erroneous with probability $1-\\pi$. This formulation thus captures optimization in continuous action spaces with both {\\it informative} and {\\it deceptive} feedback. To tackle this class of problems, we formulate a compact and scalable Bayesian representation of the solution space that simultaneously captures both the location of the optimal arm as well as the probability of receiving correct feedback. We further introduce the accompanying Thompson Sampling guided Stochastic Point Location (TS-SPL) scheme for balancing exploration against exploitation. By learning $\\pi$, TS-SPL also supports {\\it deceptive} environments that are lying about the direction of the optimal arm. This, in turn, allows us to solve the fundamental Stochastic Root Finding (SRF) Problem. Empirical results demonstrate that our scheme deals with both deceptive and informative environments, significantly outperforming competing algorithms both for SRF and SPL.\n    ",
        "submission_date": "2017-08-05T00:00:00",
        "last_modified_date": "2017-08-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.01829",
        "title": "Declarative Statistics",
        "authors": [
            "Roberto Rossi",
            "\u00d6zg\u00fcr Akg\u00fcn",
            "Steven Prestwich",
            "S. Armagan Tarim"
        ],
        "abstract": "In this work we introduce declarative statistics, a suite of declarative modelling tools for statistical analysis. Statistical constraints represent the key building block of declarative statistics. First, we introduce a range of relevant counting and matrix constraints and associated decompositions, some of which novel, that are instrumental in the design of statistical constraints. Second, we introduce a selection of novel statistical constraints and associated decompositions, which constitute a self-contained toolbox that can be used to tackle a wide range of problems typically encountered by statisticians. Finally, we deploy these statistical constraints to a wide range of application areas drawn from classical statistics and we contrast our framework against established practices.\n    ",
        "submission_date": "2017-08-06T00:00:00",
        "last_modified_date": "2017-12-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.01867",
        "title": "An Information-Theoretic Optimality Principle for Deep Reinforcement Learning",
        "authors": [
            "Felix Leibfried",
            "Jordi Grau-Moya",
            "Haitham Bou-Ammar"
        ],
        "abstract": "We methodologically address the problem of Q-value overestimation in deep reinforcement learning to handle high-dimensional state spaces efficiently. By adapting concepts from information theory, we introduce an intrinsic penalty signal encouraging reduced Q-value estimates. The resultant algorithm encompasses a wide range of learning outcomes containing deep Q-networks as a special case. Different learning outcomes can be demonstrated by tuning a Lagrange multiplier accordingly. We furthermore propose a novel scheduling scheme for this Lagrange multiplier to ensure efficient and robust learning. In experiments on Atari, our algorithm outperforms other algorithms (e.g. deep and double deep Q-networks) in terms of both game-play performance and sample complexity. These results remain valid under the recently proposed dueling architecture.\n    ",
        "submission_date": "2017-08-06T00:00:00",
        "last_modified_date": "2018-11-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.01930",
        "title": "Enhanced Emotion Enabled Cognitive Agent Based Rear End Collision Avoidance Controller for Autonomous Vehicles",
        "authors": [
            "Faisal Riaz",
            "Muaz A. Niazi"
        ],
        "abstract": "Rear end collisions are deadliest in nature and cause most of traffic casualties and injuries. In the existing research, many rear end collision avoidance solutions have been proposed. However, the problem with these proposed solutions is that they are highly dependent on precise mathematical models. Whereas, the real road driving is influenced by non-linear factors such as road surface situations, driver reaction time, pedestrian flow and vehicle dynamics, hence obtaining the accurate mathematical model of the vehicle control system is challenging. This problem with precise control based rear end collision avoidance schemes has been addressed using fuzzy logic, but the excessive number of fuzzy rules straightforwardly prejudice their efficiency. Furthermore, these fuzzy logic based controllers have been proposed without using proper agent based modeling that helps in mimicking the functions of an artificial human driver executing these fuzzy rules. Keeping in view these limitations, we have proposed an Enhanced Emotion Enabled Cognitive Agent (EEEC_Agent) based controller that helps the Autonomous Vehicles (AVs) to perform rear end collision avoidance with less number of rules, designed after fear emotion, and high efficiency. To introduce a fear emotion generation mechanism in EEEC_Agent, Orton, Clore & Collins (OCC) model has been employed. The fear generation mechanism of EEEC_Agent has been verified using NetLogo simulation. Furthermore, practical validation of EEEC_Agent functions has been performed using specially built prototype AV platform. Eventually, the qualitative comparative study with existing state of the art research works reflect that proposed model outperforms recent research.\n    ",
        "submission_date": "2017-08-06T00:00:00",
        "last_modified_date": "2017-08-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.01931",
        "title": "Towards Social Autonomous Vehicles: Efficient Collision Avoidance Scheme Using Richardson's Arms Race Model",
        "authors": [
            "Faisal Riaz",
            "Muaz A. Niazi"
        ],
        "abstract": "Background Road collisions and casualties pose a serious threat to commuters around the globe. Autonomous Vehicles (AVs) aim to make the use of technology to reduce the road accidents. However, the most of research work in the context of collision avoidance has been performed to address, separately, the rear end, front end and lateral collisions in less congested and with high inter-vehicular distances. Purpose The goal of this paper is to introduce the concept of a social agent, which interact with other AVs in social manners like humans are social having the capability of predicting intentions, i.e. mentalizing and copying the actions of each other, i.e. mirroring. The proposed social agent is based on a human-brain inspired mentalizing and mirroring capabilities and has been modelled for collision detection and avoidance under congested urban road traffic.\n",
        "submission_date": "2017-08-06T00:00:00",
        "last_modified_date": "2017-08-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.02072",
        "title": "Measuring Catastrophic Forgetting in Neural Networks",
        "authors": [
            "Ronald Kemker",
            "Marc McClure",
            "Angelina Abitino",
            "Tyler Hayes",
            "Christopher Kanan"
        ],
        "abstract": "Deep neural networks are used in many state-of-the-art systems for machine perception. Once a network is trained to do a specific task, e.g., bird classification, it cannot easily be trained to do new tasks, e.g., incrementally learning to recognize additional bird species or learning an entirely different task such as flower recognition. When new tasks are added, typical deep neural networks are prone to catastrophically forgetting previous tasks. Networks that are capable of assimilating new information incrementally, much like how humans form new memories over time, will be more efficient than re-training the model from scratch each time a new task needs to be learned. There have been multiple attempts to develop schemes that mitigate catastrophic forgetting, but these methods have not been directly compared, the tests used to evaluate them vary considerably, and these methods have only been evaluated on small-scale problems (e.g., MNIST). In this paper, we introduce new metrics and benchmarks for directly comparing five different mechanisms designed to mitigate catastrophic forgetting in neural networks: regularization, ensembling, rehearsal, dual-memory, and sparse-coding. Our experiments on real-world images and sounds show that the mechanism(s) that are critical for optimal performance vary based on the incremental training paradigm and type of data being used, but they all demonstrate that the catastrophic forgetting problem has yet to be solved.\n    ",
        "submission_date": "2017-08-07T00:00:00",
        "last_modified_date": "2017-11-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.02139",
        "title": "STARDATA: A StarCraft AI Research Dataset",
        "authors": [
            "Zeming Lin",
            "Jonas Gehring",
            "Vasil Khalidov",
            "Gabriel Synnaeve"
        ],
        "abstract": "We release a dataset of 65646 StarCraft replays that contains 1535 million frames and 496 million player actions. We provide full game state data along with the original replays that can be viewed in StarCraft. The game state data was recorded every 3 frames which ensures suitability for a wide variety of machine learning tasks such as strategy classification, inverse reinforcement learning, imitation learning, forward modeling, partial information extraction, and others. We use TorchCraft to extract and store the data, which standardizes the data format for both reading from replays and reading directly from the game. Furthermore, the data can be used on different operating systems and platforms. The dataset contains valid, non-corrupted replays only and its quality and diversity was ensured by a number of heuristics. We illustrate the diversity of the data with various statistics and provide examples of tasks that benefit from the dataset. We make the dataset available at ",
        "submission_date": "2017-08-07T00:00:00",
        "last_modified_date": "2017-08-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.02153",
        "title": "Axiomatic Characterization of Data-Driven Influence Measures for Classification",
        "authors": [
            "Jakub Sliwinski",
            "Martin Strobel",
            "Yair Zick"
        ],
        "abstract": "We study the following problem: given a labeled dataset and a specific datapoint x, how did the i-th feature influence the classification for x? We identify a family of numerical influence measures - functions that, given a datapoint x, assign a numeric value phi_i(x) to every feature i, corresponding to how altering i's value would influence the outcome for x. This family, which we term monotone influence measures (MIM), is uniquely derived from a set of desirable properties, or axioms. The MIM family constitutes a provably sound methodology for measuring feature influence in classification domains; the values generated by MIM are based on the dataset alone, and do not make any queries to the classifier. While this requirement naturally limits the scope of our framework, we demonstrate its effectiveness on data.\n    ",
        "submission_date": "2017-08-07T00:00:00",
        "last_modified_date": "2018-11-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.02167",
        "title": "Regulating Highly Automated Robot Ecologies: Insights from Three User Studies",
        "authors": [
            "Wen Shen",
            "Alanoud Al Khemeiri",
            "Abdulla Almehrezi",
            "Wael Al Enezi",
            "Iyad Rahwan",
            "Jacob W. Crandall"
        ],
        "abstract": "Highly automated robot ecologies (HARE), or societies of independent autonomous robots or agents, are rapidly becoming an important part of much of the world's critical infrastructure. As with human societies, regulation, wherein a governing body designs rules and processes for the society, plays an important role in ensuring that HARE meet societal objectives. However, to date, a careful study of interactions between a regulator and HARE is lacking. In this paper, we report on three user studies which give insights into how to design systems that allow people, acting as the regulatory authority, to effectively interact with HARE. As in the study of political systems in which governments regulate human societies, our studies analyze how interactions between HARE and regulators are impacted by regulatory power and individual (robot or agent) autonomy. Our results show that regulator power, decision support, and adaptive autonomy can each diminish the social welfare of HARE, and hint at how these seemingly desirable mechanisms can be designed so that they become part of successful HARE.\n    ",
        "submission_date": "2017-08-07T00:00:00",
        "last_modified_date": "2017-08-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.02190",
        "title": "Intrinsically Motivated Goal Exploration Processes with Automatic Curriculum Learning",
        "authors": [
            "S\u00e9bastien Forestier",
            "R\u00e9my Portelas",
            "Yoan Mollard",
            "Pierre-Yves Oudeyer"
        ],
        "abstract": "Intrinsically motivated spontaneous exploration is a key enabler of autonomous developmental learning in human children. It enables the discovery of skill repertoires through autotelic learning, i.e. the self-generation, self-selection, self-ordering and self-experimentation of learning goals. We present an algorithmic approach called Intrinsically Motivated Goal Exploration Processes (IMGEP) to enable similar properties of autonomous learning in machines. The IMGEP architecture relies on several principles: 1) self-generation of goals, generalized as parameterized fitness functions; 2) selection of goals based on intrinsic rewards; 3) exploration with incremental goal-parameterized policy search and exploitation with a batch learning algorithm; 4) systematic reuse of information acquired when targeting a goal for improving towards other goals. We present a particularly efficient form of IMGEP, called AMB, that uses a population-based policy and an object-centered spatio-temporal modularity. We provide several implementations of this architecture and demonstrate their ability to automatically generate a learning curriculum within several experimental setups. One of these experiments includes a real humanoid robot exploring multiple spaces of goals with several hundred continuous dimensions and with distractors. While no particular target goal is provided to these autotelic agents, this curriculum allows the discovery of diverse skills that act as stepping stones for learning more complex skills, e.g. nested tool use.\n    ",
        "submission_date": "2017-08-07T00:00:00",
        "last_modified_date": "2022-05-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.02255",
        "title": "Generative Statistical Models with Self-Emergent Grammar of Chord Sequences",
        "authors": [
            "Hiroaki Tsushima",
            "Eita Nakamura",
            "Katsutoshi Itoyama",
            "Kazuyoshi Yoshii"
        ],
        "abstract": "Generative statistical models of chord sequences play crucial roles in music processing. To capture syntactic similarities among certain chords (e.g. in C major key, between G and G7 and between F and Dm), we study hidden Markov models and probabilistic context-free grammar models with latent variables describing syntactic categories of chord symbols and their unsupervised learning techniques for inducing the latent grammar from data. Surprisingly, we find that these models often outperform conventional Markov models in predictive power, and the self-emergent categories often correspond to traditional harmonic functions. This implies the need for chord categories in harmony models from the informatics perspective.\n    ",
        "submission_date": "2017-08-07T00:00:00",
        "last_modified_date": "2018-03-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.02314",
        "title": "Multibiometric Secure System Based on Deep Learning",
        "authors": [
            "Veeru Talreja",
            "Matthew C. Valenti",
            "Nasser M. Nasrabadi"
        ],
        "abstract": "In this paper, we propose a secure multibiometric system that uses deep neural networks and error-correction coding. We present a feature-level fusion framework to generate a secure multibiometric template from each user's multiple biometrics. Two fusion architectures, fully connected architecture and bilinear architecture, are implemented to develop a robust multibiometric shared representation. The shared representation is used to generate a cancelable biometric template that involves the selection of a different set of reliable and discriminative features for each user. This cancelable template is a binary vector and is passed through an appropriate error-correcting decoder to find a closest codeword and this codeword is hashed to generate the final secure template. The efficacy of the proposed approach is shown using a multimodal database where we achieve state-of-the-art matching performance, along with cancelability and security.\n    ",
        "submission_date": "2017-08-07T00:00:00",
        "last_modified_date": "2017-08-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.02378",
        "title": "Investigating Reinforcement Learning Agents for Continuous State Space Environments",
        "authors": [
            "David Von Dollen"
        ],
        "abstract": "Given an environment with continuous state spaces and discrete actions, we investigate using a Double Deep Q-learning Reinforcement Agent to find optimal policies using the LunarLander-v2 OpenAI gym environment.\n    ",
        "submission_date": "2017-08-08T00:00:00",
        "last_modified_date": "2019-03-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.02553",
        "title": "Robust Computer Algebra, Theorem Proving, and Oracle AI",
        "authors": [
            "Gopal P. Sarma",
            "Nick J. Hay"
        ],
        "abstract": "In the context of superintelligent AI systems, the term \"oracle\" has two meanings. One refers to modular systems queried for domain-specific tasks. Another usage, referring to a class of systems which may be useful for addressing the value alignment and AI control problems, is a superintelligent AI system that only answers questions. The aim of this manuscript is to survey contemporary research problems related to oracles which align with long-term research goals of AI safety. We examine existing question answering systems and argue that their high degree of architectural heterogeneity makes them poor candidates for rigorous analysis as oracles. On the other hand, we identify computer algebra systems (CASs) as being primitive examples of domain-specific oracles for mathematics and argue that efforts to integrate computer algebra systems with theorem provers, systems which have largely been developed independent of one another, provide a concrete set of problems related to the notion of provable safety that has emerged in the AI safety community. We review approaches to interfacing CASs with theorem provers, describe well-defined architectural deficiencies that have been identified with CASs, and suggest possible lines of research and practical software projects for scientists interested in AI safety.\n    ",
        "submission_date": "2017-08-08T00:00:00",
        "last_modified_date": "2017-12-31T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.02654",
        "title": "Cheryl's Birthday",
        "authors": [
            "Hans van Ditmarsch",
            "Michael Ian Hartley",
            "Barteld Kooi",
            "Jonathan Welton",
            "Joseph B.W. Yeo"
        ],
        "abstract": "We present four logic puzzles and after that their solutions. Joseph Yeo designed 'Cheryl's Birthday'. Mike Hartley came up with a novel solution for 'One Hundred Prisoners and a Light Bulb'. Jonathan Welton designed 'A Blind Guess' and 'Abby's Birthday'. Hans van Ditmarsch and Barteld Kooi authored the puzzlebook 'One Hundred Prisoners and a Light Bulb' that contains other knowledge puzzles, and that can also be found on the webpage ",
        "submission_date": "2017-07-27T00:00:00",
        "last_modified_date": "2017-07-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.02747",
        "title": "An automatic water detection approach based on Dempster-Shafer theory for multi spectral images",
        "authors": [
            "Na Li",
            "Arnaud Martin",
            "R\u00e9mi Estival"
        ],
        "abstract": "Detection of surface water in natural environment via multi-spectral imagery has been widely utilized in many fields, such land cover identification. However, due to the similarity of the spectra of water bodies, built-up areas, approaches based on high-resolution satellites sometimes confuse these features. A popular direction to detect water is spectral index, often requiring the ground truth to find appropriate thresholds manually. As for traditional machine learning methods, they identify water merely via differences of spectra of various land covers, without taking specific properties of spectral reflection into account. In this paper, we propose an automatic approach to detect water bodies based on Dempster-Shafer theory, combining supervised learning with specific property of water in spectral band in a fully unsupervised context. The benefits of our approach are twofold. On the one hand, it performs well in mapping principle water bodies, including little streams and branches. On the other hand, it labels all objects usually confused with water as `ignorance', including half-dry watery areas, built-up areas and semi-transparent clouds and shadows. `Ignorance' indicates not only limitations of the spectral properties of water and supervised learning itself but insufficiency of information from multi-spectral bands as well, providing valuable information for further land cover classification.\n    ",
        "submission_date": "2017-08-09T00:00:00",
        "last_modified_date": "2017-09-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.02838",
        "title": "Decoupled Learning of Environment Characteristics for Safe Exploration",
        "authors": [
            "Pieter Van Molle",
            "Tim Verbelen",
            "Steven Bohez",
            "Sam Leroux",
            "Pieter Simoens",
            "Bart Dhoedt"
        ],
        "abstract": "Reinforcement learning is a proven technique for an agent to learn a task. However, when learning a task using reinforcement learning, the agent cannot distinguish the characteristics of the environment from those of the task. This makes it harder to transfer skills between tasks in the same environment. Furthermore, this does not reduce risk when training for a new task. In this paper, we introduce an approach to decouple the environment characteristics from the task-specific ones, allowing an agent to develop a sense of survival. We evaluate our approach in an environment where an agent must learn a sequence of collection tasks, and show that decoupled learning allows for a safer utilization of prior knowledge.\n    ",
        "submission_date": "2017-08-09T00:00:00",
        "last_modified_date": "2017-08-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.02851",
        "title": "Measuring Inconsistency in Argument Graphs",
        "authors": [
            "Anthony Hunter"
        ],
        "abstract": "There have been a number of developments in measuring inconsistency in logic-based representations of knowledge. In contrast, the development of inconsistency measures for computational models of argument has been limited. To address this shortcoming, this paper provides a general framework for measuring inconsistency in abstract argumentation, together with some proposals for specific measures, and a consideration of measuring inconsistency in logic-based instantiations of argument graphs, including a review of some existing proposals and a consideration of how existing logic-based measures of inconsistency can be applied.\n    ",
        "submission_date": "2017-08-09T00:00:00",
        "last_modified_date": "2017-08-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.02918",
        "title": "The Tensor Memory Hypothesis",
        "authors": [
            "Volker Tresp",
            "Yunpu Ma"
        ],
        "abstract": "We discuss memory models which are based on tensor decompositions using latent representations of entities and events. We show how episodic memory and semantic memory can be realized and discuss how new memory traces can be generated from sensory input: Existing memories are the basis for perception and new memories are generated via perception. We relate our mathematical approach to the hippocampal memory indexing theory. We describe the first detailed mathematical models for the complete processing pipeline from sensory input and its semantic decoding, i.e., perception, to the formation of episodic and semantic memories and their declarative semantic decodings. Our main hypothesis is that perception includes an active semantic decoding process, which relies on latent representations of entities and predicates, and that episodic and semantic memories depend on the same decoding process. We contribute to the debate between the leading memory consolidation theories, i.e., the standard consolidation theory (SCT) and the multiple trace theory (MTT). The latter is closely related to the complementary learning systems (CLS) framework. In particular, we show explicitly how episodic memory can teach the neocortex to form a semantic memory, which is a core issue in MTT and CLS.\n    ",
        "submission_date": "2017-08-09T00:00:00",
        "last_modified_date": "2017-08-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.03019",
        "title": "Addendum to: Summary Information for Reasoning About Hierarchical Plans",
        "authors": [
            "Lavindra de Silva",
            "Sebastian Sardina",
            "Lin Padgham"
        ],
        "abstract": "Hierarchically structured agent plans are important for efficient planning and acting, and they also serve (among other things) to produce \"richer\" classical plans, composed not just of a sequence of primitive actions, but also \"abstract\" ones representing the supplied hierarchies. A crucial step for this and other approaches is deriving precondition and effect \"summaries\" from a given plan hierarchy. This paper provides mechanisms to do this for more pragmatic and conventional hierarchies than in the past. To this end, we formally define the notion of a precondition and an effect for a hierarchical plan; we present data structures and algorithms for automatically deriving this information; and we analyse the properties of the presented algorithms. We conclude the paper by detailing how our algorithms may be used together with a classical planner in order to obtain abstract plans.\n    ",
        "submission_date": "2017-08-09T00:00:00",
        "last_modified_date": "2017-08-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.03151",
        "title": "The Static and Stochastic VRPTW with both random Customers and Reveal Times: algorithms and recourse strategies",
        "authors": [
            "Michael Saint-Guillain",
            "Christine Solnon",
            "Yves Deville"
        ],
        "abstract": "Unlike its deterministic counterpart, static and stochastic vehicle routing problems (SS-VRP) aim at modeling and solving real-life operational problems by considering uncertainty on data. We consider the SS-VRPTW-CR introduced in Saint-Guillain et al. (2017). Like the SS-VRP introduced by Bertsimas (1992), we search for optimal first stage routes for a fleet of vehicles to handle a set of stochastic customer demands, i.e., demands are uncertain and we only know their probabilities. In addition to capacity constraints, customer demands are also constrained by time windows. Unlike all SS-VRP variants, the SS-VRPTW-CR does not make any assumption on the time at which a stochastic demand is revealed, i.e., the reveal time is stochastic as well. To handle this new problem, we introduce waiting locations: Each vehicle is assigned a sequence of waiting locations from which it may serve some associated demands, and the objective is to minimize the expected number of demands that cannot be satisfied in time. In this paper, we propose two new recourse strategies for the SS-VRPTW-CR, together with their closed-form expressions for efficiently computing their expectations: The first one allows us to take vehicle capacities into account; The second one allows us to optimize routes by avoiding some useless trips. We propose two algorithms for searching for routes with optimal expected costs: The first one is an extended branch-and-cut algorithm, based on a stochastic integer formulation, and the second one is a local search based heuristic method. We also introduce a new public benchmark for the SS-VRPTW-CR, based on real-world data coming from the city of Lyon. We evaluate our two algorithms on this benchmark and empirically demonstrate the expected superiority of the SS-VRPTW-CR anticipative actions over a basic \"wait-and-serve\" policy.\n    ",
        "submission_date": "2017-08-10T00:00:00",
        "last_modified_date": "2017-08-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.03209",
        "title": "Tosca: Operationalizing Commitments Over Information Protocols",
        "authors": [
            "Thomas C. King",
            "Ak\u0131n G\u00fcnay",
            "Amit K. Chopra",
            "Munindar P. Singh"
        ],
        "abstract": "The notion of commitment is widely studied as a high-level abstraction for modeling multiagent interaction. An important challenge is supporting flexible decentralized enactments of commitment specifications. In this paper, we combine recent advances on specifying commitments and information protocols. Specifically, we contribute Tosca, a technique for automatically synthesizing information protocols from commitment specifications. Our main result is that the synthesized protocols support commitment alignment, which is the idea that agents must make compatible inferences about their commitments despite decentralization.\n    ",
        "submission_date": "2017-08-10T00:00:00",
        "last_modified_date": "2017-08-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.03229",
        "title": "Automatic Selection of t-SNE Perplexity",
        "authors": [
            "Yanshuai Cao",
            "Luyu Wang"
        ],
        "abstract": "t-Distributed Stochastic Neighbor Embedding (t-SNE) is one of the most widely used dimensionality reduction methods for data visualization, but it has a perplexity hyperparameter that requires manual selection. In practice, proper tuning of t-SNE perplexity requires users to understand the inner working of the method as well as to have hands-on experience. We propose a model selection objective for t-SNE perplexity that requires negligible extra computation beyond that of the t-SNE itself. We empirically validate that the perplexity settings found by our approach are consistent with preferences elicited from human experts across a number of datasets. The similarities of our approach to Bayesian information criteria (BIC) and minimum description length (MDL) are also analyzed.\n    ",
        "submission_date": "2017-08-10T00:00:00",
        "last_modified_date": "2017-08-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.03259",
        "title": "Preference fusion and Condorcet's Paradox under uncertainty",
        "authors": [
            "Yiru Zhang",
            "Tassadit Bouadi",
            "Arnaud Martin"
        ],
        "abstract": "Facing an unknown situation, a person may not be able to firmly elicit his/her preferences over different alternatives, so he/she tends to express uncertain preferences. Given a community of different persons expressing their preferences over certain alternatives under uncertainty, to get a collective representative opinion of the whole community, a preference fusion process is required. The aim of this work is to propose a preference fusion method that copes with uncertainty and escape from the Condorcet paradox. To model preferences under uncertainty, we propose to develop a model of preferences based on belief function theory that accurately describes and captures the uncertainty associated with individual or collective preferences. This work improves and extends the previous results. This work improves and extends the contribution presented in a previous work. The benefits of our contribution are twofold. On the one hand, we propose a qualitative and expressive preference modeling strategy based on belief-function theory which scales better with the number of sources. On the other hand, we propose an incremental distance-based algorithm (using Jousselme distance) for the construction of the collective preference order to avoid the Condorcet Paradox.\n    ",
        "submission_date": "2017-08-09T00:00:00",
        "last_modified_date": "2017-08-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.03310",
        "title": "Thinking, Fast and Slow: Combining Vector Spaces and Knowledge Graphs",
        "authors": [
            "Sudip Mittal",
            "Anupam Joshi",
            "Tim Finin"
        ],
        "abstract": "Knowledge graphs and vector space models are robust knowledge representation techniques with individual strengths and weaknesses. Vector space models excel at determining similarity between concepts, but are severely constrained when evaluating complex dependency relations and other logic-based operations that are a strength of knowledge graphs. We describe the VKG structure that helps unify knowledge graphs and vector representation of entities, and enables powerful inference methods and search capabilities that combine their complementary strengths. We analogize this to thinking `fast' in vector space along with thinking 'slow' and `deeply' by reasoning over the knowledge graph. We have created a query processing engine that takes complex queries and decomposes them into subqueries optimized to run on the respective knowledge graph or vector view of a VKG. We show that the VKG structure can process specific queries that are not efficiently handled by vector spaces or knowledge graphs alone. We also demonstrate and evaluate the VKG structure and the query processing engine by developing a system called Cyber-All-Intel for knowledge extraction, representation and querying in an end-to-end pipeline grounded in the cybersecurity informatics domain.\n    ",
        "submission_date": "2017-08-10T00:00:00",
        "last_modified_date": "2017-08-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.03341",
        "title": "Technical Problems With \"Programmable self-assembly in a thousand-robot swarm\"",
        "authors": [
            "Muaz A. Niazi"
        ],
        "abstract": "Rubenstein et al. present an interesting system of programmable self-assembled structure formation using 1000 Kilobot robots. The paper claims to advance work in artificial swarms similar to capabilities of natural systems besides being highly robust. However, the system lacks in terms of matching motility and complex shapes with holes, thereby limiting practical similarity to self-assembly in living systems.\n    ",
        "submission_date": "2017-08-10T00:00:00",
        "last_modified_date": "2017-08-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.03901",
        "title": "Belief Tree Search for Active Object Recognition",
        "authors": [
            "Mohsen Malmir",
            "Garrison W. Cottrell"
        ],
        "abstract": "Active Object Recognition (AOR) has been approached as an unsupervised learning problem, in which optimal trajectories for object inspection are not known and are to be discovered by reducing label uncertainty measures or training with reinforcement learning. Such approaches have no guarantees of the quality of their solution. In this paper, we treat AOR as a Partially Observable Markov Decision Process (POMDP) and find near-optimal policies on training data using Belief Tree Search (BTS) on the corresponding belief Markov Decision Process (MDP). AOR then reduces to the problem of knowledge transfer from near-optimal policies on training set to the test set. We train a Long Short Term Memory (LSTM) network to predict the best next action on the training set rollouts. We sho that the proposed AOR method generalizes well to novel views of familiar objects and also to novel objects. We compare this supervised scheme against guided policy search, and find that the LSTM network reaches higher recognition accuracy compared to the guided policy method. We further look into optimizing the observation function to increase the total collected reward of optimal policy. In AOR, the observation function is known only approximately. We propose a gradient-based method update to this approximate observation function to increase the total reward of any policy. We show that by optimizing the observation function and retraining the supervised LSTM network, the AOR performance on the test set improves significantly.\n    ",
        "submission_date": "2017-08-13T00:00:00",
        "last_modified_date": "2017-08-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.03993",
        "title": "Optimizing Gross Merchandise Volume via DNN-MAB Dynamic Ranking Paradigm",
        "authors": [
            "Yan Yan",
            "Wentao Guo",
            "Meng Zhao",
            "Jinghe Hu",
            "Weipeng P. Yan"
        ],
        "abstract": "With the transition from people's traditional `brick-and-mortar' shopping to online mobile shopping patterns in web 2.0 $\\mathit{era}$, the recommender system plays a critical role in E-Commerce and E-Retails. This is especially true when designing this system for more than $\\mathbf{236~million}$ daily active users. Ranking strategy, the key module of the recommender system, needs to be precise, accurate, and responsive for estimating customers' intents. We propose a dynamic ranking paradigm, named as DNN-MAB, that is composed of a pairwise deep neural network (DNN) $\\mathit{pre}$-ranker connecting a revised multi-armed bandit (MAB) dynamic $\\mathit{post}$-ranker. By taking into account of explicit and implicit user feedbacks such as impressions, clicks, conversions, etc. DNN-MAB is able to adjust DNN $\\mathit{pre}$-ranking scores to assist customers locating items they are interested in most so that they can converge quickly and frequently. To the best of our knowledge, frameworks like DNN-MAB have not been discussed in the previous literature to either E-Commerce or machine learning audiences. In practice, DNN-MAB has been deployed to production and it easily outperforms against other state-of-the-art models by significantly lifting the gross merchandise volume (GMV) which is the objective metrics at JD.\n    ",
        "submission_date": "2017-08-14T00:00:00",
        "last_modified_date": "2017-08-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.04196",
        "title": "Understanding and Visualizing the District of Columbia Capital Bikeshare System Using Data Analysis for Balancing Purposes",
        "authors": [
            "Kiana Roshan Zamir",
            "Ali Shafahi",
            "Ali Haghani"
        ],
        "abstract": "Bike sharing systems' popularity has consistently been rising during the past years. Managing and maintaining these emerging systems are indispensable parts of these systems. Visualizing the current operations can assist in getting a better grasp on the performance of the system. In this paper, a data mining approach is used to identify and visualize some important factors related to bike-share operations and management. To consolidate the data, we cluster stations that have a similar pickup and drop-off profiles during weekdays and weekends. We provide the temporal profile of the center of each cluster which can be used as a simple and practical approach for approximating the number of pickups and drop-offs of the stations. We also define two indices based on stations' shortages and surpluses that reflect the degree of balancing aid a station needs. These indices can help stakeholders improve the quality of the bike-share user experience in at-least two ways. It can act as a complement to balancing optimization efforts, and it can identify stations that need expansion. We mine the District of Columbia's regional bike-share data and discuss the findings of this data set. We examine the bike-share system during different quarters of the year and during both peak and non-peak hours. Findings reflect that on weekdays most of the pickups and drop-offs happen during the morning and evening peaks whereas on weekends pickups and drop-offs are spread out throughout the day. We also show that throughout the day, more than 40% of the stations are relatively self-balanced. Not worrying about these stations during ordinary days can allow the balancing efforts to focus on a fewer stations and therefore potentially improve the efficiency of the balancing optimization models.\n    ",
        "submission_date": "2017-08-14T00:00:00",
        "last_modified_date": "2017-08-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.04202",
        "title": "Learning to Plan Chemical Syntheses",
        "authors": [
            "Marwin H.S. Segler",
            "Mike Preuss",
            "Mark P. Waller"
        ],
        "abstract": "From medicines to materials, small organic molecules are indispensable for human well-being. To plan their syntheses, chemists employ a problem solving technique called retrosynthesis. In retrosynthesis, target molecules are recursively transformed into increasingly simpler precursor compounds until a set of readily available starting materials is obtained. Computer-aided retrosynthesis would be a highly valuable tool, however, past approaches were slow and provided results of unsatisfactory quality. Here, we employ Monte Carlo Tree Search (MCTS) to efficiently discover retrosynthetic routes. MCTS was combined with an expansion policy network that guides the search, and an \"in-scope\" filter network to pre-select the most promising retrosynthetic steps. These deep neural networks were trained on 12 million reactions, which represents essentially all reactions ever published in organic chemistry. Our system solves almost twice as many molecules and is 30 times faster in comparison to the traditional search method based on extracted rules and hand-coded heuristics. Finally after a 60 year history of computer-aided synthesis planning, chemists can no longer distinguish between routes generated by a computer system and real routes taken from the scientific literature. We anticipate that our method will accelerate drug and materials discovery by assisting chemists to plan better syntheses faster, and by enabling fully automated robot synthesis.\n    ",
        "submission_date": "2017-08-14T00:00:00",
        "last_modified_date": "2017-08-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.04352",
        "title": "Benchmark Environments for Multitask Learning in Continuous Domains",
        "authors": [
            "Peter Henderson",
            "Wei-Di Chang",
            "Florian Shkurti",
            "Johanna Hansen",
            "David Meger",
            "Gregory Dudek"
        ],
        "abstract": "As demand drives systems to generalize to various domains and problems, the study of multitask, transfer and lifelong learning has become an increasingly important pursuit. In discrete domains, performance on the Atari game suite has emerged as the de facto benchmark for assessing multitask learning. However, in continuous domains there is a lack of agreement on standard multitask evaluation environments which makes it difficult to compare different approaches fairly. In this work, we describe a benchmark set of tasks that we have developed in an extendable framework based on OpenAI Gym. We run a simple baseline using Trust Region Policy Optimization and release the framework publicly to be expanded and used for the systematic comparison of multitask, transfer, and lifelong learning in continuous domains.\n    ",
        "submission_date": "2017-08-14T00:00:00",
        "last_modified_date": "2017-08-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.04391",
        "title": "Learning body-affordances to simplify action spaces",
        "authors": [
            "Nicholas Guttenberg",
            "Martin Biehl",
            "Ryota Kanai"
        ],
        "abstract": "Controlling embodied agents with many actuated degrees of freedom is a challenging task. We propose a method that can discover and interpolate between context dependent high-level actions or body-affordances. These provide an abstract, low-dimensional interface indexing high-dimensional and time- extended action policies. Our method is related to recent ap- proaches in the machine learning literature but is conceptually simpler and easier to implement. More specifically our method requires the choice of a n-dimensional target sensor space that is endowed with a distance metric. The method then learns an also n-dimensional embedding of possibly reactive body-affordances that spread as far as possible throughout the target sensor space.\n    ",
        "submission_date": "2017-08-15T00:00:00",
        "last_modified_date": "2017-08-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.04806",
        "title": "New Ideas for Brain Modelling 4",
        "authors": [
            "Kieran Greer"
        ],
        "abstract": "This paper continues the research that considers a new cognitive model based strongly on the human brain. In particular, it considers the neural binding structure of an earlier paper. It also describes some new methods in the areas of image processing and behaviour simulation. The work is all based on earlier research by the author and the new additions are intended to fit in with the overall design. For image processing, a grid-like structure is used with 'full linking'. Each cell in the classifier grid stores a list of all other cells it gets associated with and this is used as the learned image that new input is compared to. For the behaviour metric, a new prediction equation is suggested, as part of a simulation, that uses feedback and history to dynamically determine its course of action. While the new methods are from widely different topics, both can be compared with the binary-analog type of interface that is the main focus of the paper. It is suggested that the simplest of linking between a tree and ensemble can explain neural binding and variable signal strengths.\n    ",
        "submission_date": "2017-08-16T00:00:00",
        "last_modified_date": "2018-03-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.04828",
        "title": "Multi-task Neural Network for Non-discrete Attribute Prediction in Knowledge Graphs",
        "authors": [
            "Yi Tay",
            "Luu Anh Tuan",
            "Minh C. Phan",
            "Siu Cheung Hui"
        ],
        "abstract": "Many popular knowledge graphs such as Freebase, YAGO or DBPedia maintain a list of non-discrete attributes for each entity. Intuitively, these attributes such as height, price or population count are able to richly characterize entities in knowledge graphs. This additional source of information may help to alleviate the inherent sparsity and incompleteness problem that are prevalent in knowledge graphs. Unfortunately, many state-of-the-art relational learning models ignore this information due to the challenging nature of dealing with non-discrete data types in the inherently binary-natured knowledge graphs. In this paper, we propose a novel multi-task neural network approach for both encoding and prediction of non-discrete attribute information in a relational setting. Specifically, we train a neural network for triplet prediction along with a separate network for attribute value regression. Via multi-task learning, we are able to learn representations of entities, relations and attributes that encode information about both tasks. Moreover, such attributes are not only central to many predictive tasks as an information source but also as a prediction target. Therefore, models that are able to encode, incorporate and predict such information in a relational learning context are highly attractive as well. We show that our approach outperforms many state-of-the-art methods for the tasks of relational triplet classification and attribute value prediction.\n    ",
        "submission_date": "2017-08-16T00:00:00",
        "last_modified_date": "2017-08-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.04846",
        "title": "Maximum A Posteriori Inference in Sum-Product Networks",
        "authors": [
            "Jun Mei",
            "Yong Jiang",
            "Kewei Tu"
        ],
        "abstract": "Sum-product networks (SPNs) are a class of probabilistic graphical models that allow tractable marginal inference. However, the maximum a posteriori (MAP) inference in SPNs is NP-hard. We investigate MAP inference in SPNs from both theoretical and algorithmic perspectives. For the theoretical part, we reduce general MAP inference to its special case without evidence and hidden variables; we also show that it is NP-hard to approximate the MAP problem to $2^{n^\\epsilon}$ for fixed $0 \\leq \\epsilon < 1$, where $n$ is the input size. For the algorithmic part, we first present an exact MAP solver that runs reasonably fast and could handle SPNs with up to 1k variables and 150k arcs in our experiments. We then present a new approximate MAP solver with a good balance between speed and accuracy, and our comprehensive experiments on real-world datasets show that it has better overall performance than existing approximate solvers.\n    ",
        "submission_date": "2017-08-16T00:00:00",
        "last_modified_date": "2017-11-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.04927",
        "title": "TheoSea: Marching Theory to Light",
        "authors": [
            "Mark A. Stalzer",
            "Chao Ju"
        ],
        "abstract": "There is sufficient information in the far-field of a radiating dipole antenna to rediscover the Maxwell Equations and the wave equations of light, including the speed of light $c.$ TheoSea is a Julia program that does this in about a second, and the key insight is that the compactness of theories drives the search. The program is a computational embodiment of the scientific method: observation, consideration of candidate theories, and validation.\n    ",
        "submission_date": "2017-08-14T00:00:00",
        "last_modified_date": "2017-08-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.04983",
        "title": "Visualizing and Exploring Dynamic High-Dimensional Datasets with LION-tSNE",
        "authors": [
            "Andrey Boytsov",
            "Francois Fouquet",
            "Thomas Hartmann",
            "Yves LeTraon"
        ],
        "abstract": "T-distributed stochastic neighbor embedding (tSNE) is a popular and prize-winning approach for dimensionality reduction and visualizing high-dimensional data. However, tSNE is non-parametric: once visualization is built, tSNE is not designed to incorporate additional data into existing representation. It highly limits the applicability of tSNE to the scenarios where data are added or updated over time (like dashboards or series of data snapshots).\n",
        "submission_date": "2017-08-16T00:00:00",
        "last_modified_date": "2017-08-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.05263",
        "title": "The Size of a Hyperball in a Conceptual Space",
        "authors": [
            "Lucas Bechberger"
        ],
        "abstract": "The cognitive framework of conceptual spaces [3] provides geometric means for representing knowledge. A conceptual space is a high-dimensional space whose dimensions are partitioned into so-called domains. Within each domain, the Euclidean metric is used to compute distances. Distances in the overall space are computed by applying the Manhattan metric to the intra-domain distances. Instances are represented as points in this space and concepts are represented by regions. In this paper, we derive a formula for the size of a hyperball under the combined metric of a conceptual space. One can think of such a hyperball as the set of all points having a certain minimal similarity to the hyperball's center.\n    ",
        "submission_date": "2017-07-04T00:00:00",
        "last_modified_date": "2017-09-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.05296",
        "title": "A Survey of Parallel A*",
        "authors": [
            "Alex Fukunaga",
            "Adi Botea",
            "Yuu Jinnai",
            "Akihiro Kishimoto"
        ],
        "abstract": "A* is a best-first search algorithm for finding optimal-cost paths in graphs. A* benefits significantly from parallelism because in many applications, A* is limited by memory usage, so distributed memory implementations of A* that use all of the aggregate memory on the cluster enable problems that can not be solved by serial, single-machine implementations to be solved. We survey approaches to parallel A*, focusing on decentralized approaches to A* which partition the state space among processors. We also survey approaches to parallel, limited-memory variants of A* such as parallel IDA*.\n    ",
        "submission_date": "2017-08-16T00:00:00",
        "last_modified_date": "2017-08-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.05346",
        "title": "General AI Challenge - Round One: Gradual Learning",
        "authors": [
            "Jan Feyereisl",
            "Matej Nikl",
            "Martin Poliak",
            "Martin Stransky",
            "Michal Vlasak"
        ],
        "abstract": "The General AI Challenge is an initiative to encourage the wider artificial intelligence community to focus on important problems in building intelligent machines with more general scope than is currently possible. The challenge comprises of multiple rounds, with the first round focusing on gradual learning, i.e. the ability to re-use already learned knowledge for efficiently learning to solve subsequent problems. In this article, we will present details of the first round of the challenge, its inspiration and aims. We also outline a more formal description of the challenge and present a preliminary analysis of its curriculum, based on ideas from computational mechanics. We believe, that such formalism will allow for a more principled approach towards investigating tasks in the challenge, building new curricula and for potentially improving consequent challenge rounds.\n    ",
        "submission_date": "2017-08-17T00:00:00",
        "last_modified_date": "2017-08-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.05448",
        "title": "On Ensuring that Intelligent Machines Are Well-Behaved",
        "authors": [
            "Philip S. Thomas",
            "Bruno Castro da Silva",
            "Andrew G. Barto",
            "Emma Brunskill"
        ],
        "abstract": "Machine learning algorithms are everywhere, ranging from simple data analysis and pattern recognition tools used across the sciences to complex systems that achieve super-human performance on various tasks. Ensuring that they are well-behaved---that they do not, for example, cause harm to humans or act in a racist or sexist way---is therefore not a hypothetical problem to be dealt with in the future, but a pressing one that we address here. We propose a new framework for designing machine learning algorithms that simplifies the problem of specifying and regulating undesirable behaviors. To show the viability of this new framework, we use it to create new machine learning algorithms that preclude the sexist and harmful behaviors exhibited by standard machine learning algorithms in our experiments. Our framework for designing machine learning algorithms simplifies the safe and responsible application of machine learning.\n    ",
        "submission_date": "2017-08-17T00:00:00",
        "last_modified_date": "2017-08-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.05522",
        "title": "Exploring Directional Path-Consistency for Solving Constraint Networks",
        "authors": [
            "Shufeng Kong",
            "Sanjiang Li",
            "Michael Sioutis"
        ],
        "abstract": "Among the local consistency techniques used for solving constraint networks, path-consistency (PC) has received a great deal of attention. However, enforcing PC is computationally expensive and sometimes even unnecessary. Directional path-consistency (DPC) is a weaker notion of PC that considers a given variable ordering and can thus be enforced more efficiently than PC. This paper shows that DPC (the DPC enforcing algorithm of Dechter and Pearl) decides the constraint satisfaction problem (CSP) of a constraint language if it is complete and has the variable elimination property (VEP). However, we also show that no complete VEP constraint language can have a domain with more than 2 values. We then present a simple variant of the DPC algorithm, called DPC*, and show that the CSP of a constraint language can be decided by DPC* if it is closed under a majority operation. In fact, DPC* is sufficient for guaranteeing backtrack-free search for such constraint networks. Examples of majority-closed constraint classes include the classes of connected row-convex (CRC) constraints and tree-preserving constraints, which have found applications in various domains, such as scene labeling, temporal reasoning, geometric reasoning, and logical filtering. Our experimental evaluations show that DPC* significantly outperforms the state-of-the-art algorithms for solving majority-closed constraints.\n    ",
        "submission_date": "2017-08-18T00:00:00",
        "last_modified_date": "2017-08-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.05629",
        "title": "Learning to Transfer",
        "authors": [
            "Ying Wei",
            "Yu Zhang",
            "Qiang Yang"
        ],
        "abstract": "Transfer learning borrows knowledge from a source domain to facilitate learning in a target domain. Two primary issues to be addressed in transfer learning are what and how to transfer. For a pair of domains, adopting different transfer learning algorithms results in different knowledge transferred between them. To discover the optimal transfer learning algorithm that maximally improves the learning performance in the target domain, researchers have to exhaustively explore all existing transfer learning algorithms, which is computationally intractable. As a trade-off, a sub-optimal algorithm is selected, which requires considerable expertise in an ad-hoc way. Meanwhile, it is widely accepted in educational psychology that human beings improve transfer learning skills of deciding what to transfer through meta-cognitive reflection on inductive transfer learning practices. Motivated by this, we propose a novel transfer learning framework known as Learning to Transfer (L2T) to automatically determine what and how to transfer are the best by leveraging previous transfer learning experiences. We establish the L2T framework in two stages: 1) we first learn a reflection function encrypting transfer learning skills from experiences; and 2) we infer what and how to transfer for a newly arrived pair of domains by optimizing the reflection function. Extensive experiments demonstrate the L2T's superiority over several state-of-the-art transfer learning algorithms and its effectiveness on discovering more transferable knowledge.\n    ",
        "submission_date": "2017-08-18T00:00:00",
        "last_modified_date": "2017-08-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.05824",
        "title": "Applying Deep Bidirectional LSTM and Mixture Density Network for Basketball Trajectory Prediction",
        "authors": [
            "Yu Zhao",
            "Rennong Yang",
            "Guillaume Chevalier",
            "Rajiv Shah",
            "Rob Romijnders"
        ],
        "abstract": "Data analytics helps basketball teams to create tactics. However, manual data collection and analytics are costly and ineffective. Therefore, we applied a deep bidirectional long short-term memory (BLSTM) and mixture density network (MDN) approach. This model is not only capable of predicting a basketball trajectory based on real data, but it also can generate new trajectory samples. It is an excellent application to help coaches and players decide when and where to shoot. Its structure is particularly suitable for dealing with time series problems. BLSTM receives forward and backward information at the same time, while stacking multiple BLSTMs further increases the learning ability of the model. Combined with BLSTMs, MDN is used to generate a multi-modal distribution of outputs. Thus, the proposed model can, in principle, represent arbitrary conditional probability distributions of output variables. We tested our model with two experiments on three-pointer datasets from NBA SportVu data. In the hit-or-miss classification experiment, the proposed model outperformed other models in terms of the convergence speed and accuracy. In the trajectory generation experiment, eight model-generated trajectories at a given time closely matched real trajectories.\n    ",
        "submission_date": "2017-08-19T00:00:00",
        "last_modified_date": "2017-08-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.05930",
        "title": "Solving a New 3D Bin Packing Problem with Deep Reinforcement Learning Method",
        "authors": [
            "Haoyuan Hu",
            "Xiaodong Zhang",
            "Xiaowei Yan",
            "Longfei Wang",
            "Yinghui Xu"
        ],
        "abstract": "In this paper, a new type of 3D bin packing problem (BPP) is proposed, in which a number of cuboid-shaped items must be put into a bin one by one orthogonally. The objective is to find a way to place these items that can minimize the surface area of the bin. This problem is based on the fact that there is no fixed-sized bin in many real business scenarios and the cost of a bin is proportional to its surface area. Our research shows that this problem is NP-hard. Based on previous research on 3D BPP, the surface area is determined by the sequence, spatial locations and orientations of items. Among these factors, the sequence of items plays a key role in minimizing the surface area. Inspired by recent achievements of deep reinforcement learning (DRL) techniques, especially Pointer Network, on combinatorial optimization problems such as TSP, a DRL-based method is applied to optimize the sequence of items to be packed into the bin. Numerical results show that the method proposed in this paper achieve about 5% improvement than heuristic method.\n    ",
        "submission_date": "2017-08-20T00:00:00",
        "last_modified_date": "2017-08-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.06000",
        "title": "Efficient Online Inference for Infinite Evolutionary Cluster models with Applications to Latent Social Event Discovery",
        "authors": [
            "Wei Wei",
            "Kennth Joseph",
            "Kathleen Carley"
        ],
        "abstract": "The Recurrent Chinese Restaurant Process (RCRP) is a powerful statistical method for modeling evolving clusters in large scale social media data. With the RCRP, one can allow both the number of clusters and the cluster parameters in a model to change over time. However, application of the RCRP has largely been limited due to the non-conjugacy between the cluster evolutionary priors and the Multinomial likelihood. This non-conjugacy makes inference di cult and restricts the scalability of models which use the RCRP, leading to the RCRP being applied only in simple problems, such as those that can be approximated by a single Gaussian emission. In this paper, we provide a novel solution for the non-conjugacy issues for the RCRP and an example of how to leverage our solution for one speci c problem - the social event discovery problem. By utilizing Sequential Monte Carlo methods in inference, our approach can be massively paralleled and is highly scalable, to the extent it can work on tens of millions of documents. We are able to generate high quality topical and location distributions of the clusters that can be directly interpreted as real social events, and our experimental results suggest that the approaches proposed achieve much better predictive performance than techniques reported in prior work. We also demonstrate how the techniques we develop can be used in a much more general ways toward similar problems.\n    ",
        "submission_date": "2017-08-20T00:00:00",
        "last_modified_date": "2017-08-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.06040",
        "title": "Meta-Learning MCMC Proposals",
        "authors": [
            "Tongzhou Wang",
            "Yi Wu",
            "David A. Moore",
            "Stuart J. Russell"
        ],
        "abstract": "Effective implementations of sampling-based probabilistic inference often require manually constructed, model-specific proposals. Inspired by recent progresses in meta-learning for training learning agents that can generalize to unseen environments, we propose a meta-learning approach to building effective and generalizable MCMC proposals. We parametrize the proposal as a neural network to provide fast approximations to block Gibbs conditionals. The learned neural proposals generalize to occurrences of common structural motifs across different models, allowing for the construction of a library of learned inference primitives that can accelerate inference on unseen models with no model-specific training required. We explore several applications including open-universe Gaussian mixture models, in which our learned proposals outperform a hand-tuned sampler, and a real-world named entity recognition task, in which our sampler yields higher final F1 scores than classical single-site Gibbs sampling.\n    ",
        "submission_date": "2017-08-21T00:00:00",
        "last_modified_date": "2019-01-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.06233",
        "title": "Fake News in Social Networks",
        "authors": [
            "Christoph Aymanns",
            "Jakob Foerster",
            "Co-Pierre Georg"
        ],
        "abstract": "We model the spread of news as a social learning game on a network. Agents can either endorse or oppose a claim made in a piece of news, which itself may be either true or false. Agents base their decision on a private signal and their neighbors' past actions. Given these inputs, agents follow strategies derived via multi-agent deep reinforcement learning and receive utility from acting in accordance with the veracity of claims. Our framework yields strategies with agent utility close to a theoretical, Bayes optimal benchmark, while remaining flexible to model re-specification. Optimized strategies allow agents to correctly identify most false claims, when all agents receive unbiased private signals. However, an adversary's attempt to spread fake news by targeting a subset of agents with a biased private signal can be successful. Even more so when the adversary has information about agents' network position or private signal. When agents are aware of the presence of an adversary they re-optimize their strategies in the training stage and the adversary's attack is less effective. Hence, exposing agents to the possibility of fake news can be an effective way to curtail the spread of fake news in social networks. Our results also highlight that information about the users' private beliefs and their social network structure can be extremely valuable to adversaries and should be well protected.\n    ",
        "submission_date": "2017-08-21T00:00:00",
        "last_modified_date": "2017-08-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.06246",
        "title": "Comparative Benchmarking of Causal Discovery Techniques",
        "authors": [
            "Karamjit Singh",
            "Garima Gupta",
            "Vartika Tewari",
            "Gautam Shroff"
        ],
        "abstract": "In this paper we present a comprehensive view of prominent causal discovery algorithms, categorized into two main categories (1) assuming acyclic and no latent variables, and (2) allowing both cycles and latent variables, along with experimental results comparing them from three perspectives: (a) structural accuracy, (b) standard predictive accuracy, and (c) accuracy of counterfactual inference. For (b) and (c) we train causal Bayesian networks with structures as predicted by each causal discovery technique to carry out counterfactual or standard predictive inference. We compare causal algorithms on two pub- licly available and one simulated datasets having different sample sizes: small, medium and large. Experiments show that structural accuracy of a technique does not necessarily correlate with higher accuracy of inferencing tasks. Fur- ther, surveyed structure learning algorithms do not perform well in terms of structural accuracy in case of datasets having large number of variables.\n    ",
        "submission_date": "2017-08-18T00:00:00",
        "last_modified_date": "2017-09-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.06266",
        "title": "Probabilistic Relation Induction in Vector Space Embeddings",
        "authors": [
            "Zied Bouraoui",
            "Shoaib Jameel",
            "Steven Schockaert"
        ],
        "abstract": "Word embeddings have been found to capture a surprisingly rich amount of syntactic and semantic knowledge. However, it is not yet sufficiently well-understood how the relational knowledge that is implicitly encoded in word embeddings can be extracted in a reliable way. In this paper, we propose two probabilistic models to address this issue. The first model is based on the common relations-as-translations view, but is cast in a probabilistic setting. Our second model is based on the much weaker assumption that there is a linear relationship between the vector representations of related words. Compared to existing approaches, our models lead to more accurate predictions, and they are more explicit about what can and cannot be extracted from the word embedding.\n    ",
        "submission_date": "2017-08-21T00:00:00",
        "last_modified_date": "2017-08-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.06551",
        "title": "Reinforcement Learning in POMDPs with Memoryless Options and Option-Observation Initiation Sets",
        "authors": [
            "Denis Steckelmacher",
            "Diederik M. Roijers",
            "Anna Harutyunyan",
            "Peter Vrancx",
            "H\u00e9l\u00e8ne Plisnier",
            "Ann Now\u00e9"
        ],
        "abstract": "Many real-world reinforcement learning problems have a hierarchical nature, and often exhibit some degree of partial observability. While hierarchy and partial observability are usually tackled separately (for instance by combining recurrent neural networks and options), we show that addressing both problems simultaneously is simpler and more efficient in many cases. More specifically, we make the initiation set of options conditional on the previously-executed option, and show that options with such Option-Observation Initiation Sets (OOIs) are at least as expressive as Finite State Controllers (FSCs), a state-of-the-art approach for learning in POMDPs. OOIs are easy to design based on an intuitive description of the task, lead to explainable policies and keep the top-level and option policies memoryless. Our experiments show that OOIs allow agents to learn optimal policies in challenging POMDPs, while being much more sample-efficient than a recurrent neural network over options.\n    ",
        "submission_date": "2017-08-22T00:00:00",
        "last_modified_date": "2017-09-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.06564",
        "title": "The Continuous Hint Factory - Providing Hints in Vast and Sparsely Populated Edit Distance Spaces",
        "authors": [
            "Benjamin Paa\u00dfen",
            "Barbara Hammer",
            "Thomas William Price",
            "Tiffany Barnes",
            "Sebastian Gross",
            "Niels Pinkwart"
        ],
        "abstract": "Intelligent tutoring systems can support students in solving multi-step tasks by providing hints regarding what to do next. However, engineering such next-step hints manually or via an expert model becomes infeasible if the space of possible states is too large. Therefore, several approaches have emerged to infer next-step hints automatically, relying on past students' data. In particular, the Hint Factory (Barnes & Stamper, 2008) recommends edits that are most likely to guide students from their current state towards a correct solution, based on what successful students in the past have done in the same situation. Still, the Hint Factory relies on student data being available for any state a student might visit while solving the task, which is not the case for some learning tasks, such as open-ended programming tasks. In this contribution we provide a mathematical framework for edit-based hint policies and, based on this theory, propose a novel hint policy to provide edit hints in vast and sparsely populated state spaces. In particular, we extend the Hint Factory by considering data of past students in all states which are similar to the student's current state and creating hints approximating the weighted average of all these reference states. Because the space of possible weighted averages is continuous, we call this approach the Continuous Hint Factory. In our experimental evaluation, we demonstrate that the Continuous Hint Factory can predict more accurately what capable students would do compared to existing prediction schemes on two learning tasks, especially in an open-ended programming task, and that the Continuous Hint Factory is comparable to existing hint policies at reproducing tutor hints on a simple UML diagram task.\n    ",
        "submission_date": "2017-08-22T00:00:00",
        "last_modified_date": "2018-06-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.06716",
        "title": "What caused what? A quantitative account of actual causation using dynamical causal networks",
        "authors": [
            "Larissa Albantakis",
            "William Marshall",
            "Erik Hoel",
            "Giulio Tononi"
        ],
        "abstract": "Actual causation is concerned with the question \"what caused what?\" Consider a transition between two states within a system of interacting elements, such as an artificial neural network, or a biological brain circuit. Which combination of synapses caused the neuron to fire? Which image features caused the classifier to misinterpret the picture? Even detailed knowledge of the system's causal network, its elements, their states, connectivity, and dynamics does not automatically provide a straightforward answer to the \"what caused what?\" question. Counterfactual accounts of actual causation based on graphical models, paired with system interventions, have demonstrated initial success in addressing specific problem cases in line with intuitive causal judgments. Here, we start from a set of basic requirements for causation (realization, composition, information, integration, and exclusion) and develop a rigorous, quantitative account of actual causation that is generally applicable to discrete dynamical systems. We present a formal framework to evaluate these causal requirements that is based on system interventions and partitions, and considers all counterfactuals of a state transition. This framework is used to provide a complete causal account of the transition by identifying and quantifying the strength of all actual causes and effects linking the two consecutive system states. Finally, we examine several exemplary cases and paradoxes of causation and show that they can be illuminated by the proposed framework for quantifying actual causation.\n    ",
        "submission_date": "2017-08-22T00:00:00",
        "last_modified_date": "2019-01-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.06816",
        "title": "Analysis of the Impact of Negative Sampling on Link Prediction in Knowledge Graphs",
        "authors": [
            "Bhushan Kotnis",
            "Vivi Nastase"
        ],
        "abstract": "Knowledge graphs are large, useful, but incomplete knowledge repositories. They encode knowledge through entities and relations which define each other through the connective structure of the graph. This has inspired methods for the joint embedding of entities and relations in continuous low-dimensional vector spaces, that can be used to induce new edges in the graph, i.e., link prediction in knowledge graphs. Learning these representations relies on contrasting positive instances with negative ones. Knowledge graphs include only positive relation instances, leaving the door open for a variety of methods for selecting negative examples. In this paper we present an empirical study on the impact of negative sampling on the learned embeddings, assessed through the task of link prediction. We use state-of-the-art knowledge graph embeddings -- \\rescal , TransE, DistMult and ComplEX -- and evaluate on benchmark datasets -- FB15k and WN18. We compare well known methods for negative sampling and additionally propose embedding based sampling methods. We note a marked difference in the impact of these sampling methods on the two datasets, with the \"traditional\" corrupting positives method leading to best results on WN18, while embedding based methods benefiting the task on FB15k.\n    ",
        "submission_date": "2017-08-22T00:00:00",
        "last_modified_date": "2018-03-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.06834",
        "title": "Skip RNN: Learning to Skip State Updates in Recurrent Neural Networks",
        "authors": [
            "Victor Campos",
            "Brendan Jou",
            "Xavier Giro-i-Nieto",
            "Jordi Torres",
            "Shih-Fu Chang"
        ],
        "abstract": "Recurrent Neural Networks (RNNs) continue to show outstanding performance in sequence modeling tasks. However, training RNNs on long sequences often face challenges like slow inference, vanishing gradients and difficulty in capturing long term dependencies. In backpropagation through time settings, these issues are tightly coupled with the large, sequential computational graph resulting from unfolding the RNN in time. We introduce the Skip RNN model which extends existing RNN models by learning to skip state updates and shortens the effective size of the computational graph. This model can also be encouraged to perform fewer state updates through a budget constraint. We evaluate the proposed model on various tasks and show how it can reduce the number of required RNN updates while preserving, and sometimes even improving, the performance of the baseline RNN models. Source code is publicly available at ",
        "submission_date": "2017-08-22T00:00:00",
        "last_modified_date": "2018-02-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.06846",
        "title": "On Relaxing Determinism in Arithmetic Circuits",
        "authors": [
            "Arthur Choi",
            "Adnan Darwiche"
        ],
        "abstract": "The past decade has seen a significant interest in learning tractable probabilistic representations. Arithmetic circuits (ACs) were among the first proposed tractable representations, with some subsequent representations being instances of ACs with weaker or stronger properties. In this paper, we provide a formal basis under which variants on ACs can be compared, and where the precise roles and semantics of their various properties can be made more transparent. This allows us to place some recent developments on ACs in a clearer perspective and to also derive new results for ACs. This includes an exponential separation between ACs with and without determinism; completeness and incompleteness results; and tractability results (or lack thereof) when computing most probable explanations (MPEs).\n    ",
        "submission_date": "2017-08-22T00:00:00",
        "last_modified_date": "2017-08-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.07129",
        "title": "A Survey of Human Activity Recognition Using WiFi CSI",
        "authors": [
            "Siamak Yousefi",
            "Hirokazu Narui",
            "Sankalp Dayal",
            "Stefano Ermon",
            "Shahrokh Valaee"
        ],
        "abstract": "In this article, we present a survey of recent advances in passive human behaviour recognition in indoor areas using the channel state information (CSI) of commercial WiFi systems. Movement of human body causes a change in the wireless signal reflections, which results in variations in the CSI. By analyzing the data streams of CSIs for different activities and comparing them against stored models, human behaviour can be recognized. This is done by extracting features from CSI data streams and using machine learning techniques to build models and classifiers. The techniques from the literature that are presented herein have great performances, however, instead of the machine learning techniques employed in these works, we propose to use deep learning techniques such as long-short term memory (LSTM) recurrent neural network (RNN), and show the improved performance. We also discuss about different challenges such as environment change, frame rate selection, and multi-user scenario, and suggest possible directions for future work.\n    ",
        "submission_date": "2017-08-23T00:00:00",
        "last_modified_date": "2017-08-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.07239",
        "title": "Finding Streams in Knowledge Graphs to Support Fact Checking",
        "authors": [
            "Prashant Shiralkar",
            "Alessandro Flammini",
            "Filippo Menczer",
            "Giovanni Luca Ciampaglia"
        ],
        "abstract": "The volume and velocity of information that gets generated online limits current journalistic practices to fact-check claims at the same rate. Computational approaches for fact checking may be the key to help mitigate the risks of massive misinformation spread. Such approaches can be designed to not only be scalable and effective at assessing veracity of dubious claims, but also to boost a human fact checker's productivity by surfacing relevant facts and patterns to aid their analysis. To this end, we present a novel, unsupervised network-flow based approach to determine the truthfulness of a statement of fact expressed in the form of a (subject, predicate, object) triple. We view a knowledge graph of background information about real-world entities as a flow network, and knowledge as a fluid, abstract commodity. We show that computational fact checking of such a triple then amounts to finding a \"knowledge stream\" that emanates from the subject node and flows toward the object node through paths connecting them. Evaluation on a range of real-world and hand-crafted datasets of facts related to entertainment, business, sports, geography and more reveals that this network-flow model can be very effective in discerning true statements from false ones, outperforming existing algorithms on many test cases. Moreover, the model is expressive in its ability to automatically discover several useful path patterns and surface relevant facts that may help a human fact checker corroborate or refute a claim.\n    ",
        "submission_date": "2017-08-24T00:00:00",
        "last_modified_date": "2017-08-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.07280",
        "title": "Learning Generalized Reactive Policies using Deep Neural Networks",
        "authors": [
            "Edward Groshev",
            "Maxwell Goldstein",
            "Aviv Tamar",
            "Siddharth Srivastava",
            "Pieter Abbeel"
        ],
        "abstract": "We present a new approach to learning for planning, where knowledge acquired while solving a given set of planning problems is used to plan faster in related, but new problem instances. We show that a deep neural network can be used to learn and represent a \\emph{generalized reactive policy} (GRP) that maps a problem instance and a state to an action, and that the learned GRPs efficiently solve large classes of challenging problem instances. In contrast to prior efforts in this direction, our approach significantly reduces the dependence of learning on handcrafted domain knowledge or feature selection. Instead, the GRP is trained from scratch using a set of successful execution traces. We show that our approach can also be used to automatically learn a heuristic function that can be used in directed search algorithms. We evaluate our approach using an extensive suite of experiments on two challenging planning problem domains and show that our approach facilitates learning complex decision making policies and powerful heuristic functions with minimal human input. Videos of our results are available at ",
        "submission_date": "2017-08-24T00:00:00",
        "last_modified_date": "2018-07-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.07285",
        "title": "Area Protection in Adversarial Path-Finding Scenarios with Multiple Mobile Agents on Graphs: a theoretical and experimental study of target-allocation strategies for defense coordination",
        "authors": [
            "Marika Ivanov\u00e1",
            "Pavel Surynek"
        ],
        "abstract": "We address a problem of area protection in graph-based scenarios with multiple agents. The problem consists of two adversarial teams of agents that move in an undirected graph shared by both teams. Agents are placed in vertices of the graph; at most one agent can occupy a vertex; and they can move into adjacent vertices in a conflict free way. Teams have asymmetric goals: the aim of one team - attackers - is to invade into given area while the aim of the opponent team - defenders - is to protect the area from being entered by attackers by occupying selected vertices. We study strategies for allocating vertices to be occupied by the team of defenders to block attacking agents. We show that the decision version of the problem of area protection is PSPACE-hard under the assumption that agents can allocate their target vertices multiple times. Further we develop various on-line vertex-allocation strategies for the defender team in a simplified variant of the problem with single stage vertex allocation and evaluated their performance in multiple benchmarks. The success of a strategy is heavily dependent on the type of the instance, and so one of the contributions of this work is that we identify suitable vertex-allocation strategies for diverse instance types. In particular, we introduce a simulation-based method that identifies and tries to capture bottlenecks in the graph, that are frequently used by the attackers. Our experimental evaluation suggests that this method often allows a successful defense even in instances where the attackers significantly outnumber the defenders.\n    ",
        "submission_date": "2017-08-24T00:00:00",
        "last_modified_date": "2017-08-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.07767",
        "title": "Non-FPT lower bounds for structural restrictions of decision DNNF",
        "authors": [
            "Andrea Cal\u00ec",
            "Florent Capelli",
            "Igor Razgon"
        ],
        "abstract": "We give a non-FPT lower bound on the size of structured decision DNNF and OBDD with decomposable AND-nodes representing CNF-formulas of bounded incidence treewidth. Both models are known to be of FPT size for CNFs of bounded primal treewidth. To the best of our knowledge this is the first parameterized separation of primal treewidth and incidence treewidth for knowledge compilation models.\n    ",
        "submission_date": "2017-08-25T00:00:00",
        "last_modified_date": "2017-08-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.07775",
        "title": "Subspace Approximation for Approximate Nearest Neighbor Search in NLP",
        "authors": [
            "Jing Wang"
        ],
        "abstract": "Most natural language processing tasks can be formulated as the approximated nearest neighbor search problem, such as word analogy, document similarity, machine translation. Take the question-answering task as an example, given a question as the query, the goal is to search its nearest neighbor in the training dataset as the answer. However, existing methods for approximate nearest neighbor search problem may not perform well owing to the following practical challenges: 1) there are noise in the data; 2) the large scale dataset yields a huge retrieval space and high search time complexity.\n",
        "submission_date": "2017-08-25T00:00:00",
        "last_modified_date": "2017-08-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.07867",
        "title": "Accelerating Dependency Graph Learning from Heterogeneous Categorical Event Streams via Knowledge Transfer",
        "authors": [
            "Chen Luo",
            "Zhengzhang Chen",
            "Lu-An Tang",
            "Anshumali Shrivastava",
            "Zhichun Li"
        ],
        "abstract": "Dependency graph, as a heterogeneous graph representing the intrinsic relationships between different pairs of system entities, is essential to many data analysis applications, such as root cause diagnosis, intrusion detection, etc. Given a well-trained dependency graph from a source domain and an immature dependency graph from a target domain, how can we extract the entity and dependency knowledge from the source to enhance the target? One way is to directly apply a mature dependency graph learned from a source domain to the target domain. But due to the domain variety problem, directly using the source dependency graph often can not achieve good performance. Traditional transfer learning methods mainly focus on numerical data and are not applicable.\n",
        "submission_date": "2017-08-25T00:00:00",
        "last_modified_date": "2017-08-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.07902",
        "title": "Deep Learning for Video Game Playing",
        "authors": [
            "Niels Justesen",
            "Philip Bontrager",
            "Julian Togelius",
            "Sebastian Risi"
        ],
        "abstract": "In this article, we review recent Deep Learning advances in the context of how they have been applied to play different types of video games such as first-person shooters, arcade games, and real-time strategy games. We analyze the unique requirements that different game genres pose to a deep learning system and highlight important open challenges in the context of applying these machine learning methods to video games, such as general game playing, dealing with extremely large decision spaces and sparse rewards.\n    ",
        "submission_date": "2017-08-25T00:00:00",
        "last_modified_date": "2019-02-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.07938",
        "title": "Deep Style Match for Complementary Recommendation",
        "authors": [
            "Kui Zhao",
            "Xia Hu",
            "Jiajun Bu",
            "Can Wang"
        ],
        "abstract": "Humans develop a common sense of style compatibility between items based on their attributes. We seek to automatically answer questions like \"Does this shirt go well with that pair of jeans?\" In order to answer these kinds of questions, we attempt to model human sense of style compatibility in this paper. The basic assumption of our approach is that most of the important attributes for a product in an online store are included in its title description. Therefore it is feasible to learn style compatibility from these descriptions. We design a Siamese Convolutional Neural Network architecture and feed it with title pairs of items, which are either compatible or incompatible. Those pairs will be mapped from the original space of symbolic words into some embedded style space. Our approach takes only words as the input with few preprocessing and there is no laborious and expensive feature engineering.\n    ",
        "submission_date": "2017-08-26T00:00:00",
        "last_modified_date": "2017-08-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.07940",
        "title": "Navigation Objects Extraction for Better Content Structure Understanding",
        "authors": [
            "Kui Zhao",
            "Bangpeng Li",
            "Zilun Peng",
            "Jiajun Bu",
            "Can Wang"
        ],
        "abstract": "Existing works for extracting navigation objects from webpages focus on navigation menus, so as to reveal the information architecture of the site. However, web 2.0 sites such as social networks, e-commerce portals etc. are making the understanding of the content structure in a web site increasingly difficult. Dynamic and personalized elements such as top stories, recommended list in a webpage are vital to the understanding of the dynamic nature of web 2.0 sites. To better understand the content structure in web 2.0 sites, in this paper we propose a new extraction method for navigation objects in a webpage. Our method will extract not only the static navigation menus, but also the dynamic and personalized page-specific navigation lists. Since the navigation objects in a webpage naturally come in blocks, we first cluster hyperlinks into different blocks by exploiting spatial locations of hyperlinks, the hierarchical structure of the DOM-tree and the hyperlink density. Then we identify navigation objects from those blocks using the SVM classifier with novel features such as anchor text lengths etc. Experiments on real-world data sets with webpages from various domains and styles verified the effectiveness of our method.\n    ",
        "submission_date": "2017-08-26T00:00:00",
        "last_modified_date": "2017-08-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.08079",
        "title": "Local Gaussian Processes for Efficient Fine-Grained Traffic Speed Prediction",
        "authors": [
            "Truc Viet Le",
            "Richard J. Oentaryo",
            "Siyuan Liu",
            "Hoong Chuin Lau"
        ],
        "abstract": "Traffic speed is a key indicator for the efficiency of an urban transportation system. Accurate modeling of the spatiotemporally varying traffic speed thus plays a crucial role in urban planning and development. This paper addresses the problem of efficient fine-grained traffic speed prediction using big traffic data obtained from static sensors. Gaussian processes (GPs) have been previously used to model various traffic phenomena, including flow and speed. However, GPs do not scale with big traffic data due to their cubic time complexity. In this work, we address their efficiency issues by proposing local GPs to learn from and make predictions for correlated subsets of data. The main idea is to quickly group speed variables in both spatial and temporal dimensions into a finite number of clusters, so that future and unobserved traffic speed queries can be heuristically mapped to one of such clusters. A local GP corresponding to that cluster can then be trained on the fly to make predictions in real-time. We call this method localization. We use non-negative matrix factorization for localization and propose simple heuristics for cluster mapping. We additionally leverage on the expressiveness of GP kernel functions to model road network topology and incorporate side information. Extensive experiments using real-world traffic data collected in the two U.S. cities of Pittsburgh and Washington, D.C., show that our proposed local GPs significantly improve both runtime performances and prediction accuracies compared to the baseline global and local GPs.\n    ",
        "submission_date": "2017-08-27T00:00:00",
        "last_modified_date": "2017-08-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.08113",
        "title": "Novel Sensor Scheduling Scheme for Intruder Tracking in Energy Efficient Sensor Networks",
        "authors": [
            "Raghuram Bharadwaj Diddigi",
            "Prabuchandran K.J.",
            "Shalabh Bhatnagar"
        ],
        "abstract": "We consider the problem of tracking an intruder using a network of wireless sensors. For tracking the intruder at each instant, the optimal number and the right configuration of sensors has to be powered. As powering the sensors consumes energy, there is a trade off between accurately tracking the position of the intruder at each instant and the energy consumption of sensors. This problem has been formulated in the framework of Partially Observable Markov Decision Process (POMDP). Even for the state-of-the-art algorithm in the literature, the curse of dimensionality renders the problem intractable. In this paper, we formulate the Intrusion Detection (ID) problem with a suitable state-action space in the framework of POMDP and develop a Reinforcement Learning (RL) algorithm utilizing the Upper Confidence Tree Search (UCT) method to solve the ID problem. Through simulations, we show that our algorithm performs and scales well with the increasing state and action spaces.\n    ",
        "submission_date": "2017-08-27T00:00:00",
        "last_modified_date": "2018-02-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.08296",
        "title": "Explainable Artificial Intelligence: Understanding, Visualizing and Interpreting Deep Learning Models",
        "authors": [
            "Wojciech Samek",
            "Thomas Wiegand",
            "Klaus-Robert M\u00fcller"
        ],
        "abstract": "With the availability of large databases and recent improvements in deep learning methodology, the performance of AI systems is reaching or even exceeding the human level on an increasing number of complex tasks. Impressive examples of this development can be found in domains such as image classification, sentiment analysis, speech understanding or strategic game playing. However, because of their nested non-linear structure, these highly successful machine learning and artificial intelligence models are usually applied in a black box manner, i.e., no information is provided about what exactly makes them arrive at their predictions. Since this lack of transparency can be a major drawback, e.g., in medical applications, the development of methods for visualizing, explaining and interpreting deep learning models has recently attracted increasing attention. This paper summarizes recent developments in this field and makes a plea for more interpretability in artificial intelligence. Furthermore, it presents two approaches to explaining predictions of deep learning models, one method which computes the sensitivity of the prediction with respect to changes in the input and one approach which meaningfully decomposes the decision in terms of the input variables. These methods are evaluated on three classification tasks.\n    ",
        "submission_date": "2017-08-28T00:00:00",
        "last_modified_date": "2017-08-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.09032",
        "title": "Plausibility and probability in deductive reasoning",
        "authors": [
            "Andrew MacFie"
        ],
        "abstract": "We consider the problem of rational uncertainty about unproven mathematical statements, remarked on by G\u00f6del and others. Using Bayesian-inspired arguments we build a normative model of fair bets under deductive uncertainty which draws from both probability and the theory of algorithms. We comment on connections to Zeilberger's notion of \"semi-rigorous proofs\", particularly that inherent subjectivity would be present. We also discuss a financial view with models of arbitrage where traders have limited computational resources.\n    ",
        "submission_date": "2017-08-29T00:00:00",
        "last_modified_date": "2019-12-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.09040",
        "title": "Modelling Protagonist Goals and Desires in First-Person Narrative",
        "authors": [
            "Elahe Rahimtoroghi",
            "Jiaqi Wu",
            "Ruimin Wang",
            "Pranav Anand",
            "Marilyn A Walker"
        ],
        "abstract": "Many genres of natural language text are narratively structured, a testament to our predilection for organizing our experiences as narratives. There is broad consensus that understanding a narrative requires identifying and tracking the goals and desires of the characters and their narrative outcomes. However, to date, there has been limited work on computational models for this problem. We introduce a new dataset, DesireDB, which includes gold-standard labels for identifying statements of desire, textual evidence for desire fulfillment, and annotations for whether the stated desire is fulfilled given the evidence in the narrative context. We report experiments on tracking desire fulfillment using different methods, and show that LSTM Skip-Thought model achieves F-measure of 0.7 on our corpus.\n    ",
        "submission_date": "2017-08-29T00:00:00",
        "last_modified_date": "2017-08-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.09086",
        "title": "A Deep Learning Approach for Population Estimation from Satellite Imagery",
        "authors": [
            "Caleb Robinson",
            "Fred Hohman",
            "Bistra Dilkina"
        ],
        "abstract": "Knowing where people live is a fundamental component of many decision making processes such as urban development, infectious disease containment, evacuation planning, risk management, conservation planning, and more. While bottom-up, survey driven censuses can provide a comprehensive view into the population landscape of a country, they are expensive to realize, are infrequently performed, and only provide population counts over broad areas. Population disaggregation techniques and population projection methods individually address these shortcomings, but also have shortcomings of their own. To jointly answer the questions of \"where do people live\" and \"how many people live there,\" we propose a deep learning model for creating high-resolution population estimations from satellite imagery. Specifically, we train convolutional neural networks to predict population in the USA at a $0.01^{\\circ} \\times 0.01^{\\circ}$ resolution grid from 1-year composite Landsat imagery. We validate these models in two ways: quantitatively, by comparing our model's grid cell estimates aggregated at a county-level to several US Census county-level population projections, and qualitatively, by directly interpreting the model's predictions in terms of the satellite image inputs. We find that aggregating our model's estimates gives comparable results to the Census county-level population projections and that the predictions made by our model can be directly interpreted, which give it advantages over traditional population disaggregation methods. In general, our model is an example of how machine learning techniques can be an effective tool for extracting information from inherently unstructured, remotely sensed data to provide effective solutions to social problems.\n    ",
        "submission_date": "2017-08-30T00:00:00",
        "last_modified_date": "2017-08-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.09175",
        "title": "Calibrating chemical multisensory devices for real world applications: An in-depth comparison of quantitative Machine Learning approaches",
        "authors": [
            "S. De Vito",
            "E. Esposito",
            "M. Salvato",
            "O. Popoola",
            "F. Formisano",
            "R. Jones",
            "G. Di Francia"
        ],
        "abstract": "Chemical multisensor devices need calibration algorithms to estimate gas concentrations. Their possible adoption as indicative air quality measurements devices poses new challenges due to the need to operate in continuous monitoring modes in uncontrolled environments. Several issues, including slow dynamics, continue to affect their real world performances. At the same time, the need for estimating pollutant concentrations on board the devices, espe- cially for wearables and IoT deployments, is becoming highly desirable. In this framework, several calibration approaches have been proposed and tested on a variety of proprietary devices and datasets; still, no thorough comparison is available to researchers. This work attempts a benchmarking of the most promising calibration algorithms according to recent literature with a focus on machine learning approaches. We test the techniques against absolute and dynamic performances, generalization capabilities and computational/storage needs using three different datasets sharing continuous monitoring operation methodology. Our results can guide researchers and engineers in the choice of optimal strategy. They show that non-linear multivariate techniques yield reproducible results, outperforming lin- ear approaches. Specifically, the Support Vector Regression method consistently shows good performances in all the considered scenarios. We highlight the enhanced suitability of shallow neural networks in a trade-off between performance and computational/storage needs. We confirm, on a much wider basis, the advantages of dynamic approaches with respect to static ones that only rely on instantaneous sensor array response. The latter have been shown to be best choice whenever prompt and precise response is needed.\n    ",
        "submission_date": "2017-08-30T00:00:00",
        "last_modified_date": "2017-08-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.00149",
        "title": "Learning what to read: Focused machine reading",
        "authors": [
            "Enrique Noriega-Atala",
            "Marco A. Valenzuela-Escarcega",
            "Clayton T. Morrison",
            "Mihai Surdeanu"
        ],
        "abstract": "Recent efforts in bioinformatics have achieved tremendous progress in the machine reading of biomedical literature, and the assembly of the extracted biochemical interactions into large-scale models such as protein signaling pathways. However, batch machine reading of literature at today's scale (PubMed alone indexes over 1 million papers per year) is unfeasible due to both cost and processing overhead. In this work, we introduce a focused reading approach to guide the machine reading of biomedical literature towards what literature should be read to answer a biomedical query as efficiently as possible. We introduce a family of algorithms for focused reading, including an intuitive, strong baseline, and a second approach which uses a reinforcement learning (RL) framework that learns when to explore (widen the search) or exploit (narrow it). We demonstrate that the RL approach is capable of answering more queries than the baseline, while being more efficient, i.e., reading fewer documents.\n    ",
        "submission_date": "2017-09-01T00:00:00",
        "last_modified_date": "2017-09-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.00322",
        "title": "Disintegration and Bayesian Inversion via String Diagrams",
        "authors": [
            "Kenta Cho",
            "Bart Jacobs"
        ],
        "abstract": "The notions of disintegration and Bayesian inversion are fundamental in conditional probability theory. They produce channels, as conditional probabilities, from a joint state, or from an already given channel (in opposite direction). These notions exist in the literature, in concrete situations, but are presented here in abstract graphical formulations. The resulting abstract descriptions are used for proving basic results in conditional probability theory. The existence of disintegration and Bayesian inversion is discussed for discrete probability, and also for measure-theoretic probability --- via standard Borel spaces and via likelihoods. Finally, the usefulness of disintegration and Bayesian inversion is illustrated in several examples.\n    ",
        "submission_date": "2017-08-29T00:00:00",
        "last_modified_date": "2019-02-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.00539",
        "title": "An Automated Compatibility Prediction Engine using DISC Theory Based Classification and Neural Networks",
        "authors": [
            "Chandrasekaran Anirudh Bhardwaj",
            "Megha Mishra",
            "Sweetlin Hemalatha"
        ],
        "abstract": "Traditionally psychometric tests were used for profiling incoming workers. These methods use DISC profiling method to classify people into distinct personality types, which are further used to predict if a person may be a possible fit to the organizational culture. This concept is taken further by introducing a novel technique to predict if a particular pair of an incoming worker and the manager being assigned are compatible at a psychological scale. This is done using multilayer perceptron neural network which can be adaptively trained to showcase the true nature of the compatibility index. The proposed prototype model is used to quantify the relevant attributes, use them to train the prediction engine, and to define the data pipeline required for it.\n    ",
        "submission_date": "2017-09-02T00:00:00",
        "last_modified_date": "2017-09-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.00661",
        "title": "Topic Independent Identification of Agreement and Disagreement in Social Media Dialogue",
        "authors": [
            "Amita Misra",
            "Marilyn Walker"
        ],
        "abstract": "Research on the structure of dialogue has been hampered for years because large dialogue corpora have not been available. This has impacted the dialogue research community's ability to develop better theories, as well as good off the shelf tools for dialogue processing. Happily, an increasing amount of information and opinion exchange occur in natural dialogue in online forums, where people share their opinions about a vast range of topics. In particular we are interested in rejection in dialogue, also called disagreement and denial, where the size of available dialogue corpora, for the first time, offers an opportunity to empirically test theoretical accounts of the expression and inference of rejection in dialogue. In this paper, we test whether topic-independent features motivated by theoretical predictions can be used to recognize rejection in online forums in a topic independent way. Our results show that our theoretically motivated features achieve 66% accuracy, an improvement over a unigram baseline of an absolute 6%.\n    ",
        "submission_date": "2017-09-03T00:00:00",
        "last_modified_date": "2017-09-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.00662",
        "title": "Using Summarization to Discover Argument Facets in Online Ideological Dialog",
        "authors": [
            "Amita Misra",
            "Pranav Anand",
            "Jean E Fox Tree",
            "Marilyn Walker"
        ],
        "abstract": "More and more of the information available on the web is dialogic, and a significant portion of it takes place in online forum conversations about current social and political topics. We aim to develop tools to summarize what these conversations are about. What are the CENTRAL PROPOSITIONS associated with different stances on an issue, what are the abstract objects under discussion that are central to a speaker's argument? How can we recognize that two CENTRAL PROPOSITIONS realize the same FACET of the argument? We hypothesize that the CENTRAL PROPOSITIONS are exactly those arguments that people find most salient, and use human summarization as a probe for discovering them. We describe our corpus of human summaries of opinionated dialogs, then show how we can identify similar repeated arguments, and group them into FACETS across many discussions of a topic. We define a new task, ARGUMENT FACET SIMILARITY (AFS), and show that we can predict AFS with a .54 correlation score, versus an ngram system baseline of .39 and a semantic textual similarity system baseline of .45.\n    ",
        "submission_date": "2017-09-03T00:00:00",
        "last_modified_date": "2017-09-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.00670",
        "title": "Difficulty-level Modeling of Ontology-based Factual Questions",
        "authors": [
            "Vinu E.V",
            "P Sreenivasa Kumar"
        ],
        "abstract": "Semantics based knowledge representations such as ontologies are found to be very useful in automatically generating meaningful factual questions. Determining the difficulty level of these system generated questions is helpful to effectively utilize them in various educational and professional applications. The existing approaches for finding the difficulty level of factual questions are very simple and are limited to a few basic principles. We propose a new methodology for this problem by considering an educational theory called Item Response Theory (IRT). In the IRT, knowledge proficiency of end users (learners) are considered for assigning difficulty levels, because of the assumptions that a given question is perceived differently by learners of various proficiencies. We have done a detailed study on the features (factors) of a question statement which could possibly determine its difficulty level for three learner categories (experts, intermediates and beginners). We formulate ontology based metrics for the same. We then train three logistic regression models to predict the difficulty level corresponding to the three learner categories.\n    ",
        "submission_date": "2017-09-03T00:00:00",
        "last_modified_date": "2017-09-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.00893",
        "title": "Interactive Attention Networks for Aspect-Level Sentiment Classification",
        "authors": [
            "Dehong Ma",
            "Sujian Li",
            "Xiaodong Zhang",
            "Houfeng Wang"
        ],
        "abstract": "Aspect-level sentiment classification aims at identifying the sentiment polarity of specific target in its context. Previous approaches have realized the importance of targets in sentiment classification and developed various methods with the goal of precisely modeling their contexts via generating target-specific representations. However, these studies always ignore the separate modeling of targets. In this paper, we argue that both targets and contexts deserve special treatment and need to be learned their own representations via interactive learning. Then, we propose the interactive attention networks (IAN) to interactively learn attentions in the contexts and targets, and generate the representations for targets and contexts separately. With this design, the IAN model can well represent a target and its collocative context, which is helpful to sentiment classification. Experimental results on SemEval 2014 Datasets demonstrate the effectiveness of our model.\n    ",
        "submission_date": "2017-09-04T00:00:00",
        "last_modified_date": "2017-09-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.00931",
        "title": "A Computer Composes A Fabled Problem: Four Knights vs. Queen",
        "authors": [
            "Azlan Iqbal"
        ],
        "abstract": "We explain how the prototype automatic chess problem composer, Chesthetica, successfully composed a rare and interesting chess problem using the new Digital Synaptic Neural Substrate (DSNS) computational creativity approach. This problem represents a greater challenge from a creative standpoint because the checkmate is not always clear and the method of winning even less so. Creating a decisive chess problem of this type without the aid of an omniscient 7-piece endgame tablebase (and one that also abides by several chess composition conventions) would therefore be a challenge for most human players and composers working on their own. The fact that a small computer with relatively low processing power and memory was sufficient to compose such a problem using the DSNS approach in just 10 days is therefore noteworthy. In this report we document the event and result in some detail. It lends additional credence to the DSNS as a viable new approach in the field of computational creativity. In particular, in areas where human-like creativity is required for targeted or specific problems with no clear path to the solution.\n    ",
        "submission_date": "2017-09-04T00:00:00",
        "last_modified_date": "2017-09-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.01122",
        "title": "Exact Inference for Relational Graphical Models with Interpreted Functions: Lifted Probabilistic Inference Modulo Theories",
        "authors": [
            "Rodrigo de Salvo Braz",
            "Ciaran O'Reilly"
        ],
        "abstract": "Probabilistic Inference Modulo Theories (PIMT) is a recent framework that expands exact inference on graphical models to use richer languages that include arithmetic, equalities, and inequalities on both integers and real numbers. In this paper, we expand PIMT to a lifted version that also processes random functions and relations. This enhancement is achieved by adapting Inversion, a method from Lifted First-Order Probabilistic Inference literature, to also be modulo theories. This results in the first algorithm for exact probabilistic inference that efficiently and simultaneously exploits random relations and functions, arithmetic, equalities and inequalities.\n    ",
        "submission_date": "2017-09-04T00:00:00",
        "last_modified_date": "2017-09-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.01308",
        "title": "BOOK: Storing Algorithm-Invariant Episodes for Deep Reinforcement Learning",
        "authors": [
            "Simyung Chang",
            "YoungJoon Yoo",
            "Jaeseok Choi",
            "Nojun Kwak"
        ],
        "abstract": "We introduce a novel method to train agents of reinforcement learning (RL) by sharing knowledge in a way similar to the concept of using a book. The recorded information in the form of a book is the main means by which humans learn knowledge. Nevertheless, the conventional deep RL methods have mainly focused either on experiential learning where the agent learns through interactions with the environment from the start or on imitation learning that tries to mimic the teacher. Contrary to these, our proposed book learning shares key information among different agents in a book-like manner by delving into the following two characteristic features: (1) By defining the linguistic function, input states can be clustered semantically into a relatively small number of core clusters, which are forwarded to other RL agents in a prescribed manner. (2) By defining state priorities and the contents for recording, core experiences can be selected and stored in a small container. We call this container as `BOOK'. Our method learns hundreds to thousand times faster than the conventional methods by learning only a handful of core cluster information, which shows that deep RL agents can effectively learn through the shared knowledge from other agents.\n    ",
        "submission_date": "2017-09-05T00:00:00",
        "last_modified_date": "2018-02-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.01490",
        "title": "Active Exploration for Learning Symbolic Representations",
        "authors": [
            "Garrett Andersen",
            "George Konidaris"
        ],
        "abstract": "We introduce an online active exploration algorithm for data-efficiently learning an abstract symbolic model of an environment. Our algorithm is divided into two parts: the first part quickly generates an intermediate Bayesian symbolic model from the data that the agent has collected so far, which the agent can then use along with the second part to guide its future exploration towards regions of the state space that the model is uncertain about. We show that our algorithm outperforms random and greedy exploration policies on two different computer game domains. The first domain is an Asteroids-inspired game with complex dynamics but basic logical structure. The second is the Treasure Game, with simpler dynamics but more complex logical structure.\n    ",
        "submission_date": "2017-09-05T00:00:00",
        "last_modified_date": "2017-11-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.01547",
        "title": "Knowledge Transfer Between Artificial Intelligence Systems",
        "authors": [
            "Ivan Y. Tyukin",
            "Alexander N. Gorban",
            "Konstantin Sofeikov",
            "Ilya Romanenko"
        ],
        "abstract": "We consider the fundamental question: how a legacy \"student\" Artificial Intelligent (AI) system could learn from a legacy \"teacher\" AI system or a human expert without complete re-training and, most importantly, without requiring significant computational resources. Here \"learning\" is understood as an ability of one system to mimic responses of the other and vice-versa. We call such learning an Artificial Intelligence knowledge transfer. We show that if internal variables of the \"student\" Artificial Intelligent system have the structure of an $n$-dimensional topological vector space and $n$ is sufficiently high then, with probability close to one, the required knowledge transfer can be implemented by simple cascades of linear functionals. In particular, for $n$ sufficiently large, with probability close to one, the \"student\" system can successfully and non-iteratively learn $k\\ll n$ new examples from the \"teacher\" (or correct the same number of mistakes) at the cost of two additional inner products. The concept is illustrated with an example of knowledge transfer from a pre-trained convolutional neural network to a simple linear classifier with HOG features.\n    ",
        "submission_date": "2017-09-05T00:00:00",
        "last_modified_date": "2017-11-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.01574",
        "title": "Opening the Black Box of Financial AI with CLEAR-Trade: A CLass-Enhanced Attentive Response Approach for Explaining and Visualizing Deep Learning-Driven Stock Market Prediction",
        "authors": [
            "Devinder Kumar",
            "Graham W Taylor",
            "Alexander Wong"
        ],
        "abstract": "Deep learning has been shown to outperform traditional machine learning algorithms across a wide range of problem domains. However, current deep learning algorithms have been criticized as uninterpretable \"black-boxes\" which cannot explain their decision making processes. This is a major shortcoming that prevents the widespread application of deep learning to domains with regulatory processes such as finance. As such, industries such as finance have to rely on traditional models like decision trees that are much more interpretable but less effective than deep learning for complex problems. In this paper, we propose CLEAR-Trade, a novel financial AI visualization framework for deep learning-driven stock market prediction that mitigates the interpretability issue of deep learning methods. In particular, CLEAR-Trade provides a effective way to visualize and explain decisions made by deep stock market prediction models. We show the efficacy of CLEAR-Trade in enhancing the interpretability of stock market prediction by conducting experiments based on S&P 500 stock index prediction. The results demonstrate that CLEAR-Trade can provide significant insight into the decision-making process of deep learning-driven financial models, particularly for regulatory processes, thus improving their potential uptake in the financial industry.\n    ",
        "submission_date": "2017-09-05T00:00:00",
        "last_modified_date": "2017-09-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.01989",
        "title": "Artificial Intelligence and Data Science in the Automotive Industry",
        "authors": [
            "Martin Hofmann",
            "Florian Neukart",
            "Thomas B\u00e4ck"
        ],
        "abstract": "Data science and machine learning are the key technologies when it comes to the processes and products with automatic learning and optimization to be used in the automotive industry of the future. This article defines the terms \"data science\" (also referred to as \"data analytics\") and \"machine learning\" and how they are related. In addition, it defines the term \"optimizing analytics\" and illustrates the role of automatic optimization as a key technology in combination with data analytics. It also uses examples to explain the way that these technologies are currently being used in the automotive industry on the basis of the major subprocesses in the automotive value chain (development, procurement; logistics, production, marketing, sales and after-sales, connected customer). Since the industry is just starting to explore the broad range of potential uses for these technologies, visionary application examples are used to illustrate the revolutionary possibilities that they offer. Finally, the article demonstrates how these technologies can make the automotive industry more efficient and enhance its customer focus throughout all its operations and activities, extending from the product and its development process to the customers and their connection to the product.\n    ",
        "submission_date": "2017-09-06T00:00:00",
        "last_modified_date": "2017-09-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.02256",
        "title": "Rationally Biased Learning",
        "authors": [
            "Michel de Lara"
        ],
        "abstract": "Humans display a tendency to pay more attention to bad outcomes, often in a disproportionate way relative to their statistical occurrence. They also display euphorism, as well as a preference for the current state of affairs (status quo bias). Based on the analysis of optimal solutions of infinite horizon stationary optimization problems under imperfect state observation, we show that such human perception and decision biases can be grounded in a form of rationality. We also provide conditions (boundaries) for their possible occurence and an analysis of their ",
        "submission_date": "2017-09-05T00:00:00",
        "last_modified_date": "2022-03-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.02357",
        "title": "Learning from lions: inferring the utility of agents from their trajectories",
        "authors": [
            "Adam D. Cobb",
            "Andrew Markham",
            "Stephen J. Roberts"
        ],
        "abstract": "We build a model using Gaussian processes to infer a spatio-temporal vector field from observed agent trajectories. Significant landmarks or influence points in agent surroundings are jointly derived through vector calculus operations that indicate presence of sources and sinks. We evaluate these influence points by using the Kullback-Leibler divergence between the posterior and prior Laplacian of the inferred spatio-temporal vector field. Through locating significant features that influence trajectories, our model aims to give greater insight into underlying causal utility functions that determine agent decision-making. A key feature of our model is that it infers a joint Gaussian process over the observed trajectories, the time-varying vector field of utility and canonical vector calculus operators. We apply our model to both synthetic data and lion GPS data collected at the Bubye Valley Conservancy in southern Zimbabwe.\n    ",
        "submission_date": "2017-09-07T00:00:00",
        "last_modified_date": "2017-09-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.02435",
        "title": "An Analysis of ISO 26262: Using Machine Learning Safely in Automotive Software",
        "authors": [
            "Rick Salay",
            "Rodrigo Queiroz",
            "Krzysztof Czarnecki"
        ],
        "abstract": "Machine learning (ML) plays an ever-increasing role in advanced automotive functionality for driver assistance and autonomous operation; however, its adequacy from the perspective of safety certification remains controversial. In this paper, we analyze the impacts that the use of ML as an implementation approach has on ISO 26262 safety lifecycle and ask what could be done to address them. We then provide a set of recommendations on how to adapt the standard to accommodate ML.\n    ",
        "submission_date": "2017-09-07T00:00:00",
        "last_modified_date": "2017-09-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.02618",
        "title": "The Shape of a Benedictine Monastery: The SaintGall Ontology (Extended Version)",
        "authors": [
            "Claudia Cantale",
            "Domenico Cantone",
            "Manuela Lupica Rinato",
            "Marianna Nicolosi-Asmundo",
            "Daniele Francesco Santamaria"
        ],
        "abstract": "We present an OWL 2 ontology representing the Saint Gall plan, one of the most ancient documents arrived intact to us, which describes the ideal model of a Benedictine monastic complex that inspired the design of many European monasteries.\n    ",
        "submission_date": "2017-09-08T00:00:00",
        "last_modified_date": "2024-02-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.02642",
        "title": "Object-Oriented Knowledge Extraction using Universal Exploiters",
        "authors": [
            "Dmytro Terletskyi"
        ],
        "abstract": "This paper contains analysis and extension of exploiters-based knowledge extraction methods, which allow generation of new knowledge, based on the basic ones. The main achievement of the paper is useful features of some universal exploiters proof, which allow extending set of basic classes and set of basic relations by finite set of new classes of objects and relations among them, which allow creating of complete lattice. Proposed approach gives an opportunity to compute quantity of new classes, which can be generated using it, and quantity of different types, which each of obtained classes describes; constructing of defined hierarchy of classes with determined subsumption relation; avoidance of some problems of inheritance and more efficient restoring of basic knowledge within the database.\n    ",
        "submission_date": "2017-09-08T00:00:00",
        "last_modified_date": "2017-09-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.02759",
        "title": "Semantic Preserving Embeddings for Generalized Graphs",
        "authors": [
            "Pedro Almagro-Blanco",
            "Fernando Sancho-Caparrini"
        ],
        "abstract": "A new approach to the study of Generalized Graphs as semantic data structures using machine learning techniques is presented. We show how vector representations maintaining semantic characteristics of the original data can be obtained from a given graph using neural encoding architectures and considering the topological properties of the graph. Semantic features of these new representations are tested by using some machine learning tasks and new directions on efficient link discovery, entitity retrieval and long distance query methodologies on large relational datasets are investigated using real datasets.\n",
        "submission_date": "2017-09-07T00:00:00",
        "last_modified_date": "2017-09-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.02844",
        "title": "Uncertainty measurement with belief entropy on interference effect in Quantum-Like Bayesian Networks",
        "authors": [
            "Zhiming Huang",
            "Lin Yang",
            "Wen Jiang"
        ],
        "abstract": "Social dilemmas have been regarded as the essence of evolution game theory, in which the prisoner's dilemma game is the most famous metaphor for the problem of cooperation. Recent findings revealed people's behavior violated the Sure Thing Principle in such games. Classic probability methodologies have difficulty explaining the underlying mechanisms of people's behavior. In this paper, a novel quantum-like Bayesian Network was proposed to accommodate the paradoxical phenomenon. The special network can take interference into consideration, which is likely to be an efficient way to describe the underlying mechanism. With the assistance of belief entropy, named as Deng entropy, the paper proposes Belief Distance to render the model practical. Tested with empirical data, the proposed model is proved to be predictable and effective.\n    ",
        "submission_date": "2017-09-08T00:00:00",
        "last_modified_date": "2017-09-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.02865",
        "title": "Prosocial learning agents solve generalized Stag Hunts better than selfish ones",
        "authors": [
            "Alexander Peysakhovich",
            "Adam Lerer"
        ],
        "abstract": "Deep reinforcement learning has become an important paradigm for constructing agents that can enter complex multi-agent situations and improve their policies through experience. One commonly used technique is reactive training - applying standard RL methods while treating other agents as a part of the learner's environment. It is known that in general-sum games reactive training can lead groups of agents to converge to inefficient outcomes. We focus on one such class of environments: Stag Hunt games. Here agents either choose a risky cooperative policy (which leads to high payoffs if both choose it but low payoffs to an agent who attempts it alone) or a safe one (which leads to a safe payoff no matter what). We ask how we can change the learning rule of a single agent to improve its outcomes in Stag Hunts that include other reactive learners. We extend existing work on reward-shaping in multi-agent reinforcement learning and show that that making a single agent prosocial, that is, making them care about the rewards of their partners can increase the probability that groups converge to good outcomes. Thus, even if we control a single agent in a group making that agent prosocial can increase our agent's long-run payoff. We show experimentally that this result carries over to a variety of more complex environments with Stag Hunt-like dynamics including ones where agents must learn from raw input pixels.\n    ",
        "submission_date": "2017-09-08T00:00:00",
        "last_modified_date": "2017-12-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.03114",
        "title": "Cognitive networks: brains, internet, and civilizations",
        "authors": [
            "Dmitrii Yu. Manin",
            "Yuri I. Manin"
        ],
        "abstract": "In this short essay, we discuss some basic features of cognitive activity at several different space-time scales: from neural networks in the brain to civilizations. One motivation for such comparative study is its heuristic value. Attempts to better understand the functioning of \"wetware\" involved in cognitive activities of central nervous system by comparing it with a computing device have a long tradition. We suggest that comparison with Internet might be more adequate. We briefly touch upon such subjects as encoding, compression, and Saussurean trichotomy langue/langage/parole in various environments.\n    ",
        "submission_date": "2017-09-10T00:00:00",
        "last_modified_date": "2017-09-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.03136",
        "title": "Computational Machines in a Coexistence with Concrete Universals and Data Streams",
        "authors": [
            "Vahid Moosavi"
        ],
        "abstract": "We discuss that how the majority of traditional modeling approaches are following the idealism point of view in scientific modeling, which follow the set theoretical notions of models based on abstract universals. We show that while successful in many classical modeling domains, there are fundamental limits to the application of set theoretical models in dealing with complex systems with many potential aspects or properties depending on the perspectives. As an alternative to abstract universals, we propose a conceptual modeling framework based on concrete universals that can be interpreted as a category theoretical approach to modeling. We call this modeling framework pre-specific modeling. We further, discuss how a certain group of mathematical and computational methods, along with ever-growing data streams are able to operationalize the concept of pre-specific modeling.\n    ",
        "submission_date": "2017-09-10T00:00:00",
        "last_modified_date": "2017-09-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.03267",
        "title": "Mining relevant interval rules",
        "authors": [
            "Thomas Guyet",
            "Ren\u00e9 Quiniou",
            "V\u00e9ronique Masson"
        ],
        "abstract": "This article extends the method of Garriga et al. for mining relevant rules to numerical attributes by extracting interval-based pattern rules. We propose an algorithm that extracts such rules from numerical datasets using the interval-pattern approach from Kaytoue et al. This algorithm has been implemented and evaluated on real datasets.\n    ",
        "submission_date": "2017-09-11T00:00:00",
        "last_modified_date": "2017-09-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.03270",
        "title": "Expert Opinion Extraction from a Biomedical Database",
        "authors": [
            "Ahmed Samet",
            "Thomas Guyet",
            "Benjamin Negrevergne",
            "Tien-Tuan Dao",
            "Tuan Nha Hoang",
            "Marie-Christine Ho Ba Tho"
        ],
        "abstract": "In this paper, we tackle the problem of extracting frequent opinions from uncertain databases. We introduce the foundation of an opinion mining approach with the definition of pattern and support measure. The support measure is derived from the commitment definition. A new algorithm called OpMiner that extracts the set of frequent opinions modelled as a mass functions is detailed. Finally, we apply our approach on a real-world biomedical database that stores opinions of experts to evaluate the reliability level of biomedical data. Performance analysis showed a better quality patterns for our proposed model in comparison with literature-based methods.\n    ",
        "submission_date": "2017-09-11T00:00:00",
        "last_modified_date": "2017-09-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.03309",
        "title": "Discriminant chronicles mining: Application to care pathways analytics",
        "authors": [
            "Yann Dauxais",
            "Thomas Guyet",
            "David Gross-Amblard",
            "Andr\u00e9 Happe"
        ],
        "abstract": "Pharmaco-epidemiology (PE) is the study of uses and effects of drugs in well defined populations. As medico-administrative databases cover a large part of the population, they have become very interesting to carry PE studies. Such databases provide longitudinal care pathways in real condition containing timestamped care events, especially drug deliveries. Temporal pattern mining becomes a strategic choice to gain valuable insights about drug uses. In this paper we propose DCM, a new discriminant temporal pattern mining algorithm. It extracts chronicle patterns that occur more in a studied population than in a control population. We present results on the identification of possible associations between hospitalizations for seizure and anti-epileptic drug switches in care pathway of epileptic patients.\n    ",
        "submission_date": "2017-09-11T00:00:00",
        "last_modified_date": "2017-09-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.03339",
        "title": "Autonomous Quadrotor Landing using Deep Reinforcement Learning",
        "authors": [
            "Riccardo Polvara",
            "Massimiliano Patacchiola",
            "Sanjay Sharma",
            "Jian Wan",
            "Andrew Manning",
            "Robert Sutton",
            "Angelo Cangelosi"
        ],
        "abstract": "Landing an unmanned aerial vehicle (UAV) on a ground marker is an open problem despite the effort of the research community. Previous attempts mostly focused on the analysis of hand-crafted geometric features and the use of external sensors in order to allow the vehicle to approach the land-pad. In this article, we propose a method based on deep reinforcement learning that only requires low-resolution images taken from a down-looking camera in order to identify the position of the marker and land the UAV on it. The proposed approach is based on a hierarchy of Deep Q-Networks (DQNs) used as high-level control policy for the navigation toward the marker. We implemented different technical solutions, such as the combination of vanilla and double DQNs, and a partitioned buffer replay. Using domain randomization we trained the vehicle on uniform textures and we tested it on a large variety of simulated and real-world environments. The overall performance is comparable with a state-of-the-art algorithm and human pilots.\n    ",
        "submission_date": "2017-09-11T00:00:00",
        "last_modified_date": "2018-02-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.03363",
        "title": "A Planning Approach to Monitoring Behavior of Computer Programs",
        "authors": [
            "Alexandre Cukier",
            "Ronen I. Brafman",
            "Yotam Perkal",
            "David Tolpin"
        ],
        "abstract": "We describe a novel approach to monitoring high level behaviors using concepts from AI planning. Our goal is to understand what a program is doing based on its system call trace. This ability is particularly important for detecting malware. We approach this problem by building an abstract model of the operating system using the STRIPS planning language, casting system calls as planning operators. Given a system call trace, we simulate the corresponding operators on our model and by observing the properties of the state reached, we learn about the nature of the original program and its behavior. Thus, unlike most statistical detection methods that focus on syntactic features, our approach is semantic in nature. Therefore, it is more robust against obfuscation techniques used by malware that change the outward appearance of the trace but not its effect. We demonstrate the efficacy of our approach by evaluating it on actual system call traces.\n    ",
        "submission_date": "2017-09-11T00:00:00",
        "last_modified_date": "2017-09-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.03413",
        "title": "Gigamachine: incremental machine learning on desktop computers",
        "authors": [
            "Eray \u00d6zkural"
        ],
        "abstract": "We present a concrete design for Solomonoff's incremental machine learning system suitable for desktop computers. We use R5RS Scheme and its standard library with a few omissions as the reference machine. We introduce a Levin Search variant based on a stochastic Context Free Grammar together with new update algorithms that use the same grammar as a guiding probability distribution for incremental machine learning. The updates include adjusting production probabilities, re-using previous solutions, learning programming idioms and discovery of frequent subprograms. The issues of extending the a priori probability distribution and bootstrapping are discussed. We have implemented a good portion of the proposed algorithms. Experiments with toy problems show that the update algorithms work as expected.\n    ",
        "submission_date": "2017-09-08T00:00:00",
        "last_modified_date": "2017-09-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.03480",
        "title": "Combining Strategic Learning and Tactical Search in Real-Time Strategy Games",
        "authors": [
            "Nicolas A. Barriga",
            "Marius Stanescu",
            "Michael Buro"
        ],
        "abstract": "A commonly used technique for managing AI complexity in real-time strategy (RTS) games is to use action and/or state abstractions. High-level abstractions can often lead to good strategic decision making, but tactical decision quality may suffer due to lost details. A competing method is to sample the search space which often leads to good tactical performance in simple scenarios, but poor high-level planning.\n",
        "submission_date": "2017-09-11T00:00:00",
        "last_modified_date": "2017-09-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.03854",
        "title": "Meta-QSAR: a large-scale application of meta-learning to drug design and discovery",
        "authors": [
            "Ivan Olier",
            "Noureddin Sadawi",
            "G. Richard Bickerton",
            "Joaquin Vanschoren",
            "Crina Grosan",
            "Larisa Soldatova",
            "Ross D. King"
        ],
        "abstract": "We investigate the learning of quantitative structure activity relationships (QSARs) as a case-study of meta-learning. This application area is of the highest societal importance, as it is a key step in the development of new medicines. The standard QSAR learning problem is: given a target (usually a protein) and a set of chemical compounds (small molecules) with associated bioactivities (e.g. inhibition of the target), learn a predictive mapping from molecular representation to activity. Although almost every type of machine learning method has been applied to QSAR learning there is no agreed single best way of learning QSARs, and therefore the problem area is well-suited to meta-learning. We first carried out the most comprehensive ever comparison of machine learning methods for QSAR learning: 18 regression methods, 6 molecular representations, applied to more than 2,700 QSAR problems. (These results have been made publicly available on OpenML and represent a valuable resource for testing novel meta-learning methods.) We then investigated the utility of algorithm selection for QSAR problems. We found that this meta-learning approach outperformed the best individual QSAR learning method (random forests using a molecular fingerprint representation) by up to 13%, on average. We conclude that meta-learning outperforms base-learning methods for QSAR learning, and as this investigation is one of the most extensive ever comparisons of base and meta-learning methods ever made, it provides evidence for the general effectiveness of meta-learning over base-learning.\n    ",
        "submission_date": "2017-09-12T00:00:00",
        "last_modified_date": "2017-09-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.03879",
        "title": "Ultimate Intelligence Part III: Measures of Intelligence, Perception and Intelligent Agents",
        "authors": [
            "Eray \u00d6zkural"
        ],
        "abstract": "We propose that operator induction serves as an adequate model of perception. We explain how to reduce universal agent models to operator induction. We propose a universal measure of operator induction fitness, and show how it can be used in a reinforcement learning model and a homeostasis (self-preserving) agent based on the free energy principle. We show that the action of the homeostasis agent can be explained by the operator induction model.\n    ",
        "submission_date": "2017-09-08T00:00:00",
        "last_modified_date": "2017-09-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.03915",
        "title": "Specious rules: an efficient and effective unifying method for removing misleading and uninformative patterns in association rule mining",
        "authors": [
            "Wilhelmiina H\u00e4m\u00e4l\u00e4inen",
            "Geoffrey I. Webb"
        ],
        "abstract": "We present theoretical analysis and a suite of tests and procedures for addressing a broad class of redundant and misleading association rules we call \\emph{specious rules}. Specious dependencies, also known as \\emph{spurious}, \\emph{apparent}, or \\emph{illusory associations}, refer to a well-known phenomenon where marginal dependencies are merely products of interactions with other variables and disappear when conditioned on those variables.\n",
        "submission_date": "2017-09-12T00:00:00",
        "last_modified_date": "2017-09-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.03946",
        "title": "Multimodal Content Analysis for Effective Advertisements on YouTube",
        "authors": [
            "Nikhita Vedula",
            "Wei Sun",
            "Hyunhwan Lee",
            "Harsh Gupta",
            "Mitsunori Ogihara",
            "Joseph Johnson",
            "Gang Ren",
            "Srinivasan Parthasarathy"
        ],
        "abstract": "The rapid advances in e-commerce and Web 2.0 technologies have greatly increased the impact of commercial advertisements on the general public. As a key enabling technology, a multitude of recommender systems exists which analyzes user features and browsing patterns to recommend appealing advertisements to users. In this work, we seek to study the characteristics or attributes that characterize an effective advertisement and recommend a useful set of features to aid the designing and production processes of commercial advertisements. We analyze the temporal patterns from multimedia content of advertisement videos including auditory, visual and textual components, and study their individual roles and synergies in the success of an advertisement. The objective of this work is then to measure the effectiveness of an advertisement, and to recommend a useful set of features to advertisement designers to make it more successful and approachable to users. Our proposed framework employs the signal processing technique of cross modality feature learning where data streams from different components are employed to train separate neural network models and are then fused together to learn a shared representation. Subsequently, a neural network model trained on this joint feature embedding representation is utilized as a classifier to predict advertisement effectiveness. We validate our approach using subjective ratings from a dedicated user study, the sentiment strength of online viewer comments, and a viewer opinion metric of the ratio of the Likes and Views received by each advertisement from an online platform.\n    ",
        "submission_date": "2017-09-12T00:00:00",
        "last_modified_date": "2017-09-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.03969",
        "title": "Explore, Exploit or Listen: Combining Human Feedback and Policy Model to Speed up Deep Reinforcement Learning in 3D Worlds",
        "authors": [
            "Zhiyu Lin",
            "Brent Harrison",
            "Aaron Keech",
            "Mark O. Riedl"
        ],
        "abstract": "We describe a method to use discrete human feedback to enhance the performance of deep learning agents in virtual three-dimensional environments by extending deep-reinforcement learning to model the confidence and consistency of human feedback. This enables deep reinforcement learning algorithms to determine the most appropriate time to listen to the human feedback, exploit the current policy model, or explore the agent's environment. Managing the trade-off between these three strategies allows DRL agents to be robust to inconsistent or intermittent human feedback. Through experimentation using a synthetic oracle, we show that our technique improves the training speed and overall performance of deep reinforcement learning in navigating three-dimensional environments using Minecraft. We further show that our technique is robust to highly innacurate human feedback and can also operate when no human feedback is given.\n    ",
        "submission_date": "2017-09-12T00:00:00",
        "last_modified_date": "2021-06-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.04029",
        "title": "Probability Reversal and the Disjunction Effect in Reasoning Systems",
        "authors": [
            "Subhash Kak"
        ],
        "abstract": "Data based judgments go into artificial intelligence applications but they undergo paradoxical reversal when seemingly unnecessary additional data is provided. Examples of this are Simpson's reversal and the disjunction effect where the beliefs about the data change once it is presented or aggregated differently. Sometimes the significance of the difference can be evaluated using statistical tests such as Pearson's chi-squared or Fisher's exact test, but this may not be helpful in threshold-based decision systems that operate with incomplete information. To mitigate risks in the use of algorithms in decision-making, we consider the question of modeling of beliefs. We argue that evidence supports that beliefs are not classical statistical variables and they should, in the general case, be considered as superposition states of disjoint or polar outcomes. We analyze the disjunction effect from the perspective of the belief as a quantum vector.\n    ",
        "submission_date": "2017-09-12T00:00:00",
        "last_modified_date": "2017-09-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.04049",
        "title": "Information Design in Crowdfunding under Thresholding Policies",
        "authors": [
            "Wen Shen",
            "Jacob W. Crandall",
            "Ke Yan",
            "Cristina V. Lopes"
        ],
        "abstract": "Crowdfunding has emerged as a prominent way for entrepreneurs to secure funding without sophisticated intermediation. In crowdfunding, an entrepreneur often has to decide how to disclose the campaign status in order to collect as many contributions as possible. Such decisions are difficult to make primarily due to incomplete information. We propose information design as a tool to help the entrepreneur to improve revenue by influencing backers' beliefs. We introduce a heuristic algorithm to dynamically compute information-disclosure policies for the entrepreneur, followed by an empirical evaluation to demonstrate its competitiveness over the widely-adopted immediate-disclosure policy. Our results demonstrate that the immediate-disclosure policy is not optimal when backers follow thresholding policies despite its ease of implementation. With appropriate heuristics, an entrepreneur can benefit from dynamic information disclosure. Our work sheds light on information design in a dynamic setting where agents make decisions using thresholding policies.\n    ",
        "submission_date": "2017-09-12T00:00:00",
        "last_modified_date": "2018-03-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.04182",
        "title": "Conflict management in information fusion with belief functions",
        "authors": [
            "Arnaud Martin"
        ],
        "abstract": "In Information fusion, the conflict is an important concept. Indeed, combining several imperfect experts or sources allows conflict. In the theory of belief functions, this notion has been discussed a lot. The mass appearing on the empty set during the conjunctive combination rule is generally considered as conflict, but that is not really a conflict. Some measures of conflict have been proposed and some approaches have been proposed in order to manage this conflict or to decide with conflicting mass functions. We recall in this chapter some of them and we propose a discussion to consider the conflict in information fusion with the theory of belief functions.\n    ",
        "submission_date": "2017-09-13T00:00:00",
        "last_modified_date": "2017-09-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.04240",
        "title": "A Comparison of Public Causal Search Packages on Linear, Gaussian Data with No Latent Variables",
        "authors": [
            "Joseph D. Ramsey",
            "Bryan Andrews"
        ],
        "abstract": "We compare Tetrad (Java) algorithms to the other public software packages BNT (Bayes Net Toolbox, Matlab), pcalg (R), bnlearn (R) on the \\vanilla\" task of recovering DAG structure to the extent possible from data generated recursively from linear, Gaussian structure equation models (SEMs) with no latent variables, for random graphs, with no additional knowledge of variable order or adjacency structure, and without additional specification of intervention information. Each one of the above packages offers at least one implementation suitable to this purpose. We compare them on adjacency and orientation accuracy as well as time performance, for fixed datasets. We vary the number of variables, the number of samples, and the density of graph, for a total of 27 combinations, averaging all statistics over 10 runs, for a total of 270 datasets. All runs are carried out on the same machine and on their native platforms. An interactive visualization tool is provided for the reader who wishes to know more than can be documented explicitly in this report.\n    ",
        "submission_date": "2017-09-13T00:00:00",
        "last_modified_date": "2017-09-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.04271",
        "title": "Action Schema Networks: Generalised Policies with Deep Learning",
        "authors": [
            "Sam Toyer",
            "Felipe Trevizan",
            "Sylvie Thi\u00e9baux",
            "Lexing Xie"
        ],
        "abstract": "In this paper, we introduce the Action Schema Network (ASNet): a neural network architecture for learning generalised policies for probabilistic planning problems. By mimicking the relational structure of planning problems, ASNets are able to adopt a weight-sharing scheme which allows the network to be applied to any problem from a given planning domain. This allows the cost of training the network to be amortised over all problems in that domain. Further, we propose a training method which balances exploration and supervised training on small problems to produce a policy which remains robust when evaluated on larger problems. In experiments, we show that ASNet's learning capability allows it to significantly outperform traditional non-learning planners in several challenging domains.\n    ",
        "submission_date": "2017-09-13T00:00:00",
        "last_modified_date": "2017-12-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.04326",
        "title": "Learning with Opponent-Learning Awareness",
        "authors": [
            "Jakob N. Foerster",
            "Richard Y. Chen",
            "Maruan Al-Shedivat",
            "Shimon Whiteson",
            "Pieter Abbeel",
            "Igor Mordatch"
        ],
        "abstract": "Multi-agent settings are quickly gathering importance in machine learning. This includes a plethora of recent work on deep multi-agent reinforcement learning, but also can be extended to hierarchical RL, generative adversarial networks and decentralised optimisation. In all these settings the presence of multiple learning agents renders the training problem non-stationary and often leads to unstable training or undesired final results. We present Learning with Opponent-Learning Awareness (LOLA), a method in which each agent shapes the anticipated learning of the other agents in the environment. The LOLA learning rule includes a term that accounts for the impact of one agent's policy on the anticipated parameter update of the other agents. Results show that the encounter of two LOLA agents leads to the emergence of tit-for-tat and therefore cooperation in the iterated prisoners' dilemma, while independent learning does not. In this domain, LOLA also receives higher payouts compared to a naive learner, and is robust against exploitation by higher order gradient-based methods. Applied to repeated matching pennies, LOLA agents converge to the Nash equilibrium. In a round robin tournament we show that LOLA agents successfully shape the learning of a range of multi-agent learning algorithms from literature, resulting in the highest average returns on the IPD. We also show that the LOLA update rule can be efficiently calculated using an extension of the policy gradient estimator, making the method suitable for model-free RL. The method thus scales to large parameter and input spaces and nonlinear function approximators. We apply LOLA to a grid world task with an embedded social dilemma using recurrent policies and opponent modelling. By explicitly considering the learning of the other agent, LOLA agents learn to cooperate out of self-interest. The code is at ",
        "submission_date": "2017-09-13T00:00:00",
        "last_modified_date": "2018-09-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.04328",
        "title": "Generating OWA weights using truncated distributions",
        "authors": [
            "Maxime Lenormand"
        ],
        "abstract": "Ordered weighted averaging (OWA) operators have been widely used in decision making these past few years. An important issue facing the OWA operators' users is the determination of the OWA weights. This paper introduces an OWA determination method based on truncated distributions that enables intuitive generation of OWA weights according to a certain level of risk and trade-off. These two dimensions are represented by the two first moments of the truncated distribution. We illustrate our approach with the well-know normal distribution and the definition of a continuous parabolic decision-strategy space. We finally study the impact of the number of criteria on the results.\n    ",
        "submission_date": "2017-09-13T00:00:00",
        "last_modified_date": "2018-02-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.04511",
        "title": "A Study of AI Population Dynamics with Million-agent Reinforcement Learning",
        "authors": [
            "Yaodong Yang",
            "Lantao Yu",
            "Yiwei Bai",
            "Jun Wang",
            "Weinan Zhang",
            "Ying Wen",
            "Yong Yu"
        ],
        "abstract": "We conduct an empirical study on discovering the ordered collective dynamics obtained by a population of intelligence agents, driven by million-agent reinforcement learning. Our intention is to put intelligent agents into a simulated natural context and verify if the principles developed in the real world could also be used in understanding an artificially-created intelligent population. To achieve this, we simulate a large-scale predator-prey world, where the laws of the world are designed by only the findings or logical equivalence that have been discovered in nature. We endow the agents with the intelligence based on deep reinforcement learning (DRL). In order to scale the population size up to millions agents, a large-scale DRL training platform with redesigned experience buffer is proposed. Our results show that the population dynamics of AI agents, driven only by each agent's individual self-interest, reveals an ordered pattern that is similar to the Lotka-Volterra model studied in population biology. We further discover the emergent behaviors of collective adaptations in studying how the agents' grouping behaviors will change with the environmental resources. Both of the two findings could be explained by the self-organization theory in nature.\n    ",
        "submission_date": "2017-09-13T00:00:00",
        "last_modified_date": "2018-05-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.04517",
        "title": "Visualizations for an Explainable Planning Agent",
        "authors": [
            "Tathagata Chakraborti",
            "Kshitij P. Fadnis",
            "Kartik Talamadupula",
            "Mishal Dholakia",
            "Biplav Srivastava",
            "Jeffrey O. Kephart",
            "Rachel K. E. Bellamy"
        ],
        "abstract": "In this paper, we report on the visualization capabilities of an Explainable AI Planning (XAIP) agent that can support human in the loop decision making. Imposing transparency and explainability requirements on such agents is especially important in order to establish trust and common ground with the end-to-end automated planning system. Visualizing the agent's internal decision-making processes is a crucial step towards achieving this. This may include externalizing the \"brain\" of the agent -- starting from its sensory inputs, to progressively higher order decisions made by it in order to drive its planning components. We also show how the planner can bootstrap on the latest techniques in explainable planning to cast plan visualization as a plan explanation problem, and thus provide concise model-based visualization of its plans. We demonstrate these functionalities in the context of the automated planning components of a smart assistant in an instrumented meeting space.\n    ",
        "submission_date": "2017-09-13T00:00:00",
        "last_modified_date": "2018-02-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.04524",
        "title": "Workflow Complexity for Collaborative Interactions: Where are the Metrics? -- A Challenge",
        "authors": [
            "Kartik Talamadupula",
            "Biplav Srivastava",
            "Jeffrey O. Kephart"
        ],
        "abstract": "In this paper, we introduce the problem of denoting and deriving the complexity of workflows (plans, schedules) in collaborative, planner-assisted settings where humans and agents are trying to jointly solve a task. The interactions -- and hence the workflows that connect the human and the agents -- may differ according to the domain and the kind of agents. We adapt insights from prior work in human-agent teaming and workflow analysis to suggest metrics for workflow complexity. The main motivation behind this work is to highlight metrics for human comprehensibility of plans and schedules. The planning community has seen its fair share of work on the synthesis of plans that take diversity into account -- what value do such plans hold if their generation is not guided at least in part by metrics that reflect the ease of engaging with and using those plans?\n    ",
        "submission_date": "2017-09-13T00:00:00",
        "last_modified_date": "2017-09-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.04571",
        "title": "When Waiting is not an Option : Learning Options with a Deliberation Cost",
        "authors": [
            "Jean Harb",
            "Pierre-Luc Bacon",
            "Martin Klissarov",
            "Doina Precup"
        ],
        "abstract": "Recent work has shown that temporally extended actions (options) can be learned fully end-to-end as opposed to being specified in advance. While the problem of \"how\" to learn options is increasingly well understood, the question of \"what\" good options should be has remained elusive. We formulate our answer to what \"good\" options should be in the bounded rationality framework (Simon, 1957) through the notion of deliberation cost. We then derive practical gradient-based learning algorithms to implement this objective. Our results in the Arcade Learning Environment (ALE) show increased performance and interpretability.\n    ",
        "submission_date": "2017-09-14T00:00:00",
        "last_modified_date": "2017-09-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.04579",
        "title": "Autonomous Extracting a Hierarchical Structure of Tasks in Reinforcement Learning and Multi-task Reinforcement Learning",
        "authors": [
            "Behzad Ghazanfari",
            "Matthew E. Taylor"
        ],
        "abstract": "Reinforcement learning (RL), while often powerful, can suffer from slow learning speeds, particularly in high dimensional spaces. The autonomous decomposition of tasks and use of hierarchical methods hold the potential to significantly speed up learning in such domains. This paper proposes a novel practical method that can autonomously decompose tasks, by leveraging association rule mining, which discovers hidden relationship among entities in data mining. We introduce a novel method called ARM-HSTRL (Association Rule Mining to extract Hierarchical Structure of Tasks in Reinforcement Learning). It extracts temporal and structural relationships of sub-goals in RL, and multi-task RL. In particular,it finds sub-goals and relationship among them. It is shown the significant efficiency and performance of the proposed method in two main topics of RL.\n    ",
        "submission_date": "2017-09-14T00:00:00",
        "last_modified_date": "2017-09-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.04636",
        "title": "Warmstarting of Model-based Algorithm Configuration",
        "authors": [
            "Marius Lindauer",
            "Frank Hutter"
        ],
        "abstract": "The performance of many hard combinatorial problem solvers depends strongly on their parameter settings, and since manual parameter tuning is both tedious and suboptimal the AI community has recently developed several algorithm configuration (AC) methods to automatically address this problem. While all existing AC methods start the configuration process of an algorithm A from scratch for each new type of benchmark instances, here we propose to exploit information about A's performance on previous benchmarks in order to warmstart its configuration on new types of benchmarks. We introduce two complementary ways in which we can exploit this information to warmstart AC methods based on a predictive model. Experiments for optimizing a very flexible modern SAT solver on twelve different instance sets show that our methods often yield substantial speedups over existing AC methods (up to 165-fold) and can also find substantially better configurations given the same compute budget.\n    ",
        "submission_date": "2017-09-14T00:00:00",
        "last_modified_date": "2017-11-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.04676",
        "title": "KBLRN : End-to-End Learning of Knowledge Base Representations with Latent, Relational, and Numerical Features",
        "authors": [
            "Alberto Garcia-Duran",
            "Mathias Niepert"
        ],
        "abstract": "We present KBLRN, a framework for end-to-end learning of knowledge base representations from latent, relational, and numerical features. KBLRN integrates feature types with a novel combination of neural representation learning and probabilistic product of experts models. To the best of our knowledge, KBLRN is the first approach that learns representations of knowledge bases by integrating latent, relational, and numerical features. We show that instances of KBLRN outperform existing methods on a range of knowledge base completion tasks. We contribute a novel data sets enriching commonly used knowledge base completion benchmarks with numerical features. The data sets are available under a permissive BSD-3 license. We also investigate the impact numerical features have on the KB completion performance of KBLRN.\n    ",
        "submission_date": "2017-09-14T00:00:00",
        "last_modified_date": "2018-06-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.04734",
        "title": "Perspectives for Evaluating Conversational AI",
        "authors": [
            "Mahipal Jadeja",
            "Neelanshi Varia"
        ],
        "abstract": "Conversational AI systems are becoming famous in day to day lives. In this paper, we are trying to address the following key question: To identify whether design, as well as development efforts for search oriented conversational AI are successful or ",
        "submission_date": "2017-09-14T00:00:00",
        "last_modified_date": "2017-09-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.04762",
        "title": "Denoising Autoencoders for Overgeneralization in Neural Networks",
        "authors": [
            "Giacomo Spigler"
        ],
        "abstract": "Despite the recent developments that allowed neural networks to achieve impressive performance on a variety of applications, these models are intrinsically affected by the problem of overgeneralization, due to their partitioning of the full input space into the fixed set of target classes used during training. Thus it is possible for novel inputs belonging to categories unknown during training or even completely unrecognizable to humans to fool the system into classifying them as one of the known classes, even with a high degree of confidence. Solving this problem may help improve the security of such systems in critical applications, and may further lead to applications in the context of open set recognition and 1-class recognition. This paper presents a novel way to compute a confidence score using denoising autoencoders and shows that such confidence score can correctly identify the regions of the input space close to the training distribution by approximately identifying its local maxima.\n    ",
        "submission_date": "2017-09-14T00:00:00",
        "last_modified_date": "2019-01-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.04763",
        "title": "Motif-based Rule Discovery for Predicting Real-valued Time Series",
        "authors": [
            "Yuanduo He",
            "Xu Chu",
            "Juguang Peng",
            "Jingyue Gao",
            "Yasha Wang"
        ],
        "abstract": "Time series prediction is of great significance in many applications and has attracted extensive attention from the data mining community. Existing work suggests that for many problems, the shape in the current time series may correlate an upcoming shape in the same or another series. Therefore, it is a promising strategy to associate two recurring patterns as a rule's antecedent and consequent: the occurrence of the antecedent can foretell the occurrence of the consequent, and the learned shape of consequent will give accurate predictions. Earlier work employs symbolization methods, but the symbolized representation maintains too little information of the original series to mine valid rules. The state-of-the-art work, though directly manipulating the series, fails to segment the series precisely for seeking antecedents/consequents, resulting in inaccurate rules in common scenarios. In this paper, we propose a novel motif-based rule discovery method, which utilizes motif discovery to accurately extract frequently occurring consecutive subsequences, i.e. motifs, as antecedents/consequents. It then investigates the underlying relationships between motifs by matching motifs as rule candidates and ranking them based on the similarities. Experimental results on real open datasets show that the proposed approach outperforms the baseline method by 23.9%. Furthermore, it extends the applicability from single time series to multiple ones.\n    ",
        "submission_date": "2017-09-14T00:00:00",
        "last_modified_date": "2017-12-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.04794",
        "title": "Fast semi-supervised discriminant analysis for binary classification of large data-sets",
        "authors": [
            "Joris Tavernier",
            "Jaak Simm",
            "Karl Meerbergen",
            "Joerg Kurt Wegner",
            "Hugo Ceulemans",
            "Yves Moreau"
        ],
        "abstract": "High-dimensional data requires scalable algorithms. We propose and analyze three scalable and related algorithms for semi-supervised discriminant analysis (SDA). These methods are based on Krylov subspace methods which exploit the data sparsity and the shift-invariance of Krylov subspaces. In addition, the problem definition was improved by adding centralization to the semi-supervised setting. The proposed methods are evaluated on a industry-scale data set from a pharmaceutical company to predict compound activity on target proteins. The results show that SDA achieves good predictive performance and our methods only require a few seconds, significantly improving computation time on previous state of the art.\n    ",
        "submission_date": "2017-09-14T00:00:00",
        "last_modified_date": "2018-03-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.04825",
        "title": "General problem solving with category theory",
        "authors": [
            "Francisco J. Arjonilla",
            "Tetsuya Ogata"
        ],
        "abstract": "This paper proposes a formal cognitive framework for problem solving based on category theory. We introduce cognitive categories, which are categories with exactly one morphism between any two objects. Objects in these categories are interpreted as states and morphisms as transformations between states. Moreover, cognitive problems are reduced to the specification of two objects in a cognitive category: an outset (i.e. the current state of the system) and a goal (i.e. the desired state). Cognitive systems transform the target system by means of generators and evaluators. Generators realize cognitive operations over a system by grouping morphisms, whilst evaluators group objects as a way to generalize outsets and goals to partially defined states. Meta-cognition emerges when the whole cognitive system is self-referenced as sub-states in the cognitive category, whilst learning must always be considered as a meta-cognitive process to maintain consistency. Several examples grounded in basic AI methods are provided as well.\n    ",
        "submission_date": "2017-09-14T00:00:00",
        "last_modified_date": "2017-09-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.05036",
        "title": "Query-based Attention CNN for Text Similarity Map",
        "authors": [
            "Tzu-Chien Liu",
            "Yu-Hsueh Wu",
            "Hung-Yi Lee"
        ],
        "abstract": "In this paper, we introduce Query-based Attention CNN(QACNN) for Text Similarity Map, an end-to-end neural network for question answering. This network is composed of compare mechanism, two-staged CNN architecture with attention mechanism, and a prediction layer. First, the compare mechanism compares between the given passage, query, and multiple answer choices to build similarity maps. Then, the two-staged CNN architecture extracts features through word-level and sentence-level. At the same time, attention mechanism helps CNN focus more on the important part of the passage based on the query information. Finally, the prediction layer find out the most possible answer choice. We conduct this model on the MovieQA dataset using Plot Synopses only, and achieve 79.99% accuracy which is the state of the art on the dataset.\n    ",
        "submission_date": "2017-09-15T00:00:00",
        "last_modified_date": "2017-10-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.05067",
        "title": "Deep Reinforcement Learning for Conversational AI",
        "authors": [
            "Mahipal Jadeja",
            "Neelanshi Varia",
            "Agam Shah"
        ],
        "abstract": "Deep reinforcement learning is revolutionizing the artificial intelligence field. Currently, it serves as a good starting point for constructing intelligent autonomous systems which offer a better knowledge of the visual world. It is possible to scale deep reinforcement learning with the use of deep learning and do amazing tasks such as use of pixels in playing video games. In this paper, key concepts of deep reinforcement learning including reward function, differences between reinforcement learning and supervised learning and models for implementation of reinforcement are discussed. Key challenges related to the implementation of reinforcement learning in conversational AI domain are identified as well as discussed in detail. Various conversational models which are based on deep reinforcement learning (as well as deep learning) are also discussed. In summary, this paper discusses key aspects of deep reinforcement learning which are crucial for designing an efficient conversational AI.\n    ",
        "submission_date": "2017-09-15T00:00:00",
        "last_modified_date": "2017-09-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.05077",
        "title": "Transforming Cooling Optimization for Green Data Center via Deep Reinforcement Learning",
        "authors": [
            "Yuanlong Li",
            "Yonggang Wen",
            "Kyle Guan",
            "Dacheng Tao"
        ],
        "abstract": "Cooling system plays a critical role in a modern data center (DC). Developing an optimal control policy for DC cooling system is a challenging task. The prevailing approaches often rely on approximating system models that are built upon the knowledge of mechanical cooling, electrical and thermal management, which is difficult to design and may lead to sub-optimal or unstable performances. In this paper, we propose utilizing the large amount of monitoring data in DC to optimize the control policy. To do so, we cast the cooling control policy design into an energy cost minimization problem with temperature constraints, and tap it into the emerging deep reinforcement learning (DRL) framework. Specifically, we propose an end-to-end cooling control algorithm (CCA) that is based on the actor-critic framework and an off-policy offline version of the deep deterministic policy gradient (DDPG) algorithm. In the proposed CCA, an evaluation network is trained to predict an energy cost counter penalized by the cooling status of the DC room, and a policy network is trained to predict optimized control settings when gave the current load and weather information. The proposed algorithm is evaluated on the EnergyPlus simulation platform and on a real data trace collected from the National Super Computing Centre (NSCC) of Singapore. Our results show that the proposed CCA can achieve about 11% cooling cost saving on the simulation platform compared with a manually configured baseline control algorithm. In the trace-based study, we propose a de-underestimation validation mechanism as we cannot directly test the algorithm on a real DC. Even though with DUE the results are conservative, we can still achieve about 15% cooling energy saving on the NSCC data trace if we set the inlet temperature threshold at 26.6 degree Celsius.\n    ",
        "submission_date": "2017-09-15T00:00:00",
        "last_modified_date": "2018-07-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.05185",
        "title": "Unsupervised state representation learning with robotic priors: a robustness benchmark",
        "authors": [
            "Timoth\u00e9e Lesort",
            "Mathieu Seurin",
            "Xinrui Li",
            "Natalia D\u00edaz-Rodr\u00edguez",
            "David Filliat"
        ],
        "abstract": "Our understanding of the world depends highly on our capacity to produce intuitive and simplified representations which can be easily used to solve problems. We reproduce this simplification process using a neural network to build a low dimensional state representation of the world from images acquired by a robot. As in Jonschkowski et al. 2015, we learn in an unsupervised way using prior knowledge about the world as loss functions called robotic priors and extend this approach to high dimension richer images to learn a 3D representation of the hand position of a robot from RGB images. We propose a quantitative evaluation of the learned representation using nearest neighbors in the state space that allows to assess its quality and show both the potential and limitations of robotic priors in realistic environments. We augment image size, add distractors and domain randomization, all crucial components to achieve transfer learning to real robots. Finally, we also contribute a new prior to improve the robustness of the representation. The applications of such low dimensional state representation range from easing reinforcement learning (RL) and knowledge transfer across tasks, to facilitating learning from raw data with more efficient and compact high level representations. The results show that the robotic prior approach is able to extract high level representation as the 3D position of an arm and organize it into a compact and coherent space of states in a challenging dataset.\n    ",
        "submission_date": "2017-09-15T00:00:00",
        "last_modified_date": "2017-09-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.05262",
        "title": "Supervising Unsupervised Learning",
        "authors": [
            "Vikas K. Garg",
            "Adam Kalai"
        ],
        "abstract": "We introduce a framework to leverage knowledge acquired from a repository of (heterogeneous) supervised datasets to new unsupervised datasets. Our perspective avoids the subjectivity inherent in unsupervised learning by reducing it to supervised learning, and provides a principled way to evaluate unsupervised algorithms. We demonstrate the versatility of our framework via simple agnostic bounds on unsupervised problems. In the context of clustering, our approach helps choose the number of clusters and the clustering algorithm, remove the outliers, and provably circumvent the Kleinberg's impossibility result. Experimental results across hundreds of problems demonstrate improved performance on unsupervised data with simple algorithms, despite the fact that our problems come from heterogeneous domains. Additionally, our framework lets us leverage deep networks to learn common features from many such small datasets, and perform zero shot learning.\n    ",
        "submission_date": "2017-09-14T00:00:00",
        "last_modified_date": "2018-02-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.05380",
        "title": "The Uncertainty Bellman Equation and Exploration",
        "authors": [
            "Brendan O'Donoghue",
            "Ian Osband",
            "Remi Munos",
            "Volodymyr Mnih"
        ],
        "abstract": "We consider the exploration/exploitation problem in reinforcement learning. For exploitation, it is well known that the Bellman equation connects the value at any time-step to the expected value at subsequent time-steps. In this paper we consider a similar \\textit{uncertainty} Bellman equation (UBE), which connects the uncertainty at any time-step to the expected uncertainties at subsequent time-steps, thereby extending the potential exploratory benefit of a policy beyond individual time-steps. We prove that the unique fixed point of the UBE yields an upper bound on the variance of the posterior distribution of the Q-values induced by any policy. This bound can be much tighter than traditional count-based bonuses that compound standard deviation rather than variance. Importantly, and unlike several existing approaches to optimism, this method scales naturally to large systems with complex generalization. Substituting our UBE-exploration strategy for $\\epsilon$-greedy improves DQN performance on 51 out of 57 games in the Atari suite.\n    ",
        "submission_date": "2017-09-15T00:00:00",
        "last_modified_date": "2018-10-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.05453",
        "title": "Augmenting End-to-End Dialog Systems with Commonsense Knowledge",
        "authors": [
            "Tom Young",
            "Erik Cambria",
            "Iti Chaturvedi",
            "Minlie Huang",
            "Hao Zhou",
            "Subham Biswas"
        ],
        "abstract": "Building dialog agents that can converse naturally with humans is a challenging yet intriguing problem of artificial intelligence. In open-domain human-computer conversation, where the conversational agent is expected to respond to human responses in an interesting and engaging way, commonsense knowledge has to be integrated into the model effectively. In this paper, we investigate the impact of providing commonsense knowledge about the concepts covered in the dialog. Our model represents the first attempt to integrating a large commonsense knowledge base into end-to-end conversational models. In the retrieval-based scenario, we propose the Tri-LSTM model to jointly take into account message and commonsense for selecting an appropriate response. Our experiments suggest that the knowledge-augmented models are superior to their knowledge-free counterparts in automatic evaluation.\n    ",
        "submission_date": "2017-09-16T00:00:00",
        "last_modified_date": "2018-02-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.05601",
        "title": "Markov Brains: A Technical Introduction",
        "authors": [
            "Arend Hintze",
            "Jeffrey A. Edlund",
            "Randal S. Olson",
            "David B. Knoester",
            "Jory Schossau",
            "Larissa Albantakis",
            "Ali Tehrani-Saleh",
            "Peter Kvam",
            "Leigh Sheneman",
            "Heather Goldsby",
            "Clifford Bohm",
            "Christoph Adami"
        ],
        "abstract": "Markov Brains are a class of evolvable artificial neural networks (ANN). They differ from conventional ANNs in many aspects, but the key difference is that instead of a layered architecture, with each node performing the same function, Markov Brains are networks built from individual computational components. These computational components interact with each other, receive inputs from sensors, and control motor outputs. The function of the computational components, their connections to each other, as well as connections to sensors and motors are all subject to evolutionary optimization. Here we describe in detail how a Markov Brain works, what techniques can be used to study them, and how they can be evolved.\n    ",
        "submission_date": "2017-09-17T00:00:00",
        "last_modified_date": "2017-09-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.05638",
        "title": "Improving Search through A3C Reinforcement Learning based Conversational Agent",
        "authors": [
            "Milan Aggarwal",
            "Aarushi Arora",
            "Shagun Sodhani",
            "Balaji Krishnamurthy"
        ],
        "abstract": "We develop a reinforcement learning based search assistant which can assist users through a set of actions and sequence of interactions to enable them realize their intent. Our approach caters to subjective search where the user is seeking digital assets such as images which is fundamentally different from the tasks which have objective and limited search modalities. Labeled conversational data is generally not available in such search tasks and training the agent through human interactions can be time consuming. We propose a stochastic virtual user which impersonates a real user and can be used to sample user behavior efficiently to train the agent which accelerates the bootstrapping of the agent. We develop A3C algorithm based context preserving architecture which enables the agent to provide contextual assistance to the user. We compare the A3C agent with Q-learning and evaluate its performance on average rewards and state values it obtains with the virtual user in validation episodes. Our experiments show that the agent learns to achieve higher rewards and better states.\n    ",
        "submission_date": "2017-09-17T00:00:00",
        "last_modified_date": "2018-08-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.05684",
        "title": "A Categorical Approach for Recognizing Emotional Effects of Music",
        "authors": [
            "Mohsen Sahraei Ardakani",
            "Ehsan Arbabi"
        ],
        "abstract": "Recently, digital music libraries have been developed and can be plainly accessed. Latest research showed that current organization and retrieval of music tracks based on album information are inefficient. Moreover, they demonstrated that people use emotion tags for music tracks in order to search and retrieve them. In this paper, we discuss separability of a set of emotional labels, proposed in the categorical emotion expression, using Fisher's separation theorem. We determine a set of adjectives to tag music parts: happy, sad, relaxing, exciting, epic and thriller. Temporal, frequency and energy features have been extracted from the music parts. It could be seen that the maximum separability within the extracted features occurs between relaxing and epic music parts. Finally, we have trained a classifier using Support Vector Machines to automatically recognize and generate emotional labels for a music part. Accuracy for recognizing each label has been calculated; where the results show that epic music can be recognized more accurately (77.4%), comparing to the other types of music.\n    ",
        "submission_date": "2017-09-17T00:00:00",
        "last_modified_date": "2017-09-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.05703",
        "title": "AI Programmer: Autonomously Creating Software Programs Using Genetic Algorithms",
        "authors": [
            "Kory Becker",
            "Justin Gottschlich"
        ],
        "abstract": "In this paper, we present the first-of-its-kind machine learning (ML) system, called AI Programmer, that can automatically generate full software programs requiring only minimal human guidance. At its core, AI Programmer uses genetic algorithms (GA) coupled with a tightly constrained programming language that minimizes the overhead of its ML search space. Part of AI Programmer's novelty stems from (i) its unique system design, including an embedded, hand-crafted interpreter for efficiency and security and (ii) its augmentation of GAs to include instruction-gene randomization bindings and programming language-specific genome construction and elimination techniques. We provide a detailed examination of AI Programmer's system design, several examples detailing how the system works, and experimental data demonstrating its software generation capabilities and performance using only mainstream CPUs.\n    ",
        "submission_date": "2017-09-17T00:00:00",
        "last_modified_date": "2017-09-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.05706",
        "title": "Memory Augmented Control Networks",
        "authors": [
            "Arbaaz Khan",
            "Clark Zhang",
            "Nikolay Atanasov",
            "Konstantinos Karydis",
            "Vijay Kumar",
            "Daniel D. Lee"
        ],
        "abstract": "Planning problems in partially observable environments cannot be solved directly with convolutional networks and require some form of memory. But, even memory networks with sophisticated addressing schemes are unable to learn intelligent reasoning satisfactorily due to the complexity of simultaneously learning to access memory and plan. To mitigate these challenges we introduce the Memory Augmented Control Network (MACN). The proposed network architecture consists of three main parts. The first part uses convolutions to extract features and the second part uses a neural network-based planning module to pre-plan in the environment. The third part uses a network controller that learns to store those specific instances of past information that are necessary for planning. The performance of the network is evaluated in discrete grid world environments for path planning in the presence of simple and complex obstacles. We show that our network learns to plan and can generalize to new environments.\n    ",
        "submission_date": "2017-09-17T00:00:00",
        "last_modified_date": "2018-02-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.05825",
        "title": "Relational Marginal Problems: Theory and Estimation",
        "authors": [
            "Ondrej Kuzelka",
            "Yuyi Wang",
            "Jesse Davis",
            "Steven Schockaert"
        ],
        "abstract": "In the propositional setting, the marginal problem is to find a (maximum-entropy) distribution that has some given marginals. We study this problem in a relational setting and make the following contributions. First, we compare two different notions of relational marginals. Second, we show a duality between the resulting relational marginal problems and the maximum likelihood estimation of the parameters of relational models, which generalizes a well-known duality from the propositional setting. Third, by exploiting the relational marginal formulation, we present a statistically sound method to learn the parameters of relational models that will be applied in settings where the number of constants differs between the training and test data. Furthermore, based on a relational generalization of marginal polytopes, we characterize cases where the standard estimators based on feature's number of true groundings needs to be adjusted and we quantitatively characterize the consequences of these adjustments. Fourth, we prove bounds on expected errors of the estimated parameters, which allows us to lower-bound, among other things, the effective sample size of relational training data.\n    ",
        "submission_date": "2017-09-18T00:00:00",
        "last_modified_date": "2018-04-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.05948",
        "title": "The shortest way to visit all metro lines in a city",
        "authors": [
            "Florian Sikora"
        ],
        "abstract": "What if $\\{$a tourist, a train addict, Dr. Sheldon Cooper, somebody who likes to waste time$\\}$ wants to visit all metro lines or carriages in a given network in a minimum number of steps? We study this problem with an application to the metro network of Paris and Tokyo, proposing optimal solutions thanks to mathematical programming tools. Quite surprisingly, it appears that you can visit all 16 Parisian metro lines in only 26 steps (we denote by a step the act of taking the metro from one station to an adjacent one). Perhaps even more surprisingly, adding the 5 RER lines to these 16 lines does not increase the size of the best solution. It is also possible to visit the 13 lines of (the dense network of) Tokyo with only 15 steps.\n    ",
        "submission_date": "2017-09-13T00:00:00",
        "last_modified_date": "2018-04-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.05958",
        "title": "Toward Cognitive and Immersive Systems: Experiments in a Cognitive Microworld",
        "authors": [
            "Matthew Peveler",
            "Naveen Sundar Govindarajulu",
            "Selmer Bringsjord",
            "Atriya Sen",
            "Biplav Srivastava",
            "Kartik Talamadupula",
            "Hui Su"
        ],
        "abstract": "As computational power has continued to increase, and sensors have become more accurate, the corresponding advent of systems that are at once cognitive and immersive has arrived. These \\textit{cognitive and immersive systems} (CAISs) fall squarely into the intersection of AI with HCI/HRI: such systems interact with and assist the human agents that enter them, in no small part because such systems are infused with AI able to understand and reason about these humans and their knowledge, beliefs, goals, communications, plans, etc. We herein explain our approach to engineering CAISs. We emphasize the capacity of a CAIS to develop and reason over a `theory of the mind' of its human partners. This capacity entails that the AI in question has a sophisticated model of the beliefs, knowledge, goals, desires, emotions, etc.\\ of these humans. To accomplish this engineering, a formal framework of very high expressivity is needed. In our case, this framework is a \\textit{cognitive event calculus}, a particular kind of quantified multi-operator modal logic, and a matching high-expressivity automated reasoner and planner. To explain, advance, and to a degree validate our approach, we show that a calculus of this type satisfies a set of formal requirements, and can enable a CAIS to understand a psychologically tricky scenario couched in what we call the \\textit{cognitive polysolid framework} (CPF). We also formally show that a room that satisfies these requirements can have a useful property we term \\emph{expectation of usefulness}. CPF, a sub-class of \\textit{cognitive microworlds}, includes machinery able to represent and plan over not merely blocks and actions (such as seen in the primitive `blocks worlds' of old), but also over agents and their mental attitudes about both other agents and inanimate objects.\n    ",
        "submission_date": "2017-09-14T00:00:00",
        "last_modified_date": "2018-12-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.06166",
        "title": "DropoutDAgger: A Bayesian Approach to Safe Imitation Learning",
        "authors": [
            "Kunal Menda",
            "Katherine Driggs-Campbell",
            "Mykel J. Kochenderfer"
        ],
        "abstract": "While imitation learning is becoming common practice in robotics, this approach often suffers from data mismatch and compounding errors. DAgger is an iterative algorithm that addresses these issues by continually aggregating training data from both the expert and novice policies, but does not consider the impact of safety. We present a probabilistic extension to DAgger, which uses the distribution over actions provided by the novice policy, for a given observation. Our method, which we call DropoutDAgger, uses dropout to train the novice as a Bayesian neural network that provides insight to its confidence. Using the distribution over the novice's actions, we estimate a probabilistic measure of safety with respect to the expert action, tuned to balance exploration and exploitation. The utility of this approach is evaluated on the MuJoCo HalfCheetah and in a simple driving experiment, demonstrating improved performance and safety compared to other DAgger variants and classic imitation learning.\n    ",
        "submission_date": "2017-09-18T00:00:00",
        "last_modified_date": "2017-09-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.06196",
        "title": "Online algorithms for POMDPs with continuous state, action, and observation spaces",
        "authors": [
            "Zachary Sunberg",
            "Mykel Kochenderfer"
        ],
        "abstract": "Online solvers for partially observable Markov decision processes have been applied to problems with large discrete state spaces, but continuous state, action, and observation spaces remain a challenge. This paper begins by investigating double progressive widening (DPW) as a solution to this challenge. However, we prove that this modification alone is not sufficient because the belief representations in the search tree collapse to a single particle causing the algorithm to converge to a policy that is suboptimal regardless of the computation time. This paper proposes and evaluates two new algorithms, POMCPOW and PFT-DPW, that overcome this deficiency by using weighted particle filtering. Simulation results show that these modifications allow the algorithms to be successful where previous approaches fail.\n    ",
        "submission_date": "2017-09-18T00:00:00",
        "last_modified_date": "2018-09-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.06201",
        "title": "Human Understandable Explanation Extraction for Black-box Classification Models Based on Matrix Factorization",
        "authors": [
            "Jaedeok Kim",
            "Jingoo Seo"
        ],
        "abstract": "In recent years, a number of artificial intelligent services have been developed such as defect detection system or diagnosis system for customer services. Unfortunately, the core in these services is a black-box in which human cannot understand the underlying decision making logic, even though the inspection of the logic is crucial before launching a commercial service. Our goal in this paper is to propose an analytic method of a model explanation that is applicable to general classification models. To this end, we introduce the concept of a contribution matrix and an explanation embedding in a constraint space by using a matrix factorization. We extract a rule-like model explanation from the contribution matrix with the help of the nonnegative matrix factorization. To validate our method, the experiment results provide with open datasets as well as an industry dataset of a LTE network diagnosis and the results show our method extracts reasonable explanations.\n    ",
        "submission_date": "2017-09-18T00:00:00",
        "last_modified_date": "2017-09-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.06275",
        "title": "Incorrigibility in the CIRL Framework",
        "authors": [
            "Ryan Carey"
        ],
        "abstract": "A value learning system has incentives to follow shutdown instructions, assuming the shutdown instruction provides information (in the technical sense) about which actions lead to valuable outcomes. However, this assumption is not robust to model mis-specification (e.g., in the case of programmer errors). We demonstrate this by presenting some Supervised POMDP scenarios in which errors in the parameterized reward function remove the incentive to follow shutdown commands. These difficulties parallel those discussed by Soares et al. (2015) in their paper on corrigibility. We argue that it is important to consider systems that follow shutdown commands under some weaker set of assumptions (e.g., that one small verified module is correctly implemented; as opposed to an entire prior probability distribution and/or parameterized reward function). We discuss some difficulties with simple ways to attempt to attain these sorts of guarantees in a value learning framework.\n    ",
        "submission_date": "2017-09-19T00:00:00",
        "last_modified_date": "2018-06-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.06404",
        "title": "Interactive Music Generation with Positional Constraints using Anticipation-RNNs",
        "authors": [
            "Ga\u00ebtan Hadjeres",
            "Frank Nielsen"
        ],
        "abstract": "Recurrent Neural Networks (RNNS) are now widely used on sequence generation tasks due to their ability to learn long-range dependencies and to generate sequences of arbitrary length. However, their left-to-right generation procedure only allows a limited control from a potential user which makes them unsuitable for interactive and creative usages such as interactive music generation. This paper introduces a novel architecture called Anticipation-RNN which possesses the assets of the RNN-based generative models while allowing to enforce user-defined positional constraints. We demonstrate its efficiency on the task of generating melodies satisfying positional constraints in the style of the soprano parts of the J.S. Bach chorale harmonizations. Sampling using the Anticipation-RNN is of the same order of complexity than sampling from the traditional RNN model. This fast and interactive generation of musical sequences opens ways to devise real-time systems that could be used for creative purposes.\n    ",
        "submission_date": "2017-09-19T00:00:00",
        "last_modified_date": "2017-09-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.06493",
        "title": "Learning to update Auto-associative Memory in Recurrent Neural Networks for Improving Sequence Memorization",
        "authors": [
            "Wei Zhang",
            "Bowen Zhou"
        ],
        "abstract": "Learning to remember long sequences remains a challenging task for recurrent neural networks. Register memory and attention mechanisms were both proposed to resolve the issue with either high computational cost to retain memory differentiability, or by discounting the RNN representation learning towards encoding shorter local contexts than encouraging long sequence encoding. Associative memory, which studies the compression of multiple patterns in a fixed size memory, were rarely considered in recent years. Although some recent work tries to introduce associative memory in RNN and mimic the energy decay process in Hopfield nets, it inherits the shortcoming of rule-based memory updates, and the memory capacity is limited. This paper proposes a method to learn the memory update rule jointly with task objective to improve memory capacity for remembering long sequences. Also, we propose an architecture that uses multiple such associative memory for more complex input encoding. We observed some interesting facts when compared to other RNN architectures on some well-studied sequence learning tasks.\n    ",
        "submission_date": "2017-09-19T00:00:00",
        "last_modified_date": "2017-10-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.06656",
        "title": "Deep Reinforcement Learning for Event-Driven Multi-Agent Decision Processes",
        "authors": [
            "Kunal Menda",
            "Yi-Chun Chen",
            "Justin Grana",
            "James W. Bono",
            "Brendan D. Tracey",
            "Mykel J. Kochenderfer",
            "David Wolpert"
        ],
        "abstract": "The incorporation of macro-actions (temporally extended actions) into multi-agent decision problems has the potential to address the curse of dimensionality associated with such decision problems. Since macro-actions last for stochastic durations, multiple agents executing decentralized policies in cooperative environments must act asynchronously. We present an algorithm that modifies generalized advantage estimation for temporally extended actions, allowing a state-of-the-art policy optimization algorithm to optimize policies in Dec-POMDPs in which agents act asynchronously. We show that our algorithm is capable of learning optimal policies in two cooperative domains, one involving real-time bus holding control and one involving wildfire fighting with unmanned aircraft. Our algorithm works by framing problems as \"event-driven decision processes,\" which are scenarios in which the sequence and timing of actions and events are random and governed by an underlying stochastic process. In addition to optimizing policies with continuous state and action spaces, our algorithm also facilitates the use of event-driven simulators, which do not require time to be discretized into time-steps. We demonstrate the benefit of using event-driven simulation in the context of multiple agents taking asynchronous actions. We show that fixed time-step simulation risks obfuscating the sequence in which closely separated events occur, adversely affecting the policies learned. In addition, we show that arbitrarily shrinking the time-step scales poorly with the number of agents.\n    ",
        "submission_date": "2017-09-19T00:00:00",
        "last_modified_date": "2019-05-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.06692",
        "title": "A Voting-Based System for Ethical Decision Making",
        "authors": [
            "Ritesh Noothigattu",
            "Snehalkumar 'Neil' S. Gaikwad",
            "Edmond Awad",
            "Sohan Dsouza",
            "Iyad Rahwan",
            "Pradeep Ravikumar",
            "Ariel D. Procaccia"
        ],
        "abstract": "We present a general approach to automating ethical decisions, drawing on machine learning and computational social choice. In a nutshell, we propose to learn a model of societal preferences, and, when faced with a specific ethical dilemma at runtime, efficiently aggregate those preferences to identify a desirable choice. We provide a concrete algorithm that instantiates our approach; some of its crucial steps are informed by a new theory of swap-dominance efficient voting rules. Finally, we implement and evaluate a system for ethical decision making in the autonomous vehicle domain, using preference data collected from 1.3 million people through the Moral Machine website.\n    ",
        "submission_date": "2017-09-20T00:00:00",
        "last_modified_date": "2018-12-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.06772",
        "title": "Temporal Pattern Mining from Evolving Networks",
        "authors": [
            "Angelo Impedovo",
            "Corrado Loglisci",
            "Michelangelo Ceci"
        ],
        "abstract": "Recently, evolving networks are becoming a suitable form to model many real-world complex systems, due to their peculiarities to represent the systems and their constituting entities, the interactions between the entities and the time-variability of their structure and properties. Designing computational models able to analyze evolving networks becomes relevant in many applications. The goal of this research project is to evaluate the possible contribution of temporal pattern mining techniques in the analysis of evolving networks. In particular, we aim at exploiting available snapshots for the recognition of valuable and potentially useful knowledge about the temporal dynamics exhibited by the network over the time, without making any prior assumption about the underlying evolutionary schema. Pattern-based approaches of temporal pattern mining can be exploited to detect and characterize changes exhibited by a network over the time, starting from observed snapshots.\n    ",
        "submission_date": "2017-09-20T00:00:00",
        "last_modified_date": "2017-09-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.06908",
        "title": "EMR-based medical knowledge representation and inference via Markov random fields and distributed representation learning",
        "authors": [
            "Chao Zhao",
            "Jingchi Jiang",
            "Yi Guan"
        ],
        "abstract": "Objective: Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support (CDS). Our objective is a general system that can extract and represent these knowledge contained in EMRs to support three CDS tasks: test recommendation, initial diagnosis, and treatment plan recommendation, with the given condition of one patient. Methods: We extracted four kinds of medical entities from records and constructed an EMR-based medical knowledge network (EMKN), in which nodes are entities and edges reflect their co-occurrence in a single record. Three bipartite subgraphs (bi-graphs) were extracted from the EMKN to support each task. One part of the bi-graph was the given condition (e.g., symptoms), and the other was the condition to be inferred (e.g., diseases). Each bi-graph was regarded as a Markov random field to support the inference. Three lazy energy functions and one parameter-based energy function were proposed, as well as two knowledge representation learning-based energy functions, which can provide a distributed representation of medical entities. Three measures were utilized for performance evaluation. Results: On the initial diagnosis task, 80.11% of the test records identified at least one correct disease from top 10 candidates. Test and treatment recommendation results were 87.88% and 92.55%, respectively. These results altogether indicate that the proposed system outperformed the baseline methods. The distributed representation of medical entities does reflect similarity relationships in regards to knowledge level. Conclusion: Combining EMKN and MRF is an effective approach for general medical knowledge representation and inference. Different tasks, however, require designing their energy functions individually.\n    ",
        "submission_date": "2017-09-20T00:00:00",
        "last_modified_date": "2017-09-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.06977",
        "title": "Deep Reinforcement Learning for Dexterous Manipulation with Concept Networks",
        "authors": [
            "Aditya Gudimella",
            "Ross Story",
            "Matineh Shaker",
            "Ruofan Kong",
            "Matthew Brown",
            "Victor Shnayder",
            "Marcos Campos"
        ],
        "abstract": "Deep reinforcement learning yields great results for a large array of problems, but models are generally retrained anew for each new problem to be solved. Prior learning and knowledge are difficult to incorporate when training new models, requiring increasingly longer training as problems become more complex. This is especially problematic for problems with sparse rewards. We provide a solution to these problems by introducing Concept Network Reinforcement Learning (CNRL), a framework which allows us to decompose problems using a multi-level hierarchy. Concepts in a concept network are reusable, and flexible enough to encapsulate feature extractors, skills, or other concept networks. With this hierarchical learning approach, deep reinforcement learning can be used to solve complex tasks in a modular way, through problem decomposition. We demonstrate the strength of CNRL by training a model to grasp a rectangular prism and precisely stack it on top of a cube using a gripper on a Kinova JACO arm, simulated in MuJoCo. Our experiments show that our use of hierarchy results in a 45x reduction in environment interactions compared to the state-of-the-art on this task.\n    ",
        "submission_date": "2017-09-20T00:00:00",
        "last_modified_date": "2017-09-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.07092",
        "title": "On Compiling DNNFs without Determinism",
        "authors": [
            "Umut Oztok",
            "Adnan Darwiche"
        ],
        "abstract": "State-of-the-art knowledge compilers generate deterministic subsets of DNNF, which have been recently shown to be exponentially less succinct than DNNF. In this paper, we propose a new method to compile DNNFs without enforcing determinism necessarily. Our approach is based on compiling deterministic DNNFs with the addition of auxiliary variables to the input formula. These variables are then existentially quantified from the deterministic structure in linear time, which would lead to a DNNF that is equivalent to the input formula and not necessarily deterministic. On the theoretical side, we show that the new method could generate exponentially smaller DNNFs than deterministic ones, even by adding a single auxiliary variable. Further, we show that various existing techniques that introduce auxiliary variables to the input formulas can be employed in our framework. On the practical side, we empirically demonstrate that our new method can significantly advance DNNF compilation on certain benchmarks.\n    ",
        "submission_date": "2017-09-20T00:00:00",
        "last_modified_date": "2017-09-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.07114",
        "title": "Cost Adaptation for Robust Decentralized Swarm Behaviour",
        "authors": [
            "Peter Henderson",
            "Matthew Vertescher",
            "David Meger",
            "Mark Coates"
        ],
        "abstract": "Decentralized receding horizon control (D-RHC) provides a mechanism for coordination in multi-agent settings without a centralized command center. However, combining a set of different goals, costs, and constraints to form an efficient optimization objective for D-RHC can be difficult. To allay this problem, we use a meta-learning process -- cost adaptation -- which generates the optimization objective for D-RHC to solve based on a set of human-generated priors (cost and constraint functions) and an auxiliary heuristic. We use this adaptive D-RHC method for control of mesh-networked swarm agents. This formulation allows a wide range of tasks to be encoded and can account for network delays, heterogeneous capabilities, and increasingly large swarms through the adaptation mechanism. We leverage the Unity3D game engine to build a simulator capable of introducing artificial networking failures and delays in the swarm. Using the simulator we validate our method on an example coordinated exploration task. We demonstrate that cost adaptation allows for more efficient and safer task completion under varying environment conditions and increasingly large swarm sizes. We release our simulator and code to the community for future work.\n    ",
        "submission_date": "2017-09-21T00:00:00",
        "last_modified_date": "2018-09-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.07150",
        "title": "Feature Engineering for Predictive Modeling using Reinforcement Learning",
        "authors": [
            "Udayan Khurana",
            "Horst Samulowitz",
            "Deepak Turaga"
        ],
        "abstract": "Feature engineering is a crucial step in the process of predictive modeling. It involves the transformation of given feature space, typically using mathematical functions, with the objective of reducing the modeling error for a given target. However, there is no well-defined basis for performing effective feature engineering. It involves domain knowledge, intuition, and most of all, a lengthy process of trial and error. The human attention involved in overseeing this process significantly influences the cost of model generation. We present a new framework to automate feature engineering. It is based on performance driven exploration of a transformation graph, which systematically and compactly enumerates the space of given options. A highly efficient exploration strategy is derived through reinforcement learning on past examples.\n    ",
        "submission_date": "2017-09-21T00:00:00",
        "last_modified_date": "2017-09-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.07255",
        "title": "Assumption-Based Approaches to Reasoning with Priorities",
        "authors": [
            "Jesse Heyninck",
            "Christian Stra\u00dfer",
            "Pere Pardo"
        ],
        "abstract": "This paper maps out the relation between different approaches for handling preferences in argumentation with strict rules and defeasible assumptions by offering translations between them. The systems we compare are: non-prioritized defeats i.e. attacks, preference-based defeats, and preference-based defeats extended with reverse defeat.\n    ",
        "submission_date": "2017-09-21T00:00:00",
        "last_modified_date": "2017-09-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.07417",
        "title": "Neural Optimizer Search with Reinforcement Learning",
        "authors": [
            "Irwan Bello",
            "Barret Zoph",
            "Vijay Vasudevan",
            "Quoc V. Le"
        ],
        "abstract": "We present an approach to automate the process of discovering optimization methods, with a focus on deep learning architectures. We train a Recurrent Neural Network controller to generate a string in a domain specific language that describes a mathematical update equation based on a list of primitive functions, such as the gradient, running average of the gradient, etc. The controller is trained with Reinforcement Learning to maximize the performance of a model after a few epochs. On CIFAR-10, our method discovers several update rules that are better than many commonly used optimizers, such as Adam, RMSProp, or SGD with and without Momentum on a ConvNet model. We introduce two new optimizers, named PowerSign and AddSign, which we show transfer well and improve training on a variety of different tasks and architectures, including ImageNet classification and Google's neural machine translation system.\n    ",
        "submission_date": "2017-09-21T00:00:00",
        "last_modified_date": "2017-09-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.07511",
        "title": "Robust Optimization of Unconstrained Binary Quadratic Problems",
        "authors": [
            "Mark Lewis",
            "Gary Kochenberger",
            "John Metcalfe"
        ],
        "abstract": "In this paper we focus on the unconstrained binary quadratic optimization model, maximize x^t Qx, x binary, and consider the problem of identifying optimal solutions that are robust with respect to perturbations in the Q matrix.. We are motivated to find robust, or stable, solutions because of the uncertainty inherent in the big data origins of Q and limitations in computer numerical precision, particularly in a new class of quantum annealing computers. Experimental design techniques are used to generate a diverse subset of possible scenarios, from which robust solutions are identified. An illustrative example with practical application to business decision making is examined. The approach presented also generates a surface response equation which is used to estimate upper bounds in constant time for Q instantiations within the scenario extremes. In addition, a theoretical framework for the robustness of individual x_i variables is considered by examining the range of Q values over which the x_i are predetermined.\n    ",
        "submission_date": "2017-09-21T00:00:00",
        "last_modified_date": "2017-09-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.07534",
        "title": "MRNet-Product2Vec: A Multi-task Recurrent Neural Network for Product Embeddings",
        "authors": [
            "Arijit Biswas",
            "Mukul Bhutani",
            "Subhajit Sanyal"
        ],
        "abstract": "E-commerce websites such as Amazon, Alibaba, Flipkart, and Walmart sell billions of products. Machine learning (ML) algorithms involving products are often used to improve the customer experience and increase revenue, e.g., product similarity, recommendation, and price estimation. The products are required to be represented as features before training an ML algorithm. In this paper, we propose an approach called MRNet-Product2Vec for creating generic embeddings of products within an e-commerce ecosystem. We learn a dense and low-dimensional embedding where a diverse set of signals related to a product are explicitly injected into its representation. We train a Discriminative Multi-task Bidirectional Recurrent Neural Network (RNN), where the input is a product title fed through a Bidirectional RNN and at the output, product labels corresponding to fifteen different tasks are predicted. The task set includes several intrinsic characteristics about a product such as price, weight, size, color, popularity, and material. We evaluate the proposed embedding quantitatively and qualitatively. We demonstrate that they are almost as good as sparse and extremely high-dimensional TF-IDF representation in spite of having less than 3% of the TF-IDF dimension. We also use a multimodal autoencoder for comparing products from different language-regions and show preliminary yet promising qualitative results.\n    ",
        "submission_date": "2017-09-21T00:00:00",
        "last_modified_date": "2017-09-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.07576",
        "title": "EB-GLS: An Improved Guided Local Search Based on the Big Valley Structure",
        "authors": [
            "Jialong Shi",
            "Qingfu Zhang",
            "Edward Tsang"
        ],
        "abstract": "Local search is a basic building block in memetic algorithms. Guided Local Search (GLS) can improve the efficiency of local search. By changing the guide function, GLS guides a local search to escape from locally optimal solutions and find better solutions. The key component of GLS is its penalizing mechanism which determines which feature is selected to penalize when the search is trapped in a locally optimal solution. The original GLS penalizing mechanism only makes use of the cost and the current penalty value of each feature. It is well known that many combinatorial optimization problems have a big valley structure, i.e., the better a solution is, the more the chance it is closer to a globally optimal solution. This paper proposes to use big valley structure assumption to improve the GLS penalizing mechanism. An improved GLS algorithm called Elite Biased GLS (EB-GLS) is proposed. EB-GLS records and maintains an elite solution as an estimate of the globally optimal solutions, and reduces the chance of penalizing the features in this solution. We have systematically tested the proposed algorithm on the symmetric traveling salesman problem. Experimental results show that EB-GLS is significantly better than GLS.\n    ",
        "submission_date": "2017-09-22T00:00:00",
        "last_modified_date": "2017-09-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.07597",
        "title": "Inverse Reinforcement Learning with Conditional Choice Probabilities",
        "authors": [
            "Mohit Sharma",
            "Kris M. Kitani",
            "Joachim Groeger"
        ],
        "abstract": "We make an important connection to existing results in econometrics to describe an alternative formulation of inverse reinforcement learning (IRL). In particular, we describe an algorithm using Conditional Choice Probabilities (CCP), which are maximum likelihood estimates of the policy estimated from expert demonstrations, to solve the IRL problem. Using the language of structural econometrics, we re-frame the optimal decision problem and introduce an alternative representation of value functions due to (Hotz and Miller 1993). In addition to presenting the theoretical connections that bridge the IRL literature between Economics and Robotics, the use of CCPs also has the practical benefit of reducing the computational cost of solving the IRL problem. Specifically, under the CCP representation, we show how one can avoid repeated calls to the dynamic programming subroutine typically used in IRL. We show via extensive experimentation on standard IRL benchmarks that CCP-IRL is able to outperform MaxEnt-IRL, with as much as a 5x speedup and without compromising on the quality of the recovered reward function.\n    ",
        "submission_date": "2017-09-22T00:00:00",
        "last_modified_date": "2017-09-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.07604",
        "title": "A Comprehensive Survey of Graph Embedding: Problems, Techniques and Applications",
        "authors": [
            "Hongyun Cai",
            "Vincent W. Zheng",
            "Kevin Chen-Chuan Chang"
        ],
        "abstract": "Graph is an important data representation which appears in a wide diversity of real-world scenarios. Effective graph analytics provides users a deeper understanding of what is behind the data, and thus can benefit a lot of useful applications such as node classification, node recommendation, link prediction, etc. However, most graph analytics methods suffer the high computation and space cost. Graph embedding is an effective yet efficient way to solve the graph analytics problem. It converts the graph data into a low dimensional space in which the graph structural information and graph properties are maximally preserved. In this survey, we conduct a comprehensive review of the literature in graph embedding. We first introduce the formal definition of graph embedding as well as the related concepts. After that, we propose two taxonomies of graph embedding which correspond to what challenges exist in different graph embedding problem settings and how the existing work address these challenges in their solutions. Finally, we summarize the applications that graph embedding enables and suggest four promising future research directions in terms of computation efficiency, problem settings, techniques and application scenarios.\n    ",
        "submission_date": "2017-09-22T00:00:00",
        "last_modified_date": "2018-02-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.07615",
        "title": "Neural Networks for Predicting Algorithm Runtime Distributions",
        "authors": [
            "Katharina Eggensperger",
            "Marius Lindauer",
            "Frank Hutter"
        ],
        "abstract": "Many state-of-the-art algorithms for solving hard combinatorial problems in artificial intelligence (AI) include elements of stochasticity that lead to high variations in runtime, even for a fixed problem instance. Knowledge about the resulting runtime distributions (RTDs) of algorithms on given problem instances can be exploited in various meta-algorithmic procedures, such as algorithm selection, portfolios, and randomized restarts. Previous work has shown that machine learning can be used to individually predict mean, median and variance of RTDs. To establish a new state-of-the-art in predicting RTDs, we demonstrate that the parameters of an RTD should be learned jointly and that neural networks can do this well by directly optimizing the likelihood of an RTD given runtime observations. In an empirical study involving five algorithms for SAT solving and AI planning, we show that neural networks predict the true RTDs of unseen instances better than previous methods, and can even do so when only few runtime observations are available per training instance.\n    ",
        "submission_date": "2017-09-22T00:00:00",
        "last_modified_date": "2018-05-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.07642",
        "title": "Code Attention: Translating Code to Comments by Exploiting Domain Features",
        "authors": [
            "Wenhao Zheng",
            "Hong-Yu Zhou",
            "Ming Li",
            "Jianxin Wu"
        ],
        "abstract": "Appropriate comments of code snippets provide insight for code functionality, which are helpful for program comprehension. However, due to the great cost of authoring with the comments, many code projects do not contain adequate comments. Automatic comment generation techniques have been proposed to generate comments from pieces of code in order to alleviate the human efforts in annotating the code. Most existing approaches attempt to exploit certain correlations (usually manually given) between code and generated comments, which could be easily violated if the coding patterns change and hence the performance of comment generation declines. In this paper, we first build C2CGit, a large dataset from open projects in GitHub, which is more than 20$\\times$ larger than existing datasets. Then we propose a new attention module called Code Attention to translate code to comments, which is able to utilize the domain features of code snippets, such as symbols and identifiers. We make ablation studies to determine effects of different parts in Code Attention. Experimental results demonstrate that the proposed module has better performance over existing approaches in both BLEU and METEOR.\n    ",
        "submission_date": "2017-09-22T00:00:00",
        "last_modified_date": "2017-11-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.07791",
        "title": "Humanoid Robots as Agents of Human Consciousness Expansion",
        "authors": [
            "Ben Goertzel",
            "Julia Mossbridge",
            "Eddie Monroe",
            "David Hanson",
            "Gino Yu"
        ],
        "abstract": "The \"Loving AI\" project involves developing software enabling humanoid robots to interact with people in loving and compassionate ways, and to promote people' self-understanding and self-transcendence. Currently the project centers on the Hanson Robotics robot \"Sophia\" -- specifically, on supplying Sophia with personality content and cognitive, linguistic, perceptual and behavioral content aimed at enabling loving interactions supportive of human self-transcendence. In September 2017 a small pilot study was conducted, involving the Sophia robot leading human subjects through dialogues and exercises focused on meditation, visualization and relaxation. The pilot was an apparent success, qualitatively demonstrating the viability of the approach and the ability of appropriate human-robot interaction to increase human well-being and advance human consciousness.\n    ",
        "submission_date": "2017-09-22T00:00:00",
        "last_modified_date": "2017-09-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.08019",
        "title": "Semi-Supervised Hierarchical Semantic Object Parsing",
        "authors": [
            "Jalal Mirakhorli",
            "Hamidreza Amindavar"
        ],
        "abstract": "Models based on Convolutional Neural Networks (CNNs) have been proven very successful for semantic segmentation and object parsing that yield hierarchies of features. Our key insight is to build convolutional networks that take input of arbitrary size and produce object parsing output with efficient inference and learning. In this work, we focus on the task of instance segmentation and parsing which recognizes and localizes objects down to a pixel level base on deep CNN. Therefore, unlike some related work, a pixel cannot belong to multiple instances and parsing. Our model is based on a deep neural network trained for object masking that supervised with input image and follow incorporates a Conditional Random Field (CRF) with end-to-end trainable piecewise order potentials based on object parsing outputs. In each CRF unit we designed terms to capture the short range and long range dependencies from various neighbors. The accurate instance-level segmentation that our network produce is reflected by the considerable improvements obtained over previous work at high APr thresholds. We demonstrate the effectiveness of our model with extensive experiments on challenging dataset subset of PASCAL VOC2012.\n    ",
        "submission_date": "2017-09-23T00:00:00",
        "last_modified_date": "2017-10-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.08024",
        "title": "When Traffic Flow Prediction Meets Wireless Big Data Analytics",
        "authors": [
            "Yuanfang Chen",
            "Mohsen Guizani",
            "Yan Zhang",
            "Lei Wang",
            "Noel Crespi",
            "Gyu Myoung Lee"
        ],
        "abstract": "Traffic flow prediction is an important research issue for solving the traffic congestion problem in an Intelligent Transportation System (ITS). Traffic congestion is one of the most serious problems in a city, which can be predicted in advance by analyzing traffic flow patterns. Such prediction is possible by analyzing the real-time transportation data from correlative roads and vehicles. This article first gives a brief introduction to the transportation data, and surveys the state-of-the-art prediction methods. Then, we verify whether or not the prediction performance is able to be improved by fitting actual data to optimize the parameters of the prediction model which is used to predict the traffic flow. Such verification is conducted by comparing the optimized time series prediction model with the normal time series prediction model. This means that in the era of big data, accurate use of the data becomes the focus of studying the traffic flow prediction to solve the congestion problem. Finally, experimental results of a case study are provided to verify the existence of such performance improvement, while the research challenges of this data-analytics-based prediction are presented and discussed.\n    ",
        "submission_date": "2017-09-23T00:00:00",
        "last_modified_date": "2017-09-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.08027",
        "title": "Object-Oriented Knowledge Representation and Data Storage Using Inhomogeneous Classes",
        "authors": [
            "Dmytro Terletskyi"
        ],
        "abstract": "This paper contains analysis of concept of a class within different object-oriented knowledge representation models. The main attention is paid to structure of the class and its efficiency in the context of data storage, using object-relational mapping. The main achievement of the paper is extension of concept of homogeneous class of objects by introducing concepts of single-core and multi-core inhomogeneous classes of objects, which allow simultaneous defining of a few different types within one class of objects, avoiding duplication of properties and methods in representation of types, decreasing sizes of program codes and providing more efficient information storage in the databases. In addition, the paper contains results of experiment, which show that data storage in relational database, using proposed extensions of the class, in some cases is more efficient in contrast to usage of homogeneous classes of objects.\n    ",
        "submission_date": "2017-09-23T00:00:00",
        "last_modified_date": "2017-09-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.08028",
        "title": "Towards Classification of Web ontologies using the Horizontal and Vertical Segmentation",
        "authors": [
            "Noreddine Gherabi",
            "Redouane Nejjahi",
            "Abderrahim Marzouk"
        ],
        "abstract": "The new era of the Web is known as the semantic Web or the Web of data. The semantic Web depends on ontologies that are seen as one of its pillars. The bigger these ontologies, the greater their exploitation. However, when these ontologies become too big other problems may appear, such as the complexity to charge big files in memory, the time it needs to download such files and especially the time it needs to make reasoning on them. We discuss in this paper approaches for segmenting such big Web ontologies as well as its usefulness. The segmentation method extracts from an existing ontology a segment that represents a layer or a generation in the existing ontology; i.e. a horizontally extraction. The extracted segment should be itself an ontology.\n    ",
        "submission_date": "2017-09-23T00:00:00",
        "last_modified_date": "2017-09-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.08034",
        "title": "Prioritized Norms in Formal Argumentation",
        "authors": [
            "Beishui Liao",
            "Nir Oren",
            "Leendert van der Torre",
            "Serena Villata"
        ],
        "abstract": "To resolve conflicts among norms, various nonmonotonic formalisms can be used to perform prioritized normative reasoning. Meanwhile, formal argumentation provides a way to represent nonmonotonic logics. In this paper, we propose a representation of prioritized normative reasoning by argumentation. Using hierarchical abstract normative systems, we define three kinds of prioritized normative reasoning approaches, called Greedy, Reduction, and Optimization. Then, after formulating an argumentation theory for a hierarchical abstract normative system, we show that for a totally ordered hierarchical abstract normative system, Greedy and Reduction can be represented in argumentation by applying the weakest link and the last link principles respectively, and Optimization can be represented by introducing additional defeats capturing the idea that for each argument that contains a norm not belonging to the maximal obeyable set then this argument should be rejected.\n    ",
        "submission_date": "2017-09-23T00:00:00",
        "last_modified_date": "2018-02-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.08071",
        "title": "Autonomous Agents Modelling Other Agents: A Comprehensive Survey and Open Problems",
        "authors": [
            "Stefano V. Albrecht",
            "Peter Stone"
        ],
        "abstract": "Much research in artificial intelligence is concerned with the development of autonomous agents that can interact effectively with other agents. An important aspect of such agents is the ability to reason about the behaviours of other agents, by constructing models which make predictions about various properties of interest (such as actions, goals, beliefs) of the modelled agents. A variety of modelling approaches now exist which vary widely in their methodology and underlying assumptions, catering to the needs of the different sub-communities within which they were developed and reflecting the different practical uses for which they are intended. The purpose of the present article is to provide a comprehensive survey of the salient modelling methods which can be found in the literature. The article concludes with a discussion of open problems which may form the basis for fruitful future research.\n    ",
        "submission_date": "2017-09-23T00:00:00",
        "last_modified_date": "2018-02-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.08163",
        "title": "A Renewal Model of Intrusion",
        "authors": [
            "David Tolpin"
        ],
        "abstract": "We present a probabilistic model of an intrusion in a renewal process. Given a process and a sequence of events, an intrusion is a subsequence of events that is not produced by the process. Applications of the model are, for example, online payment fraud with the fraudster taking over a user's account and performing payments on the user's behalf, or unexpected equipment failures due to unintended use.\n",
        "submission_date": "2017-09-24T00:00:00",
        "last_modified_date": "2018-05-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.08201",
        "title": "An Optimal Online Method of Selecting Source Policies for Reinforcement Learning",
        "authors": [
            "Siyuan Li",
            "Chongjie Zhang"
        ],
        "abstract": "Transfer learning significantly accelerates the reinforcement learning process by exploiting relevant knowledge from previous experiences. The problem of optimally selecting source policies during the learning process is of great importance yet challenging. There has been little theoretical analysis of this problem. In this paper, we develop an optimal online method to select source policies for reinforcement learning. This method formulates online source policy selection as a multi-armed bandit problem and augments Q-learning with policy reuse. We provide theoretical guarantees of the optimal selection process and convergence to the optimal policy. In addition, we conduct experiments on a grid-based robot navigation domain to demonstrate its efficiency and robustness by comparing to the state-of-the-art transfer learning method.\n    ",
        "submission_date": "2017-09-24T00:00:00",
        "last_modified_date": "2017-09-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.08233",
        "title": "Learning Unmanned Aerial Vehicle Control for Autonomous Target Following",
        "authors": [
            "Siyi Li",
            "Tianbo Liu",
            "Chi Zhang",
            "Dit-Yan Yeung",
            "Shaojie Shen"
        ],
        "abstract": "While deep reinforcement learning (RL) methods have achieved unprecedented successes in a range of challenging problems, their applicability has been mainly limited to simulation or game domains due to the high sample complexity of the trial-and-error learning process. However, real-world robotic applications often need a data-efficient learning process with safety-critical constraints. In this paper, we consider the challenging problem of learning unmanned aerial vehicle (UAV) control for tracking a moving target. To acquire a strategy that combines perception and control, we represent the policy by a convolutional neural network. We develop a hierarchical approach that combines a model-free policy gradient method with a conventional feedback proportional-integral-derivative (PID) controller to enable stable learning without catastrophic failure. The neural network is trained by a combination of supervised learning from raw images and reinforcement learning from games of self-play. We show that the proposed approach can learn a target following policy in a simulator efficiently and the learned behavior can be successfully transferred to the DJI quadrotor platform for real-world UAV control.\n    ",
        "submission_date": "2017-09-24T00:00:00",
        "last_modified_date": "2017-09-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.08366",
        "title": "\"Let me convince you to buy my product ... \": A Case Study of an Automated Persuasive System for Fashion Products",
        "authors": [
            "Vitobha Munigala",
            "Srikanth Tamilselvam",
            "Anush Sankaran"
        ],
        "abstract": "Persuasivenes is a creative art aimed at making people believe in certain set of beliefs. Many a times, such creativity is about adapting richness of one domain into another to strike a chord with the target audience. In this research, we present PersuAIDE! - A persuasive system based on linguistic creativity to transform given sentence to generate various forms of persuading sentences. These various forms cover multiple focus of persuasion such as memorability and sentiment. For a given simple product line, the algorithm is composed of several steps including: (i) select an appropriate well-known expression for the target domain to add memorability, (ii) identify keywords and entities in the given sentence and expression and transform it to produce creative persuading sentence, and (iii) adding positive or negative sentiment for further persuasion. The persuasive conversion were manually verified using qualitative results and the effectiveness of the proposed approach is empirically discussed.\n    ",
        "submission_date": "2017-09-25T00:00:00",
        "last_modified_date": "2017-09-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.08448",
        "title": "Extracting Ontological Knowledge from Textual Descriptions",
        "authors": [
            "Kevin Alex Mathews",
            "P Sreenivasa Kumar"
        ],
        "abstract": "Authoring of OWL-DL ontologies is intellectually challenging and to make this process simpler, many systems accept natural language text as input. A text-based ontology authoring approach can be successful only when it is combined with an effective method for extracting ontological axioms from text. Extracting axioms from unrestricted English input is a substantially challenging task due to the richness of the language. Controlled natural languages (CNLs) have been proposed in this context and these tend to be highly restrictive. In this paper, we propose a new CNL called TEDEI (TExtual DEscription Identifier) whose grammar is inspired by the different ways OWL-DL constructs are expressed in English. We built a system that transforms TEDEI sentences into corresponding OWL-DL axioms. Now, ambiguity due to different possible lexicalizations of sentences and semantic ambiguity present in sentences are challenges in this context. We find that the best way to handle these challenges is to construct axioms corresponding to alternative formalizations of the sentence so that the end-user can make an appropriate choice. The output is compared against human-authored axioms and in substantial number of cases, human-authored axiom is indeed one of the alternatives given by the system. The proposed system substantially enhances the types of sentence structures that can be used for ontology authoring.\n    ",
        "submission_date": "2017-09-25T00:00:00",
        "last_modified_date": "2017-09-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.08590",
        "title": "Ensemble Classifier for Eye State Classification using EEG Signals",
        "authors": [
            "Ali Al-Taei"
        ],
        "abstract": "The growing importance and utilization of measuring brain waves (e.g. EEG signals of eye state) in brain-computer interface (BCI) applications highlighted the need for suitable classification methods. In this paper, a comparison between three of well-known classification methods (i.e. support vector machine (SVM), hidden Markov map (HMM), and radial basis function (RBF)) for EEG based eye state classification was achieved. Furthermore, a suggested method that is based on ensemble model was tested. The suggested (ensemble system) method based on a voting algorithm with two kernels: random forest (RF) and Kstar classification methods. The performance was tested using three measurement parameters: accuracy, mean absolute error (MAE), and confusion matrix. Results showed that the proposed method outperforms the other tested methods. For instance, the suggested method's performance was 97.27% accuracy and 0.13 MAE.\n    ",
        "submission_date": "2017-09-25T00:00:00",
        "last_modified_date": "2017-09-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.08693",
        "title": "Fooling Vision and Language Models Despite Localization and Attention Mechanism",
        "authors": [
            "Xiaojun Xu",
            "Xinyun Chen",
            "Chang Liu",
            "Anna Rohrbach",
            "Trevor Darrell",
            "Dawn Song"
        ],
        "abstract": "Adversarial attacks are known to succeed on classifiers, but it has been an open question whether more complex vision systems are vulnerable. In this paper, we study adversarial examples for vision and language models, which incorporate natural language understanding and complex structures such as attention, localization, and modular architectures. In particular, we investigate attacks on a dense captioning model and on two visual question answering (VQA) models. Our evaluation shows that we can generate adversarial examples with a high success rate (i.e., > 90%) for these models. Our work sheds new light on understanding adversarial attacks on vision systems which have a language component and shows that attention, bounding box localization, and compositional internal structures are vulnerable to adversarial attacks. These observations will inform future work towards building effective defenses.\n    ",
        "submission_date": "2017-09-25T00:00:00",
        "last_modified_date": "2018-04-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.08850",
        "title": "Active Learning amidst Logical Knowledge",
        "authors": [
            "Emmanouil Antonios Platanios",
            "Ashish Kapoor",
            "Eric Horvitz"
        ],
        "abstract": "Structured prediction is ubiquitous in applications of machine learning such as knowledge extraction and natural language processing. Structure often can be formulated in terms of logical constraints. We consider the question of how to perform efficient active learning in the presence of logical constraints among variables inferred by different classifiers. We propose several methods and provide theoretical results that demonstrate the inappropriateness of employing uncertainty guided sampling, a commonly used active learning method. Furthermore, experiments on ten different datasets demonstrate that the methods significantly outperform alternatives in practice. The results are of practical significance in situations where labeled data is scarce.\n    ",
        "submission_date": "2017-09-26T00:00:00",
        "last_modified_date": "2017-09-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.08982",
        "title": "User and Developer Interaction with Editable and Readable Ontologies",
        "authors": [
            "Aisha Blfgeh",
            "Phillip Lord"
        ],
        "abstract": "The process of building ontologies is a difficult task that involves collaboration between ontology developers and domain experts and requires an ongoing interaction between them. This collaboration is made more difficult, because they tend to use different tool sets, which can hamper this interaction. In this paper, we propose to decrease this distance between domain experts and ontology developers by creating more readable forms of ontologies, and further to enable editing in normal office environments. Building on a programmatic ontology development environment, such as Tawny-OWL, we are now able to generate these readable/editable from the raw ontological source and its embedded comments. We have this translation to HTML for reading; this environment provides rich hyperlinking as well as active features such as hiding the source code in favour of comments. We are now working on translation to a Word document that also enables editing. Taken together this should provide a significant new route for collaboration between the ontologist and domain specialist.\n    ",
        "submission_date": "2017-09-26T00:00:00",
        "last_modified_date": "2017-09-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.09108",
        "title": "Tensors Come of Age: Why the AI Revolution will help HPC",
        "authors": [
            "John L. Gustafson",
            "Lenore M. Mullin"
        ],
        "abstract": "This article discusses how the automation of tensor algorithms, based on A Mathematics of Arrays and Psi Calculus, and a new way to represent numbers, Unum Arithmetic, enables mechanically provable, scalable, portable, and more numerically accurate software.\n    ",
        "submission_date": "2017-09-26T00:00:00",
        "last_modified_date": "2017-09-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.09131",
        "title": "Automatic Error Analysis of Human Motor Performance for Interactive Coaching in Virtual Reality",
        "authors": [
            "Felix H\u00fclsmann",
            "Stefan Kopp",
            "Mario Botsch"
        ],
        "abstract": "In the context of fitness coaching or for rehabilitation purposes, the motor actions of a human participant must be observed and analyzed for errors in order to provide effective feedback. This task is normally carried out by human coaches, and it needs to be solved automatically in technical applications that are to provide automatic coaching (e.g. training environments in VR). However, most coaching systems only provide coarse information on movement quality, such as a scalar value per body part that describes the overall deviation from the correct movement. Further, they are often limited to static body postures or rather simple movements of single body parts. While there are many approaches to distinguish between different types of movements (e.g., between walking and jumping), the detection of more subtle errors in a motor performance is less investigated. We propose a novel approach to classify errors in sports or rehabilitation exercises such that feedback can be delivered in a rapid and detailed manner: Homogeneous sub-sequences of exercises are first temporally aligned via Dynamic Time Warping. Next, we extract a feature vector from the aligned sequences, which serves as a basis for feature selection using Random Forests. The selected features are used as input for Support Vector Machines, which finally classify the movement errors. We compare our algorithm to a well established state-of-the-art approach in time series classification, 1-Nearest Neighbor combined with Dynamic Time Warping, and show our algorithm's superiority regarding classification quality as well as computational cost.\n    ",
        "submission_date": "2017-09-26T00:00:00",
        "last_modified_date": "2017-09-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.09312",
        "title": "A Simple Reinforcement Learning Mechanism for Resource Allocation in LTE-A Networks with Markov Decision Process and Q-Learning",
        "authors": [
            "Einar Cesar Santos"
        ],
        "abstract": "Resource allocation is still a difficult issue to deal with in wireless networks. The unstable channel condition and traffic demand for Quality of Service (QoS) raise some barriers that interfere with the process. It is significant that an optimal policy takes into account some resources available to each traffic class while considering the spectral efficiency and other related channel issues. Reinforcement learning is a dynamic and effective method to support the accomplishment of resource allocation properly maintaining QoS levels for applications. The technique can track the system state as feedback to enhance the performance of a given task. Herein, it is proposed a simple reinforcement learning mechanism introduced in LTE-A networks and aimed to choose and limit the number of resources allocated for each traffic class, regarding the QoS Class Identifier (QCI), at each Transmission Time Interval (TTI) along the scheduling procedure. The proposed mechanism implements a Markov Decision Process (MDP) solved by the Q-Learning algorithm to find an optimal action-state decision policy. The results obtained from simulation exhibit good performance, especially for the real-time Video application.\n    ",
        "submission_date": "2017-09-27T00:00:00",
        "last_modified_date": "2017-09-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.09433",
        "title": "Scene learning, recognition and similarity detection in a fuzzy ontology via human examples",
        "authors": [
            "Luca Buoncompagni",
            "Fulvio Mastrogiovanni",
            "Alessandro Saffiotti"
        ],
        "abstract": "This paper introduces a Fuzzy Logic framework for scene learning, recognition and similarity detection, where scenes are taught via human examples. The framework allows a robot to: (i) deal with the intrinsic vagueness associated with determining spatial relations among objects; (ii) infer similarities and dissimilarities in a set of scenes, and represent them in a hierarchical structure represented in a Fuzzy ontology. In this paper, we briefly formalize our approach and we provide a few use cases by way of illustration. Nevertheless, we discuss how the framework can be used in real-world scenarios.\n    ",
        "submission_date": "2017-09-27T00:00:00",
        "last_modified_date": "2017-09-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.09480",
        "title": "A Benchmark Environment Motivated by Industrial Control Problems",
        "authors": [
            "Daniel Hein",
            "Stefan Depeweg",
            "Michel Tokic",
            "Steffen Udluft",
            "Alexander Hentschel",
            "Thomas A. Runkler",
            "Volkmar Sterzing"
        ],
        "abstract": "In the research area of reinforcement learning (RL), frequently novel and promising methods are developed and introduced to the RL community. However, although many researchers are keen to apply their methods on real-world problems, implementing such methods in real industry environments often is a frustrating and tedious process. Generally, academic research groups have only limited access to real industrial data and applications. For this reason, new methods are usually developed, evaluated and compared by using artificial software benchmarks. On one hand, these benchmarks are designed to provide interpretable RL training scenarios and detailed insight into the learning process of the method on hand. On the other hand, they usually do not share much similarity with industrial real-world applications. For this reason we used our industry experience to design a benchmark which bridges the gap between freely available, documented, and motivated artificial benchmarks and properties of real industrial problems. The resulting industrial benchmark (IB) has been made publicly available to the RL community by publishing its Java and Python code, including an OpenAI Gym wrapper, on Github. In this paper we motivate and describe in detail the IB's dynamics and identify prototypic experimental settings that capture common situations in real-world industry control problems.\n    ",
        "submission_date": "2017-09-27T00:00:00",
        "last_modified_date": "2022-11-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.09534",
        "title": "Tweeting AI: Perceptions of Lay vs Expert Twitterati",
        "authors": [
            "Lydia Manikonda",
            "Subbarao Kambhampati"
        ],
        "abstract": "With the recent advancements in Artificial Intelligence (AI), various organizations and individuals are debating about the progress of AI as a blessing or a curse for the future of the society. This paper conducts an investigation on how the public perceives the progress of AI by utilizing the data shared on Twitter. Specifically, this paper performs a comparative analysis on the understanding of users belonging to two categories -- general AI-Tweeters (AIT) and expert AI-Tweeters (EAIT) who share posts about AI on Twitter. Our analysis revealed that users from both the categories express distinct emotions and interests towards AI. Users from both the categories regard AI as positive and are optimistic about the progress of AI but the experts are more negative than the general AI-Tweeters. Expert AI-Tweeters share relatively large percentage of tweets about their personal news compared to technical aspects of AI. However, the effects of automation on the future are of primary concern to AIT than to EAIT. When the expert category is sub-categorized, the emotion analysis revealed that students and industry professionals have more insights in their tweets about AI than academicians.\n    ",
        "submission_date": "2017-09-25T00:00:00",
        "last_modified_date": "2017-09-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.09585",
        "title": "DeepTransport: Learning Spatial-Temporal Dependency for Traffic Condition Forecasting",
        "authors": [
            "Xingyi Cheng",
            "Ruiqing Zhang",
            "Jie Zhou",
            "Wei Xu"
        ],
        "abstract": "Predicting traffic conditions has been recently explored as a way to relieve traffic congestion. Several pioneering approaches have been proposed based on traffic observations of the target location as well as its adjacent regions, but they obtain somewhat limited accuracy due to a lack of mining road topology. To address the effect attenuation problem, we suggest taking into account the traffic of surrounding locations(wider than the adjacent range). We propose an end-to-end framework called DeepTransport, in which Convolutional Neural Networks (CNN) and Recurrent Neural Networks (RNN) are utilized to obtain spatial-temporal traffic information within a transport network topology. In addition, an attention mechanism is introduced to align spatial and temporal information. Moreover, we constructed and released a real-world large traffic condition dataset with a 5-minute resolution. Our experiments on this dataset demonstrate our method captures the complex relationship in the temporal and spatial domains. It significantly outperforms traditional statistical methods and a state-of-the-art deep learning method.\n    ",
        "submission_date": "2017-09-27T00:00:00",
        "last_modified_date": "2023-08-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.09586",
        "title": "Case Study: Explaining Diabetic Retinopathy Detection Deep CNNs via Integrated Gradients",
        "authors": [
            "Linyi Li",
            "Matt Fredrikson",
            "Shayak Sen",
            "Anupam Datta"
        ],
        "abstract": "In this report, we applied integrated gradients to explaining a neural network for diabetic retinopathy detection. The integrated gradient is an attribution method which measures the contributions of input to the quantity of interest. We explored some new ways for applying this method such as explaining intermediate layers, filtering out unimportant units by their attribution value and generating contrary samples. Moreover, the visualization results extend the use of diabetic retinopathy detection model from merely predicting to assisting finding potential lesions.\n    ",
        "submission_date": "2017-09-27T00:00:00",
        "last_modified_date": "2017-10-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.09611",
        "title": "A Policy Search Method For Temporal Logic Specified Reinforcement Learning Tasks",
        "authors": [
            "Xiao Li",
            "Yao Ma",
            "Calin Belta"
        ],
        "abstract": "Reward engineering is an important aspect of reinforcement learning. Whether or not the user's intentions can be correctly encapsulated in the reward function can significantly impact the learning outcome. Current methods rely on manually crafted reward functions that often require parameter tuning to obtain the desired behavior. This operation can be expensive when exploration requires systems to interact with the physical world. In this paper, we explore the use of temporal logic (TL) to specify tasks in reinforcement learning. TL formula can be translated to a real-valued function that measures its level of satisfaction against a trajectory. We take advantage of this function and propose temporal logic policy search (TLPS), a model-free learning technique that finds a policy that satisfies the TL specification. A set of simulated experiments are conducted to evaluate the proposed approach.\n    ",
        "submission_date": "2017-09-27T00:00:00",
        "last_modified_date": "2017-09-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.09741",
        "title": "WHY: Natural Explanations from a Robot Navigator",
        "authors": [
            "Raj Korpan",
            "Susan L. Epstein",
            "Anoop Aroor",
            "Gil Dekel"
        ],
        "abstract": "Effective collaboration between a robot and a person requires natural communication. When a robot travels with a human companion, the robot should be able to explain its navigation behavior in natural language. This paper explains how a cognitively-based, autonomous robot navigation system produces informative, intuitive explanations for its decisions. Language generation here is based upon the robot's commonsense, its qualitative reasoning, and its learned spatial model. This approach produces natural explanations in real time for a robot as it navigates in a large, complex indoor environment.\n    ",
        "submission_date": "2017-09-27T00:00:00",
        "last_modified_date": "2017-09-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.09839",
        "title": "Heuristic Online Goal Recognition in Continuous Domains",
        "authors": [
            "Mor Vered",
            "Gal A. Kaminka"
        ],
        "abstract": "Goal recognition is the problem of inferring the goal of an agent, based on its observed actions. An inspiring approach - plan recognition by planning (PRP) - uses off-the-shelf planners to dynamically generate plans for given goals, eliminating the need for the traditional plan library. However, existing PRP formulation is inherently inefficient in online recognition, and cannot be used with motion planners for continuous spaces. In this paper, we utilize a different PRP formulation which allows for online goal recognition, and for application in continuous spaces. We present an online recognition algorithm, where two heuristic decision points may be used to improve run-time significantly over existing work. We specify heuristics for continuous domains, prove guarantees on their use, and empirically evaluate the algorithm over hundreds of experiments in both a 3D navigational environment and a cooperative robotic team task.\n    ",
        "submission_date": "2017-09-28T00:00:00",
        "last_modified_date": "2017-09-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.09844",
        "title": "Distance-based Confidence Score for Neural Network Classifiers",
        "authors": [
            "Amit Mandelbaum",
            "Daphna Weinshall"
        ],
        "abstract": "The reliable measurement of confidence in classifiers' predictions is very important for many applications and is, therefore, an important part of classifier design. Yet, although deep learning has received tremendous attention in recent years, not much progress has been made in quantifying the prediction confidence of neural network classifiers. Bayesian models offer a mathematically grounded framework to reason about model uncertainty, but usually come with prohibitive computational costs. In this paper we propose a simple, scalable method to achieve a reliable confidence score, based on the data embedding derived from the penultimate layer of the network. We investigate two ways to achieve desirable embeddings, by using either a distance-based loss or Adversarial Training. We then test the benefits of our method when used for classification error prediction, weighting an ensemble of classifiers, and novelty detection. In all tasks we show significant improvement over traditional, commonly used confidence scores.\n    ",
        "submission_date": "2017-09-28T00:00:00",
        "last_modified_date": "2017-09-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.09972",
        "title": "Deep Learning Assisted Heuristic Tree Search for the Container Pre-marshalling Problem",
        "authors": [
            "Andr\u00e9 Hottung",
            "Shunji Tanaka",
            "Kevin Tierney"
        ],
        "abstract": "The container pre-marshalling problem (CPMP) is concerned with the re-ordering of containers in container terminals during off-peak times so that containers can be quickly retrieved when the port is busy. The problem has received significant attention in the literature and is addressed by a large number of exact and heuristic methods. Existing methods for the CPMP heavily rely on problem-specific components (e.g., proven lower bounds) that need to be developed by domain experts with knowledge of optimization techniques and a deep understanding of the problem at hand. With the goal to automate the costly and time-intensive design of heuristics for the CPMP, we propose a new method called Deep Learning Heuristic Tree Search (DLTS). It uses deep neural networks to learn solution strategies and lower bounds customized to the CPMP solely through analyzing existing (near-) optimal solutions to CPMP instances. The networks are then integrated into a tree search procedure to decide which branch to choose next and to prune the search tree. DLTS produces the highest quality heuristic solutions to the CPMP to date with gaps to optimality below 2% on real-world sized instances.\n    ",
        "submission_date": "2017-09-28T00:00:00",
        "last_modified_date": "2019-09-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.09994",
        "title": "Premise Selection for Theorem Proving by Deep Graph Embedding",
        "authors": [
            "Mingzhe Wang",
            "Yihe Tang",
            "Jian Wang",
            "Jia Deng"
        ],
        "abstract": "We propose a deep learning-based approach to the problem of premise selection: selecting mathematical statements relevant for proving a given conjecture. We represent a higher-order logic formula as a graph that is invariant to variable renaming but still fully preserves syntactic and semantic information. We then embed the graph into a vector via a novel embedding method that preserves the information of edge ordering. Our approach achieves state-of-the-art results on the HolStep dataset, improving the classification accuracy from 83% to 90.3%.\n    ",
        "submission_date": "2017-09-28T00:00:00",
        "last_modified_date": "2017-09-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.10163",
        "title": "Deep TAMER: Interactive Agent Shaping in High-Dimensional State Spaces",
        "authors": [
            "Garrett Warnell",
            "Nicholas Waytowich",
            "Vernon Lawhern",
            "Peter Stone"
        ],
        "abstract": "While recent advances in deep reinforcement learning have allowed autonomous learning agents to succeed at a variety of complex tasks, existing algorithms generally require a lot of training data. One way to increase the speed at which agents are able to learn to perform tasks is by leveraging the input of human trainers. Although such input can take many forms, real-time, scalar-valued feedback is especially useful in situations where it proves difficult or impossible for humans to provide expert demonstrations. Previous approaches have shown the usefulness of human input provided in this fashion (e.g., the TAMER framework), but they have thus far not considered high-dimensional state spaces or employed the use of deep learning. In this paper, we do both: we propose Deep TAMER, an extension of the TAMER framework that leverages the representational power of deep neural networks in order to learn complex tasks in just a short amount of time with a human trainer. We demonstrate Deep TAMER's success by using it and just 15 minutes of human-provided feedback to train an agent that performs better than humans on the Atari game of Bowling - a task that has proven difficult for even state-of-the-art reinforcement learning methods.\n    ",
        "submission_date": "2017-09-28T00:00:00",
        "last_modified_date": "2018-01-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.10242",
        "title": "Intelligence Quotient and Intelligence Grade of Artificial Intelligence",
        "authors": [
            "Feng Liu",
            "Yong Shi",
            "Ying Liu"
        ],
        "abstract": "Although artificial intelligence is currently one of the most interesting areas in scientific research, the potential threats posed by emerging AI systems remain a source of persistent controversy. To address the issue of AI threat, this study proposes a standard intelligence model that unifies AI and human characteristics in terms of four aspects of knowledge, i.e., input, output, mastery, and creation. Using this model, we observe three challenges, namely, expanding of the von Neumann architecture; testing and ranking the intelligence quotient of naturally and artificially intelligent systems, including humans, Google, Bing, Baidu, and Siri; and finally, the dividing of artificially intelligent systems into seven grades from robots to Google Brain. Based on this, we conclude that AlphaGo belongs to the third grade.\n    ",
        "submission_date": "2017-09-29T00:00:00",
        "last_modified_date": "2017-10-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.10256",
        "title": "Explainable Planning",
        "authors": [
            "Maria Fox",
            "Derek Long",
            "Daniele Magazzeni"
        ],
        "abstract": "As AI is increasingly being adopted into application solutions, the challenge of supporting interaction with humans is becoming more apparent. Partly this is to support integrated working styles, in which humans and intelligent systems cooperate in problem-solving, but also it is a necessary step in the process of building trust as humans migrate greater responsibility to such systems. The challenge is to find effective ways to communicate the foundations of AI-driven behaviour, when the algorithms that drive it are far from transparent to humans. In this paper we consider the opportunities that arise in AI planning, exploiting the model-based representations that form a familiar and common basis for communication with users, while acknowledging the gap between planning algorithms and human problem-solving.\n    ",
        "submission_date": "2017-09-29T00:00:00",
        "last_modified_date": "2017-09-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.10482",
        "title": "What Automated Planning can do for Business Process Management",
        "authors": [
            "Andrea Marrella"
        ],
        "abstract": "Business Process Management (BPM) is a central element of today organizations. Despite over the years its main focus has been the support of processes in highly controlled domains, nowadays many domains of interest to the BPM community are characterized by ever-changing requirements, unpredictable environments and increasing amounts of data that influence the execution of process instances. Under such dynamic conditions, BPM systems must increase their level of automation to provide the reactivity and flexibility necessary for process management. On the other hand, the Artificial Intelligence (AI) community has concentrated its efforts on investigating dynamic domains that involve active control of computational entities and physical devices (e.g., robots, software agents, etc.). In this context, Automated Planning, which is one of the oldest areas in AI, is conceived as a model-based approach to synthesize autonomous behaviours in automated way from a model. In this paper, we discuss how automated planning techniques can be leveraged to enable new levels of automation and support for business processing, and we show some concrete examples of their successful application to the different stages of the BPM life cycle.\n    ",
        "submission_date": "2017-09-29T00:00:00",
        "last_modified_date": "2017-10-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.10507",
        "title": "Vision-based deep execution monitoring",
        "authors": [
            "Francesco Puja",
            "Simone Grazioso",
            "Antonio Tammaro",
            "Valsmis Ntouskos",
            "Marta Sanzari",
            "Fiora Pirri"
        ],
        "abstract": "Execution monitor of high-level robot actions can be effectively improved by visual monitoring the state of the world in terms of preconditions and postconditions that hold before and after the execution of an action. Furthermore a policy for searching where to look at, either for verifying the relations that specify the pre and postconditions or to refocus in case of a failure, can tremendously improve the robot execution in an uncharted environment. It is now possible to strongly rely on visual perception in order to make the assumption that the environment is observable, by the amazing results of deep learning. In this work we present visual execution monitoring for a robot executing tasks in an uncharted Lab environment. The execution monitor interacts with the environment via a visual stream that uses two DCNN for recognizing the objects the robot has to deal with and manipulate, and a non-parametric Bayes estimation to discover the relations out of the DCNN features. To recover from lack of focus and failures due to missed objects we resort to visual search policies via deep reinforcement learning.\n    ",
        "submission_date": "2017-09-29T00:00:00",
        "last_modified_date": "2017-09-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.00336",
        "title": "Parameter Sharing Deep Deterministic Policy Gradient for Cooperative Multi-agent Reinforcement Learning",
        "authors": [
            "Xiangxiang Chu",
            "Hangjun Ye"
        ],
        "abstract": "Deep reinforcement learning for multi-agent cooperation and competition has been a hot topic recently. This paper focuses on cooperative multi-agent problem based on actor-critic methods under local observations settings. Multi agent deep deterministic policy gradient obtained state of art results for some multi-agent games, whereas, it cannot scale well with growing amount of agents. In order to boost scalability, we propose a parameter sharing deterministic policy gradient method with three variants based on neural networks, including actor-critic sharing, actor sharing and actor sharing with partially shared critic. Benchmarks from rllab show that the proposed method has advantages in learning speed and memory efficiency, well scales with growing amount of agents, and moreover, it can make full use of reward sharing and exchangeability if possible.\n    ",
        "submission_date": "2017-10-01T00:00:00",
        "last_modified_date": "2017-10-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.00461",
        "title": "Cooperative Automated Vehicles: a Review of Opportunities and Challenges in Socially Intelligent Vehicles Beyond Networking",
        "authors": [
            "Seng W. Loke"
        ],
        "abstract": "The connected automated vehicle has been often touted as a technology that will become pervasive in society in the near future. One can view an automated vehicle as having Artificial Intelligence (AI) capabilities, being able to self-drive, sense its surroundings, recognise objects in its vicinity, and perform reasoning and decision-making.\n",
        "submission_date": "2017-10-02T00:00:00",
        "last_modified_date": "2019-05-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.00490",
        "title": "The Dutch's Real World Financial Institute: Introducing Quantum-Like Bayesian Networks as an Alternative Model to deal with Uncertainty",
        "authors": [
            "Catarina Moreira",
            "Emmanuel Haven",
            "Sandro Sozzo",
            "Andreas Wichert"
        ],
        "abstract": "In this work, we analyse and model a real life financial loan application belonging to a sample bank in the Netherlands. The log is robust in terms of data, containing a total of 262 200 event logs, belonging to 13 087 different credit applications. The dataset is heterogeneous and consists of a mixture of computer generated automatic processes and manual human tasks. The goal is to work out a decision model, which represents the underlying tasks that make up the loan application service, and to assess potential areas of improvement of the institution's internal processes. To this end we study the impact of incomplete event logs for the extraction and analysis of business processes. It is quite common that event logs are incomplete with several amounts of missing information (for instance, workers forget to register their tasks). Absence of data is translated into a drastic decrease of precision and compromises the decision models, leading to biased and unrepresentative results. We investigate how classical probabilistic models are affected by incomplete event logs and we explore quantum-like probabilistic inferences as an alternative mathematical model to classical probability. This work represents a first step towards systematic investigation of the impact of quantum interference in a real life large scale decision scenario. The results obtained in this study indicate that, under high levels of uncertainty, the quantum-like models generate quantum interference terms, which allow an additional non-linear parameterisation of the data. Experimental results attest the efficiency of the quantum-like Bayesian networks, since the application of interference terms is able to reduce the error percentage of inferences performed over quantum-like models when compared to inferences produced by classical models.\n    ",
        "submission_date": "2017-10-02T00:00:00",
        "last_modified_date": "2017-10-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.00675",
        "title": "Sensor Synthesis for POMDPs with Reachability Objectives",
        "authors": [
            "Krishnendu Chatterjee",
            "Martin Chmelik",
            "Ufuk Topcu"
        ],
        "abstract": "Partially observable Markov decision processes (POMDPs) are widely used in probabilistic planning problems in which an agent interacts with an environment using noisy and imprecise sensors. We study a setting in which the sensors are only partially defined and the goal is to synthesize \"weakest\" additional sensors, such that in the resulting POMDP, there is a small-memory policy for the agent that almost-surely (with probability~1) satisfies a reachability objective. We show that the problem is NP-complete, and present a symbolic algorithm by encoding the problem into SAT instances. We illustrate trade-offs between the amount of memory of the policy and the number of additional sensors on a simple example. We have implemented our approach and consider three classical POMDP examples from the literature, and show that in all the examples the number of sensors can be significantly decreased (as compared to the existing solutions in the literature) without increasing the complexity of the policies.\n    ",
        "submission_date": "2017-09-29T00:00:00",
        "last_modified_date": "2017-09-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.00794",
        "title": "What Does Explainable AI Really Mean? A New Conceptualization of Perspectives",
        "authors": [
            "Derek Doran",
            "Sarah Schulz",
            "Tarek R. Besold"
        ],
        "abstract": "We characterize three notions of explainable AI that cut across research fields: opaque systems that offer no insight into its algo- rithmic mechanisms; interpretable systems where users can mathemat- ically analyze its algorithmic mechanisms; and comprehensible systems that emit symbols enabling user-driven explanations of how a conclusion is reached. The paper is motivated by a corpus analysis of NIPS, ACL, COGSCI, and ICCV/ECCV paper titles showing differences in how work on explainable AI is positioned in various fields. We close by introducing a fourth notion: truly explainable systems, where automated reasoning is central to output crafted explanations without requiring human post processing as final step of the generative process.\n    ",
        "submission_date": "2017-10-02T00:00:00",
        "last_modified_date": "2017-10-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.01275",
        "title": "Indexing the Event Calculus with Kd-trees to Monitor Diabetes",
        "authors": [
            "Stefano Bromuri",
            "Albert Brugues de la Torre",
            "Fabien Duboisson",
            "Michael Schumacher"
        ],
        "abstract": "Personal Health Systems (PHS) are mobile solutions tailored to monitoring patients affected by chronic non communicable diseases. A patient affected by a chronic disease can generate large amounts of events. Type 1 Diabetic patients generate several glucose events per day, ranging from at least 6 events per day (under normal monitoring) to 288 per day when wearing a continuous glucose monitor (CGM) that samples the blood every 5 minutes for several days. This is a large number of events to monitor for medical doctors, in particular when considering that they may have to take decisions concerning adjusting the treatment, which may impact the life of the patients for a long time. Given the need to analyse such a large stream of data, doctors need a simple approach towards physiological time series that allows them to promptly transfer their knowledge into queries to identify interesting patterns in the data. Achieving this with current technology is not an easy task, as on one hand it cannot be expected that medical doctors have the technical knowledge to query databases and on the other hand these time series include thousands of events, which requires to re-think the way data is indexed. In order to tackle the knowledge representation and efficiency problem, this contribution presents the kd-tree cached event calculus (\\ceckd) an event calculus extension for knowledge engineering of temporal rules capable to handle many thousands events produced by a diabetic patient. \\ceckd\\ is built as a support to a graphical interface to represent monitoring rules for diabetes type 1. In addition, the paper evaluates the \\ceckd\\ with respect to the cached event calculus (CEC) to show how indexing events using kd-trees improves scalability with respect to the current state of the art.\n    ",
        "submission_date": "2017-10-03T00:00:00",
        "last_modified_date": "2017-10-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.01347",
        "title": "Simple Cortex: A Model of Cells in the Sensory Nervous System",
        "authors": [
            "David Di Giorgio"
        ],
        "abstract": "Neuroscience research has produced many theories and computational neural models of sensory nervous systems. Notwithstanding many different perspectives towards developing intelligent machines, artificial intelligence has ultimately been influenced by neuroscience. Therefore, this paper provides an introduction to biologically inspired machine intelligence by exploring the basic principles of sensation and perception as well as the structure and behavior of biological sensory nervous systems like the neocortex. Concepts like spike timing, synaptic plasticity, inhibition, neural structure, and neural behavior are applied to a new model, Simple Cortex (SC). A software implementation of SC has been built and demonstrates fast observation, learning, and prediction of spatio-temporal sensory-motor patterns and sequences. Finally, this paper suggests future areas of improvement and growth for Simple Cortex and other related machine intelligence models.\n    ",
        "submission_date": "2017-10-03T00:00:00",
        "last_modified_date": "2017-10-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.01447",
        "title": "Feasibility Study: Moving Non-Homogeneous Teams in Congested Video Game Environments",
        "authors": [
            "Hang Ma",
            "Jingxing Yang",
            "Liron Cohen",
            "T. K. Satish Kumar",
            "Sven Koenig"
        ],
        "abstract": "Multi-agent path finding (MAPF) is a well-studied problem in artificial intelligence, where one needs to find collision-free paths for agents with given start and goal locations. In video games, agents of different types often form teams. In this paper, we demonstrate the usefulness of MAPF algorithms from artificial intelligence for moving such non-homogeneous teams in congested video game environments.\n    ",
        "submission_date": "2017-10-04T00:00:00",
        "last_modified_date": "2017-10-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.01813",
        "title": "Neural Task Programming: Learning to Generalize Across Hierarchical Tasks",
        "authors": [
            "Danfei Xu",
            "Suraj Nair",
            "Yuke Zhu",
            "Julian Gao",
            "Animesh Garg",
            "Li Fei-Fei",
            "Silvio Savarese"
        ],
        "abstract": "In this work, we propose a novel robot learning framework called Neural Task Programming (NTP), which bridges the idea of few-shot learning from demonstration and neural program induction. NTP takes as input a task specification (e.g., video demonstration of a task) and recursively decomposes it into finer sub-task specifications. These specifications are fed to a hierarchical neural program, where bottom-level programs are callable subroutines that interact with the environment. We validate our method in three robot manipulation tasks. NTP achieves strong generalization across sequential tasks that exhibit hierarchal and compositional structures. The experimental results show that NTP learns to generalize well to- wards unseen tasks with increasing lengths, variable topologies, and changing objectives.\n    ",
        "submission_date": "2017-10-04T00:00:00",
        "last_modified_date": "2018-03-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.01823",
        "title": "Automatic Taxonomy Generation - A Use-Case in the Legal Domain",
        "authors": [
            "C\u00e9cile Robin",
            "James O'Neill",
            "Paul Buitelaar"
        ],
        "abstract": "A key challenge in the legal domain is the adaptation and representation of the legal knowledge expressed through texts, in order for legal practitioners and researchers to access this information easier and faster to help with compliance related issues. One way to approach this goal is in the form of a taxonomy of legal concepts. While this task usually requires a manual construction of terms and their relations by domain experts, this paper describes a methodology to automatically generate a taxonomy of legal noun concepts. We apply and compare two approaches on a corpus consisting of statutory instruments for UK, Wales, Scotland and Northern Ireland laws.\n    ",
        "submission_date": "2017-10-04T00:00:00",
        "last_modified_date": "2017-10-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.02103",
        "title": "Learning Graphical Models from a Distributed Stream",
        "authors": [
            "Yu Zhang",
            "Srikanta Tirthapura",
            "Graham Cormode"
        ],
        "abstract": "A current challenge for data management systems is to support the construction and maintenance of machine learning models over data that is large, multi-dimensional, and evolving. While systems that could support these tasks are emerging, the need to scale to distributed, streaming data requires new models and algorithms. In this setting, as well as computational scalability and model accuracy, we also need to minimize the amount of communication between distributed processors, which is the chief component of latency. We study Bayesian networks, the workhorse of graphical models, and present a communication-efficient method for continuously learning and maintaining a Bayesian network model over data that is arriving as a distributed stream partitioned across multiple processors. We show a strategy for maintaining model parameters that leads to an exponential reduction in communication when compared with baseline approaches to maintain the exact MLE (maximum likelihood estimation). Meanwhile, our strategy provides similar prediction errors for the target distribution and for classification tasks.\n    ",
        "submission_date": "2017-10-05T00:00:00",
        "last_modified_date": "2017-10-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.02210",
        "title": "Exploration in Feature Space for Reinforcement Learning",
        "authors": [
            "Suraj Narayanan Sasikumar"
        ],
        "abstract": "The infamous exploration-exploitation dilemma is one of the oldest and most important problems in reinforcement learning (RL). Deliberate and effective exploration is necessary for RL agents to succeed in most environments. However, until very recently even very sophisticated RL algorithms employed simple, undirected exploration strategies in large-scale RL tasks.\n",
        "submission_date": "2017-10-05T00:00:00",
        "last_modified_date": "2017-10-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.02224",
        "title": "Dilated Recurrent Neural Networks",
        "authors": [
            "Shiyu Chang",
            "Yang Zhang",
            "Wei Han",
            "Mo Yu",
            "Xiaoxiao Guo",
            "Wei Tan",
            "Xiaodong Cui",
            "Michael Witbrock",
            "Mark Hasegawa-Johnson",
            "Thomas S. Huang"
        ],
        "abstract": "Learning with recurrent neural networks (RNNs) on long sequences is a notoriously difficult task. There are three major challenges: 1) complex dependencies, 2) vanishing and exploding gradients, and 3) efficient parallelization. In this paper, we introduce a simple yet effective RNN connection structure, the DilatedRNN, which simultaneously tackles all of these challenges. The proposed architecture is characterized by multi-resolution dilated recurrent skip connections and can be combined flexibly with diverse RNN cells. Moreover, the DilatedRNN reduces the number of parameters needed and enhances training efficiency significantly, while matching state-of-the-art performance (even with standard RNN cells) in tasks involving very long-term dependencies. To provide a theory-based quantification of the architecture's advantages, we introduce a memory capacity measure, the mean recurrent length, which is more suitable for RNNs with long skip connections than existing measures. We rigorously prove the advantages of the DilatedRNN over other recurrent neural architectures. The code for our method is publicly available at ",
        "submission_date": "2017-10-05T00:00:00",
        "last_modified_date": "2017-11-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.02298",
        "title": "Rainbow: Combining Improvements in Deep Reinforcement Learning",
        "authors": [
            "Matteo Hessel",
            "Joseph Modayil",
            "Hado van Hasselt",
            "Tom Schaul",
            "Georg Ostrovski",
            "Will Dabney",
            "Dan Horgan",
            "Bilal Piot",
            "Mohammad Azar",
            "David Silver"
        ],
        "abstract": "The deep reinforcement learning community has made several independent improvements to the DQN algorithm. However, it is unclear which of these extensions are complementary and can be fruitfully combined. This paper examines six extensions to the DQN algorithm and empirically studies their combination. Our experiments show that the combination provides state-of-the-art performance on the Atari 2600 benchmark, both in terms of data efficiency and final performance. We also provide results from a detailed ablation study that shows the contribution of each component to overall performance.\n    ",
        "submission_date": "2017-10-06T00:00:00",
        "last_modified_date": "2017-10-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.02511",
        "title": "Performance Prediction and Optimization of Solar Water Heater via a Knowledge-Based Machine Learning Method",
        "authors": [
            "Hao Li",
            "Zhijian Liu"
        ],
        "abstract": "Measuring the performance of solar energy and heat transfer systems requires a lot of time, economic cost and manpower. Meanwhile, directly predicting their performance is challenging due to the complicated internal structures. Fortunately, a knowledge-based machine learning method can provide a promising prediction and optimization strategy for the performance of energy systems. In this Chapter, the authors will show how they utilize the machine learning models trained from a large experimental database to perform precise prediction and optimization on a solar water heater (SWH) system. A new energy system optimization strategy based on a high-throughput screening (HTS) process is proposed. This Chapter consists of: i) Comparative studies on varieties of machine learning models (artificial neural networks (ANNs), support vector machine (SVM) and extreme learning machine (ELM)) to predict the performances of SWHs; ii) Development of an ANN-based software to assist the quick prediction and iii) Introduction of a computational HTS method to design a high-performance SWH system.\n    ",
        "submission_date": "2017-10-06T00:00:00",
        "last_modified_date": "2017-10-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.02648",
        "title": "Can Machines Think in Radio Language?",
        "authors": [
            "Yujian Li"
        ],
        "abstract": "People can think in auditory, visual and tactile forms of language, so can machines principally. But is it possible for them to think in radio language? According to a first principle presented for general intelligence, i.e. the principle of language's relativity, the answer may give an exceptional solution for robot astronauts to talk with each other in space exploration.\n    ",
        "submission_date": "2017-10-07T00:00:00",
        "last_modified_date": "2017-12-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.02714",
        "title": "Interactive Learning of State Representation through Natural Language Instruction and Explanation",
        "authors": [
            "Qiaozi Gao",
            "Lanbo She",
            "Joyce Y. Chai"
        ],
        "abstract": "One significant simplification in most previous work on robot learning is the closed-world assumption where the robot is assumed to know ahead of time a complete set of predicates describing the state of the physical world. However, robots are not likely to have a complete model of the world especially when learning a new task. To address this problem, this extended abstract gives a brief introduction to our on-going work that aims to enable the robot to acquire new state representations through language communication with humans.\n    ",
        "submission_date": "2017-10-07T00:00:00",
        "last_modified_date": "2017-10-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.02869",
        "title": "An Analysis of the Value of Information when Exploring Stochastic, Discrete Multi-Armed Bandits",
        "authors": [
            "Isaac J. Sledge",
            "Jose C. Principe"
        ],
        "abstract": "In this paper, we propose an information-theoretic exploration strategy for stochastic, discrete multi-armed bandits that achieves optimal regret. Our strategy is based on the value of information criterion. This criterion measures the trade-off between policy information and obtainable rewards. High amounts of policy information are associated with exploration-dominant searches of the space and yield high rewards. Low amounts of policy information favor the exploitation of existing knowledge. Information, in this criterion, is quantified by a parameter that can be varied during search. We demonstrate that a simulated-annealing-like update of this parameter, with a sufficiently fast cooling schedule, leads to an optimal regret that is logarithmic with respect to the number of episodes.\n    ",
        "submission_date": "2017-10-08T00:00:00",
        "last_modified_date": "2018-03-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.02896",
        "title": "Recurrent Deterministic Policy Gradient Method for Bipedal Locomotion on Rough Terrain Challenge",
        "authors": [
            "Doo Re Song",
            "Chuanyu Yang",
            "Christopher McGreavy",
            "Zhibin Li"
        ],
        "abstract": "This paper presents a deep learning framework that is capable of solving partially observable locomotion tasks based on our novel interpretation of Recurrent Deterministic Policy Gradient (RDPG). We study on bias of sampled error measure and its variance induced by the partial observability of environment and subtrajectory sampling, respectively. Three major improvements are introduced in our RDPG based learning framework: tail-step bootstrap of interpolated temporal difference, initialisation of hidden state using past trajectory scanning, and injection of external experiences learned by other agents. The proposed learning framework was implemented to solve the Bipedal-Walker challenge in OpenAI's gym simulation environment where only partial state information is available. Our simulation study shows that the autonomous behaviors generated by the RDPG agent are highly adaptive to a variety of obstacles and enables the agent to effectively traverse rugged terrains for long distance with higher success rate than leading contenders.\n    ",
        "submission_date": "2017-10-08T00:00:00",
        "last_modified_date": "2019-12-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.03131",
        "title": "MSC: A Dataset for Macro-Management in StarCraft II",
        "authors": [
            "Huikai Wu",
            "Yanqi Zong",
            "Junge Zhang",
            "Kaiqi Huang"
        ],
        "abstract": "Macro-management is an important problem in StarCraft, which has been studied for a long time. Various datasets together with assorted methods have been proposed in the last few years. But these datasets have some defects for boosting the academic and industrial research: 1) There're neither standard preprocessing, parsing and feature extraction procedures nor predefined training, validation and test set in some datasets. 2) Some datasets are only specified for certain tasks in macro-management. 3) Some datasets are either too small or don't have enough labeled data for modern machine learning algorithms such as deep neural networks. So most previous methods are trained with various features, evaluated on different test sets from the same or different datasets, making it difficult to be compared directly. To boost the research of macro-management in StarCraft, we release a new dataset MSC based on the platform SC2LE. MSC consists of well-designed feature vectors, pre-defined high-level actions and final result of each match. We also split MSC into training, validation and test set for the convenience of evaluation and comparison. Besides the dataset, we propose a baseline model and present initial baseline results for global state evaluation and build order prediction, which are two of the key tasks in macro-management. Various downstream tasks and analyses of the dataset are also described for the sake of research on macro-management in StarCraft II. Homepage: ",
        "submission_date": "2017-10-09T00:00:00",
        "last_modified_date": "2023-04-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.03263",
        "title": "Function space analysis of deep learning representation layers",
        "authors": [
            "Oren Elisha",
            "Shai Dekel"
        ],
        "abstract": "In this paper we propose a function space approach to Representation Learning and the analysis of the representation layers in deep learning architectures. We show how to compute a weak-type Besov smoothness index that quantifies the geometry of the clustering in the feature space. This approach was already applied successfully to improve the performance of machine learning algorithms such as the Random Forest and tree-based Gradient Boosting. Our experiments demonstrate that in well-known and well-performing trained networks, the Besov smoothness of the training set, measured in the corresponding hidden layer feature map representation, increases from layer to layer. We also contribute to the understanding of generalization by showing how the Besov smoothness of the representations, decreases as we add more mis-labeling to the training data. We hope this approach will contribute to the de-mystification of some aspects of deep learning.\n    ",
        "submission_date": "2017-10-09T00:00:00",
        "last_modified_date": "2017-10-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.03285",
        "title": "Coresets for Dependency Networks",
        "authors": [
            "Alejandro Molina",
            "Alexander Munteanu",
            "Kristian Kersting"
        ],
        "abstract": "Many applications infer the structure of a probabilistic graphical model from data to elucidate the relationships between variables. But how can we train graphical models on a massive data set? In this paper, we show how to construct coresets -compressed data sets which can be used as proxy for the original data and have provably bounded worst case error- for Gaussian dependency networks (DNs), i.e., cyclic directed graphical models over Gaussians, where the parents of each variable are its Markov blanket. Specifically, we prove that Gaussian DNs admit coresets of size independent of the size of the data set. Unfortunately, this does not extend to DNs over members of the exponential family in general. As we will prove, Poisson DNs do not admit small coresets. Despite this worst-case result, we will provide an argument why our coreset construction for DNs can still work well in practice on count data. To corroborate our theoretical results, we empirically evaluated the resulting Core DNs on real data sets. The results\n    ",
        "submission_date": "2017-10-09T00:00:00",
        "last_modified_date": "2017-10-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.03346",
        "title": "Geo-referencing Place from Everyday Natural Language Descriptions",
        "authors": [
            "Hao Chen",
            "Maria Vasardani",
            "Stephan Winter"
        ],
        "abstract": "Natural language place descriptions in everyday communication provide a rich source of spatial knowledge about places. An important step to utilize such knowledge in information systems is geo-referencing all the places referred to in these descriptions. Current techniques for geo-referencing places from text documents are using place name recognition and disambiguation; however, place descriptions often contain place references that are not known by gazetteers, or that are expressed in other, more flexible ways. Hence, the approach for geo-referencing presented in this paper starts from a place graph that contains the place references as well as spatial relationships extracted from place descriptions. Spatial relationships are used to constrain the locations of places and allow the later best-matching process for geo-referencing. The novel geo-referencing process results in higher precision and recall compared to state-of-art toponym resolution approaches on several tested place description datasets.\n    ",
        "submission_date": "2017-10-09T00:00:00",
        "last_modified_date": "2017-10-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.03390",
        "title": "On Preemption and Overdetermination in Formal Theories of Causality",
        "authors": [
            "Sjur K Dyrkolbotn"
        ],
        "abstract": "One of the key challenges when looking for the causes of a complex event is to determine the causal status of factors that are neither individually necessary nor individually sufficient to produce that event. In order to reason about how such factors should be taken into account, we need a vocabulary to distinguish different cases. In philosophy, the concept of overdetermination and the concept of preemption serve an important purpose in this regard, although their exact meaning tends to remain elusive. In this paper, I provide theory-neutral definitions of these concepts using structural equations in the Halpern-Pearl tradition. While my definitions do not presuppose any particular causal theory, they take such a theory as a variable parameter. This enables us to specify formal constraints on theories of causality, in terms of a pre-theoretic understanding of what preemption and overdetermination actually mean. I demonstrate the usefulness of this by presenting and arguing for what I call the principle of presumption. Roughly speaking, this principle states that a possible cause can only be regarded as having been preempted if there is independent evidence to support such an inference. I conclude by showing that the principle of presumption is violated by the two main theories of causality formulated in the Halpern-Pearl tradition. The paper concludes by defining the class of empirical causal theories, characterised in terms of a fixed-point of counterfactual reasoning about difference-making. It is argued that theories of actual causality ought to be empirical.\n    ",
        "submission_date": "2017-10-10T00:00:00",
        "last_modified_date": "2017-10-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.03392",
        "title": "Causality and Temporal Dependencies in the Design of Fault Management Systems",
        "authors": [
            "Marco Bozzano"
        ],
        "abstract": "Reasoning about causes and effects naturally arises in the engineering of safety-critical systems. A classical example is Fault Tree Analysis, a deductive technique used for system safety assessment, whereby an undesired state is reduced to the set of its immediate causes. The design of fault management systems also requires reasoning on causality relationships. In particular, a fail-operational system needs to ensure timely detection and identification of faults, i.e. recognize the occurrence of run-time faults through their observable effects on the system. Even more complex scenarios arise when multiple faults are involved and may interact in subtle ways.\n",
        "submission_date": "2017-10-10T00:00:00",
        "last_modified_date": "2017-10-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.03442",
        "title": "On- and Off-Policy Monotonic Policy Improvement",
        "authors": [
            "Ryo Iwaki",
            "Minoru Asada"
        ],
        "abstract": "Monotonic policy improvement and off-policy learning are two main desirable properties for reinforcement learning algorithms. In this paper, by lower bounding the performance difference of two policies, we show that the monotonic policy improvement is guaranteed from on- and off-policy mixture samples. An optimization procedure which applies the proposed bound can be regarded as an off-policy natural policy gradient method. In order to support the theoretical result, we provide a trust region policy optimization method using experience replay as a naive application of our bound, and evaluate its performance in two classical benchmark problems.\n    ",
        "submission_date": "2017-10-10T00:00:00",
        "last_modified_date": "2017-11-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.03481",
        "title": "A Note on Nesting in Dyadic Deontic Logic",
        "authors": [
            "Agneau Belanyek",
            "Davide Grossi",
            "Wiebe van der Hoek"
        ],
        "abstract": "The paper reports on some results concerning Aqvist's dyadic logic known as system G, which is one of the most influential logics for reasoning with dyadic obligations (\"it ought to be the case that ... if it is the case that ...\"). Although this logic has been known in the literature for a while, many of its properties still await in-depth consideration. In this short paper we show: that any formula in system G including nested modal operators is equivalent to some formula with no nesting; that the universal modality introduced by Aqvist in the first presentation of the system is definable in terms of the deontic modality.\n    ",
        "submission_date": "2017-10-10T00:00:00",
        "last_modified_date": "2017-10-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.03592",
        "title": "Meta Inverse Reinforcement Learning via Maximum Reward Sharing for Human Motion Analysis",
        "authors": [
            "Kun Li",
            "Joel W. Burdick"
        ],
        "abstract": "This work handles the inverse reinforcement learning (IRL) problem where only a small number of demonstrations are available from a demonstrator for each high-dimensional task, insufficient to estimate an accurate reward function. Observing that each demonstrator has an inherent reward for each state and the task-specific behaviors mainly depend on a small number of key states, we propose a meta IRL algorithm that first models the reward function for each task as a distribution conditioned on a baseline reward function shared by all tasks and dependent only on the demonstrator, and then finds the most likely reward function in the distribution that explains the task-specific behaviors. We test the method in a simulated environment on path planning tasks with limited demonstrations, and show that the accuracy of the learned reward function is significantly improved. We also apply the method to analyze the motion of a patient under rehabilitation.\n    ",
        "submission_date": "2017-10-07T00:00:00",
        "last_modified_date": "2017-10-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.03740",
        "title": "Mixed Precision Training",
        "authors": [
            "Paulius Micikevicius",
            "Sharan Narang",
            "Jonah Alben",
            "Gregory Diamos",
            "Erich Elsen",
            "David Garcia",
            "Boris Ginsburg",
            "Michael Houston",
            "Oleksii Kuchaiev",
            "Ganesh Venkatesh",
            "Hao Wu"
        ],
        "abstract": "Deep neural networks have enabled progress in a wide variety of applications. Growing the size of the neural network typically results in improved accuracy. As model sizes grow, the memory and compute requirements for training these models also increases. We introduce a technique to train deep neural networks using half precision floating point numbers. In our technique, weights, activations and gradients are stored in IEEE half-precision format. Half-precision floating numbers have limited numerical range compared to single-precision numbers. We propose two techniques to handle this loss of information. Firstly, we recommend maintaining a single-precision copy of the weights that accumulates the gradients after each optimizer step. This single-precision copy is rounded to half-precision format during training. Secondly, we propose scaling the loss appropriately to handle the loss of information with half-precision gradients. We demonstrate that this approach works for a wide variety of models including convolution neural networks, recurrent neural networks and generative adversarial networks. This technique works for large scale models with more than 100 million parameters trained on large datasets. Using this approach, we can reduce the memory consumption of deep learning models by nearly 2x. In future processors, we can also expect a significant computation speedup using half-precision hardware units.\n    ",
        "submission_date": "2017-10-10T00:00:00",
        "last_modified_date": "2018-02-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.03748",
        "title": "Emergent Complexity via Multi-Agent Competition",
        "authors": [
            "Trapit Bansal",
            "Jakub Pachocki",
            "Szymon Sidor",
            "Ilya Sutskever",
            "Igor Mordatch"
        ],
        "abstract": "Reinforcement learning algorithms can train agents that solve problems in complex, interesting environments. Normally, the complexity of the trained agent is closely related to the complexity of the environment. This suggests that a highly capable agent requires a complex environment for training. In this paper, we point out that a competitive multi-agent environment trained with self-play can produce behaviors that are far more complex than the environment itself. We also point out that such environments come with a natural curriculum, because for any skill level, an environment full of agents of this level will have the right level of difficulty. This work introduces several competitive multi-agent environments where agents compete in a 3D world with simulated physics. The trained agents learn a wide variety of complex and interesting skills, even though the environment themselves are relatively simple. The skills include behaviors such as running, blocking, ducking, tackling, fooling opponents, kicking, and defending using both arms and legs. A highlight of the learned behaviors can be found here: ",
        "submission_date": "2017-10-10T00:00:00",
        "last_modified_date": "2018-03-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.03774",
        "title": "AI Buzzwords Explained: Multi-Agent Path Finding (MAPF)",
        "authors": [
            "Hang Ma",
            "Sven Koenig"
        ],
        "abstract": "Explanation of the hot topic \"multi-agent path finding\".\n    ",
        "submission_date": "2017-10-10T00:00:00",
        "last_modified_date": "2017-10-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.03792",
        "title": "Deep Reinforcement Learning: Framework, Applications, and Embedded Implementations",
        "authors": [
            "Hongjia Li",
            "Tianshu Wei",
            "Ao Ren",
            "Qi Zhu",
            "Yanzhi Wang"
        ],
        "abstract": "The recent breakthroughs of deep reinforcement learning (DRL) technique in Alpha Go and playing Atari have set a good example in handling large state and actions spaces of complicated control problems. The DRL technique is comprised of (i) an offline deep neural network (DNN) construction phase, which derives the correlation between each state-action pair of the system and its value function, and (ii) an online deep Q-learning phase, which adaptively derives the optimal action and updates value estimates. In this paper, we first present the general DRL framework, which can be widely utilized in many applications with different optimization objectives. This is followed by the introduction of three specific applications: the cloud computing resource allocation problem, the residential smart grid task scheduling problem, and building HVAC system optimal control problem. The effectiveness of the DRL technique in these three cyber-physical applications have been validated. Finally, this paper investigates the stochastic computing-based hardware implementations of the DRL framework, which consumes a significant improvement in area efficiency and power consumption compared with binary-based implementation counterparts.\n    ",
        "submission_date": "2017-10-10T00:00:00",
        "last_modified_date": "2017-10-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.03937",
        "title": "PRM-RL: Long-range Robotic Navigation Tasks by Combining Reinforcement Learning and Sampling-based Planning",
        "authors": [
            "Aleksandra Faust",
            "Oscar Ramirez",
            "Marek Fiser",
            "Kenneth Oslund",
            "Anthony Francis",
            "James Davidson",
            "Lydia Tapia"
        ],
        "abstract": "We present PRM-RL, a hierarchical method for long-range navigation task completion that combines sampling based path planning with reinforcement learning (RL). The RL agents learn short-range, point-to-point navigation policies that capture robot dynamics and task constraints without knowledge of the large-scale topology. Next, the sampling-based planners provide roadmaps which connect robot configurations that can be successfully navigated by the RL agent. The same RL agents are used to control the robot under the direction of the planning, enabling long-range navigation. We use the Probabilistic Roadmaps (PRMs) for the sampling-based planner. The RL agents are constructed using feature-based and deep neural net policies in continuous state and action spaces. We evaluate PRM-RL, both in simulation and on-robot, on two navigation tasks with non-trivial robot dynamics: end-to-end differential drive indoor navigation in office environments, and aerial cargo delivery in urban environments with load displacement constraints. Our results show improvement in task completion over both RL agents on their own and traditional sampling-based planners. In the indoor navigation task, PRM-RL successfully completes up to 215 m long trajectories under noisy sensor conditions, and the aerial cargo delivery completes flights over 1000 m without violating the task constraints in an environment 63 million times larger than used in training.\n    ",
        "submission_date": "2017-10-11T00:00:00",
        "last_modified_date": "2018-05-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.04157",
        "title": "Neural Program Meta-Induction",
        "authors": [
            "Jacob Devlin",
            "Rudy Bunel",
            "Rishabh Singh",
            "Matthew Hausknecht",
            "Pushmeet Kohli"
        ],
        "abstract": "Most recently proposed methods for Neural Program Induction work under the assumption of having a large set of input/output (I/O) examples for learning any underlying input-output mapping. This paper aims to address the problem of data and computation efficiency of program induction by leveraging information from related tasks. Specifically, we propose two approaches for cross-task knowledge transfer to improve program induction in limited-data scenarios. In our first proposal, portfolio adaptation, a set of induction models is pretrained on a set of related tasks, and the best model is adapted towards the new task using transfer learning. In our second approach, meta program induction, a $k$-shot learning approach is used to make a model generalize to new tasks without additional training. To test the efficacy of our methods, we constructed a new benchmark of programs written in the Karel programming language. Using an extensive experimental evaluation on the Karel benchmark, we demonstrate that our proposals dramatically outperform the baseline induction method that does not use knowledge transfer. We also analyze the relative performance of the two approaches and study conditions in which they perform best. In particular, meta induction outperforms all existing approaches under extreme data sparsity (when a very small number of examples are available), i.e., fewer than ten. As the number of available I/O examples increase (i.e. a thousand or more), portfolio adapted program induction becomes the best approach. For intermediate data sizes, we demonstrate that the combined method of adapted meta program induction has the strongest performance.\n    ",
        "submission_date": "2017-10-11T00:00:00",
        "last_modified_date": "2017-10-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.04161",
        "title": "Counterfactual Conditionals in Quantified Modal Logic",
        "authors": [
            "Naveen Sundar Govindarajulu",
            "Selmer Bringsjord"
        ],
        "abstract": "We present a novel formalization of counterfactual conditionals in a quantified modal logic. Counterfactual conditionals play a vital role in ethical and moral reasoning. Prior work has shown that moral reasoning systems (and more generally, theory-of-mind reasoning systems) should be at least as expressive as first-order (quantified) modal logic (QML) to be well-behaved. While existing work on moral reasoning has focused on counterfactual-free QML moral reasoning, we present a fully specified and implemented formal system that includes counterfactual conditionals. We validate our model with two projects. In the first project, we demonstrate that our system can be used to model a complex moral principle, the doctrine of double effect. In the second project, we use the system to build a data-set with true and false counterfactuals as licensed by our theory, which we believe can be useful for other researchers. This project also shows that our model can be computationally feasible.\n    ",
        "submission_date": "2017-10-11T00:00:00",
        "last_modified_date": "2017-11-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.04324",
        "title": "Explaining Trained Neural Networks with Semantic Web Technologies: First Steps",
        "authors": [
            "Md Kamruzzaman Sarker",
            "Ning Xie",
            "Derek Doran",
            "Michael Raymer",
            "Pascal Hitzler"
        ],
        "abstract": "The ever increasing prevalence of publicly available structured data on the World Wide Web enables new applications in a variety of domains. In this paper, we provide a conceptual approach that leverages such data in order to explain the input-output behavior of trained artificial neural networks. We apply existing Semantic Web technologies in order to provide an experimental proof of concept.\n    ",
        "submission_date": "2017-10-11T00:00:00",
        "last_modified_date": "2017-10-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.04459",
        "title": "Arguing Machines: Human Supervision of Black Box AI Systems That Make Life-Critical Decisions",
        "authors": [
            "Lex Fridman",
            "Li Ding",
            "Benedikt Jenik",
            "Bryan Reimer"
        ],
        "abstract": "We consider the paradigm of a black box AI system that makes life-critical decisions. We propose an \"arguing machines\" framework that pairs the primary AI system with a secondary one that is independently trained to perform the same task. We show that disagreement between the two systems, without any knowledge of underlying system design or operation, is sufficient to arbitrarily improve the accuracy of the overall decision pipeline given human supervision over disagreements. We demonstrate this system in two applications: (1) an illustrative example of image classification and (2) on large-scale real-world semi-autonomous driving data. For the first application, we apply this framework to image classification achieving a reduction from 8.0% to 2.8% top-5 error on ImageNet. For the second application, we apply this framework to Tesla Autopilot and demonstrate the ability to predict 90.4% of system disengagements that were labeled by human annotators as challenging and needing human supervision.\n    ",
        "submission_date": "2017-10-12T00:00:00",
        "last_modified_date": "2018-09-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.04502",
        "title": "Clusters of Driving Behavior from Observational Smartphone Data",
        "authors": [
            "Josh Warren",
            "Jeff Lipkowitz",
            "Vadim Sokolov"
        ],
        "abstract": "Understanding driving behaviors is essential for improving safety and mobility of our transportation systems. Data is usually collected via simulator-based studies or naturalistic driving studies. Those techniques allow for understanding relations between demographics, road conditions and safety. On the other hand, they are very costly and time consuming. Thanks to the ubiquity of smartphones, we have an opportunity to substantially complement more traditional data collection techniques with data extracted from phone sensors, such as GPS, accelerometer gyroscope and camera. We developed statistical models that provided insight into driver behavior in the San Francisco metro area based on tens of thousands of driver logs. We used novel data sources to support our work. We used cell phone sensor data drawn from five hundred drivers in San Francisco to understand the speed of traffic across the city as well as the maneuvers of drivers in different areas. Specifically, we clustered drivers based on their driving behavior. We looked at driver norms by street and flagged driving behaviors that deviated from the norm.\n    ",
        "submission_date": "2017-10-12T00:00:00",
        "last_modified_date": "2018-01-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.04748",
        "title": "HyperENTM: Evolving Scalable Neural Turing Machines through HyperNEAT",
        "authors": [
            "Jakob Merrild",
            "Mikkel Angaju Rasmussen",
            "Sebastian Risi"
        ],
        "abstract": "Recent developments within memory-augmented neural networks have solved sequential problems requiring long-term memory, which are intractable for traditional neural networks. However, current approaches still struggle to scale to large memory sizes and sequence lengths. In this paper we show how access to memory can be encoded geometrically through a HyperNEAT-based Neural Turing Machine (HyperENTM). We demonstrate that using the indirect HyperNEAT encoding allows for training on small memory vectors in a bit-vector copy task and then applying the knowledge gained from such training to speed up training on larger size memory vectors. Additionally, we demonstrate that in some instances, networks trained to copy bit-vectors of size 9 can be scaled to sizes of 1,000 without further training. While the task in this paper is simple, these results could open up the problems amendable to networks with external memories to problems with larger memory vectors and theoretically unbounded memory sizes.\n    ",
        "submission_date": "2017-10-12T00:00:00",
        "last_modified_date": "2017-10-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.04805",
        "title": "Combinatorial Multi-armed Bandits for Real-Time Strategy Games",
        "authors": [
            "Santiago Onta\u00f1\u00f3n"
        ],
        "abstract": "Games with large branching factors pose a significant challenge for game tree search algorithms. In this paper, we address this problem with a sampling strategy for Monte Carlo Tree Search (MCTS) algorithms called {\\em na\u00efve sampling}, based on a variant of the Multi-armed Bandit problem called {\\em Combinatorial Multi-armed Bandits} (CMAB). We analyze the theoretical properties of several variants of {\\em na\u00efve sampling}, and empirically compare it against the other existing strategies in the literature for CMABs. We then evaluate these strategies in the context of real-time strategy (RTS) games, a genre of computer games characterized by their very large branching factors. Our results show that as the branching factor grows, {\\em na\u00efve sampling} outperforms the other sampling strategies.\n    ",
        "submission_date": "2017-10-13T00:00:00",
        "last_modified_date": "2017-10-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.04806",
        "title": "Deep Learning for Case-Based Reasoning through Prototypes: A Neural Network that Explains Its Predictions",
        "authors": [
            "Oscar Li",
            "Hao Liu",
            "Chaofan Chen",
            "Cynthia Rudin"
        ],
        "abstract": "Deep neural networks are widely used for classification. These deep models often suffer from a lack of interpretability -- they are particularly difficult to understand because of their non-linear nature. As a result, neural networks are often treated as \"black box\" models, and in the past, have been trained purely to optimize the accuracy of predictions. In this work, we create a novel network architecture for deep learning that naturally explains its own reasoning for each prediction. This architecture contains an autoencoder and a special prototype layer, where each unit of that layer stores a weight vector that resembles an encoded training input. The encoder of the autoencoder allows us to do comparisons within the latent space, while the decoder allows us to visualize the learned prototypes. The training objective has four terms: an accuracy term, a term that encourages every prototype to be similar to at least one encoded input, a term that encourages every encoded input to be close to at least one prototype, and a term that encourages faithful reconstruction by the autoencoder. The distances computed in the prototype layer are used as part of the classification process. Since the prototypes are learned during training, the learned network naturally comes with explanations for each prediction, and the explanations are loyal to what the network actually computes.\n    ",
        "submission_date": "2017-10-13T00:00:00",
        "last_modified_date": "2017-11-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.04822",
        "title": "Fast Top-k Area Topics Extraction with Knowledge Base",
        "authors": [
            "Fang Zhang",
            "Xiaochen Wang",
            "Jingfei Han",
            "Jie Tang",
            "Shiyin Wang",
            "Marie-Francine Moens"
        ],
        "abstract": "What are the most popular research topics in Artificial Intelligence (AI)? We formulate the problem as extracting top-$k$ topics that can best represent a given area with the help of knowledge base. We theoretically prove that the problem is NP-hard and propose an optimization model, FastKATE, to address this problem by combining both explicit and latent representations for each topic. We leverage a large-scale knowledge base (Wikipedia) to generate topic embeddings using neural networks and use this kind of representations to help capture the representativeness of topics for given areas. We develop a fast heuristic algorithm to efficiently solve the problem with a provable error bound. We evaluate the proposed model on three real-world datasets. Experimental results demonstrate our model's effectiveness, robustness, real-timeness (return results in $<1$s), and its superiority over several alternative methods.\n    ",
        "submission_date": "2017-10-13T00:00:00",
        "last_modified_date": "2017-12-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.05060",
        "title": "Functional Decision Theory: A New Theory of Instrumental Rationality",
        "authors": [
            "Eliezer Yudkowsky",
            "Nate Soares"
        ],
        "abstract": "This paper describes and motivates a new decision theory known as functional decision theory (FDT), as distinct from causal decision theory and evidential decision theory. Functional decision theorists hold that the normative principle for action is to treat one's decision as the output of a fixed mathematical function that answers the question, \"Which output of this very function would yield the best outcome?\" Adhering to this principle delivers a number of benefits, including the ability to maximize wealth in an array of traditional decision-theoretic and game-theoretic problems where CDT and EDT perform poorly. Using one simple and coherent decision rule, functional decision theorists (for example) achieve more utility than CDT on Newcomb's problem, more utility than EDT on the smoking lesion problem, and more utility than both in Parfit's hitchhiker problem. In this paper, we define FDT, explore its prescriptions in a number of different decision problems, compare it to CDT and EDT, and give philosophical justifications for FDT as a normative theory of decision-making.\n    ",
        "submission_date": "2017-10-13T00:00:00",
        "last_modified_date": "2018-05-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.05096",
        "title": "On the Ontological Modeling of Trees",
        "authors": [
            "David Carral",
            "Pascal Hitzler",
            "Hilmar Lapp",
            "Sebastian Rudolph"
        ],
        "abstract": "Trees -- i.e., the type of data structure known under this name -- are central to many aspects of knowledge organization. We investigate some central design choices concerning the ontological modeling of such trees. In particular, we consider the limits of what is expressible in the Web Ontology Language, and provide a reusable ontology design pattern for trees.\n    ",
        "submission_date": "2017-10-13T00:00:00",
        "last_modified_date": "2017-10-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.05207",
        "title": "Network Model Selection Using Task-Focused Minimum Description Length",
        "authors": [
            "Ivan Brugere",
            "Tanya Y. Berger-Wolf"
        ],
        "abstract": "Networks are fundamental models for data used in practically every application domain. In most instances, several implicit or explicit choices about the network definition impact the translation of underlying data to a network representation, and the subsequent question(s) about the underlying system being represented. Users of downstream network data may not even be aware of these choices or their impacts. We propose a task-focused network model selection methodology which addresses several key challenges. Our approach constructs network models from underlying data and uses minimum description length (MDL) criteria for selection. Our methodology measures efficiency, a general and comparable measure of the network's performance of a local (i.e. node-level) predictive task of interest. Selection on efficiency favors parsimonious (e.g. sparse) models to avoid overfitting and can be applied across arbitrary tasks and representations. We show stability, sensitivity, and significance testing in our methodology.\n    ",
        "submission_date": "2017-10-14T00:00:00",
        "last_modified_date": "2018-01-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.05257",
        "title": "Multi-Value Rule Sets",
        "authors": [
            "Tong Wang"
        ],
        "abstract": "We present the Multi-vAlue Rule Set (MARS) model for interpretable classification with feature efficient presentations. MARS introduces a more generalized form of association rules that allows multiple values in a condition. Rules of this form are more concise than traditional single-valued rules in capturing and describing patterns in data. MARS mitigates the problem of dealing with continuous features and high-cardinality categorical features faced by rule-based models. Our formulation also pursues a higher efficiency of feature utilization, which reduces the cognitive load to understand the decision process. We propose an efficient inference method for learning a maximum a posteriori model, incorporating theoretically grounded bounds to iteratively reduce the search space to improve search efficiency. Experiments with synthetic and real-world data demonstrate that MARS models have significantly smaller complexity and fewer features, providing better interpretability while being competitive in predictive accuracy. We conducted a usability study with human subjects and results show that MARS is the easiest to use compared with other competing rule-based models, in terms of the correct rate and response time. Overall, MARS introduces a new approach to rule-based models that balance accuracy and interpretability with feature-efficient representations.\n    ",
        "submission_date": "2017-10-15T00:00:00",
        "last_modified_date": "2017-10-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.05341",
        "title": "The Complete Extensions do not form a Complete Semilattice",
        "authors": [
            "Anthony P. Young"
        ],
        "abstract": "In his seminal paper that inaugurated abstract argumentation, Dung proved that the set of complete extensions forms a complete semilattice with respect to set inclusion. In this note we demonstrate that this proof is incorrect with counterexamples. We then trace the error in the proof and explain why it arose. We then examine the implications for the grounded extension.\n[Reason for withdrawal continued] Page 4, Example 2 is not a counterexample to Dung 1995 Theorem 25(3). It was believed to be a counter-example because the author misunderstood ``glb'' to be set-theoretic intersection. But in this case, ``glb'' is defined to be other than set-theoretic intersection such that Theorem 25(3) is true.\nThe author was motivated to fully understand the lattice-theoretic claims of Dung 1995 in writing this note and was not aware that this issue is probably folklore; the author bears full responsibility for this error.\n    ",
        "submission_date": "2017-10-15T00:00:00",
        "last_modified_date": "2017-10-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.05426",
        "title": "Causal Rule Sets for Identifying Subgroups with Enhanced Treatment Effect",
        "authors": [
            "Tong Wang",
            "Cynthia Rudin"
        ],
        "abstract": "A key question in causal inference analyses is how to find subgroups with elevated treatment effects. This paper takes a machine learning approach and introduces a generative model, Causal Rule Sets (CRS), for interpretable subgroup discovery. A CRS model uses a small set of short decision rules to capture a subgroup where the average treatment effect is elevated. We present a Bayesian framework for learning a causal rule set. The Bayesian model consists of a prior that favors simple models for better interpretability as well as avoiding overfitting, and a Bayesian logistic regression that captures the likelihood of data, characterizing the relation between outcomes, attributes, and subgroup membership. The Bayesian model has tunable parameters that can characterize subgroups with various sizes, providing users with more flexible choices of models from the \\emph{treatment efficient frontier}. We find maximum a posteriori models using iterative discrete Monte Carlo steps in the joint solution space of rules sets and parameters. To improve search efficiency, we provide theoretically grounded heuristics and bounding strategies to prune and confine the search space. Experiments show that the search algorithm can efficiently recover true underlying subgroups. We apply CRS on public and real-world datasets from domains where interpretability is indispensable. We compare CRS with state-of-the-art rule-based subgroup discovery models. Results show that CRS achieved consistently competitive performance on datasets from various domains, represented by high treatment efficient frontiers.\n    ",
        "submission_date": "2017-10-16T00:00:00",
        "last_modified_date": "2021-05-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.05465",
        "title": "Flow: A Modular Learning Framework for Mixed Autonomy Traffic",
        "authors": [
            "Cathy Wu",
            "Aboudy Kreidieh",
            "Kanaad Parvate",
            "Eugene Vinitsky",
            "Alexandre M Bayen"
        ],
        "abstract": "The rapid development of autonomous vehicles (AVs) holds vast potential for transportation systems through improved safety, efficiency, and access to mobility. However, the progression of these impacts, as AVs are adopted, is not well understood. Numerous technical challenges arise from the goal of analyzing the partial adoption of autonomy: partial control and observation, multi-vehicle interactions, and the sheer variety of scenarios represented by real-world networks. To shed light into near-term AV impacts, this article studies the suitability of deep reinforcement learning (RL) for overcoming these challenges in a low AV-adoption regime. A modular learning framework is presented, which leverages deep RL to address complex traffic dynamics. Modules are composed to capture common traffic phenomena (stop-and-go traffic jams, lane changing, intersections). Learned control laws are found to improve upon human driving performance, in terms of system-level velocity, by up to 57% with only 4-7% adoption of AVs. Furthermore, in single-lane traffic, a small neural network control law with only local observation is found to eliminate stop-and-go traffic - surpassing all known model-based controllers to achieve near-optimal performance - and generalize to out-of-distribution traffic densities.\n    ",
        "submission_date": "2017-10-16T00:00:00",
        "last_modified_date": "2021-12-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.05503",
        "title": "Toward Crowd-Sensitive Path Planning",
        "authors": [
            "Anoop Aroor",
            "Susan L. Epstein"
        ],
        "abstract": "If a robot can predict crowds in parts of its environment that are inaccessible to its sensors, then it can plan to avoid them. This paper proposes a fast, online algorithm that learns average crowd densities in different areas. It also describes how these densities can be incorporated into existing navigation architectures. In simulation across multiple challenging crowd scenarios, the robot reaches its target faster, travels less, and risks fewer collisions than if it were to plan with the traditional A* algorithm.\n    ",
        "submission_date": "2017-10-16T00:00:00",
        "last_modified_date": "2017-10-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.05627",
        "title": "Intention-Net: Integrating Planning and Deep Learning for Goal-Directed Autonomous Navigation",
        "authors": [
            "Wei Gao",
            "David Hsu",
            "Wee Sun Lee",
            "Shengmei Shen",
            "Karthikk Subramanian"
        ],
        "abstract": "How can a delivery robot navigate reliably to a destination in a new office building, with minimal prior information? To tackle this challenge, this paper introduces a two-level hierarchical approach, which integrates model-free deep learning and model-based path planning. At the low level, a neural-network motion controller, called the intention-net, is trained end-to-end to provide robust local navigation. The intention-net maps images from a single monocular camera and \"intentions\" directly to robot controls. At the high level, a path planner uses a crude map, e.g., a 2-D floor plan, to compute a path from the robot's current location to the goal. The planned path provides intentions to the intention-net. Preliminary experiments suggest that the learned motion controller is robust against perceptual uncertainty and by integrating with a path planner, it generalizes effectively to new environments and goals.\n    ",
        "submission_date": "2017-10-16T00:00:00",
        "last_modified_date": "2017-10-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.05693",
        "title": "Mining Frequent Patterns in Process Models",
        "authors": [
            "David Chapela-Campa",
            "Manuel Mucientes",
            "Manuel Lama"
        ],
        "abstract": "Process mining has emerged as a way to analyze the behavior of an organization by extracting knowledge from event logs and by offering techniques to discover, monitor and enhance real processes. In the discovery of process models, retrieving a complex one, i.e., a hardly readable process model, can hinder the extraction of information. Even in well-structured process models, there is information that cannot be obtained with the current techniques. In this paper, we present WoMine, an algorithm to retrieve frequent behavioural patterns from the model. Our approach searches in process models extracting structures with sequences, selections, parallels and loops, which are frequently executed in the logs. This proposal has been validated with a set of process models, including some from BPI Challenges, and compared with the state of the art techniques. Experiments have validated that WoMine can find all types of patterns, extracting information that cannot be mined with the state of the art techniques.\n    ",
        "submission_date": "2017-10-11T00:00:00",
        "last_modified_date": "2017-10-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.05720",
        "title": "ACCBench: A Framework for Comparing Causality Algorithms",
        "authors": [
            "Simon Rehwald",
            "Amjad Ibrahim",
            "Kristian Beckers",
            "Alexander Pretschner"
        ],
        "abstract": "Modern socio-technical systems are increasingly complex. A fundamental problem is that the borders of such systems are often not well-defined a-priori, which among other problems can lead to unwanted behavior during runtime. Ideally, unwanted behavior should be prevented. If this is not possible the system shall at least be able to help determine potential cause(s) a-posterori, identify responsible parties and make them accountable for their behavior. Recently, several algorithms addressing these concepts have been proposed. However, the applicability of the corresponding approaches, specifically their effectiveness and performance, is mostly unknown. Therefore, in this paper, we propose ACCBench, a benchmark tool that allows to compare and evaluate causality algorithms under a consistent setting. Furthermore, we contribute an implementation of the two causality algorithms by G\u00f6\u00dfler and Metayer and G\u00f6\u00dfler and Astefanoaei as well as of a policy compliance approach based on some concepts of Main et al. Lastly, we conduct a case study of an Intelligent Door Control System, which exposes concrete strengths and weaknesses of all algorithms under different aspects. In the course of this, we show that the effectiveness of the algorithms in terms of cause detection as well as their performance differ to some extent. In addition, our analysis reports on some qualitative aspects that should be considered when evaluating each algorithm. For example, the human effort needed to configure the algorithm and model the use case is analyzed.\n    ",
        "submission_date": "2017-10-10T00:00:00",
        "last_modified_date": "2017-10-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.05733",
        "title": "Characterizing Driving Context from Driver Behavior",
        "authors": [
            "Sobhan Moosavi",
            "Behrooz Omidvar-Tehrani",
            "R. Bruce Craig",
            "Arnab Nandi",
            "Rajiv Ramnath"
        ],
        "abstract": "Because of the increasing availability of spatiotemporal data, a variety of data-analytic applications have become possible. Characterizing driving context, where context may be thought of as a combination of location and time, is a new challenging application. An example of such a characterization is finding the correlation between driving behavior and traffic conditions. This contextual information enables analysts to validate observation-based hypotheses about the driving of an individual. In this paper, we present DriveContext, a novel framework to find the characteristics of a context, by extracting significant driving patterns (e.g., a slow-down), and then identifying the set of potential causes behind patterns (e.g., traffic congestion). Our experimental results confirm the feasibility of the framework in identifying meaningful driving patterns, with improvements in comparison with the state-of-the-art. We also demonstrate how the framework derives interesting characteristics for different contexts, through real-world examples.\n    ",
        "submission_date": "2017-10-13T00:00:00",
        "last_modified_date": "2017-11-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.06525",
        "title": "Near-Optimal Adversarial Policy Switching for Decentralized Asynchronous Multi-Agent Systems",
        "authors": [
            "Trong Nghia Hoang",
            "Yuchen Xiao",
            "Kavinayan Sivakumar",
            "Christopher Amato",
            "Jonathan How"
        ],
        "abstract": "A key challenge in multi-robot and multi-agent systems is generating solutions that are robust to other self-interested or even adversarial parties who actively try to prevent the agents from achieving their goals. The practicality of existing works addressing this challenge is limited to only small-scale synchronous decision-making scenarios or a single agent planning its best response against a single adversary with fixed, procedurally characterized strategies. In contrast this paper considers a more realistic class of problems where a team of asynchronous agents with limited observation and communication capabilities need to compete against multiple strategic adversaries with changing strategies. This problem necessitates agents that can coordinate to detect changes in adversary strategies and plan the best response accordingly. Our approach first optimizes a set of stratagems that represent these best responses. These optimized stratagems are then integrated into a unified policy that can detect and respond when the adversaries change their strategies. The near-optimality of the proposed framework is established theoretically as well as demonstrated empirically in simulation and hardware.\n    ",
        "submission_date": "2017-10-17T00:00:00",
        "last_modified_date": "2017-10-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.06574",
        "title": "The Effects of Memory Replay in Reinforcement Learning",
        "authors": [
            "Ruishan Liu",
            "James Zou"
        ],
        "abstract": "Experience replay is a key technique behind many recent advances in deep reinforcement learning. Allowing the agent to learn from earlier memories can speed up learning and break undesirable temporal correlations. Despite its wide-spread application, very little is understood about the properties of experience replay. How does the amount of memory kept affect learning dynamics? Does it help to prioritize certain experiences? In this paper, we address these questions by formulating a dynamical systems ODE model of Q-learning with experience replay. We derive analytic solutions of the ODE for a simple setting. We show that even in this very simple setting, the amount of memory kept can substantially affect the agent's performance. Too much or too little memory both slow down learning. Moreover, we characterize regimes where prioritized replay harms the agent's learning. We show that our analytic solutions have excellent agreement with experiments. Finally, we propose a simple algorithm for adaptively changing the memory buffer size which achieves consistently good empirical performance.\n    ",
        "submission_date": "2017-10-18T00:00:00",
        "last_modified_date": "2017-10-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.06879",
        "title": "Graph Embedding with Rich Information through Heterogeneous Network",
        "authors": [
            "Guolei Sun",
            "Xiangliang Zhang"
        ],
        "abstract": "Graph embedding has attracted increasing attention due to its critical application in social network analysis. Most existing algorithms for graph embedding only rely on the typology information and fail to use the copious information in nodes as well as edges. As a result, their performance for many tasks may not be satisfactory. In this paper, we proposed a novel and general framework of representation learning for graph with rich text information through constructing a bipartite heterogeneous network. Specially, we designed a biased random walk to explore the constructed heterogeneous network with the notion of flexible neighborhood. The efficacy of our method is demonstrated by extensive comparison experiments with several baselines on various datasets. It improves the Micro-F1 and Macro-F1 of node classification by 10% and 7% on Cora dataset.\n    ",
        "submission_date": "2017-10-18T00:00:00",
        "last_modified_date": "2018-01-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.06975",
        "title": "Consequentialist conditional cooperation in social dilemmas with imperfect information",
        "authors": [
            "Alexander Peysakhovich",
            "Adam Lerer"
        ],
        "abstract": "Social dilemmas, where mutual cooperation can lead to high payoffs but participants face incentives to cheat, are ubiquitous in multi-agent interaction. We wish to construct agents that cooperate with pure cooperators, avoid exploitation by pure defectors, and incentivize cooperation from the rest. However, often the actions taken by a partner are (partially) unobserved or the consequences of individual actions are hard to predict. We show that in a large class of games good strategies can be constructed by conditioning one's behavior solely on outcomes (ie. one's past rewards). We call this consequentialist conditional cooperation. We show how to construct such strategies using deep reinforcement learning techniques and demonstrate, both analytically and experimentally, that they are effective in social dilemmas beyond simple matrix games. We also show the limitations of relying purely on consequences and discuss the need for understanding both the consequences of and the intentions behind an action.\n    ",
        "submission_date": "2017-10-19T00:00:00",
        "last_modified_date": "2018-03-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.07031",
        "title": "Protein Folding Optimization using Differential Evolution Extended with Local Search and Component Reinitialization",
        "authors": [
            "Borko Bo\u0161kovi\u0107",
            "Janez Brest"
        ],
        "abstract": "This paper presents a novel Differential Evolution algorithm for protein folding optimization that is applied to a three-dimensional AB off-lattice model. The proposed algorithm includes two new mechanisms. A local search is used to improve convergence speed and to reduce the runtime complexity of the energy calculation. For this purpose, a local movement is introduced within the local search. The designed evolutionary algorithm has fast convergence speed and, therefore, when it is trapped into the local optimum or a relatively good solution is located, it is hard to locate a better similar solution. The similar solution is different from the good solution in only a few components. A component reinitialization method is designed to mitigate this problem. Both the new mechanisms and the proposed algorithm were analyzed on well-known amino acid sequences that are used frequently in the literature. Experimental results show that the employed new mechanisms improve the efficiency of our algorithm and that the proposed algorithm is superior to other state-of-the-art algorithms. It obtained a hit ratio of 100% for sequences up to 18 monomers, within a budget of $10^{11}$ solution evaluations. New best-known solutions were obtained for most of the sequences. The existence of the symmetric best-known solutions is also demonstrated in the paper.\n    ",
        "submission_date": "2017-10-19T00:00:00",
        "last_modified_date": "2018-05-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.07075",
        "title": "Decision Trees for Helpdesk Advisor Graphs",
        "authors": [
            "Spyros Gkezerlis",
            "Dimitris Kalles"
        ],
        "abstract": "We use decision trees to build a helpdesk agent reference network to facilitate the on-the-job advising of junior or less experienced staff on how to better address telecommunication customer fault reports. Such reports generate field measurements and remote measurements which, when coupled with location data and client attributes, and fused with organization-level statistics, can produce models of how support should be provided. Beyond decision support, these models can help identify staff who can act as advisors, based on the quality, consistency and predictability of dealing with complex troubleshooting reports. Advisor staff models are then used to guide less experienced staff in their decision making; thus, we advocate the deployment of a simple mechanism which exploits the availability of staff with a sound track record at the helpdesk to act as dormant tutors.\n    ",
        "submission_date": "2017-10-19T00:00:00",
        "last_modified_date": "2017-10-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.07114",
        "title": "Swift Linked Data Miner: Mining OWL 2 EL class expressions directly from online RDF datasets",
        "authors": [
            "Jedrzej Potoniec",
            "Piotr Jakubowski",
            "Agnieszka \u0141awrynowicz"
        ],
        "abstract": "In this study, we present Swift Linked Data Miner, an interruptible algorithm that can directly mine an online Linked Data source (e.g., a SPARQL endpoint) for OWL 2 EL class expressions to extend an ontology with new SubClassOf: axioms. The algorithm works by downloading only a small part of the Linked Data source at a time, building a smart index in the memory and swiftly iterating over the index to mine axioms. We propose a transformation function from mined axioms to RDF Data Shapes. We show, by means of a crowdsourcing experiment, that most of the axioms mined by Swift Linked Data Miner are correct and can be added to an ontology. We provide a ready to use Prot\u00e9g\u00e9 plugin implementing the algorithm, to support ontology engineers in their daily modeling work.\n    ",
        "submission_date": "2017-10-19T00:00:00",
        "last_modified_date": "2017-10-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.07147",
        "title": "A Two-Phase Safe Vehicle Routing and Scheduling Problem: Formulations and Solution Algorithms",
        "authors": [
            "Aschkan Omidvar",
            "Eren Erman Ozguven",
            "O. Arda Vanli",
            "R. Tavakkoli-Moghaddam"
        ],
        "abstract": "We propose a two phase time dependent vehicle routing and scheduling optimization model that identifies the safest routes, as a substitute for the classical objectives given in the literature such as shortest distance or travel time, through (1) avoiding recurring congestions, and (2) selecting routes that have a lower probability of crash occurrences and non-recurring congestion caused by those crashes. In the first phase, we solve a mixed-integer programming model which takes the dynamic speed variations into account on a graph of roadway networks according to the time of day, and identify the routing of a fleet and sequence of nodes on the safest feasible paths. Second phase considers each route as an independent transit path (fixed route with fixed node sequences), and tries to avoid congestion by rescheduling the departure times of each vehicle from each node, and by adjusting the sub-optimal speed on each arc. A modified simulated annealing (SA) algorithm is formulated to solve both complex models iteratively, which is found to be capable of providing solutions in a considerably short amount of time.\n    ",
        "submission_date": "2017-10-18T00:00:00",
        "last_modified_date": "2017-10-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.07214",
        "title": "On Using Linear Diophantine Equations to Tune the extent of Look Ahead while Hiding Decision Tree Rules",
        "authors": [
            "Georgios Feretzakis",
            "Dimitris Kalles",
            "Vassilios S. Verykios"
        ],
        "abstract": "This paper focuses on preserving the privacy of sensitive pat-terns when inducing decision trees. We adopt a record aug-mentation approach for hiding sensitive classification rules in binary datasets. Such a hiding methodology is preferred over other heuristic solutions like output perturbation or crypto-graphic techniques - which restrict the usability of the data - since the raw data itself is readily available for public use. In this paper, we propose a look ahead approach using linear Diophantine equations in order to add the appropriate number of instances while minimally disturbing the initial entropy of the nodes.\n    ",
        "submission_date": "2017-10-18T00:00:00",
        "last_modified_date": "2017-10-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.07360",
        "title": "Go game formal revealing by Ising model",
        "authors": [
            "Mat\u00edas Alvarado",
            "Arturo Yee",
            "Carlos Villarreal"
        ],
        "abstract": "Go gaming is a struggle for territory control between rival, black and white, stones on a board. We model the Go dynamics in a game by means of the Ising model whose interaction coefficients reflect essential rules and tactics employed in Go to build long-term strategies. At any step of the game, the energy functional of the model provides the control degree (strength) of a player over the board. A close fit between predictions of the model with actual games is obtained.\n    ",
        "submission_date": "2017-10-19T00:00:00",
        "last_modified_date": "2017-10-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.07551",
        "title": "Spoken Language Biomarkers for Detecting Cognitive Impairment",
        "authors": [
            "Tuka Alhanai",
            "Rhoda Au",
            "James Glass"
        ],
        "abstract": "In this study we developed an automated system that evaluates speech and language features from audio recordings of neuropsychological examinations of 92 subjects in the Framingham Heart Study. A total of 265 features were used in an elastic-net regularized binomial logistic regression model to classify the presence of cognitive impairment, and to select the most predictive features. We compared performance with a demographic model from 6,258 subjects in the greater study cohort (0.79 AUC), and found that a system that incorporated both audio and text features performed the best (0.92 AUC), with a True Positive Rate of 29% (at 0% False Positive Rate) and a good model fit (Hosmer-Lemeshow test > 0.05). We also found that decreasing pitch and jitter, shorter segments of speech, and responses phrased as questions were positively associated with cognitive impairment.\n    ",
        "submission_date": "2017-10-20T00:00:00",
        "last_modified_date": "2017-10-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.07709",
        "title": "Solving the \"false positives\" problem in fraud prediction",
        "authors": [
            "Roy Wedge",
            "James Max Kanter",
            "Santiago Moral Rubio",
            "Sergio Iglesias Perez",
            "Kalyan Veeramachaneni"
        ],
        "abstract": "In this paper, we present an automated feature engineering based approach to dramatically reduce false positives in fraud prediction. False positives plague the fraud prediction industry. It is estimated that only 1 in 5 declared as fraud are actually fraud and roughly 1 in every 6 customers have had a valid transaction declined in the past year. To address this problem, we use the Deep Feature Synthesis algorithm to automatically derive behavioral features based on the historical data of the card associated with a transaction. We generate 237 features (>100 behavioral patterns) for each transaction, and use a random forest to learn a classifier. We tested our machine learning model on data from a large multinational bank and compared it to their existing solution. On an unseen data of 1.852 million transactions, we were able to reduce the false positives by 54% and provide a savings of 190K euros. We also assess how to deploy this solution, and whether it necessitates streaming computation for real time scoring. We found that our solution can maintain similar benefits even when historical features are computed once every 7 days.\n    ",
        "submission_date": "2017-10-20T00:00:00",
        "last_modified_date": "2017-10-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.07983",
        "title": "Safety-Aware Apprenticeship Learning",
        "authors": [
            "Weichao Zhou",
            "Wenchao Li"
        ],
        "abstract": "Apprenticeship learning (AL) is a kind of Learning from Demonstration techniques where the reward function of a Markov Decision Process (MDP) is unknown to the learning agent and the agent has to derive a good policy by observing an expert's demonstrations. In this paper, we study the problem of how to make AL algorithms inherently safe while still meeting its learning objective. We consider a setting where the unknown reward function is assumed to be a linear combination of a set of state features, and the safety property is specified in Probabilistic Computation Tree Logic (PCTL). By embedding probabilistic model checking inside AL, we propose a novel counterexample-guided approach that can ensure safety while retaining performance of the learnt policy. We demonstrate the effectiveness of our approach on several challenging AL scenarios where safety is essential.\n    ",
        "submission_date": "2017-10-22T00:00:00",
        "last_modified_date": "2018-04-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.07990",
        "title": "Hierarchical State Abstractions for Decision-Making Problems with Computational Constraints",
        "authors": [
            "Daniel T. Larsson",
            "Daniel Braun",
            "Panagiotis Tsiotras"
        ],
        "abstract": "In this semi-tutorial paper, we first review the information-theoretic approach to account for the computational costs incurred during the search for optimal actions in a sequential decision-making problem. The traditional (MDP) framework ignores computational limitations while searching for optimal policies, essentially assuming that the acting agent is perfectly rational and aims for exact optimality. Using the free-energy, a variational principle is introduced that accounts not only for the value of a policy alone, but also considers the cost of finding this optimal policy. The solution of the variational equations arising from this formulation can be obtained using familiar Bellman-like value iterations from dynamic programming (DP) and the Blahut-Arimoto (BA) algorithm from rate distortion theory. Finally, we demonstrate the utility of the approach for generating hierarchies of state abstractions that can be used to best exploit the available computational resources. A numerical example showcases these concepts for a path-planning problem in a grid world environment.\n    ",
        "submission_date": "2017-10-22T00:00:00",
        "last_modified_date": "2017-10-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.08191",
        "title": "Human-in-the-loop Artificial Intelligence",
        "authors": [
            "Fabio Massimo Zanzotto"
        ],
        "abstract": "Little by little, newspapers are revealing the bright future that Artificial Intelligence (AI) is building. Intelligent machines will help everywhere. However, this bright future has a dark side: a dramatic job market contraction before its unpredictable transformation. Hence, in a near future, large numbers of job seekers will need financial support while catching up with these novel unpredictable jobs. This possible job market crisis has an antidote inside. In fact, the rise of AI is sustained by the biggest knowledge theft of the recent years. Learning AI machines are extracting knowledge from unaware skilled or unskilled workers by analyzing their interactions. By passionately doing their jobs, these workers are digging their own graves.\n",
        "submission_date": "2017-10-23T00:00:00",
        "last_modified_date": "2017-10-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.08986",
        "title": "Multi-Objective Approaches to Markov Decision Processes with Uncertain Transition Parameters",
        "authors": [
            "Dimitri Scheftelowitsch",
            "Peter Buchholz",
            "Vahid Hashemi",
            "Holger Hermanns"
        ],
        "abstract": "Markov decision processes (MDPs) are a popular model for performance analysis and optimization of stochastic systems. The parameters of stochastic behavior of MDPs are estimates from empirical observations of a system; their values are not known precisely. Different types of MDPs with uncertain, imprecise or bounded transition rates or probabilities and rewards exist in the literature.\n",
        "submission_date": "2017-10-20T00:00:00",
        "last_modified_date": "2017-10-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.09102",
        "title": "Sufficient and necessary causation are dual",
        "authors": [
            "Robert K\u00fcnnemann"
        ],
        "abstract": "Causation has been the issue of philosophic debate since Hippocrates. Recent work defines actual causation in terms of Pearl/Halpern's causality framework, formalizing necessary causes (IJCAI'15). This has inspired causality notions in the security domain (CSF'15), which, perhaps surprisingly, formalize sufficient causes instead. We provide an explicit relation between necessary and sufficient causes.\n    ",
        "submission_date": "2017-10-25T00:00:00",
        "last_modified_date": "2017-10-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.09278",
        "title": "Evidence of an exponential speed-up in the solution of hard optimization problems",
        "authors": [
            "Fabio L. Traversa",
            "Pietro Cicotti",
            "Forrest Sheldon",
            "Massimiliano Di Ventra"
        ],
        "abstract": "Optimization problems pervade essentially every scientific discipline and industry. Many such problems require finding a solution that maximizes the number of constraints satisfied. Often, these problems are particularly difficult to solve because they belong to the NP-hard class, namely algorithms that always find a solution in polynomial time are not known. Over the past decades, research has focused on developing heuristic approaches that attempt to find an approximation to the solution. However, despite numerous research efforts, in many cases even approximations to the optimal solution are hard to find, as the computational time for further refining a candidate solution grows exponentially with input size. Here, we show a non-combinatorial approach to hard optimization problems that achieves an exponential speed-up and finds better approximations than the current state-of-the-art. First, we map the optimization problem into a boolean circuit made of specially designed, self-organizing logic gates, which can be built with (non-quantum) electronic components; the equilibrium points of the circuit represent the approximation to the problem at hand. Then, we solve its associated non-linear ordinary differential equations numerically, towards the equilibrium points. We demonstrate this exponential gain by comparing a sequential MatLab implementation of our solver with the winners of the 2016 Max-SAT competition on a variety of hard optimization instances. We show empirical evidence that our solver scales linearly with the size of the problem, both in time and memory, and argue that this property derives from the collective behavior of the simulated physical circuit. Our approach can be applied to other types of optimization problems and the results presented here have far-reaching consequences in many fields.\n    ",
        "submission_date": "2017-10-23T00:00:00",
        "last_modified_date": "2017-10-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.09300",
        "title": "Feature learning in feature-sample networks using multi-objective optimization",
        "authors": [
            "Filipe Alves Neto Verri",
            "Renato Tin\u00f3s",
            "Liang Zhao"
        ],
        "abstract": "Data and knowledge representation are fundamental concepts in machine learning. The quality of the representation impacts the performance of the learning model directly. Feature learning transforms or enhances raw data to structures that are effectively exploited by those models. In recent years, several works have been using complex networks for data representation and analysis. However, no feature learning method has been proposed for such category of techniques. Here, we present an unsupervised feature learning mechanism that works on datasets with binary features. First, the dataset is mapped into a feature--sample network. Then, a multi-objective optimization process selects a set of new vertices to produce an enhanced version of the network. The new features depend on a nonlinear function of a combination of preexisting features. Effectively, the process projects the input data into a higher-dimensional space. To solve the optimization problem, we design two metaheuristics based on the lexicographic genetic algorithm and the improved strength Pareto evolutionary algorithm (SPEA2). We show that the enhanced network contains more information and can be exploited to improve the performance of machine learning methods. The advantages and disadvantages of each optimization strategy are discussed.\n    ",
        "submission_date": "2017-10-25T00:00:00",
        "last_modified_date": "2017-10-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.09627",
        "title": "SRE: Semantic Rules Engine For the Industrial Internet-Of-Things Gateways",
        "authors": [
            "Charbel El Kaed",
            "Imran Khan",
            "Andre Van Den Berg",
            "Hicham Hossayni",
            "Christophe Saint-Marcel"
        ],
        "abstract": "The Advent of the Internet-of-Things (IoT) paradigm has brought opportunities to solve many real-world problems. Energy management, for example, has attracted huge interest from academia, industries, governments and regulatory bodies. It involves collecting energy usage data, analyzing it, and optimizing the energy consumption by applying control strategies. However, in industrial environments, performing such optimization is not trivial. The changes in business rules, process control, and customer requirements make it much more challenging. In this paper, a Semantic Rules Engine (SRE) for industrial gateways is presented that allows implementing dynamic and flexible rule-based control strategies. It is simple, expressive, and allows managing rules on-the-fly without causing any service interruption. Additionally, it can handle semantic queries and provide results by inferring additional knowledge from previously defined concepts in ontologies. SRE has been validated and tested on different hardware platforms and in commercial products. Performance evaluations are also presented to validate its conformance to the customer requirements.\n    ",
        "submission_date": "2017-10-26T00:00:00",
        "last_modified_date": "2017-10-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.09788",
        "title": "FashionBrain Project: A Vision for Understanding Europe's Fashion Data Universe",
        "authors": [
            "Alessandro Checco",
            "Gianluca Demartini",
            "Alexander Loeser",
            "Ines Arous",
            "Mourad Khayati",
            "Matthias Dantone",
            "Richard Koopmanschap",
            "Svetlin Stalinov",
            "Martin Kersten",
            "Ying Zhang"
        ],
        "abstract": "A core business in the fashion industry is the understanding and prediction of customer needs and trends. Search engines and social networks are at the same time a fundamental bridge and a costly middleman between the customer's purchase intention and the retailer. To better exploit Europe's distinctive characteristics e.g., multiple languages, fashion and cultural differences, it is pivotal to reduce retailers' dependence to search engines. This goal can be achieved by harnessing various data channels (manufacturers and distribution networks, online shops, large retailers, social media, market observers, call centers, press/magazines etc.) that retailers can leverage in order to gain more insight about potential buyers, and on the industry trends as a whole. This can enable the creation of novel on-line shopping experiences, the detection of influencers, and the prediction of upcoming fashion trends.\n",
        "submission_date": "2017-10-26T00:00:00",
        "last_modified_date": "2017-10-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.09952",
        "title": "Enhancements of linked data expressiveness for ontologies",
        "authors": [
            "Renato Fabbri"
        ],
        "abstract": "The semantic web has received many contributions of researchers as ontologies which, in this context, i.e. within RDF linked data, are formalized conceptualizations that might use different protocols, such as RDFS, OWL DL and OWL FULL. In this article, we describe new expressive techniques which were found necessary after elaborating dozens of OWL ontologies for the scientific academy, the State and the civil society. They consist in: 1) stating possible uses a property might have without incurring into axioms or restrictions; 2) assigning a level of priority for an element (class, property, triple); 3) correct depiction in diagrams of relations between classes, between individuals which are imperative, and between individuals which are optional; 4) a convenient association between OWL classes and SKOS concepts. We propose specific rules to accomplish these enhancements and exemplify both its use and the difficulties that arise because these techniques are currently not established as standards to the ontology designer.\n    ",
        "submission_date": "2017-10-27T00:00:00",
        "last_modified_date": "2017-10-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.10044",
        "title": "Distributional Reinforcement Learning with Quantile Regression",
        "authors": [
            "Will Dabney",
            "Mark Rowland",
            "Marc G. Bellemare",
            "R\u00e9mi Munos"
        ],
        "abstract": "In reinforcement learning an agent interacts with the environment by taking actions and observing the next state and reward. When sampled probabilistically, these state transitions, rewards, and actions can all induce randomness in the observed long-term return. Traditionally, reinforcement learning algorithms average over this randomness to estimate the value function. In this paper, we build on recent work advocating a distributional approach to reinforcement learning in which the distribution over returns is modeled explicitly instead of only estimating the mean. That is, we examine methods of learning the value distribution instead of the value function. We give results that close a number of gaps between the theoretical and algorithmic results given by Bellemare, Dabney, and Munos (2017). First, we extend existing results to the approximate distribution setting. Second, we present a novel distributional reinforcement learning algorithm consistent with our theoretical formulation. Finally, we evaluate this new algorithm on the Atari 2600 games, observing that it significantly outperforms many of the recent improvements on DQN, including the related distributional algorithm C51.\n    ",
        "submission_date": "2017-10-27T00:00:00",
        "last_modified_date": "2017-10-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.10093",
        "title": "On modeling vagueness and uncertainty in data-to-text systems through fuzzy sets",
        "authors": [
            "A. Ramos-Soto",
            "M. Pereira-Fari\u00f1a"
        ],
        "abstract": "Vagueness and uncertainty management is counted among one of the challenges that remain unresolved in systems that generate texts from non-linguistic data, known as data-to-text systems. In the last decade, work in fuzzy linguistic summarization and description of data has raised the interest of using fuzzy sets to model and manage the imprecision of human language in data-to-text systems. However, despite some research in this direction, there has not been an actual clear discussion and justification on how fuzzy sets can contribute to data-to-text for modeling vagueness and uncertainty in words and expressions. This paper intends to bridge this gap by answering the following questions: What does vagueness mean in fuzzy sets theory? What does vagueness mean in data-to-text contexts? In what ways can fuzzy sets theory contribute to improve data-to-text systems? What are the challenges that researchers from both disciplines need to address for a successful integration of fuzzy sets into data-to-text systems? In what cases should the use of fuzzy sets be avoided in D2T? For this, we review and discuss the state of the art of vagueness modeling in natural language generation and data-to-text, describe potential and actual usages of fuzzy sets in data-to-text contexts, and provide some additional insights about the engineering of data-to-text systems that make use of fuzzy set-based techniques.\n    ",
        "submission_date": "2017-10-27T00:00:00",
        "last_modified_date": "2017-10-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.10098",
        "title": "An efficient SAT formulation for learning multiple criteria non-compensatory sorting rules from examples",
        "authors": [
            "K. Belahc\u00e8ne",
            "C. Labreuche",
            "N. Maudet",
            "V. Mousseau",
            "W. Ouerdane"
        ],
        "abstract": "The literature on Multiple Criteria Decision Analysis (MCDA) proposes several methods in order to sort alternatives evaluated on several attributes into ordered classes. Non Compensatory Sorting models (NCS) assign alternatives to classes based on the way they compare to multicriteria profiles separating the consecutive classes. Previous works have proposed approaches to learn the parameters of a NCS model based on a learning set. Exact approaches based on mixed integer linear programming ensures that the learning set is best restored, but can only handle datasets of limited size. Heuristic approaches can handle large learning sets, but do not provide any guarantee about the inferred model. In this paper, we propose an alternative formulation to learn a NCS model. This formulation, based on a SAT problem, guarantees to find a model fully consistent with the learning set (whenever it exists), and is computationally much more efficient than existing exact MIP approaches.\n    ",
        "submission_date": "2017-10-27T00:00:00",
        "last_modified_date": "2017-10-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.10164",
        "title": "Towards a new paradigm for assistive technology at home: research challenges, design issues and performance assessment",
        "authors": [
            "Luca Buoncompagni",
            "Barbara Bruno",
            "Antonella Giuni",
            "Fulvio Mastrogiovanni",
            "Renato Zaccaria"
        ],
        "abstract": "Providing elderly and people with special needs, including those suffering from physical disabilities and chronic diseases, with the possibility of retaining their independence at best is one of the most important challenges our society is expected to face. Assistance models based on the home care paradigm are being adopted rapidly in almost all industrialized and emerging countries. Such paradigms hypothesize that it is necessary to ensure that the so-called Activities of Daily Living are correctly and regularly performed by the assisted person to increase the perception of an improved quality of life. This chapter describes the computational inference engine at the core of Arianna, a system able to understand whether an assisted person performs a given set of ADL and to motivate him/her in performing them through a speech-mediated motivational dialogue, using a set of nearables to be installed in an apartment, plus a wearable to be worn or fit in garments.\n    ",
        "submission_date": "2017-10-27T00:00:00",
        "last_modified_date": "2017-10-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.10381",
        "title": "Partitioning Relational Matrices of Similarities or Dissimilarities using the Value of Information",
        "authors": [
            "Isaac J. Sledge",
            "Jose C. Principe"
        ],
        "abstract": "In this paper, we provide an approach to clustering relational matrices whose entries correspond to either similarities or dissimilarities between objects. Our approach is based on the value of information, a parameterized, information-theoretic criterion that measures the change in costs associated with changes in information. Optimizing the value of information yields a deterministic annealing style of clustering with many benefits. For instance, investigators avoid needing to a priori specify the number of clusters, as the partitions naturally undergo phase changes, during the annealing process, whereby the number of clusters changes in a data-driven fashion. The global-best partition can also often be identified.\n    ",
        "submission_date": "2017-10-28T00:00:00",
        "last_modified_date": "2017-10-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.10433",
        "title": "An Ontology to support automated negotiation",
        "authors": [
            "Susel Fernandez",
            "Takayuki Ito"
        ],
        "abstract": "In this work we propose an ontology to support automated negotiation in multiagent systems. The ontology can be connected with some domain-specific ontologies to facilitate the negotiation in different domains, such as Intelligent Transportation Systems (ITS), e-commerce, etc. The specific negotiation rules for each type of negotiation strategy can also be defined as part of the ontology, reducing the amount of knowledge hardcoded in the agents and ensuring the interoperability. The expressiveness of the ontology was proved in a multiagent architecture for the automatic traffic light setting application on ITS.\n    ",
        "submission_date": "2017-10-28T00:00:00",
        "last_modified_date": "2017-10-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.10538",
        "title": "Partial Knowledge In Embeddings",
        "authors": [
            "Ramanathan V. Guha"
        ],
        "abstract": "Representing domain knowledge is crucial for any task. There has been a wide range of techniques developed to represent this knowledge, from older logic based approaches to the more recent deep learning based techniques (i.e. embeddings). In this paper, we discuss some of these methods, focusing on the representational expressiveness tradeoffs that are often made. In particular, we focus on the the ability of various techniques to encode `partial knowledge' - a key component of successful knowledge systems. We introduce and describe the concepts of `ensembles of embeddings' and `aggregate embeddings' and demonstrate how they allow for partial knowledge.\n    ",
        "submission_date": "2017-10-28T00:00:00",
        "last_modified_date": "2017-10-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.10675",
        "title": "Discovery Radiomics with CLEAR-DR: Interpretable Computer Aided Diagnosis of Diabetic Retinopathy",
        "authors": [
            "Devinder Kumar",
            "Graham W. Taylor",
            "Alexander Wong"
        ],
        "abstract": "Objective: Radiomics-driven Computer Aided Diagnosis (CAD) has shown considerable promise in recent years as a potential tool for improving clinical decision support in medical oncology, particularly those based around the concept of Discovery Radiomics, where radiomic sequencers are discovered through the analysis of medical imaging data. One of the main limitations with current CAD approaches is that it is very difficult to gain insight or rationale as to how decisions are made, thus limiting their utility to clinicians. Methods: In this study, we propose CLEAR-DR, a novel interpretable CAD system based on the notion of CLass-Enhanced Attentive Response Discovery Radiomics for the purpose of clinical decision support for diabetic retinopathy. Results: In addition to disease grading via the discovered deep radiomic sequencer, the CLEAR-DR system also produces a visual interpretation of the decision-making process to provide better insight and understanding into the decision-making process of the system. Conclusion: We demonstrate the effectiveness and utility of the proposed CLEAR-DR system of enhancing the interpretability of diagnostic grading results for the application of diabetic retinopathy grading. Significance: CLEAR-DR can act as a potential powerful tool to address the uninterpretability issue of current CAD systems, thus improving their utility to clinicians.\n    ",
        "submission_date": "2017-10-29T00:00:00",
        "last_modified_date": "2017-10-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.10776",
        "title": "Transfer Learning to Learn with Multitask Neural Model Search",
        "authors": [
            "Catherine Wong",
            "Andrea Gesmundo"
        ],
        "abstract": "Deep learning models require extensive architecture design exploration and hyperparameter optimization to perform well on a given task. The exploration of the model design space is often made by a human expert, and optimized using a combination of grid search and search heuristics over a large space of possible choices. Neural Architecture Search (NAS) is a Reinforcement Learning approach that has been proposed to automate architecture design. NAS has been successfully applied to generate Neural Networks that rival the best human-designed architectures. However, NAS requires sampling, constructing, and training hundreds to thousands of models to achieve well-performing architectures. This procedure needs to be executed from scratch for each new task. The application of NAS to a wide set of tasks currently lacks a way to transfer generalizable knowledge across tasks. In this paper, we present the Multitask Neural Model Search (MNMS) controller. Our goal is to learn a generalizable framework that can condition model construction on successful model searches for previously seen tasks, thus significantly speeding up the search for new tasks. We demonstrate that MNMS can conduct an automated architecture search for multiple tasks simultaneously while still learning well-performing, specialized models for each task. We then show that pre-trained MNMS controllers can transfer learning to new tasks. By leveraging knowledge from previous searches, we find that pre-trained MNMS models start from a better location in the search space and reduce search time on unseen tasks, while still discovering models that outperform published human-designed models.\n    ",
        "submission_date": "2017-10-30T00:00:00",
        "last_modified_date": "2017-10-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.11054",
        "title": "Semantic Code Repair using Neuro-Symbolic Transformation Networks",
        "authors": [
            "Jacob Devlin",
            "Jonathan Uesato",
            "Rishabh Singh",
            "Pushmeet Kohli"
        ],
        "abstract": "We study the problem of semantic code repair, which can be broadly defined as automatically fixing non-syntactic bugs in source code. The majority of past work in semantic code repair assumed access to unit tests against which candidate repairs could be validated. In contrast, the goal here is to develop a strong statistical model to accurately predict both bug locations and exact fixes without access to information about the intended correct behavior of the program. Achieving such a goal requires a robust contextual repair model, which we train on a large corpus of real-world source code that has been augmented with synthetically injected bugs. Our framework adopts a two-stage approach where first a large set of repair candidates are generated by rule-based processors, and then these candidates are scored by a statistical model using a novel neural network architecture which we refer to as Share, Specialize, and Compete. Specifically, the architecture (1) generates a shared encoding of the source code using an RNN over the abstract syntax tree, (2) scores each candidate repair using specialized network modules, and (3) then normalizes these scores together so they can compete against one another in comparable probability space. We evaluate our model on a real-world test set gathered from GitHub containing four common categories of bugs. Our model is able to predict the exact correct repair 41\\% of the time with a single guess, compared to 13\\% accuracy for an attentional sequence-to-sequence model.\n    ",
        "submission_date": "2017-10-30T00:00:00",
        "last_modified_date": "2017-10-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.11204",
        "title": "Improve SAT-solving with Machine Learning",
        "authors": [
            "Haoze Wu"
        ],
        "abstract": "In this project, we aimed to improve the runtime of Minisat, a Conflict-Driven Clause Learning (CDCL) solver that solves the Propositional Boolean Satisfiability (SAT) problem. We first used a logistic regression model to predict the satisfiability of propositional boolean formulae after fixing the values of a certain fraction of the variables in each formula. We then applied the logistic model and added a preprocessing period to Minisat to determine the preferable initial value (either true or false) of each boolean variable using a Monte-Carlo approach. Concretely, for each Monte-Carlo trial, we fixed the values of a certain ratio of randomly selected variables, and calculated the confidence that the resulting sub-formula is satisfiable with our logistic regression model. The initial value of each variable was set based on the mean confidence scores of the trials that started from the literals of that variable. We were particularly interested in setting the initial values of the backbone variables correctly, which are variables that have the same value in all solutions of a SAT formula. Our Monte-Carlo method was able to set 78% of the backbones correctly. Excluding the preprocessing time, compared with the default setting of Minisat, the runtime of Minisat for satisfiable formulae decreased by 23%. However, our method did not outperform vanilla Minisat in runtime, as the decrease in the conflicts was outweighed by the long runtime of the preprocessing period.\n    ",
        "submission_date": "2017-10-30T00:00:00",
        "last_modified_date": "2017-10-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.11417",
        "title": "TreeQN and ATreeC: Differentiable Tree-Structured Models for Deep Reinforcement Learning",
        "authors": [
            "Gregory Farquhar",
            "Tim Rockt\u00e4schel",
            "Maximilian Igl",
            "Shimon Whiteson"
        ],
        "abstract": "Combining deep model-free reinforcement learning with on-line planning is a promising approach to building on the successes of deep RL. On-line planning with look-ahead trees has proven successful in environments where transition models are known a priori. However, in complex environments where transition models need to be learned from data, the deficiencies of learned models have limited their utility for planning. To address these challenges, we propose TreeQN, a differentiable, recursive, tree-structured model that serves as a drop-in replacement for any value function network in deep RL with discrete actions. TreeQN dynamically constructs a tree by recursively applying a transition model in a learned abstract state space and then aggregating predicted rewards and state-values using a tree backup to estimate Q-values. We also propose ATreeC, an actor-critic variant that augments TreeQN with a softmax layer to form a stochastic policy network. Both approaches are trained end-to-end, such that the learned model is optimised for its actual use in the tree. We show that TreeQN and ATreeC outperform n-step DQN and A2C on a box-pushing task, as well as n-step DQN and value prediction networks (Oh et al. 2017) on multiple Atari games. Furthermore, we present ablation studies that demonstrate the effect of different auxiliary losses on learning transition models.\n    ",
        "submission_date": "2017-10-31T00:00:00",
        "last_modified_date": "2018-03-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.11531",
        "title": "SemTK: An Ontology-first, Open Source Semantic Toolkit for Managing and Querying Knowledge Graphs",
        "authors": [
            "Paul Cuddihy",
            "Justin McHugh",
            "Jenny Weisenberg Williams",
            "Varish Mulwad",
            "Kareem S. Aggour"
        ],
        "abstract": "The relatively recent adoption of Knowledge Graphs as an enabling technology in multiple high-profile artificial intelligence and cognitive applications has led to growing interest in the Semantic Web technology stack. Many semantics-related tools, however, are focused on serving experts with a deep understanding of semantic technologies. For example, triplification of relational data is available but there is no open source tool that allows a user unfamiliar with OWL/RDF to import data into a semantic triple store in an intuitive manner. Further, many tools require users to have a working understanding of SPARQL to query data. Casual users interested in benefiting from the power of Knowledge Graphs have few tools available for exploring, querying, and managing semantic data. We present SemTK, the Semantics Toolkit, a user-friendly suite of tools that allow both expert and non-expert semantics users convenient ingestion of relational data, simplified query generation, and more. The exploration of ontologies and instance data is performed through SPARQLgraph, an intuitive web-based user interface in SemTK understandable and navigable by a lay user. The open source version of SemTK is available at ",
        "submission_date": "2017-10-31T00:00:00",
        "last_modified_date": "2018-06-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.00054",
        "title": "Abnormal Spatial-Temporal Pattern Analysis for Niagara Frontier Border Wait Times",
        "authors": [
            "Zhenhua Zhang",
            "Lei Lin"
        ],
        "abstract": "Border crossing delays cause problems like huge economics loss and heavy environmental pollutions. To understand more about the nature of border crossing delay, this study applies a dictionary-based compression algorithm to process the historical Niagara Frontier border wait times data. It can identify the abnormal spatial-temporal patterns for both passenger vehicles and trucks at three bridges connecting US and Canada. Furthermore, it provides a quantitate anomaly score to rank the wait times patterns across the three bridges for each vehicle type and each direction. By analyzing the top three most abnormal patterns, we find that there are at least two factors contributing the anomaly of the patterns. The weekends and holidays may cause unusual heave congestions at the three bridges at the same time, and the freight transportation demand may be uneven from Canada to the USA at Peace Bridge and Lewiston-Queenston Bridge, which may lead to a high anomaly score. By calculating the frequency of the top 5% abnormal patterns by hour of the day, the results show that for cars from the USA to Canada, the frequency of abnormal waiting time patterns is the highest during noon while for trucks in the same direction, it is the highest during the afternoon peak hours. For Canada to US direction, the frequency of abnormal border wait time patterns for both cars and trucks reaches to the peak during the afternoon. The analysis of abnormal spatial-temporal wait times patterns is promising to improve the border crossing management\n    ",
        "submission_date": "2017-10-31T00:00:00",
        "last_modified_date": "2017-10-31T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.00129",
        "title": "Automata-Guided Hierarchical Reinforcement Learning for Skill Composition",
        "authors": [
            "Xiao Li",
            "Yao Ma",
            "Calin Belta"
        ],
        "abstract": "Skills learned through (deep) reinforcement learning often generalizes poorly across domains and re-training is necessary when presented with a new task. We present a framework that combines techniques in \\textit{formal methods} with \\textit{reinforcement learning} (RL). The methods we provide allows for convenient specification of tasks with logical expressions, learns hierarchical policies (meta-controller and low-level controllers) with well-defined intrinsic rewards, and construct new skills from existing ones with little to no additional exploration. We evaluate the proposed methods in a simple grid world simulation as well as a more complicated kitchen environment in AI2Thor\n    ",
        "submission_date": "2017-10-31T00:00:00",
        "last_modified_date": "2018-05-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.00137",
        "title": "Pomegranate: fast and flexible probabilistic modeling in python",
        "authors": [
            "Jacob Schreiber"
        ],
        "abstract": "We present pomegranate, an open source machine learning package for probabilistic modeling in Python. Probabilistic modeling encompasses a wide range of methods that explicitly describe uncertainty using probability distributions. Three widely used probabilistic models implemented in pomegranate are general mixture models, hidden Markov models, and Bayesian networks. A primary focus of pomegranate is to abstract away the complexities of training models from their definition. This allows users to focus on specifying the correct model for their application instead of being limited by their understanding of the underlying algorithms. An aspect of this focus involves the collection of additive sufficient statistics from data sets as a strategy for training models. This approach trivially enables many useful learning strategies, such as out-of-core learning, minibatch learning, and semi-supervised learning, without requiring the user to consider how to partition data or modify the algorithms to handle these tasks themselves. pomegranate is written in Cython to speed up calculations and releases the global interpreter lock to allow for built-in multithreaded parallelism, making it competitive with---or outperform---other implementations of similar algorithms. This paper presents an overview of the design choices in pomegranate, and how they have enabled complex features to be supported by simple code.\n    ",
        "submission_date": "2017-10-31T00:00:00",
        "last_modified_date": "2018-02-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.00138",
        "title": "Visualizing and Understanding Atari Agents",
        "authors": [
            "Sam Greydanus",
            "Anurag Koul",
            "Jonathan Dodge",
            "Alan Fern"
        ],
        "abstract": "While deep reinforcement learning (deep RL) agents are effective at maximizing rewards, it is often unclear what strategies they use to do so. In this paper, we take a step toward explaining deep RL agents through a case study using Atari 2600 environments. In particular, we focus on using saliency maps to understand how an agent learns and executes a policy. We introduce a method for generating useful saliency maps and use it to show 1) what strong agents attend to, 2) whether agents are making decisions for the right or wrong reasons, and 3) how agents evolve during learning. We also test our method on non-expert human subjects and find that it improves their ability to reason about these agents. Overall, our results show that saliency information can provide significant insight into an RL agent's decisions and learning behavior.\n    ",
        "submission_date": "2017-10-31T00:00:00",
        "last_modified_date": "2018-09-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.00150",
        "title": "Erratum: Link prediction in drug-target interactions network using similarity indices",
        "authors": [
            "Yiding Lu",
            "Yufan Guo",
            "Anna Korhonen"
        ],
        "abstract": "Background: In silico drug-target interaction (DTI) prediction plays an integral role in drug repositioning: the discovery of new uses for existing drugs. One popular method of drug repositioning is network-based DTI prediction, which uses complex network theory to predict DTIs from a drug-target network. Currently, most network-based DTI prediction is based on machine learning methods such as Restricted Boltzmann Machines (RBM) or Support Vector Machines (SVM). These methods require additional information about the characteristics of drugs, targets and DTIs, such as chemical structure, genome sequence, binding types, causes of interactions, etc., and do not perform satisfactorily when such information is unavailable. We propose a new, alternative method for DTI prediction that makes use of only network topology information attempting to solve this problem.\n",
        "submission_date": "2017-11-01T00:00:00",
        "last_modified_date": "2017-11-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.00363",
        "title": "Servant of Many Masters: Shifting priorities in Pareto-optimal sequential decision-making",
        "authors": [
            "Andrew Critch",
            "Stuart Russell"
        ],
        "abstract": "It is often argued that an agent making decisions on behalf of two or more principals who have different utility functions should adopt a {\\em Pareto-optimal} policy, i.e., a policy that cannot be improved upon for one agent without making sacrifices for another. A famous theorem of Harsanyi shows that, when the principals have a common prior on the outcome distributions of all policies, a Pareto-optimal policy for the agent is one that maximizes a fixed, weighted linear combination of the principals' utilities.\n",
        "submission_date": "2017-10-31T00:00:00",
        "last_modified_date": "2017-10-31T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.00399",
        "title": "Counterfactual Explanations without Opening the Black Box: Automated Decisions and the GDPR",
        "authors": [
            "Sandra Wachter",
            "Brent Mittelstadt",
            "Chris Russell"
        ],
        "abstract": "There has been much discussion of the right to explanation in the EU General Data Protection Regulation, and its existence, merits, and disadvantages. Implementing a right to explanation that opens the black box of algorithmic decision-making faces major legal and technical barriers. Explaining the functionality of complex algorithmic decision-making systems and their rationale in specific cases is a technically challenging problem. Some explanations may offer little meaningful information to data subjects, raising questions around their value. Explanations of automated decisions need not hinge on the general public understanding how algorithmic systems function. Even though such interpretability is of great importance and should be pursued, explanations can, in principle, be offered without opening the black box. Looking at explanations as a means to help a data subject act rather than merely understand, one could gauge the scope and content of explanations according to the specific goal or action they are intended to support. From the perspective of individuals affected by automated decision-making, we propose three aims for explanations: (1) to inform and help the individual understand why a particular decision was reached, (2) to provide grounds to contest the decision if the outcome is undesired, and (3) to understand what would need to change in order to receive a desired result in the future, based on the current decision-making model. We assess how each of these goals finds support in the GDPR. We suggest data controllers should offer a particular type of explanation, unconditional counterfactual explanations, to support these three aims. These counterfactual explanations describe the smallest change to the world that can be made to obtain a desirable outcome, or to arrive at the closest possible world, without needing to explain the internal logic of the system.\n    ",
        "submission_date": "2017-11-01T00:00:00",
        "last_modified_date": "2018-03-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.00404",
        "title": "Building Data-driven Models with Microstructural Images: Generalization and Interpretability",
        "authors": [
            "Julia Ling",
            "Maxwell Hutchinson",
            "Erin Antono",
            "Brian DeCost",
            "Elizabeth A. Holm",
            "Bryce Meredig"
        ],
        "abstract": "As data-driven methods rise in popularity in materials science applications, a key question is how these machine learning models can be used to understand microstructure. Given the importance of process-structure-property relations throughout materials science, it seems logical that models that can leverage microstructural data would be more capable of predicting property information. While there have been some recent attempts to use convolutional neural networks to understand microstructural images, these early studies have focused only on which featurizations yield the highest machine learning model accuracy for a single data set. This paper explores the use of convolutional neural networks for classifying microstructure with a more holistic set of objectives in mind: generalization between data sets, number of features required, and interpretability.\n    ",
        "submission_date": "2017-11-01T00:00:00",
        "last_modified_date": "2017-11-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.00455",
        "title": "A Unified View of Piecewise Linear Neural Network Verification",
        "authors": [
            "Rudy Bunel",
            "Ilker Turkaslan",
            "Philip H.S. Torr",
            "Pushmeet Kohli",
            "M. Pawan Kumar"
        ],
        "abstract": "The success of Deep Learning and its potential use in many safety-critical applications has motivated research on formal verification of Neural Network (NN) models. Despite the reputation of learned NN models to behave as black boxes and the theoretical hardness of proving their properties, researchers have been successful in verifying some classes of models by exploiting their piecewise linear structure and taking insights from formal methods such as Satisifiability Modulo Theory. These methods are however still far from scaling to realistic neural networks. To facilitate progress on this crucial area, we make two key contributions. First, we present a unified framework that encompasses previous methods. This analysis results in the identification of new methods that combine the strengths of multiple existing approaches, accomplishing a speedup of two orders of magnitude compared to the previous state of the art. Second, we propose a new data set of benchmarks which includes a collection of previously released testcases. We use the benchmark to provide the first experimental comparison of existing algorithms and identify the factors impacting the hardness of verification problems.\n    ",
        "submission_date": "2017-11-01T00:00:00",
        "last_modified_date": "2018-05-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.00694",
        "title": "Interpretable and Pedagogical Examples",
        "authors": [
            "Smitha Milli",
            "Pieter Abbeel",
            "Igor Mordatch"
        ],
        "abstract": "Teachers intentionally pick the most informative examples to show their students. However, if the teacher and student are neural networks, the examples that the teacher network learns to give, although effective at teaching the student, are typically uninterpretable. We show that training the student and teacher iteratively, rather than jointly, can produce interpretable teaching strategies. We evaluate interpretability by (1) measuring the similarity of the teacher's emergent strategies to intuitive strategies in each domain and (2) conducting human experiments to evaluate how effective the teacher's strategies are at teaching humans. We show that the teacher network learns to select or generate interpretable, pedagogical examples to teach rule-based, probabilistic, boolean, and hierarchical concepts.\n    ",
        "submission_date": "2017-11-02T00:00:00",
        "last_modified_date": "2018-02-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.00698",
        "title": "Adaptive coordination of working-memory and reinforcement learning in non-human primates performing a trial-and-error problem solving task",
        "authors": [
            "Guillaume Viejo",
            "Beno\u00eet Girard",
            "Emmanuel Procyk",
            "Mehdi Khamassi"
        ],
        "abstract": "Accumulating evidence suggest that human behavior in trial-and-error learning tasks based on decisions between discrete actions may involve a combination of reinforcement learning (RL) and working-memory (WM). While the understanding of brain activity at stake in this type of tasks often involve the comparison with non-human primate neurophysiological results, it is not clear whether monkeys use similar combined RL and WM processes to solve these tasks. Here we analyzed the behavior of five monkeys with computational models combining RL and WM. Our model-based analysis approach enables to not only fit trial-by-trial choices but also transient slowdowns in reaction times, indicative of WM use. We found that the behavior of the five monkeys was better explained in terms of a combination of RL and WM despite inter-individual differences. The same coordination dynamics we used in a previous study in humans best explained the behavior of some monkeys while the behavior of others showed the opposite pattern, revealing a possible different dynamics of WM process. We further analyzed different variants of the tested models to open a discussion on how the long pretraining in these tasks may have favored particular coordination dynamics between RL and WM. This points towards either inter-species differences or protocol differences which could be further tested in humans.\n    ",
        "submission_date": "2017-11-02T00:00:00",
        "last_modified_date": "2017-11-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.00832",
        "title": "A Unified Game-Theoretic Approach to Multiagent Reinforcement Learning",
        "authors": [
            "Marc Lanctot",
            "Vinicius Zambaldi",
            "Audrunas Gruslys",
            "Angeliki Lazaridou",
            "Karl Tuyls",
            "Julien Perolat",
            "David Silver",
            "Thore Graepel"
        ],
        "abstract": "To achieve general intelligence, agents must learn how to interact with others in a shared environment: this is the challenge of multiagent reinforcement learning (MARL). The simplest form is independent reinforcement learning (InRL), where each agent treats its experience as part of its (non-stationary) environment. In this paper, we first observe that policies learned using InRL can overfit to the other agents' policies during training, failing to sufficiently generalize during execution. We introduce a new metric, joint-policy correlation, to quantify this effect. We describe an algorithm for general MARL, based on approximate best responses to mixtures of policies generated using deep reinforcement learning, and empirical game-theoretic analysis to compute meta-strategies for policy selection. The algorithm generalizes previous ones such as InRL, iterated best response, double oracle, and fictitious play. Then, we present a scalable implementation which reduces the memory requirement using decoupled meta-solvers. Finally, we demonstrate the generality of the resulting policies in two partially observable settings: gridworld coordination games and poker.\n    ",
        "submission_date": "2017-11-02T00:00:00",
        "last_modified_date": "2017-11-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.00909",
        "title": "Weight-Based Variable Ordering in the Context of High-Level Consistencies",
        "authors": [
            "Robert J. Woodward",
            "Berthe Y. Choueiry"
        ],
        "abstract": "Dom/wdeg is one of the best performing heuristics for dynamic variable ordering in backtrack search [Boussemart et al., 2004]. As originally defined, this heuristic increments the weight of the constraint that causes a domain wipeout (i.e., a dead-end) when enforcing arc consistency during search. \"The process of weighting constraints with dom/wdeg is not defined when more than one constraint lead to a domain wipeout [Vion et al., 2011].\" In this paper, we investigate how weights should be updated in the context of two high-level consistencies, namely, singleton (POAC) and relational consistencies (RNIC). We propose, analyze, and empirically evaluate several strategies for updating the weights. We statistically compare the proposed strategies and conclude with our recommendations.\n    ",
        "submission_date": "2017-11-02T00:00:00",
        "last_modified_date": "2017-11-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.01134",
        "title": "Accountability of AI Under the Law: The Role of Explanation",
        "authors": [
            "Finale Doshi-Velez",
            "Mason Kortz",
            "Ryan Budish",
            "Chris Bavitz",
            "Sam Gershman",
            "David O'Brien",
            "Kate Scott",
            "Stuart Schieber",
            "James Waldo",
            "David Weinberger",
            "Adrian Weller",
            "Alexandra Wood"
        ],
        "abstract": "The ubiquity of systems using artificial intelligence or \"AI\" has brought increasing attention to how those systems should be regulated. The choice of how to regulate AI systems will require care. AI systems have the potential to synthesize large amounts of data, allowing for greater levels of personalization and precision than ever before---applications range from clinical decision support to autonomous driving and predictive policing. That said, there exist legitimate concerns about the intentional and unintentional negative consequences of AI systems. There are many ways to hold AI systems accountable. In this work, we focus on one: explanation. Questions about a legal right to explanation from AI systems was recently debated in the EU General Data Protection Regulation, and thus thinking carefully about when and how explanation from AI systems might improve accountability is timely. In this work, we review contexts in which explanation is currently required under the law, and then list the technical considerations that must be considered if we desired AI systems that could provide kinds of explanations that are currently required of humans.\n    ",
        "submission_date": "2017-11-03T00:00:00",
        "last_modified_date": "2019-12-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.01391",
        "title": "Guiding the search in continuous state-action spaces by learning an action sampling distribution from off-target samples",
        "authors": [
            "Beomjoon Kim",
            "Leslie Pack Kaelbling",
            "Tomas Lozano-Perez"
        ],
        "abstract": "In robotics, it is essential to be able to plan efficiently in high-dimensional continuous state-action spaces for long horizons. For such complex planning problems, unguided uniform sampling of actions until a path to a goal is found is hopelessly inefficient, and gradient-based approaches often fall short when the optimization manifold of a given problem is not smooth. In this paper we present an approach that guides the search of a state-space planner, such as A*, by learning an action-sampling distribution that can generalize across different instances of a planning problem. The motivation is that, unlike typical learning approaches for planning for continuous action space that estimate a policy, an estimated action sampler is more robust to error since it has a planner to fall back on. We use a Generative Adversarial Network (GAN), and address an important issue: search experience consists of a relatively large number of actions that are not on a solution path and a relatively small number of actions that actually are on a solution path. We introduce a new technique, based on an importance-ratio estimation method, for using samples from a non-target distribution to make GAN learning more data-efficient. We provide theoretical guarantees and empirical evaluation in three challenging continuous robot planning problems to illustrate the effectiveness of our algorithm.\n    ",
        "submission_date": "2017-11-04T00:00:00",
        "last_modified_date": "2017-11-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.01431",
        "title": "The Case for Meta-Cognitive Machine Learning: On Model Entropy and Concept Formation in Deep Learning",
        "authors": [
            "Johan Loeckx"
        ],
        "abstract": "Machine learning is usually defined in behaviourist terms, where external validation is the primary mechanism of learning. In this paper, I argue for a more holistic interpretation in which finding more probable, efficient and abstract representations is as central to learning as performance. In other words, machine learning should be extended with strategies to reason over its own learning process, leading to so-called meta-cognitive machine learning. As such, the de facto definition of machine learning should be reformulated in these intrinsically multi-objective terms, taking into account not only the task performance but also internal learning objectives. To this end, we suggest a \"model entropy function\" to be defined that quantifies the efficiency of the internal learning processes. It is conjured that the minimization of this model entropy leads to concept formation. Besides philosophical aspects, some initial illustrations are included to support the claims.\n    ",
        "submission_date": "2017-11-04T00:00:00",
        "last_modified_date": "2017-11-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.01503",
        "title": "Composing Meta-Policies for Autonomous Driving Using Hierarchical Deep Reinforcement Learning",
        "authors": [
            "Richard Liaw",
            "Sanjay Krishnan",
            "Animesh Garg",
            "Daniel Crankshaw",
            "Joseph E. Gonzalez",
            "Ken Goldberg"
        ],
        "abstract": "Rather than learning new control policies for each new task, it is possible, when tasks share some structure, to compose a \"meta-policy\" from previously learned policies. This paper reports results from experiments using Deep Reinforcement Learning on a continuous-state, discrete-action autonomous driving simulator. We explore how Deep Neural Networks can represent meta-policies that switch among a set of previously learned policies, specifically in settings where the dynamics of a new scenario are composed of a mixture of previously learned dynamics and where the state observation is possibly corrupted by sensing noise. We also report the results of experiments varying dynamics mixes, distractor policies, magnitudes/distributions of sensing noise, and obstacles. In a fully observed experiment, the meta-policy learning algorithm achieves 2.6x the reward achieved by the next best policy composition technique with 80% less exploration. In a partially observed experiment, the meta-policy learning algorithm converges after 50 iterations while a direct application of RL fails to converge even after 200 iterations.\n    ",
        "submission_date": "2017-11-04T00:00:00",
        "last_modified_date": "2017-11-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.01518",
        "title": "Semantic Web Today: From Oil Rigs to Panama Papers",
        "authors": [
            "Rivindu Perera",
            "Parma Nand",
            "Boris Bacic",
            "Wen-Hsin Yang",
            "Kazuhiro Seki",
            "Radek Burget"
        ],
        "abstract": "The next leap on the internet has already started as Semantic Web. At its core, Semantic Web transforms the document oriented web to a data oriented web enriched with semantics embedded as metadata. This change in perspective towards the web offers numerous benefits for vast amount of data intensive industries that are bound to the web and its related applications. The industries are diverse as they range from Oil & Gas exploration to the investigative journalism, and everything in between. This paper discusses eight different industries which currently reap the benefits of Semantic Web. The paper also offers a future outlook into Semantic Web applications and discusses the areas in which Semantic Web would play a key role in the future.\n    ",
        "submission_date": "2017-11-05T00:00:00",
        "last_modified_date": "2017-11-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.01569",
        "title": "Double Q($\u03c3$) and Q($\u03c3, \u03bb$): Unifying Reinforcement Learning Control Algorithms",
        "authors": [
            "Markus Dumke"
        ],
        "abstract": "Temporal-difference (TD) learning is an important field in reinforcement learning. Sarsa and Q-Learning are among the most used TD algorithms. The Q($\\sigma$) algorithm (Sutton and Barto (2017)) unifies both. This paper extends the Q($\\sigma$) algorithm to an online multi-step algorithm Q($\\sigma, \\lambda$) using eligibility traces and introduces Double Q($\\sigma$) as the extension of Q($\\sigma$) to double learning. Experiments suggest that the new Q($\\sigma, \\lambda$) algorithm can outperform the classical TD control methods Sarsa($\\lambda$), Q($\\lambda$) and Q($\\sigma$).\n    ",
        "submission_date": "2017-11-05T00:00:00",
        "last_modified_date": "2017-11-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.01703",
        "title": "RoboCupSimData: A RoboCup soccer research dataset",
        "authors": [
            "Olivia Michael",
            "Oliver Obst",
            "Falk Schmidsberger",
            "Frieder Stolzenburg"
        ],
        "abstract": "RoboCup is an international scientific robot competition in which teams of multiple robots compete against each other. Its different leagues provide many sources of robotics data, that can be used for further analysis and application of machine learning. This paper describes a large dataset from games of some of the top teams (from 2016 and 2017) in RoboCup Soccer Simulation League (2D), where teams of 11 robots (agents) compete against each other. Overall, we used 10 different teams to play each other, resulting in 45 unique pairings. For each pairing, we ran 25 matches (of 10mins), leading to 1125 matches or more than 180 hours of game play. The generated CSV files are 17GB of data (zipped), or 229GB (unzipped). The dataset is unique in the sense that it contains both the ground truth data (global, complete, noise-free information of all objects on the field), as well as the noisy, local and incomplete percepts of each robot. These data are made available as CSV files, as well as in the original soccer simulator formats.\n    ",
        "submission_date": "2017-11-06T00:00:00",
        "last_modified_date": "2017-11-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.01754",
        "title": "Learning Solving Procedure for Artificial Neural Network",
        "authors": [
            "Ju-Hong Lee",
            "Moon-Ju Kang",
            "Bumghi Choi"
        ],
        "abstract": "It is expected that progress toward true artificial intelligence will be achieved through the emergence of a system that integrates representation learning and complex reasoning (LeCun et al. 2015). In response to this prediction, research has been conducted on implementing the symbolic reasoning of a von Neumann computer in an artificial neural network (Graves et al. 2016; Graves et al. 2014; Reed et al. 2015). However, these studies have many limitations in realizing neural-symbolic integration (Jaeger. 2016). Here, we present a new learning paradigm: a learning solving procedure (LSP) that learns the procedure for solving complex problems. This is not accomplished merely by learning input-output data, but by learning algorithms through a solving procedure that obtains the output as a sequence of tasks for a given input problem. The LSP neural network system not only learns simple problems of addition and multiplication, but also the algorithms of complicated problems, such as complex arithmetic expression, sorting, and Hanoi Tower. To realize this, the LSP neural network structure consists of a deep neural network and long short-term memory, which are recursively combined. Through experimentation, we demonstrate the efficiency and scalability of LSP and its validity as a mechanism of complex reasoning.\n    ",
        "submission_date": "2017-11-06T00:00:00",
        "last_modified_date": "2017-11-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.01927",
        "title": "A Foundry of Human Activities and Infrastructures",
        "authors": [
            "Robert B. Allen",
            "Eunsang Yang",
            "Tatsawan Timakum"
        ],
        "abstract": "Direct representation knowledgebases can enhance and even provide an alternative to document-centered digital libraries. Here we consider realist semantic modeling of everyday activities and infrastructures in such knowledgebases. Because we want to integrate a wide variety of topics, a collection of ontologies (a foundry) and a range of other knowledge resources are needed. We first consider modeling the routine procedures that support human activities and technologies. Next, we examine the interactions of technologies with aspects of social organization. Then, we consider approaches and issues for developing and validating explanations of the relationships among various entities.\n    ",
        "submission_date": "2017-10-31T00:00:00",
        "last_modified_date": "2017-10-31T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.02132",
        "title": "Weighted Transformer Network for Machine Translation",
        "authors": [
            "Karim Ahmed",
            "Nitish Shirish Keskar",
            "Richard Socher"
        ],
        "abstract": "State-of-the-art results on neural machine translation often use attentional sequence-to-sequence models with some form of convolution or recursion. Vaswani et al. (2017) propose a new architecture that avoids recurrence and convolution completely. Instead, it uses only self-attention and feed-forward layers. While the proposed architecture achieves state-of-the-art results on several machine translation tasks, it requires a large number of parameters and training iterations to converge. We propose Weighted Transformer, a Transformer with modified attention layers, that not only outperforms the baseline network in BLEU score but also converges 15-40% faster. Specifically, we replace the multi-head attention by multiple self-attention branches that the model learns to combine during the training process. Our model improves the state-of-the-art performance by 0.5 BLEU points on the WMT 2014 English-to-German translation task and by 0.4 on the English-to-French translation task.\n    ",
        "submission_date": "2017-11-06T00:00:00",
        "last_modified_date": "2017-11-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.02301",
        "title": "Can Deep Reinforcement Learning Solve Erdos-Selfridge-Spencer Games?",
        "authors": [
            "Maithra Raghu",
            "Alex Irpan",
            "Jacob Andreas",
            "Robert Kleinberg",
            "Quoc V. Le",
            "Jon Kleinberg"
        ],
        "abstract": "Deep reinforcement learning has achieved many recent successes, but our understanding of its strengths and limitations is hampered by the lack of rich environments in which we can fully characterize optimal behavior, and correspondingly diagnose individual actions against such a characterization. Here we consider a family of combinatorial games, arising from work of Erdos, Selfridge, and Spencer, and we propose their use as environments for evaluating and comparing different approaches to reinforcement learning. These games have a number of appealing features: they are challenging for current learning approaches, but they form (i) a low-dimensional, simply parametrized environment where (ii) there is a linear closed form solution for optimal behavior from any state, and (iii) the difficulty of the game can be tuned by changing environment parameters in an interpretable way. We use these Erdos-Selfridge-Spencer games not only to compare different algorithms, but test for generalization, make comparisons to supervised learning, analyse multiagent play, and even develop a self play algorithm. Code can be found at: ",
        "submission_date": "2017-11-07T00:00:00",
        "last_modified_date": "2018-06-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.02326",
        "title": "Sparse Attentive Backtracking: Long-Range Credit Assignment in Recurrent Networks",
        "authors": [
            "Nan Rosemary Ke",
            "Anirudh Goyal",
            "Olexa Bilaniuk",
            "Jonathan Binas",
            "Laurent Charlin",
            "Chris Pal",
            "Yoshua Bengio"
        ],
        "abstract": "A major drawback of backpropagation through time (BPTT) is the difficulty of learning long-term dependencies, coming from having to propagate credit information backwards through every single step of the forward computation. This makes BPTT both computationally impractical and biologically implausible. For this reason, full backpropagation through time is rarely used on long sequences, and truncated backpropagation through time is used as a heuristic. However, this usually leads to biased estimates of the gradient in which longer term dependencies are ignored. Addressing this issue, we propose an alternative algorithm, Sparse Attentive Backtracking, which might also be related to principles used by brains to learn long-term dependencies. Sparse Attentive Backtracking learns an attention mechanism over the hidden states of the past and selectively backpropagates through paths with high attention weights. This allows the model to learn long term dependencies while only backtracking for a small number of time steps, not just from the recent past but also from attended relevant past states.\n    ",
        "submission_date": "2017-11-07T00:00:00",
        "last_modified_date": "2017-11-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.02368",
        "title": "Distributed Bayesian Piecewise Sparse Linear Models",
        "authors": [
            "Masato Asahara",
            "Ryohei Fujimaki"
        ],
        "abstract": "The importance of interpretability of machine learning models has been increasing due to emerging enterprise predictive analytics, threat of data privacy, accountability of artificial intelligence in society, and so on. Piecewise linear models have been actively studied to achieve both accuracy and interpretability. They often produce competitive accuracy against state-of-the-art non-linear methods. In addition, their representations (i.e., rule-based segmentation plus sparse linear formula) are often preferred by domain experts. A disadvantage of such models, however, is high computational cost for simultaneous determinations of the number of \"pieces\" and cardinality of each linear predictor, which has restricted their applicability to middle-scale data sets. This paper proposes a distributed factorized asymptotic Bayesian (FAB) inference of learning piece-wise sparse linear models on distributed memory architectures. The distributed FAB inference solves the simultaneous model selection issue without communicating $O(N)$ data where N is the number of training samples and achieves linear scale-out against the number of CPU cores. Experimental results demonstrate that the distributed FAB inference achieves high prediction accuracy and performance scalability with both synthetic and benchmark data.\n    ",
        "submission_date": "2017-11-07T00:00:00",
        "last_modified_date": "2017-11-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.02807",
        "title": "Faster Fuzzing: Reinitialization with Deep Neural Models",
        "authors": [
            "Nicole Nichols",
            "Mark Raugas",
            "Robert Jasper",
            "Nathan Hilliard"
        ],
        "abstract": "We improve the performance of the American Fuzzy Lop (AFL) fuzz testing framework by using Generative Adversarial Network (GAN) models to reinitialize the system with novel seed files. We assess performance based on the temporal rate at which we produce novel and unseen code paths. We compare this approach to seed file generation from a random draw of bytes observed in the training seed files. The code path lengths and variations were not sufficiently diverse to fully replace AFL input generation. However, augmenting native AFL with these additional code paths demonstrated improvements over AFL alone. Specifically, experiments showed the GAN was faster and more effective than the LSTM and out-performed a random augmentation strategy, as measured by the number of unique code paths discovered. GAN helps AFL discover 14.23% more code paths than the random strategy in the same amount of CPU time, finds 6.16% more unique code paths, and finds paths that are on average 13.84% longer. Using GAN shows promise as a reinitialization strategy for AFL to help the fuzzer exercise deep paths in software.\n    ",
        "submission_date": "2017-11-08T00:00:00",
        "last_modified_date": "2017-11-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.02827",
        "title": "Inverse Reward Design",
        "authors": [
            "Dylan Hadfield-Menell",
            "Smitha Milli",
            "Pieter Abbeel",
            "Stuart Russell",
            "Anca Dragan"
        ],
        "abstract": "Autonomous agents optimize the reward function we give them. What they don't know is how hard it is for us to design a reward function that actually captures what we want. When designing the reward, we might think of some specific training scenarios, and make sure that the reward will lead to the right behavior in those scenarios. Inevitably, agents encounter new scenarios (e.g., new types of terrain) where optimizing that same reward may lead to undesired behavior. Our insight is that reward functions are merely observations about what the designer actually wants, and that they should be interpreted in the context in which they were designed. We introduce inverse reward design (IRD) as the problem of inferring the true objective based on the designed reward and the training MDP. We introduce approximate methods for solving IRD problems, and use their solution to plan risk-averse behavior in test MDPs. Empirical results suggest that this approach can help alleviate negative side effects of misspecified reward functions and mitigate reward hacking.\n    ",
        "submission_date": "2017-11-08T00:00:00",
        "last_modified_date": "2020-10-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.03087",
        "title": "Exploration in NetHack With Secret Discovery",
        "authors": [
            "Jonathan C. Campbell",
            "Clark Verbrugge"
        ],
        "abstract": "Roguelike games generally feature exploration problems as a critical, yet often repetitive element of gameplay. Automated approaches, however, face challenges in terms of optimality, as well as due to incomplete information, such as from the presence of secret doors. This paper presents an algorithmic approach to exploration of roguelike dungeon environments. Our design aims to minimize exploration time, balancing coverage and discovery of secret areas with resource cost. Our algorithm is based on the concept of occupancy maps popular in robotics, adapted to encourage efficient discovery of secret access points. Through extensive experimentation on NetHack maps we show that this technique is significantly more efficient than simpler greedy approaches and an existing automated player. We further investigate optimized parameterization for the algorithm through a comprehensive data analysis. These results point towards better automation for players as well as heuristics applicable to fully automated gameplay.\n    ",
        "submission_date": "2017-11-08T00:00:00",
        "last_modified_date": "2018-08-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.03147",
        "title": "On the incorporation of interval-valued fuzzy sets into the Bousi-Prolog system: declarative semantics, implementation and applications",
        "authors": [
            "Clemente Rubio-Manzano",
            "Martin Pereira-Fari\u00f1a"
        ],
        "abstract": "In this paper we analyse the benefits of incorporating interval-valued fuzzy sets into the Bousi-Prolog system. A syntax, declarative semantics and im- plementation for this extension is presented and formalised. We show, by using potential applications, that fuzzy logic programming frameworks enhanced with them can correctly work together with lexical resources and ontologies in order to improve their capabilities for knowledge representation and reasoning.\n    ",
        "submission_date": "2017-11-08T00:00:00",
        "last_modified_date": "2017-11-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.03237",
        "title": "CogSciK: Clustering for Cognitive Science Motivated Decision Making",
        "authors": [
            "Dr. W. A. Rivera",
            "James C. Wu"
        ],
        "abstract": "Computational models of decisionmaking must contend with the variance of context and any number of possible decisions that a defined strategic actor can make at a given time. Relying on cognitive science theory, the authors have created an algorithm that captures the orientation of the actor towards an object and arrays the possible decisions available to that actor based on their given intersubjective orientation. This algorithm, like a traditional K-means clustering algorithm, relies on a core-periphery structure that gives the likelihood of moves as those closest to the cluster's centroid. The result is an algorithm that enables unsupervised classification of an array of decision points belonging to an actor's present state and deeply rooted in cognitive science theory.\n    ",
        "submission_date": "2017-11-09T00:00:00",
        "last_modified_date": "2017-11-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.03243",
        "title": "Selecting Representative Examples for Program Synthesis",
        "authors": [
            "Yewen Pu",
            "Zachery Miranda",
            "Armando Solar-Lezama",
            "Leslie Pack Kaelbling"
        ],
        "abstract": "Program synthesis is a class of regression problems where one seeks a solution, in the form of a source-code program, mapping the inputs to their corresponding outputs exactly. Due to its precise and combinatorial nature, program synthesis is commonly formulated as a constraint satisfaction problem, where input-output examples are encoded as constraints and solved with a constraint solver. A key challenge of this formulation is scalability: while constraint solvers work well with a few well-chosen examples, a large set of examples can incur significant overhead in both time and memory. We describe a method to discover a subset of examples that is both small and representative: the subset is constructed iteratively, using a neural network to predict the probability of unchosen examples conditioned on the chosen examples in the subset, and greedily adding the least probable example. We empirically evaluate the representativeness of the subsets constructed by our method, and demonstrate such subsets can significantly improve synthesis time and stability.\n    ",
        "submission_date": "2017-11-09T00:00:00",
        "last_modified_date": "2018-06-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.03430",
        "title": "Repairing Ontologies via Axiom Weakening",
        "authors": [
            "Nicolas Troquard",
            "Roberto Confalonieri",
            "Pietro Galliani",
            "Rafael Penaloza",
            "Daniele Porello",
            "Oliver Kutz"
        ],
        "abstract": "Ontology engineering is a hard and error-prone task, in which small changes may lead to errors, or even produce an inconsistent ontology. As ontologies grow in size, the need for automated methods for repairing inconsistencies while preserving as much of the original knowledge as possible increases. Most previous approaches to this task are based on removing a few axioms from the ontology to regain consistency. We propose a new method based on weakening these axioms to make them less restrictive, employing the use of refinement operators. We introduce the theoretical framework for weakening DL ontologies, propose algorithms to repair ontologies based on the framework, and provide an analysis of the computational complexity. Through an empirical analysis made over real-life ontologies, we show that our approach preserves significantly more of the original knowledge of the ontology than removing axioms.\n    ",
        "submission_date": "2017-11-09T00:00:00",
        "last_modified_date": "2017-11-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.03438",
        "title": "Open-World Knowledge Graph Completion",
        "authors": [
            "Baoxu Shi",
            "Tim Weninger"
        ],
        "abstract": "Knowledge Graphs (KGs) have been applied to many tasks including Web search, link prediction, recommendation, natural language processing, and entity linking. However, most KGs are far from complete and are growing at a rapid pace. To address these problems, Knowledge Graph Completion (KGC) has been proposed to improve KGs by filling in its missing connections. Unlike existing methods which hold a closed-world assumption, i.e., where KGs are fixed and new entities cannot be easily added, in the present work we relax this assumption and propose a new open-world KGC task. As a first attempt to solve this task we introduce an open-world KGC model called ConMask. This model learns embeddings of the entity's name and parts of its text-description to connect unseen entities to the KG. To mitigate the presence of noisy text descriptions, ConMask uses a relationship-dependent content masking to extract relevant snippets and then trains a fully convolutional neural network to fuse the extracted snippets with entities in the KG. Experiments on large data sets, both old and new, show that ConMask performs well in the open-world KGC task and even outperforms existing KGC models on the standard closed-world KGC task.\n    ",
        "submission_date": "2017-11-09T00:00:00",
        "last_modified_date": "2017-11-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.03580",
        "title": "First Results from Using Game Refinement Measure and Learning Coefficient in Scrabble",
        "authors": [
            "Kananat Suwanviwatana",
            "Hiroyuki Iida"
        ],
        "abstract": "This paper explores the entertainment experience and learning experience in Scrabble. It proposes a new measure from the educational point of view, which we call learning coefficient, based on the balance between the learner's skill and the challenge in Scrabble. Scrabble variants, generated using different size of board and dictionary, are analyzed with two measures of game refinement and learning coefficient. The results show that 13x13 Scrabble yields the best entertainment experience and 15x15 (standard) Scrabble with 4% of original dictionary size yields the most effective environment for language learners. Moreover, 15x15 Scrabble with 10% of original dictionary size has a good balance between entertainment and learning experience.\n    ",
        "submission_date": "2017-11-07T00:00:00",
        "last_modified_date": "2017-11-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.03676",
        "title": "Communicative Capital for Prosthetic Agents",
        "authors": [
            "Patrick M. Pilarski",
            "Richard S. Sutton",
            "Kory W. Mathewson",
            "Craig Sherstan",
            "Adam S. R. Parker",
            "Ann L. Edwards"
        ],
        "abstract": "This work presents an overarching perspective on the role that machine intelligence can play in enhancing human abilities, especially those that have been diminished due to injury or illness. As a primary contribution, we develop the hypothesis that assistive devices, and specifically artificial arms and hands, can and should be viewed as agents in order for us to most effectively improve their collaboration with their human users. We believe that increased agency will enable more powerful interactions between human users and next generation prosthetic devices, especially when the sensorimotor space of the prosthetic technology greatly exceeds the conventional control and communication channels available to a prosthetic user. To more concretely examine an agency-based view on prosthetic devices, we propose a new schema for interpreting the capacity of a human-machine collaboration as a function of both the human's and machine's degrees of agency. We then introduce the idea of communicative capital as a way of thinking about the communication resources developed by a human and a machine during their ongoing interaction. Using this schema of agency and capacity, we examine the benefits and disadvantages of increasing the agency of a prosthetic limb. To do so, we present an analysis of examples from the literature where building communicative capital has enabled a progression of fruitful, task-directed interactions between prostheses and their human users. We then describe further work that is needed to concretely evaluate the hypothesis that prostheses are best thought of as agents. The agent-based viewpoint developed in this article significantly extends current thinking on how best to support the natural, functional use of increasingly complex prosthetic enhancements, and opens the door for more powerful interactions between humans and their assistive technologies.\n    ",
        "submission_date": "2017-11-10T00:00:00",
        "last_modified_date": "2017-11-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.03752",
        "title": "Lattice embeddings between types of fuzzy sets. Closed-valued fuzzy sets",
        "authors": [
            "F. J. Lobillo",
            "Luis Merino",
            "Gabriel Navarro",
            "Evangelina Santos"
        ],
        "abstract": "In this paper we deal with the problem of extending Zadeh's operators on fuzzy sets (FSs) to interval-valued (IVFSs), set-valued (SVFSs) and type-2 (T2FSs) fuzzy sets. Namely, it is known that seeing FSs as SVFSs, or T2FSs, whose membership degrees are singletons is not order-preserving. We then describe a family of lattice embeddings from FSs to SVFSs. Alternatively, if the former singleton viewpoint is required, we reformulate the intersection on hesitant fuzzy sets and introduce what we have called closed-valued fuzzy sets. This new type of fuzzy sets extends standard union and intersection on FSs. In addition, it allows handling together membership degrees of different nature as, for instance, closed intervals and finite sets. Finally, all these constructions are viewed as T2FSs forming a chain of lattices.\n    ",
        "submission_date": "2017-11-10T00:00:00",
        "last_modified_date": "2017-11-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.03817",
        "title": "Learning with Options that Terminate Off-Policy",
        "authors": [
            "Anna Harutyunyan",
            "Peter Vrancx",
            "Pierre-Luc Bacon",
            "Doina Precup",
            "Ann Nowe"
        ],
        "abstract": "A temporally abstract action, or an option, is specified by a policy and a termination condition: the policy guides option behavior, and the termination condition roughly determines its length. Generally, learning with longer options (like learning with multi-step returns) is known to be more efficient. However, if the option set for the task is not ideal, and cannot express the primitive optimal policy exactly, shorter options offer more flexibility and can yield a better solution. Thus, the termination condition puts learning efficiency at odds with solution quality. We propose to resolve this dilemma by decoupling the behavior and target terminations, just like it is done with policies in off-policy learning. To this end, we give a new algorithm, Q(\\beta), that learns the solution with respect to any termination condition, regardless of how the options actually terminate. We derive Q(\\beta) by casting learning with options into a common framework with well-studied multi-step off-policy learning. We validate our algorithm empirically, and show that it holds up to its motivating claims.\n    ",
        "submission_date": "2017-11-10T00:00:00",
        "last_modified_date": "2017-12-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.03892",
        "title": "Arrhythmia Classification from the Abductive Interpretation of Short Single-Lead ECG Records",
        "authors": [
            "Tom\u00e1s Teijeiro",
            "Constantino A. Garc\u00eda",
            "Daniel Castro",
            "Paulo F\u00e9lix"
        ],
        "abstract": "In this work we propose a new method for the rhythm classification of short single-lead ECG records, using a set of high-level and clinically meaningful features provided by the abductive interpretation of the records. These features include morphological and rhythm-related features that are used to build two classifiers: one that evaluates the record globally, using aggregated values for each feature; and another one that evaluates the record as a sequence, using a Recurrent Neural Network fed with the individual features for each detected heartbeat. The two classifiers are finally combined using the stacking technique, providing an answer by means of four target classes: Normal sinus rhythm, Atrial fibrillation, Other anomaly, and Noisy. The approach has been validated against the 2017 Physionet/CinC Challenge dataset, obtaining a final score of 0.83 and ranking first in the competition.\n    ",
        "submission_date": "2017-11-10T00:00:00",
        "last_modified_date": "2017-11-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.03902",
        "title": "Neural-Symbolic Learning and Reasoning: A Survey and Interpretation",
        "authors": [
            "Tarek R. Besold",
            "Artur d'Avila Garcez",
            "Sebastian Bader",
            "Howard Bowman",
            "Pedro Domingos",
            "Pascal Hitzler",
            "Kai-Uwe Kuehnberger",
            "Luis C. Lamb",
            "Daniel Lowd",
            "Priscila Machado Vieira Lima",
            "Leo de Penning",
            "Gadi Pinkas",
            "Hoifung Poon",
            "Gerson Zaverucha"
        ],
        "abstract": "The study and understanding of human behaviour is relevant to computer science, artificial intelligence, neural computation, cognitive science, philosophy, psychology, and several other areas. Presupposing cognition as basis of behaviour, among the most prominent tools in the modelling of behaviour are computational-logic systems, connectionist models of cognition, and models of uncertainty. Recent studies in cognitive science, artificial intelligence, and psychology have produced a number of cognitive models of reasoning, learning, and language that are underpinned by computation. In addition, efforts in computer science research have led to the development of cognitive computational systems integrating machine learning and automated reasoning. Such systems have shown promise in a range of applications, including computational biology, fault diagnosis, training and assessment in simulators, and software verification. This joint survey reviews the personal ideas and views of several researchers on neural-symbolic learning and reasoning. The article is organised in three parts: Firstly, we frame the scope and goals of neural-symbolic computation and have a look at the theoretical foundations. We then proceed to describe the realisations of neural-symbolic computation, systems, and applications. Finally we present the challenges facing the area and avenues for further research.\n    ",
        "submission_date": "2017-11-10T00:00:00",
        "last_modified_date": "2017-11-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.04013",
        "title": "Stream Reasoning in Temporal Datalog",
        "authors": [
            "Alessandro Ronca",
            "Mark Kaminski",
            "Bernardo Cuenca Grau",
            "Boris Motik",
            "Ian Horrocks"
        ],
        "abstract": "In recent years, there has been an increasing interest in extending traditional stream processing engines with logical, rule-based, reasoning capabilities. This poses significant theoretical and practical challenges since rules can derive new information and propagate it both towards past and future time points; as a result, streamed query answers can depend on data that has not yet been received, as well as on data that arrived far in the past. Stream reasoning algorithms, however, must be able to stream out query answers as soon as possible, and can only keep a limited number of previous input facts in memory. In this paper, we propose novel reasoning problems to deal with these challenges, and study their computational properties on Datalog extended with a temporal sort and the successor function (a core rule-based language for stream reasoning applications).\n    ",
        "submission_date": "2017-11-10T00:00:00",
        "last_modified_date": "2018-11-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.04036",
        "title": "Physiological and behavioral profiling for nociceptive pain estimation using personalized multitask learning",
        "authors": [
            "Daniel Lopez-Martinez",
            "Ognjen Rudovic",
            "Rosalind Picard"
        ],
        "abstract": "Pain is a subjective experience commonly measured through patient's self report. While there exist numerous situations in which automatic pain estimation methods may be preferred, inter-subject variability in physiological and behavioral pain responses has hindered the development of such methods. In this work, we address this problem by introducing a novel personalized multitask machine learning method for pain estimation based on individual physiological and behavioral pain response profiles, and show its advantages in a dataset containing multimodal responses to nociceptive heat pain.\n    ",
        "submission_date": "2017-11-10T00:00:00",
        "last_modified_date": "2017-11-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.04076",
        "title": "Differential Performance Debugging with Discriminant Regression Trees",
        "authors": [
            "Saeid Tizpaz-Niari",
            "Pavol Cerny",
            "Bor-Yuh Evan Chang",
            "Ashutosh Trivedi"
        ],
        "abstract": "Differential performance debugging is a technique to find performance problems. It applies in situations where the performance of a program is (unexpectedly) different for different classes of inputs. The task is to explain the differences in asymptotic performance among various input classes in terms of program internals. We propose a data-driven technique based on discriminant regression tree (DRT) learning problem where the goal is to discriminate among different classes of inputs. We propose a new algorithm for DRT learning that first clusters the data into functional clusters, capturing different asymptotic performance classes, and then invokes off-the-shelf decision tree learning algorithms to explain these clusters. We focus on linear functional clusters and adapt classical clustering algorithms (K-means and spectral) to produce them. For the K-means algorithm, we generalize the notion of the cluster centroid from a point to a linear function. We adapt spectral clustering by defining a novel kernel function to capture the notion of linear similarity between two data points. We evaluate our approach on benchmarks consisting of Java programs where we are interested in debugging performance. We show that our algorithm significantly outperforms other well-known regression tree learning algorithms in terms of running time and accuracy of classification.\n    ",
        "submission_date": "2017-11-11T00:00:00",
        "last_modified_date": "2017-11-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.04203",
        "title": "Building machines that adapt and compute like brains",
        "authors": [
            "Nikolaus Kriegeskorte",
            "Robert M. Mok"
        ],
        "abstract": "Building machines that learn and think like humans is essential not only for cognitive science, but also for computational neuroscience, whose ultimate goal is to understand how cognition is implemented in biological brains. A new cognitive computational neuroscience should build cognitive-level and neural- level models, understand their relationships, and test both types of models with both brain and behavioral data.\n    ",
        "submission_date": "2017-11-11T00:00:00",
        "last_modified_date": "2017-11-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.04259",
        "title": "On the Synthesis of Guaranteed-Quality Plans for Robot Fleets in Logistics Scenarios via Optimization Modulo Theories",
        "authors": [
            "Francesco Leofante",
            "Erika \u00c1brah\u00e1m",
            "Tim Niemueller",
            "Gerhard Lakemeyer",
            "Armando Tacchella"
        ],
        "abstract": "In manufacturing, the increasing involvement of autonomous robots in production processes poses new challenges on the production management. In this paper we report on the usage of Optimization Modulo Theories (OMT) to solve certain multi-robot scheduling problems in this area. Whereas currently existing methods are heuristic, our approach guarantees optimality for the computed solution. We do not only present our final method but also its chronological development, and draw some general observations for the development of OMT-based approaches.\n    ",
        "submission_date": "2017-11-12T00:00:00",
        "last_modified_date": "2017-11-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.04309",
        "title": "Self-Regulating Artificial General Intelligence",
        "authors": [
            "Joshua S. Gans"
        ],
        "abstract": "Here we examine the paperclip apocalypse concern for artificial general intelligence (or AGI) whereby a superintelligent AI with a simple goal (ie., producing paperclips) accumulates power so that all resources are devoted towards that simple goal and are unavailable for any other use. We provide conditions under which a paper apocalypse can arise but also show that, under certain architectures for recursive self-improvement of AIs, that a paperclip AI may refrain from allowing power capabilities to be developed. The reason is that such developments pose the same control problem for the AI as they do for humans (over AIs) and hence, threaten to deprive it of resources for its primary goal.\n    ",
        "submission_date": "2017-11-12T00:00:00",
        "last_modified_date": "2018-02-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.04329",
        "title": "Medical Diagnosis From Laboratory Tests by Combining Generative and Discriminative Learning",
        "authors": [
            "Shiyue Zhang",
            "Pengtao Xie",
            "Dong Wang",
            "Eric P. Xing"
        ],
        "abstract": "A primary goal of computational phenotype research is to conduct medical diagnosis. In hospital, physicians rely on massive clinical data to make diagnosis decisions, among which laboratory tests are one of the most important resources. However, the longitudinal and incomplete nature of laboratory test data casts a significant challenge on its interpretation and usage, which may result in harmful decisions by both human physicians and automatic diagnosis systems. In this work, we take advantage of deep generative models to deal with the complex laboratory tests. Specifically, we propose an end-to-end architecture that involves a deep generative variational recurrent neural networks (VRNN) to learn robust and generalizable features, and a discriminative neural network (NN) model to learn diagnosis decision making, and the two models are trained jointly. Our experiments are conducted on a dataset involving 46,252 patients, and the 50 most frequent tests are used to predict the 50 most common diagnoses. The results show that our model, VRNN+NN, significantly (p<0.001) outperforms other baseline models. Moreover, we demonstrate that the representations learned by the joint training are more informative than those learned by pure generative models. Finally, we find that our model offers a surprisingly good imputation for missing values.\n    ",
        "submission_date": "2017-11-12T00:00:00",
        "last_modified_date": "2017-11-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.04438",
        "title": "Learning Abduction under Partial Observability",
        "authors": [
            "Brendan Juba",
            "Zongyi Li",
            "Evan Miller"
        ],
        "abstract": "Juba recently proposed a formulation of learning abductive reasoning from examples, in which both the relative plausibility of various explanations, as well as which explanations are valid, are learned directly from data. The main shortcoming of this formulation of the task is that it assumes access to full-information (i.e., fully specified) examples; relatedly, it offers no role for declarative background knowledge, as such knowledge is rendered redundant in the abduction task by complete information. In this work, we extend the formulation to utilize such partially specified examples, along with declarative background knowledge about the missing data. We show that it is possible to use implicitly learned rules together with the explicitly given declarative knowledge to support hypotheses in the course of abduction. We observe that when a small explanation exists, it is possible to obtain a much-improved guarantee in the challenging exception-tolerant setting. Such small, human-understandable explanations are of particular interest for potential applications of the task.\n    ",
        "submission_date": "2017-11-13T00:00:00",
        "last_modified_date": "2017-11-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.04971",
        "title": "DataVizard: Recommending Visual Presentations for Structured Data",
        "authors": [
            "Rema Ananthanarayanan",
            "Pranay Kr. Lohia",
            "Srikanta Bedathur"
        ],
        "abstract": "Selecting the appropriate visual presentation of the data such that it preserves the semantics of the underlying data and at the same time provides an intuitive summary of the data is an important, often the final step of data analytics. Unfortunately, this is also a step involving significant human effort starting from selection of groups of columns in the structured results from analytics stages, to the selection of right visualization by experimenting with various alternatives. In this paper, we describe our \\emph{DataVizard} system aimed at reducing this overhead by automatically recommending the most appropriate visual presentation for the structured result. Specifically, we consider the following two scenarios: first, when one needs to visualize the results of a structured query such as SQL; and the second, when one has acquired a data table with an associated short description (e.g., tables from the Web). Using a corpus of real-world database queries (and their results) and a number of statistical tables crawled from the Web, we show that DataVizard is capable of recommending visual presentations with high accuracy. We also present the results of a user survey that we conducted in order to assess user views of the suitability of the presented charts vis-a-vis the plain text captions of the data.\n    ",
        "submission_date": "2017-11-14T00:00:00",
        "last_modified_date": "2017-11-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.04981",
        "title": "SkipFlow: Incorporating Neural Coherence Features for End-to-End Automatic Text Scoring",
        "authors": [
            "Yi Tay",
            "Minh C. Phan",
            "Luu Anh Tuan",
            "Siu Cheung Hui"
        ],
        "abstract": "Deep learning has demonstrated tremendous potential for Automatic Text Scoring (ATS) tasks. In this paper, we describe a new neural architecture that enhances vanilla neural network models with auxiliary neural coherence features. Our new method proposes a new \\textsc{SkipFlow} mechanism that models relationships between snapshots of the hidden representations of a long short-term memory (LSTM) network as it reads. Subsequently, the semantic relationships between multiple snapshots are used as auxiliary features for prediction. This has two main benefits. Firstly, essays are typically long sequences and therefore the memorization capability of the LSTM network may be insufficient. Implicit access to multiple snapshots can alleviate this problem by acting as a protection against vanishing gradients. The parameters of the \\textsc{SkipFlow} mechanism also acts as an auxiliary memory. Secondly, modeling relationships between multiple positions allows our model to learn features that represent and approximate textual coherence. In our model, we call this \\textit{neural coherence} features. Overall, we present a unified deep learning architecture that generates neural coherence features as it reads in an end-to-end fashion. Our approach demonstrates state-of-the-art performance on the benchmark ASAP dataset, outperforming not only feature engineering baselines but also other deep learning models.\n    ",
        "submission_date": "2017-11-14T00:00:00",
        "last_modified_date": "2017-11-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.04994",
        "title": "Prediction Under Uncertainty with Error-Encoding Networks",
        "authors": [
            "Mikael Henaff",
            "Junbo Zhao",
            "Yann LeCun"
        ],
        "abstract": "In this work we introduce a new framework for performing temporal predictions in the presence of uncertainty. It is based on a simple idea of disentangling components of the future state which are predictable from those which are inherently unpredictable, and encoding the unpredictable components into a low-dimensional latent variable which is fed into a forward model. Our method uses a supervised training objective which is fast and easy to train. We evaluate it in the context of video prediction on multiple datasets and show that it is able to consistently generate diverse predictions without the need for alternating minimization over a latent space or adversarial training.\n    ",
        "submission_date": "2017-11-14T00:00:00",
        "last_modified_date": "2017-11-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.05090",
        "title": "Efficiency Analysis of ASP Encodings for Sequential Pattern Mining Tasks",
        "authors": [
            "Thomas Guyet",
            "Yves Moinard",
            "Ren\u00e9 Quiniou",
            "Torsten Schaub"
        ],
        "abstract": "This article presents the use of Answer Set Programming (ASP) to mine sequential patterns. ASP is a high-level declarative logic programming paradigm for high level encoding combinatorial and optimization problem solving as well as knowledge representation and reasoning. Thus, ASP is a good candidate for implementing pattern mining with background knowledge, which has been a data mining issue for a long time. We propose encodings of the classical sequential pattern mining tasks within two representations of embeddings (fill-gaps vs skip-gaps) and for various kinds of patterns: frequent, constrained and condensed. We compare the computational performance of these encodings with each other to get a good insight into the efficiency of ASP encodings. The results show that the fill-gaps strategy is better on real problems due to lower memory consumption. Finally, compared to a constraint programming approach (CPSM), another declarative programming paradigm, our proposal showed comparable performance.\n    ",
        "submission_date": "2017-11-14T00:00:00",
        "last_modified_date": "2017-11-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.05098",
        "title": "Web Robot Detection in Academic Publishing",
        "authors": [
            "Athanasios Lagopoulos",
            "Grigorios Tsoumakas",
            "Georgios Papadopoulos"
        ],
        "abstract": "Recent industry reports assure the rise of web robots which comprise more than half of the total web traffic. They not only threaten the security, privacy and efficiency of the web but they also distort analytics and metrics, doubting the veracity of the information being promoted. In the academic publishing domain, this can cause articles to be faulty presented as prominent and influential. In this paper, we present our approach on detecting web robots in academic publishing websites. We use different supervised learning algorithms with a variety of characteristics deriving from both the log files of the server and the content served by the website. Our approach relies on the assumption that human users will be interested in specific domains or articles, while web robots crawl a web library incoherently. We experiment with features adopted in previous studies with the addition of novel semantic characteristics which derive after performing a semantic analysis using the Latent Dirichlet Allocation (LDA) algorithm. Our real-world case study shows promising results, pinpointing the significance of semantic features in the web robot detection problem.\n    ",
        "submission_date": "2017-11-14T00:00:00",
        "last_modified_date": "2017-11-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.05105",
        "title": "An Empirical Study of the Effects of Spurious Transitions on Abstraction-based Heuristics",
        "authors": [
            "Mehdi Sadeqi",
            "Robert C. Holte",
            "Sandra Zilles"
        ],
        "abstract": "The efficient solution of state space search problems is often attempted by guiding search algorithms with heuristics (estimates of the distance from any state to the goal). A popular way for creating heuristic functions is by using an abstract version of the state space. However, the quality of abstraction-based heuristic functions, and thus the speed of search, can suffer from spurious transitions, i.e., state transitions in the abstract state space for which no corresponding transitions in the reachable component of the original state space exist. Our first contribution is a quantitative study demonstrating that the harmful effects of spurious transitions on heuristic functions can be substantial, in terms of both the increase in the number of abstract states and the decrease in the heuristic values, which may slow down search. Our second contribution is an empirical study on the benefits of removing a certain kind of spurious transition, namely those that involve states with a pair of mutually exclusive (mutex) variablevalue assignments. In the context of state space planning, a mutex pair is a pair of variable-value assignments that does not occur in any reachable state. Detecting mutex pairs is a problem that has been addressed frequently in the planning literature. Our study shows that there are cases in which mutex detection helps to eliminate harmful spurious transitions to a large extent and thus to speed up search substantially.\n    ",
        "submission_date": "2017-11-14T00:00:00",
        "last_modified_date": "2017-11-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.05216",
        "title": "Tree Projections and Constraint Optimization Problems: Fixed-Parameter Tractability and Parallel Algorithms",
        "authors": [
            "Georg Gottlob",
            "Gianlugi Greco",
            "Francesco Scarcello"
        ],
        "abstract": "Tree projections provide a unifying framework to deal with most structural decomposition methods of constraint satisfaction problems (CSPs). Within this framework, a CSP instance is decomposed into a number of sub-problems, called views, whose solutions are either already available or can be computed efficiently. The goal is to arrange portions of these views in a tree-like structure, called tree projection, which determines an efficiently solvable CSP instance equivalent to the original one. Deciding whether a tree projection exists is NP-hard. Solution methods have therefore been proposed in the literature that do not require a tree projection to be given, and that either correctly decide whether the given CSP instance is satisfiable, or return that a tree projection actually does not exist. These approaches had not been generalized so far on CSP extensions for optimization problems, where the goal is to compute a solution of maximum value/minimum cost. The paper fills the gap, by exhibiting a fixed-parameter polynomial-time algorithm that either disproves the existence of tree projections or computes an optimal solution, with the parameter being the size of the expression of the objective function to be optimized over all possible solutions (and not the size of the whole constraint formula, used in related works). Tractability results are also established for the problem of returning the best K solutions. Finally, parallel algorithms for such optimization problems are proposed and analyzed. Given that the classes of acyclic hypergraphs, hypergraphs of bounded treewidth, and hypergraphs of bounded generalized hypertree width are all covered as special cases of the tree projection framework, the results in this paper directly apply to these classes. These classes are extensively considered in the CSP setting, as well as in conjunctive database query evaluation and optimization.\n    ",
        "submission_date": "2017-11-14T00:00:00",
        "last_modified_date": "2017-11-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.05227",
        "title": "Goal-Driven Query Answering for Existential Rules with Equality",
        "authors": [
            "Michael Benedikt",
            "Boris Motik",
            "Efthymia Tsamoura"
        ],
        "abstract": "Inspired by the magic sets for Datalog, we present a novel goal-driven approach for answering queries over terminating existential rules with equality (aka TGDs and EGDs). Our technique improves the performance of query answering by pruning the consequences that are not relevant for the query. This is challenging in our setting because equalities can potentially affect all predicates in a dataset. We address this problem by combining the existing singularization technique with two new ingredients: an algorithm for identifying the rules relevant to a query and a new magic sets algorithm. We show empirically that our technique can significantly improve the performance of query answering, and that it can mean the difference between answering a query in a few seconds or not being able to process the query at all.\n    ",
        "submission_date": "2017-11-14T00:00:00",
        "last_modified_date": "2017-11-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.05401",
        "title": "Revisiting Simple Neural Networks for Learning Representations of Knowledge Graphs",
        "authors": [
            "Srinivas Ravishankar",
            "Chandrahas",
            "Partha Pratim Talukdar"
        ],
        "abstract": "We address the problem of learning vector representations for entities and relations in Knowledge Graphs (KGs) for Knowledge Base Completion (KBC). This problem has received significant attention in the past few years and multiple methods have been proposed. Most of the existing methods in the literature use a predefined characteristic scoring function for evaluating the correctness of KG triples. These scoring functions distinguish correct triples (high score) from incorrect ones (low score). However, their performance vary across different datasets. In this work, we demonstrate that a simple neural network based score function can consistently achieve near start-of-the-art performance on multiple datasets. We also quantitatively demonstrate biases in standard benchmark datasets, and highlight the need to perform evaluation spanning various datasets.\n    ",
        "submission_date": "2017-11-15T00:00:00",
        "last_modified_date": "2018-01-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.05435",
        "title": "TorusE: Knowledge Graph Embedding on a Lie Group",
        "authors": [
            "Takuma Ebisu",
            "Ryutaro Ichise"
        ],
        "abstract": "Knowledge graphs are useful for many artificial intelligence (AI) tasks. However, knowledge graphs often have missing facts. To populate the graphs, knowledge graph embedding models have been developed. Knowledge graph embedding models map entities and relations in a knowledge graph to a vector space and predict unknown triples by scoring candidate triples. TransE is the first translation-based method and it is well known because of its simplicity and efficiency for knowledge graph completion. It employs the principle that the differences between entity embeddings represent their relations. The principle seems very simple, but it can effectively capture the rules of a knowledge graph. However, TransE has a problem with its regularization. TransE forces entity embeddings to be on a sphere in the embedding vector space. This regularization warps the embeddings and makes it difficult for them to fulfill the abovementioned principle. The regularization also affects adversely the accuracies of the link predictions. On the other hand, regularization is important because entity embeddings diverge by negative sampling without it. This paper proposes a novel embedding model, TorusE, to solve the regularization problem. The principle of TransE can be defined on any Lie group. A torus, which is one of the compact Lie groups, can be chosen for the embedding space to avoid regularization. To the best of our knowledge, TorusE is the first model that embeds objects on other than a real or complex vector space, and this paper is the first to formally discuss the problem of regularization of TransE. Our approach outperforms other state-of-the-art approaches such as TransE, DistMult and ComplEx on a standard link prediction task. We show that TorusE is scalable to large-size knowledge graphs and is faster than the original TransE.\n    ",
        "submission_date": "2017-11-15T00:00:00",
        "last_modified_date": "2017-11-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.05508",
        "title": "A Generally Applicable, Highly Scalable Measurement Computation and Optimization Approach to Sequential Model-Based Diagnosis",
        "authors": [
            "Patrick Rodler",
            "Wolfgang Schmid",
            "Konstantin Schekotihin"
        ],
        "abstract": "Model-Based Diagnosis deals with the identification of the real cause of a system's malfunction based on a formal system model and observations of the system behavior. When a malfunction is detected, there is usually not enough information available to pinpoint the real cause and one needs to discriminate between multiple fault hypotheses (called diagnoses). To this end, Sequential Diagnosis approaches ask an oracle for additional system measurements.\n",
        "submission_date": "2017-11-15T00:00:00",
        "last_modified_date": "2017-11-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.05509",
        "title": "Note on Representing attribute reduction and concepts in concepts lattice using graphs",
        "authors": [
            "Jan Konecny"
        ],
        "abstract": "Mao H. (2017, Representing attribute reduction and concepts in concept lattice using graphs. Soft Computing 21(24):7293--7311) claims to make contributions to the study of reduction of attributes in concept lattices by using graph theory. We show that her results are either trivial or already well-known and all three algorithms proposed in the paper are incorrect.\n    ",
        "submission_date": "2017-11-15T00:00:00",
        "last_modified_date": "2018-05-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.05541",
        "title": "Good and safe uses of AI Oracles",
        "authors": [
            "Stuart Armstrong",
            "Xavier O'Rorke"
        ],
        "abstract": "It is possible that powerful and potentially dangerous artificial intelligence (AI) might be developed in the future. An Oracle is a design which aims to restrain the impact of a potentially dangerous AI by restricting the agent to no actions besides answering questions. Unfortunately, most Oracles will be motivated to gain more control over the world by manipulating users through the content of their answers, and Oracles of potentially high intelligence might be very successful at this \\citep{DBLP:journals/corr/AlfonsecaCACAR16}. In this paper we present two designs for Oracles which, even under pessimistic assumptions, will not manipulate their users into releasing them and yet will still be incentivised to provide their users with helpful answers. The first design is the counterfactual Oracle -- which choses its answer as if it expected nobody to ever read it. The second design is the low-bandwidth Oracle -- which is limited by the quantity of information it can transmit.\n    ",
        "submission_date": "2017-11-15T00:00:00",
        "last_modified_date": "2018-06-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.05715",
        "title": "BBQ-Networks: Efficient Exploration in Deep Reinforcement Learning for Task-Oriented Dialogue Systems",
        "authors": [
            "Zachary Lipton",
            "Xiujun Li",
            "Jianfeng Gao",
            "Lihong Li",
            "Faisal Ahmed",
            "Li Deng"
        ],
        "abstract": "We present a new algorithm that significantly improves the efficiency of exploration for deep Q-learning agents in dialogue systems. Our agents explore via Thompson sampling, drawing Monte Carlo samples from a Bayes-by-Backprop neural network. Our algorithm learns much faster than common exploration strategies such as \\epsilon-greedy, Boltzmann, bootstrapping, and intrinsic-reward-based ones. Additionally, we show that spiking the replay buffer with experiences from just a few successful episodes can make Q-learning feasible when it might otherwise fail.\n    ",
        "submission_date": "2017-11-15T00:00:00",
        "last_modified_date": "2017-11-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.05738",
        "title": "The Neural Network Pushdown Automaton: Model, Stack and Learning Simulations",
        "authors": [
            "G.Z. Sun",
            "C.L. Giles",
            "H.H. Chen",
            "Y.C. Lee"
        ],
        "abstract": "In order for neural networks to learn complex languages or grammars, they must have sufficient computational power or resources to recognize or generate such languages. Though many approaches have been discussed, one ob- vious approach to enhancing the processing power of a recurrent neural network is to couple it with an external stack memory - in effect creating a neural network pushdown automata (NNPDA). This paper discusses in detail this NNPDA - its construction, how it can be trained and how useful symbolic information can be extracted from the trained network.\n",
        "submission_date": "2017-11-15T00:00:00",
        "last_modified_date": "2017-11-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.05767",
        "title": "Predicting vehicular travel times by modeling heterogeneous influences between arterial roads",
        "authors": [
            "Avinash Achar",
            "Venkatesh Sarangan",
            "R Rohith",
            "Anand Sivasubramaniam"
        ],
        "abstract": "Predicting travel times of vehicles in urban settings is a useful and tangible quantity of interest in the context of intelligent transportation systems. We address the problem of travel time prediction in arterial roads using data sampled from probe vehicles. There is only a limited literature on methods using data input from probe vehicles. The spatio-temporal dependencies captured by existing data driven approaches are either too detailed or very simplistic. We strike a balance of the existing data driven approaches to account for varying degrees of influence a given road may experience from its neighbors, while controlling the number of parameters to be learnt. Specifically, we use a NoisyOR conditional probability distribution (CPD) in conjunction with a dynamic bayesian network (DBN) to model state transitions of various roads. We propose an efficient algorithm to learn model parameters. We propose an algorithm for predicting travel times on trips of arbitrary durations. Using synthetic and real world data traces we demonstrate the superior performance of the proposed method under different traffic conditions.\n    ",
        "submission_date": "2017-11-15T00:00:00",
        "last_modified_date": "2017-11-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.05788",
        "title": "Quantile Markov Decision Process",
        "authors": [
            "Xiaocheng Li",
            "Huaiyang Zhong",
            "Margaret L. Brandeau"
        ],
        "abstract": "The goal of a traditional Markov decision process (MDP) is to maximize expected cumulativereward over a defined horizon (possibly infinite). In many applications, however, a decision maker may beinterested in optimizing a specific quantile of the cumulative reward instead of its expectation. In this paperwe consider the problem of optimizing the quantiles of the cumulative rewards of a Markov decision process(MDP), which we refer to as a quantile Markov decision process (QMDP). We provide analytical resultscharacterizing the optimal QMDP value function and present a dynamic programming-based algorithm tosolve for the optimal policy. The algorithm also extends to the MDP problem with a conditional value-at-risk(CVaR) objective. We illustrate the practical relevance of our model by evaluating it on an HIV treatmentinitiation problem, where patients aim to balance the potential benefits and risks of the treatment.\n    ",
        "submission_date": "2017-11-15T00:00:00",
        "last_modified_date": "2020-08-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.05816",
        "title": "K3, L3, LP, RM3, A3, FDE: How to Make Many-Valued Logics Work for You",
        "authors": [
            "Allen P. Hazen",
            "Francis Jeffry Pelletier"
        ],
        "abstract": "We investigate some well-known (and a few not-so-well-known) many-valued logics that have a small number (3 or 4) of truth values. For some of them we complain that they do not have any \\emph{logical} use (despite their perhaps having some intuitive semantic interest) and we look at ways to add features so as to make them useful, while retaining their intuitive appeal. At the end, we show some surprising results in the system FDE, and its relationships with features of other logics. We close with some new examples of \"synonymous logics.\" An Appendix contains a natural deduction system for our augmented FDE, and proofs of soundness and completeness.\n    ",
        "submission_date": "2017-11-15T00:00:00",
        "last_modified_date": "2017-11-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.05900",
        "title": "Using Noisy Extractions to Discover Causal Knowledge",
        "authors": [
            "Dhanya Sridhar",
            "Jay Pujara",
            "Lise Getoor"
        ],
        "abstract": "Knowledge bases (KB) constructed through information extraction from text play an important role in query answering and reasoning. In this work, we study a particular reasoning task, the problem of discovering causal relationships between entities, known as causal discovery. There are two contrasting types of approaches to discovering causal knowledge. One approach attempts to identify causal relationships from text using automatic extraction techniques, while the other approach infers causation from observational data. However, extractions alone are often insufficient to capture complex patterns and full observational data is expensive to obtain. We introduce a probabilistic method for fusing noisy extractions with observational data to discover causal knowledge. We propose a principled approach that uses the probabilistic soft logic (PSL) framework to encode well-studied constraints to recover long-range patterns and consistent predictions, while cheaply acquired extractions provide a proxy for unseen observations. We apply our method gene regulatory networks and show the promise of exploiting KB signals in causal discovery, suggesting a critical, new area of research.\n    ",
        "submission_date": "2017-11-16T00:00:00",
        "last_modified_date": "2017-11-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.05905",
        "title": "Using experimental game theory to transit human values to ethical AI",
        "authors": [
            "Yijia Wang",
            "Yan Wan",
            "Zhijian Wang"
        ],
        "abstract": "Knowing the reflection of game theory and ethics, we develop a mathematical representation to bridge the gap between the concepts in moral philosophy (e.g., Kantian and Utilitarian) and AI ethics industry technology standard (e.g., IEEE P7000 standard series for Ethical AI). As an application, we demonstrate how human value can be obtained from the experimental game theory (e.g., trust game experiment) so as to build an ethical AI. Moreover, an approach to test the ethics (rightness or wrongness) of a given AI algorithm by using an iterated Prisoner's Dilemma Game experiment is discussed as an example. Compared with existing mathematical frameworks and testing method on AI ethics technology, the advantages of the proposed approach are analyzed.\n    ",
        "submission_date": "2017-11-16T00:00:00",
        "last_modified_date": "2017-11-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.06035",
        "title": "From Algorithmic Black Boxes to Adaptive White Boxes: Declarative Decision-Theoretic Ethical Programs as Codes of Ethics",
        "authors": [
            "Martijn van Otterlo"
        ],
        "abstract": "Ethics of algorithms is an emerging topic in various disciplines such as social science, law, and philosophy, but also artificial intelligence (AI). The value alignment problem expresses the challenge of (machine) learning values that are, in some way, aligned with human requirements or values. In this paper I argue for looking at how humans have formalized and communicated values, in professional codes of ethics, and for exploring declarative decision-theoretic ethical programs (DDTEP) to formalize codes of ethics. This renders machine ethical reasoning and decision-making, as well as learning, more transparent and hopefully more accountable. The paper includes proof-of-concept examples of known toy dilemmas and gatekeeping domains such as archives and libraries.\n    ",
        "submission_date": "2017-11-16T00:00:00",
        "last_modified_date": "2017-11-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.06128",
        "title": "Enabling Reasoning with LegalRuleML",
        "authors": [
            "Ho-Pun Lam",
            "Mustafa Hashmi"
        ],
        "abstract": "In order to automate verification process, regulatory rules written in natural language need to be translated into a format that machines can understand. However, none of the existing formalisms can fully represent the elements that appear in legal norms. For instance, most of these formalisms do not provide features to capture the behavior of deontic effects, which is an important aspect in automated compliance checking. This paper presents an approach for transforming legal norms represented using LegalRuleML to a variant of Modal Defeasible Logic (and vice versa) such that a legal statement represented using LegalRuleML can be transformed into a machine-readable format that can be understood and reasoned about depending upon the client's preferences.\n    ",
        "submission_date": "2017-11-11T00:00:00",
        "last_modified_date": "2018-04-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.06202",
        "title": "A Robust Genetic Algorithm for Learning Temporal Specifications from Data",
        "authors": [
            "Laura Nenzi",
            "Simone Silvetti",
            "Ezio Bartocci",
            "Luca Bortolussi"
        ],
        "abstract": "We consider the problem of mining signal temporal logical requirements from a dataset of regular (good) and anomalous (bad) trajectories of a dynamical system. We assume the training set to be labeled by human experts and that we have access only to a limited amount of data, typically noisy. We provide a systematic approach to synthesize both the syntactical structure and the parameters of the temporal logic formula using a two-steps procedure: first, we leverage a novel evolutionary algorithm for learning the structure of the formula; second, we perform the parameter synthesis operating on the statistical emulation of the average robustness for a candidate formula w.r.t. its parameters. We compare our results with our previous work [{BufoBSBLB14] and with a recently proposed decision-tree [bombara_decision_2016] based method. We present experimental results on two case studies: an anomalous trajectory detection problem of a naval surveillance system and the characterization of an Ineffective Respiratory effort, showing the usefulness of our work.\n    ",
        "submission_date": "2017-11-13T00:00:00",
        "last_modified_date": "2018-08-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.06301",
        "title": "One Model for the Learning of Language",
        "authors": [
            "Yuan Yang"
        ],
        "abstract": "A major target of linguistics and cognitive science has been to understand what class of learning systems can acquire the key structures of natural language. Until recently, the computational requirements of language have been used to argue that learning is impossible without a highly constrained hypothesis space. Here, we describe a learning system that is maximally unconstrained, operating over the space of all computations, and is able to acquire several of the key structures present natural language from positive evidence alone. The model successfully acquires regular (e.g. $(ab)^n$), context-free (e.g. $a^n b^n$, $x x^R$), and context-sensitive (e.g. $a^nb^nc^n$, $a^nb^mc^nd^m$, $xx$) formal languages. Our approach develops the concept of factorized programs in Bayesian program induction in order to help manage the complexity of representation. We show in learning, the model predicts several phenomena empirically observed in human grammar acquisition experiments.\n    ",
        "submission_date": "2017-11-16T00:00:00",
        "last_modified_date": "2017-11-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.06362",
        "title": "Exploring the Use of Shatter for AllSAT Through Ramsey-Type Problems",
        "authors": [
            "David E. Narv\u00e1ez"
        ],
        "abstract": "In the context of SAT solvers, Shatter is a popular tool for symmetry breaking on CNF formulas. Nevertheless, little has been said about its use in the context of AllSAT problems: problems where we are interested in listing all the models of a Boolean formula. AllSAT has gained much popularity in recent years due to its many applications in domains like model checking, data mining, etc. One example of a particularly transparent application of AllSAT to other fields of computer science is computational Ramsey theory. In this paper we study the effect of incorporating Shatter to the workflow of using Boolean formulas to generate all possible edge colorings of a graph avoiding prescribed monochromatic subgraphs. Generating complete sets of colorings is an important building block in computational Ramsey theory. We identify two drawbacks in the na\u00efve use of Shatter to break the symmetries of Boolean formulas encoding Ramsey-type problems for graphs: a \"blow-up\" in the number of models and the generation of incomplete sets of colorings. The issues presented in this work are not intended to discourage the use of Shatter as a preprocessing tool for AllSAT problems in combinatorial computing but to help researchers properly use this tool by avoiding these potential pitfalls. To this end, we provide strategies and additional tools to cope with the negative effects of using Shatter for AllSAT. While the specific application addressed in this paper is that of Ramsey-type problems, the analysis we carry out applies to many other areas in which highly-symmetrical Boolean formulas arise and we wish to find all of their models.\n    ",
        "submission_date": "2017-11-17T00:00:00",
        "last_modified_date": "2017-11-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.06431",
        "title": "Using KL-divergence to focus Deep Visual Explanation",
        "authors": [
            "Housam Khalifa Bashier Babiker",
            "Randy Goebel"
        ],
        "abstract": "We present a method for explaining the image classification predictions of deep convolution neural networks, by highlighting the pixels in the image which influence the final class prediction. Our method requires the identification of a heuristic method to select parameters hypothesized to be most relevant in this prediction, and here we use Kullback-Leibler divergence to provide this focus. Overall, our approach helps in understanding and interpreting deep network predictions and we hope contributes to a foundation for such understanding of deep learning networks. In this brief paper, our experiments evaluate the performance of two popular networks in this context of interpretability.\n    ",
        "submission_date": "2017-11-17T00:00:00",
        "last_modified_date": "2018-01-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.06498",
        "title": "Win Prediction in Esports: Mixed-Rank Match Prediction in Multi-player Online Battle Arena Games",
        "authors": [
            "Victoria Hodge",
            "Sam Devlin",
            "Nick Sephton",
            "Florian Block",
            "Anders Drachen",
            "Peter Cowling"
        ],
        "abstract": "Esports has emerged as a popular genre for players as well as spectators, supporting a global entertainment industry. Esports analytics has evolved to address the requirement for data-driven feedback, and is focused on cyber-athlete evaluation, strategy and prediction. Towards the latter, previous work has used match data from a variety of player ranks from hobbyist to professional players. However, professional players have been shown to behave differently than lower ranked players. Given the comparatively limited supply of professional data, a key question is thus whether mixed-rank match datasets can be used to create data-driven models which predict winners in professional matches and provide a simple in-game statistic for viewers and broadcasters. Here we show that, although there is a slightly reduced accuracy, mixed-rank datasets can be used to predict the outcome of professional matches, with suitably optimized configurations.\n    ",
        "submission_date": "2017-11-17T00:00:00",
        "last_modified_date": "2017-11-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.06517",
        "title": "Wikipedia for Smart Machines and Double Deep Machine Learning",
        "authors": [
            "Moshe BenBassat"
        ],
        "abstract": "Very important breakthroughs in data centric deep learning algorithms led to impressive performance in transactional point applications of Artificial Intelligence (AI) such as Face Recognition, or EKG classification. With all due appreciation, however, knowledge blind data only machine learning algorithms have severe limitations for non-transactional AI applications, such as medical diagnosis beyond the EKG results. Such applications require deeper and broader knowledge in their problem solving capabilities, e.g. integrating anatomy and physiology knowledge with EKG results and other patient findings. Following a review and illustrations of such limitations for several real life AI applications, we point at ways to overcome them. The proposed Wikipedia for Smart Machines initiative aims at building repositories of software structures that represent humanity science & technology knowledge in various parts of life; knowledge that we all learn in schools, universities and during our professional life. Target readers for these repositories are smart machines; not human. AI software developers will have these Reusable Knowledge structures readily available, hence, the proposed name ReKopedia. Big Data is by now a mature technology, it is time to focus on Big Knowledge. Some will be derived from data, some will be obtained from mankind gigantic repository of knowledge. Wikipedia for smart machines along with the new Double Deep Learning approach offer a paradigm for integrating datacentric deep learning algorithms with algorithms that leverage deep knowledge, e.g. evidential reasoning and causality reasoning. For illustration, a project is described to produce ReKopedia knowledge modules for medical diagnosis of about 1,000 disorders. Data is important, but knowledge deep, basic, and commonsense is equally important.\n    ",
        "submission_date": "2017-11-17T00:00:00",
        "last_modified_date": "2018-05-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.06583",
        "title": "Learning to Play Othello with Deep Neural Networks",
        "authors": [
            "Pawe\u0142 Liskowski",
            "Wojciech Ja\u015bkowski",
            "Krzysztof Krawiec"
        ],
        "abstract": "Achieving superhuman playing level by AlphaGo corroborated the capabilities of convolutional neural architectures (CNNs) for capturing complex spatial patterns. This result was to a great extent due to several analogies between Go board states and 2D images CNNs have been designed for, in particular translational invariance and a relatively large board. In this paper, we verify whether CNN-based move predictors prove effective for Othello, a game with significantly different characteristics, including a much smaller board size and complete lack of translational invariance. We compare several CNN architectures and board encodings, augment them with state-of-the-art extensions, train on an extensive database of experts' moves, and examine them with respect to move prediction accuracy and playing strength. The empirical evaluation confirms high capabilities of neural move predictors and suggests a strong correlation between prediction accuracy and playing strength. The best CNNs not only surpass all other 1-ply Othello players proposed to date but defeat (2-ply) Edax, the best open-source Othello player.\n    ",
        "submission_date": "2017-11-17T00:00:00",
        "last_modified_date": "2017-11-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.06588",
        "title": "Dependent landmark drift: robust point set registration with a Gaussian mixture model and a statistical shape model",
        "authors": [
            "Osamu Hirose"
        ],
        "abstract": "The goal of point set registration is to find point-by-point correspondences between point sets, each of which characterizes the shape of an object. Because local preservation of object geometry is assumed, prevalent algorithms in the area can often elegantly solve the problems without using geometric information specific to the objects. This means that registration performance can be further improved by using prior knowledge of object geometry. In this paper, we propose a novel point set registration method using the Gaussian mixture model with prior shape information encoded as a statistical shape model. Our transformation model is defined as a combination of the similar transformation, motion coherence, and the statistical shape model. Therefore, the proposed method works effectively if the target point set includes outliers and missing regions, or if it is rotated. The computational cost can be reduced to linear, and therefore the method is scalable to large point sets. The effectiveness of the method will be verified through comparisons with existing algorithms using datasets concerning human body shapes, hands, and faces.\n    ",
        "submission_date": "2017-11-17T00:00:00",
        "last_modified_date": "2018-07-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.06605",
        "title": "Evolving soft locomotion in aquatic and terrestrial environments: effects of material properties and environmental transitions",
        "authors": [
            "Francesco Corucci",
            "Nick Cheney",
            "Francesco Giorgio-Serchi",
            "Josh Bongard",
            "Cecilia Laschi"
        ],
        "abstract": "Designing soft robots poses considerable challenges: automated design approaches may be particularly appealing in this field, as they promise to optimize complex multi-material machines with very little or no human intervention. Evolutionary soft robotics is concerned with the application of optimization algorithms inspired by natural evolution in order to let soft robots (both morphologies and controllers) spontaneously evolve within physically-realistic simulated environments, figuring out how to satisfy a set of objectives defined by human designers. In this paper a powerful evolutionary system is put in place in order to perform a broad investigation on the free-form evolution of walking and swimming soft robots in different environments. Three sets of experiments are reported, tackling different aspects of the evolution of soft locomotion. The first two sets explore the effects of different material properties on the evolution of terrestrial and aquatic soft locomotion: particularly, we show how different materials lead to the evolution of different morphologies, behaviors, and energy-performance tradeoffs. It is found that within our simplified physics world stiffer robots evolve more sophisticated and effective gaits and morphologies on land, while softer ones tend to perform better in water. The third set of experiments starts investigating the effect and potential benefits of major environmental transitions (land - water) during evolution. Results provide interesting morphological exaptation phenomena, and point out a potential asymmetry between land-water and water-land transitions: while the first type of transition appears to be detrimental, the second one seems to have some beneficial effects.\n    ",
        "submission_date": "2017-11-17T00:00:00",
        "last_modified_date": "2017-11-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.06632",
        "title": "ATRank: An Attention-Based User Behavior Modeling Framework for Recommendation",
        "authors": [
            "Chang Zhou",
            "Jinze Bai",
            "Junshuai Song",
            "Xiaofei Liu",
            "Zhengchao Zhao",
            "Xiusi Chen",
            "Jun Gao"
        ],
        "abstract": "A user can be represented as what he/she does along the history. A common way to deal with the user modeling problem is to manually extract all kinds of aggregated features over the heterogeneous behaviors, which may fail to fully represent the data itself due to limited human instinct. Recent works usually use RNN-based methods to give an overall embedding of a behavior sequence, which then could be exploited by the downstream applications. However, this can only preserve very limited information, or aggregated memories of a person. When a downstream application requires to facilitate the modeled user features, it may lose the integrity of the specific highly correlated behavior of the user, and introduce noises derived from unrelated behaviors. This paper proposes an attention based user behavior modeling framework called ATRank, which we mainly use for recommendation tasks. Heterogeneous user behaviors are considered in our model that we project all types of behaviors into multiple latent semantic spaces, where influence can be made among the behaviors via self-attention. Downstream applications then can use the user behavior vectors via vanilla attention. Experiments show that ATRank can achieve better performance and faster training process. We further explore ATRank to use one unified model to predict different types of user behaviors at the same time, showing a comparable performance with the highly optimized individual models.\n    ",
        "submission_date": "2017-11-17T00:00:00",
        "last_modified_date": "2017-11-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.06677",
        "title": "Is prioritized sweeping the better episodic control?",
        "authors": [
            "Johanni Brea"
        ],
        "abstract": "Episodic control has been proposed as a third approach to reinforcement learning, besides model-free and model-based control, by analogy with the three types of human memory. i.e. episodic, procedural and semantic memory. But the theoretical properties of episodic control are not well investigated. Here I show that in deterministic tree Markov decision processes, episodic control is equivalent to a form of prioritized sweeping in terms of sample efficiency as well as memory and computation demands. For general deterministic and stochastic environments, prioritized sweeping performs better even when memory and computation demands are restricted to be equal to those of episodic control. These results suggest generalizations of prioritized sweeping to partially observable environments, its combined use with function approximation and the search for possible implementations of prioritized sweeping in brains.\n    ",
        "submission_date": "2017-11-20T00:00:00",
        "last_modified_date": "2018-08-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.06800",
        "title": "Scalable Relaxations of Sparse Packing Constraints: Optimal Biocontrol in Predator-Prey Network",
        "authors": [
            "Johan Bjorck",
            "Yiwei Bai",
            "Xiaojian Wu",
            "Yexiang Xue",
            "Mark C. Whitmore",
            "Carla Gomes"
        ],
        "abstract": "Cascades represent rapid changes in networks. A cascading phenomenon of ecological and economic impact is the spread of invasive species in geographic landscapes. The most promising management strategy is often biocontrol, which entails introducing a natural predator able to control the invading population, a setting that can be treated as two interacting cascades of predator and prey populations. We formulate and study a nonlinear problem of optimal biocontrol: optimally seeding the predator cascade over time to minimize the harmful prey population. Recurring budgets, which typically face conservation organizations, naturally leads to sparse constraints which make the problem amenable to approximation algorithms. Available methods based on continuous relaxations scale poorly, to remedy this we develop a novel and scalable randomized algorithm based on a width relaxation, applicable to a broad class of combinatorial optimization problems. We evaluate our contributions in the context of biocontrol for the insect pest Hemlock Wolly Adelgid (HWA) in eastern North America. Our algorithm outperforms competing methods in terms of scalability and solution quality, and finds near optimal strategies for the control of the HWA for fine-grained networks -- an important problem in computational sustainability.\n    ",
        "submission_date": "2017-11-18T00:00:00",
        "last_modified_date": "2018-02-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.06821",
        "title": "Acquiring Common Sense Spatial Knowledge through Implicit Spatial Templates",
        "authors": [
            "Guillem Collell",
            "Luc Van Gool",
            "Marie-Francine Moens"
        ],
        "abstract": "Spatial understanding is a fundamental problem with wide-reaching real-world applications. The representation of spatial knowledge is often modeled with spatial templates, i.e., regions of acceptability of two objects under an explicit spatial relationship (e.g., \"on\", \"below\", etc.). In contrast with prior work that restricts spatial templates to explicit spatial prepositions (e.g., \"glass on table\"), here we extend this concept to implicit spatial language, i.e., those relationships (generally actions) for which the spatial arrangement of the objects is only implicitly implied (e.g., \"man riding horse\"). In contrast with explicit relationships, predicting spatial arrangements from implicit spatial language requires significant common sense spatial understanding. Here, we introduce the task of predicting spatial templates for two objects under a relationship, which can be seen as a spatial question-answering task with a (2D) continuous output (\"where is the man w.r.t. a horse when the man is walking the horse?\"). We present two simple neural-based models that leverage annotated images and structured text to learn this task. The good performance of these models reveals that spatial locations are to a large extent predictable from implicit spatial language. Crucially, the models attain similar performance in a challenging generalized setting, where the object-relation-object combinations (e.g.,\"man walking dog\") have never been seen before. Next, we go one step further by presenting the models with unseen objects (e.g., \"dog\"). In this scenario, we show that leveraging word embeddings enables the models to output accurate spatial predictions, proving that the models acquire solid common sense spatial knowledge allowing for such generalization.\n    ",
        "submission_date": "2017-11-18T00:00:00",
        "last_modified_date": "2020-03-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.06892",
        "title": "Learning to select computations",
        "authors": [
            "Frederick Callaway",
            "Sayan Gul",
            "Paul M. Krueger",
            "Thomas L. Griffiths",
            "Falk Lieder"
        ],
        "abstract": "The efficient use of limited computational resources is an essential ingredient of intelligence. Selecting computations optimally according to rational metareasoning would achieve this, but this is computationally intractable. Inspired by psychology and neuroscience, we propose the first concrete and domain-general learning algorithm for approximating the optimal selection of computations: Bayesian metalevel policy search (BMPS). We derive this general, sample-efficient search algorithm for a computation-selecting metalevel policy based on the insight that the value of information lies between the myopic value of information and the value of perfect information. We evaluate BMPS on three increasingly difficult metareasoning problems: when to terminate computation, how to allocate computation between competing options, and planning. Across all three domains, BMPS achieved near-optimal performance and compared favorably to previously proposed metareasoning heuristics. Finally, we demonstrate the practical utility of BMPS in an emergency management scenario, even accounting for the overhead of metareasoning.\n    ",
        "submission_date": "2017-11-18T00:00:00",
        "last_modified_date": "2018-08-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.06922",
        "title": "Run, skeleton, run: skeletal model in a physics-based simulation",
        "authors": [
            "Mikhail Pavlov",
            "Sergey Kolesnikov",
            "Sergey M. Plis"
        ],
        "abstract": "In this paper, we present our approach to solve a physics-based reinforcement learning challenge \"Learning to Run\" with objective to train physiologically-based human model to navigate a complex obstacle course as quickly as possible. The environment is computationally expensive, has a high-dimensional continuous action space and is stochastic. We benchmark state of the art policy-gradient methods and test several improvements, such as layer normalization, parameter noise, action and state reflecting, to stabilize training and improve its sample-efficiency. We found that the Deep Deterministic Policy Gradient method is the most efficient method for this environment and the improvements we have introduced help to stabilize training. Learned models are able to generalize to new physical scenarios, e.g. different obstacle courses.\n    ",
        "submission_date": "2017-11-18T00:00:00",
        "last_modified_date": "2018-01-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.06930",
        "title": "Computational Results for Extensive-Form Adversarial Team Games",
        "authors": [
            "Andrea Celli",
            "Nicola Gatti"
        ],
        "abstract": "We provide, to the best of our knowledge, the first computational study of extensive-form adversarial team games. These games are sequential, zero-sum games in which a team of players, sharing the same utility function, faces an adversary. We define three different scenarios according to the communication capabilities of the team. In the first, the teammates can communicate and correlate their actions both before and during the play. In the second, they can only communicate before the play. In the third, no communication is possible at all. We define the most suitable solution concepts, and we study the inefficiency caused by partial or null communication, showing that the inefficiency can be arbitrarily large in the size of the game tree. Furthermore, we study the computational complexity of the equilibrium-finding problem in the three scenarios mentioned above, and we provide, for each of the three scenarios, an exact algorithm. Finally, we empirically evaluate the scalability of the algorithms in random games and the inefficiency caused by partial or null communication.\n    ",
        "submission_date": "2017-11-18T00:00:00",
        "last_modified_date": "2017-11-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.07071",
        "title": "The destiny of constant structure discrete time closed semantic systems",
        "authors": [
            "Evgeny Ivanko"
        ],
        "abstract": "Constant structure closed semantic systems are the systems each element of which receives its definition through the correspondent unchangeable set of other elements of the system. Discrete time means here that the definitions of the elements change iteratively and simultaneously based on the \"neighbor portraits\" from the previous iteration. I prove that the iterative redefinition process in such class of systems will quickly degenerate into a series of pairwise isomorphic states and discuss some directions of further research.\n    ",
        "submission_date": "2017-11-19T00:00:00",
        "last_modified_date": "2017-11-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.07111",
        "title": "Modeling Epistemological Principles for Bias Mitigation in AI Systems: An Illustration in Hiring Decisions",
        "authors": [
            "Marisa Vasconcelos",
            "Carlos Cardonha",
            "Bernardo Gon\u00e7alves"
        ],
        "abstract": "Artificial Intelligence (AI) has been used extensively in automatic decision making in a broad variety of scenarios, ranging from credit ratings for loans to recommendations of movies. Traditional design guidelines for AI models focus essentially on accuracy maximization, but recent work has shown that economically irrational and socially unacceptable scenarios of discrimination and unfairness are likely to arise unless these issues are explicitly addressed. This undesirable behavior has several possible sources, such as biased datasets used for training that may not be detected in black-box models. After pointing out connections between such bias of AI and the problem of induction, we focus on Popper's contributions after Hume's, which offer a logical theory of preferences. An AI model can be preferred over others on purely rational grounds after one or more attempts at refutation based on accuracy and fairness. Inspired by such epistemological principles, this paper proposes a structured approach to mitigate discrimination and unfairness caused by bias in AI systems. In the proposed computational framework, models are selected and enhanced after attempts at refutation. To illustrate our discussion, we focus on hiring decision scenarios where an AI system filters in which job applicants should go to the interview phase.\n    ",
        "submission_date": "2017-11-20T00:00:00",
        "last_modified_date": "2017-11-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.07163",
        "title": "Dynamic Neural Program Embedding for Program Repair",
        "authors": [
            "Ke Wang",
            "Rishabh Singh",
            "Zhendong Su"
        ],
        "abstract": "Neural program embeddings have shown much promise recently for a variety of program analysis tasks, including program synthesis, program repair, fault localization, etc. However, most existing program embeddings are based on syntactic features of programs, such as raw token sequences or abstract syntax trees. Unlike images and text, a program has an unambiguous semantic meaning that can be difficult to capture by only considering its syntax (i.e. syntactically similar pro- grams can exhibit vastly different run-time behavior), which makes syntax-based program embeddings fundamentally limited. This paper proposes a novel semantic program embedding that is learned from program execution traces. Our key insight is that program states expressed as sequential tuples of live variable values not only captures program semantics more precisely, but also offer a more natural fit for Recurrent Neural Networks to model. We evaluate different syntactic and semantic program embeddings on predicting the types of errors that students make in their submissions to an introductory programming class and two exercises on the CodeHunt education platform. Evaluation results show that our new semantic program embedding significantly outperforms the syntactic program embeddings based on token sequences and abstract syntax trees. In addition, we augment a search-based program repair system with the predictions obtained from our se- mantic embedding, and show that search efficiency is also significantly improved.\n    ",
        "submission_date": "2017-11-20T00:00:00",
        "last_modified_date": "2018-06-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.07273",
        "title": "Facets, Tiers and Gems: Ontology Patterns for Hypernormalisation",
        "authors": [
            "Phillip Lord",
            "Robert Stevens"
        ],
        "abstract": "There are many methodologies and techniques for easing the task of ontology building. Here we describe the intersection of two of these: ontology normalisation and fully programmatic ontology development. The first of these describes a standardized organisation for an ontology, with singly inherited self-standing entities, and a number of small taxonomies of refining entities. The former are described and defined in terms of the latter and used to manage the polyhierarchy of the self-standing entities. Fully programmatic development is a technique where an ontology is developed using a domain-specific language within a programming language, meaning that as well defining ontological entities, it is possible to add arbitrary patterns or new syntax within the same environment. We describe how new patterns can be used to enable a new style of ontology development that we call hypernormalisation.\n    ",
        "submission_date": "2017-11-20T00:00:00",
        "last_modified_date": "2017-11-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.07321",
        "title": "Related family-based attribute reduction of covering information systems when varying attribute sets",
        "authors": [
            "Guangming Lang"
        ],
        "abstract": "In practical situations, there are many dynamic covering information systems with variations of attributes, but there are few studies on related family-based attribute reduction of dynamic covering information systems. In this paper, we first investigate updated mechanisms of constructing attribute reducts for consistent and inconsistent covering information systems when varying attribute sets by using related families. Then we employ examples to illustrate how to compute attribute reducts of dynamic covering information systems with variations of attribute sets. Finally, the experimental results illustrates that the related family-based methods are effective to perform attribute reduction of dynamic covering information systems when attribute sets are varying with time.\n    ",
        "submission_date": "2017-11-16T00:00:00",
        "last_modified_date": "2017-11-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.07364",
        "title": "Classification with Costly Features using Deep Reinforcement Learning",
        "authors": [
            "Jarom\u00edr Janisch",
            "Tom\u00e1\u0161 Pevn\u00fd",
            "Viliam Lis\u00fd"
        ],
        "abstract": "We study a classification problem where each feature can be acquired for a cost and the goal is to optimize a trade-off between the expected classification error and the feature cost. We revisit a former approach that has framed the problem as a sequential decision-making problem and solved it by Q-learning with a linear approximation, where individual actions are either requests for feature values or terminate the episode by providing a classification decision. On a set of eight problems, we demonstrate that by replacing the linear approximation with neural networks the approach becomes comparable to the state-of-the-art algorithms developed specifically for this problem. The approach is flexible, as it can be improved with any new reinforcement learning enhancement, it allows inclusion of pre-trained high-performance classifier, and unlike prior art, its performance is robust across all evaluated datasets.\n    ",
        "submission_date": "2017-11-20T00:00:00",
        "last_modified_date": "2018-11-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.07414",
        "title": "The Promise and Peril of Human Evaluation for Model Interpretability",
        "authors": [
            "Bernease Herman"
        ],
        "abstract": "Transparency, user trust, and human comprehension are popular ethical motivations for interpretable machine learning. In support of these goals, researchers evaluate model explanation performance using humans and real world applications. This alone presents a challenge in many areas of artificial intelligence. In this position paper, we propose a distinction between descriptive and persuasive explanations. We discuss reasoning suggesting that functional interpretability may be correlated with cognitive function and user preferences. If this is indeed the case, evaluation and optimization using functional metrics could perpetuate implicit cognitive bias in explanations that threaten transparency. Finally, we propose two potential research directions to disambiguate cognitive function and explanation models, retaining control over the tradeoff between accuracy and interpretability.\n    ",
        "submission_date": "2017-11-20T00:00:00",
        "last_modified_date": "2019-10-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.07832",
        "title": "Situationally Aware Options",
        "authors": [
            "Daniel J. Mankowitz",
            "Aviv Tamar",
            "Shie Mannor"
        ],
        "abstract": "Hierarchical abstractions, also known as options -- a type of temporally extended action (Sutton et. al. 1999) that enables a reinforcement learning agent to plan at a higher level, abstracting away from the lower-level details. In this work, we learn reusable options whose parameters can vary, encouraging different behaviors, based on the current situation. In principle, these behaviors can include vigor, defence or even risk-averseness. These are some examples of what we refer to in the broader context as Situational Awareness (SA). We incorporate SA, in the form of vigor, into hierarchical RL by defining and learning situationally aware options in a Probabilistic Goal Semi-Markov Decision Process (PG-SMDP). This is achieved using our Situationally Aware oPtions (SAP) policy gradient algorithm which comes with a theoretical convergence guarantee. We learn reusable options in different scenarios in a RoboCup soccer domain (i.e., winning/losing). These options learn to execute with different levels of vigor resulting in human-like behaviours such as `time-wasting' in the winning scenario. We show the potential of the agent to exit bad local optima using reusable options in RoboCup. Finally, using SAP, the agent mitigates feature-based model misspecification in a Bottomless Pit of Death domain.\n    ",
        "submission_date": "2017-11-20T00:00:00",
        "last_modified_date": "2017-11-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.07875",
        "title": "Constructive Preference Elicitation over Hybrid Combinatorial Spaces",
        "authors": [
            "Paolo Dragone",
            "Stefano Teso",
            "Andrea Passerini"
        ],
        "abstract": "Preference elicitation is the task of suggesting a highly preferred configuration to a decision maker. The preferences are typically learned by querying the user for choice feedback over pairs or sets of objects. In its constructive variant, new objects are synthesized \"from scratch\" by maximizing an estimate of the user utility over a combinatorial (possibly infinite) space of candidates. In the constructive setting, most existing elicitation techniques fail because they rely on exhaustive enumeration of the candidates. A previous solution explicitly designed for constructive tasks comes with no formal performance guarantees, and can be very expensive in (or unapplicable to) problems with non-Boolean attributes. We propose the Choice Perceptron, a Perceptron-like algorithm for learning user preferences from set-wise choice feedback over constructive domains and hybrid Boolean-numeric feature spaces. We provide a theoretical analysis on the attained regret that holds for a large class of query selection strategies, and devise a heuristic strategy that aims at optimizing the regret in practice. Finally, we demonstrate its effectiveness by empirical evaluation against existing competitors on constructive scenarios of increasing complexity.\n    ",
        "submission_date": "2017-11-21T00:00:00",
        "last_modified_date": "2018-05-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.07970",
        "title": "Deep Learning for Physical Processes: Incorporating Prior Scientific Knowledge",
        "authors": [
            "Emmanuel de Bezenac",
            "Arthur Pajot",
            "Patrick Gallinari"
        ],
        "abstract": "We consider the use of Deep Learning methods for modeling complex phenomena like those occurring in natural physical processes. With the large amount of data gathered on these phenomena the data intensive paradigm could begin to challenge more traditional approaches elaborated over the years in fields like maths or physics. However, despite considerable successes in a variety of application domains, the machine learning field is not yet ready to handle the level of complexity required by such problems. Using an example application, namely Sea Surface Temperature Prediction, we show how general background knowledge gained from physics could be used as a guideline for designing efficient Deep Learning models. In order to motivate the approach and to assess its generality we demonstrate a formal link between the solution of a class of differential equations underlying a large family of physical phenomena and the proposed model. Experiments and comparison with series of baselines including a state of the art numerical approach is then provided.\n    ",
        "submission_date": "2017-11-21T00:00:00",
        "last_modified_date": "2018-01-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.08028",
        "title": "Recurrent Relational Networks",
        "authors": [
            "Rasmus Berg Palm",
            "Ulrich Paquet",
            "Ole Winther"
        ],
        "abstract": "This paper is concerned with learning to solve tasks that require a chain of interdependent steps of relational inference, like answering complex questions about the relationships between objects, or solving puzzles where the smaller elements of a solution mutually constrain each other. We introduce the recurrent relational network, a general purpose module that operates on a graph representation of objects. As a generalization of Santoro et al. [2017]'s relational network, it can augment any neural network model with the capacity to do many-step relational reasoning. We achieve state of the art results on the bAbI textual question-answering dataset with the recurrent relational network, consistently solving 20/20 tasks. As bAbI is not particularly challenging from a relational reasoning point of view, we introduce Pretty-CLEVR, a new diagnostic dataset for relational reasoning. In the Pretty-CLEVR set-up, we can vary the question to control for the number of relational reasoning steps that are required to obtain the answer. Using Pretty-CLEVR, we probe the limitations of multi-layer perceptrons, relational and recurrent relational networks. Finally, we show how recurrent relational networks can learn to solve Sudoku puzzles from supervised training data, a challenging task requiring upwards of 64 steps of relational reasoning. We achieve state-of-the-art results amongst comparable methods by solving 96.6% of the hardest Sudoku puzzles.\n    ",
        "submission_date": "2017-11-21T00:00:00",
        "last_modified_date": "2018-11-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.08068",
        "title": "Deterministic Policy Optimization by Combining Pathwise and Score Function Estimators for Discrete Action Spaces",
        "authors": [
            "Daniel Levy",
            "Stefano Ermon"
        ],
        "abstract": "Policy optimization methods have shown great promise in solving complex reinforcement and imitation learning tasks. While model-free methods are broadly applicable, they often require many samples to optimize complex policies. Model-based methods greatly improve sample-efficiency but at the cost of poor generalization, requiring a carefully handcrafted model of the system dynamics for each task. Recently, hybrid methods have been successful in trading off applicability for improved sample-complexity. However, these have been limited to continuous action spaces. In this work, we present a new hybrid method based on an approximation of the dynamics as an expectation over the next state under the current policy. This relaxation allows us to derive a novel hybrid policy gradient estimator, combining score function and pathwise derivative estimators, that is applicable to discrete action spaces. We show significant gains in sample complexity, ranging between $1.7$ and $25\\times$, when learning parameterized policies on Cart Pole, Acrobot, Mountain Car and Hand Mass. Our method is applicable to both discrete and continuous action spaces, when competing pathwise methods are limited to the latter.\n    ",
        "submission_date": "2017-11-21T00:00:00",
        "last_modified_date": "2017-11-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.08101",
        "title": "Asymmetric Action Abstractions for Multi-Unit Control in Adversarial Real-Time Games",
        "authors": [
            "Rubens O. Moraes",
            "Levi H. S. Lelis"
        ],
        "abstract": "Action abstractions restrict the number of legal actions available during search in multi-unit real-time adversarial games, thus allowing algorithms to focus their search on a set of promising actions. Optimal strategies derived from un-abstracted spaces are guaranteed to be no worse than optimal strategies derived from action-abstracted spaces. In practice, however, due to real-time constraints and the state space size, one is only able to derive good strategies in un-abstracted spaces in small-scale games. In this paper we introduce search algorithms that use an action abstraction scheme we call asymmetric abstraction. Asymmetric abstractions retain the un-abstracted spaces' theoretical advantage over regularly abstracted spaces while still allowing the search algorithms to derive effective strategies, even in large-scale games. Empirical results on combat scenarios that arise in a real-time strategy game show that our search algorithms are able to substantially outperform state-of-the-art approaches.\n    ",
        "submission_date": "2017-11-22T00:00:00",
        "last_modified_date": "2017-11-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.08228",
        "title": "An influence-based fast preceding questionnaire model for elderly assessments",
        "authors": [
            "Tong Mo",
            "Rong Zhang",
            "Weiping Li",
            "Jingbo Zhang",
            "Zhonghai Wu",
            "Wei Tan"
        ],
        "abstract": "To improve the efficiency of elderly assessments, an influence-based fast preceding questionnaire model (FPQM) is proposed. Compared with traditional assessments, the FPQM optimizes questionnaires by reordering their attributes. The values of low-ranking attributes can be predicted by the values of the high-ranking attributes. Therefore, the number of attributes can be reduced without redesigning the questionnaires. A new function for calculating the influence of the attributes is proposed based on probability theory. Reordering and reducing algorithms are given based on the attributes' influences. The model is verified through a practical application. The practice in an elderly-care company shows that the FPQM can reduce the number of attributes by 90.56% with a prediction accuracy of 98.39%. Compared with other methods, such as the Expert Knowledge, Rough Set and C4.5 methods, the FPQM achieves the best performance. In addition, the FPQM can also be applied to other questionnaires.\n    ",
        "submission_date": "2017-11-22T00:00:00",
        "last_modified_date": "2017-11-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.08333",
        "title": "A correlational analysis of multiagent sensorimotor interactions: clustering autonomous and controllable entities",
        "authors": [
            "M. S\u00e1nchez-Fibla",
            "C. Moulin-Frier",
            "X. Arsiwalla",
            "P. Verschure"
        ],
        "abstract": "A first step to reach Theory of Mind (ToM) abilities (attribution of beliefs to others) in synthetic agents through sensorimotor interactions, would be to tag sensory data with agent typology and action intentions: autonomous agent X moved an object under the box. We propose a dual arm robotic setup in which ToM could be probed. We then discuss what measures can be extracted from sensorimotor interaction data (based on a correlation analysis) in the proposed setup that allow to distinguish self than other and other/inanimate from other/active with intentions. We finally discuss what elements are missing in current cognitive architectures to be able to acquire ToM abilities in synthetic agents from sensorimotor interactions, bottom-up from reactive agent interaction behaviors and top-down from the optimization of social behaviour and cooperation.\n    ",
        "submission_date": "2017-11-22T00:00:00",
        "last_modified_date": "2017-11-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.08345",
        "title": "Allocation Problems in Ride-Sharing Platforms: Online Matching with Offline Reusable Resources",
        "authors": [
            "John P Dickerson",
            "Karthik A Sankararaman",
            "Aravind Srinivasan",
            "Pan Xu"
        ],
        "abstract": "Bipartite matching markets pair agents on one side of a market with agents, items, or contracts on the opposing side. Prior work addresses online bipartite matching markets, where agents arrive over time and are dynamically matched to a known set of disposable resources. In this paper, we propose a new model, Online Matching with (offline) Reusable Resources under Known Adversarial Distributions (OM-RR-KAD), in which resources on the offline side are reusable instead of disposable; that is, once matched, resources become available again at some point in the future. We show that our model is tractable by presenting an LP-based adaptive algorithm that achieves an online competitive ratio of 1/2 - eps for any given eps greater than 0. We also show that no non-adaptive algorithm can achieve a ratio of 1/2 + o(1) based on the same benchmark LP. Through a data-driven analysis on a massive openly-available dataset, we show our model is robust enough to capture the application of taxi dispatching services and ride-sharing systems. We also present heuristics that perform well in practice.\n    ",
        "submission_date": "2017-11-22T00:00:00",
        "last_modified_date": "2017-12-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.08378",
        "title": "Building Machines that Learn and Think for Themselves: Commentary on Lake et al., Behavioral and Brain Sciences, 2017",
        "authors": [
            "M. Botvinick",
            "D.G.T. Barrett",
            "P. Battaglia",
            "N. de Freitas",
            "D. Kumaran",
            "J. Z Leibo",
            "T. Lillicrap",
            "J. Modayil",
            "S. Mohamed",
            "N.C. Rabinowitz",
            "D. J. Rezende",
            "A. Santoro",
            "T. Schaul",
            "C. Summerfield",
            "G. Wayne",
            "T. Weber",
            "D. Wierstra",
            "S. Legg",
            "D. Hassabis"
        ],
        "abstract": "We agree with Lake and colleagues on their list of key ingredients for building humanlike intelligence, including the idea that model-based reasoning is essential. However, we favor an approach that centers on one additional ingredient: autonomy. In particular, we aim toward agents that can both build and exploit their own internal models, with minimal human hand-engineering. We believe an approach centered on autonomous learning has the greatest chance of success as we scale toward real-world complexity, tackling domains for which ready-made formal models are not available. Here we survey several important examples of the progress that has been made toward building autonomous agents with humanlike abilities, and highlight some outstanding challenges.\n    ",
        "submission_date": "2017-11-22T00:00:00",
        "last_modified_date": "2017-11-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.08819",
        "title": "Improvised Comedy as a Turing Test",
        "authors": [
            "Kory Wallace Mathewson",
            "Piotr Mirowski"
        ],
        "abstract": "The best improvisational theatre actors can make any scene partner, of any skill level or ability, appear talented and proficient in the art form, and thus \"make them shine\". To challenge this improvisational paradigm, we built an artificial intelligence (AI) trained to perform live shows alongside human actors for human audiences. Over the course of 30 performances to a combined audience of almost 3000 people, we have refined theatrical games which involve combinations of human and (at times, adversarial) AI actors. We have developed specific scene structures to include audience participants in interesting ways. Finally, we developed a complete show structure that submitted the audience to a Turing test and observed their suspension of disbelief, which we believe is key for human/non-human theatre co-creation.\n    ",
        "submission_date": "2017-11-23T00:00:00",
        "last_modified_date": "2017-12-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.09048",
        "title": "A Compression-Inspired Framework for Macro Discovery",
        "authors": [
            "Francisco M. Garcia",
            "Bruno C. da Silva",
            "Philip S. Thomas"
        ],
        "abstract": "In this paper we consider the problem of how a reinforcement learning agent tasked with solving a set of related Markov decision processes can use knowledge acquired early in its lifetime to improve its ability to more rapidly solve novel, but related, tasks. One way of exploiting this experience is by identifying recurrent patterns in trajectories obtained from well-performing policies. We propose a three-step framework in which an agent 1) generates a set of candidate open-loop macros by compressing trajectories drawn from near-optimal policies; 2) evaluates the value of each macro; and 3) selects a maximally diverse subset of macros that spans the space of policies typically required for solving the set of related tasks. Our experiments show that extending the original primitive action-set of the agent with the identified macros allows it to more rapidly learn an optimal policy in unseen, but similar MDPs.\n    ",
        "submission_date": "2017-11-24T00:00:00",
        "last_modified_date": "2019-02-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.09057",
        "title": "Cooperative Multi-Agent Planning: A Survey",
        "authors": [
            "Alejandro Torre\u00f1o",
            "Eva Onaindia",
            "Anton\u00edn Komenda",
            "Michal \u0160tolba"
        ],
        "abstract": "Cooperative multi-agent planning (MAP) is a relatively recent research field that combines technologies, algorithms and techniques developed by the Artificial Intelligence Planning and Multi-Agent Systems communities. While planning has been generally treated as a single-agent task, MAP generalizes this concept by considering multiple intelligent agents that work cooperatively to develop a course of action that satisfies the goals of the group.\n",
        "submission_date": "2017-11-24T00:00:00",
        "last_modified_date": "2017-11-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.09142",
        "title": "Cascade Attribute Learning Network",
        "authors": [
            "Zhuo Xu",
            "Haonan Chang",
            "Masayoshi Tomizuka"
        ],
        "abstract": "We propose the cascade attribute learning network (CALNet), which can learn attributes in a control task separately and assemble them together. Our contribution is twofold: first we propose attribute learning in reinforcement learning (RL). Attributes used to be modeled using constraint functions or terms in the objective function, making it hard to transfer. Attribute learning, on the other hand, models these task properties as modules in the policy network. We also propose using novel cascading compensative networks in the CALNet to learn and assemble attributes. Using the CALNet, one can zero shoot an unseen task by separately learning all its attributes, and assembling the attribute modules. We have validated the capacity of our model on a wide variety of control problems with attributes in time, position, velocity and acceleration phases.\n    ",
        "submission_date": "2017-11-24T00:00:00",
        "last_modified_date": "2017-11-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.09186",
        "title": "D numbers theory based game-theoretic framework in adversarial decision making under fuzzy environment",
        "authors": [
            "Xinyang Deng",
            "Wen Jiang"
        ],
        "abstract": "Adversarial decision making is a particular type of decision making problem where the gain a decision maker obtains as a result of his decisions is affected by the actions taken by others. Representation of alternatives' evaluations and methods to find the optimal alternative are two important aspects in the adversarial decision making. The aim of this study is to develop a general framework for solving the adversarial decision making issue under uncertain environment. By combining fuzzy set theory, game theory and D numbers theory (DNT), a DNT based game-theoretic framework for adversarial decision making under fuzzy environment is presented. Within the proposed framework or model, fuzzy set theory is used to model the uncertain evaluations of decision makers to alternatives, the non-exclusiveness among fuzzy evaluations are taken into consideration by using DNT, and the conflict of interests among decision makers is considered in a two-person non-constant sum game theory perspective. An illustrative application is given to demonstrate the effectiveness of the proposed model. This work, on one hand, has developed an effective framework for adversarial decision making under fuzzy environment; One the other hand, it has further improved the basis of DNT as a generalization of Dempster-Shafer theory for uncertainty reasoning.\n    ",
        "submission_date": "2017-11-25T00:00:00",
        "last_modified_date": "2017-11-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.09401",
        "title": "Pedagogical learning",
        "authors": [
            "Long Ouyang",
            "Michael C. Frank"
        ],
        "abstract": "A common assumption in machine learning is that training data are i.i.d. samples from some distribution. Processes that generate i.i.d. samples are, in a sense, uninformative---they produce data without regard to how good this data is for learning. By contrast, cognitive science research has shown that when people generate training data for others (i.e., teaching), they deliberately select examples that are helpful for learning. Because the data is more informative, learning can require less data. Interestingly, such examples are most effective when learners know that the data were pedagogically generated (as opposed to randomly generated). We call this pedagogical learning---when a learner assumes that evidence comes from a helpful teacher. In this work, we ask how pedagogical learning might work for machine learning algorithms. Studying this question requires understanding how people actually teach complex concepts with examples, so we conducted a behavioral study examining how people teach regular expressions using example strings. We found that teachers' examples contain powerful clustering structure that can greatly facilitate learning. We then develop a model of teaching and show a proof of concept that using this model inside of a learner can improve performance.\n    ",
        "submission_date": "2017-11-26T00:00:00",
        "last_modified_date": "2017-11-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.09441",
        "title": "A general unified framework for interval pairwise comparison matrices",
        "authors": [
            "Bice Cavallo",
            "Matteo Brunelli"
        ],
        "abstract": "Interval Pairwise Comparison Matrices have been widely used to account for uncertain statements concerning the preferences of decision makers. Several approaches have been proposed in the literature, such as multiplicative and fuzzy interval matrices. In this paper, we propose a general unified approach to Interval Pairwise Comparison Matrices, based on Abelian linearly ordered groups. In this framework, we generalize some consistency conditions provided for multiplicative and/or fuzzy interval pairwise comparison matrices and provide inclusion relations between them. Then, we provide a concept of distance between intervals that, together with a notion of mean defined over real continuous Abelian linearly ordered groups, allows us to provide a consistency index and an indeterminacy index. In this way, by means of suitable isomorphisms between Abelian linearly ordered groups, we will be able to compare the inconsistency and the indeterminacy of different kinds of Interval Pairwise Comparison Matrices, e.g. multiplicative, additive, and fuzzy, on a unique Cartesian coordinate system.\n    ",
        "submission_date": "2017-11-26T00:00:00",
        "last_modified_date": "2017-11-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.09602",
        "title": "Deep Reinforcement Learning for Sepsis Treatment",
        "authors": [
            "Aniruddh Raghu",
            "Matthieu Komorowski",
            "Imran Ahmed",
            "Leo Celi",
            "Peter Szolovits",
            "Marzyeh Ghassemi"
        ],
        "abstract": "Sepsis is a leading cause of mortality in intensive care units and costs hospitals billions annually. Treating a septic patient is highly challenging, because individual patients respond very differently to medical interventions and there is no universally agreed-upon treatment for sepsis. In this work, we propose an approach to deduce treatment policies for septic patients by using continuous state-space models and deep reinforcement learning. Our model learns clinically interpretable treatment policies, similar in important aspects to the treatment policies of physicians. The learned policies could be used to aid intensive care clinicians in medical decision making and improve the likelihood of patient survival.\n    ",
        "submission_date": "2017-11-27T00:00:00",
        "last_modified_date": "2017-11-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.09744",
        "title": "How linguistic descriptions of data can help to the teaching-learning process in higher education, case of study: artificial intelligence",
        "authors": [
            "Clemente Rubio-Manzano",
            "Tomas Lermanda Senoceain"
        ],
        "abstract": "Artificial Intelligence is a central topic in the computer science curriculum. From the year 2011 a project-based learning methodology based on computer games has been designed and implemented into the intelligence artificial course at the University of the Bio-Bio. The project aims to develop software-controlled agents (bots) which are programmed by using heuristic algorithms seen during the course. This methodology allows us to obtain good learning results, however several challenges have been founded during its implementation.\n",
        "submission_date": "2017-11-27T00:00:00",
        "last_modified_date": "2018-01-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.10046",
        "title": "Recurrent Generative Adversarial Networks for Proximal Learning and Automated Compressive Image Recovery",
        "authors": [
            "Morteza Mardani",
            "Hatef Monajemi",
            "Vardan Papyan",
            "Shreyas Vasanawala",
            "David Donoho",
            "John Pauly"
        ],
        "abstract": "Recovering images from undersampled linear measurements typically leads to an ill-posed linear inverse problem, that asks for proper statistical priors. Building effective priors is however challenged by the low train and test overhead dictated by real-time tasks; and the need for retrieving visually \"plausible\" and physically \"feasible\" images with minimal hallucination. To cope with these challenges, we design a cascaded network architecture that unrolls the proximal gradient iterations by permeating benefits from generative residual networks (ResNet) to modeling the proximal operator. A mixture of pixel-wise and perceptual costs is then deployed to train proximals. The overall architecture resembles back-and-forth projection onto the intersection of feasible and plausible images. Extensive computational experiments are examined for a global task of reconstructing MR images of pediatric patients, and a more local task of superresolving CelebA faces, that are insightful to design efficient architectures. Our observations indicate that for MRI reconstruction, a recurrent ResNet with a single residual block effectively learns the proximal. This simple architecture appears to significantly outperform the alternative deep ResNet architecture by 2dB SNR, and the conventional compressed-sensing MRI by 4dB SNR with 100x faster inference. For image superresolution, our preliminary results indicate that modeling the denoising proximal demands deep ResNets.\n    ",
        "submission_date": "2017-11-27T00:00:00",
        "last_modified_date": "2017-11-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.10055",
        "title": "Risk-sensitive Inverse Reinforcement Learning via Semi- and Non-Parametric Methods",
        "authors": [
            "Sumeet Singh",
            "Jonathan Lacotte",
            "Anirudha Majumdar",
            "Marco Pavone"
        ],
        "abstract": "The literature on Inverse Reinforcement Learning (IRL) typically assumes that humans take actions in order to minimize the expected value of a cost function, i.e., that humans are risk neutral. Yet, in practice, humans are often far from being risk neutral. To fill this gap, the objective of this paper is to devise a framework for risk-sensitive IRL in order to explicitly account for a human's risk sensitivity. To this end, we propose a flexible class of models based on coherent risk measures, which allow us to capture an entire spectrum of risk preferences from risk-neutral to worst-case. We propose efficient non-parametric algorithms based on linear programming and semi-parametric algorithms based on maximum likelihood for inferring a human's underlying risk measure and cost function for a rich class of static and dynamic decision-making settings. The resulting approach is demonstrated on a simulated driving game with ten human participants. Our method is able to infer and mimic a wide range of qualitatively different driving styles from highly risk-averse to risk-neutral in a data-efficient manner. Moreover, comparisons of the Risk-Sensitive (RS) IRL approach with a risk-neutral model show that the RS-IRL framework more accurately captures observed participant behavior both qualitatively and quantitatively, especially in scenarios where catastrophic outcomes such as collisions can occur.\n    ",
        "submission_date": "2017-11-28T00:00:00",
        "last_modified_date": "2018-03-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.10137",
        "title": "One-Shot Reinforcement Learning for Robot Navigation with Interactive Replay",
        "authors": [
            "Jake Bruce",
            "Niko Suenderhauf",
            "Piotr Mirowski",
            "Raia Hadsell",
            "Michael Milford"
        ],
        "abstract": "Recently, model-free reinforcement learning algorithms have been shown to solve challenging problems by learning from extensive interaction with the environment. A significant issue with transferring this success to the robotics domain is that interaction with the real world is costly, but training on limited experience is prone to overfitting. We present a method for learning to navigate, to a fixed goal and in a known environment, on a mobile robot. The robot leverages an interactive world model built from a single traversal of the environment, a pre-trained visual feature encoder, and stochastic environmental augmentation, to demonstrate successful zero-shot transfer under real-world environmental variations without fine-tuning.\n    ",
        "submission_date": "2017-11-28T00:00:00",
        "last_modified_date": "2017-11-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.10177",
        "title": "Gradual Tuning: a better way of Fine Tuning the parameters of a Deep Neural Network",
        "authors": [
            "Guglielmo Montone",
            "J. Kevin O'Regan",
            "Alexander V. Terekhov"
        ],
        "abstract": "In this paper we present an alternative strategy for fine-tuning the parameters of a network. We named the technique Gradual Tuning. Once trained on a first task, the network is fine-tuned on a second task by modifying a progressively larger set of the network's parameters. We test Gradual Tuning on different transfer learning tasks, using networks of different sizes trained with different regularization techniques. The result shows that compared to the usual fine tuning, our approach significantly reduces catastrophic forgetting of the initial task, while still retaining comparable if not better performance on the new task.\n    ",
        "submission_date": "2017-11-28T00:00:00",
        "last_modified_date": "2017-11-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.10185",
        "title": "Hyper-dimensional computing for a visual question-answering system that is trainable end-to-end",
        "authors": [
            "Guglielmo Montone",
            "J. Kevin O'Regan",
            "Alexander V. Terekhov"
        ],
        "abstract": "In this work we propose a system for visual question answering. Our architecture is composed of two parts, the first part creates the logical knowledge base given the image. The second part evaluates questions against the knowledge base. Differently from previous work, the knowledge base is represented using hyper-dimensional computing. This choice has the advantage that all the operations in the system, namely creating the knowledge base and evaluating the questions against it, are differentiable, thereby making the system easily trainable in an end-to-end fashion.\n    ",
        "submission_date": "2017-11-28T00:00:00",
        "last_modified_date": "2017-11-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.10241",
        "title": "The Price of Quota-based Diversity in Assignment Problems",
        "authors": [
            "Nawal Benabbou",
            "Mithun Chakraborty",
            "Vinh Ho Xuan",
            "Jakub Sliwinski",
            "Yair Zick"
        ],
        "abstract": "We introduce and analyze an extension to the matching problem on a weighted bipartite graph: Assignment with Type Constraints. The two parts of the graph are partitioned into subsets called types and blocks; we seek a matching with the largest sum of weights under the constraint that there is a pre-specified cap on the number of vertices matched in every type-block pair. Our primary motivation stems from the public housing program of Singapore, accounting for over 70% of its residential real estate. To promote ethnic diversity within its housing projects, Singapore imposes ethnicity quotas: each new housing development comprises blocks of flats and each ethnicity-based group in the population must not own more than a certain percentage of flats in a block. Other domains using similar hard capacity constraints include matching prospective students to schools or medical residents to hospitals. Limiting agents' choices for ensuring diversity in this manner naturally entails some welfare loss. One of our goals is to study the trade-off between diversity and social welfare in such settings. We first show that, while the classic assignment program is polynomial-time computable, adding diversity constraints makes it computationally intractable; however, we identify a $\\tfrac{1}{2}$-approximation algorithm, as well as reasonable assumptions on the weights that permit poly-time algorithms. Next, we provide two upper bounds on the price of diversity -- a measure of the loss in welfare incurred by imposing diversity constraints -- as functions of natural problem parameters. We conclude the paper with simulations based on publicly available data from two diversity-constrained allocation problems -- Singapore Public Housing and Chicago School Choice -- which shed light on how the constrained maximization as well as lottery-based variants perform in practice.\n    ",
        "submission_date": "2017-11-28T00:00:00",
        "last_modified_date": "2020-10-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.10314",
        "title": "Crossmodal Attentive Skill Learner",
        "authors": [
            "Shayegan Omidshafiei",
            "Dong-Ki Kim",
            "Jason Pazis",
            "Jonathan P. How"
        ],
        "abstract": "This paper presents the Crossmodal Attentive Skill Learner (CASL), integrated with the recently-introduced Asynchronous Advantage Option-Critic (A2OC) architecture [Harb et al., 2017] to enable hierarchical reinforcement learning across multiple sensory inputs. We provide concrete examples where the approach not only improves performance in a single task, but accelerates transfer to new tasks. We demonstrate the attention mechanism anticipates and identifies useful latent features, while filtering irrelevant sensor modalities during execution. We modify the Arcade Learning Environment [Bellemare et al., 2013] to support audio queries, and conduct evaluations of crossmodal learning in the Atari 2600 game Amidar. Finally, building on the recent work of Babaeizadeh et al. [2017], we open-source a fast hybrid CPU-GPU implementation of CASL.\n    ",
        "submission_date": "2017-11-28T00:00:00",
        "last_modified_date": "2018-05-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.10317",
        "title": "Classification of entities via their descriptive sentences",
        "authors": [
            "Chao Zhao",
            "Min Zhao",
            "Yi Guan"
        ],
        "abstract": "Hypernym identification of open-domain entities is crucial for taxonomy construction as well as many higher-level applications. Current methods suffer from either low precision or low recall. To decrease the difficulty of this problem, we adopt a classification-based method. We pre-define a concept taxonomy and classify an entity to one of its leaf concept, based on the name and description information of the entity. A convolutional neural network classifier and a K-means clustering module are adopted for classification. We applied this system to 2.1 million Baidu Baike entities, and 1.1 million of them were successfully identified with a precision of 99.36%.\n    ",
        "submission_date": "2017-11-28T00:00:00",
        "last_modified_date": "2017-11-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.10355",
        "title": "Role of Deep LSTM Neural Networks And WiFi Networks in Support of Occupancy Prediction in Smart Buildings",
        "authors": [
            "Basheer Qolomany",
            "Ala Al-Fuqaha",
            "Driss Benhaddou",
            "Ajay Gupta"
        ],
        "abstract": "Knowing how many people occupy a building, and where they are located, is a key component of smart building services. Commercial, industrial and residential buildings often incorporate systems used to determine occupancy. However, relatively simple sensor technology and control algorithms limit the effectiveness of smart building services. In this paper we propose to replace sensor technology with time series models that can predict the number of occupants at a given location and time. We use Wi-Fi data sets readily available in abundance for smart building services and train Auto Regression Integrating Moving Average (ARIMA) models and Long Short-Term Memory (LSTM) time series models. As a use case scenario of smart building services, these models allow forecasting of the number of people at a given time and location in 15, 30 and 60 minutes time intervals at building as well as Access Point (AP) level. For LSTM, we build our models in two ways: a separate model for every time scale, and a combined model for the three time scales. Our experiments show that LSTM combined model reduced the computational resources with respect to the number of neurons by 74.48 % for the AP level, and by 67.13 % for the building level. Further, the root mean square error (RMSE) was reduced by 88.2% - 93.4% for LSTM in comparison to ARIMA for the building levels models and by 80.9% - 87% for the AP level models.\n    ",
        "submission_date": "2017-11-28T00:00:00",
        "last_modified_date": "2017-11-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.10401",
        "title": "A Modification of Particle Swarm Optimization using Random Walk",
        "authors": [
            "Rajesh Misra",
            "Kumar S. Ray"
        ],
        "abstract": "Particle swarm optimization comes under lot of changes after James Kennedy and Russell Eberhart first proposes the idea in 1995. The changes has been done mainly on Inertia parameters in velocity updating equation so that the convergence rate will be higher. We are proposing a novel approach where particles movement will not be depend on its velocity rather it will be decided by constrained biased random walk of particles. In random walk every particles movement based on two significant parameters, one is random process like toss of a coin and other is how much displacement a particle should have. In our approach we exploit this idea by performing a biased random operation and based on the outcome of that random operation, PSO particles choose the direction of the path and move non-uniformly into the solution space. This constrained, non-uniform movement helps the random walking particle to converge quicker then classical PSO. In our constrained biased random walking approach, we no longer needed velocity term (Vi), rather we introduce a new parameter (K) which is a probabilistic function. No global best particle (PGbest), local best particle (PLbest), Constriction parameter (W) are required rather we use a new term called Ptarg which is loosely influenced by ",
        "submission_date": "2017-11-16T00:00:00",
        "last_modified_date": "2018-02-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.10561",
        "title": "Physics Informed Deep Learning (Part I): Data-driven Solutions of Nonlinear Partial Differential Equations",
        "authors": [
            "Maziar Raissi",
            "Paris Perdikaris",
            "George Em Karniadakis"
        ],
        "abstract": "We introduce physics informed neural networks -- neural networks that are trained to solve supervised learning tasks while respecting any given law of physics described by general nonlinear partial differential equations. In this two part treatise, we present our developments in the context of solving two main classes of problems: data-driven solution and data-driven discovery of partial differential equations. Depending on the nature and arrangement of the available data, we devise two distinct classes of algorithms, namely continuous time and discrete time models. The resulting neural networks form a new class of data-efficient universal function approximators that naturally encode any underlying physical laws as prior information. In this first part, we demonstrate how these networks can be used to infer solutions to partial differential equations, and obtain physics-informed surrogate models that are fully differentiable with respect to all input coordinates and free parameters.\n    ",
        "submission_date": "2017-11-28T00:00:00",
        "last_modified_date": "2017-11-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.10566",
        "title": "Physics Informed Deep Learning (Part II): Data-driven Discovery of Nonlinear Partial Differential Equations",
        "authors": [
            "Maziar Raissi",
            "Paris Perdikaris",
            "George Em Karniadakis"
        ],
        "abstract": "We introduce physics informed neural networks -- neural networks that are trained to solve supervised learning tasks while respecting any given law of physics described by general nonlinear partial differential equations. In this second part of our two-part treatise, we focus on the problem of data-driven discovery of partial differential equations. Depending on whether the available data is scattered in space-time or arranged in fixed temporal snapshots, we introduce two main classes of algorithms, namely continuous time and discrete time models. The effectiveness of our approach is demonstrated using a wide range of benchmark problems in mathematical physics, including conservation laws, incompressible fluid flow, and the propagation of nonlinear shallow-water waves.\n    ",
        "submission_date": "2017-11-28T00:00:00",
        "last_modified_date": "2017-11-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.10574",
        "title": "A reinforcement learning algorithm for building collaboration in multi-agent systems",
        "authors": [
            "Mehmet Emin Aydin",
            "Ryan Fellows"
        ],
        "abstract": "This paper presents a proof-of concept study for demonstrating the viability of building collaboration among multiple agents through standard Q learning algorithm embedded in particle swarm optimisation. Collaboration is formulated to be achieved among the agents via some sort competition, where the agents are expected to balance their action in such a way that none of them drifts away of the team and none intervene any fellow neighbours territory. Particles are devised with Q learning algorithm for self training to learn how to act as members of a swarm and how to produce collaborative/collective behaviours. The produced results are supportive to the algorithmic structures suggesting that a substantive collaboration can be build via proposed learning algorithm.\n    ",
        "submission_date": "2017-11-28T00:00:00",
        "last_modified_date": "2018-04-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.10768",
        "title": "Leveraging Conversation Structure on Social Media to Identify Potentially Influential Users",
        "authors": [
            "Dario De Nart",
            "Dante Degl'Innocenti",
            "Marco Pavan"
        ],
        "abstract": "Social networks have a community providing feedback on comments that allows to identify opinion leaders and users whose positions are unwelcome. Other platforms are not backed by such tools. Having a picture of the community's reactions to a published content is a non trivial problem. In this work we propose a novel approach using Abstract Argumentation Frameworks and machine learning to describe interactions between users. Our experiments provide evidence that modelling the flow of a conversation with the primitives of AAF can support the identification of users who produce consistently appreciated content without modelling such content.\n    ",
        "submission_date": "2017-11-29T00:00:00",
        "last_modified_date": "2017-11-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.10907",
        "title": "Deep Reinforcement Learning for De-Novo Drug Design",
        "authors": [
            "Mariya Popova",
            "Olexandr Isayev",
            "Alexander Tropsha"
        ],
        "abstract": "We propose a novel computational strategy for de novo design of molecules with desired properties termed ReLeaSE (Reinforcement Learning for Structural Evolution). Based on deep and reinforcement learning approaches, ReLeaSE integrates two deep neural networks - generative and predictive - that are trained separately but employed jointly to generate novel targeted chemical libraries. ReLeaSE employs simple representation of molecules by their SMILES strings only. Generative models are trained with stack-augmented memory network to produce chemically feasible SMILES strings, and predictive models are derived to forecast the desired properties of the de novo generated compounds. In the first phase of the method, generative and predictive models are trained separately with a supervised learning algorithm. In the second phase, both models are trained jointly with the reinforcement learning approach to bias the generation of new chemical structures towards those with the desired physical and/or biological properties. In the proof-of-concept study, we have employed the ReLeaSE method to design chemical libraries with a bias toward structural complexity or biased toward compounds with either maximal, minimal, or specific range of physical properties such as melting point or hydrophobicity, as well as to develop novel putative inhibitors of JAK2. The approach proposed herein can find a general use for generating targeted chemical libraries of novel compounds optimized for either a single desired property or multiple properties.\n    ",
        "submission_date": "2017-11-29T00:00:00",
        "last_modified_date": "2018-05-31T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.11017",
        "title": "HoME: a Household Multimodal Environment",
        "authors": [
            "Simon Brodeur",
            "Ethan Perez",
            "Ankesh Anand",
            "Florian Golemo",
            "Luca Celotti",
            "Florian Strub",
            "Jean Rouat",
            "Hugo Larochelle",
            "Aaron Courville"
        ],
        "abstract": "We introduce HoME: a Household Multimodal Environment for artificial agents to learn from vision, audio, semantics, physics, and interaction with objects and other agents, all within a realistic context. HoME integrates over 45,000 diverse 3D house layouts based on the SUNCG dataset, a scale which may facilitate learning, generalization, and transfer. HoME is an open-source, OpenAI Gym-compatible platform extensible to tasks in reinforcement learning, language grounding, sound-based navigation, robotics, multi-agent learning, and more. We hope HoME better enables artificial agents to learn as humans do: in an interactive, multimodal, and richly contextualized setting.\n    ",
        "submission_date": "2017-11-29T00:00:00",
        "last_modified_date": "2017-11-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.11157",
        "title": "A Semantic Loss Function for Deep Learning with Symbolic Knowledge",
        "authors": [
            "Jingyi Xu",
            "Zilu Zhang",
            "Tal Friedman",
            "Yitao Liang",
            "Guy Van den Broeck"
        ],
        "abstract": "This paper develops a novel methodology for using symbolic knowledge in deep learning. From first principles, we derive a semantic loss function that bridges between neural output vectors and logical constraints. This loss function captures how close the neural network is to satisfying the constraints on its output. An experimental evaluation shows that it effectively guides the learner to achieve (near-)state-of-the-art results on semi-supervised multi-class classification. Moreover, it significantly increases the ability of the neural network to predict structured objects, such as rankings and paths. These discrete concepts are tremendously difficult to learn, and benefit from a tight integration of deep learning and symbolic reasoning methods.\n    ",
        "submission_date": "2017-11-29T00:00:00",
        "last_modified_date": "2018-06-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.11175",
        "title": "Towards Data Quality Assessment in Online Advertising",
        "authors": [
            "Sahin Cem Geyik",
            "Jianqiang Shen",
            "Shahriar Shariat",
            "Ali Dasdan",
            "Santanu Kolay"
        ],
        "abstract": "In online advertising, our aim is to match the advertisers with the most relevant users to optimize the campaign performance. In the pursuit of achieving this goal, multiple data sources provided by the advertisers or third-party data providers are utilized to choose the set of users according to the advertisers' targeting criteria. In this paper, we present a framework that can be applied to assess the quality of such data sources in large scale. This framework efficiently evaluates the similarity of a specific data source categorization to that of the ground truth, especially for those cases when the ground truth is accessible only in aggregate, and the user-level information is anonymized or unavailable due to privacy reasons. We propose multiple methodologies within this framework, present some preliminary assessment results, and evaluate how the methodologies compare to each other. We also present two use cases where we can utilize the data quality assessment results: the first use case is targeting specific user categories, and the second one is forecasting the desirable audiences we can reach for an online advertising campaign with pre-set targeting criteria.\n    ",
        "submission_date": "2017-11-30T00:00:00",
        "last_modified_date": "2017-11-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.11180",
        "title": "Improved Learning in Evolution Strategies via Sparser Inter-Agent Network Topologies",
        "authors": [
            "Dhaval Adjodah",
            "Dan Calacci",
            "Yan Leng",
            "Peter Krafft",
            "Esteban Moro",
            "Alex Pentland"
        ],
        "abstract": "We draw upon a previously largely untapped literature on human collective intelligence as a source of inspiration for improving deep learning. Implicit in many algorithms that attempt to solve Deep Reinforcement Learning (DRL) tasks is the network of processors along which parameter values are shared. So far, existing approaches have implicitly utilized fully-connected networks, in which all processors are connected. However, the scientific literature on human collective intelligence suggests that complete networks may not always be the most effective information network structures for distributed search through complex spaces. Here we show that alternative topologies can improve deep neural network training: we find that sparser networks learn higher rewards faster, leading to learning improvements at lower communication costs.\n    ",
        "submission_date": "2017-11-30T00:00:00",
        "last_modified_date": "2019-02-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.11231",
        "title": "Knowledge Graph Embedding with Iterative Guidance from Soft Rules",
        "authors": [
            "Shu Guo",
            "Quan Wang",
            "Lihong Wang",
            "Bin Wang",
            "Li Guo"
        ],
        "abstract": "Embedding knowledge graphs (KGs) into continuous vector spaces is a focus of current research. Combining such an embedding model with logic rules has recently attracted increasing attention. Most previous attempts made a one-time injection of logic rules, ignoring the interactive nature between embedding learning and logical inference. And they focused only on hard rules, which always hold with no exception and usually require extensive manual effort to create or validate. In this paper, we propose Rule-Guided Embedding (RUGE), a novel paradigm of KG embedding with iterative guidance from soft rules. RUGE enables an embedding model to learn simultaneously from 1) labeled triples that have been directly observed in a given KG, 2) unlabeled triples whose labels are going to be predicted iteratively, and 3) soft rules with various confidence levels extracted automatically from the KG. In the learning process, RUGE iteratively queries rules to obtain soft labels for unlabeled triples, and integrates such newly labeled triples to update the embedding model. Through this iterative procedure, knowledge embodied in logic rules may be better transferred into the learned embeddings. We evaluate RUGE in link prediction on Freebase and YAGO. Experimental results show that: 1) with rule knowledge injected iteratively, RUGE achieves significant and consistent improvements over state-of-the-art baselines; and 2) despite their uncertainties, automatically extracted soft rules are highly beneficial to KG embedding, even those with moderate confidence levels. The code and data used for this paper can be obtained from ",
        "submission_date": "2017-11-30T00:00:00",
        "last_modified_date": "2017-11-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.11289",
        "title": "Learning to Compose Skills",
        "authors": [
            "Himanshu Sahni",
            "Saurabh Kumar",
            "Farhan Tejani",
            "Charles Isbell"
        ],
        "abstract": "We present a differentiable framework capable of learning a wide variety of compositions of simple policies that we call skills. By recursively composing skills with themselves, we can create hierarchies that display complex behavior. Skill networks are trained to generate skill-state embeddings that are provided as inputs to a trainable composition function, which in turn outputs a policy for the overall task. Our experiments on an environment consisting of multiple collect and evade tasks show that this architecture is able to quickly build complex skills from simpler ones. Furthermore, the learned composition function displays some transfer to unseen combinations of skills, allowing for zero-shot generalizations.\n    ",
        "submission_date": "2017-11-30T00:00:00",
        "last_modified_date": "2017-11-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.00180",
        "title": "New Techniques for Inferring L-Systems Using Genetic Algorithm",
        "authors": [
            "Jason Bernard",
            "Ian McQuillan"
        ],
        "abstract": "Lindenmayer systems (L-systems) are a formal grammar system that iteratively rewrites all symbols of a string, in parallel. When visualized with a graphical interpretation, the images have self-similar shapes that appear frequently in nature, and they have been particularly successful as a concise, reusable technique for simulating plants. The L-system inference problem is to find an L-system to simulate a given plant. This is currently done mainly by experts, but this process is limited by the availability of experts, the complexity that may be solved by humans, and time. This paper introduces the Plant Model Inference Tool (PMIT) that infers deterministic context-free L-systems from an initial sequence of strings generated by the system using a genetic algorithm. PMIT is able to infer more complex systems than existing approaches. Indeed, while existing approaches are limited to L-systems with a total sum of 20 combined symbols in the productions, PMIT can infer almost all L-systems tested where the total sum is 140 symbols. This was validated using a test bed of 28 previously developed L-system models, in addition to models created artificially by bootstrapping larger models.\n    ",
        "submission_date": "2017-12-01T00:00:00",
        "last_modified_date": "2017-12-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.00222",
        "title": "A double competitive strategy based learning automata algorithm",
        "authors": [
            "Chong Di"
        ],
        "abstract": "Learning Automata (LA) are considered as one of the most powerful tools in the field of reinforcement learning. The family of estimator algorithms is proposed to improve the convergence rate of LA and has made great achievements. However, the estimators perform poorly on estimating the reward probabilities of actions in the initial stage of the learning process of LA. In this situation, a lot of rewards would be added to the probabilities of non-optimal actions. Thus, a large number of extra iterations are needed to compensate for these wrong rewards. In order to improve the speed of convergence, we propose a new P-model absorbing learning automaton by utilizing a double competitive strategy which is designed for updating the action probability vector. In this way, the wrong rewards can be corrected instantly. Hence, the proposed Double Competitive Algorithm overcomes the drawbacks of existing estimator algorithms. A refined analysis is presented to show the $\\epsilon-optimality$ of the proposed scheme. The extensive experimental results in benchmark environments demonstrate that our proposed learning automata perform more efficiently than the most classic LA $SE_{RI}$ and the current fastest LA $DGCPA^{*}$.\n    ",
        "submission_date": "2017-12-01T00:00:00",
        "last_modified_date": "2017-12-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.00428",
        "title": "Novel Exploration Techniques (NETs) for Malaria Policy Interventions",
        "authors": [
            "Oliver Bent",
            "Sekou L. Remy",
            "Stephen Roberts",
            "Aisha Walcott-Bryant"
        ],
        "abstract": "The task of decision-making under uncertainty is daunting, especially for problems which have significant complexity. Healthcare policy makers across the globe are facing problems under challenging constraints, with limited tools to help them make data driven decisions. In this work we frame the process of finding an optimal malaria policy as a stochastic multi-armed bandit problem, and implement three agent based strategies to explore the policy space. We apply a Gaussian Process regression to the findings of each agent, both for comparison and to account for stochastic results from simulating the spread of malaria in a fixed population. The generated policy spaces are compared with published results to give a direct reference with human expert decisions for the same simulated population. Our novel approach provides a powerful resource for policy makers, and a platform which can be readily extended to capture future more nuanced policy spaces.\n    ",
        "submission_date": "2017-12-01T00:00:00",
        "last_modified_date": "2017-12-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.00547",
        "title": "Explainable AI: Beware of Inmates Running the Asylum Or: How I Learnt to Stop Worrying and Love the Social and Behavioural Sciences",
        "authors": [
            "Tim Miller",
            "Piers Howe",
            "Liz Sonenberg"
        ],
        "abstract": "In his seminal book `The Inmates are Running the Asylum: Why High-Tech Products Drive Us Crazy And How To Restore The Sanity' [2004, Sams Indianapolis, IN, USA], Alan Cooper argues that a major reason why software is often poorly designed (from a user perspective) is that programmers are in charge of design decisions, rather than interaction designers. As a result, programmers design software for themselves, rather than for their target audience, a phenomenon he refers to as the `inmates running the asylum'. This paper argues that explainable AI risks a similar fate. While the re-emergence of explainable AI is positive, this paper argues most of us as AI researchers are building explanatory agents for ourselves, rather than for the intended users. But explainable AI is more likely to succeed if researchers and practitioners understand, adopt, implement, and improve models from the vast and valuable bodies of research in philosophy, psychology, and cognitive science, and if evaluation of these models is focused more on people than on technology. From a light scan of literature, we demonstrate that there is considerable scope to infuse more results from the social and behavioural sciences into explainable AI, and present some key results from these fields that are relevant to explainable AI.\n    ",
        "submission_date": "2017-12-02T00:00:00",
        "last_modified_date": "2017-12-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.00576",
        "title": "Interactive Reinforcement Learning for Object Grounding via Self-Talking",
        "authors": [
            "Yan Zhu",
            "Shaoting Zhang",
            "Dimitris Metaxas"
        ],
        "abstract": "Humans are able to identify a referred visual object in a complex scene via a few rounds of natural language communications. Success communication requires both parties to engage and learn to adapt for each other. In this paper, we introduce an interactive training method to improve the natural language conversation system for a visual grounding task. During interactive training, both agents are reinforced by the guidance from a common reward function. The parametrized reward function also cooperatively updates itself via interactions, and contribute to accomplishing the task. We evaluate the method on GuessWhat?! visual grounding task, and significantly improve the task success rate. However, we observe language drifting problem during training and propose to use reward engineering to improve the interpretability for the generated conversations. Our result also indicates evaluating goal-ended visual conversation tasks require semantic relevant metrics beyond task success rate.\n    ",
        "submission_date": "2017-12-02T00:00:00",
        "last_modified_date": "2017-12-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.00646",
        "title": "From knowledge-based to data-driven modeling of fuzzy rule-based systems: A critical reflection",
        "authors": [
            "Eyke H\u00fcllermeier"
        ],
        "abstract": "This paper briefly elaborates on a development in (applied) fuzzy logic that has taken place in the last couple of decades, namely, the complementation or even replacement of the traditional knowledge-based approach to fuzzy rule-based systems design by a data-driven one. It is argued that the classical rule-based modeling paradigm is actually more amenable to the knowledge-based approach, for which it has originally been conceived, while being less apt to data-driven model design. An important reason that prevents fuzzy (rule-based) systems from being leveraged in large-scale applications is the flat structure of rule bases, along with the local nature of fuzzy rules and their limited ability to express complex dependencies between variables. This motivates alternative approaches to fuzzy systems modeling, in which functional dependencies can be represented more flexibly and more compactly in terms of hierarchical structures.\n    ",
        "submission_date": "2017-12-02T00:00:00",
        "last_modified_date": "2017-12-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.00709",
        "title": "Simulated Annealing Algorithm for Graph Coloring",
        "authors": [
            "Alper Kose",
            "Berke Aral Sonmez",
            "Metin Balaban"
        ],
        "abstract": "The goal of this Random Walks project is to code and experiment the Markov Chain Monte Carlo (MCMC) method for the problem of graph coloring. In this report, we present the plots of cost function \\(\\mathbf{H}\\) by varying the parameters like \\(\\mathbf{q}\\) (Number of colors that can be used in coloring) and \\(\\mathbf{c}\\) (Average node degree). The results are obtained by using simulated annealing scheme, where the temperature (inverse of \\(\\mathbf{\\beta}\\)) parameter in the MCMC is lowered progressively.\n    ",
        "submission_date": "2017-12-03T00:00:00",
        "last_modified_date": "2017-12-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.00840",
        "title": "Visual Explanation by High-Level Abduction: On Answer-Set Programming Driven Reasoning about Moving Objects",
        "authors": [
            "Jakob Suchan",
            "Mehul Bhatt",
            "Przemys\u0142aw Wa\u0142\u0119ga",
            "Carl Schultz"
        ],
        "abstract": "We propose a hybrid architecture for systematically computing robust visual explanation(s) encompassing hypothesis formation, belief revision, and default reasoning with video data. The architecture consists of two tightly integrated synergistic components: (1) (functional) answer set programming based abductive reasoning with space-time tracklets as native entities; and (2) a visual processing pipeline for detection based object tracking and motion analysis.\n",
        "submission_date": "2017-12-03T00:00:00",
        "last_modified_date": "2017-12-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.00846",
        "title": "Always Lurking: Understanding and Mitigating Bias in Online Human Trafficking Detection",
        "authors": [
            "Kyle Hundman",
            "Thamme Gowda",
            "Mayank Kejriwal",
            "Benedikt Boecking"
        ],
        "abstract": "Web-based human trafficking activity has increased in recent years but it remains sparsely dispersed among escort advertisements and difficult to identify due to its often-latent nature. The use of intelligent systems to detect trafficking can thus have a direct impact on investigative resource allocation and decision-making, and, more broadly, help curb a widespread social problem. Trafficking detection involves assigning a normalized score to a set of escort advertisements crawled from the Web -- a higher score indicates a greater risk of trafficking-related (involuntary) activities. In this paper, we define and study the problem of trafficking detection and present a trafficking detection pipeline architecture developed over three years of research within the DARPA Memex program. Drawing on multi-institutional data, systems, and experiences collected during this time, we also conduct post hoc bias analyses and present a bias mitigation plan. Our findings show that, while automatic trafficking detection is an important application of AI for social good, it also provides cautionary lessons for deploying predictive machine learning algorithms without appropriate de-biasing. This ultimately led to integration of an interpretable solution into a search system that contains over 100 million advertisements and is used by over 200 law enforcement agencies to investigate leads.\n    ",
        "submission_date": "2017-12-03T00:00:00",
        "last_modified_date": "2017-12-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.00929",
        "title": "SERKET: An Architecture for Connecting Stochastic Models to Realize a Large-Scale Cognitive Model",
        "authors": [
            "Tomoaki Nakamura",
            "Takayuki Nagai",
            "Tadahiro Taniguchi"
        ],
        "abstract": "To realize human-like robot intelligence, a large-scale cognitive architecture is required for robots to understand the environment through a variety of sensors with which they are equipped. In this paper, we propose a novel framework named Serket that enables the construction of a large-scale generative model and its inference easily by connecting sub-modules to allow the robots to acquire various capabilities through interaction with their environments and others. We consider that large-scale cognitive models can be constructed by connecting smaller fundamental models hierarchically while maintaining their programmatic independence. Moreover, connected modules are dependent on each other, and parameters are required to be optimized as a whole. Conventionally, the equations for parameter estimation have to be derived and implemented depending on the models. However, it becomes harder to derive and implement those of a larger scale model. To solve these problems, in this paper, we propose a method for parameter estimation by communicating the minimal parameters between various modules while maintaining their programmatic independence. Therefore, Serket makes it easy to construct large-scale models and estimate their parameters via the connection of modules. Experimental results demonstrated that the model can be constructed by connecting modules, the parameters can be optimized as a whole, and they are comparable with the original models that we have proposed.\n    ",
        "submission_date": "2017-12-04T00:00:00",
        "last_modified_date": "2017-12-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.00948",
        "title": "Learning Multi-Level Hierarchies with Hindsight",
        "authors": [
            "Andrew Levy",
            "George Konidaris",
            "Robert Platt",
            "Kate Saenko"
        ],
        "abstract": "Hierarchical agents have the potential to solve sequential decision making tasks with greater sample efficiency than their non-hierarchical counterparts because hierarchical agents can break down tasks into sets of subtasks that only require short sequences of decisions. In order to realize this potential of faster learning, hierarchical agents need to be able to learn their multiple levels of policies in parallel so these simpler subproblems can be solved simultaneously. Yet, learning multiple levels of policies in parallel is hard because it is inherently unstable: changes in a policy at one level of the hierarchy may cause changes in the transition and reward functions at higher levels in the hierarchy, making it difficult to jointly learn multiple levels of policies. In this paper, we introduce a new Hierarchical Reinforcement Learning (HRL) framework, Hierarchical Actor-Critic (HAC), that can overcome the instability issues that arise when agents try to jointly learn multiple levels of policies. The main idea behind HAC is to train each level of the hierarchy independently of the lower levels by training each level as if the lower level policies are already optimal. We demonstrate experimentally in both grid world and simulated robotics domains that our approach can significantly accelerate learning relative to other non-hierarchical and hierarchical methods. Indeed, our framework is the first to successfully learn 3-level hierarchies in parallel in tasks with continuous state and action spaces.\n    ",
        "submission_date": "2017-12-04T00:00:00",
        "last_modified_date": "2019-09-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.00988",
        "title": "End-to-End Relation Extraction using Markov Logic Networks",
        "authors": [
            "Sachin Pawar",
            "Pushpak Bhattacharya",
            "Girish K. Palshikar"
        ],
        "abstract": "The task of end-to-end relation extraction consists of two sub-tasks: i) identifying entity mentions along with their types and ii) recognizing semantic relations among the entity mention pairs. %Identifying entity mentions along with their types and recognizing semantic relations among the entity mentions, are two very important problems in Information Extraction. It has been shown that for better performance, it is necessary to address these two sub-tasks jointly. We propose an approach for simultaneous extraction of entity mentions and relations in a sentence, by using inference in Markov Logic Networks (MLN). We learn three different classifiers : i) local entity classifier, ii) local relation classifier and iii) \"pipeline\" relation classifier which uses predictions of the local entity classifier. Predictions of these classifiers may be inconsistent with each other. We represent these predictions along with some domain knowledge using weighted first-order logic rules in an MLN and perform joint inference over the MLN to obtain a global output with minimum inconsistencies. Experiments on the ACE (Automatic Content Extraction) 2004 dataset demonstrate that our approach of joint extraction using MLNs outperforms the baselines of individual classifiers. Our end-to-end relation extraction performance is better than 2 out of 3 previous results reported on the ACE 2004 dataset.\n    ",
        "submission_date": "2017-12-04T00:00:00",
        "last_modified_date": "2017-12-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.01093",
        "title": "The mind as a computational system",
        "authors": [
            "Christoph Adami"
        ],
        "abstract": "The present document is an excerpt of an essay that I wrote as part of my application material to graduate school in Computer Science (with a focus on Artificial Intelligence), in 1986. I was not invited by any of the schools that received it, so I became a theoretical physicist instead. The essay's full title was \"Some Topics in Philosophy and Computer Science\". I am making this text (unchanged from 1985, preserving the typesetting as much as possible) available now in memory of Jerry Fodor, whose writings had influenced me significantly at the time (even though I did not always agree).\n    ",
        "submission_date": "2017-12-01T00:00:00",
        "last_modified_date": "2017-12-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.01235",
        "title": "On the Real-time Vehicle Placement Problem",
        "authors": [
            "Abhinav Jauhri",
            "Carlee Joe-Wong",
            "John Paul Shen"
        ],
        "abstract": "Motivated by ride-sharing platforms' efforts to reduce their riders' wait times for a vehicle, this paper introduces a novel problem of placing vehicles to fulfill real-time pickup requests in a spatially and temporally changing environment. The real-time nature of this problem makes it fundamentally different from other placement and scheduling problems, as it requires not only real-time placement decisions but also handling real-time request dynamics, which are influenced by human mobility patterns. We use a dataset of ten million ride requests from four major U.S. cities to show that the requests exhibit significant self-similarity. We then propose distributed online learning algorithms for the real-time vehicle placement problem and bound their expected performance under this observed self-similarity.\n    ",
        "submission_date": "2017-12-04T00:00:00",
        "last_modified_date": "2017-12-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.01328",
        "title": "Learning User Intent from Action Sequences on Interactive Systems",
        "authors": [
            "Rakshit Agrawal",
            "Anwar Habeeb",
            "Chih-Hsin Hsueh"
        ],
        "abstract": "Interactive systems have taken over the web and mobile space with increasing participation from users. Applications across every marketing domain can now be accessed through mobile or web where users can directly perform certain actions and reach a desired outcome. Actions of user on a system, though, can be representative of a certain intent. Ability to learn this intent through user's actions can help draw certain insight into the behavior of users on a system.\n",
        "submission_date": "2017-12-04T00:00:00",
        "last_modified_date": "2017-12-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.01455",
        "title": "Multimodal Storytelling via Generative Adversarial Imitation Learning",
        "authors": [
            "Zhiqian Chen",
            "Xuchao Zhang",
            "Arnold P. Boedihardjo",
            "Jing Dai",
            "Chang-Tien Lu"
        ],
        "abstract": "Deriving event storylines is an effective summarization method to succinctly organize extensive information, which can significantly alleviate the pain of information overload. The critical challenge is the lack of widely recognized definition of storyline metric. Prior studies have developed various approaches based on different assumptions about users' interests. These works can extract interesting patterns, but their assumptions do not guarantee that the derived patterns will match users' preference. On the other hand, their exclusiveness of single modality source misses cross-modality information. This paper proposes a method, multimodal imitation learning via generative adversarial networks(MIL-GAN), to directly model users' interests as reflected by various data. In particular, the proposed model addresses the critical challenge by imitating users' demonstrated storylines. Our proposed model is designed to learn the reward patterns given user-provided storylines and then applies the learned policy to unseen data. The proposed approach is demonstrated to be capable of acquiring the user's implicit intent and outperforming competing methods by a substantial margin with a user study.\n    ",
        "submission_date": "2017-12-05T00:00:00",
        "last_modified_date": "2017-12-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.01626",
        "title": "Autonomous development and learning in artificial intelligence and robotics: Scaling up deep learning to human--like learning",
        "authors": [
            "Pierre-Yves Oudeyer"
        ],
        "abstract": "Autonomous lifelong development and learning is a fundamental capability of humans, differentiating them from current deep learning systems. However, other branches of artificial intelligence have designed crucial ingredients towards autonomous learning: curiosity and intrinsic motivation, social learning and natural interaction with peers, and embodiment. These mechanisms guide exploration and autonomous choice of goals, and integrating them with deep learning opens stimulating perspectives. Deep learning (DL) approaches made great advances in artificial intelligence, but are still far away from human learning. As argued convincingly by Lake et al., differences include human capabilities to learn causal models of the world from very little data, leveraging compositional representations and priors like intuitive physics and psychology. However, there are other fundamental differences between current DL systems and human learning, as well as technical ingredients to fill this gap, that are either superficially, or not adequately, discussed by Lake et al. These fundamental mechanisms relate to autonomous development and learning. They are bound to play a central role in artificial intelligence in the future. Current DL systems require engineers to manually specify a task-specific objective function for every new task, and learn through off-line processing of large training databases. On the contrary, humans learn autonomously open-ended repertoires of skills, deciding for themselves which goals to pursue or value, and which skills to explore, driven by intrinsic motivation/curiosity and social learning through natural interaction with peers. Such learning processes are incremental, online, and progressive. Human child development involves a progressive increase of complexity in a curriculum of learning where skills are explored, acquired, and built on each other, through particular ordering and timing. Finally, human learning happens in the physical world, and through bodily and physical experimentation, under severe constraints on energy, time, and computational resources. In the two last decades, the field of Developmental and Cognitive Robotics (Cangelosi and Schlesinger, 2015, Asada et al., 2009), in strong interaction with developmental psychology and neuroscience, has achieved significant advances in computational\n    ",
        "submission_date": "2017-12-05T00:00:00",
        "last_modified_date": "2017-12-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.01815",
        "title": "Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm",
        "authors": [
            "David Silver",
            "Thomas Hubert",
            "Julian Schrittwieser",
            "Ioannis Antonoglou",
            "Matthew Lai",
            "Arthur Guez",
            "Marc Lanctot",
            "Laurent Sifre",
            "Dharshan Kumaran",
            "Thore Graepel",
            "Timothy Lillicrap",
            "Karen Simonyan",
            "Demis Hassabis"
        ],
        "abstract": "The game of chess is the most widely-studied domain in the history of artificial intelligence. The strongest programs are based on a combination of sophisticated search techniques, domain-specific adaptations, and handcrafted evaluation functions that have been refined by human experts over several decades. In contrast, the AlphaGo Zero program recently achieved superhuman performance in the game of Go, by tabula rasa reinforcement learning from games of self-play. In this paper, we generalise this approach into a single AlphaZero algorithm that can achieve, tabula rasa, superhuman performance in many challenging domains. Starting from random play, and given no domain knowledge except the game rules, AlphaZero achieved within 24 hours a superhuman level of play in the games of chess and shogi (Japanese chess) as well as Go, and convincingly defeated a world-champion program in each case.\n    ",
        "submission_date": "2017-12-05T00:00:00",
        "last_modified_date": "2017-12-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.01949",
        "title": "Recognizing Plans by Learning Embeddings from Observed Action Distributions",
        "authors": [
            "Yantian Zha",
            "Yikang Li",
            "Sriram Gopalakrishnan",
            "Baoxin Li",
            "Subbarao Kambhampati"
        ],
        "abstract": "Recent advances in visual activity recognition have raised the possibility of applications such as automated video surveillance. Effective approaches for such problems however require the ability to recognize the plans of agents from video information. Although traditional plan recognition algorithms depend on access to sophisticated planning domain models, one recent promising direction involves learning approximated (or shallow) domain models directly from the observed activity sequences DUP. One limitation is that such approaches expect observed action sequences as inputs. In many cases involving vision/sensing from raw data, there is considerable uncertainty about the specific action at any given time point. The most we can expect in such cases is probabilistic information about the action at that point. The input will then be sequences of such observed action distributions. In this work, we address the problem of constructing an effective data-interface that allows a plan recognition module to directly handle such observation distributions. Such an interface works like a bridge between the low-level perception module, and the high-level plan recognition module. We propose two approaches. The first involves resampling the distribution sequences to single action sequences, from which we could learn an action affinity model based on learned action (word) embeddings for plan recognition. The second is to directly learn action distribution embeddings by our proposed Distr2vec (distribution to vector) model, to construct an affinity model for plan recognition.\n    ",
        "submission_date": "2017-12-05T00:00:00",
        "last_modified_date": "2018-11-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.02838",
        "title": "End-to-End Offline Goal-Oriented Dialog Policy Learning via Policy Gradient",
        "authors": [
            "Li Zhou",
            "Kevin Small",
            "Oleg Rokhlenko",
            "Charles Elkan"
        ],
        "abstract": "Learning a goal-oriented dialog policy is generally performed offline with supervised learning algorithms or online with reinforcement learning (RL). Additionally, as companies accumulate massive quantities of dialog transcripts between customers and trained human agents, encoder-decoder methods have gained popularity as agent utterances can be directly treated as supervision without the need for utterance-level annotations. However, one potential drawback of such approaches is that they myopically generate the next agent utterance without regard for dialog-level considerations. To resolve this concern, this paper describes an offline RL method for learning from unannotated corpora that can optimize a goal-oriented policy at both the utterance and dialog level. We introduce a novel reward function and use both on-policy and off-policy policy gradient to learn a policy offline without requiring online user interaction or an explicit state space definition.\n    ",
        "submission_date": "2017-12-07T00:00:00",
        "last_modified_date": "2017-12-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.02869",
        "title": "Perspectival Knowledge in PSOA RuleML: Representation, Model Theory, and Translation",
        "authors": [
            "Harold Boley",
            "Gen Zou"
        ],
        "abstract": "In Positional-Slotted Object-Applicative (PSOA) RuleML, a predicate application (atom) can have an Object IDentifier (OID) and descriptors that may be positional arguments (tuples) or attribute-value pairs (slots). PSOA RuleML explicitly specifies for each descriptor whether it is to be interpreted under the perspective of the predicate in whose scope it occurs. This predicate-dependency dimension refines the space between oidless, positional atoms (relationships) and oidful, slotted atoms (framepoints): While relationships use only a predicate-scope-sensitive (predicate-dependent) tuple and framepoints use only predicate-scope-insensitive (predicate-independent) slots, PSOA uses a systematics of orthogonal constructs also permitting atoms with (predicate-)independent tuples and atoms with (predicate-)dependent slots. This supports data and knowledge representation where a slot attribute can have different values depending on the predicate. PSOA thus extends object-oriented multi-membership and multiple inheritance. Based on objectification, PSOA laws are given: Besides unscoping and centralization, the semantic restriction and transformation of describution permits rescoping of one atom's independent descriptors to another atom with the same OID but a different predicate. For inheritance, default descriptors are realized by rules. On top of a metamodel and a Grailog visualization, PSOA's atom systematics for facts, queries, and rules is explained. The presentation and (XML-)serialization syntaxes of PSOA RuleML are introduced. Its model-theoretic semantics is formalized by extending the interpretation functions for dependent descriptors. The open-source PSOATransRun system realizes PSOA RuleML by a translator to runtime predicates, including for dependent tuples (prdtupterm) and slots (prdsloterm). Our tests show efficiency advantages of dependent and tupled modeling.\n    ",
        "submission_date": "2017-12-07T00:00:00",
        "last_modified_date": "2019-07-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.02975",
        "title": "Recruitment Market Trend Analysis with Sequential Latent Variable Models",
        "authors": [
            "Chen Zhu",
            "Hengshu Zhu",
            "Hui Xiong",
            "Pengliang Ding",
            "Fang Xie"
        ],
        "abstract": "Recruitment market analysis provides valuable understanding of industry-specific economic growth and plays an important role for both employers and job seekers. With the rapid development of online recruitment services, massive recruitment data have been accumulated and enable a new paradigm for recruitment market analysis. However, traditional methods for recruitment market analysis largely rely on the knowledge of domain experts and classic statistical models, which are usually too general to model large-scale dynamic recruitment data, and have difficulties to capture the fine-grained market trends. To this end, in this paper, we propose a new research paradigm for recruitment market analysis by leveraging unsupervised learning techniques for automatically discovering recruitment market trends based on large-scale recruitment data. Specifically, we develop a novel sequential latent variable model, named MTLVM, which is designed for capturing the sequential dependencies of corporate recruitment states and is able to automatically learn the latent recruitment topics within a Bayesian generative framework. In particular, to capture the variability of recruitment topics over time, we design hierarchical dirichlet processes for MTLVM. These processes allow to dynamically generate the evolving recruitment topics. Finally, we implement a prototype system to empirically evaluate our approach based on real-world recruitment data in China. Indeed, by visualizing the results from MTLVM, we can successfully reveal many interesting findings, such as the popularity of LBS related jobs reached the peak in the 2nd half of 2014, and decreased in 2015.\n    ",
        "submission_date": "2017-12-08T00:00:00",
        "last_modified_date": "2017-12-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.03043",
        "title": "A Heuristic Search Algorithm Using the Stability of Learning Algorithms in Certain Scenarios as the Fitness Function: An Artificial General Intelligence Engineering Approach",
        "authors": [
            "Zengkun Li"
        ],
        "abstract": "This paper presents a non-manual design engineering method based on heuristic search algorithm to search for candidate agents in the solution space which formed by artificial intelligence agents modeled on the base of ",
        "submission_date": "2017-12-08T00:00:00",
        "last_modified_date": "2018-07-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.03223",
        "title": "S-Shaped vs. V-Shaped Transfer Functions for Antlion Optimization Algorithm in Feature Selection Problems",
        "authors": [
            "Majdi Mafarja",
            "Seyedali Mirjalili"
        ],
        "abstract": "Feature selection is an important preprocessing step for classification problems. It deals with selecting near optimal features in the original dataset. Feature selection is an NP-hard problem, so meta-heuristics can be more efficient than exact methods. In this work, Ant Lion Optimizer (ALO), which is a recent metaheuristic algorithm, is employed as a wrapper feature selection method. Six variants of ALO are proposed where each employ a transfer function to map a continuous search space to a discrete search space. The performance of the proposed approaches is tested on eighteen UCI datasets and compared to a number of existing approaches in the literature: Particle Swarm Optimization, Gravitational Search Algorithm, and two existing ALO-based approaches. Computational experiments show that the proposed approaches efficiently explore the feature space and select the most informative features, which help to improve the classification accuracy.\n    ",
        "submission_date": "2017-12-06T00:00:00",
        "last_modified_date": "2017-12-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.03249",
        "title": "Social Emotion Mining Techniques for Facebook Posts Reaction Prediction",
        "authors": [
            "Florian Krebs",
            "Bruno Lubascher",
            "Tobias Moers",
            "Pieter Schaap",
            "Gerasimos Spanakis"
        ],
        "abstract": "As of February 2016 Facebook allows users to express their experienced emotions about a post by using five so-called `reactions'. This research paper proposes and evaluates alternative methods for predicting these reactions to user posts on public pages of firms/companies (like supermarket chains). For this purpose, we collected posts (and their reactions) from Facebook pages of large supermarket chains and constructed a dataset which is available for other researches. In order to predict the distribution of reactions of a new post, neural network architectures (convolutional and recurrent neural networks) were tested using pretrained word embeddings. Results of the neural networks were improved by introducing a bootstrapping approach for sentiment and emotion mining on the comments for each post. The final model (a combination of neural network and a baseline emotion miner) is able to predict the reaction distribution on Facebook posts with a mean squared error (or misclassification rate) of 0.135.\n    ",
        "submission_date": "2017-12-08T00:00:00",
        "last_modified_date": "2017-12-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.03280",
        "title": "Nintendo Super Smash Bros. Melee: An \"Untouchable\" Agent",
        "authors": [
            "Ben Parr",
            "Deepak Dilipkumar",
            "Yuan Liu"
        ],
        "abstract": "Nintendo's Super Smash Bros. Melee fighting game can be emulated on modern hardware allowing us to inspect internal memory states, such as character positions. We created an AI that avoids being hit by training using these internal memory states and outputting controller button presses. After training on a month's worth of Melee matches, our best agent learned to avoid the toughest AI built into the game for a full minute 74.6% of the time.\n    ",
        "submission_date": "2017-12-08T00:00:00",
        "last_modified_date": "2017-12-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.04020",
        "title": "Detecting Qualia in Natural and Artificial Agents",
        "authors": [
            "Roman V. Yampolskiy"
        ],
        "abstract": "The Hard Problem of consciousness has been dismissed as an illusion. By showing that computers are capable of experiencing, we show that they are at least rudimentarily conscious with potential to eventually reach superconsciousness. The main contribution of the paper is a test for confirming certain subjective experiences in a tested agent. We follow with analysis of benefits and problems with conscious machines and implications of such capability on future of computing, machine rights and artificial intelligence safety.\n    ",
        "submission_date": "2017-12-11T00:00:00",
        "last_modified_date": "2017-12-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.04065",
        "title": "The Eigenoption-Critic Framework",
        "authors": [
            "Miao Liu",
            "Marlos C. Machado",
            "Gerald Tesauro",
            "Murray Campbell"
        ],
        "abstract": "Eigenoptions (EOs) have been recently introduced as a promising idea for generating a diverse set of options through the graph Laplacian, having been shown to allow efficient exploration. Despite its initial promising results, a couple of issues in current algorithms limit its application, namely: (1) EO methods require two separate steps (eigenoption discovery and reward maximization) to learn a control policy, which can incur a significant amount of storage and computation; (2) EOs are only defined for problems with discrete state-spaces and; (3) it is not easy to take the environment's reward function into consideration when discovering EOs. To addresses these issues, we introduce an algorithm termed eigenoption-critic (EOC) based on the Option-critic (OC) framework [Bacon17], a general hierarchical reinforcement learning (RL) algorithm that allows learning the intra-option policies simultaneously with the policy over options. We also propose a generalization of EOC to problems with continuous state-spaces through the Nystr\u00f6m approximation. EOC can also be seen as extending OC to nonstationary settings, where the discovered options are not tailored for a single task.\n    ",
        "submission_date": "2017-12-11T00:00:00",
        "last_modified_date": "2017-12-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.04155",
        "title": "Toward `verifying' a Water Treatment System",
        "authors": [
            "Jingyi Wang",
            "Jun Sun",
            "Yifan Jia",
            "Shengchao Qin",
            "Zhiwu Xu"
        ],
        "abstract": "Modeling and verifying real-world cyber-physical systems is challenging, which is especially so for complex systems where manually modeling is infeasible. In this work, we report our experience on combining model learning and abstraction refinement to analyze a challenging system, i.e., a real-world Secure Water Treatment system (SWaT). Given a set of safety requirements, the objective is to either show that the system is safe with a high probability (so that a system shutdown is rarely triggered due to safety violation) or not. As the system is too complicated to be manually modeled, we apply latest automatic model learning techniques to construct a set of Markov chains through abstraction and refinement, based on two long system execution logs (one for training and the other for testing). For each probabilistic safety property, we either report it does not hold with a certain level of probabilistic confidence, or report that it holds by showing the evidence in the form of an abstract Markov chain. The Markov chains can subsequently be implemented as runtime monitors in SWaT.\n    ",
        "submission_date": "2017-12-12T00:00:00",
        "last_modified_date": "2018-05-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.04170",
        "title": "Interpretable Policies for Reinforcement Learning by Genetic Programming",
        "authors": [
            "Daniel Hein",
            "Steffen Udluft",
            "Thomas A. Runkler"
        ],
        "abstract": "The search for interpretable reinforcement learning policies is of high academic and industrial interest. Especially for industrial systems, domain experts are more likely to deploy autonomously learned controllers if they are understandable and convenient to evaluate. Basic algebraic equations are supposed to meet these requirements, as long as they are restricted to an adequate complexity. Here we introduce the genetic programming for reinforcement learning (GPRL) approach based on model-based batch reinforcement learning and genetic programming, which autonomously learns policy equations from pre-existing default state-action trajectory samples. GPRL is compared to a straight-forward method which utilizes genetic programming for symbolic regression, yielding policies imitating an existing well-performing, but non-interpretable policy. Experiments on three reinforcement learning benchmarks, i.e., mountain car, cart-pole balancing, and industrial benchmark, demonstrate the superiority of our GPRL approach compared to the symbolic regression method. GPRL is capable of producing well-performing interpretable reinforcement learning policies from pre-existing default trajectory data.\n    ",
        "submission_date": "2017-12-12T00:00:00",
        "last_modified_date": "2018-04-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.04172",
        "title": "A Low-Cost Ethics Shaping Approach for Designing Reinforcement Learning Agents",
        "authors": [
            "Yueh-Hua Wu",
            "Shou-De Lin"
        ],
        "abstract": "This paper proposes a low-cost, easily realizable strategy to equip a reinforcement learning (RL) agent the capability of behaving ethically. Our model allows the designers of RL agents to solely focus on the task to achieve, without having to worry about the implementation of multiple trivial ethical patterns to follow. Based on the assumption that the majority of human behavior, regardless which goals they are achieving, is ethical, our design integrates human policy with the RL policy to achieve the target objective with less chance of violating the ethical code that human beings normally obey.\n    ",
        "submission_date": "2017-12-12T00:00:00",
        "last_modified_date": "2018-09-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.04182",
        "title": "A Generic Model for Swarm Intelligence and Its Validations",
        "authors": [
            "Wenpin Jiao"
        ],
        "abstract": "The modeling of emergent swarm intelligence constitutes a major challenge and it has been tackled in a number of different ways. However, existing approaches fail to capture the nature of swarm intelligence and they are either too abstract for practical application or not generic enough to describe the various types of emergence phenomena. In this paper, a contradiction-centric model for swarm intelligence is proposed, in which individu-als determine their behaviors based on their internal contradictions whilst they associate and interact to update their contradictions. The model hypothesizes that 1) the emergence of swarm intelligence is rooted in the de-velopment of individuals' internal contradictions and the interactions taking place between individuals and the environment, and 2) swarm intelligence is essentially a combinative reflection of the configurations of individuals' internal contradictions and the distributions of these contradictions across individuals. The model is formally described and five swarm intelligence systems are studied to illustrate its broad applicability. The studies confirm the generic character of the model and its effectiveness for describing the emergence of various kinds of swarm intelligence; and they also demonstrate that the model is straightforward to apply, without the need for complicated computations.\n    ",
        "submission_date": "2017-12-12T00:00:00",
        "last_modified_date": "2025-01-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.04306",
        "title": "In folly ripe. In reason rotten. Putting machine theology to rest",
        "authors": [
            "Mihai Nadin"
        ],
        "abstract": "Computation has changed the world more than any previous expressions of knowledge. In its particular algorithmic embodiment, it offers a perspective, within which the digital computer (one of many possible) exercises a role reminiscent of theology. Since it is closed to meaning, algorithmic digital computation can at most mimic the creative aspects of life. AI, in the perspective of time, proved to be less an acronym for artificial intelligence and more of automating tasks associated with intelligence. The entire development led to the hypostatized role of the machine: outputting nothing else but reality, including that of the humanity that made the machine happen. The convergence machine called deep learning is only the latest form through which the deterministic theology of the machine claims more than what extremely effective data processing actually is. A new understanding of complexity, as well as the need to distinguish between the reactive nature of the artificial and the anticipatory nature of the living are suggested as practical responses to the challenges posed by machine theology.\n    ",
        "submission_date": "2017-12-03T00:00:00",
        "last_modified_date": "2017-12-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.04307",
        "title": "AI Safety and Reproducibility: Establishing Robust Foundations for the Neuropsychology of Human Values",
        "authors": [
            "Gopal P. Sarma",
            "Nick J. Hay",
            "Adam Safron"
        ],
        "abstract": "We propose the creation of a systematic effort to identify and replicate key findings in neuropsychology and allied fields related to understanding human values. Our aim is to ensure that research underpinning the value alignment problem of artificial intelligence has been sufficiently validated to play a role in the design of AI systems.\n    ",
        "submission_date": "2017-12-08T00:00:00",
        "last_modified_date": "2018-09-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.04363",
        "title": "Simulated Autonomous Driving on Realistic Road Networks using Deep Reinforcement Learning",
        "authors": [
            "Patrick Klose",
            "Rudolf Mester"
        ],
        "abstract": "Using Deep Reinforcement Learning (DRL) can be a promising approach to handle various tasks in the field of (simulated) autonomous driving. However, recent publications mainly consider learning in unusual driving environments. This paper presents Driving School for Autonomous Agents (DSA^2), a software for validating DRL algorithms in more usual driving environments based on artificial and realistic road networks. We also present the results of applying DSA^2 for handling the task of driving on a straight road while regulating the velocity of one vehicle according to different speed limits.\n    ",
        "submission_date": "2017-12-12T00:00:00",
        "last_modified_date": "2018-04-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.04415",
        "title": "Deception Detection in Videos",
        "authors": [
            "Zhe Wu",
            "Bharat Singh",
            "Larry S. Davis",
            "V. S. Subrahmanian"
        ],
        "abstract": "We present a system for covert automated deception detection in real-life courtroom trial videos. We study the importance of different modalities like vision, audio and text for this task. On the vision side, our system uses classifiers trained on low level video features which predict human micro-expressions. We show that predictions of high-level micro-expressions can be used as features for deception prediction. Surprisingly, IDT (Improved Dense Trajectory) features which have been widely used for action recognition, are also very good at predicting deception in videos. We fuse the score of classifiers trained on IDT features and high-level micro-expressions to improve performance. MFCC (Mel-frequency Cepstral Coefficients) features from the audio domain also provide a significant boost in performance, while information from transcripts is not very beneficial for our system. Using various classifiers, our automated system obtains an AUC of 0.877 (10-fold cross-validation) when evaluated on subjects which were not part of the training set. Even though state-of-the-art methods use human annotations of micro-expressions for deception detection, our fully automated approach outperforms them by 5%. When combined with human annotations of micro-expressions, our AUC improves to 0.922. We also present results of a user-study to analyze how well do average humans perform on this task, what modalities they use for deception detection and how they perform if only one modality is accessible. Our project page can be found at \\url{",
        "submission_date": "2017-12-12T00:00:00",
        "last_modified_date": "2017-12-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.04596",
        "title": "Consideration on Example 2 of \"An Algorithm of General Fuzzy InferenceWith The Reductive Property\"",
        "authors": [
            "Son-Il Kwak",
            "Oh-Chol Gwon",
            "Chung-Jin Kwak"
        ],
        "abstract": "In this paper, we will show that (1) the results about the fuzzy reasoning algoritm obtained in the paper \"Computer Sciences Vol. 34, No.4, pp.145-148, 2007\" according to the paper \"IEEE Transactions On systems, Man and cybernetics, 18, pp.1049-1056, 1988\" are correct; (2) example 2 in the paper \"An Algorithm of General Fuzzy Inference With The Reductive Property\" presented by He Ying-Si, Quan Hai-Jin and Deng Hui-Wen according to the paper \"An approximate analogical reasoning approach based on similarity measures\" presented by Tursken I.B. and Zhong zhao is incorrect; (3) the mistakes in their paper are modified and then a calculation example of FMT is supplemented.\n    ",
        "submission_date": "2017-12-13T00:00:00",
        "last_modified_date": "2017-12-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.04909",
        "title": "Reasoning in Systems with Elements that Randomly Switch Characteristics",
        "authors": [
            "Subhash Kak"
        ],
        "abstract": "We examine the issue of stability of probability in reasoning about complex systems with uncertainty in structure. Normally, propositions are viewed as probability functions on an abstract random graph where it is implicitly assumed that the nodes of the graph have stable properties. But what if some of the nodes change their characteristics? This is a situation that cannot be covered by abstractions of either static or dynamic sets when these changes take place at regular intervals. We propose the use of sets with elements that change, and modular forms are proposed to account for one type of such change. An expression for the dependence of the mean on the probability of the switching elements has been determined. The system is also analyzed from the perspective of decision between different hypotheses. Such sets are likely to be of use in complex system queries and in analysis of surveys.\n    ",
        "submission_date": "2017-12-13T00:00:00",
        "last_modified_date": "2017-12-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.05247",
        "title": "Intrinsic Point of Interest Discovery from Trajectory Data",
        "authors": [
            "Matthew Piekenbrock",
            "Derek Doran"
        ],
        "abstract": "This paper presents a framework for intrinsic point of interest discovery from trajectory databases. Intrinsic points of interest are regions of a geospatial area innately defined by the spatial and temporal aspects of trajectory data, and can be of varying size, shape, and resolution. Any trajectory database exhibits such points of interest, and hence are intrinsic, as compared to most other point of interest definitions which are said to be extrinsic, as they require trajectory metadata, external knowledge about the region the trajectories are observed, or other application-specific information. Spatial and temporal aspects are qualities of any trajectory database, making the framework applicable to data from any domain and of any resolution. The framework is developed under recent developments on the consistency of nonparametric hierarchical density estimators and enables the possibility of formal statistical inference and evaluation over such intrinsic points of interest. Comparisons of the POIs uncovered by the framework in synthetic truth data to thousands of parameter settings for common POI discovery methods show a marked improvement in fidelity without the need to tune any parameters by hand.\n    ",
        "submission_date": "2017-12-14T00:00:00",
        "last_modified_date": "2017-12-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.05302",
        "title": "Constraint and Mathematical Programming Models for Integrated Port Container Terminal Operations",
        "authors": [
            "Damla Kizilay",
            "Deniz T. Eliiyi",
            "Pascal Van Hentenryck"
        ],
        "abstract": "This paper considers the integrated problem of quay crane assignment, quay crane scheduling, yard location assignment, and vehicle dispatching operations at a container terminal. The main objective is to minimize vessel turnover times and maximize the terminal throughput, which are key economic drivers in terminal operations. Due to their computational complexities, these problems are not optimized jointly in existing work. This paper revisits this limitation and proposes Mixed Integer Programming (MIP) and Constraint Programming (CP) models for the integrated problem, under some realistic assumptions. Experimental results show that the MIP formulation can only solve small instances, while the CP model finds optimal solutions in reasonable times for realistic instances derived from actual container terminal operations.\n    ",
        "submission_date": "2017-12-14T00:00:00",
        "last_modified_date": "2017-12-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.05497",
        "title": "What Can This Robot Do? Learning from Appearance and Experiments",
        "authors": [
            "Ashwin Khadke",
            "Manuela Veloso"
        ],
        "abstract": "When presented with an unknown robot (subject) how can an autonomous agent (learner) figure out what this new robot can do? The subject's appearance can provide cues to its physical as well as cognitive capabilities. Seeing a humanoid can make one wonder if it can kick balls, climb stairs or recognize faces. What if the learner can request the subject to perform these tasks? We present an approach to make the learner build a model of the subject at a task based on the latter's appearance and refine it by experimentation. Apart from the subject's inherent capabilities, certain extrinsic factors may affect its performance at a task. Based on the subject's appearance and prior knowledge about the task a learner can identify a set of potential factors, a subset of which we assume are controllable. Our approach picks values of controllable factors to generate the most informative experiments to test the subject at. Additionally, we present a metric to determine if a factor should be incorporated in the model. We present results of our approach on modeling a humanoid robot at the task of kicking a ball. Firstly, we show that actively picking values for controllable factors, even in noisy experiments, leads to faster learning of the subject's model for the task. Secondly, starting from a minimal set of factors our metric identifies the set of relevant factors to incorporate in the model. Lastly, we show that the refined model better represents the subject's performance at the task.\n    ",
        "submission_date": "2017-12-15T00:00:00",
        "last_modified_date": "2018-08-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.05514",
        "title": "Inverse Reinforce Learning with Nonparametric Behavior Clustering",
        "authors": [
            "Siddharthan Rajasekaran",
            "Jinwei Zhang",
            "Jie Fu"
        ],
        "abstract": "Inverse Reinforcement Learning (IRL) is the task of learning a single reward function given a Markov Decision Process (MDP) without defining the reward function, and a set of demonstrations generated by humans/experts. However, in practice, it may be unreasonable to assume that human behaviors can be explained by one reward function since they may be inherently inconsistent. Also, demonstrations may be collected from various users and aggregated to infer and predict user's behaviors. In this paper, we introduce the Non-parametric Behavior Clustering IRL algorithm to simultaneously cluster demonstrations and learn multiple reward functions from demonstrations that may be generated from more than one behaviors. Our method is iterative: It alternates between clustering demonstrations into different behavior clusters and inverse learning the reward functions until convergence. It is built upon the Expectation-Maximization formulation and non-parametric clustering in the IRL setting. Further, to improve the computation efficiency, we remove the need of completely solving multiple IRL problems for multiple clusters during the iteration steps and introduce a resampling technique to avoid generating too many unlikely clusters. We demonstrate the convergence and efficiency of the proposed method through learning multiple driver behaviors from demonstrations generated from a grid-world environment and continuous trajectories collected from autonomous robot cars using the Gazebo robot simulator.\n    ",
        "submission_date": "2017-12-15T00:00:00",
        "last_modified_date": "2017-12-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.05812",
        "title": "Occam's razor is insufficient to infer the preferences of irrational agents",
        "authors": [
            "Stuart Armstrong",
            "S\u00f6ren Mindermann"
        ],
        "abstract": "Inverse reinforcement learning (IRL) attempts to infer human rewards or preferences from observed behavior. Since human planning systematically deviates from rationality, several approaches have been tried to account for specific human shortcomings. However, the general problem of inferring the reward function of an agent of unknown rationality has received little attention. Unlike the well-known ambiguity problems in IRL, this one is practically relevant but cannot be resolved by observing the agent's policy in enough environments. This paper shows (1) that a No Free Lunch result implies it is impossible to uniquely decompose a policy into a planning algorithm and reward function, and (2) that even with a reasonable simplicity prior/Occam's razor on the set of decompositions, we cannot distinguish between the true decomposition and others that lead to high regret. To address this, we need simple `normative' assumptions, which cannot be deduced exclusively from observations.\n    ",
        "submission_date": "2017-12-15T00:00:00",
        "last_modified_date": "2019-01-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.05855",
        "title": "A Berkeley View of Systems Challenges for AI",
        "authors": [
            "Ion Stoica",
            "Dawn Song",
            "Raluca Ada Popa",
            "David Patterson",
            "Michael W. Mahoney",
            "Randy Katz",
            "Anthony D. Joseph",
            "Michael Jordan",
            "Joseph M. Hellerstein",
            "Joseph E. Gonzalez",
            "Ken Goldberg",
            "Ali Ghodsi",
            "David Culler",
            "Pieter Abbeel"
        ],
        "abstract": "With the increasing commoditization of computer vision, speech recognition and machine translation systems and the widespread deployment of learning-based back-end technologies such as digital advertising and intelligent infrastructures, AI (Artificial Intelligence) has moved from research labs to production. These changes have been made possible by unprecedented levels of data and computation, by methodological advances in machine learning, by innovations in systems software and architectures, and by the broad accessibility of these technologies.\n",
        "submission_date": "2017-12-15T00:00:00",
        "last_modified_date": "2017-12-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.05881",
        "title": "Morphology dictates a robot's ability to ground crowd-proposed language",
        "authors": [
            "Zahra Mahoor",
            "Jack Felag",
            "Josh Bongard"
        ],
        "abstract": "As more robots act in physical proximity to people, it is essential to ensure they make decisions and execute actions that align with human values. To do so, robots need to understand the true intentions behind human-issued commands. In this paper, we define a safe robot as one that receives a natural-language command from humans, considers an action in response to that command, and accurately predicts how humans will judge that action if is executed in reality. Our contribution is two-fold: First, we introduce a web platform for human users to propose commands to simulated robots. The robots receive commands and act based on those proposed commands, and then the users provide positive and/or negative reinforcement. Next, we train a critic for each robot to predict the crowd's responses to one of the crowd-proposed commands. Second, we show that the morphology of a robot plays a role in the way it grounds language: The critics show that two of the robots used in the experiment achieve a lower prediction error than the others. Thus, those two robots are safer, according to our definition, since they ground the proposed command more accurately.\n    ",
        "submission_date": "2017-12-16T00:00:00",
        "last_modified_date": "2017-12-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.06180",
        "title": "Towards a Deep Reinforcement Learning Approach for Tower Line Wars",
        "authors": [
            "Per-Arne Andersen",
            "Morten Goodwin",
            "Ole-Christoffer Granmo"
        ],
        "abstract": "There have been numerous breakthroughs with reinforcement learning in the recent years, perhaps most notably on Deep Reinforcement Learning successfully playing and winning relatively advanced computer games. There is undoubtedly an anticipation that Deep Reinforcement Learning will play a major role when the first AI masters the complicated game plays needed to beat a professional Real-Time Strategy game player. For this to be possible, there needs to be a game environment that targets and fosters AI research, and specifically Deep Reinforcement Learning. Some game environments already exist, however, these are either overly simplistic such as Atari 2600 or complex such as Starcraft II from Blizzard Entertainment. We propose a game environment in between Atari 2600 and Starcraft II, particularly targeting Deep Reinforcement Learning algorithm research. The environment is a variant of Tower Line Wars from Warcraft III, Blizzard Entertainment. Further, as a proof of concept that the environment can harbor Deep Reinforcement algorithms, we propose and apply a Deep Q-Reinforcement architecture. The architecture simplifies the state space so that it is applicable to Q-learning, and in turn improves performance compared to current state-of-the-art methods. Our experiments show that the proposed architecture can learn to play the environment well, and score 33% better than standard Deep Q-learning which in turn proves the usefulness of the game environment.\n    ",
        "submission_date": "2017-12-17T00:00:00",
        "last_modified_date": "2017-12-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.06365",
        "title": "'Indifference' methods for managing agent rewards",
        "authors": [
            "Stuart Armstrong",
            "Xavier O'Rourke"
        ],
        "abstract": "`Indifference' refers to a class of methods used to control reward based agents. Indifference techniques aim to achieve one or more of three distinct goals: rewards dependent on certain events (without the agent being motivated to manipulate the probability of those events), effective disbelief (where agents behave as if particular events could never happen), and seamless transition from one reward function to another (with the agent acting as if this change is unanticipated). This paper presents several methods for achieving these goals in the POMDP setting, establishing their uses, strengths, and requirements. These methods of control work even when the implications of the agent's reward are otherwise not fully understood.\n    ",
        "submission_date": "2017-12-18T00:00:00",
        "last_modified_date": "2018-06-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.06440",
        "title": "Three IQs of AI Systems and their Testing Methods",
        "authors": [
            "Feng Liu",
            "Yong Shi",
            "Ying Liu"
        ],
        "abstract": "The rapid development of artificial intelligence has brought the artificial intelligence threat theory as well as the problem about how to evaluate the intelligence level of intelligent products. Both need to find a quantitative method to evaluate the intelligence level of intelligence systems, including human intelligence. Based on the standard intelligence system and the extended Von Neumann architecture, this paper proposes General IQ, Service IQ and Value IQ evaluation methods for intelligence systems, depending on different evaluation purposes. Among them, the General IQ of intelligence systems is to answer the question of whether the artificial intelligence can surpass the human intelligence, which is reflected in putting the intelligence systems on an equal status and conducting the unified evaluation. The Service IQ and Value IQ of intelligence systems are used to answer the question of how the intelligent products can better serve the human, reflecting the intelligence and required cost of each intelligence system as a product in the process of serving human.\n    ",
        "submission_date": "2017-12-14T00:00:00",
        "last_modified_date": "2017-12-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.06560",
        "title": "Improving Exploration in Evolution Strategies for Deep Reinforcement Learning via a Population of Novelty-Seeking Agents",
        "authors": [
            "Edoardo Conti",
            "Vashisht Madhavan",
            "Felipe Petroski Such",
            "Joel Lehman",
            "Kenneth O. Stanley",
            "Jeff Clune"
        ],
        "abstract": "Evolution strategies (ES) are a family of black-box optimization algorithms able to train deep neural networks roughly as well as Q-learning and policy gradient methods on challenging deep reinforcement learning (RL) problems, but are much faster (e.g. hours vs. days) because they parallelize better. However, many RL problems require directed exploration because they have reward functions that are sparse or deceptive (i.e. contain local optima), and it is unknown how to encourage such exploration with ES. Here we show that algorithms that have been invented to promote directed exploration in small-scale evolved neural networks via populations of exploring agents, specifically novelty search (NS) and quality diversity (QD) algorithms, can be hybridized with ES to improve its performance on sparse or deceptive deep RL tasks, while retaining scalability. Our experiments confirm that the resultant new algorithms, NS-ES and two QD algorithms, NSR-ES and NSRA-ES, avoid local optima encountered by ES to achieve higher performance on Atari and simulated robots learning to walk around a deceptive trap. This paper thus introduces a family of fast, scalable algorithms for reinforcement learning that are capable of directed exploration. It also adds this new family of exploration algorithms to the RL toolbox and raises the interesting possibility that analogous algorithms with multiple simultaneous paths of exploration might also combine well with existing RL algorithms outside ES.\n    ",
        "submission_date": "2017-12-18T00:00:00",
        "last_modified_date": "2018-10-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.06657",
        "title": "Towards the Augmented Pathologist: Challenges of Explainable-AI in Digital Pathology",
        "authors": [
            "Andreas Holzinger",
            "Bernd Malle",
            "Peter Kieseberg",
            "Peter M. Roth",
            "Heimo M\u00fcller",
            "Robert Reihs",
            "Kurt Zatloukal"
        ],
        "abstract": "Digital pathology is not only one of the most promising fields of diagnostic medicine, but at the same time a hot topic for fundamental research. Digital pathology is not just the transfer of histopathological slides into digital representations. The combination of different data sources (images, patient records, and *omics data) together with current advances in artificial intelligence/machine learning enable to make novel information accessible and quantifiable to a human expert, which is not yet available and not exploited in current medical settings. The grand goal is to reach a level of usable intelligence to understand the data in the context of an application task, thereby making machine decisions transparent, interpretable and explainable. The foundation of such an \"augmented pathologist\" needs an integrated approach: While machine learning algorithms require many thousands of training examples, a human expert is often confronted with only a few data points. Interestingly, humans can learn from such few examples and are able to instantly interpret complex patterns. Consequently, the grand goal is to combine the possibilities of artificial intelligence with human intelligence and to find a well-suited balance between them to enable what neither of them could do on their own. This can raise the quality of education, diagnosis, prognosis and prediction of cancer and other diseases. In this paper we describe some (incomplete) research issues which we believe should be addressed in an integrated and concerted effort for paving the way towards the augmented pathologist.\n    ",
        "submission_date": "2017-12-18T00:00:00",
        "last_modified_date": "2017-12-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.06778",
        "title": "Learning Representations from Road Network for End-to-End Urban Growth Simulation",
        "authors": [
            "Saptarshi Pal",
            "Soumya K Ghosh"
        ],
        "abstract": "From our experiences in the past, we have seen that the growth of cities is very much dependent on the transportation networks. In mega cities, transportation networks determine to a significant extent as to where the people will move and houses will be built. Hence, transportation network data is crucial to an urban growth prediction system. Existing works have used manually derived distance based features based on the road networks to build models on urban growth. But due to the non-generic and laborious nature of the manual feature engineering process, we can shift to End-to-End systems which do not rely on manual feature engineering. In this paper, we propose a method to integrate road network data to an existing Rule based End-to-End framework without manual feature engineering. Our method employs recurrent neural networks to represent road networks in a structured way such that it can be plugged into the previously proposed End-to-End framework. The proposed approach enhances the performance in terms of Figure of Merit, Producer's accuracy, User's accuracy and Overall accuracy of the existing Rule based End-to-End framework.\n    ",
        "submission_date": "2017-12-19T00:00:00",
        "last_modified_date": "2018-02-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.06935",
        "title": "Mining Smart Card Data for Travelers' Mini Activities",
        "authors": [
            "Boris Chidlovskii"
        ],
        "abstract": "In the context of public transport modeling and simulation, we address the problem of mismatch between simulated transit trips and observed ones. We point to the weakness of the current travel demand modeling process; the trips it generates are over-optimistic and do not reflect the real passenger choices. We introduce the notion of mini activities the travelers do during the trips; they can explain the deviation of simulated trips from the observed trips. We propose to mine the smart card data to extract the mini activities. We develop a technique to integrate them in the generated trips and learn such an integration from two available sources, the trip history and trip planner recommendations. For an input travel demand, we build a Markov chain over the trip collection and apply the Monte Carlo Markov Chain algorithm to integrate mini activities in such a way that the selected characteristics converge to the desired distributions. We test our method in different settings on the passenger trip collection of Nancy, France. We report experimental results demonstrating a very important mismatch reduction.\n    ",
        "submission_date": "2017-12-19T00:00:00",
        "last_modified_date": "2017-12-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.07081",
        "title": "Column Generation for Interaction Coverage in Combinatorial Software Testing",
        "authors": [
            "Serdar Kadioglu"
        ],
        "abstract": "This paper proposes a novel column generation framework for combinatorial software testing. In particular, it combines Mathematical Programming and Constraint Programming in a hybrid decomposition to generate covering arrays. The approach allows generating parameterized test cases with coverage guarantees between parameter interactions of a given application. Compared to exhaustive testing, combinatorial test case generation reduces the number of tests to run significantly. Our column generation algorithm is generic and can accommodate mixed coverage arrays over heterogeneous alphabets. The algorithm is realized in practice as a cloud service and recognized as one of the five winners of the company-wide cloud application challenge at Oracle. The service is currently helping software developers from a range of different product teams in their testing efforts while exposing declarative constraint models and hybrid optimization techniques to a broader audience.\n    ",
        "submission_date": "2017-12-19T00:00:00",
        "last_modified_date": "2017-12-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.07165",
        "title": "Scale-invariant temporal history (SITH): optimal slicing of the past in an uncertain world",
        "authors": [
            "Tyler A. Spears",
            "Brandon G. Jacques",
            "Marc W. Howard",
            "Per B. Sederberg"
        ],
        "abstract": "In both the human brain and any general artificial intelligence (AI), a representation of the past is necessary to predict the future. However, perfect storage of all experiences is not feasible. One approach utilized in many applications, including reward prediction in reinforcement learning, is to retain recently active features of experience in a buffer. Despite its prior successes, we show that the fixed length buffer renders Deep Q-learning Networks (DQNs) fragile to changes in the scale over which information can be learned. To enable learning when the relevant temporal scales in the environment are not known *a priori*, recent advances in psychology and neuroscience suggest that the brain maintains a compressed representation of the past. Here we introduce a neurally-plausible, scale-free memory representation we call Scale-Invariant Temporal History (SITH) for use with artificial agents. This representation covers an exponentially large period of time by sacrificing temporal accuracy for events further in the past. We demonstrate the utility of this representation by comparing the performance of agents given SITH, buffer, and exponential decay representations in learning to play video games at different levels of complexity. In these environments, SITH exhibits better learning performance by storing information for longer timescales than a fixed-size buffer, and representing this information more clearly than a set of exponentially decayed features. Finally, we discuss how the application of SITH, along with other human-inspired models of cognition, could improve reinforcement and machine learning algorithms in general.\n    ",
        "submission_date": "2017-12-19T00:00:00",
        "last_modified_date": "2018-12-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.07294",
        "title": "Hierarchical and Interpretable Skill Acquisition in Multi-task Reinforcement Learning",
        "authors": [
            "Tianmin Shu",
            "Caiming Xiong",
            "Richard Socher"
        ],
        "abstract": "Learning policies for complex tasks that require multiple different skills is a major challenge in reinforcement learning (RL). It is also a requirement for its deployment in real-world scenarios. This paper proposes a novel framework for efficient multi-task reinforcement learning. Our framework trains agents to employ hierarchical policies that decide when to use a previously learned policy and when to learn a new skill. This enables agents to continually acquire new skills during different stages of training. Each learned task corresponds to a human language description. Because agents can only access previously learned skills through these descriptions, the agent can always provide a human-interpretable description of its choices. In order to help the agent learn the complex temporal dependencies necessary for the hierarchical policy, we provide it with a stochastic temporal grammar that modulates when to rely on previously learned skills and when to execute new skills. We validate our approach on Minecraft games designed to explicitly test the ability to reuse previously learned skills while simultaneously learning new skills.\n    ",
        "submission_date": "2017-12-20T00:00:00",
        "last_modified_date": "2017-12-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.07305",
        "title": "Revisiting the Master-Slave Architecture in Multi-Agent Deep Reinforcement Learning",
        "authors": [
            "Xiangyu Kong",
            "Bo Xin",
            "Fangchen Liu",
            "Yizhou Wang"
        ],
        "abstract": "Many tasks in artificial intelligence require the collaboration of multiple agents. We exam deep reinforcement learning for multi-agent domains. Recent research efforts often take the form of two seemingly conflicting perspectives, the decentralized perspective, where each agent is supposed to have its own controller; and the centralized perspective, where one assumes there is a larger model controlling all agents. In this regard, we revisit the idea of the master-slave architecture by incorporating both perspectives within one framework. Such a hierarchical structure naturally leverages advantages from one another. The idea of combining both perspectives is intuitive and can be well motivated from many real world systems, however, out of a variety of possible realizations, we highlights three key ingredients, i.e. composed action representation, learnable communication and independent reasoning. With network designs to facilitate these explicitly, our proposal consistently outperforms latest competing methods both in synthetic experiments and when applied to challenging StarCraft micromanagement tasks.\n    ",
        "submission_date": "2017-12-20T00:00:00",
        "last_modified_date": "2017-12-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.07686",
        "title": "Pseudorehearsal in actor-critic agents with neural network function approximation",
        "authors": [
            "Vladimir Marochko",
            "Leonard Johard",
            "Manuel Mazzara",
            "Luca Longo"
        ],
        "abstract": "Catastrophic forgetting has a significant negative impact in reinforcement learning. The purpose of this study is to investigate how pseudorehearsal can change performance of an actor-critic agent with neural-network function approximation. We tested agent in a pole balancing task and compared different pseudorehearsal approaches. We have found that pseudorehearsal can assist learning and decrease forgetting.\n    ",
        "submission_date": "2017-12-20T00:00:00",
        "last_modified_date": "2018-02-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.07752",
        "title": "Towards an unanimous international regulatory body for responsible use of Artificial Intelligence [UIRB-AI]",
        "authors": [
            "Rajesh Chidambaram"
        ],
        "abstract": "Artificial Intelligence (AI), is once again in the phase of drastic advancements. Unarguably, the technology itself can revolutionize the way we live our everyday life. But the exponential growth of technology poses a daunting task for policy researchers and law makers in making amendments to the existing norms. In addition, not everyone in the society is studying the potential socio-economic intricacies and cultural drifts that AI can bring about. It is prudence to reflect from our historical past to propel the development of technology in the right direction. To benefit the society of the present and future, I scientifically explore the societal impact of AI. While there are many public and private partnerships working on similar aspects, here I describe the necessity for an Unanimous International Regulatory Body for all applications of AI (UIRB-AI). I also discuss the benefits and drawbacks of such an organization. To combat any drawbacks in the formation of an UIRB-AI, both idealistic and pragmatic perspectives are discussed alternatively. The paper further advances the discussion by proposing novel policies on how such organization should be structured and how it can bring about a win-win situation for everyone in the society.\n    ",
        "submission_date": "2017-12-21T00:00:00",
        "last_modified_date": "2018-06-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.07893",
        "title": "A Deep Policy Inference Q-Network for Multi-Agent Systems",
        "authors": [
            "Zhang-Wei Hong",
            "Shih-Yang Su",
            "Tzu-Yun Shann",
            "Yi-Hsiang Chang",
            "Chun-Yi Lee"
        ],
        "abstract": "We present DPIQN, a deep policy inference Q-network that targets multi-agent systems composed of controllable agents, collaborators, and opponents that interact with each other. We focus on one challenging issue in such systems---modeling agents with varying strategies---and propose to employ \"policy features\" learned from raw observations (e.g., raw images) of collaborators and opponents by inferring their policies. DPIQN incorporates the learned policy features as a hidden vector into its own deep Q-network (DQN), such that it is able to predict better Q values for the controllable agents than the state-of-the-art deep reinforcement learning models. We further propose an enhanced version of DPIQN, called deep recurrent policy inference Q-network (DRPIQN), for handling partial observability. Both DPIQN and DRPIQN are trained by an adaptive training procedure, which adjusts the network's attention to learn the policy features and its own Q-values at different phases of the training process. We present a comprehensive analysis of DPIQN and DRPIQN, and highlight their effectiveness and generalizability in various multi-agent settings. Our models are evaluated in a classic soccer game involving both competitive and collaborative scenarios. Experimental results performed on 1 vs. 1 and 2 vs. 2 games show that DPIQN and DRPIQN demonstrate superior performance to the baseline DQN and deep recurrent Q-network (DRQN) models. We also explore scenarios in which collaborators or opponents dynamically change their policies, and show that DPIQN and DRPIQN do lead to better overall performance in terms of stability and mean scores.\n    ",
        "submission_date": "2017-12-21T00:00:00",
        "last_modified_date": "2018-04-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.07901",
        "title": "Improvements to Inference Compilation for Probabilistic Programming in Large-Scale Scientific Simulators",
        "authors": [
            "Mario Lezcano Casado",
            "Atilim Gunes Baydin",
            "David Martinez Rubio",
            "Tuan Anh Le",
            "Frank Wood",
            "Lukas Heinrich",
            "Gilles Louppe",
            "Kyle Cranmer",
            "Karen Ng",
            "Wahid Bhimji",
            "Prabhat"
        ],
        "abstract": "We consider the problem of Bayesian inference in the family of probabilistic models implicitly defined by stochastic generative models of data. In scientific fields ranging from population biology to cosmology, low-level mechanistic components are composed to create complex generative models. These models lead to intractable likelihoods and are typically non-differentiable, which poses challenges for traditional approaches to inference. We extend previous work in \"inference compilation\", which combines universal probabilistic programming and deep learning methods, to large-scale scientific simulators, and introduce a C++ based probabilistic programming library called CPProb. We successfully use CPProb to interface with SHERPA, a large code-base used in particle physics. Here we describe the technical innovations realized and planned for this library.\n    ",
        "submission_date": "2017-12-21T00:00:00",
        "last_modified_date": "2017-12-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.08266",
        "title": "Federated Control with Hierarchical Multi-Agent Deep Reinforcement Learning",
        "authors": [
            "Saurabh Kumar",
            "Pararth Shah",
            "Dilek Hakkani-Tur",
            "Larry Heck"
        ],
        "abstract": "We present a framework combining hierarchical and multi-agent deep reinforcement learning approaches to solve coordination problems among a multitude of agents using a semi-decentralized model. The framework extends the multi-agent learning setup by introducing a meta-controller that guides the communication between agent pairs, enabling agents to focus on communicating with only one other agent at any step. This hierarchical decomposition of the task allows for efficient exploration to learn policies that identify globally optimal solutions even as the number of collaborating agents increases. We show promising initial experimental results on a simulated distributed scheduling problem.\n    ",
        "submission_date": "2017-12-22T00:00:00",
        "last_modified_date": "2017-12-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.08296",
        "title": "Intelligent Device Discovery in the Internet of Things - Enabling the Robot Society",
        "authors": [
            "James Sunthonlap",
            "Phuoc Nguyen",
            "Zilong Ye"
        ],
        "abstract": "The Internet of Things (IoT) is continuously growing to connect billions of smart devices anywhere and anytime in an Internet-like structure, which enables a variety of applications, services and interactions between human and objects. In the future, the smart devices are supposed to be able to autonomously discover a target device with desired features and generate a set of entirely new services and applications that are not supervised or even imagined by human beings. The pervasiveness of smart devices, as well as the heterogeneity of their design and functionalities, raise a major concern: How can a smart device efficiently discover a desired target device? In this paper, we propose a Social-Aware and Distributed (SAND) scheme that achieves a fast, scalable and efficient device discovery in the IoT. The proposed SAND scheme adopts a novel device ranking criteria that measures the device's degree, social relationship diversity, clustering coefficient and betweenness. Based on the device ranking criteria, the discovery request can be guided to travel through critical devices that stand at the major intersections of the network, and thus quickly reach the desired target device by contacting only a limited number of intermediate devices. With the help of such an intelligent device discovery as SAND, the IoT devices, as well as other computing facilities, software and data on the Internet, can autonomously establish new social connections with each other as human being do. They can formulate self-organized computing groups to perform required computing tasks, facilitate a fusion of a variety of computing service, network service and data to generate novel applications and services, evolve from the individual aritificial intelligence to the collaborative intelligence, and eventually enable the birth of a robot society.\n    ",
        "submission_date": "2017-12-22T00:00:00",
        "last_modified_date": "2018-01-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.08588",
        "title": "Rank Pruning for Dominance Queries in CP-Nets",
        "authors": [
            "Kathryn Laing",
            "Peter Adam Thwaites",
            "John Paul Gosling"
        ],
        "abstract": "Conditional preference networks (CP-nets) are a graphical representation of a person's (conditional) preferences over a set of discrete variables. In this paper, we introduce a novel method of quantifying preference for any given outcome based on a CP-net representation of a user's preferences. We demonstrate that these values are useful for reasoning about user preferences. In particular, they allow us to order (any subset of) the possible outcomes in accordance with the user's preferences. Further, these values can be used to improve the efficiency of outcome dominance testing. That is, given a pair of outcomes, we can determine which the user prefers more efficiently. Through experimental results, we show that this method is more effective than existing techniques for improving dominance testing efficiency. We show that the above results also hold for CP-nets that express indifference between variable values.\n    ",
        "submission_date": "2017-12-22T00:00:00",
        "last_modified_date": "2018-09-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.08626",
        "title": "Obtaining Accurate Probabilistic Causal Inference by Post-Processing Calibration",
        "authors": [
            "Fattaneh Jabbari",
            "Mahdi Pakdaman Naeini",
            "Gregory F. Cooper"
        ],
        "abstract": "Discovery of an accurate causal Bayesian network structure from observational data can be useful in many areas of science. Often the discoveries are made under uncertainty, which can be expressed as probabilities. To guide the use of such discoveries, including directing further investigation, it is important that those probabilities be well-calibrated. In this paper, we introduce a novel framework to derive calibrated probabilities of causal relationships from observational data. The framework consists of three components: (1) an approximate method for generating initial probability estimates of the edge types for each pair of variables, (2) the availability of a relatively small number of the causal relationships in the network for which the truth status is known, which we call a calibration training set, and (3) a calibration method for using the approximate probability estimates and the calibration training set to generate calibrated probabilities for the many remaining pairs of variables. We also introduce a new calibration method based on a shallow neural network. Our experiments on simulated data support that the proposed approach improves the calibration of causal edge predictions. The results also support that the approach often improves the precision and recall of predictions.\n    ",
        "submission_date": "2017-12-22T00:00:00",
        "last_modified_date": "2017-12-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.08697",
        "title": "Interpretable Counting for Visual Question Answering",
        "authors": [
            "Alexander Trott",
            "Caiming Xiong",
            "Richard Socher"
        ],
        "abstract": "Questions that require counting a variety of objects in images remain a major challenge in visual question answering (VQA). The most common approaches to VQA involve either classifying answers based on fixed length representations of both the image and question or summing fractional counts estimated from each section of the image. In contrast, we treat counting as a sequential decision process and force our model to make discrete choices of what to count. Specifically, the model sequentially selects from detected objects and learns interactions between objects that influence subsequent selections. A distinction of our approach is its intuitive and interpretable output, as discrete counts are automatically grounded in the image. Furthermore, our method outperforms the state of the art architecture for VQA on multiple metrics that evaluate counting.\n    ",
        "submission_date": "2017-12-23T00:00:00",
        "last_modified_date": "2018-03-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.08858",
        "title": "Towards Collaborative Conceptual Exploration",
        "authors": [
            "Tom Hanika",
            "Jens Zumbr\u00e4gel"
        ],
        "abstract": "In domains with high knowledge distribution a natural objective is to create principle foundations for collaborative interactive learning environments. We present a first mathematical characterization of a collaborative learning group, a consortium, based on closure systems of attribute sets and the well-known attribute exploration algorithm from formal concept analysis. To this end, we introduce (weak) local experts for subdomains of a given knowledge domain. These entities are able to refute and potentially accept a given (implicational) query for some closure system that is a restriction of the whole domain. On this we build up a consortial expert and show first insights about the ability of such an expert to answer queries. Furthermore, we depict techniques on how to cope with falsely accepted implications and on combining counterexamples. Using notions from combinatorial design theory we further expand those insights as far as providing first results on the decidability problem if a given consortium is able to explore some target domain. Applications in conceptual knowledge acquisition as well as in collaborative interactive ontology learning are at hand.\n    ",
        "submission_date": "2017-12-23T00:00:00",
        "last_modified_date": "2018-03-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.08875",
        "title": "Predicting Rich Drug-Drug Interactions via Biomedical Knowledge Graphs and Text Jointly Embedding",
        "authors": [
            "Meng Wang"
        ],
        "abstract": "Minimizing adverse reactions caused by drug-drug interactions has always been a momentous research topic in clinical pharmacology. Detecting all possible interactions through clinical studies before a drug is released to the market is a demanding task. The power of big data is opening up new approaches to discover various drug-drug interactions. However, these discoveries contain a huge amount of noise and provide knowledge bases far from complete and trustworthy ones to be utilized. Most existing studies focus on predicting binary drug-drug interactions between drug pairs but ignore other interactions. In this paper, we propose a novel framework, called PRD, to predict drug-drug interactions. The framework uses the graph embedding that can overcome data incompleteness and sparsity issues to achieve multiple DDI label prediction. First, a large-scale drug knowledge graph is generated from different sources. Then, the knowledge graph is embedded with comprehensive biomedical text into a common low dimensional space. Finally, the learned embeddings are used to efficiently compute rich DDI information through a link prediction process. To validate the effectiveness of the proposed framework, extensive experiments were conducted on real-world datasets. The results demonstrate that our model outperforms several state-of-the-art baseline methods in terms of capability and accuracy.\n    ",
        "submission_date": "2017-12-24T00:00:00",
        "last_modified_date": "2018-03-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.08883",
        "title": "Traffic Flow Forecasting Using a Spatio-Temporal Bayesian Network Predictor",
        "authors": [
            "Shiliang Sun",
            "Changshui Zhang",
            "Yi Zhang"
        ],
        "abstract": "A novel predictor for traffic flow forecasting, namely spatio-temporal Bayesian network predictor, is proposed. Unlike existing methods, our approach incorporates all the spatial and temporal information available in a transportation network to carry our traffic flow forecasting of the current site. The Pearson correlation coefficient is adopted to rank the input variables (traffic flows) for prediction, and the best-first strategy is employed to select a subset as the cause nodes of a Bayesian network. Given the derived cause nodes and the corresponding effect node in the spatio-temporal Bayesian network, a Gaussian Mixture Model is applied to describe the statistical relationship between the input and output. Finally, traffic flow forecasting is performed under the criterion of Minimum Mean Square Error (M.M.S.E.). Experimental results with the urban vehicular flow data of Beijing demonstrate the effectiveness of our presented spatio-temporal Bayesian network predictor.\n    ",
        "submission_date": "2017-12-24T00:00:00",
        "last_modified_date": "2017-12-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.09014",
        "title": "Null Dynamical State Models of Human Cognitive Dysfunction",
        "authors": [
            "M. J. Gagen"
        ],
        "abstract": "The hard problem in artificial intelligence asks how the shuffling of syntactical symbols in a program can lead to systems which experience semantics and qualia. We address this question in three stages. First, we introduce a new class of human semantic symbols which appears when unexpected and drastic environmental change causes humans to become surprised, confused, uncertain, and in extreme cases, unresponsive, passive and dysfunctional. For this class of symbols, pre-learned programs become inoperative so these syntactical programs cannot be the source of experienced qualia. Second, we model the dysfunctional human response to a radically changed environment as being the natural response of any learning machine facing novel inputs from well outside its previous training set. In this situation, learning machines are unable to extract information from their input and will typically enter a dynamical state characterized by null outputs and a lack of response. This state immediately predicts and explains the characteristics of the semantic experiences of humans in similar circumstances. In the third stage, we consider learning machines trained to implement multiple functions in simple sequential programs using environmental data to specify subroutine names, control flow instructions, memory calls, and so on. Drastic change in any of these environmental inputs can again lead to inoperative programs. By examining changes specific to people or locations we can model human cognitive symbols featuring these dependencies, such as attachment and grief. Our approach links known dynamical machines states with human qualia and thus offers new insight into the hard problem of artificial intelligence.\n    ",
        "submission_date": "2017-12-25T00:00:00",
        "last_modified_date": "2017-12-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.09227",
        "title": "A Real-Time Autonomous Highway Accident Detection Model Based on Big Data Processing and Computational Intelligence",
        "authors": [
            "A. Murat Ozbayoglu",
            "Gokhan Kucukayan",
            "Erdogan Dogdu"
        ],
        "abstract": "Due to increasing urban population and growing number of motor vehicles, traffic congestion is becoming a major problem of the 21st century. One of the main reasons behind traffic congestion is accidents which can not only result in casualties and losses for the participants, but also in wasted and lost time for the others that are stuck behind the wheels. Early detection of an accident can save lives, provides quicker road openings, hence decreases wasted time and resources, and increases efficiency. In this study, we propose a preliminary real-time autonomous accident-detection system based on computational intelligence techniques. Istanbul City traffic-flow data for the year 2015 from various sensor locations are populated using big data processing methodologies. The extracted features are then fed into a nearest neighbor model, a regression tree, and a feed-forward neural network model. For the output, the possibility of an occurrence of an accident is predicted. The results indicate that even though the number of false alarms dominates the real accident cases, the system can still provide useful information that can be used for status verification and early reaction to possible accidents.\n    ",
        "submission_date": "2017-12-26T00:00:00",
        "last_modified_date": "2017-12-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.09344",
        "title": "Whatever Does Not Kill Deep Reinforcement Learning, Makes It Stronger",
        "authors": [
            "Vahid Behzadan",
            "Arslan Munir"
        ],
        "abstract": "Recent developments have established the vulnerability of deep Reinforcement Learning (RL) to policy manipulation attacks via adversarial perturbations. In this paper, we investigate the robustness and resilience of deep RL to training-time and test-time attacks. Through experimental results, we demonstrate that under noncontiguous training-time attacks, Deep Q-Network (DQN) agents can recover and adapt to the adversarial conditions by reactively adjusting the policy. Our results also show that policies learned under adversarial perturbations are more robust to test-time attacks. Furthermore, we compare the performance of $\\epsilon$-greedy and parameter-space noise exploration methods in terms of robustness and resilience against adversarial perturbations.\n    ",
        "submission_date": "2017-12-23T00:00:00",
        "last_modified_date": "2017-12-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.09356",
        "title": "An Online Ride-Sharing Path Planning Strategy for Public Vehicle Systems",
        "authors": [
            "Ming Zhu",
            "Xiao-Yang Liu",
            "Xiaodong Wang"
        ],
        "abstract": "As efficient traffic-management platforms, public vehicle (PV) systems are envisioned to be a promising approach to solving traffic congestions and pollutions for future smart cities. PV systems provide online/dynamic peer-to-peer ride-sharing services with the goal of serving sufficient number of customers with minimum number of vehicles and lowest possible cost. A key component of the PV system is the online ride-sharing scheduling strategy. In this paper, we propose an efficient path planning strategy that focuses on a limited potential search area for each vehicle by filtering out the requests that violate passenger service quality level, so that the global search is reduced to local search. We analyze the performance of the proposed solution such as reduction ratio of computational complexity. Simulations based on the Manhattan taxi data set show that, the computing time is reduced by 22% compared with the exhaustive search method under the same service quality performance.\n    ",
        "submission_date": "2017-12-27T00:00:00",
        "last_modified_date": "2017-12-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.09381",
        "title": "RLlib: Abstractions for Distributed Reinforcement Learning",
        "authors": [
            "Eric Liang",
            "Richard Liaw",
            "Philipp Moritz",
            "Robert Nishihara",
            "Roy Fox",
            "Ken Goldberg",
            "Joseph E. Gonzalez",
            "Michael I. Jordan",
            "Ion Stoica"
        ],
        "abstract": "Reinforcement learning (RL) algorithms involve the deep nesting of highly irregular computation patterns, each of which typically exhibits opportunities for distributed computation. We argue for distributing RL components in a composable way by adapting algorithms for top-down hierarchical control, thereby encapsulating parallelism and resource requirements within short-running compute tasks. We demonstrate the benefits of this principle through RLlib: a library that provides scalable software primitives for RL. These primitives enable a broad range of algorithms to be implemented with high performance, scalability, and substantial code reuse. RLlib is available at ",
        "submission_date": "2017-12-26T00:00:00",
        "last_modified_date": "2018-06-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.09923",
        "title": "What do we need to build explainable AI systems for the medical domain?",
        "authors": [
            "Andreas Holzinger",
            "Chris Biemann",
            "Constantinos S. Pattichis",
            "Douglas B. Kell"
        ],
        "abstract": "Artificial intelligence (AI) generally and machine learning (ML) specifically demonstrate impressive practical success in many different application domains, e.g. in autonomous driving, speech recognition, or recommender systems. Deep learning approaches, trained on extremely large data sets or using reinforcement learning methods have even exceeded human performance in visual tasks, particularly on playing games such as Atari, or mastering the game of Go. Even in the medical domain there are remarkable results. The central problem of such models is that they are regarded as black-box models and even if we understand the underlying mathematical principles, they lack an explicit declarative knowledge representation, hence have difficulty in generating the underlying explanatory structures. This calls for systems enabling to make decisions transparent, understandable and explainable. A huge motivation for our approach are rising legal and privacy aspects. The new European General Data Protection Regulation entering into force on May 25th 2018, will make black-box approaches difficult to use in business. This does not imply a ban on automatic learning approaches or an obligation to explain everything all the time, however, there must be a possibility to make the results re-traceable on demand. In this paper we outline some of our research topics in the context of the relatively new area of explainable-AI with a focus on the application in medicine, which is a very special domain. This is due to the fact that medical professionals are working mostly with distributed heterogeneous and complex sources of data. In this paper we concentrate on three sources: images, *omics data and text. We argue that research in explainable-AI would generally help to facilitate the implementation of AI/ML in the medical domain, and specifically help to facilitate transparency and trust.\n    ",
        "submission_date": "2017-12-28T00:00:00",
        "last_modified_date": "2017-12-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.10070",
        "title": "Reinforcement Learning with Analogical Similarity to Guide Schema Induction and Attention",
        "authors": [
            "James M. Foster",
            "Matt Jones"
        ],
        "abstract": "Research in analogical reasoning suggests that higher-order cognitive functions such as abstract reasoning, far transfer, and creativity are founded on recognizing structural similarities among relational systems. Here we integrate theories of analogy with the computational framework of reinforcement learning (RL). We propose a psychology theory that is a computational synergy between analogy and RL, in which analogical comparison provides the RL learning algorithm with a measure of relational similarity, and RL provides feedback signals that can drive analogical learning. Simulation results support the power of this approach.\n    ",
        "submission_date": "2017-12-28T00:00:00",
        "last_modified_date": "2017-12-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.10179",
        "title": "RedDwarfData: a simplified dataset of StarCraft matches",
        "authors": [
            "Juan J. Merelo-Guerv\u00f3s",
            "Antonio Fern\u00e1ndez-Ares",
            "Antonio \u00c1lvarez Caballero",
            "Pablo Garc\u00eda-S\u00e1nchez",
            "Victor Rivas"
        ],
        "abstract": "The game Starcraft is one of the most interesting arenas to test new machine learning and computational intelligence techniques; however, StarCraft matches take a long time and creating a good dataset for training can be hard. Besides, analyzing match logs to extract the main characteristics can also be done in many different ways to the point that extracting and processing data itself can take an inordinate amount of time and of course, depending on what you choose, can bias learning algorithms. In this paper we present a simplified dataset extracted from the set of matches published by Robinson and Watson, which we have called RedDwarfData, containing several thousand matches processed to frames, so that temporal studies can also be undertaken. This dataset is available from GitHub under a free license. An initial analysis and appraisal of these matches is also made.\n    ",
        "submission_date": "2017-12-29T00:00:00",
        "last_modified_date": "2017-12-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.00001",
        "title": "Digital Advertising Traffic Operation: Machine Learning for Process Discovery",
        "authors": [
            "Massimiliano Dal Mas"
        ],
        "abstract": "In a Web Advertising Traffic Operation it's necessary to manage the day-to-day trafficking, pacing and optimization of digital and paid social campaigns. The data analyst on Traffic Operation can not only quickly provide answers but also speaks the language of the Process Manager and visually displays the discovered process problems. In order to solve a growing number of complaints in the customer service process, the weaknesses in the process itself must be identified and communicated to the department. With the help of Process Mining for the CRM data it is possible to identify unwanted loops and delays in the process. With this paper we propose a process discovery based on Machine Learning technique to automatically discover variations and detect at first glance what the problem is, and undertake corrective measures.\n    ",
        "submission_date": "2016-12-30T00:00:00",
        "last_modified_date": "2016-12-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.00016",
        "title": "Non-Negative Matrix Factorization Test Cases",
        "authors": [
            "Connor Sell",
            "Jeremy Kepner"
        ],
        "abstract": "Non-negative matrix factorization (NMF) is a prob- lem with many applications, ranging from facial recognition to document clustering. However, due to the variety of algorithms that solve NMF, the randomness involved in these algorithms, and the somewhat subjective nature of the problem, there is no clear \"correct answer\" to any particular NMF problem, and as a result, it can be hard to test new algorithms. This paper suggests some test cases for NMF algorithms derived from matrices with enumerable exact non-negative factorizations and perturbations of these matrices. Three algorithms using widely divergent approaches to NMF all give similar solutions over these test cases, suggesting that these test cases could be used as test cases for implementations of these existing NMF algorithms as well as potentially new NMF algorithms. This paper also describes how the proposed test cases could be used in practice.\n    ",
        "submission_date": "2016-12-30T00:00:00",
        "last_modified_date": "2016-12-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.00077",
        "title": "Learning Weighted Association Rules in Human Phenotype Ontology",
        "authors": [
            "Pietro Hiram Guzzi",
            "Giuseppe Agapito",
            "Marianna Milano",
            "Mario Cannataro"
        ],
        "abstract": "The Human Phenotype Ontology (HPO) is a structured repository of concepts (HPO Terms) that are associated to one or more diseases. The process of association is referred to as annotation. The relevance and the specificity of both HPO terms and annotations are evaluated by a measure defined as Information Content (IC). The analysis of annotated data is thus an important challenge for bioinformatics. There exist different approaches of analysis. From those, the use of Association Rules (AR) may provide useful knowledge, and it has been used in some applications, e.g. improving the quality of annotations. Nevertheless classical association rules algorithms do not take into account the source of annotation nor the importance yielding to the generation of candidate rules with low IC. This paper presents HPO-Miner (Human Phenotype Ontology-based Weighted Association Rules) a methodology for extracting Weighted Association Rules. HPO-Miner can extract relevant rules from a biological point of view. A case study on using of HPO-Miner on publicly available HPO annotation datasets is used to demonstrate the effectiveness of our methodology.\n    ",
        "submission_date": "2016-12-31T00:00:00",
        "last_modified_date": "2016-12-31T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.00138",
        "title": "Cutting-off Redundant Repeating Generations for Neural Abstractive Summarization",
        "authors": [
            "Jun Suzuki",
            "Masaaki Nagata"
        ],
        "abstract": "This paper tackles the reduction of redundant repeating generation that is often observed in RNN-based encoder-decoder models. Our basic idea is to jointly estimate the upper-bound frequency of each target vocabulary in the encoder and control the output words based on the estimation in the decoder. Our method shows significant improvement over a strong RNN-based encoder-decoder baseline and achieved its best results on an abstractive summarization benchmark.\n    ",
        "submission_date": "2016-12-31T00:00:00",
        "last_modified_date": "2017-02-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.00178",
        "title": "Lazily Adapted Constant Kinky Inference for Nonparametric Regression and Model-Reference Adaptive Control",
        "authors": [
            "Jan-Peter Calliess"
        ],
        "abstract": "Techniques known as Nonlinear Set Membership prediction, Lipschitz Interpolation or Kinky Inference are approaches to machine learning that utilise presupposed Lipschitz properties to compute inferences over unobserved function values. Provided a bound on the true best Lipschitz constant of the target function is known a priori they offer convergence guarantees as well as bounds around the predictions. Considering a more general setting that builds on Hoelder continuity relative to pseudo-metrics, we propose an online method for estimating the Hoelder constant online from function value observations that possibly are corrupted by bounded observational errors. Utilising this to compute adaptive parameters within a kinky inference rule gives rise to a nonparametric machine learning method, for which we establish strong universal approximation guarantees. That is, we show that our prediction rule can learn any continuous function in the limit of increasingly dense data to within a worst-case error bound that depends on the level of observational uncertainty. We apply our method in the context of nonparametric model-reference adaptive control (MRAC). Across a range of simulated aircraft roll-dynamics and performance metrics our approach outperforms recently proposed alternatives that were based on Gaussian processes and RBF-neural networks. For discrete-time systems, we provide guarantees on the tracking success of our learning-based controllers both for the batch and the online learning setting.\n    ",
        "submission_date": "2016-12-31T00:00:00",
        "last_modified_date": "2021-03-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.00529",
        "title": "Truthful Facility Location with Additive Errors",
        "authors": [
            "Iddan Golomb",
            "Christos Tzamos"
        ],
        "abstract": "We address the problem of locating facilities on the $[0,1]$ interval based on reports from strategic agents. The cost of each agent is her distance to the closest facility, and the global objective is to minimize either the maximum cost of an agent or the social cost.\n",
        "submission_date": "2017-01-02T00:00:00",
        "last_modified_date": "2017-01-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.00622",
        "title": "Knowledge Engineering for Hybrid Deductive Databases",
        "authors": [
            "Dietmar Seipel"
        ],
        "abstract": "Modern knowledge base systems frequently need to combine a collection of databases in different formats: e.g., relational databases, XML databases, rule bases, ontologies, etc. In the deductive database system DDBASE, we can manage these different formats of knowledge and reason about them. Even the file systems on different computers can be part of the knowledge base. Often, it is necessary to handle different versions of a knowledge base. E.g., we might want to find out common parts or differences of two versions of a relational database.\n",
        "submission_date": "2017-01-03T00:00:00",
        "last_modified_date": "2017-01-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.00736",
        "title": "Simulated Tornado Optimization",
        "authors": [
            "S. Hossein Hosseini",
            "Tohid Nouri",
            "Afshin Ebrahimi",
            "S. Ali Hosseini"
        ],
        "abstract": "We propose a swarm-based optimization algorithm inspired by air currents of a tornado. Two main air currents - spiral and updraft - are mimicked. Spiral motion is designed for exploration of new search areas and updraft movements is deployed for exploitation of a promising candidate solution. Assignment of just one search direction to each particle at each iteration, leads to low computational complexity of the proposed algorithm respect to the conventional algorithms. Regardless of the step size parameters, the only parameter of the proposed algorithm, called tornado diameter, can be efficiently adjusted by randomization. Numerical results over six different benchmark cost functions indicate comparable and, in some cases, better performance of the proposed algorithm respect to some other metaheuristics.\n    ",
        "submission_date": "2016-12-31T00:00:00",
        "last_modified_date": "2016-12-31T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.01272",
        "title": "Autoencoder Regularized Network For Driving Style Representation Learning",
        "authors": [
            "Weishan Dong",
            "Ting Yuan",
            "Kai Yang",
            "Changsheng Li",
            "Shilei Zhang"
        ],
        "abstract": "In this paper, we study learning generalized driving style representations from automobile GPS trip data. We propose a novel Autoencoder Regularized deep neural Network (ARNet) and a trip encoding framework trip2vec to learn drivers' driving styles directly from GPS records, by combining supervised and unsupervised feature learning in a unified architecture. Experiments on a challenging driver number estimation problem and the driver identification problem show that ARNet can learn a good generalized driving style representation: It significantly outperforms existing methods and alternative architectures by reaching the least estimation error on average (0.68, less than one driver) and the highest identification accuracy (by at least 3% improvement) compared with traditional supervised learning methods.\n    ",
        "submission_date": "2017-01-05T00:00:00",
        "last_modified_date": "2017-01-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.01329",
        "title": "Generating Focussed Molecule Libraries for Drug Discovery with Recurrent Neural Networks",
        "authors": [
            "Marwin H.S. Segler",
            "Thierry Kogej",
            "Christian Tyrchan",
            "Mark P. Waller"
        ],
        "abstract": "In de novo drug design, computational strategies are used to generate novel molecules with good affinity to the desired biological target. In this work, we show that recurrent neural networks can be trained as generative models for molecular structures, similar to statistical language models in natural language processing. We demonstrate that the properties of the generated molecules correlate very well with the properties of the molecules used to train the model. In order to enrich libraries with molecules active towards a given biological target, we propose to fine-tune the model with small sets of molecules, which are known to be active against that target.\n",
        "submission_date": "2017-01-05T00:00:00",
        "last_modified_date": "2017-01-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.01461",
        "title": "Understanding the complexity of #SAT using knowledge compilation",
        "authors": [
            "Florent Capelli"
        ],
        "abstract": "Two main techniques have been used so far to solve the #P-hard problem #SAT. The first one, used in practice, is based on an extension of DPLL for model counting called exhaustive DPLL. The second approach, more theoretical, exploits the structure of the input to compute the number of satisfying assignments by usually using a dynamic programming scheme on a decomposition of the formula. In this paper, we make a first step toward the separation of these two techniques by exhibiting a family of formulas that can be solved in polynomial time with the first technique but needs an exponential time with the second one. We show this by observing that both techniques implicitely construct a very specific boolean circuit equivalent to the input formula. We then show that every beta-acyclic formula can be represented by a polynomial size circuit corresponding to the first method and exhibit a family of beta-acyclic formulas which cannot be represented by polynomial size circuits corresponding to the second method. This result shed a new light on the complexity of #SAT and related problems on beta-acyclic formulas. As a byproduct, we give new handy tools to design algorithms on beta-acyclic hypergraphs.\n    ",
        "submission_date": "2017-01-05T00:00:00",
        "last_modified_date": "2017-01-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.01654",
        "title": "Application of Fuzzy Logic in Design of Smart Washing Machine",
        "authors": [
            "Rao Farhat Masood"
        ],
        "abstract": "Washing machine is of great domestic necessity as it frees us from the burden of washing our clothes and saves ample of our time. This paper will cover the aspect of designing and developing of Fuzzy Logic based, Smart Washing Machine. The regular washing machine (timer based) makes use of multi-turned timer based start-stop mechanism which is mechanical as is prone to breakage. In addition to its starting and stopping issues, the mechanical timers are not efficient with respect of maintenance and electricity usage. Recent developments have shown that merger of digital electronics in optimal functionality of this machine is possible and nowadays in practice. A number of international renowned companies have developed the machine with the introduction of smart artificial intelligence. Such a machine makes use of sensors and smartly calculates the amount of run-time (washing time) for the main machine motor. Realtime calculations and processes are also catered in optimizing the run-time of the machine. The obvious result is smart time management, better economy of electricity and efficiency of work. This paper deals with the indigenization of FLC (Fuzzy Logic Controller) based Washing Machine, which is capable of automating the inputs and getting the desired output (wash-time).\n    ",
        "submission_date": "2017-01-04T00:00:00",
        "last_modified_date": "2017-03-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.01675",
        "title": "Pareto Efficient Multi Objective Optimization for Local Tuning of Analogy Based Estimation",
        "authors": [
            "Mohammad Azzeh",
            "Ali Bou Nassif",
            "Shadi Banitaan",
            "Fadi Almasalha"
        ],
        "abstract": "Analogy Based Effort Estimation (ABE) is one of the prominent methods for software effort estimation. The fundamental concept of ABE is closer to the mentality of expert estimation but with an automated procedure in which the final estimate is generated by reusing similar historical projects. The main key issue when using ABE is how to adapt the effort of the retrieved nearest neighbors. The adaptation process is an essential part of ABE to generate more successful accurate estimation based on tuning the selected raw solutions, using some adaptation strategy. In this study we show that there are three interrelated decision variables that have great impact on the success of adaptation method: (1) number of nearest analogies (k), (2) optimum feature set needed for adaptation, and (3) adaptation weights. To find the right decision regarding these variables, one need to study all possible combinations and evaluate them individually to select the one that can improve all prediction evaluation measures. The existing evaluation measures usually behave differently, presenting sometimes opposite trends in evaluating prediction methods. This means that changing one decision variable could improve one evaluation measure while it is decreasing the others. Therefore, the main theme of this research is how to come up with best decision variables that improve adaptation strategy and thus, the overall evaluation measures without degrading the others. The impact of these decisions together has not been investigated before, therefore we propose to view the building of adaptation procedure as a multi-objective optimization problem. The Particle Swarm Optimization Algorithm (PSO) is utilized to find the optimum solutions for such decision variables based on optimizing multiple evaluation measures\n    ",
        "submission_date": "2016-11-29T00:00:00",
        "last_modified_date": "2016-11-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.02025",
        "title": "Multi-level Representations for Fine-Grained Typing of Knowledge Base Entities",
        "authors": [
            "Yadollah Yaghoobzadeh",
            "Hinrich Sch\u00fctze"
        ],
        "abstract": "Entities are essential elements of natural language. In this paper, we present methods for learning multi-level representations of entities on three complementary levels: character (character patterns in entity names extracted, e.g., by neural networks), word (embeddings of words in entity names) and entity (entity embeddings). We investigate state-of-the-art learning methods on each level and find large differences, e.g., for deep learning models, traditional ngram features and the subword model of fasttext (Bojanowski et al., 2016) on the character level; for word2vec (Mikolov et al., 2013) on the word level; and for the order-aware model wang2vec (Ling et al., 2015a) on the entity level. We confirm experimentally that each level of representation contributes complementary information and a joint representation of all three levels improves the existing embedding based baseline for fine-grained entity typing by a large margin. Additionally, we show that adding information from entity descriptions further improves multi-level representations of entities.\n    ",
        "submission_date": "2017-01-08T00:00:00",
        "last_modified_date": "2017-01-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.02058",
        "title": "Coupled Compound Poisson Factorization",
        "authors": [
            "Mehmet E. Basbug",
            "Barbara E. Engelhardt"
        ],
        "abstract": "We present a general framework, the coupled compound Poisson factorization (CCPF), to capture the missing-data mechanism in extremely sparse data sets by coupling a hierarchical Poisson factorization with an arbitrary data-generating model. We derive a stochastic variational inference algorithm for the resulting model and, as examples of our framework, implement three different data-generating models---a mixture model, linear regression, and factor analysis---to robustly model non-random missing data in the context of clustering, prediction, and matrix factorization. In all three cases, we test our framework against models that ignore the missing-data mechanism on large scale studies with non-random missing data, and we show that explicitly modeling the missing-data mechanism substantially improves the quality of the results, as measured using data log likelihood on a held-out test set.\n    ",
        "submission_date": "2017-01-09T00:00:00",
        "last_modified_date": "2017-01-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.02272",
        "title": "Morphognosis: the shape of knowledge in space and time",
        "authors": [
            "Thomas E. Portegys"
        ],
        "abstract": "Artificial intelligence research to a great degree focuses on the brain and behaviors that the brain generates. But the brain, an extremely complex structure resulting from millions of years of evolution, can be viewed as a solution to problems posed by an environment existing in space and time. The environment generates signals that produce sensory events within an organism. Building an internal spatial and temporal model of the environment allows an organism to navigate and manipulate the environment. Higher intelligence might be the ability to process information coming from a larger extent of space-time. In keeping with nature's penchant for extending rather than replacing, the purpose of the mammalian neocortex might then be to record events from distant reaches of space and time and render them, as though yet near and present, to the older, deeper brain whose instinctual roles have changed little over eons. Here this notion is embodied in a model called morphognosis (morpho = shape and gnosis = knowledge). Its basic structure is a pyramid of event recordings called a morphognostic. At the apex of the pyramid are the most recent and nearby events. Receding from the apex are less recent and possibly more distant events. A morphognostic can thus be viewed as a structure of progressively larger chunks of space-time knowledge. A set of morphognostics forms long-term memories that are learned by exposure to the environment. A cellular automaton is used as the platform to investigate the morphognosis model, using a simulated organism that learns to forage in its world for food, build a nest, and play the game of Pong.\n    ",
        "submission_date": "2017-01-05T00:00:00",
        "last_modified_date": "2017-03-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.02343",
        "title": "Information Pursuit: A Bayesian Framework for Sequential Scene Parsing",
        "authors": [
            "Ehsan Jahangiri",
            "Erdem Yoruk",
            "Rene Vidal",
            "Laurent Younes",
            "Donald Geman"
        ],
        "abstract": "Despite enormous progress in object detection and classification, the problem of incorporating expected contextual relationships among object instances into modern recognition systems remains a key challenge. In this work we propose Information Pursuit, a Bayesian framework for scene parsing that combines prior models for the geometry of the scene and the spatial arrangement of objects instances with a data model for the output of high-level image classifiers trained to answer specific questions about the scene. In the proposed framework, the scene interpretation is progressively refined as evidence accumulates from the answers to a sequence of questions. At each step, we choose the question to maximize the mutual information between the new answer and the full interpretation given the current evidence obtained from previous inquiries. We also propose a method for learning the parameters of the model from synthesized, annotated scenes obtained by top-down sampling from an easy-to-learn generative scene model. Finally, we introduce a database of annotated indoor scenes of dining room tables, which we use to evaluate the proposed approach.\n    ",
        "submission_date": "2017-01-09T00:00:00",
        "last_modified_date": "2017-01-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.02359",
        "title": "Playtime Measurement with Survival Analysis",
        "authors": [
            "Markus Viljanen",
            "Antti Airola",
            "Jukka Heikkonen",
            "Tapio Pahikkala"
        ],
        "abstract": "Maximizing product use is a central goal of many businesses, which makes retention and monetization two central analytics metrics in games. Player retention may refer to various duration variables quantifying product use: total playtime or session playtime are popular research targets, and active playtime is well-suited for subscription games. Such research often has the goal of increasing player retention or conversely decreasing player churn. Survival analysis is a framework of powerful tools well suited for retention type data. This paper contributes new methods to game analytics on how playtime can be analyzed using survival analysis without covariates. Survival and hazard estimates provide both a visual and an analytic interpretation of the playtime phenomena as a funnel type nonparametric estimate. Metrics based on the survival curve can be used to aggregate this playtime information into a single statistic. Comparison of survival curves between cohorts provides a scientific AB-test. All these methods work on censored data and enable computation of confidence intervals. This is especially important in time and sample limited data which occurs during game development. Throughout this paper, we illustrate the application of these methods to real world game development problems on the Hipster Sheep mobile game.\n    ",
        "submission_date": "2017-01-04T00:00:00",
        "last_modified_date": "2017-01-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.02369",
        "title": "Reinforcement Learning based Embodied Agents Modelling Human Users Through Interaction and Multi-Sensory Perception",
        "authors": [
            "Kory W. Mathewson",
            "Patrick M. Pilarski"
        ],
        "abstract": "This paper extends recent work in interactive machine learning (IML) focused on effectively incorporating human feedback. We show how control and feedback signals complement each other in systems which model human reward. We demonstrate that simultaneously incorporating human control and feedback signals can improve interactive robotic systems' performance on a self-mirrored movement control task where an RL-agent controlled right arm attempts to match the preprogrammed movement pattern of the left arm. We illustrate the impact of varying human feedback parameters on task performance by investigating the probability of giving feedback on each time step and the likelihood of given feedback being correct. We further illustrate that varying the temporal decay with which the agent incorporates human feedback has a significant impact on task performance. We found that smearing human feedback over time steps improves performance and we show varying the probability of feedback at each time step, and an increased likelihood of those feedbacks being 'correct' can impact agent performance. We conclude that understanding latent variables in human feedback is crucial for learning algorithms acting in human-machine interaction domains.\n    ",
        "submission_date": "2017-01-09T00:00:00",
        "last_modified_date": "2017-01-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.02392",
        "title": "Reinforcement Learning via Recurrent Convolutional Neural Networks",
        "authors": [
            "Tanmay Shankar",
            "Santosha K. Dwivedy",
            "Prithwijit Guha"
        ],
        "abstract": "Deep Reinforcement Learning has enabled the learning of policies for complex tasks in partially observable environments, without explicitly learning the underlying model of the tasks. While such model-free methods achieve considerable performance, they often ignore the structure of task. We present a natural representation of to Reinforcement Learning (RL) problems using Recurrent Convolutional Neural Networks (RCNNs), to better exploit this inherent structure. We define 3 such RCNNs, whose forward passes execute an efficient Value Iteration, propagate beliefs of state in partially observable environments, and choose optimal actions respectively. Backpropagating gradients through these RCNNs allows the system to explicitly learn the Transition Model and Reward Function associated with the underlying MDP, serving as an elegant alternative to classical model-based RL. We evaluate the proposed algorithms in simulation, considering a robot planning problem. We demonstrate the capability of our framework to reduce the cost of replanning, learn accurate MDP models, and finally re-plan with learnt models to achieve near-optimal policies.\n    ",
        "submission_date": "2017-01-09T00:00:00",
        "last_modified_date": "2017-01-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.02477",
        "title": "Multi-task Learning Of Deep Neural Networks For Audio Visual Automatic Speech Recognition",
        "authors": [
            "Abhinav Thanda",
            "Shankar M Venkatesan"
        ],
        "abstract": "Multi-task learning (MTL) involves the simultaneous training of two or more related tasks over shared representations. In this work, we apply MTL to audio-visual automatic speech recognition(AV-ASR). Our primary task is to learn a mapping between audio-visual fused features and frame labels obtained from acoustic GMM/HMM model. This is combined with an auxiliary task which maps visual features to frame labels obtained from a separate visual GMM/HMM model. The MTL model is tested at various levels of babble noise and the results are compared with a base-line hybrid DNN-HMM AV-ASR model. Our results indicate that MTL is especially useful at higher level of noise. Compared to base-line, upto 7\\% relative improvement in WER is reported at -3 SNR dB\n    ",
        "submission_date": "2017-01-10T00:00:00",
        "last_modified_date": "2017-01-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.02490",
        "title": "Real-Time Bidding by Reinforcement Learning in Display Advertising",
        "authors": [
            "Han Cai",
            "Kan Ren",
            "Weinan Zhang",
            "Kleanthis Malialis",
            "Jun Wang",
            "Yong Yu",
            "Defeng Guo"
        ],
        "abstract": "The majority of online display ads are served through real-time bidding (RTB) --- each ad display impression is auctioned off in real-time when it is just being generated from a user visit. To place an ad automatically and optimally, it is critical for advertisers to devise a learning algorithm to cleverly bid an ad impression in real-time. Most previous works consider the bid decision as a static optimization problem of either treating the value of each impression independently or setting a bid price to each segment of ad volume. However, the bidding for a given ad campaign would repeatedly happen during its life span before the budget runs out. As such, each bid is strategically correlated by the constrained budget and the overall effectiveness of the campaign (e.g., the rewards from generated clicks), which is only observed after the campaign has completed. Thus, it is of great interest to devise an optimal bidding strategy sequentially so that the campaign budget can be dynamically allocated across all the available impressions on the basis of both the immediate and future rewards. In this paper, we formulate the bid decision process as a reinforcement learning problem, where the state space is represented by the auction information and the campaign's real-time parameters, while an action is the bid price to set. By modeling the state transition via auction competition, we build a Markov Decision Process framework for learning the optimal bidding policy to optimize the advertising performance in the dynamic real-time bidding environment. Furthermore, the scalability problem from the large real-world auction volume and campaign budget is well handled by state value approximation using neural networks.\n    ",
        "submission_date": "2017-01-10T00:00:00",
        "last_modified_date": "2017-01-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.02547",
        "title": "A Convenient Category for Higher-Order Probability Theory",
        "authors": [
            "Chris Heunen",
            "Ohad Kammar",
            "Sam Staton",
            "Hongseok Yang"
        ],
        "abstract": "Higher-order probabilistic programming languages allow programmers to write sophisticated models in machine learning and statistics in a succinct and structured way, but step outside the standard measure-theoretic formalization of probability theory. Programs may use both higher-order functions and continuous distributions, or even define a probability distribution on functions. But standard probability theory does not handle higher-order functions well: the category of measurable spaces is not cartesian closed.\n",
        "submission_date": "2017-01-10T00:00:00",
        "last_modified_date": "2020-11-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.02593",
        "title": "A Simple and Accurate Syntax-Agnostic Neural Model for Dependency-based Semantic Role Labeling",
        "authors": [
            "Diego Marcheggiani",
            "Anton Frolov",
            "Ivan Titov"
        ],
        "abstract": "We introduce a simple and accurate neural model for dependency-based semantic role labeling. Our model predicts predicate-argument dependencies relying on states of a bidirectional LSTM encoder. The semantic role labeler achieves competitive performance on English, even without any kind of syntactic information and only using local inference. However, when automatically predicted part-of-speech tags are provided as input, it substantially outperforms all previous local models and approaches the best reported results on the English CoNLL-2009 dataset. We also consider Chinese, Czech and Spanish where our approach also achieves competitive results. Syntactic parsers are unreliable on out-of-domain data, so standard (i.e., syntactically-informed) SRL models are hindered when tested in this setting. Our syntax-agnostic model appears more robust, resulting in the best reported results on standard out-of-domain test sets.\n    ",
        "submission_date": "2017-01-10T00:00:00",
        "last_modified_date": "2017-06-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.02810",
        "title": "OpenNMT: Open-Source Toolkit for Neural Machine Translation",
        "authors": [
            "Guillaume Klein",
            "Yoon Kim",
            "Yuntian Deng",
            "Jean Senellart",
            "Alexander M. Rush"
        ],
        "abstract": "We describe an open-source toolkit for neural machine translation (NMT). The toolkit prioritizes efficiency, modularity, and extensibility with the goal of supporting NMT research into model architectures, feature representations, and source modalities, while maintaining competitive performance and reasonable training requirements. The toolkit consists of modeling and translation support, as well as detailed pedagogical documentation about the underlying techniques.\n    ",
        "submission_date": "2017-01-10T00:00:00",
        "last_modified_date": "2017-03-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.02854",
        "title": "Towards Decoding as Continuous Optimization in Neural Machine Translation",
        "authors": [
            "Cong Duy Vu Hoang",
            "Gholamreza Haffari",
            "Trevor Cohn"
        ],
        "abstract": "We propose a novel decoding approach for neural machine translation (NMT) based on continuous optimisation. We convert decoding - basically a discrete optimization problem - into a continuous optimization problem. The resulting constrained continuous optimisation problem is then tackled using gradient-based methods. Our powerful decoding framework enables decoding intractable models such as the intersection of left-to-right and right-to-left (bidirectional) as well as source-to-target and target-to-source (bilingual) NMT models. Our empirical results show that our decoding framework is effective, and leads to substantial improvements in translations generated from the intersected models where the typical greedy or beam search is not feasible. We also compare our framework against reranking, and analyse its advantages and disadvantages.\n    ",
        "submission_date": "2017-01-11T00:00:00",
        "last_modified_date": "2017-07-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.02870",
        "title": "Context-aware Captions from Context-agnostic Supervision",
        "authors": [
            "Ramakrishna Vedantam",
            "Samy Bengio",
            "Kevin Murphy",
            "Devi Parikh",
            "Gal Chechik"
        ],
        "abstract": "We introduce an inference technique to produce discriminative context-aware image captions (captions that describe differences between images or visual concepts) using only generic context-agnostic training data (captions that describe a concept or an image in isolation). For example, given images and captions of \"siamese cat\" and \"tiger cat\", we generate language that describes the \"siamese cat\" in a way that distinguishes it from \"tiger cat\". Our key novelty is that we show how to do joint inference over a language model that is context-agnostic and a listener which distinguishes closely-related concepts. We first apply our technique to a justification task, namely to describe why an image contains a particular fine-grained category as opposed to another closely-related category of the CUB-200-2011 dataset. We then study discriminative image captioning to generate language that uniquely refers to one of two semantically-similar images in the COCO dataset. Evaluations with discriminative ground truth for justification and human studies for discriminative image captioning reveal that our approach outperforms baseline generative and speaker-listener approaches for discrimination.\n    ",
        "submission_date": "2017-01-11T00:00:00",
        "last_modified_date": "2017-07-31T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.03102",
        "title": "Linear Disentangled Representation Learning for Facial Actions",
        "authors": [
            "Xiang Xiang",
            "Trac D. Tran"
        ],
        "abstract": "Limited annotated data available for the recognition of facial expression and action units embarrasses the training of deep networks, which can learn disentangled invariant features. However, a linear model with just several parameters normally is not demanding in terms of training data. In this paper, we propose an elegant linear model to untangle confounding factors in challenging realistic multichannel signals such as 2D face videos. The simple yet powerful model does not rely on huge training data and is natural for recognizing facial actions without explicitly disentangling the identity. Base on well-understood intuitive linear models such as Sparse Representation based Classification (SRC), previous attempts require a prepossessing of explicit decoupling which is practically inexact. Instead, we exploit the low-rank property across frames to subtract the underlying neutral faces which are modeled jointly with sparse representation on the action components with group sparsity enforced. On the extended Cohn-Kanade dataset (CK+), our one-shot automatic method on raw face videos performs as competitive as SRC applied on manually prepared action components and performs even better than SRC in terms of true positive rate. We apply the model to the even more challenging task of facial action unit recognition, verified on the MPI Face Video Database (MPI-VDB) achieving a decent performance. All the programs and data have been made publicly available.\n    ",
        "submission_date": "2017-01-11T00:00:00",
        "last_modified_date": "2017-01-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.03162",
        "title": "Real-time eSports Match Result Prediction",
        "authors": [
            "Yifan Yang",
            "Tian Qin",
            "Yu-Heng Lei"
        ],
        "abstract": "In this paper, we try to predict the winning team of a match in the multiplayer eSports game Dota 2. To address the weaknesses of previous work, we consider more aspects of prior (pre-match) features from individual players' match history, as well as real-time (during-match) features at each minute as the match progresses. We use logistic regression, the proposed Attribute Sequence Model, and their combinations as the prediction models. In a dataset of 78362 matches where 20631 matches contain replay data, our experiments show that adding more aspects of prior features improves accuracy from 58.69% to 71.49%, and introducing real-time features achieves up to 93.73% accuracy when predicting at the 40th minute.\n    ",
        "submission_date": "2016-12-10T00:00:00",
        "last_modified_date": "2016-12-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.03360",
        "title": "Residual LSTM: Design of a Deep Recurrent Architecture for Distant Speech Recognition",
        "authors": [
            "Jaeyoung Kim",
            "Mostafa El-Khamy",
            "Jungwon Lee"
        ],
        "abstract": "In this paper, a novel architecture for a deep recurrent neural network, residual LSTM is introduced. A plain LSTM has an internal memory cell that can learn long term dependencies of sequential data. It also provides a temporal shortcut path to avoid vanishing or exploding gradients in the temporal domain. The residual LSTM provides an additional spatial shortcut path from lower layers for efficient training of deep networks with multiple LSTM layers. Compared with the previous work, highway LSTM, residual LSTM separates a spatial shortcut path with temporal one by using output layers, which can help to avoid a conflict between spatial and temporal-domain gradient flows. Furthermore, residual LSTM reuses the output projection matrix and the output gate of LSTM to control the spatial information flow instead of additional gate networks, which effectively reduces more than 10% of network parameters. An experiment for distant speech recognition on the AMI SDM corpus shows that 10-layer plain and highway LSTM networks presented 13.7% and 6.2% increase in WER over 3-layer aselines, respectively. On the contrary, 10-layer residual LSTM networks provided the lowest WER 41.0%, which corresponds to 3.3% and 2.8% WER reduction over plain and highway LSTM networks, respectively.\n    ",
        "submission_date": "2017-01-10T00:00:00",
        "last_modified_date": "2017-06-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.03577",
        "title": "Kernel Approximation Methods for Speech Recognition",
        "authors": [
            "Avner May",
            "Alireza Bagheri Garakani",
            "Zhiyun Lu",
            "Dong Guo",
            "Kuan Liu",
            "Aur\u00e9lien Bellet",
            "Linxi Fan",
            "Michael Collins",
            "Daniel Hsu",
            "Brian Kingsbury",
            "Michael Picheny",
            "Fei Sha"
        ],
        "abstract": "We study large-scale kernel methods for acoustic modeling in speech recognition and compare their performance to deep neural networks (DNNs). We perform experiments on four speech recognition datasets, including the TIMIT and Broadcast News benchmark tasks, and compare these two types of models on frame-level performance metrics (accuracy, cross-entropy), as well as on recognition metrics (word/character error rate). In order to scale kernel methods to these large datasets, we use the random Fourier feature method of Rahimi and Recht (2007). We propose two novel techniques for improving the performance of kernel acoustic models. First, in order to reduce the number of random features required by kernel models, we propose a simple but effective method for feature selection. The method is able to explore a large number of non-linear features while maintaining a compact model more efficiently than existing approaches. Second, we present a number of frame-level metrics which correlate very strongly with recognition performance when computed on the heldout set; we take advantage of these correlations by monitoring these metrics during training in order to decide when to stop learning. This technique can noticeably improve the recognition performance of both DNN and kernel models, while narrowing the gap between them. Additionally, we show that the linear bottleneck method of Sainath et al. (2013) improves the performance of our kernel models significantly, in addition to speeding up training and making the models more compact. Together, these three methods dramatically improve the performance of kernel acoustic models, making their performance comparable to DNNs on the tasks we explored.\n    ",
        "submission_date": "2017-01-13T00:00:00",
        "last_modified_date": "2017-01-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.03578",
        "title": "Efficient Transfer Learning Schemes for Personalized Language Modeling using Recurrent Neural Network",
        "authors": [
            "Seunghyun Yoon",
            "Hyeongu Yun",
            "Yuna Kim",
            "Gyu-tae Park",
            "Kyomin Jung"
        ],
        "abstract": "In this paper, we propose an efficient transfer leaning methods for training a personalized language model using a recurrent neural network with long short-term memory architecture. With our proposed fast transfer learning schemes, a general language model is updated to a personalized language model with a small amount of user data and a limited computing resource. These methods are especially useful for a mobile device environment while the data is prevented from transferring out of the device for privacy purposes. Through experiments on dialogue data in a drama, it is verified that our transfer learning methods have successfully generated the personalized language model, whose output is more similar to the personal language style in both qualitative and quantitative aspects.\n    ",
        "submission_date": "2017-01-13T00:00:00",
        "last_modified_date": "2017-01-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.03757",
        "title": "Deep Probabilistic Programming",
        "authors": [
            "Dustin Tran",
            "Matthew D. Hoffman",
            "Rif A. Saurous",
            "Eugene Brevdo",
            "Kevin Murphy",
            "David M. Blei"
        ],
        "abstract": "We propose Edward, a Turing-complete probabilistic programming language. Edward defines two compositional representations---random variables and inference. By treating inference as a first class citizen, on a par with modeling, we show that probabilistic programming can be as flexible and computationally efficient as traditional deep learning. For flexibility, Edward makes it easy to fit the same model using a variety of composable inference methods, ranging from point estimation to variational inference to MCMC. In addition, Edward can reuse the modeling representation as part of inference, facilitating the design of rich variational models and generative adversarial networks. For efficiency, Edward is integrated into TensorFlow, providing significant speedups over existing probabilistic systems. For example, we show on a benchmark logistic regression task that Edward is at least 35x faster than Stan and 6x faster than PyMC3. Further, Edward incurs no runtime overhead: it is as fast as handwritten TensorFlow.\n    ",
        "submission_date": "2017-01-13T00:00:00",
        "last_modified_date": "2017-03-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.03891",
        "title": "Learning to Invert: Signal Recovery via Deep Convolutional Networks",
        "authors": [
            "Ali Mousavi",
            "Richard G. Baraniuk"
        ],
        "abstract": "The promise of compressive sensing (CS) has been offset by two significant challenges. First, real-world data is not exactly sparse in a fixed basis. Second, current high-performance recovery algorithms are slow to converge, which limits CS to either non-real-time applications or scenarios where massive back-end computing is available. In this paper, we attack both of these challenges head-on by developing a new signal recovery framework we call {\\em DeepInverse} that learns the inverse transformation from measurement vectors to signals using a {\\em deep convolutional network}. When trained on a set of representative images, the network learns both a representation for the signals (addressing challenge one) and an inverse map approximating a greedy or convex recovery algorithm (addressing challenge two). Our experiments indicate that the DeepInverse network closely approximates the solution produced by state-of-the-art CS recovery algorithms yet is hundreds of times faster in run time. The tradeoff for the ultrafast run time is a computationally intensive, off-line training procedure typical to deep networks. However, the training needs to be completed only once, which makes the approach attractive for a host of sparse recovery problems.\n    ",
        "submission_date": "2017-01-14T00:00:00",
        "last_modified_date": "2017-01-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.04024",
        "title": "A Copy-Augmented Sequence-to-Sequence Architecture Gives Good Performance on Task-Oriented Dialogue",
        "authors": [
            "Mihail Eric",
            "Christopher D. Manning"
        ],
        "abstract": "Task-oriented dialogue focuses on conversational agents that participate in user-initiated dialogues on domain-specific topics. In contrast to chatbots, which simply seek to sustain open-ended meaningful discourse, existing task-oriented agents usually explicitly model user intent and belief states. This paper examines bypassing such an explicit representation by depending on a latent neural embedding of state and learning selective attention to dialogue history together with copying to incorporate relevant prior context. We complement recent work by showing the effectiveness of simple sequence-to-sequence neural architectures with a copy mechanism. Our model outperforms more complex memory-augmented models by 7% in per-response generation and is on par with the current state-of-the-art on DSTC2.\n    ",
        "submission_date": "2017-01-15T00:00:00",
        "last_modified_date": "2017-08-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.04079",
        "title": "Agent-Agnostic Human-in-the-Loop Reinforcement Learning",
        "authors": [
            "David Abel",
            "John Salvatier",
            "Andreas Stuhlm\u00fcller",
            "Owain Evans"
        ],
        "abstract": "Providing Reinforcement Learning agents with expert advice can dramatically improve various aspects of learning. Prior work has developed teaching protocols that enable agents to learn efficiently in complex environments; many of these methods tailor the teacher's guidance to agents with a particular representation or underlying learning scheme, offering effective but specialized teaching procedures. In this work, we explore protocol programs, an agent-agnostic schema for Human-in-the-Loop Reinforcement Learning. Our goal is to incorporate the beneficial properties of a human teacher into Reinforcement Learning without making strong assumptions about the inner workings of the agent. We show how to represent existing approaches such as action pruning, reward shaping, and training in simulation as special cases of our schema and conduct preliminary experiments on simple domains.\n    ",
        "submission_date": "2017-01-15T00:00:00",
        "last_modified_date": "2017-01-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.04113",
        "title": "Near Optimal Behavior via Approximate State Abstraction",
        "authors": [
            "David Abel",
            "D. Ellis Hershkowitz",
            "Michael L. Littman"
        ],
        "abstract": "The combinatorial explosion that plagues planning and reinforcement learning (RL) algorithms can be moderated using state abstraction. Prohibitively large task representations can be condensed such that essential information is preserved, and consequently, solutions are tractably computable. However, exact abstractions, which treat only fully-identical situations as equivalent, fail to present opportunities for abstraction in environments where no two situations are exactly alike. In this work, we investigate approximate state abstractions, which treat nearly-identical situations as equivalent. We present theoretical guarantees of the quality of behaviors derived from four types of approximate abstractions. Additionally, we empirically demonstrate that approximate abstractions lead to reduction in task complexity and bounded loss of optimality of behavior in a variety of environments.\n    ",
        "submission_date": "2017-01-15T00:00:00",
        "last_modified_date": "2017-01-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.04128",
        "title": "Understanding the Effective Receptive Field in Deep Convolutional Neural Networks",
        "authors": [
            "Wenjie Luo",
            "Yujia Li",
            "Raquel Urtasun",
            "Richard Zemel"
        ],
        "abstract": "We study characteristics of receptive fields of units in deep convolutional networks. The receptive field size is a crucial issue in many visual tasks, as the output must respond to large enough areas in the image to capture information about large objects. We introduce the notion of an effective receptive field, and show that it both has a Gaussian distribution and only occupies a fraction of the full theoretical receptive field. We analyze the effective receptive field in several architecture designs, and the effect of nonlinear activations, dropout, sub-sampling and skip connections on it. This leads to suggestions for ways to address its tendency to be too small.\n    ",
        "submission_date": "2017-01-15T00:00:00",
        "last_modified_date": "2017-01-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.04143",
        "title": "Vulnerability of Deep Reinforcement Learning to Policy Induction Attacks",
        "authors": [
            "Vahid Behzadan",
            "Arslan Munir"
        ],
        "abstract": "Deep learning classifiers are known to be inherently vulnerable to manipulation by intentionally perturbed inputs, named adversarial examples. In this work, we establish that reinforcement learning techniques based on Deep Q-Networks (DQNs) are also vulnerable to adversarial input perturbations, and verify the transferability of adversarial examples across different DQN models. Furthermore, we present a novel class of attacks based on this vulnerability that enable policy manipulation and induction in the learning process of DQNs. We propose an attack mechanism that exploits the transferability of adversarial examples to implement policy induction attacks on DQNs, and demonstrate its efficacy and impact through experimental study of a game-learning scenario.\n    ",
        "submission_date": "2017-01-16T00:00:00",
        "last_modified_date": "2017-01-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.04222",
        "title": "Achieving Privacy in the Adversarial Multi-Armed Bandit",
        "authors": [
            "Aristide C. Y. Tossou",
            "Christos Dimitrakakis"
        ],
        "abstract": "In this paper, we improve the previously best known regret bound to achieve $\\epsilon$-differential privacy in oblivious adversarial bandits from $\\mathcal{O}{(T^{2/3}/\\epsilon)}$ to $\\mathcal{O}{(\\sqrt{T} \\ln T /\\epsilon)}$. This is achieved by combining a Laplace Mechanism with EXP3. We show that though EXP3 is already differentially private, it leaks a linear amount of information in $T$. However, we can improve this privacy by relying on its intrinsic exponential mechanism for selecting actions. This allows us to reach $\\mathcal{O}{(\\sqrt{\\ln T})}$-DP, with a regret of $\\mathcal{O}{(T^{2/3})}$ that holds against an adaptive adversary, an improvement from the best known of $\\mathcal{O}{(T^{3/4})}$. This is done by using an algorithm that run EXP3 in a mini-batch loop. Finally, we run experiments that clearly demonstrate the validity of our theoretical analysis.\n    ",
        "submission_date": "2017-01-16T00:00:00",
        "last_modified_date": "2017-01-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.04238",
        "title": "Thompson Sampling For Stochastic Bandits with Graph Feedback",
        "authors": [
            "Aristide C. Y. Tossou",
            "Christos Dimitrakakis",
            "Devdatt Dubhashi"
        ],
        "abstract": "We present a novel extension of Thompson Sampling for stochastic sequential decision problems with graph feedback, even when the graph structure itself is unknown and/or changing. We provide theoretical guarantees on the Bayesian regret of the algorithm, linking its performance to the underlying properties of the graph. Thompson Sampling has the advantage of being applicable without the need to construct complicated upper confidence bounds for different problems. We illustrate its performance through extensive experimental results on real and simulated networks with graph feedback. More specifically, we tested our algorithms on power law, planted partitions and Erdo's-Renyi graphs, as well as on graphs derived from Facebook and Flixster data. These all show that our algorithms clearly outperform related methods that employ upper confidence bounds, even if the latter use more information about the graph.\n    ",
        "submission_date": "2017-01-16T00:00:00",
        "last_modified_date": "2017-01-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.04503",
        "title": "Deep Learning for Computational Chemistry",
        "authors": [
            "Garrett B. Goh",
            "Nathan O. Hodas",
            "Abhinav Vishnu"
        ],
        "abstract": "The rise and fall of artificial neural networks is well documented in the scientific literature of both computer science and computational chemistry. Yet almost two decades later, we are now seeing a resurgence of interest in deep learning, a machine learning algorithm based on multilayer neural networks. Within the last few years, we have seen the transformative impact of deep learning in many domains, particularly in speech recognition and computer vision, to the extent that the majority of expert practitioners in those field are now regularly eschewing prior established models in favor of deep learning models. In this review, we provide an introductory overview into the theory of deep neural networks and their unique properties that distinguish them from traditional machine learning algorithms used in cheminformatics. By providing an overview of the variety of emerging applications of deep neural networks, we highlight its ubiquity and broad applicability to a wide range of challenges in the field, including QSAR, virtual screening, protein structure prediction, quantum chemistry, materials design and property prediction. In reviewing the performance of deep neural networks, we observed a consistent outperformance against non-neural networks state-of-the-art models across disparate research topics, and deep neural network based models often exceeded the \"glass ceiling\" expectations of their respective tasks. Coupled with the maturity of GPU-accelerated computing for training deep neural networks and the exponential growth of chemical data on which to train these networks on, we anticipate that deep learning algorithms will be a valuable tool for computational chemistry.\n    ",
        "submission_date": "2017-01-17T00:00:00",
        "last_modified_date": "2017-01-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.04528",
        "title": "From Community Detection to Community Profiling",
        "authors": [
            "Hongyun Cai",
            "Vincent W. Zheng",
            "Fanwei Zhu",
            "Kevin Chen-Chuan Chang",
            "Zi Huang"
        ],
        "abstract": "Most existing community-related studies focus on detection, which aim to find the community membership for each user from user friendship links. However, membership alone, without a complete profile of what a community is and how it interacts with other communities, has limited applications. This motivates us to consider systematically profiling the communities and thereby developing useful community-level applications. In this paper, we for the first time formalize the concept of community profiling. With rich user information on the network, such as user published content and user diffusion links, we characterize a community in terms of both its internal content profile and external diffusion profile. The difficulty of community profiling is often underestimated. We novelly identify three unique challenges and propose a joint Community Profiling and Detection (CPD) model to address them accordingly. We also contribute a scalable inference algorithm, which scales linearly with the data size and it is easily parallelizable. We evaluate CPD on large-scale real-world data sets, and show that it is significantly better than the state-of-the-art baselines in various tasks.\n    ",
        "submission_date": "2017-01-17T00:00:00",
        "last_modified_date": "2017-01-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.05004",
        "title": "Converting Cascade-Correlation Neural Nets into Probabilistic Generative Models",
        "authors": [
            "Ardavan Salehi Nobandegani",
            "Thomas R. Shultz"
        ],
        "abstract": "Humans are not only adept in recognizing what class an input instance belongs to (i.e., classification task), but perhaps more remarkably, they can imagine (i.e., generate) plausible instances of a desired class with ease, when prompted. Inspired by this, we propose a framework which allows transforming Cascade-Correlation Neural Networks (CCNNs) into probabilistic generative models, thereby enabling CCNNs to generate samples from a category of interest. CCNNs are a well-known class of deterministic, discriminative NNs, which autonomously construct their topology, and have been successful in giving accounts for a variety of psychological phenomena. Our proposed framework is based on a Markov Chain Monte Carlo (MCMC) method, called the Metropolis-adjusted Langevin algorithm, which capitalizes on the gradient information of the target distribution to direct its explorations towards regions of high probability, thereby achieving good mixing properties. Through extensive simulations, we demonstrate the efficacy of our proposed framework.\n    ",
        "submission_date": "2017-01-18T00:00:00",
        "last_modified_date": "2017-01-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.05131",
        "title": "Basic protocols in quantum reinforcement learning with superconducting circuits",
        "authors": [
            "Lucas Lamata"
        ],
        "abstract": "Superconducting circuit technologies have recently achieved quantum protocols involving closed feedback loops. Quantum artificial intelligence and quantum machine learning are emerging fields inside quantum technologies which may enable quantum devices to acquire information from the outer world and improve themselves via a learning process. Here we propose the implementation of basic protocols in quantum reinforcement learning, with superconducting circuits employing feedback-loop control. We introduce diverse scenarios for proof-of-principle experiments with state-of-the-art superconducting circuit technologies and analyze their feasibility in presence of imperfections. The field of quantum artificial intelligence implemented with superconducting circuits paves the way for enhanced quantum control and quantum computation protocols.\n    ",
        "submission_date": "2017-01-18T00:00:00",
        "last_modified_date": "2017-05-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.05221",
        "title": "Parsimonious Inference on Convolutional Neural Networks: Learning and applying on-line kernel activation rules",
        "authors": [
            "I. Theodorakopoulos",
            "V. Pothos",
            "D. Kastaniotis",
            "N. Fragoulis"
        ],
        "abstract": "A new, radical CNN design approach is presented in this paper, considering the reduction of the total computational load during inference. This is achieved by a new holistic intervention on both the CNN architecture and the training procedure, which targets to the parsimonious inference by learning to exploit or remove the redundant capacity of a CNN architecture. This is accomplished, by the introduction of a new structural element that can be inserted as an add-on to any contemporary CNN architecture, whilst preserving or even improving its recognition accuracy. Our approach formulates a systematic and data-driven method for developing CNNs that are trained to eventually change size and form in real-time during inference, targeting to the smaller possible computational footprint. Results are provided for the optimal implementation on a few modern, high-end mobile computing platforms indicating a significant speed-up of up to x3 times.\n    ",
        "submission_date": "2017-01-18T00:00:00",
        "last_modified_date": "2017-01-31T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.05311",
        "title": "Semantic Evolutionary Concept Distances for Effective Information Retrieval in Query Expansion",
        "authors": [
            "Valentina Franzoni",
            "Yuanxi Li",
            "Clement H.C.Leung",
            "Alfredo Milani"
        ],
        "abstract": "In this work several semantic approaches to concept-based query expansion and reranking schemes are studied and compared with different ontology-based expansion methods in web document search and retrieval. In particular, we focus on concept-based query expansion schemes, where, in order to effectively increase the precision of web document retrieval and to decrease the users browsing time, the main goal is to quickly provide users with the most suitable query expansion. Two key tasks for query expansion in web document retrieval are to find the expansion candidates, as the closest concepts in web document domain, and to rank the expanded queries properly. The approach we propose aims at improving the expansion phase for better web document retrieval and precision. The basic idea is to measure the distance between candidate concepts using the PMING distance, a collaborative semantic proximity measure, i.e. a measure which can be computed by using statistical results from web search engine. Experiments show that the proposed technique can provide users with more satisfying expansion results and improve the quality of web document retrieval.\n    ",
        "submission_date": "2017-01-19T00:00:00",
        "last_modified_date": "2017-01-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.05498",
        "title": "T-LESS: An RGB-D Dataset for 6D Pose Estimation of Texture-less Objects",
        "authors": [
            "Tomas Hodan",
            "Pavel Haluza",
            "Stepan Obdrzalek",
            "Jiri Matas",
            "Manolis Lourakis",
            "Xenophon Zabulis"
        ],
        "abstract": "We introduce T-LESS, a new public dataset for estimating the 6D pose, i.e. translation and rotation, of texture-less rigid objects. The dataset features thirty industry-relevant objects with no significant texture and no discriminative color or reflectance properties. The objects exhibit symmetries and mutual similarities in shape and/or size. Compared to other datasets, a unique property is that some of the objects are parts of others. The dataset includes training and test images that were captured with three synchronized sensors, specifically a structured-light and a time-of-flight RGB-D sensor and a high-resolution RGB camera. There are approximately 39K training and 10K test images from each sensor. Additionally, two types of 3D models are provided for each object, i.e. a manually created CAD model and a semi-automatically reconstructed one. Training images depict individual objects against a black background. Test images originate from twenty test scenes having varying complexity, which increases from simple scenes with several isolated objects to very challenging ones with multiple instances of several objects and with a high amount of clutter and occlusion. The images were captured from a systematically sampled view sphere around the object/scene, and are annotated with accurate ground truth 6D poses of all modeled objects. Initial evaluation results indicate that the state of the art in 6D object pose estimation has ample room for improvement, especially in difficult cases with significant occlusion. The T-LESS dataset is available online at ",
        "submission_date": "2017-01-19T00:00:00",
        "last_modified_date": "2017-01-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.06075",
        "title": "Label Propagation on K-partite Graphs with Heterophily",
        "authors": [
            "Dingxiong Deng",
            "Fan Bai",
            "Yiqi Tang",
            "Shuigeng Zhou",
            "Cyrus Shahabi",
            "Linhong Zhu"
        ],
        "abstract": "In this paper, for the first time, we study label propagation in heterogeneous graphs under heterophily assumption. Homophily label propagation (i.e., two connected nodes share similar labels) in homogeneous graph (with same types of vertices and relations) has been extensively studied before. Unfortunately, real-life networks are heterogeneous, they contain different types of vertices (e.g., users, images, texts) and relations (e.g., friendships, co-tagging) and allow for each node to propagate both the same and opposite copy of labels to its neighbors. We propose a $\\mathcal{K}$-partite label propagation model to handle the mystifying combination of heterogeneous nodes/relations and heterophily propagation. With this model, we develop a novel label inference algorithm framework with update rules in near-linear time complexity. Since real networks change over time, we devise an incremental approach, which supports fast updates for both new data and evidence (e.g., ground truth labels) with guaranteed efficiency. We further provide a utility function to automatically determine whether an incremental or a re-modeling approach is favored. Extensive experiments on real datasets have verified the effectiveness and efficiency of our approach, and its superiority over the state-of-the-art label propagation methods.\n    ",
        "submission_date": "2017-01-21T00:00:00",
        "last_modified_date": "2017-01-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.06078",
        "title": "Lyrics-to-Audio Alignment by Unsupervised Discovery of Repetitive Patterns in Vowel Acoustics",
        "authors": [
            "Sungkyun Chang",
            "Kyogu Lee"
        ],
        "abstract": "Most of the previous approaches to lyrics-to-audio alignment used a pre-developed automatic speech recognition (ASR) system that innately suffered from several difficulties to adapt the speech model to individual singers. A significant aspect missing in previous works is the self-learnability of repetitive vowel patterns in the singing voice, where the vowel part used is more consistent than the consonant part. Based on this, our system first learns a discriminative subspace of vowel sequences, based on weighted symmetric non-negative matrix factorization (WS-NMF), by taking the self-similarity of a standard acoustic feature as an input. Then, we make use of canonical time warping (CTW), derived from a recent computer vision technique, to find an optimal spatiotemporal transformation between the text and the acoustic sequences. Experiments with Korean and English data sets showed that deploying this method after a pre-developed, unsupervised, singing source separation achieved more promising results than other state-of-the-art unsupervised approaches and an existing ASR-based system.\n    ",
        "submission_date": "2017-01-21T00:00:00",
        "last_modified_date": "2017-01-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.06106",
        "title": "Neurogenesis-Inspired Dictionary Learning: Online Model Adaption in a Changing World",
        "authors": [
            "Sahil Garg",
            "Irina Rish",
            "Guillermo Cecchi",
            "Aurelie Lozano"
        ],
        "abstract": "In this paper, we focus on online representation learning in non-stationary environments which may require continuous adaptation of model architecture. We propose a novel online dictionary-learning (sparse-coding) framework which incorporates the addition and deletion of hidden units (dictionary elements), and is inspired by the adult neurogenesis phenomenon in the dentate gyrus of the hippocampus, known to be associated with improved cognitive function and adaptation to new environments. In the online learning setting, where new input instances arrive sequentially in batches, the neuronal-birth is implemented by adding new units with random initial weights (random dictionary elements); the number of new units is determined by the current performance (representation error) of the dictionary, higher error causing an increase in the birth rate. Neuronal-death is implemented by imposing l1/l2-regularization (group sparsity) on the dictionary within the block-coordinate descent optimization at each iteration of our online alternating minimization scheme, which iterates between the code and dictionary updates. Finally, hidden unit connectivity adaptation is facilitated by introducing sparsity in dictionary elements. Our empirical evaluation on several real-life datasets (images and language) as well as on synthetic data demonstrates that the proposed approach can considerably outperform the state-of-art fixed-size (nonadaptive) online sparse coding of Mairal et al. (2009) in the presence of nonstationary data. Moreover, we identify certain properties of the data (e.g., sparse inputs with nearly non-overlapping supports) and of the model (e.g., dictionary sparsity) associated with such improvements.\n    ",
        "submission_date": "2017-01-22T00:00:00",
        "last_modified_date": "2017-02-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.06233",
        "title": "What the Language You Tweet Says About Your Occupation",
        "authors": [
            "Tianran Hu",
            "Haoyuan Xiao",
            "Thuy-vy Thi Nguyen",
            "Jiebo Luo"
        ],
        "abstract": "Many aspects of people's lives are proven to be deeply connected to their jobs. In this paper, we first investigate the distinct characteristics of major occupation categories based on tweets. From multiple social media platforms, we gather several types of user information. From users' LinkedIn webpages, we learn their proficiencies. To overcome the ambiguity of self-reported information, a soft clustering approach is applied to extract occupations from crowd-sourced data. Eight job categories are extracted, including Marketing, Administrator, Start-up, Editor, Software Engineer, Public Relation, Office Clerk, and Designer. Meanwhile, users' posts on Twitter provide cues for understanding their linguistic styles, interests, and personalities. Our results suggest that people of different jobs have unique tendencies in certain language styles and interests. Our results also clearly reveal distinctive levels in terms of Big Five Traits for different jobs. Finally, a classifier is built to predict job types based on the features extracted from tweets. A high accuracy indicates a strong discrimination power of language features for job prediction task.\n    ",
        "submission_date": "2017-01-22T00:00:00",
        "last_modified_date": "2017-01-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.06247",
        "title": "A Multichannel Convolutional Neural Network For Cross-language Dialog State Tracking",
        "authors": [
            "Hongjie Shi",
            "Takashi Ushio",
            "Mitsuru Endo",
            "Katsuyoshi Yamagami",
            "Noriaki Horii"
        ],
        "abstract": "The fifth Dialog State Tracking Challenge (DSTC5) introduces a new cross-language dialog state tracking scenario, where the participants are asked to build their trackers based on the English training corpus, while evaluating them with the unlabeled Chinese corpus. Although the computer-generated translations for both English and Chinese corpus are provided in the dataset, these translations contain errors and careless use of them can easily hurt the performance of the built trackers. To address this problem, we propose a multichannel Convolutional Neural Networks (CNN) architecture, in which we treat English and Chinese language as different input channels of one single CNN model. In the evaluation of DSTC5, we found that such multichannel architecture can effectively improve the robustness against translation errors. Additionally, our method for DSTC5 is purely machine learning based and requires no prior knowledge about the target language. We consider this a desirable property for building a tracker in the cross-language context, as not every developer will be familiar with both languages.\n    ",
        "submission_date": "2017-01-23T00:00:00",
        "last_modified_date": "2017-01-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.06450",
        "title": "Identification of Unmodeled Objects from Symbolic Descriptions",
        "authors": [
            "Andrea Baisero",
            "Stefan Otte",
            "Peter Englert",
            "Marc Toussaint"
        ],
        "abstract": "Successful human-robot cooperation hinges on each agent's ability to process and exchange information about the shared environment and the task at hand. Human communication is primarily based on symbolic abstractions of object properties, rather than precise quantitative measures. A comprehensive robotic framework thus requires an integrated communication module which is able to establish a link and convert between perceptual and abstract information.\n",
        "submission_date": "2017-01-23T00:00:00",
        "last_modified_date": "2017-01-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.06532",
        "title": "ENIGMA: Efficient Learning-based Inference Guiding Machine",
        "authors": [
            "Jan Jakub\u016fv",
            "Josef Urban"
        ],
        "abstract": "ENIGMA is a learning-based method for guiding given clause selection in saturation-based theorem provers. Clauses from many proof searches are classified as positive and negative based on their participation in the proofs. An efficient classification model is trained on this data, using fast feature-based characterization of the clauses . The learned model is then tightly linked with the core prover and used as a basis of a new parameterized evaluation heuristic that provides fast ranking of all generated clauses. The approach is evaluated on the E prover and the CASC 2016 AIM benchmark, showing a large increase of E's performance.\n    ",
        "submission_date": "2017-01-23T00:00:00",
        "last_modified_date": "2017-01-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.06641",
        "title": "Perceptually Optimized Image Rendering",
        "authors": [
            "Valero Laparra",
            "Alex Berardino",
            "Johannes Ball\u00e9",
            "Eero P. Simoncelli"
        ],
        "abstract": "We develop a framework for rendering photographic images, taking into account display limitations, so as to optimize perceptual similarity between the rendered image and the original scene. We formulate this as a constrained optimization problem, in which we minimize a measure of perceptual dissimilarity, the Normalized Laplacian Pyramid Distance (NLPD), which mimics the early stage transformations of the human visual system. When rendering images acquired with higher dynamic range than that of the display, we find that the optimized solution boosts the contrast of low-contrast features without introducing significant artifacts, yielding results of comparable visual quality to current state-of-the art methods with no manual intervention or parameter settings. We also examine a variety of other display constraints, including limitations on minimum luminance (black point), mean luminance (as a proxy for energy consumption), and quantized luminance levels (halftoning). Finally, we show that the method may be used to enhance details and contrast of images degraded by optical scattering (e.g. fog).\n    ",
        "submission_date": "2017-01-23T00:00:00",
        "last_modified_date": "2017-01-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.06745",
        "title": "Proceedings of the 12th Workshop on User Interfaces for Theorem Provers",
        "authors": [
            "Serge Autexier",
            "Pedro Quaresma"
        ],
        "abstract": "The UITP workshop series brings together researchers interested in designing, developing and evaluating user interfaces for automated reasoning tools, such as interactive proof assistants, automated theorem provers, model finders, tools for formal methods, and tools for visualising and manipulating logical formulas and proofs. The twelth edition of UITP took place in Coimbra, Portugal, and was part of the International Joint Conference on Automated Reasoning (IJCAR'16). The workshop consisted of an invited talk, six presentations of submitted papers and lively hands-on session for reasoning tools and their user-interface. These post-proceedings contain four contributed papers accepted for publication after a second round of reviewing after the workshop as well as the invited paper.\n    ",
        "submission_date": "2017-01-24T00:00:00",
        "last_modified_date": "2017-01-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.06852",
        "title": "Incorporating Prior Information in Compressive Online Robust Principal Component Analysis",
        "authors": [
            "Huynh Van Luong",
            "Nikos Deligiannis",
            "Jurgen Seiler",
            "Soren Forchhammer",
            "Andre Kaup"
        ],
        "abstract": "We consider an online version of the robust Principle Component Analysis (PCA), which arises naturally in time-varying source separations such as video foreground-background separation. This paper proposes a compressive online robust PCA with prior information for recursively separating a sequences of frames into sparse and low-rank components from a small set of measurements. In contrast to conventional batch-based PCA, which processes all the frames directly, the proposed method processes measurements taken from each frame. Moreover, this method can efficiently incorporate multiple prior information, namely previous reconstructed frames, to improve the separation and thereafter, update the prior information for the next frame. We utilize multiple prior information by solving $n\\text{-}\\ell_{1}$ minimization for incorporating the previous sparse components and using incremental singular value decomposition ($\\mathrm{SVD}$) for exploiting the previous low-rank components. We also establish theoretical bounds on the number of measurements required to guarantee successful separation under assumptions of static or slowly-changing low-rank components. Using numerical experiments, we evaluate our bounds and the performance of the proposed algorithm. In addition, we apply the proposed algorithm to online video foreground and background separation from compressive measurements. Experimental results show that the proposed method outperforms the existing methods.\n    ",
        "submission_date": "2017-01-24T00:00:00",
        "last_modified_date": "2017-05-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.07123",
        "title": "Towards Automatic Learning of Heuristics for Mechanical Transformations of Procedural Code",
        "authors": [
            "Guillermo Vigueras",
            "Manuel Carro",
            "Salvador Tamarit",
            "Julio Mari\u00f1o"
        ],
        "abstract": "The current trends in next-generation exascale systems go towards integrating a wide range of specialized (co-)processors into traditional supercomputers. Due to the efficiency of heterogeneous systems in terms of Watts and FLOPS per surface unit, opening the access of heterogeneous platforms to a wider range of users is an important problem to be tackled. However, heterogeneous platforms limit the portability of the applications and increase development complexity due to the programming skills required. Program transformation can help make programming heterogeneous systems easier by defining a step-wise transformation process that translates a given initial code into a semantically equivalent final code, but adapted to a specific platform. Program transformation systems require the definition of efficient transformation strategies to tackle the combinatorial problem that emerges due to the large set of transformations applicable at each step of the process. In this paper we propose a machine learning-based approach to learn heuristics to define program transformation strategies. Our approach proposes a novel combination of reinforcement learning and classification methods to efficiently tackle the problems inherent to this type of systems. Preliminary results demonstrate the suitability of this approach.\n    ",
        "submission_date": "2017-01-25T00:00:00",
        "last_modified_date": "2017-01-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.07204",
        "title": "Fast Exact k-Means, k-Medians and Bregman Divergence Clustering in 1D",
        "authors": [
            "Allan Gr\u00f8nlund",
            "Kasper Green Larsen",
            "Alexander Mathiasen",
            "Jesper Sindahl Nielsen",
            "Stefan Schneider",
            "Mingzhou Song"
        ],
        "abstract": "The $k$-Means clustering problem on $n$ points is NP-Hard for any dimension $d\\ge 2$, however, for the 1D case there exists exact polynomial time algorithms. Previous literature reported an $O(kn^2)$ time dynamic programming algorithm that uses $O(kn)$ space. It turns out that the problem has been considered under a different name more than twenty years ago. We present all the existing work that had been overlooked and compare the various solutions theoretically. Moreover, we show how to reduce the space usage for some of them, as well as generalize them to data structures that can quickly report an optimal $k$-Means clustering for any $k$. Finally we also generalize all the algorithms to work for the absolute distance and to work for any Bregman Divergence. We complement our theoretical contributions by experiments that compare the practical performance of the various algorithms.\n    ",
        "submission_date": "2017-01-25T00:00:00",
        "last_modified_date": "2018-04-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.07396",
        "title": "LAREX - A semi-automatic open-source Tool for Layout Analysis and Region Extraction on Early Printed Books",
        "authors": [
            "Christian Reul",
            "Uwe Springmann",
            "Frank Puppe"
        ],
        "abstract": "A semi-automatic open-source tool for layout analysis on early printed books is presented. LAREX uses a rule based connected components approach which is very fast, easily comprehensible for the user and allows an intuitive manual correction if necessary. The PageXML format is used to support integration into existing OCR workflows. Evaluations showed that LAREX provides an efficient and flexible way to segment pages of early printed books.\n    ",
        "submission_date": "2017-01-20T00:00:00",
        "last_modified_date": "2017-01-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.07398",
        "title": "Learning an attention model in an artificial visual system",
        "authors": [
            "Alon Hazan",
            "Yuval Harel",
            "Ron Meir"
        ],
        "abstract": "The Human visual perception of the world is of a large fixed image that is highly detailed and sharp. However, receptor density in the retina is not uniform: a small central region called the fovea is very dense and exhibits high resolution, whereas a peripheral region around it has much lower spatial resolution. Thus, contrary to our perception, we are only able to observe a very small region around the line of sight with high resolution. The perception of a complete and stable view is aided by an attention mechanism that directs the eyes to the numerous points of interest within the scene. The eyes move between these targets in quick, unconscious movements, known as \"saccades\". Once a target is centered at the fovea, the eyes fixate for a fraction of a second while the visual system extracts the necessary information. An artificial visual system was built based on a fully recurrent neural network set within a reinforcement learning protocol, and learned to attend to regions of interest while solving a classification task. The model is consistent with several experimentally observed phenomena, and suggests novel predictions.\n    ",
        "submission_date": "2017-01-24T00:00:00",
        "last_modified_date": "2017-01-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.08125",
        "title": "Organic Computing in the Spotlight",
        "authors": [
            "Sven Tomforde",
            "Bernhard Sick",
            "Christian M\u00fcller-Schloer"
        ],
        "abstract": "Organic Computing is an initiative in the field of systems engineering that proposed to make use of concepts such as self-adaptation and self-organisation to increase the robustness of technical systems. Based on the observation that traditional design and operation concepts reach their limits, transferring more autonomy to the systems themselves should result in a reduction of complexity for users, administrators, and developers. However, there seems to be a need for an updated definition of the term \"Organic Computing\", of desired properties of technical, organic systems, and the objectives of the Organic Computing initiative. With this article, we will address these points.\n    ",
        "submission_date": "2017-01-27T00:00:00",
        "last_modified_date": "2017-01-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.08251",
        "title": "Image-Grounded Conversations: Multimodal Context for Natural Question and Response Generation",
        "authors": [
            "Nasrin Mostafazadeh",
            "Chris Brockett",
            "Bill Dolan",
            "Michel Galley",
            "Jianfeng Gao",
            "Georgios P. Spithourakis",
            "Lucy Vanderwende"
        ],
        "abstract": "The popularity of image sharing on social media and the engagement it creates between users reflects the important role that visual context plays in everyday conversations. We present a novel task, Image-Grounded Conversations (IGC), in which natural-sounding conversations are generated about a shared image. To benchmark progress, we introduce a new multiple-reference dataset of crowd-sourced, event-centric conversations on images. IGC falls on the continuum between chit-chat and goal-directed conversation models, where visual grounding constrains the topic of conversation to event-driven utterances. Experiments with models trained on social media data show that the combination of visual and textual context enhances the quality of generated conversational turns. In human evaluation, the gap between human performance and that of both neural and retrieval architectures suggests that multi-modal IGC presents an interesting challenge for dialogue research.\n    ",
        "submission_date": "2017-01-28T00:00:00",
        "last_modified_date": "2017-04-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.08254",
        "title": "Entropic Causality and Greedy Minimum Entropy Coupling",
        "authors": [
            "Murat Kocaoglu",
            "Alexandros G. Dimakis",
            "Sriram Vishwanath",
            "Babak Hassibi"
        ],
        "abstract": "We study the problem of identifying the causal relationship between two discrete random variables from observational data. We recently proposed a novel framework called entropic causality that works in a very general functional model but makes the assumption that the unobserved exogenous variable has small entropy in the true causal direction.\n",
        "submission_date": "2017-01-28T00:00:00",
        "last_modified_date": "2017-01-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.08269",
        "title": "Systems of natural-language-facilitated human-robot cooperation: A review",
        "authors": [
            "Rui Liu",
            "Xiaoli Zhang"
        ],
        "abstract": "Natural-language-facilitated human-robot cooperation (NLC), in which natural language (NL) is used to share knowledge between a human and a robot for conducting intuitive human-robot cooperation (HRC), is continuously developing in the recent decade. Currently, NLC is used in several robotic domains such as manufacturing, daily assistance and health caregiving. It is necessary to summarize current NLC-based robotic systems and discuss the future developing trends, providing helpful information for future NLC research. In this review, we first analyzed the driving forces behind the NLC research. Regarding to a robot s cognition level during the cooperation, the NLC implementations then were categorized into four types {NL-based control, NL-based robot training, NL-based task execution, NL-based social companion} for comparison and discussion. Last based on our perspective and comprehensive paper review, the future research trends were discussed.\n    ",
        "submission_date": "2017-01-28T00:00:00",
        "last_modified_date": "2017-05-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.08305",
        "title": "Multiclass MinMax Rank Aggregation",
        "authors": [
            "Pan Li",
            "Olgica Milenkovic"
        ],
        "abstract": "We introduce a new family of minmax rank aggregation problems under two distance measures, the Kendall {\\tau} and the Spearman footrule. As the problems are NP-hard, we proceed to describe a number of constant-approximation algorithms for solving them. We conclude with illustrative applications of the aggregation methods on the Mallows model and genomic data.\n    ",
        "submission_date": "2017-01-28T00:00:00",
        "last_modified_date": "2017-01-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.08374",
        "title": "Feature base fusion for splicing forgery detection based on neuro fuzzy",
        "authors": [
            "Habib Ghaffari Hadigheh",
            "Ghazali bin sulong"
        ],
        "abstract": "Most of researches on image forensics have been mainly focused on detection of artifacts introduced by a single processing tool. They lead in the development of many specialized algorithms looking for one or more particular footprints under specific settings. Naturally, the performance of such algorithms are not perfect, and accordingly the provided output might be noisy, inaccurate and only partially correct. Furthermore, a forged image in practical scenarios is often the result of utilizing several tools available by image-processing software systems. Therefore, reliable tamper detection requires developing more poweful tools to deal with various tempering scenarios. Fusion of forgery detection tools based on Fuzzy Inference System has been used before for addressing this problem. Adjusting the membership functions and defining proper fuzzy rules for attaining to better results are time-consuming processes. This can be accounted as main disadvantage of fuzzy inference systems. In this paper, a Neuro-Fuzzy inference system for fusion of forgery detection tools is developed. The neural network characteristic of these systems provides appropriate tool for automatically adjusting the membership functions. Moreover, initial fuzzy inference system is generated based on fuzzy clustering techniques. The proposed framework is implemented and validated on a benchmark image splicing data set in which three forgery detection tools are fused based on adaptive Neuro-Fuzzy inference system. The outcome of the proposed method reveals that applying Neuro Fuzzy inference systems could be a better approach for fusion of forgery detection tools.\n    ",
        "submission_date": "2017-01-29T00:00:00",
        "last_modified_date": "2017-01-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.08567",
        "title": "Decision structure of risky choice",
        "authors": [
            "Lamb Wubin",
            "Naixin Ren"
        ],
        "abstract": "As we know, there is a controversy about the decision making under risk between economists and psychologists. We discuss to build a unified theory of risky choice, which would explain both of compensatory and non-compensatory theories. For risky choice, according to cognition ability, we argue that people could not build a continuous and accurate subjective probability world, but several order concepts, such as small, middle and large probability. People make decisions based on information, experience, imagination and other things. All of these things are so huge that people have to prepare some strategies. That is, people have different strategies when facing to different situations. The distributions of these things have different decision structures. More precisely, decision making is a process of simplifying the decision structure. However, the process of decision structure simplifying is not stuck in a rut, but through different path when facing problems repeatedly. It is why preference reversal always happens when making decisions. The most efficient way to simplify the decision structure is calculating expected value or making decisions based on one or two dimensions. We also argue that the deliberation time at least has four parts, which are consist of substitution time, first order time, second order time and calculation time. Decision structure also can simply explain the phenomenon of paradoxes and anomalies. JEL Codes: C10, D03, D81\n    ",
        "submission_date": "2017-01-30T00:00:00",
        "last_modified_date": "2017-03-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.08744",
        "title": "Click Through Rate Prediction for Contextual Advertisment Using Linear Regression",
        "authors": [
            "Muhammad Junaid Effendi",
            "Syed Abbas Ali"
        ],
        "abstract": "This research presents an innovative and unique way of solving the advertisement prediction problem which is considered as a learning problem over the past several years. Online advertising is a multi-billion-dollar industry and is growing every year with a rapid pace. The goal of this research is to enhance click through rate of the contextual advertisements using Linear Regression. In order to address this problem, a new technique propose in this paper to predict the CTR which will increase the overall revenue of the system by serving the advertisements more suitable to the viewers with the help of feature extraction and displaying the advertisements based on context of the publishers. The important steps include the data collection, feature extraction, CTR prediction and advertisement serving. The statistical results obtained from the dynamically used technique show an efficient outcome by fitting the data close to perfection for the LR technique using optimized feature selection.\n    ",
        "submission_date": "2017-01-30T00:00:00",
        "last_modified_date": "2017-01-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.08756",
        "title": "A Review of Methodologies for Natural-Language-Facilitated Human-Robot Cooperation",
        "authors": [
            "Rui Liu",
            "Xiaoli Zhang"
        ],
        "abstract": "Natural-language-facilitated human-robot cooperation (NLC) refers to using natural language (NL) to facilitate interactive information sharing and task executions with a common goal constraint between robots and humans. Recently, NLC research has received increasing attention. Typical NLC scenarios include robotic daily assistance, robotic health caregiving, intelligent manufacturing, autonomous navigation, and robot social accompany. However, a thorough review, that can reveal latest methodologies to use NL to facilitate human-robot cooperation, is missing. In this review, a comprehensive summary about methodologies for NLC is presented. NLC research includes three main research focuses: NL instruction understanding, NL-based execution plan generation, and knowledge-world mapping. In-depth analyses on theoretical methods, applications, and model advantages and disadvantages are made. Based on our paper review and perspective, potential research directions of NLC are summarized.\n    ",
        "submission_date": "2017-01-30T00:00:00",
        "last_modified_date": "2017-08-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.08761",
        "title": "C3A: A Cognitive Collaborative Control Architecture For an Intelligent Wheelchair",
        "authors": [
            "Rupam Bhattacharyya",
            "Adity Saikia",
            "Shyamanta M. Hazarika"
        ],
        "abstract": "Retention of residual skills for persons who partially lose their cognitive or physical ability is of utmost importance. Research is focused on developing systems that provide need-based assistance for retention of such residual skills. This paper describes a novel cognitive collaborative control architecture C3A, designed to address the challenges of developing need- based assistance for wheelchair navigation. Organization of C3A is detailed and results from simulation of the proposed architecture is presented. For simulation of our proposed architecture, we have used ROS (Robot Operating System) as a control framework and a 3D robotic simulator called USARSim (Unified System for Automation and Robot Simulation).\n    ",
        "submission_date": "2017-01-30T00:00:00",
        "last_modified_date": "2017-01-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.08810",
        "title": "Reinforcement Learning Algorithm Selection",
        "authors": [
            "Romain Laroche",
            "Raphael Feraud"
        ],
        "abstract": "This paper formalises the problem of online algorithm selection in the context of Reinforcement Learning. The setup is as follows: given an episodic task and a finite number of off-policy RL algorithms, a meta-algorithm has to decide which RL algorithm is in control during the next episode so as to maximize the expected return. The article presents a novel meta-algorithm, called Epochal Stochastic Bandit Algorithm Selection (ESBAS). Its principle is to freeze the policy updates at each epoch, and to leave a rebooted stochastic bandit in charge of the algorithm selection. Under some assumptions, a thorough theoretical analysis demonstrates its near-optimality considering the structural sampling budget limitations. ESBAS is first empirically evaluated on a dialogue task where it is shown to outperform each individual algorithm in most configurations. ESBAS is then adapted to a true online setting where algorithms update their policies after each transition, which we call SSBAS. SSBAS is evaluated on a fruit collection task where it is shown to adapt the stepsize parameter more efficiently than the classical hyperbolic decay, and on an Atari game, where it improves the performance by a wide margin.\n    ",
        "submission_date": "2017-01-30T00:00:00",
        "last_modified_date": "2017-11-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.08878",
        "title": "Deep Reinforcement Learning for Robotic Manipulation-The state of the art",
        "authors": [
            "Smruti Amarjyoti"
        ],
        "abstract": "The focus of this work is to enumerate the various approaches and algorithms that center around application of reinforcement learning in robotic ma- ]]nipulation tasks. Earlier methods utilized specialized policy representations and human demonstrations to constrict the policy. Such methods worked well with continuous state and policy space of robots but failed to come up with generalized policies. Subsequently, high dimensional non-linear function approximators like neural networks have been used to learn policies from scratch. Several novel and recent approaches have also embedded control policy with efficient perceptual representation using deep learning. This has led to the emergence of a new branch of dynamic robot control system called deep r inforcement learning(DRL). This work embodies a survey of the most recent algorithms, architectures and their implementations in simulations and real world robotic platforms. The gamut of DRL architectures are partitioned into two different branches namely, discrete action space algorithms(DAS) and continuous action space algorithms(CAS). Further, the CAS algorithms are divided into stochastic continuous action space(SCAS) and deterministic continuous action space(DCAS) algorithms. Along with elucidating an organ- isation of the DRL algorithms this work also manifests some of the state of the art applications of these approaches in robotic manipulation tasks.\n    ",
        "submission_date": "2017-01-31T00:00:00",
        "last_modified_date": "2017-01-31T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.08888",
        "title": "Integrating Reviews into Personalized Ranking for Cold Start Recommendation",
        "authors": [
            "Guang-Neng Hu",
            "Xin-Yu Dai"
        ],
        "abstract": "Item recommendation task predicts a personalized ranking over a set of items for each individual user. One paradigm is the rating-based methods that concentrate on explicit feedbacks and hence face the difficulties in collecting them. Meanwhile, the ranking-based methods are presented with rated items and then rank the rated above the unrated. This paradigm takes advantage of widely available implicit feedback. It, however, usually ignores a kind of important information: item reviews. Item reviews not only justify the preferences of users, but also help alleviate the cold-start problem that fails the collaborative filtering. In this paper, we propose two novel and simple models to integrate item reviews into Bayesian personalized ranking. In each model, we make use of text features extracted from item reviews using word embeddings. On top of text features we uncover the review dimensions that explain the variation in users' feedback and these review factors represent a prior preference of users. Experiments on six real-world data sets show the benefits of leveraging item reviews on ranking prediction. We also conduct analyses to understand the proposed models.\n    ",
        "submission_date": "2017-01-31T00:00:00",
        "last_modified_date": "2018-12-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.08954",
        "title": "CommAI: Evaluating the first steps towards a useful general AI",
        "authors": [
            "Marco Baroni",
            "Armand Joulin",
            "Allan Jabri",
            "Germ\u00e0n Kruszewski",
            "Angeliki Lazaridou",
            "Klemen Simonic",
            "Tomas Mikolov"
        ],
        "abstract": "With machine learning successfully applied to new daunting problems almost every day, general AI starts looking like an attainable goal. However, most current research focuses instead on important but narrow applications, such as image classification or machine translation. We believe this to be largely due to the lack of objective ways to measure progress towards broad machine intelligence. In order to fill this gap, we propose here a set of concrete desiderata for general AI, together with a platform to test machines on how well they satisfy such desiderata, while keeping all further complexities to a minimum.\n    ",
        "submission_date": "2017-01-31T00:00:00",
        "last_modified_date": "2017-03-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.09042",
        "title": "Comparing Dataset Characteristics that Favor the Apriori, Eclat or FP-Growth Frequent Itemset Mining Algorithms",
        "authors": [
            "Jeff Heaton"
        ],
        "abstract": "Frequent itemset mining is a popular data mining technique. Apriori, Eclat, and FP-Growth are among the most common algorithms for frequent itemset mining. Considerable research has been performed to compare the relative performance between these three algorithms, by evaluating the scalability of each algorithm as the dataset size increases. While scalability as data size increases is important, previous papers have not examined the performance impact of similarly sized datasets that contain different itemset characteristics. This paper explores the effects that two dataset characteristics can have on the performance of these three frequent itemset algorithms. To perform this empirical analysis, a dataset generator is created to measure the effects of frequent item density and the maximum transaction size on performance. The generated datasets contain the same number of rows. This provides some insight into dataset characteristics that are conducive to each algorithm. The results of this paper's research demonstrate Eclat and FP-Growth both handle increases in maximum transaction size and frequent itemset density considerably better than the Apriori algorithm.\n",
        "submission_date": "2017-01-30T00:00:00",
        "last_modified_date": "2017-01-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.09083",
        "title": "Efficient Rank Aggregation via Lehmer Codes",
        "authors": [
            "Pan Li",
            "Arya Mazumdar",
            "Olgica Milenkovic"
        ],
        "abstract": "We propose a novel rank aggregation method based on converting permutations into their corresponding Lehmer codes or other subdiagonal images. Lehmer codes, also known as inversion vectors, are vector representations of permutations in which each coordinate can take values not restricted by the values of other coordinates. This transformation allows for decoupling of the coordinates and for performing aggregation via simple scalar median or mode computations. We present simulation results illustrating the performance of this completely parallelizable approach and analytically prove that both the mode and median aggregation procedure recover the correct centroid aggregate with small sample complexity when the permutations are drawn according to the well-known Mallows models. The proposed Lehmer code approach may also be used on partial rankings, with similar performance guarantees.\n    ",
        "submission_date": "2017-01-28T00:00:00",
        "last_modified_date": "2017-01-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1701.09123",
        "title": "Robust Multilingual Named Entity Recognition with Shallow Semi-Supervised Features",
        "authors": [
            "Rodrigo Agerri",
            "German Rigau"
        ],
        "abstract": "We present a multilingual Named Entity Recognition approach based on a robust and general set of features across languages and datasets. Our system combines shallow local information with clustering semi-supervised features induced on large amounts of unlabeled text. Understanding via empirical experimentation how to effectively combine various types of clustering features allows us to seamlessly export our system to other datasets and languages. The result is a simple but highly competitive system which obtains state of the art results across five languages and twelve datasets. The results are reported on standard shared task evaluation data such as CoNLL for English, Spanish and Dutch. Furthermore, and despite the lack of linguistically motivated features, we also report best results for languages such as Basque and German. In addition, we demonstrate that our method also obtains very competitive results even when the amount of supervised data is cut by half, alleviating the dependency on manually annotated data. Finally, the results show that our emphasis on clustering features is crucial to develop robust out-of-domain models. The system and models are freely available to facilitate its use and guarantee the reproducibility of results.\n    ",
        "submission_date": "2017-01-31T00:00:00",
        "last_modified_date": "2017-01-31T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.00700",
        "title": "Multilingual and Cross-lingual Timeline Extraction",
        "authors": [
            "Egoitz Laparra",
            "Rodrigo Agerri",
            "Itziar Aldabe",
            "German Rigau"
        ],
        "abstract": "In this paper we present an approach to extract ordered timelines of events, their participants, locations and times from a set of multilingual and cross-lingual data sources. Based on the assumption that event-related information can be recovered from different documents written in different languages, we extend the Cross-document Event Ordering task presented at SemEval 2015 by specifying two new tasks for, respectively, Multilingual and Cross-lingual Timeline Extraction. We then develop three deterministic algorithms for timeline extraction based on two main ideas. First, we address implicit temporal relations at document level since explicit time-anchors are too scarce to build a wide coverage timeline extraction system. Second, we leverage several multilingual resources to obtain a single, inter-operable, semantic representation of events across documents and across languages. The result is a highly competitive system that strongly outperforms the current state-of-the-art. Nonetheless, further analysis of the results reveals that linking the event mentions with their target entities and time-anchors remains a difficult challenge. The systems, resources and scorers are freely available to facilitate its use and guarantee the reproducibility of results.\n    ",
        "submission_date": "2017-02-02T00:00:00",
        "last_modified_date": "2017-02-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.00953",
        "title": "Deep Learning with Low Precision by Half-wave Gaussian Quantization",
        "authors": [
            "Zhaowei Cai",
            "Xiaodong He",
            "Jian Sun",
            "Nuno Vasconcelos"
        ],
        "abstract": "The problem of quantizing the activations of a deep neural network is considered. An examination of the popular binary quantization approach shows that this consists of approximating a classical non-linearity, the hyperbolic tangent, by two functions: a piecewise constant sign function, which is used in feedforward network computations, and a piecewise linear hard tanh function, used in the backpropagation step during network learning. The problem of approximating the ReLU non-linearity, widely used in the recent deep learning literature, is then considered. An half-wave Gaussian quantizer (HWGQ) is proposed for forward approximation and shown to have efficient implementation, by exploiting the statistics of of network activations and batch normalization operations commonly used in the literature. To overcome the problem of gradient mismatch, due to the use of different forward and backward approximations, several piece-wise backward approximators are then investigated. The implementation of the resulting quantized network, denoted as HWGQ-Net, is shown to achieve much closer performance to full precision networks, such as AlexNet, ResNet, GoogLeNet and VGG-Net, than previously available low-precision networks, with 1-bit binary weights and 2-bit quantized activations.\n    ",
        "submission_date": "2017-02-03T00:00:00",
        "last_modified_date": "2017-02-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.01018",
        "title": "On Robustness in Multilayer Interdependent Network",
        "authors": [
            "Joydeep Banerjee",
            "Chenyang Zhou",
            "Arunabha Sen"
        ],
        "abstract": "Critical Infrastructures like power and communication networks are highly interdependent on each other for their full functionality. Many significant research have been pursued to model the interdependency and failure analysis of these interdependent networks. However, most of these models fail to capture the complex interdependencies that might actually exist between the infrastructures. The \\emph{Implicative Interdependency Model} that utilizes Boolean Logic to capture complex interdependencies was recently proposed which overcome the limitations of the existing models. A number of problems were studies based on this model. In this paper we study the \\textit{Robustness} problem in Interdependent Power and Communication Network. The robustness is defined with respect to two parameters $K \\in I^{+} \\cup \\{0\\}$ and $\\rho \\in (0,1]$. We utilized the \\emph{Implicative Interdependency Model} model to capture the complex interdependency between the two networks. The model classifies the interdependency relations into four cases. Computational complexity of the problem is analyzed for each of these cases. A polynomial time algorithm is designed for the first case that outputs the optimal solution. All the other cases are proved to be NP-complete. An in-approximability bound is provided for the third case. For the general case we formulate an Integer Linear Program to get the optimal solution and a polynomial time heuristic. The applicability of the heuristic is evaluated using power and communication network data of Maricopa County, Arizona. The experimental results showed that the heuristic almost always produced near optimal value of parameter $K$ for $\\rho < 0.42$.\n    ",
        "submission_date": "2017-01-24T00:00:00",
        "last_modified_date": "2017-01-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.01208",
        "title": "A Theoretical Analysis of First Heuristics of Crowdsourced Entity Resolution",
        "authors": [
            "Arya Mazumdar",
            "Barna Saha"
        ],
        "abstract": "Entity resolution (ER) is the task of identifying all records in a database that refer to the same underlying entity, and are therefore duplicates of each other. Due to inherent ambiguity of data representation and poor data quality, ER is a challenging task for any automated process. As a remedy, human-powered ER via crowdsourcing has become popular in recent years. Using crowd to answer queries is costly and time consuming. Furthermore, crowd-answers can often be faulty. Therefore, crowd-based ER methods aim to minimize human participation without sacrificing the quality and use a computer generated similarity matrix actively. While, some of these methods perform well in practice, no theoretical analysis exists for them, and further their worst case performances do not reflect the experimental findings. This creates a disparity in the understanding of the popular heuristics for this problem. In this paper, we make the first attempt to close this gap. We provide a thorough analysis of the prominent heuristic algorithms for crowd-based ER. We justify experimental observations with our analysis and information theoretic lower bounds.\n    ",
        "submission_date": "2017-02-03T00:00:00",
        "last_modified_date": "2017-02-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.01313",
        "title": "Cluster-based Kriging Approximation Algorithms for Complexity Reduction",
        "authors": [
            "Bas van Stein",
            "Hao Wang",
            "Wojtek Kowalczyk",
            "Michael Emmerich",
            "Thomas B\u00e4ck"
        ],
        "abstract": "Kriging or Gaussian Process Regression is applied in many fields as a non-linear regression model as well as a surrogate model in the field of evolutionary computation. However, the computational and space complexity of Kriging, that is cubic and quadratic in the number of data points respectively, becomes a major bottleneck with more and more data available nowadays. In this paper, we propose a general methodology for the complexity reduction, called cluster Kriging, where the whole data set is partitioned into smaller clusters and multiple Kriging models are built on top of them. In addition, four Kriging approximation algorithms are proposed as candidate algorithms within the new framework. Each of these algorithms can be applied to much larger data sets while maintaining the advantages and power of Kriging. The proposed algorithms are explained in detail and compared empirically against a broad set of existing state-of-the-art Kriging approximation methods on a well-defined testing framework. According to the empirical study, the proposed algorithms consistently outperform the existing algorithms. Moreover, some practical suggestions are provided for using the proposed algorithms.\n    ",
        "submission_date": "2017-02-04T00:00:00",
        "last_modified_date": "2017-02-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.01721",
        "title": "View Independent Vehicle Make, Model and Color Recognition Using Convolutional Neural Network",
        "authors": [
            "Afshin Dehghan",
            "Syed Zain Masood",
            "Guang Shu",
            "Enrique. G. Ortiz"
        ],
        "abstract": "This paper describes the details of Sighthound's fully automated vehicle make, model and color recognition system. The backbone of our system is a deep convolutional neural network that is not only computationally inexpensive, but also provides state-of-the-art results on several competitive benchmarks. Additionally, our deep network is trained on a large dataset of several million images which are labeled through a semi-automated process. Finally we test our system on several public datasets as well as our own internal test dataset. Our results show that we outperform other methods on all benchmarks by significant margins. Our model is available to developers through the Sighthound Cloud API at ",
        "submission_date": "2017-02-06T00:00:00",
        "last_modified_date": "2017-02-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.01975",
        "title": "Learning what matters - Sampling interesting patterns",
        "authors": [
            "Vladimir Dzyuba",
            "Matthijs van Leeuwen"
        ],
        "abstract": "In the field of exploratory data mining, local structure in data can be described by patterns and discovered by mining algorithms. Although many solutions have been proposed to address the redundancy problems in pattern mining, most of them either provide succinct pattern sets or take the interests of the user into account-but not both. Consequently, the analyst has to invest substantial effort in identifying those patterns that are relevant to her specific interests and goals. To address this problem, we propose a novel approach that combines pattern sampling with interactive data mining. In particular, we introduce the LetSIP algorithm, which builds upon recent advances in 1) weighted sampling in SAT and 2) learning to rank in interactive pattern mining. Specifically, it exploits user feedback to directly learn the parameters of the sampling distribution that represents the user's interests. We compare the performance of the proposed algorithm to the state-of-the-art in interactive pattern mining by emulating the interests of a user. The resulting system allows efficient and interleaved learning and sampling, thus user-specific anytime data exploration. Finally, LetSIP demonstrates favourable trade-offs concerning both quality-diversity and exploitation-exploration when compared to existing methods.\n    ",
        "submission_date": "2017-02-07T00:00:00",
        "last_modified_date": "2017-02-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.01991",
        "title": "Representations of language in a model of visually grounded speech signal",
        "authors": [
            "Grzegorz Chrupa\u0142a",
            "Lieke Gelderloos",
            "Afra Alishahi"
        ],
        "abstract": "We present a visually grounded model of speech perception which projects spoken utterances and images to a joint semantic space. We use a multi-layer recurrent highway network to model the temporal nature of spoken speech, and show that it learns to extract both form and meaning-based linguistic knowledge from the input signal. We carry out an in-depth analysis of the representations used by different components of the trained model and show that encoding of semantic aspects tends to become richer as we go up the hierarchy of layers, whereas encoding of form-related aspects of the language input tends to initially increase and then plateau or decrease.\n    ",
        "submission_date": "2017-02-07T00:00:00",
        "last_modified_date": "2017-06-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.02032",
        "title": "Solving the Brachistochrone Problem by an Influence Diagram",
        "authors": [
            "Ji\u0159\u00ed Vomlel"
        ],
        "abstract": "Influence diagrams are a decision-theoretic extension of probabilistic graphical models. In this paper we show how they can be used to solve the Brachistochrone problem. We present results of numerical experiments on this problem, compare the solution provided by the influence diagram with the optimal solution. The R code used for the experiments is presented in the Appendix.\n    ",
        "submission_date": "2017-02-04T00:00:00",
        "last_modified_date": "2017-02-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.02258",
        "title": "Generating Multiple Diverse Hypotheses for Human 3D Pose Consistent with 2D Joint Detections",
        "authors": [
            "Ehsan Jahangiri",
            "Alan L. Yuille"
        ],
        "abstract": "We propose a method to generate multiple diverse and valid human pose hypotheses in 3D all consistent with the 2D detection of joints in a monocular RGB image. We use a novel generative model uniform (unbiased) in the space of anatomically plausible 3D poses. Our model is compositional (produces a pose by combining parts) and since it is restricted only by anatomical constraints it can generalize to every plausible human 3D pose. Removing the model bias intrinsically helps to generate more diverse 3D pose hypotheses. We argue that generating multiple pose hypotheses is more reasonable than generating only a single 3D pose based on the 2D joint detection given the depth ambiguity and the uncertainty due to occlusion and imperfect 2D joint detection. We hope that the idea of generating multiple consistent pose hypotheses can give rise to a new line of future work that has not received much attention in the literature. We used the Human3.6M dataset for empirical evaluation.\n    ",
        "submission_date": "2017-02-08T00:00:00",
        "last_modified_date": "2017-08-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.02277",
        "title": "A Historical Review of Forty Years of Research on CMAC",
        "authors": [
            "Frank Z. Xing"
        ],
        "abstract": "The Cerebellar Model Articulation Controller (CMAC) is an influential brain-inspired computing model in many relevant fields. Since its inception in the 1970s, the model has been intensively studied and many variants of the prototype, such as Kernel-CMAC, Self-Organizing Map CMAC, and Linguistic CMAC, have been proposed. This review article focus on how the CMAC model is gradually developed and refined to meet the demand of fast, adaptive, and robust control. Two perspective, CMAC as a neural network and CMAC as a table look-up technique are presented. Three aspects of the model: the architecture, learning algorithms and applications are discussed. In the end, some potential future research directions on this model are suggested.\n    ",
        "submission_date": "2017-02-08T00:00:00",
        "last_modified_date": "2017-02-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.02519",
        "title": "Deep Generalized Canonical Correlation Analysis",
        "authors": [
            "Adrian Benton",
            "Huda Khayrallah",
            "Biman Gujral",
            "Dee Ann Reisinger",
            "Sheng Zhang",
            "Raman Arora"
        ],
        "abstract": "We present Deep Generalized Canonical Correlation Analysis (DGCCA) -- a method for learning nonlinear transformations of arbitrarily many views of data, such that the resulting transformations are maximally informative of each other. While methods for nonlinear two-view representation learning (Deep CCA, (Andrew et al., 2013)) and linear many-view representation learning (Generalized CCA (Horst, 1961)) exist, DGCCA is the first CCA-style multiview representation learning technique that combines the flexibility of nonlinear (deep) representation learning with the statistical power of incorporating information from many independent sources, or views. We present the DGCCA formulation as well as an efficient stochastic optimization algorithm for solving it. We learn DGCCA representations on two distinct datasets for three downstream tasks: phonetic transcription from acoustic and articulatory measurements, and recommending hashtags and friends on a dataset of Twitter users. We find that DGCCA representations soundly beat existing methods at phonetic transcription and hashtag recommendation, and in general perform no worse than standard linear many-view techniques.\n    ",
        "submission_date": "2017-02-08T00:00:00",
        "last_modified_date": "2017-06-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.02540",
        "title": "Automatic Rule Extraction from Long Short Term Memory Networks",
        "authors": [
            "W. James Murdoch",
            "Arthur Szlam"
        ],
        "abstract": "Although deep learning models have proven effective at solving problems in natural language processing, the mechanism by which they come to their conclusions is often unclear. As a result, these models are generally treated as black boxes, yielding no insight of the underlying learned patterns. In this paper we consider Long Short Term Memory networks (LSTMs) and demonstrate a new approach for tracking the importance of a given input to the LSTM for a given output. By identifying consistently important patterns of words, we are able to distill state of the art LSTMs on sentiment analysis and question answering into a set of representative phrases. This representation is then quantitatively validated by using the extracted phrases to construct a simple, rule-based classifier which approximates the output of the LSTM.\n    ",
        "submission_date": "2017-02-08T00:00:00",
        "last_modified_date": "2017-02-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.02604",
        "title": "Causal Regularization",
        "authors": [
            "Mohammad Taha Bahadori",
            "Krzysztof Chalupka",
            "Edward Choi",
            "Robert Chen",
            "Walter F. Stewart",
            "Jimeng Sun"
        ],
        "abstract": "In application domains such as healthcare, we want accurate predictive models that are also causally interpretable. In pursuit of such models, we propose a causal regularizer to steer predictive models towards causally-interpretable solutions and theoretically study its properties. In a large-scale analysis of Electronic Health Records (EHR), our causally-regularized model outperforms its L1-regularized counterpart in causal accuracy and is competitive in predictive performance. We perform non-linear causality analysis by causally regularizing a special neural network architecture. We also show that the proposed causal regularizer can be used together with neural representation learning algorithms to yield up to 20% improvement over multilayer perceptron in detecting multivariate causation, a situation common in healthcare, where many causal factors should occur simultaneously to have an effect on the target variable.\n    ",
        "submission_date": "2017-02-08T00:00:00",
        "last_modified_date": "2017-02-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.02676",
        "title": "Energy Saving Additive Neural Network",
        "authors": [
            "Arman Afrasiyabi",
            "Ozan Yildiz",
            "Baris Nasir",
            "Fatos T. Yarman Vural",
            "A. Enis Cetin"
        ],
        "abstract": "In recent years, machine learning techniques based on neural networks for mobile computing become increasingly popular. Classical multi-layer neural networks require matrix multiplications at each stage. Multiplication operation is not an energy efficient operation and consequently it drains the battery of the mobile device. In this paper, we propose a new energy efficient neural network with the universal approximation property over space of Lebesgue integrable functions. This network, called, additive neural network, is very suitable for mobile computing. The neural structure is based on a novel vector product definition, called ef-operator, that permits a multiplier-free implementation. In ef-operation, the \"product\" of two real numbers is defined as the sum of their absolute values, with the sign determined by the sign of the product of the numbers. This \"product\" is used to construct a vector product in $R^N$. The vector product induces the $l_1$ norm. The proposed additive neural network successfully solves the XOR problem. The experiments on MNIST dataset show that the classification performances of the proposed additive neural networks are very similar to the corresponding multi-layer perceptron and convolutional neural networks (LeNet).\n    ",
        "submission_date": "2017-02-09T00:00:00",
        "last_modified_date": "2017-02-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.02817",
        "title": "Graph Based Relational Features for Collective Classification",
        "authors": [
            "Immanuel Bayer",
            "Uwe Nagel",
            "Steffen Rendle"
        ],
        "abstract": "Statistical Relational Learning (SRL) methods have shown that classification accuracy can be improved by integrating relations between samples. Techniques such as iterative classification or relaxation labeling achieve this by propagating information between related samples during the inference process. When only a few samples are labeled and connections between samples are sparse, collective inference methods have shown large improvements over standard feature-based ML methods. However, in contrast to feature based ML, collective inference methods require complex inference procedures and often depend on the strong assumption of label consistency among related samples. In this paper, we introduce new relational features for standard ML methods by extracting information from direct and indirect relations. We show empirically on three standard benchmark datasets that our relational features yield results comparable to collective inference methods. Finally we show that our proposal outperforms these methods when additional information is available.\n    ",
        "submission_date": "2017-02-09T00:00:00",
        "last_modified_date": "2017-02-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.02821",
        "title": "Phase Transitions of the Typical Algorithmic Complexity of the Random Satisfiability Problem Studied with Linear Programming",
        "authors": [
            "Hendrik Schawe",
            "Roman Bleim",
            "Alexander K. Hartmann"
        ],
        "abstract": "Here we study the NP-complete $K$-SAT problem. Although the worst-case complexity of NP-complete problems is conjectured to be exponential, there exist parametrized random ensembles of problems where solutions can typically be found in polynomial time for suitable ranges of the parameter. In fact, random $K$-SAT, with $\\alpha=M/N $ as control parameter, can be solved quickly for small enough values of $\\alpha$. It shows a phase transition between a satisfiable phase and an unsatisfiable phase. For branch and bound algorithms, which operate in the space of feasible Boolean configurations, the empirically hardest problems are located only close to this phase transition. Here we study $K$-SAT ($K=3,4$) and the related optimization problem MAX-SAT by a linear programming approach, which is widely used for practical problems and allows for polynomial run time. In contrast to branch and bound it operates outside the space of feasible configurations. On the other hand, finding a solution within polynomial time is not guaranteed. We investigated several variants like including artificial objective functions, so called cutting-plane approaches, and a mapping to the NP-complete vertex-cover problem. We observed several easy-hard transitions, from where the problems are typically solvable (in polynomial time) using the given algorithms, respectively, to where they are not solvable in polynomial time. For the related vertex-cover problem on random graphs these easy-hard transitions can be identified with structural properties of the graphs, like percolation transitions. For the present random $K$-SAT problem we have investigated numerous structural properties also exhibiting clear transitions, but they appear not be correlated to the here observed easy-hard transitions. This renders the behaviour of random $K$-SAT more complex than, e.g., the vertex-cover problem.\n    ",
        "submission_date": "2017-02-09T00:00:00",
        "last_modified_date": "2018-09-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.02890",
        "title": "Answer Set Solving with Bounded Treewidth Revisited",
        "authors": [
            "Johannes Fichte",
            "Markus Hecher",
            "Michael Morak",
            "Stefan Woltran"
        ],
        "abstract": "Parameterized algorithms are a way to solve hard problems more efficiently, given that a specific parameter of the input is small. In this paper, we apply this idea to the field of answer set programming (ASP). To this end, we propose two kinds of graph representations of programs to exploit their treewidth as a parameter. Treewidth roughly measures to which extent the internal structure of a program resembles a tree. Our main contribution is the design of parameterized dynamic programming algorithms, which run in linear time if the treewidth and weights of the given program are bounded. Compared to previous work, our algorithms handle the full syntax of ASP. Finally, we report on an empirical evaluation that shows good runtime behaviour for benchmark instances of low treewidth, especially for counting answer sets.\n    ",
        "submission_date": "2017-02-09T00:00:00",
        "last_modified_date": "2017-02-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.03037",
        "title": "Multi-agent Reinforcement Learning in Sequential Social Dilemmas",
        "authors": [
            "Joel Z. Leibo",
            "Vinicius Zambaldi",
            "Marc Lanctot",
            "Janusz Marecki",
            "Thore Graepel"
        ],
        "abstract": "Matrix games like Prisoner's Dilemma have guided research on social dilemmas for decades. However, they necessarily treat the choice to cooperate or defect as an atomic action. In real-world social dilemmas these choices are temporally extended. Cooperativeness is a property that applies to policies, not elementary actions. We introduce sequential social dilemmas that share the mixed incentive structure of matrix game social dilemmas but also require agents to learn policies that implement their strategic intentions. We analyze the dynamics of policies learned by multiple self-interested independent learning agents, each using its own deep Q-network, on two Markov games we introduce here: 1. a fruit Gathering game and 2. a Wolfpack hunting game. We characterize how learned behavior in each domain changes as a function of environmental factors including resource abundance. Our experiments show how conflict can emerge from competition over shared resources and shed light on how the sequential nature of real world social dilemmas affects cooperation.\n    ",
        "submission_date": "2017-02-10T00:00:00",
        "last_modified_date": "2017-02-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.03044",
        "title": "Incremental Network Quantization: Towards Lossless CNNs with Low-Precision Weights",
        "authors": [
            "Aojun Zhou",
            "Anbang Yao",
            "Yiwen Guo",
            "Lin Xu",
            "Yurong Chen"
        ],
        "abstract": "This paper presents incremental network quantization (INQ), a novel method, targeting to efficiently convert any pre-trained full-precision convolutional neural network (CNN) model into a low-precision version whose weights are constrained to be either powers of two or zero. Unlike existing methods which are struggled in noticeable accuracy loss, our INQ has the potential to resolve this issue, as benefiting from two innovations. On one hand, we introduce three interdependent operations, namely weight partition, group-wise quantization and re-training. A well-proven measure is employed to divide the weights in each layer of a pre-trained CNN model into two disjoint groups. The weights in the first group are responsible to form a low-precision base, thus they are quantized by a variable-length encoding method. The weights in the other group are responsible to compensate for the accuracy loss from the quantization, thus they are the ones to be re-trained. On the other hand, these three operations are repeated on the latest re-trained group in an iterative manner until all the weights are converted into low-precision ones, acting as an incremental network quantization and accuracy enhancement procedure. Extensive experiments on the ImageNet classification task using almost all known deep CNN architectures including AlexNet, VGG-16, GoogleNet and ResNets well testify the efficacy of the proposed method. Specifically, at 5-bit quantization, our models have improved accuracy than the 32-bit floating-point references. Taking ResNet-18 as an example, we further show that our quantized models with 4-bit, 3-bit and 2-bit ternary weights have improved or very similar accuracy against its 32-bit floating-point baseline. Besides, impressive results with the combination of network pruning and INQ are also reported. The code is available at ",
        "submission_date": "2017-02-10T00:00:00",
        "last_modified_date": "2017-08-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.03121",
        "title": "Modeling Semantic Expectation: Using Script Knowledge for Referent Prediction",
        "authors": [
            "Ashutosh Modi",
            "Ivan Titov",
            "Vera Demberg",
            "Asad Sayeed",
            "Manfred Pinkal"
        ],
        "abstract": "Recent research in psycholinguistics has provided increasing evidence that humans predict upcoming content. Prediction also affects perception and might be a key to robustness in human language processing. In this paper, we investigate the factors that affect human prediction by building a computational model that can predict upcoming discourse referents based on linguistic knowledge alone vs. linguistic knowledge jointly with common-sense knowledge in the form of scripts. We find that script knowledge significantly improves model estimates of human predictions. In a second study, we test the highly controversial hypothesis that predictability influences referring expression type but do not find evidence for such an effect.\n    ",
        "submission_date": "2017-02-10T00:00:00",
        "last_modified_date": "2017-02-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.03443",
        "title": "Group Scissor: Scaling Neuromorphic Computing Design to Large Neural Networks",
        "authors": [
            "Yandan Wang",
            "Wei Wen",
            "Beiye Liu",
            "Donald Chiarulli",
            "Hai Li"
        ],
        "abstract": "Synapse crossbar is an elementary structure in Neuromorphic Computing Systems (NCS). However, the limited size of crossbars and heavy routing congestion impedes the NCS implementations of big neural networks. In this paper, we propose a two-step framework (namely, group scissor) to scale NCS designs to big neural networks. The first step is rank clipping, which integrates low-rank approximation into the training to reduce total crossbar area. The second step is group connection deletion, which structurally prunes connections to reduce routing congestion between crossbars. Tested on convolutional neural networks of LeNet on MNIST database and ConvNet on CIFAR-10 database, our experiments show significant reduction of crossbar area and routing area in NCS designs. Without accuracy loss, rank clipping reduces total crossbar area to 13.62\\% and 51.81\\% in the NCS designs of LeNet and ConvNet, respectively. Following rank clipping, group connection deletion further reduces the routing area of LeNet and ConvNet to 8.1\\% and 52.06\\%, respectively.\n    ",
        "submission_date": "2017-02-11T00:00:00",
        "last_modified_date": "2017-06-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.03767",
        "title": "Is Big Data Sufficient for a Reliable Detection of Non-Technical Losses?",
        "authors": [
            "Patrick Glauner",
            "Angelo Migliosi",
            "Jorge Meira",
            "Petko Valtchev",
            "Radu State",
            "Franck Bettinger"
        ],
        "abstract": "Non-technical losses (NTL) occur during the distribution of electricity in power grids and include, but are not limited to, electricity theft and faulty meters. In emerging countries, they may range up to 40% of the total electricity distributed. In order to detect NTLs, machine learning methods are used that learn irregular consumption patterns from customer data and inspection results. The Big Data paradigm followed in modern machine learning reflects the desire of deriving better conclusions from simply analyzing more data, without the necessity of looking at theory and models. However, the sample of inspected customers may be biased, i.e. it does not represent the population of all customers. As a consequence, machine learning models trained on these inspection results are biased as well and therefore lead to unreliable predictions of whether customers cause NTL or not. In machine learning, this issue is called covariate shift and has not been addressed in the literature on NTL detection yet. In this work, we present a novel framework for quantifying and visualizing covariate shift. We apply it to a commercial data set from Brazil that consists of 3.6M customers and 820K inspection results. We show that some features have a stronger covariate shift than others, making predictions less reliable. In particular, previous inspections were focused on certain neighborhoods or customer classes and that they were not sufficiently spread among the population of customers. This framework is about to be deployed in a commercial product for NTL detection.\n    ",
        "submission_date": "2017-02-13T00:00:00",
        "last_modified_date": "2017-07-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.03812",
        "title": "Reservoir Computing Using Non-Uniform Binary Cellular Automata",
        "authors": [
            "Stefano Nichele",
            "Magnus S. Gundersen"
        ],
        "abstract": "The Reservoir Computing (RC) paradigm utilizes a dynamical system, i.e., a reservoir, and a linear classifier, i.e., a read-out layer, to process data from sequential classification tasks. In this paper the usage of Cellular Automata (CA) as a reservoir is investigated. The use of CA in RC has been showing promising results. In this paper, selected state-of-the-art experiments are reproduced. It is shown that some CA-rules perform better than others, and the reservoir performance is improved by increasing the size of the CA reservoir itself. In addition, the usage of parallel loosely coupled CA-reservoirs, where each reservoir has a different CA-rule, is investigated. The experiments performed on quasi-uniform CA reservoir provide valuable insights in CA reservoir design. The results herein show that some rules do not work well together, while other combinations work remarkably well. This suggests that non-uniform CA could represent a powerful tool for novel CA reservoir implementations.\n    ",
        "submission_date": "2017-02-13T00:00:00",
        "last_modified_date": "2017-02-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.03859",
        "title": "Offline bilingual word vectors, orthogonal transformations and the inverted softmax",
        "authors": [
            "Samuel L. Smith",
            "David H. P. Turban",
            "Steven Hamblin",
            "Nils Y. Hammerla"
        ],
        "abstract": "Usually bilingual word vectors are trained \"online\". Mikolov et al. showed they can also be found \"offline\", whereby two pre-trained embeddings are aligned with a linear transformation, using dictionaries compiled from expert knowledge. In this work, we prove that the linear transformation between two spaces should be orthogonal. This transformation can be obtained using the singular value decomposition. We introduce a novel \"inverted softmax\" for identifying translation pairs, with which we improve the precision @1 of Mikolov's original mapping from 34% to 43%, when translating a test set composed of both common and rare English words into Italian. Orthogonal transformations are more robust to noise, enabling us to learn the transformation without expert bilingual signal by constructing a \"pseudo-dictionary\" from the identical character strings which appear in both languages, achieving 40% precision on the same test set. Finally, we extend our method to retrieve the true translations of English sentences from a corpus of 200k Italian sentences with a precision @1 of 68%.\n    ",
        "submission_date": "2017-02-13T00:00:00",
        "last_modified_date": "2017-02-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.03920",
        "title": "Cognitive Mapping and Planning for Visual Navigation",
        "authors": [
            "Saurabh Gupta",
            "Varun Tolani",
            "James Davidson",
            "Sergey Levine",
            "Rahul Sukthankar",
            "Jitendra Malik"
        ],
        "abstract": "We introduce a neural architecture for navigation in novel environments. Our proposed architecture learns to map from first-person views and plans a sequence of actions towards goals in the environment. The Cognitive Mapper and Planner (CMP) is based on two key ideas: a) a unified joint architecture for mapping and planning, such that the mapping is driven by the needs of the task, and b) a spatial memory with the ability to plan given an incomplete set of observations about the world. CMP constructs a top-down belief map of the world and applies a differentiable neural net planner to produce the next action at each time step. The accumulated belief of the world enables the agent to track visited regions of the environment. We train and test CMP on navigation problems in simulation environments derived from scans of real world buildings. Our experiments demonstrate that CMP outperforms alternate learning-based architectures, as well as, classical mapping and path planning approaches in many cases. Furthermore, it naturally extends to semantically specified goals, such as 'going to a chair'. We also deploy CMP on physical robots in indoor environments, where it achieves reasonable performance, even though it is trained entirely in simulation.\n    ",
        "submission_date": "2017-02-13T00:00:00",
        "last_modified_date": "2019-02-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.03935",
        "title": "Data-Intensive Supercomputing in the Cloud: Global Analytics for Satellite Imagery",
        "authors": [
            "Michael S. Warren",
            "Samuel W. Skillman",
            "Rick Chartrand",
            "Tim Kelton",
            "Ryan Keisler",
            "David Raleigh",
            "Matthew Turk"
        ],
        "abstract": "We present our experiences using cloud computing to support data-intensive analytics on satellite imagery for commercial applications. Drawing from our background in high-performance computing, we draw parallels between the early days of clustered computing systems and the current state of cloud computing and its potential to disrupt the HPC market. Using our own virtual file system layer on top of cloud remote object storage, we demonstrate aggregate read bandwidth of 230 gigabytes per second using 512 Google Compute Engine (GCE) nodes accessing a USA multi-region standard storage bucket. This figure is comparable to the best HPC storage systems in existence. We also present several of our application results, including the identification of field boundaries in Ukraine, and the generation of a global cloud-free base layer from Landsat imagery.\n    ",
        "submission_date": "2017-02-13T00:00:00",
        "last_modified_date": "2017-02-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.04267",
        "title": "On Detecting Adversarial Perturbations",
        "authors": [
            "Jan Hendrik Metzen",
            "Tim Genewein",
            "Volker Fischer",
            "Bastian Bischoff"
        ],
        "abstract": "Machine learning and deep learning in particular has advanced tremendously on perceptual tasks in recent years. However, it remains vulnerable against adversarial perturbations of the input that have been crafted specifically to fool the system while being quasi-imperceptible to a human. In this work, we propose to augment deep neural networks with a small \"detector\" subnetwork which is trained on the binary classification task of distinguishing genuine data from data containing adversarial perturbations. Our method is orthogonal to prior work on addressing adversarial perturbations, which has mostly focused on making the classification network itself more robust. We show empirically that adversarial perturbations can be detected surprisingly well even though they are quasi-imperceptible to humans. Moreover, while the detectors have been trained to detect only a specific adversary, they generalize to similar and weaker adversaries. In addition, we propose an adversarial attack that fools both the classifier and the detector and a novel training procedure for the detector that counteracts this attack.\n    ",
        "submission_date": "2017-02-14T00:00:00",
        "last_modified_date": "2017-02-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.04280",
        "title": "DAGER: Deep Age, Gender and Emotion Recognition Using Convolutional Neural Network",
        "authors": [
            "Afshin Dehghan",
            "Enrique G. Ortiz",
            "Guang Shu",
            "Syed Zain Masood"
        ],
        "abstract": "This paper describes the details of Sighthound's fully automated age, gender and emotion recognition system. The backbone of our system consists of several deep convolutional neural networks that are not only computationally inexpensive, but also provide state-of-the-art results on several competitive benchmarks. To power our novel deep networks, we collected large labeled datasets through a semi-supervised pipeline to reduce the annotation effort/time. We tested our system on several public benchmarks and report outstanding results. Our age, gender and emotion recognition models are available to developers through the Sighthound Cloud API at ",
        "submission_date": "2017-02-14T00:00:00",
        "last_modified_date": "2017-03-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.04423",
        "title": "Efficient Multitask Feature and Relationship Learning",
        "authors": [
            "Han Zhao",
            "Otilia Stretcu",
            "Alex Smola",
            "Geoff Gordon"
        ],
        "abstract": "We consider a multitask learning problem, in which several predictors are learned jointly. Prior research has shown that learning the relations between tasks, and between the input features, together with the predictor, can lead to better generalization and interpretability, which proved to be useful for applications in many domains. In this paper, we consider a formulation of multitask learning that learns the relationships both between tasks and between features, represented through a task covariance and a feature covariance matrix, respectively. First, we demonstrate that existing methods proposed for this problem present an issue that may lead to ill-posed optimization. We then propose an alternative formulation, as well as an efficient algorithm to optimize it. Using ideas from optimization and graph theory, we propose an efficient coordinate-wise minimization algorithm that has a closed form solution for each block subproblem. Our experiments show that the proposed optimization method is orders of magnitude faster than its competitors. We also provide a nonlinear extension that is able to achieve better generalization than existing methods.\n    ",
        "submission_date": "2017-02-14T00:00:00",
        "last_modified_date": "2019-07-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.04521",
        "title": "Frustratingly Short Attention Spans in Neural Language Modeling",
        "authors": [
            "Micha\u0142 Daniluk",
            "Tim Rockt\u00e4schel",
            "Johannes Welbl",
            "Sebastian Riedel"
        ],
        "abstract": "Neural language models predict the next token using a latent representation of the immediate token history. Recently, various methods for augmenting neural language models with an attention mechanism over a differentiable memory have been proposed. For predicting the next token, these models query information from a memory of the recent history which can facilitate learning mid- and long-range dependencies. However, conventional attention mechanisms used in memory-augmented neural language models produce a single output vector per time step. This vector is used both for predicting the next token as well as for the key and value of a differentiable memory of a token history. In this paper, we propose a neural language model with a key-value attention mechanism that outputs separate representations for the key and value of a differentiable memory, as well as for encoding the next-word distribution. This model outperforms existing memory-augmented neural language models on two corpora. Yet, we found that our method mainly utilizes a memory of the five most recent output representations. This led to the unexpected main finding that a much simpler model based only on the concatenation of recent output representations from previous time steps is on par with more sophisticated memory-augmented neural language models.\n    ",
        "submission_date": "2017-02-15T00:00:00",
        "last_modified_date": "2017-02-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.04577",
        "title": "On the Discrepancy Between Kleinberg's Clustering Axioms and $k$-Means Clustering Algorithm Behavior",
        "authors": [
            "Robert K\u0142opotek",
            "Mieczys\u0142aw K\u0142opotek"
        ],
        "abstract": "This paper investigates the validity of Kleinberg's axioms for clustering functions with respect to the quite popular clustering algorithm called $k$-means. While Kleinberg's axioms have been discussed heavily in the past, we concentrate here on the case predominantly relevant for $k$-means algorithm, that is behavior embedded in Euclidean space. We point at some contradictions and counter intuitiveness aspects of this axiomatic set within $\\mathbb{R}^m$ that were evidently not discussed so far. Our results suggest that apparently without defining clearly what kind of clusters we expect we will not be able to construct a valid axiomatic system. In particular we look at the shape and the gaps between the clusters. Finally we demonstrate that there exist several ways to reconcile the formulation of the axioms with their intended meaning and that under this reformulation the axioms stop to be contradictory and the real-world $k$-means algorithm conforms to this axiomatic system.\n    ",
        "submission_date": "2017-02-15T00:00:00",
        "last_modified_date": "2017-04-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.04595",
        "title": "Visualizing Deep Neural Network Decisions: Prediction Difference Analysis",
        "authors": [
            "Luisa M Zintgraf",
            "Taco S Cohen",
            "Tameem Adel",
            "Max Welling"
        ],
        "abstract": "This article presents the prediction difference analysis method for visualizing the response of a deep neural network to a specific input. When classifying images, the method highlights areas in a given input image that provide evidence for or against a certain class. It overcomes several shortcoming of previous methods and provides great additional insight into the decision making process of classifiers. Making neural network decisions interpretable through visualization is important both to improve models and to accelerate the adoption of black-box classifiers in application areas such as medicine. We illustrate the method in experiments on natural images (ImageNet data), as well as medical images (MRI brain scans).\n    ",
        "submission_date": "2017-02-15T00:00:00",
        "last_modified_date": "2017-02-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.04767",
        "title": "Linear Time Computation of Moments in Sum-Product Networks",
        "authors": [
            "Han Zhao",
            "Geoff Gordon"
        ],
        "abstract": "Bayesian online algorithms for Sum-Product Networks (SPNs) need to update their posterior distribution after seeing one single additional instance. To do so, they must compute moments of the model parameters under this distribution. The best existing method for computing such moments scales quadratically in the size of the SPN, although it scales linearly for trees. This unfortunate scaling makes Bayesian online algorithms prohibitively expensive, except for small or tree-structured SPNs. We propose an optimal linear-time algorithm that works even when the SPN is a general directed acyclic graph (DAG), which significantly broadens the applicability of Bayesian online algorithms for SPNs. There are three key ingredients in the design and analysis of our algorithm: 1). For each edge in the graph, we construct a linear time reduction from the moment computation problem to a joint inference problem in SPNs. 2). Using the property that each SPN computes a multilinear polynomial, we give an efficient procedure for polynomial evaluation by differentiation without expanding the network that may contain exponentially many monomials. 3). We propose a dynamic programming method to further reduce the computation of the moments of all the edges in the graph from quadratic to linear. We demonstrate the usefulness of our linear time algorithm by applying it to develop a linear time assume density filter (ADF) for SPNs.\n    ",
        "submission_date": "2017-02-15T00:00:00",
        "last_modified_date": "2017-11-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.04849",
        "title": "Theoretical and Practical Advances on Smoothing for Extensive-Form Games",
        "authors": [
            "Christian Kroer",
            "Kevin Waugh",
            "Fatma Kilinc-Karzan",
            "Tuomas Sandholm"
        ],
        "abstract": "Sparse iterative methods, in particular first-order methods, are known to be among the most effective in solving large-scale two-player zero-sum extensive-form games. The convergence rates of these methods depend heavily on the properties of the distance-generating function that they are based on. We investigate the acceleration of first-order methods for solving extensive-form games through better design of the dilated entropy function---a class of distance-generating functions related to the domains associated with the extensive-form games. By introducing a new weighting scheme for the dilated entropy function, we develop the first distance-generating function for the strategy spaces of sequential games that has no dependence on the branching factor of the player. This result improves the convergence rate of several first-order methods by a factor of $\\Omega(b^dd)$, where $b$ is the branching factor of the player, and $d$ is the depth of the game tree.\n",
        "submission_date": "2017-02-16T00:00:00",
        "last_modified_date": "2017-05-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.04956",
        "title": "Reflexive Regular Equivalence for Bipartite Data",
        "authors": [
            "Aaron Gerow",
            "Mingyang Zhou",
            "Stan Matwin",
            "Feng Shi"
        ],
        "abstract": "Bipartite data is common in data engineering and brings unique challenges, particularly when it comes to clustering tasks that impose on strong structural assumptions. This work presents an unsupervised method for assessing similarity in bipartite data. Similar to some co-clustering methods, the method is based on regular equivalence in graphs. The algorithm uses spectral properties of a bipartite adjacency matrix to estimate similarity in both dimensions. The method is reflexive in that similarity in one dimension is used to inform similarity in the other. Reflexive regular equivalence can also use the structure of transitivities -- in a network sense -- the contribution of which is controlled by the algorithm's only free-parameter, $\\alpha$. The method is completely unsupervised and can be used to validate assumptions of co-similarity, which are required but often untested, in co-clustering analyses. Three variants of the method with different normalizations are tested on synthetic data. The method is found to be robust to noise and well-suited to asymmetric co-similar structure, making it particularly informative for cluster analysis and recommendation in bipartite data of unknown structure. In experiments, the convergence and speed of the algorithm are found to be stable for different levels of noise. Real-world data from a network of malaria genes are analyzed, where the similarity produced by the reflexive method is shown to out-perform other measures' ability to correctly classify genes.\n    ",
        "submission_date": "2017-02-16T00:00:00",
        "last_modified_date": "2017-02-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.05112",
        "title": "OntoMath Digital Ecosystem: Ontologies, Mathematical Knowledge Analytics and Management",
        "authors": [
            "Alexander Elizarov",
            "Alexander Kirillovich",
            "Evgeny Lipachev",
            "Olga Nevzorova"
        ],
        "abstract": "In this article we consider the basic ideas, approaches and results of developing of mathematical knowledge management technologies based on ontologies. These solutions form the basis of a specialized digital ecosystem OntoMath which consists of the ontology of the logical structure of mathematical documents Mocassin and ontology of mathematical knowledge OntoMathPRO, tools of text analysis, recommender system and other applications to manage mathematical knowledge. The studies are in according to the ideas of creating a distributed system of interconnected repositories of digitized versions of mathematical documents and project to create a World Digital Mathematical Library.\n    ",
        "submission_date": "2017-02-16T00:00:00",
        "last_modified_date": "2017-02-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.05222",
        "title": "Direct Estimation of Information Divergence Using Nearest Neighbor Ratios",
        "authors": [
            "Morteza Noshad",
            "Kevin R. Moon",
            "Salimeh Yasaei Sekeh",
            "Alfred O. Hero III"
        ],
        "abstract": "We propose a direct estimation method for R\u00e9nyi and f-divergence measures based on a new graph theoretical interpretation. Suppose that we are given two sample sets $X$ and $Y$, respectively with $N$ and $M$ samples, where $\\eta:=M/N$ is a constant value. Considering the $k$-nearest neighbor ($k$-NN) graph of $Y$ in the joint data set $(X,Y)$, we show that the average powered ratio of the number of $X$ points to the number of $Y$ points among all $k$-NN points is proportional to R\u00e9nyi divergence of $X$ and $Y$ densities. A similar method can also be used to estimate f-divergence measures. We derive bias and variance rates, and show that for the class of $\\gamma$-H\u00f6lder smooth functions, the estimator achieves the MSE rate of $O(N^{-2\\gamma/(\\gamma+d)})$. Furthermore, by using a weighted ensemble estimation technique, for density functions with continuous and bounded derivatives of up to the order $d$, and some extra conditions at the support set boundary, we derive an ensemble estimator that achieves the parametric MSE rate of $O(1/N)$. Our estimators are more computationally tractable than other competing estimators, which makes them appealing in many practical applications.\n    ",
        "submission_date": "2017-02-17T00:00:00",
        "last_modified_date": "2017-11-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.05270",
        "title": "Be Precise or Fuzzy: Learning the Meaning of Cardinals and Quantifiers from Vision",
        "authors": [
            "Sandro Pezzelle",
            "Marco Marelli",
            "Raffaella Bernardi"
        ],
        "abstract": "People can refer to quantities in a visual scene by using either exact cardinals (e.g. one, two, three) or natural language quantifiers (e.g. few, most, all). In humans, these two processes underlie fairly different cognitive and neural mechanisms. Inspired by this evidence, the present study proposes two models for learning the objective meaning of cardinals and quantifiers from visual scenes containing multiple objects. We show that a model capitalizing on a 'fuzzy' measure of similarity is effective for learning quantifiers, whereas the learning of exact cardinals is better accomplished when information about number is provided.\n    ",
        "submission_date": "2017-02-17T00:00:00",
        "last_modified_date": "2017-02-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.05437",
        "title": "Quantifying Program Bias",
        "authors": [
            "Aws Albarghouthi",
            "Loris D'Antoni",
            "Samuel Drews",
            "Aditya Nori"
        ],
        "abstract": "With the range and sensitivity of algorithmic decisions expanding at a break-neck speed, it is imperative that we aggressively investigate whether programs are biased. We propose a novel probabilistic program analysis technique and apply it to quantifying bias in decision-making programs. Specifically, we (i) present a sound and complete automated verification technique for proving quantitative properties of probabilistic programs; (ii) show that certain notions of bias, recently proposed in the fairness literature, can be phrased as quantitative correctness properties; and (iii) present FairSquare, the first verification tool for quantifying program bias, and evaluate it on a range of decision-making programs.\n    ",
        "submission_date": "2017-02-17T00:00:00",
        "last_modified_date": "2017-03-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.05472",
        "title": "Threshold Constraints with Guarantees for Parity Objectives in Markov Decision Processes",
        "authors": [
            "Rapha\u00ebl Berthon",
            "Mickael Randour",
            "Jean-Fran\u00e7ois Raskin"
        ],
        "abstract": "The beyond worst-case synthesis problem was introduced recently by Bruy\u00e8re et al. [BFRR14]: it aims at building system controllers that provide strict worst-case performance guarantees against an antagonistic environment while ensuring higher expected performance against a stochastic model of the environment. Our work extends the framework of [BFRR14] and follow-up papers, which focused on quantitative objectives, by addressing the case of $\\omega$-regular conditions encoded as parity objectives, a natural way to represent functional requirements of systems.\n",
        "submission_date": "2017-02-17T00:00:00",
        "last_modified_date": "2017-04-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.05677",
        "title": "Quadratic Upper Bound for Recursive Teaching Dimension of Finite VC Classes",
        "authors": [
            "Lunjia Hu",
            "Ruihan Wu",
            "Tianhong Li",
            "Liwei Wang"
        ],
        "abstract": "In this work we study the quantitative relation between the recursive teaching dimension (RTD) and the VC dimension (VCD) of concept classes of finite sizes. The RTD of a concept class $\\mathcal C \\subseteq \\{0, 1\\}^n$, introduced by Zilles et al. (2011), is a combinatorial complexity measure characterized by the worst-case number of examples necessary to identify a concept in $\\mathcal C$ according to the recursive teaching model.\n",
        "submission_date": "2017-02-18T00:00:00",
        "last_modified_date": "2017-02-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.05710",
        "title": "Polynomial Time Efficient Construction Heuristics for Vertex Separation Minimization Problem",
        "authors": [
            "Pallavi Jain",
            "Gur Saran",
            "Kamal Srivastava"
        ],
        "abstract": "Vertex Separation Minimization Problem (VSMP) consists of finding a layout of a graph G = (V,E) which minimizes the maximum vertex cut or separation of a layout. It is an NP-complete problem in general for which metaheuristic techniques can be applied to find near optimal solution. VSMP has applications in VLSI design, graph drawing and computer language compiler design. VSMP is polynomially solvable for grids, trees, permutation graphs and cographs. Construction heuristics play a very important role in the metaheuristic techniques as they are responsible for generating initial solutions which lead to fast convergence. In this paper, we have proposed three construction heuristics H1, H2 and H3 and performed experiments on Grids, Small graphs, Trees and Harwell Boeing graphs, totaling 248 instances of graphs. Experiments reveal that H1, H2 and H3 are able to achieve best results for 88.71%, 43.5% and 37.1% of the total instances respectively while the best construction heuristic in the literature achieves the best solution for 39.9% of the total instances. We have also compared the results with the state-of-the-art metaheuristic GVNS and observed that the proposed construction heuristics improves the results for some of the input instances. It was found that GVNS obtained best results for 82.9% instances of all input instances and the heuristic H1 obtained best results for 82.3% of all input instances.\n    ",
        "submission_date": "2017-02-19T00:00:00",
        "last_modified_date": "2017-02-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.05800",
        "title": "Revisiting Distributed Synchronous SGD",
        "authors": [
            "Xinghao Pan",
            "Jianmin Chen",
            "Rajat Monga",
            "Samy Bengio",
            "Rafal Jozefowicz"
        ],
        "abstract": "Distributed training of deep learning models on large-scale training data is typically conducted with asynchronous stochastic optimization to maximize the rate of updates, at the cost of additional noise introduced from asynchrony. In contrast, the synchronous approach is often thought to be impractical due to idle time wasted on waiting for straggling workers. We revisit these conventional beliefs in this paper, and examine the weaknesses of both approaches. We demonstrate that a third approach, synchronous optimization with backup workers, can avoid asynchronous noise while mitigating for the worst stragglers. Our approach is empirically validated and shown to converge faster and to better test accuracies.\n    ",
        "submission_date": "2017-02-19T00:00:00",
        "last_modified_date": "2017-03-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.05865",
        "title": "Hemingway: Modeling Distributed Optimization Algorithms",
        "authors": [
            "Xinghao Pan",
            "Shivaram Venkataraman",
            "Zizheng Tai",
            "Joseph Gonzalez"
        ],
        "abstract": "Distributed optimization algorithms are widely used in many industrial machine learning applications. However choosing the appropriate algorithm and cluster size is often difficult for users as the performance and convergence rate of optimization algorithms vary with the size of the cluster. In this paper we make the case for an ML-optimizer that can select the appropriate algorithm and cluster size to use for a given problem. To do this we propose building two models: one that captures the system level characteristics of how computation, communication change as we increase cluster sizes and another that captures how convergence rates change with cluster sizes. We present preliminary results from our prototype implementation called Hemingway and discuss some of the challenges involved in developing such a system.\n    ",
        "submission_date": "2017-02-20T00:00:00",
        "last_modified_date": "2017-02-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.05870",
        "title": "Cosine Normalization: Using Cosine Similarity Instead of Dot Product in Neural Networks",
        "authors": [
            "Chunjie Luo",
            "Jianfeng Zhan",
            "Lei Wang",
            "Qiang Yang"
        ],
        "abstract": "Traditionally, multi-layer neural networks use dot product between the output vector of previous layer and the incoming weight vector as the input to activation function. The result of dot product is unbounded, thus increases the risk of large variance. Large variance of neuron makes the model sensitive to the change of input distribution, thus results in poor generalization, and aggravates the internal covariate shift which slows down the training. To bound dot product and decrease the variance, we propose to use cosine similarity or centered cosine similarity (Pearson Correlation Coefficient) instead of dot product in neural networks, which we call cosine normalization. We compare cosine normalization with batch, weight and layer normalization in fully-connected neural networks as well as convolutional networks on the data sets of MNIST, 20NEWS GROUP, CIFAR-10/100 and SVHN. Experiments show that cosine normalization achieves better performance than other normalization techniques.\n    ",
        "submission_date": "2017-02-20T00:00:00",
        "last_modified_date": "2017-10-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.05970",
        "title": "Automatic Liver and Tumor Segmentation of CT and MRI Volumes using Cascaded Fully Convolutional Neural Networks",
        "authors": [
            "Patrick Ferdinand Christ",
            "Florian Ettlinger",
            "Felix Gr\u00fcn",
            "Mohamed Ezzeldin A. Elshaera",
            "Jana Lipkova",
            "Sebastian Schlecht",
            "Freba Ahmaddy",
            "Sunil Tatavarty",
            "Marc Bickel",
            "Patrick Bilic",
            "Markus Rempfler",
            "Felix Hofmann",
            "Melvin D Anastasi",
            "Seyed-Ahmad Ahmadi",
            "Georgios Kaissis",
            "Julian Holch",
            "Wieland Sommer",
            "Rickmer Braren",
            "Volker Heinemann",
            "Bjoern Menze"
        ],
        "abstract": "Automatic segmentation of the liver and hepatic lesions is an important step towards deriving quantitative biomarkers for accurate clinical diagnosis and computer-aided decision support systems. This paper presents a method to automatically segment liver and lesions in CT and MRI abdomen images using cascaded fully convolutional neural networks (CFCNs) enabling the segmentation of a large-scale medical trial or quantitative image analysis. We train and cascade two FCNs for a combined segmentation of the liver and its lesions. In the first step, we train a FCN to segment the liver as ROI input for a second FCN. The second FCN solely segments lesions within the predicted liver ROIs of step 1. CFCN models were trained on an abdominal CT dataset comprising 100 hepatic tumor volumes. Validations on further datasets show that CFCN-based semantic liver and lesion segmentation achieves Dice scores over 94% for liver with computation times below 100s per volume. We further experimentally demonstrate the robustness of the proposed method on an 38 MRI liver tumor volumes and the public 3DIRCAD dataset.\n    ",
        "submission_date": "2017-02-20T00:00:00",
        "last_modified_date": "2017-02-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.06054",
        "title": "Learning to Repeat: Fine Grained Action Repetition for Deep Reinforcement Learning",
        "authors": [
            "Sahil Sharma",
            "Aravind Srinivas",
            "Balaraman Ravindran"
        ],
        "abstract": "Reinforcement Learning algorithms can learn complex behavioral patterns for sequential decision making tasks wherein an agent interacts with an environment and acquires feedback in the form of rewards sampled from it. Traditionally, such algorithms make decisions, i.e., select actions to execute, at every single time step of the agent-environment interactions. In this paper, we propose a novel framework, Fine Grained Action Repetition (FiGAR), which enables the agent to decide the action as well as the time scale of repeating it. FiGAR can be used for improving any Deep Reinforcement Learning algorithm which maintains an explicit policy estimate by enabling temporal abstractions in the action space. We empirically demonstrate the efficacy of our framework by showing performance improvements on top of three policy search algorithms in different domains: Asynchronous Advantage Actor Critic in the Atari 2600 domain, Trust Region Policy Optimization in Mujoco domain and Deep Deterministic Policy Gradients in the TORCS car racing domain.\n    ",
        "submission_date": "2017-02-20T00:00:00",
        "last_modified_date": "2020-09-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.06186",
        "title": "Survey of reasoning using Neural networks",
        "authors": [
            "Amit Sahu"
        ],
        "abstract": "Reason and inference require process as well as memory skills by humans. Neural networks are able to process tasks like image recognition (better than humans) but in memory aspects are still limited (by attention mechanism, size). Recurrent Neural Network (RNN) and it's modified version LSTM are able to solve small memory contexts, but as context becomes larger than a threshold, it is difficult to use them. The Solution is to use large external memory. Still, it poses many challenges like, how to train neural networks for discrete memory representation, how to describe long term dependencies in sequential data etc. Most prominent neural architectures for such tasks are Memory networks: inference components combined with long term memory and Neural Turing Machines: neural networks using external memory resources. Also, additional techniques like attention mechanism, end to end gradient descent on discrete memory representation are needed to support these solutions. Preliminary results of above neural architectures on simple algorithms (sorting, copying) and Question Answering (based on story, dialogs) application are comparable with the state of the art. In this paper, I explain these architectures (in general), the additional techniques used and the results of their application.\n    ",
        "submission_date": "2017-02-14T00:00:00",
        "last_modified_date": "2017-03-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.06230",
        "title": "Beating the World's Best at Super Smash Bros. with Deep Reinforcement Learning",
        "authors": [
            "Vlad Firoiu",
            "William F. Whitney",
            "Joshua B. Tenenbaum"
        ],
        "abstract": "There has been a recent explosion in the capabilities of game-playing artificial intelligence. Many classes of RL tasks, from Atari games to motor control to board games, are now solvable by fairly generic algorithms, based on deep learning, that learn to play from experience with minimal knowledge of the specific domain of interest. In this work, we will investigate the performance of these methods on Super Smash Bros. Melee (SSBM), a popular console fighting game. The SSBM environment has complex dynamics and partial observability, making it challenging for human and machine alike. The multi-player aspect poses an additional challenge, as the vast majority of recent advances in RL have focused on single-agent environments. Nonetheless, we will show that it is possible to train agents that are competitive against and even surpass human professionals, a new result for the multi-player video game setting.\n    ",
        "submission_date": "2017-02-21T00:00:00",
        "last_modified_date": "2017-05-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.06253",
        "title": "Player Skill Decomposition in Multiplayer Online Battle Arenas",
        "authors": [
            "Zhengxing Chen",
            "Yizhou Sun",
            "Magy Seif El-nasr",
            "Truong-Huy D. Nguyen"
        ],
        "abstract": "Successful analysis of player skills in video games has important impacts on the process of enhancing player experience without undermining their continuous skill development. Moreover, player skill analysis becomes more intriguing in team-based video games because such form of study can help discover useful factors in effective team formation. In this paper, we consider the problem of skill decomposition in MOBA (MultiPlayer Online Battle Arena) games, with the goal to understand what player skill factors are essential for the outcome of a game match. To understand the construct of MOBA player skills, we utilize various skill-based predictive models to decompose player skills into interpretative parts, the impact of which are assessed in statistical terms. We apply this analysis approach on two widely known MOBAs, namely League of Legends (LoL) and Defense of the Ancients 2 (DOTA2). The finding is that base skills of in-game avatars, base skills of players, and players' champion-specific skills are three prominent skill components influencing LoL's match outcomes, while those of DOTA2 are mainly impacted by in-game avatars' base skills but not much by the other two.\n    ",
        "submission_date": "2017-02-21T00:00:00",
        "last_modified_date": "2017-02-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.06334",
        "title": "Synthesizing Imperative Programs from Examples Guided by Static Analysis",
        "authors": [
            "Sunbeom So",
            "Hakjoo Oh"
        ],
        "abstract": "We present a novel algorithm that synthesizes imperative programs for introductory programming courses. Given a set of input-output examples and a partial program, our algorithm generates a complete program that is consistent with every example. Our key idea is to combine enumerative program synthesis and static analysis, which aggressively prunes out a large search space while guaranteeing to find, if any, a correct solution. We have implemented our algorithm in a tool, called SIMPL, and evaluated it on 30 problems used in introductory programming courses. The results show that SIMPL is able to solve the benchmark problems in 6.6 seconds on average.\n    ",
        "submission_date": "2017-02-21T00:00:00",
        "last_modified_date": "2017-06-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.06674",
        "title": "Unsupervised Diverse Colorization via Generative Adversarial Networks",
        "authors": [
            "Yun Cao",
            "Zhiming Zhou",
            "Weinan Zhang",
            "Yong Yu"
        ],
        "abstract": "Colorization of grayscale images has been a hot topic in computer vision. Previous research mainly focuses on producing a colored image to match the original one. However, since many colors share the same gray value, an input grayscale image could be diversely colored while maintaining its reality. In this paper, we design a novel solution for unsupervised diverse colorization. Specifically, we leverage conditional generative adversarial networks to model the distribution of real-world item colors, in which we develop a fully convolutional generator with multi-layer noise to enhance diversity, with multi-layer condition concatenation to maintain reality, and with stride 1 to keep spatial information. With such a novel network architecture, the model yields highly competitive performance on the open LSUN bedroom dataset. The Turing test of 80 humans further indicates our generated color schemes are highly convincible.\n    ",
        "submission_date": "2017-02-22T00:00:00",
        "last_modified_date": "2017-07-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.06700",
        "title": "Task-driven Visual Saliency and Attention-based Visual Question Answering",
        "authors": [
            "Yuetan Lin",
            "Zhangyang Pang",
            "Donghui Wang",
            "Yueting Zhuang"
        ],
        "abstract": "Visual question answering (VQA) has witnessed great progress since May, 2015 as a classic problem unifying visual and textual data into a system. Many enlightening VQA works explore deep into the image and question encodings and fusing methods, of which attention is the most effective and infusive mechanism. Current attention based methods focus on adequate fusion of visual and textual features, but lack the attention to where people focus to ask questions about the image. Traditional attention based methods attach a single value to the feature at each spatial location, which losses many useful information. To remedy these problems, we propose a general method to perform saliency-like pre-selection on overlapped region features by the interrelation of bidirectional LSTM (BiLSTM), and use a novel element-wise multiplication based attention method to capture more competent correlation information between visual and textual features. We conduct experiments on the large-scale COCO-VQA dataset and analyze the effectiveness of our model demonstrated by strong empirical results.\n    ",
        "submission_date": "2017-02-22T00:00:00",
        "last_modified_date": "2017-02-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.06763",
        "title": "DeepCloak: Masking Deep Neural Network Models for Robustness Against Adversarial Samples",
        "authors": [
            "Ji Gao",
            "Beilun Wang",
            "Zeming Lin",
            "Weilin Xu",
            "Yanjun Qi"
        ],
        "abstract": "Recent studies have shown that deep neural networks (DNN) are vulnerable to adversarial samples: maliciously-perturbed samples crafted to yield incorrect model outputs. Such attacks can severely undermine DNN systems, particularly in security-sensitive settings. It was observed that an adversary could easily generate adversarial samples by making a small perturbation on irrelevant feature dimensions that are unnecessary for the current classification task. To overcome this problem, we introduce a defensive mechanism called DeepCloak. By identifying and removing unnecessary features in a DNN model, DeepCloak limits the capacity an attacker can use generating adversarial samples and therefore increase the robustness against such inputs. Comparing with other defensive approaches, DeepCloak is easy to implement and computationally efficient. Experimental results show that DeepCloak can increase the performance of state-of-the-art DNN models against adversarial samples.\n    ",
        "submission_date": "2017-02-22T00:00:00",
        "last_modified_date": "2017-04-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.06776",
        "title": "Causal Inference by Stochastic Complexity",
        "authors": [
            "Kailash Budhathoki",
            "Jilles Vreeken"
        ],
        "abstract": "The algorithmic Markov condition states that the most likely causal direction between two random variables X and Y can be identified as that direction with the lowest Kolmogorov complexity. Due to the halting problem, however, this notion is not computable.\n",
        "submission_date": "2017-02-22T00:00:00",
        "last_modified_date": "2017-02-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.06820",
        "title": "EOMM: An Engagement Optimized Matchmaking Framework",
        "authors": [
            "Zhengxing Chen",
            "Su Xue",
            "John Kolen",
            "Navid Aghdaie",
            "Kazi A. Zaman",
            "Yizhou Sun",
            "Magy Seif El-Nasr"
        ],
        "abstract": "Matchmaking connects multiple players to participate in online player-versus-player games. Current matchmaking systems depend on a single core strategy: create fair games at all times. These systems pair similarly skilled players on the assumption that a fair game is best player experience. We will demonstrate, however, that this intuitive assumption sometimes fails and that matchmaking based on fairness is not optimal for engagement.\n",
        "submission_date": "2017-02-22T00:00:00",
        "last_modified_date": "2017-02-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.06831",
        "title": "Using Redescription Mining to Relate Clinical and Biological Characteristics of Cognitively Impaired and Alzheimer's Disease Patients",
        "authors": [
            "Matej Mihel\u010di\u0107",
            "Goran \u0160imi\u0107",
            "Mirjana Babi\u0107 Leko",
            "Nada Lavra\u010d",
            "Sa\u0161o D\u017eeroski",
            "Tomislav \u0160muc"
        ],
        "abstract": "We used redescription mining to find interpretable rules revealing associations between those determinants that provide insights about the Alzheimer's disease (AD). We extended the CLUS-RM redescription mining algorithm to a constraint-based redescription mining (CBRM) setting, which enables several modes of targeted exploration of specific, user-constrained associations. Redescription mining enabled finding specific constructs of clinical and biological attributes that describe many groups of subjects of different size, homogeneity and levels of cognitive impairment. We confirmed some previously known findings. However, in some instances, as with the attributes: testosterone, the imaging attribute Spatial Pattern of Abnormalities for Recognition of Early AD, as well as the levels of leptin and angiopoietin-2 in plasma, we corroborated previously debatable findings or provided additional information about these variables and their association with AD pathogenesis. Applying redescription mining on ADNI data resulted with the discovery of one largely unknown attribute: the Pregnancy-Associated Protein-A (PAPP-A), which we found highly associated with cognitive impairment in AD. Statistically significant correlations (p <= 0.01) were found between PAPP-A and various different clinical tests. The high importance of this finding lies in the fact that PAPP-A is a metalloproteinase, known to cleave insulin-like growth factor binding proteins. Since it also shares similar substrates with A Disintegrin and the Metalloproteinase family of enzymes that act as {\\alpha}-secretase to physiologically cleave amyloid precursor protein (APP) in the non-amyloidogenic pathway, it could be directly involved in the metabolism of APP very early during the disease course. Therefore, further studies should investigate the role of PAPP-A in the development of AD more thoroughly.\n    ",
        "submission_date": "2017-02-20T00:00:00",
        "last_modified_date": "2017-11-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.06925",
        "title": "Regularizing Face Verification Nets For Pain Intensity Regression",
        "authors": [
            "Feng Wang",
            "Xiang Xiang",
            "Chang Liu",
            "Trac D. Tran",
            "Austin Reiter",
            "Gregory D. Hager",
            "Harry Quon",
            "Jian Cheng",
            "Alan L. Yuille"
        ],
        "abstract": "Limited labeled data are available for the research of estimating facial expression intensities. For instance, the ability to train deep networks for automated pain assessment is limited by small datasets with labels of patient-reported pain intensities. Fortunately, fine-tuning from a data-extensive pre-trained domain, such as face verification, can alleviate this problem. In this paper, we propose a network that fine-tunes a state-of-the-art face verification network using a regularized regression loss and additional data with expression labels. In this way, the expression intensity regression task can benefit from the rich feature representations trained on a huge amount of data for face verification. The proposed regularized deep regressor is applied to estimate the pain expression intensity and verified on the widely-used UNBC-McMaster Shoulder-Pain dataset, achieving the state-of-the-art performance. A weighted evaluation metric is also proposed to address the imbalance issue of different pain intensities.\n    ",
        "submission_date": "2017-02-22T00:00:00",
        "last_modified_date": "2017-06-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.07031",
        "title": "Proactive Resource Management for LTE in Unlicensed Spectrum: A Deep Learning Perspective",
        "authors": [
            "Ursula Challita",
            "Li Dong",
            "Walid Saad"
        ],
        "abstract": "LTE in unlicensed spectrum using licensed assisted access LTE (LTE-LAA) is a promising approach to overcome the wireless spectrum scarcity. However, to reap the benefits of LTE-LAA, a fair coexistence mechanism with other incumbent WiFi deployments is required. In this paper, a novel deep learning approach is proposed for modeling the resource allocation problem of LTE-LAA small base stations (SBSs). The proposed approach enables multiple SBSs to proactively perform dynamic channel selection, carrier aggregation, and fractional spectrum access while guaranteeing fairness with existing WiFi networks and other LTE-LAA operators. Adopting a proactive coexistence mechanism enables future delay-tolerant LTE-LAA data demands to be served within a given prediction window ahead of their actual arrival time thus avoiding the underutilization of the unlicensed spectrum during off-peak hours while maximizing the total served LTE-LAA traffic load. To this end, a noncooperative game model is formulated in which SBSs are modeled as Homo Egualis agents that aim at predicting a sequence of future actions and thus achieving long-term equal weighted fairness with WLAN and other LTE-LAA operators over a given time horizon. The proposed deep learning algorithm is then shown to reach a mixed-strategy Nash equilibrium (NE), when it converges. Simulation results using real data traces show that the proposed scheme can yield up to 28% and 11% gains over a conventional reactive approach and a proportional fair coexistence mechanism, respectively. The results also show that the proposed framework prevents WiFi performance degradation for a densely deployed LTE-LAA network.\n    ",
        "submission_date": "2017-02-22T00:00:00",
        "last_modified_date": "2018-12-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.07134",
        "title": "Diverse Weighted Bipartite b-Matching",
        "authors": [
            "Faez Ahmed",
            "John P. Dickerson",
            "Mark Fuge"
        ],
        "abstract": "Bipartite matching, where agents on one side of a market are matched to agents or items on the other, is a classical problem in computer science and economics, with widespread application in healthcare, education, advertising, and general resource allocation. A practitioner's goal is typically to maximize a matching market's economic efficiency, possibly subject to some fairness requirements that promote equal access to resources. A natural balancing act exists between fairness and efficiency in matching markets, and has been the subject of much research.\n",
        "submission_date": "2017-02-23T00:00:00",
        "last_modified_date": "2017-08-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.07450",
        "title": "Strongly-Typed Agents are Guaranteed to Interact Safely",
        "authors": [
            "David Balduzzi"
        ],
        "abstract": "As artificial agents proliferate, it is becoming increasingly important to ensure that their interactions with one another are well-behaved. In this paper, we formalize a common-sense notion of when algorithms are well-behaved: an algorithm is safe if it does no harm. Motivated by recent progress in deep learning, we focus on the specific case where agents update their actions according to gradient descent. The paper shows that that gradient descent converges to a Nash equilibrium in safe games. The main contribution is to define strongly-typed agents and show they are guaranteed to interact safely, thereby providing sufficient conditions to guarantee safe interactions. A series of examples show that strong-typing generalizes certain key features of convexity, is closely related to blind source separation, and introduces a new perspective on classical multilinear games based on tensor decomposition.\n    ",
        "submission_date": "2017-02-24T00:00:00",
        "last_modified_date": "2018-06-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.07475",
        "title": "Sequence-based Multimodal Apprenticeship Learning For Robot Perception and Decision Making",
        "authors": [
            "Fei Han",
            "Xue Yang",
            "Yu Zhang",
            "Hao Zhang"
        ],
        "abstract": "Apprenticeship learning has recently attracted a wide attention due to its capability of allowing robots to learn physical tasks directly from demonstrations provided by human experts. Most previous techniques assumed that the state space is known a priori or employed simple state representations that usually suffer from perceptual aliasing. Different from previous research, we propose a novel approach named Sequence-based Multimodal Apprenticeship Learning (SMAL), which is capable to simultaneously fusing temporal information and multimodal data, and to integrate robot perception with decision making. To evaluate the SMAL approach, experiments are performed using both simulations and real-world robots in the challenging search and rescue scenarios. The empirical study has validated that our SMAL approach can effectively learn plans for robots to make decisions using sequence of multimodal observations. Experimental results have also showed that SMAL outperforms the baseline methods using individual images.\n    ",
        "submission_date": "2017-02-24T00:00:00",
        "last_modified_date": "2017-02-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.07492",
        "title": "Robot gains Social Intelligence through Multimodal Deep Reinforcement Learning",
        "authors": [
            "Ahmed Hussain Qureshi",
            "Yutaka Nakamura",
            "Yuichiro Yoshikawa",
            "Hiroshi Ishiguro"
        ],
        "abstract": "For robots to coexist with humans in a social world like ours, it is crucial that they possess human-like social interaction skills. Programming a robot to possess such skills is a challenging task. In this paper, we propose a Multimodal Deep Q-Network (MDQN) to enable a robot to learn human-like interaction skills through a trial and error method. This paper aims to develop a robot that gathers data during its interaction with a human and learns human interaction behaviour from the high-dimensional sensory information using end-to-end reinforcement learning. This paper demonstrates that the robot was able to learn basic interaction skills successfully, after 14 days of interacting with people.\n    ",
        "submission_date": "2017-02-24T00:00:00",
        "last_modified_date": "2017-02-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.07784",
        "title": "Measuring #GamerGate: A Tale of Hate, Sexism, and Bullying",
        "authors": [
            "Despoina Chatzakou",
            "Nicolas Kourtellis",
            "Jeremy Blackburn",
            "Emiliano De Cristofaro",
            "Gianluca Stringhini",
            "Athena Vakali"
        ],
        "abstract": "Over the past few years, online aggression and abusive behaviors have occurred in many different forms and on a variety of platforms. In extreme cases, these incidents have evolved into hate, discrimination, and bullying, and even materialized into real-world threats and attacks against individuals or groups. In this paper, we study the Gamergate controversy. Started in August 2014 in the online gaming world, it quickly spread across various social networking platforms, ultimately leading to many incidents of cyberbullying and cyberaggression. We focus on Twitter, presenting a measurement study of a dataset of 340k unique users and 1.6M tweets to study the properties of these users, the content they post, and how they differ from random Twitter users. We find that users involved in this \"Twitter war\" tend to have more friends and followers, are generally more engaged and post tweets with negative sentiment, less joy, and more hate than random users. We also perform preliminary measurements on how the Twitter suspension mechanism deals with such abusive behaviors. While we focus on Gamergate, our methodology to collect and analyze tweets related to aggressive and bullying activities is of independent interest.\n    ",
        "submission_date": "2017-02-24T00:00:00",
        "last_modified_date": "2017-02-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.07889",
        "title": "Contractibility for Open Global Constraints",
        "authors": [
            "Michael J. Maher"
        ],
        "abstract": "Open forms of global constraints allow the addition of new variables to an argument during the execution of a constraint program. Such forms are needed for difficult constraint programming problems where problem construction and problem solving are interleaved, and fit naturally within constraint logic programming. However, in general, filtering that is sound for a global constraint can be unsound when the constraint is open. This paper provides a simple characterization, called contractibility, of the constraints where filtering remains sound when the constraint is open. With this characterization we can easily determine whether a constraint has this property or not. In the latter case, we can use it to derive a contractible approximation to the constraint. We demonstrate this work on both hard and soft constraints. In the process, we formulate two general classes of soft constraints.\n    ",
        "submission_date": "2017-02-25T00:00:00",
        "last_modified_date": "2017-02-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.07944",
        "title": "Stochastic Variance Reduction Methods for Policy Evaluation",
        "authors": [
            "Simon S. Du",
            "Jianshu Chen",
            "Lihong Li",
            "Lin Xiao",
            "Dengyong Zhou"
        ],
        "abstract": "Policy evaluation is a crucial step in many reinforcement-learning procedures, which estimates a value function that predicts states' long-term value under a given policy. In this paper, we focus on policy evaluation with linear function approximation over a fixed dataset. We first transform the empirical policy evaluation problem into a (quadratic) convex-concave saddle point problem, and then present a primal-dual batch gradient method, as well as two stochastic variance reduction methods for solving the problem. These algorithms scale linearly in both sample size and feature dimension. Moreover, they achieve linear convergence even when the saddle-point problem has only strong concavity in the dual variables but no strong convexity in the primal variables. Numerical experiments on benchmark problems demonstrate the effectiveness of our methods.\n    ",
        "submission_date": "2017-02-25T00:00:00",
        "last_modified_date": "2017-06-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.08165",
        "title": "Reinforcement Learning with Deep Energy-Based Policies",
        "authors": [
            "Tuomas Haarnoja",
            "Haoran Tang",
            "Pieter Abbeel",
            "Sergey Levine"
        ],
        "abstract": "We propose a method for learning expressive energy-based policies for continuous states and actions, which has been feasible only in tabular domains before. We apply our method to learning maximum entropy policies, resulting into a new algorithm, called soft Q-learning, that expresses the optimal policy via a Boltzmann distribution. We use the recently proposed amortized Stein variational gradient descent to learn a stochastic sampling network that approximates samples from this distribution. The benefits of the proposed algorithm include improved exploration and compositionality that allows transferring skills between tasks, which we confirm in simulated experiments with swimming and walking robots. We also draw a connection to actor-critic methods, which can be viewed performing approximate inference on the corresponding energy-based model.\n    ",
        "submission_date": "2017-02-27T00:00:00",
        "last_modified_date": "2017-07-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.08192",
        "title": "DeepNAT: Deep Convolutional Neural Network for Segmenting Neuroanatomy",
        "authors": [
            "Christian Wachinger",
            "Martin Reuter",
            "Tassilo Klein"
        ],
        "abstract": "We introduce DeepNAT, a 3D Deep convolutional neural network for the automatic segmentation of NeuroAnaTomy in T1-weighted magnetic resonance images. DeepNAT is an end-to-end learning-based approach to brain segmentation that jointly learns an abstract feature representation and a multi-class classification. We propose a 3D patch-based approach, where we do not only predict the center voxel of the patch but also neighbors, which is formulated as multi-task learning. To address a class imbalance problem, we arrange two networks hierarchically, where the first one separates foreground from background, and the second one identifies 25 brain structures on the foreground. Since patches lack spatial context, we augment them with coordinates. To this end, we introduce a novel intrinsic parameterization of the brain volume, formed by eigenfunctions of the Laplace-Beltrami operator. As network architecture, we use three convolutional layers with pooling, batch normalization, and non-linearities, followed by fully connected layers with dropout. The final segmentation is inferred from the probabilistic output of the network with a 3D fully connected conditional random field, which ensures label agreement between close voxels. The roughly 2.7 million parameters in the network are learned with stochastic gradient descent. Our results show that DeepNAT compares favorably to state-of-the-art methods. Finally, the purely learning-based method may have a high potential for the adaptation to young, old, or diseased brains by fine-tuning the pre-trained network with a small training sample on the target application, where the availability of larger datasets with manual annotations may boost the overall segmentation accuracy in the future.\n    ",
        "submission_date": "2017-02-27T00:00:00",
        "last_modified_date": "2017-02-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.08286",
        "title": "Balancing Lexicographic Fairness and a Utilitarian Objective with Application to Kidney Exchange",
        "authors": [
            "Duncan C. McElfresh",
            "John P. Dickerson"
        ],
        "abstract": "Balancing fairness and efficiency in resource allocation is a classical economic and computational problem. The price of fairness measures the worst-case loss of economic efficiency when using an inefficient but fair allocation rule; for indivisible goods in many settings, this price is unacceptably high. One such setting is kidney exchange, where needy patients swap willing but incompatible kidney donors. In this work, we close an open problem regarding the theoretical price of fairness in modern kidney exchanges. We then propose a general hybrid fairness rule that balances a strict lexicographic preference ordering over classes of agents, and a utilitarian objective that maximizes economic efficiency. We develop a utility function for this rule that favors disadvantaged groups lexicographically; but if cost to overall efficiency becomes too high, it switches to a utilitarian objective. This rule has only one parameter which is proportional to a bound on the price of fairness, and can be adjusted by policymakers. We apply this rule to real data from a large kidney exchange and show that our hybrid rule produces more reliable outcomes than other fairness rules.\n    ",
        "submission_date": "2017-02-27T00:00:00",
        "last_modified_date": "2017-09-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.08400",
        "title": "Asymmetric Tri-training for Unsupervised Domain Adaptation",
        "authors": [
            "Kuniaki Saito",
            "Yoshitaka Ushiku",
            "Tatsuya Harada"
        ],
        "abstract": "Deep-layered models trained on a large number of labeled samples boost the accuracy of many tasks. It is important to apply such models to different domains because collecting many labeled samples in various domains is expensive. In unsupervised domain adaptation, one needs to train a classifier that works well on a target domain when provided with labeled source samples and unlabeled target samples. Although many methods aim to match the distributions of source and target samples, simply matching the distribution cannot ensure accuracy on the target domain. To learn discriminative representations for the target domain, we assume that artificially labeling target samples can result in a good representation. Tri-training leverages three classifiers equally to give pseudo-labels to unlabeled samples, but the method does not assume labeling samples generated from a different ",
        "submission_date": "2017-02-27T00:00:00",
        "last_modified_date": "2017-05-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.08484",
        "title": "Boosted Generative Models",
        "authors": [
            "Aditya Grover",
            "Stefano Ermon"
        ],
        "abstract": "We propose a novel approach for using unsupervised boosting to create an ensemble of generative models, where models are trained in sequence to correct earlier mistakes. Our meta-algorithmic framework can leverage any existing base learner that permits likelihood evaluation, including recent deep expressive models. Further, our approach allows the ensemble to include discriminative models trained to distinguish real data from model-generated data. We show theoretical conditions under which incorporating a new model in the ensemble will improve the fit and empirically demonstrate the effectiveness of our black-box boosting algorithms on density estimation, classification, and sample generation on benchmark datasets for a wide range of generative models.\n    ",
        "submission_date": "2017-02-27T00:00:00",
        "last_modified_date": "2017-12-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.08567",
        "title": "Optimal Experiment Design for Causal Discovery from Fixed Number of Experiments",
        "authors": [
            "AmirEmad Ghassami",
            "Saber Salehkaleybar",
            "Negar Kiyavash"
        ],
        "abstract": "We study the problem of causal structure learning over a set of random variables when the experimenter is allowed to perform at most $M$ experiments in a non-adaptive manner. We consider the optimal learning strategy in terms of minimizing the portions of the structure that remains unknown given the limited number of experiments in both Bayesian and minimax setting. We characterize the theoretical optimal solution and propose an algorithm, which designs the experiments efficiently in terms of time complexity. We show that for bounded degree graphs, in the minimax case and in the Bayesian case with uniform priors, our proposed algorithm is a $\\rho$-approximation algorithm, where $\\rho$ is independent of the order of the underlying graph. Simulations on both synthetic and real data show that the performance of our algorithm is very close to the optimal solution.\n    ",
        "submission_date": "2017-02-27T00:00:00",
        "last_modified_date": "2017-02-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.08608",
        "title": "Towards A Rigorous Science of Interpretable Machine Learning",
        "authors": [
            "Finale Doshi-Velez",
            "Been Kim"
        ],
        "abstract": "As machine learning systems become ubiquitous, there has been a surge of interest in interpretable machine learning: systems that provide explanation for their outputs. These explanations are often used to qualitatively assess other criteria such as safety or non-discrimination. However, despite the interest in interpretability, there is very little consensus on what interpretable machine learning is and how it should be measured. In this position paper, we first define interpretability and describe when interpretability is needed (and when it is not). Next, we suggest a taxonomy for rigorous evaluation and expose open questions towards a more rigorous science of interpretable machine learning.\n    ",
        "submission_date": "2017-02-28T00:00:00",
        "last_modified_date": "2017-03-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.08626",
        "title": "Show, Attend and Interact: Perceivable Human-Robot Social Interaction through Neural Attention Q-Network",
        "authors": [
            "Ahmed Hussain Qureshi",
            "Yutaka Nakamura",
            "Yuichiro Yoshikawa",
            "Hiroshi Ishiguro"
        ],
        "abstract": "For a safe, natural and effective human-robot social interaction, it is essential to develop a system that allows a robot to demonstrate the perceivable responsive behaviors to complex human behaviors. We introduce the Multimodal Deep Attention Recurrent Q-Network using which the robot exhibits human-like social interaction skills after 14 days of interacting with people in an uncontrolled real world. Each and every day during the 14 days, the system gathered robot interaction experiences with people through a hit-and-trial method and then trained the MDARQN on these experiences using end-to-end reinforcement learning approach. The results of interaction based learning indicate that the robot has learned to respond to complex human behaviors in a perceivable and socially acceptable manner.\n    ",
        "submission_date": "2017-02-28T00:00:00",
        "last_modified_date": "2017-02-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.08628",
        "title": "Analysis of Agent Expertise in Ms. Pac-Man using Value-of-Information-based Policies",
        "authors": [
            "Isaac J. Sledge",
            "Jose C. Principe"
        ],
        "abstract": "Conventional reinforcement learning methods for Markov decision processes rely on weakly-guided, stochastic searches to drive the learning process. It can therefore be difficult to predict what agent behaviors might emerge. In this paper, we consider an information-theoretic cost function for performing constrained stochastic searches that promote the formation of risk-averse to risk-favoring behaviors. This cost function is the value of information, which provides the optimal trade-off between the expected return of a policy and the policy's complexity; policy complexity is measured by number of bits and controlled by a single hyperparameter on the cost function. As the policy complexity is reduced, the agents will increasingly eschew risky actions. This reduces the potential for high accrued rewards. As the policy complexity increases, the agents will take actions, regardless of the risk, that can raise the long-term rewards. The obtainable reward depends on a single, tunable hyperparameter that regulates the degree of policy complexity.\n",
        "submission_date": "2017-02-28T00:00:00",
        "last_modified_date": "2017-11-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.08635",
        "title": "Learning What Data to Learn",
        "authors": [
            "Yang Fan",
            "Fei Tian",
            "Tao Qin",
            "Jiang Bian",
            "Tie-Yan Liu"
        ],
        "abstract": "Machine learning is essentially the sciences of playing with data. An adaptive data selection strategy, enabling to dynamically choose different data at various training stages, can reach a more effective model in a more efficient way. In this paper, we propose a deep reinforcement learning framework, which we call \\emph{\\textbf{N}eural \\textbf{D}ata \\textbf{F}ilter} (\\textbf{NDF}), to explore automatic and adaptive data selection in the training process. In particular, NDF takes advantage of a deep neural network to adaptively select and filter important data instances from a sequential stream of training data, such that the future accumulative reward (e.g., the convergence speed) is maximized. In contrast to previous studies in data selection that is mainly based on heuristic strategies, NDF is quite generic and thus can be widely suitable for many machine learning tasks. Taking neural network training with stochastic gradient descent (SGD) as an example, comprehensive experiments with respect to various neural network modeling (e.g., multi-layer perceptron networks, convolutional neural networks and recurrent neural networks) and several applications (e.g., image classification and text understanding) demonstrate that NDF powered SGD can achieve comparable accuracy with standard SGD process by using less data and fewer iterations.\n    ",
        "submission_date": "2017-02-28T00:00:00",
        "last_modified_date": "2017-02-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.08690",
        "title": "Borrowing Treasures from the Wealthy: Deep Transfer Learning through Selective Joint Fine-tuning",
        "authors": [
            "Weifeng Ge",
            "Yizhou Yu"
        ],
        "abstract": "Deep neural networks require a large amount of labeled training data during supervised learning. However, collecting and labeling so much data might be infeasible in many cases. In this paper, we introduce a source-target selective joint fine-tuning scheme for improving the performance of deep learning tasks with insufficient training data. In this scheme, a target learning task with insufficient training data is carried out simultaneously with another source learning task with abundant training data. However, the source learning task does not use all existing training data. Our core idea is to identify and use a subset of training images from the original source learning task whose low-level characteristics are similar to those from the target learning task, and jointly fine-tune shared convolutional layers for both tasks. Specifically, we compute descriptors from linear or nonlinear filter bank responses on training images from both tasks, and use such descriptors to search for a desired subset of training samples for the source learning task.\n",
        "submission_date": "2017-02-28T00:00:00",
        "last_modified_date": "2017-06-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.08725",
        "title": "Bayesian Verification under Model Uncertainty",
        "authors": [
            "Lenz Belzner",
            "Thomas Gabor"
        ],
        "abstract": "Machine learning enables systems to build and update domain models based on runtime observations. In this paper, we study statistical model checking and runtime verification for systems with this ability. Two challenges arise: (1) Models built from limited runtime data yield uncertainty to be dealt with. (2) There is no definition of satisfaction w.r.t. uncertain hypotheses. We propose such a definition of subjective satisfaction based on recently introduced satisfaction functions. We also propose the BV algorithm as a Bayesian solution to runtime verification of subjective satisfaction under model uncertainty. BV provides user-definable stochastic bounds for type I and II errors. We discuss empirical results from an example application to illustrate our ideas.\n    ",
        "submission_date": "2017-02-28T00:00:00",
        "last_modified_date": "2017-02-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.08726",
        "title": "Stacked Thompson Bandits",
        "authors": [
            "Lenz Belzner",
            "Thomas Gabor"
        ],
        "abstract": "We introduce Stacked Thompson Bandits (STB) for efficiently generating plans that are likely to satisfy a given bounded temporal logic requirement. STB uses a simulation for evaluation of plans, and takes a Bayesian approach to using the resulting information to guide its search. In particular, we show that stacking multiarmed bandits and using Thompson sampling to guide the action selection process for each bandit enables STB to generate plans that satisfy requirements with a high probability while only searching a fraction of the search space.\n    ",
        "submission_date": "2017-02-28T00:00:00",
        "last_modified_date": "2017-02-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.08736",
        "title": "Analysing Congestion Problems in Multi-agent Reinforcement Learning",
        "authors": [
            "Roxana R\u0103dulescu",
            "Peter Vrancx",
            "Ann Now\u00e9"
        ],
        "abstract": "Congestion problems are omnipresent in today's complex networks and represent a challenge in many research domains. In the context of Multi-agent Reinforcement Learning (MARL), approaches like difference rewards and resource abstraction have shown promising results in tackling such problems. Resource abstraction was shown to be an ideal candidate for solving large-scale resource allocation problems in a fully decentralized manner. However, its performance and applicability strongly depends on some, until now, undocumented assumptions. Two of the main congestion benchmark problems considered in the literature are: the Beach Problem Domain and the Traffic Lane Domain. In both settings the highest system utility is achieved when overcrowding one resource and keeping the rest at optimum capacity. We analyse how abstract grouping can promote this behaviour and how feasible it is to apply this approach in a real-world domain (i.e., what assumptions need to be satisfied and what knowledge is necessary). We introduce a new test problem, the Road Network Domain (RND), where the resources are no longer independent, but rather part of a network (e.g., road network), thus choosing one path will also impact the load on other paths having common road segments. We demonstrate the application of state-of-the-art MARL methods for this new congestion model and analyse their performance. RND allows us to highlight an important limitation of resource abstraction and show that the difference rewards approach manages to better capture and inform the agents about the dynamics of the environment.\n    ",
        "submission_date": "2017-02-28T00:00:00",
        "last_modified_date": "2017-03-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.08791",
        "title": "Robust Budget Allocation via Continuous Submodular Functions",
        "authors": [
            "Matthew Staib",
            "Stefanie Jegelka"
        ],
        "abstract": "The optimal allocation of resources for maximizing influence, spread of information or coverage, has gained attention in the past years, in particular in machine learning and data mining. But in applications, the parameters of the problem are rarely known exactly, and using wrong parameters can lead to undesirable outcomes. We hence revisit a continuous version of the Budget Allocation or Bipartite Influence Maximization problem introduced by Alon et al. (2012) from a robust optimization perspective, where an adversary may choose the least favorable parameters within a confidence set. The resulting problem is a nonconvex-concave saddle point problem (or game). We show that this nonconvex problem can be solved exactly by leveraging connections to continuous submodular functions, and by solving a constrained submodular minimization problem. Although constrained submodular minimization is hard in general, here, we establish conditions under which such a problem can be solved to arbitrary precision $\\epsilon$.\n    ",
        "submission_date": "2017-02-28T00:00:00",
        "last_modified_date": "2017-06-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1702.08862",
        "title": "Proportional Representation in Vote Streams",
        "authors": [
            "Palash Dey",
            "Nimrod Talmon",
            "Otniel van Handel"
        ],
        "abstract": "We consider elections where the voters come one at a time, in a streaming fashion, and devise space-efficient algorithms which identify an approximate winning committee with respect to common multiwinner proportional representation voting rules; specifically, we consider the Approval-based and the Borda-based variants of both the Chamberlin-- ourant rule and the Monroe rule. We complement our algorithms with lower bounds. Somewhat surprisingly, our results imply that, using space which does not depend on the number of voters it is possible to efficiently identify an approximate representative committee of fixed size over vote streams with huge number of voters.\n    ",
        "submission_date": "2017-02-28T00:00:00",
        "last_modified_date": "2017-02-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.00048",
        "title": "Provably Optimal Algorithms for Generalized Linear Contextual Bandits",
        "authors": [
            "Lihong Li",
            "Yu Lu",
            "Dengyong Zhou"
        ],
        "abstract": "Contextual bandits are widely used in Internet services from news recommendation to advertising, and to Web search. Generalized linear models (logistical regression in particular) have demonstrated stronger performance than linear models in many applications where rewards are binary. However, most theoretical analyses on contextual bandits so far are on linear bandits. In this work, we propose an upper confidence bound based algorithm for generalized linear contextual bandits, which achieves an $\\tilde{O}(\\sqrt{dT})$ regret over $T$ rounds with $d$ dimensional feature vectors. This regret matches the minimax lower bound, up to logarithmic terms, and improves on the best previous result by a $\\sqrt{d}$ factor, assuming the number of arms is fixed. A key component in our analysis is to establish a new, sharp finite-sample confidence bound for maximum-likelihood estimates in generalized linear models, which may be of independent interest. We also analyze a simpler upper confidence bound algorithm, which is useful in practice, and prove it to have optimal regret for certain cases.\n    ",
        "submission_date": "2017-02-28T00:00:00",
        "last_modified_date": "2017-06-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.00099",
        "title": "Learning Conversational Systems that Interleave Task and Non-Task Content",
        "authors": [
            "Zhou Yu",
            "Alan W Black",
            "Alexander I. Rudnicky"
        ],
        "abstract": "Task-oriented dialog systems have been applied in various tasks, such as automated personal assistants, customer service providers and tutors. These systems work well when users have clear and explicit intentions that are well-aligned to the systems' capabilities. However, they fail if users intentions are not explicit. To address this shortcoming, we propose a framework to interleave non-task content (i.e. everyday social conversation) into task conversations. When the task content fails, the system can still keep the user engaged with the non-task content. We trained a policy using reinforcement learning algorithms to promote long-turn conversation coherence and consistency, so that the system can have smooth transitions between task and non-task content. To test the effectiveness of the proposed framework, we developed a movie promotion dialog system. Experiments with human users indicate that a system that interleaves social and task content achieves a better task success rate and is also rated as more engaging compared to a pure task-oriented system.\n    ",
        "submission_date": "2017-03-01T00:00:00",
        "last_modified_date": "2017-03-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.00317",
        "title": "Tracing Linguistic Relations in Winning and Losing Sides of Explicit Opposing Groups",
        "authors": [
            "Ceyda Sanli",
            "Anupam Mondal",
            "Erik Cambria"
        ],
        "abstract": "Linguistic relations in oral conversations present how opinions are constructed and developed in a restricted time. The relations bond ideas, arguments, thoughts, and feelings, re-shape them during a speech, and finally build knowledge out of all information provided in the conversation. Speakers share a common interest to discuss. It is expected that each speaker's reply includes duplicated forms of words from previous speakers. However, linguistic adaptation is observed and evolves in a more complex path than just transferring slightly modified versions of common concepts. A conversation aiming a benefit at the end shows an emergent cooperation inducing the adaptation. Not only cooperation, but also competition drives the adaptation or an opposite scenario and one can capture the dynamic process by tracking how the concepts are linguistically linked. To uncover salient complex dynamic events in verbal communications, we attempt to discover self-organized linguistic relations hidden in a conversation with explicitly stated winners and losers. We examine open access data of the United States Supreme Court. Our understanding is crucial in big data research to guide how transition states in opinion mining and decision-making should be modeled and how this required knowledge to guide the model should be pinpointed, by filtering large amount of data.\n    ",
        "submission_date": "2017-03-01T00:00:00",
        "last_modified_date": "2017-03-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.00320",
        "title": "Investigating the Characteristics of One-Sided Matching Mechanisms Under Various Preferences and Risk Attitudes",
        "authors": [
            "Hadi Hosseini",
            "Kate Larson",
            "Robin Cohen"
        ],
        "abstract": "One-sided matching mechanisms are fundamental for assigning a set of indivisible objects to a set of self-interested agents when monetary transfers are not allowed. Two widely-studied randomized mechanisms in multiagent settings are the Random Serial Dictatorship (RSD) and the Probabilistic Serial Rule (PS). Both mechanisms require only that agents specify ordinal preferences and have a number of desirable economic and computational properties. However, the induced outcomes of the mechanisms are often incomparable and thus there are challenges when it comes to deciding which mechanism to adopt in practice. In this paper, we first consider the space of general ordinal preferences and provide empirical results on the (in)comparability of RSD and PS. We analyze their respective economic properties under general and lexicographic preferences. We then instantiate utility functions with the goal of gaining insights on the manipulability, efficiency, and envyfreeness of the mechanisms under different risk-attitude models. Our results hold under various preference distribution models, which further confirm the broad use of RSD in most practical applications.\n    ",
        "submission_date": "2017-03-01T00:00:00",
        "last_modified_date": "2017-03-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.00352",
        "title": "Do Reichenbachian Common Cause Systems of Arbitrary Finite Size Exist?",
        "authors": [
            "Claudio Mazzola",
            "Peter Evans"
        ],
        "abstract": "The principle of common cause asserts that positive correlations between causally unrelated events ought to be explained through the action of some shared causal factors. Reichenbachian common cause systems are probabilistic structures aimed at accounting for cases where correlations of the aforesaid sort cannot be explained through the action of a single common cause. The existence of Reichenbachian common cause systems of arbitrary finite size for each pair of non-causally correlated events was allegedly demonstrated by Hofer-Szab\u00f3 and R\u00e9dei in 2006. This paper shows that their proof is logically deficient, and we propose an improved proof.\n    ",
        "submission_date": "2017-02-28T00:00:00",
        "last_modified_date": "2017-02-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.00381",
        "title": "The Statistical Recurrent Unit",
        "authors": [
            "Junier B. Oliva",
            "Barnabas Poczos",
            "Jeff Schneider"
        ],
        "abstract": "Sophisticated gated recurrent neural network architectures like LSTMs and GRUs have been shown to be highly effective in a myriad of applications. We develop an un-gated unit, the statistical recurrent unit (SRU), that is able to learn long term dependencies in data by only keeping moving averages of statistics. The SRU's architecture is simple, un-gated, and contains a comparable number of parameters to LSTMs; yet, SRUs perform favorably to more sophisticated LSTM and GRU alternatives, often outperforming one or both in various tasks. We show the efficacy of SRUs as compared to LSTMs and GRUs in an unbiased manner by optimizing respective architectures' hyperparameters in a Bayesian optimization scheme for both synthetic and real-world tasks.\n    ",
        "submission_date": "2017-03-01T00:00:00",
        "last_modified_date": "2017-03-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.00420",
        "title": "Virtual-to-real Deep Reinforcement Learning: Continuous Control of Mobile Robots for Mapless Navigation",
        "authors": [
            "Lei Tai",
            "Giuseppe Paolo",
            "Ming Liu"
        ],
        "abstract": "We present a learning-based mapless motion planner by taking the sparse 10-dimensional range findings and the target position with respect to the mobile robot coordinate frame as input and the continuous steering commands as output. Traditional motion planners for mobile ground robots with a laser range sensor mostly depend on the obstacle map of the navigation environment where both the highly precise laser sensor and the obstacle map building work of the environment are indispensable. We show that, through an asynchronous deep reinforcement learning method, a mapless motion planner can be trained end-to-end without any manually designed features and prior demonstrations. The trained planner can be directly applied in unseen virtual and real environments. The experiments show that the proposed mapless motion planner can navigate the nonholonomic mobile robot to the desired targets without colliding with any obstacles.\n    ",
        "submission_date": "2017-03-01T00:00:00",
        "last_modified_date": "2017-07-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.00440",
        "title": "Fast k-Nearest Neighbour Search via Prioritized DCI",
        "authors": [
            "Ke Li",
            "Jitendra Malik"
        ],
        "abstract": "Most exact methods for k-nearest neighbour search suffer from the curse of dimensionality; that is, their query times exhibit exponential dependence on either the ambient or the intrinsic dimensionality. Dynamic Continuous Indexing (DCI) offers a promising way of circumventing the curse and successfully reduces the dependence of query time on intrinsic dimensionality from exponential to sublinear. In this paper, we propose a variant of DCI, which we call Prioritized DCI, and show a remarkable improvement in the dependence of query time on intrinsic dimensionality. In particular, a linear increase in intrinsic dimensionality, or equivalently, an exponential increase in the number of points near a query, can be mostly counteracted with just a linear increase in space. We also demonstrate empirically that Prioritized DCI significantly outperforms prior methods. In particular, relative to Locality-Sensitive Hashing (LSH), Prioritized DCI reduces the number of distance evaluations by a factor of 14 to 116 and the memory consumption by a factor of 21.\n    ",
        "submission_date": "2017-03-01T00:00:00",
        "last_modified_date": "2017-07-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.00441",
        "title": "Learning to Optimize Neural Nets",
        "authors": [
            "Ke Li",
            "Jitendra Malik"
        ],
        "abstract": "Learning to Optimize is a recently proposed framework for learning optimization algorithms using reinforcement learning. In this paper, we explore learning an optimization algorithm for training shallow neural nets. Such high-dimensional stochastic optimization problems present interesting challenges for existing reinforcement learning algorithms. We develop an extension that is suited to learning optimization algorithms in this setting and demonstrate that the learned optimization algorithm consistently outperforms other known optimization algorithms even on unseen tasks and is robust to changes in stochasticity of gradients and the neural net architecture. More specifically, we show that an optimization algorithm trained with the proposed method on the problem of training a neural net on MNIST generalizes to the problems of training neural nets on the Toronto Faces Dataset, CIFAR-10 and CIFAR-100.\n    ",
        "submission_date": "2017-03-01T00:00:00",
        "last_modified_date": "2017-11-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.00443",
        "title": "OptNet: Differentiable Optimization as a Layer in Neural Networks",
        "authors": [
            "Brandon Amos",
            "J. Zico Kolter"
        ],
        "abstract": "This paper presents OptNet, a network architecture that integrates optimization problems (here, specifically in the form of quadratic programs) as individual layers in larger end-to-end trainable deep networks. These layers encode constraints and complex dependencies between the hidden states that traditional convolutional and fully-connected layers often cannot capture. We explore the foundations for such an architecture: we show how techniques from sensitivity analysis, bilevel optimization, and implicit differentiation can be used to exactly differentiate through these layers and with respect to layer parameters; we develop a highly efficient solver for these layers that exploits fast GPU-based batch solves within a primal-dual interior point method, and which provides backpropagation gradients with virtually no additional cost on top of the solve; and we highlight the application of these approaches in several problems. In one notable example, the method is learns to play mini-Sudoku (4x4) given just input and output games, with no a-priori information about the rules of the game; this highlights the ability of OptNet to learn hard constraints better than other neural architectures.\n    ",
        "submission_date": "2017-03-01T00:00:00",
        "last_modified_date": "2021-12-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.00484",
        "title": "Truth and Regret in Online Scheduling",
        "authors": [
            "Shuchi Chawla",
            "Nikhil Devanur",
            "Janardhan Kulkarni",
            "Rad Niazadeh"
        ],
        "abstract": "We consider a scheduling problem where a cloud service provider has multiple units of a resource available over time. Selfish clients submit jobs, each with an arrival time, deadline, length, and value. The service provider's goal is to implement a truthful online mechanism for scheduling jobs so as to maximize the social welfare of the schedule. Recent work shows that under a stochastic assumption on job arrivals, there is a single-parameter family of mechanisms that achieves near-optimal social welfare. We show that given any such family of near-optimal online mechanisms, there exists an online mechanism that in the worst case performs nearly as well as the best of the given mechanisms. Our mechanism is truthful whenever the mechanisms in the given family are truthful and prompt, and achieves optimal (within constant factors) regret.\n",
        "submission_date": "2017-03-01T00:00:00",
        "last_modified_date": "2017-03-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.00503",
        "title": "Learning Social Affordance Grammar from Videos: Transferring Human Interactions to Human-Robot Interactions",
        "authors": [
            "Tianmin Shu",
            "Xiaofeng Gao",
            "Michael S. Ryoo",
            "Song-Chun Zhu"
        ],
        "abstract": "In this paper, we present a general framework for learning social affordance grammar as a spatiotemporal AND-OR graph (ST-AOG) from RGB-D videos of human interactions, and transfer the grammar to humanoids to enable a real-time motion inference for human-robot interaction (HRI). Based on Gibbs sampling, our weakly supervised grammar learning can automatically construct a hierarchical representation of an interaction with long-term joint sub-tasks of both agents and short term atomic actions of individual agents. Based on a new RGB-D video dataset with rich instances of human interactions, our experiments of Baxter simulation, human evaluation, and real Baxter test demonstrate that the model learned from limited training data successfully generates human-like behaviors in unseen scenarios and outperforms both baselines.\n    ",
        "submission_date": "2017-03-01T00:00:00",
        "last_modified_date": "2017-03-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.00512",
        "title": "PMLB: A Large Benchmark Suite for Machine Learning Evaluation and Comparison",
        "authors": [
            "Randal S. Olson",
            "William La Cava",
            "Patryk Orzechowski",
            "Ryan J. Urbanowicz",
            "Jason H. Moore"
        ],
        "abstract": "The selection, development, or comparison of machine learning methods in data mining can be a difficult task based on the target problem and goals of a particular study. Numerous publicly available real-world and simulated benchmark datasets have emerged from different sources, but their organization and adoption as standards have been inconsistent. As such, selecting and curating specific benchmarks remains an unnecessary burden on machine learning practitioners and data scientists. The present study introduces an accessible, curated, and developing public benchmark resource to facilitate identification of the strengths and weaknesses of different machine learning methodologies. We compare meta-features among the current set of benchmark datasets in this resource to characterize the diversity of available data. Finally, we apply a number of established machine learning methods to the entire benchmark suite and analyze how datasets and algorithms cluster in terms of performance. This work is an important first step towards understanding the limitations of popular benchmarking suites and developing a resource that connects existing benchmarking standards to more diverse and efficient standards in the future.\n    ",
        "submission_date": "2017-03-01T00:00:00",
        "last_modified_date": "2017-03-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.00548",
        "title": "Evolving Deep Neural Networks",
        "authors": [
            "Risto Miikkulainen",
            "Jason Liang",
            "Elliot Meyerson",
            "Aditya Rawal",
            "Dan Fink",
            "Olivier Francon",
            "Bala Raju",
            "Hormoz Shahrzad",
            "Arshak Navruzyan",
            "Nigel Duffy",
            "Babak Hodjat"
        ],
        "abstract": "The success of deep learning depends on finding an architecture to fit the task. As deep learning has scaled up to more challenging tasks, the architectures have become difficult to design by hand. This paper proposes an automated method, CoDeepNEAT, for optimizing deep learning architectures through evolution. By extending existing neuroevolution methods to topology, components, and hyperparameters, this method achieves results comparable to best human designs in standard benchmarks in object recognition and language modeling. It also supports building a real-world application of automated image captioning on a magazine website. Given the anticipated increases in available computing power, evolution of deep networks is promising approach to constructing deep learning applications in the future.\n    ",
        "submission_date": "2017-03-01T00:00:00",
        "last_modified_date": "2017-03-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.00556",
        "title": "Conversion Rate Optimization through Evolutionary Computation",
        "authors": [
            "Risto Miikkulainen",
            "Neil Iscoe",
            "Aaron Shagrin",
            "Ron Cordell",
            "Sam Nazari",
            "Cory Schoolland",
            "Myles Brundage",
            "Jonathan Epstein",
            "Randy Dean",
            "Gurmeet Lamba"
        ],
        "abstract": "Conversion optimization means designing a web interface so that as many users as possible take a desired action on it, such as register or purchase. Such design is usually done by hand, testing one change at a time through A/B testing, or a limited number of combinations through multivariate testing, making it possible to evaluate only a small fraction of designs in a vast design space. This paper describes Sentient Ascend, an automatic conversion optimization system that uses evolutionary optimization to create effective web interface designs. Ascend makes it possible to discover and utilize interactions between the design elements that are difficult to identify otherwise. Moreover, evaluation of design candidates is done in parallel online, i.e. with a large number of real users interacting with the system. A case study on an existing media site shows that significant improvements (i.e. over 43%) are possible beyond human design. Ascend can therefore be seen as an approach to massively multivariate conversion optimization, based on a massively parallel interactive evolution.\n    ",
        "submission_date": "2017-03-01T00:00:00",
        "last_modified_date": "2017-04-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.00848",
        "title": "Unsupervised Image-to-Image Translation Networks",
        "authors": [
            "Ming-Yu Liu",
            "Thomas Breuel",
            "Jan Kautz"
        ],
        "abstract": "Unsupervised image-to-image translation aims at learning a joint distribution of images in different domains by using images from the marginal distributions in individual domains. Since there exists an infinite set of joint distributions that can arrive the given marginal distributions, one could infer nothing about the joint distribution from the marginal distributions without additional assumptions. To address the problem, we make a shared-latent space assumption and propose an unsupervised image-to-image translation framework based on Coupled GANs. We compare the proposed framework with competing approaches and present high quality image translation results on various challenging unsupervised image translation tasks, including street scene image translation, animal image translation, and face image translation. We also apply the proposed framework to domain adaptation and achieve state-of-the-art performance on benchmark datasets. Code and additional results are available in ",
        "submission_date": "2017-03-02T00:00:00",
        "last_modified_date": "2018-07-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.00948",
        "title": "DAWT: Densely Annotated Wikipedia Texts across multiple languages",
        "authors": [
            "Nemanja Spasojevic",
            "Preeti Bhargava",
            "Guoning Hu"
        ],
        "abstract": "In this work, we open up the DAWT dataset - Densely Annotated Wikipedia Texts across multiple languages. The annotations include labeled text mentions mapping to entities (represented by their Freebase machine ids) as well as the type of the entity. The data set contains total of 13.6M articles, 5.0B tokens, 13.8M mention entity co-occurrences. DAWT contains 4.8 times more anchor text to entity links than originally present in the Wikipedia markup. Moreover, it spans several languages including English, Spanish, Italian, German, French and Arabic. We also present the methodology used to generate the dataset which enriches Wikipedia markup in order to increase number of links. In addition to the main dataset, we open up several derived datasets including mention entity co-occurrence counts and entity embeddings, as well as mappings between Freebase ids and Wikidata item ids. We also discuss two applications of these datasets and hope that opening them up would prove useful for the Natural Language Processing and Information Retrieval communities, as well as facilitate multi-lingual research.\n    ",
        "submission_date": "2017-03-02T00:00:00",
        "last_modified_date": "2017-03-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.00955",
        "title": "Toward Controlled Generation of Text",
        "authors": [
            "Zhiting Hu",
            "Zichao Yang",
            "Xiaodan Liang",
            "Ruslan Salakhutdinov",
            "Eric P. Xing"
        ],
        "abstract": "Generic generation and manipulation of text is challenging and has limited success compared to recent deep generative modeling in visual domain. This paper aims at generating plausible natural language sentences, whose attributes are dynamically controlled by learning disentangled latent representations with designated semantics. We propose a new neural generative model which combines variational auto-encoders and holistic attribute discriminators for effective imposition of semantic structures. With differentiable approximation to discrete text samples, explicit constraints on independent attribute controls, and efficient collaborative learning of generator and discriminators, our model learns highly interpretable representations from even only word annotations, and produces realistic sentences with desired attributes. Quantitative evaluation validates the accuracy of sentence and attribute generation.\n    ",
        "submission_date": "2017-03-02T00:00:00",
        "last_modified_date": "2018-09-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.00956",
        "title": "A Laplacian Framework for Option Discovery in Reinforcement Learning",
        "authors": [
            "Marlos C. Machado",
            "Marc G. Bellemare",
            "Michael Bowling"
        ],
        "abstract": "Representation learning and option discovery are two of the biggest challenges in reinforcement learning (RL). Proto-value functions (PVFs) are a well-known approach for representation learning in MDPs. In this paper we address the option discovery problem by showing how PVFs implicitly define options. We do it by introducing eigenpurposes, intrinsic reward functions derived from the learned representations. The options discovered from eigenpurposes traverse the principal directions of the state space. They are useful for multiple tasks because they are discovered without taking the environment's rewards into consideration. Moreover, different options act at different time scales, making them helpful for exploration. We demonstrate features of eigenpurposes in traditional tabular domains as well as in Atari 2600 games.\n    ",
        "submission_date": "2017-03-02T00:00:00",
        "last_modified_date": "2017-06-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.01008",
        "title": "End-to-End Task-Completion Neural Dialogue Systems",
        "authors": [
            "Xiujun Li",
            "Yun-Nung Chen",
            "Lihong Li",
            "Jianfeng Gao",
            "Asli Celikyilmaz"
        ],
        "abstract": "One of the major drawbacks of modularized task-completion dialogue systems is that each module is trained individually, which presents several challenges. For example, downstream modules are affected by earlier modules, and the performance of the entire system is not robust to the accumulated errors. This paper presents a novel end-to-end learning framework for task-completion dialogue systems to tackle such issues. Our neural dialogue system can directly interact with a structured database to assist users in accessing information and accomplishing certain tasks. The reinforcement learning based dialogue manager offers robust capabilities to handle noises caused by other components of the dialogue system. Our experiments in a movie-ticket booking domain show that our end-to-end system not only outperforms modularized dialogue system baselines for both objective and subjective evaluation, but also is robust to noises as demonstrated by several systematic experiments with different error granularity and rates specific to the language understanding module.\n    ",
        "submission_date": "2017-03-03T00:00:00",
        "last_modified_date": "2018-02-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.01040",
        "title": "Learning Robot Activities from First-Person Human Videos Using Convolutional Future Regression",
        "authors": [
            "Jangwon Lee",
            "Michael S. Ryoo"
        ],
        "abstract": "We design a new approach that allows robot learning of new activities from unlabeled human example videos. Given videos of humans executing the same activity from a human's viewpoint (i.e., first-person videos), our objective is to make the robot learn the temporal structure of the activity as its future regression network, and learn to transfer such model for its own motor execution. We present a new deep learning model: We extend the state-of-the-art convolutional object detection network for the representation/estimation of human hands in training videos, and newly introduce the concept of using a fully convolutional network to regress (i.e., predict) the intermediate scene representation corresponding to the future frame (e.g., 1-2 seconds later). Combining these allows direct prediction of future locations of human hands and objects, which enables the robot to infer the motor control plan using our manipulation network. We experimentally confirm that our approach makes learning of robot activities from unlabeled human interaction videos possible, and demonstrate that our robot is able to execute the learned collaborative activities in real-time directly based on its camera input.\n    ",
        "submission_date": "2017-03-03T00:00:00",
        "last_modified_date": "2017-07-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.01041",
        "title": "Large-Scale Evolution of Image Classifiers",
        "authors": [
            "Esteban Real",
            "Sherry Moore",
            "Andrew Selle",
            "Saurabh Saxena",
            "Yutaka Leon Suematsu",
            "Jie Tan",
            "Quoc Le",
            "Alex Kurakin"
        ],
        "abstract": "Neural networks have proven effective at solving difficult problems but designing their architectures can be challenging, even for image classification problems alone. Our goal is to minimize human participation, so we employ evolutionary algorithms to discover such networks automatically. Despite significant computational requirements, we show that it is now possible to evolve models with accuracies within the range of those published in the last year. Specifically, we employ simple evolutionary techniques at unprecedented scales to discover models for the CIFAR-10 and CIFAR-100 datasets, starting from trivial initial conditions and reaching accuracies of 94.6% (95.6% for ensemble) and 77.0%, respectively. To do this, we use novel and intuitive mutation operators that navigate large search spaces; we stress that no human participation is required once evolution starts and that the output is a fully-trained model. Throughout this work, we place special emphasis on the repeatability of results, the variability in the outcomes and the computational requirements.\n    ",
        "submission_date": "2017-03-03T00:00:00",
        "last_modified_date": "2017-06-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.01127",
        "title": "On the Behavior of Convolutional Nets for Feature Extraction",
        "authors": [
            "Dario Garcia-Gasulla",
            "Ferran Par\u00e9s",
            "Armand Vilalta",
            "Jonatan Moreno",
            "Eduard Ayguad\u00e9",
            "Jes\u00fas Labarta",
            "Ulises Cort\u00e9s",
            "Toyotaro Suzumura"
        ],
        "abstract": "Deep neural networks are representation learning techniques. During training, a deep net is capable of generating a descriptive language of unprecedented size and detail in machine learning. Extracting the descriptive language coded within a trained CNN model (in the case of image data), and reusing it for other purposes is a field of interest, as it provides access to the visual descriptors previously learnt by the CNN after processing millions of images, without requiring an expensive training phase. Contributions to this field (commonly known as feature representation transfer or transfer learning) have been purely empirical so far, extracting all CNN features from a single layer close to the output and testing their performance by feeding them to a classifier. This approach has provided consistent results, although its relevance is limited to classification tasks. In a completely different approach, in this paper we statistically measure the discriminative power of every single feature found within a deep CNN, when used for characterizing every class of 11 datasets. We seek to provide new insights into the behavior of CNN features, particularly the ones from convolutional layers, as this can be relevant for their application to knowledge representation and reasoning. Our results confirm that low and middle level features may behave differently to high level features, but only under certain conditions. We find that all CNN features can be used for knowledge representation purposes both by their presence or by their absence, doubling the information a single CNN feature may provide. We also study how much noise these features may include, and propose a thresholding approach to discard most of it. All these insights have a direct application to the generation of CNN embedding spaces.\n    ",
        "submission_date": "2017-03-03T00:00:00",
        "last_modified_date": "2018-01-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.01203",
        "title": "Stochastic Separation Theorems",
        "authors": [
            "A.N. Gorban",
            "I.Y. Tyukin"
        ],
        "abstract": "The problem of non-iterative one-shot and non-destructive correction of unavoidable mistakes arises in all Artificial Intelligence applications in the real world. Its solution requires robust separation of samples with errors from samples where the system works properly. We demonstrate that in (moderately) high dimension this separation could be achieved with probability close to one by linear discriminants. Surprisingly, separation of a new image from a very large set of known images is almost always possible even in moderately high dimensions by linear functionals, and coefficients of these functionals can be found explicitly. Based on fundamental properties of measure concentration, we show that for $M<a\\exp(b{n})$ random $M$-element sets in $\\mathbb{R}^n$ are linearly separable with probability $p$, $p>1-\\vartheta$, where $1>\\vartheta>0$ is a given small constant. Exact values of $a,b>0$ depend on the probability distribution that determines how the random $M$-element sets are drawn, and on the constant $\\vartheta$. These {\\em stochastic separation theorems} provide a new instrument for the development, analysis, and assessment of machine learning methods and algorithms in high dimension. Theoretical statements are illustrated with numerical examples.\n    ",
        "submission_date": "2017-03-03T00:00:00",
        "last_modified_date": "2017-08-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.01398",
        "title": "Sparse Depth Sensing for Resource-Constrained Robots",
        "authors": [
            "Fangchang Ma",
            "Luca Carlone",
            "Ulas Ayaz",
            "Sertac Karaman"
        ],
        "abstract": "We consider the case in which a robot has to navigate in an unknown environment but does not have enough on-board power or payload to carry a traditional depth sensor (e.g., a 3D lidar) and thus can only acquire a few (point-wise) depth measurements. We address the following question: is it possible to reconstruct the geometry of an unknown environment using sparse and incomplete depth measurements? Reconstruction from incomplete data is not possible in general, but when the robot operates in man-made environments, the depth exhibits some regularity (e.g., many planar surfaces with only a few edges); we leverage this regularity to infer depth from a small number of measurements. Our first contribution is a formulation of the depth reconstruction problem that bridges robot perception with the compressive sensing literature in signal processing. The second contribution includes a set of formal results that ascertain the exactness and stability of the depth reconstruction in 2D and 3D problems, and completely characterize the geometry of the profiles that we can reconstruct. Our third contribution is a set of practical algorithms for depth reconstruction: our formulation directly translates into algorithms for depth estimation based on convex programming. In real-world problems, these convex programs are very large and general-purpose solvers are relatively slow. For this reason, we discuss ad-hoc solvers that enable fast depth reconstruction in real problems. The last contribution is an extensive experimental evaluation in 2D and 3D problems, including Monte Carlo runs on simulated instances and testing on multiple real datasets. Empirical results confirm that the proposed approach ensures accurate depth reconstruction, outperforms interpolation-based strategies, and performs well even when the assumption of structured environment is violated.\n    ",
        "submission_date": "2017-03-04T00:00:00",
        "last_modified_date": "2017-10-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.01720",
        "title": "Sound-Word2Vec: Learning Word Representations Grounded in Sounds",
        "authors": [
            "Ashwin K Vijayakumar",
            "Ramakrishna Vedantam",
            "Devi Parikh"
        ],
        "abstract": "To be able to interact better with humans, it is crucial for machines to understand sound - a primary modality of human perception. Previous works have used sound to learn embeddings for improved generic textual similarity assessment. In this work, we treat sound as a first-class citizen, studying downstream textual tasks which require aural grounding. To this end, we propose sound-word2vec - a new embedding scheme that learns specialized word embeddings grounded in sounds. For example, we learn that two seemingly (semantically) unrelated concepts, like leaves and paper are similar due to the similar rustling sounds they make. Our embeddings prove useful in textual tasks requiring aural reasoning like text-based sound retrieval and discovering foley sound effects (used in movies). Moreover, our embedding space captures interesting dependencies between words and onomatopoeia and outperforms prior work on aurally-relevant word relatedness datasets such as AMEN and ASLex.\n    ",
        "submission_date": "2017-03-06T00:00:00",
        "last_modified_date": "2017-08-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.01918",
        "title": "High-Resolution Multispectral Dataset for Semantic Segmentation",
        "authors": [
            "Ronald Kemker",
            "Carl Salvaggio",
            "Christopher Kanan"
        ],
        "abstract": "Unmanned aircraft have decreased the cost required to collect remote sensing imagery, which has enabled researchers to collect high-spatial resolution data from multiple sensor modalities more frequently and easily. The increase in data will push the need for semantic segmentation frameworks that are able to classify non-RGB imagery, but this type of algorithmic development requires an increase in publicly available benchmark datasets with class labels. In this paper, we introduce a high-resolution multispectral dataset with image labels. This new benchmark dataset has been pre-split into training/testing folds in order to standardize evaluation and continue to push state-of-the-art classification frameworks for non-RGB imagery.\n    ",
        "submission_date": "2017-03-06T00:00:00",
        "last_modified_date": "2017-03-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.01946",
        "title": "Metric Learning for Generalizing Spatial Relations to New Objects",
        "authors": [
            "Oier Mees",
            "Nichola Abdo",
            "Mladen Mazuran",
            "Wolfram Burgard"
        ],
        "abstract": "Human-centered environments are rich with a wide variety of spatial relations between everyday objects. For autonomous robots to operate effectively in such environments, they should be able to reason about these relations and generalize them to objects with different shapes and sizes. For example, having learned to place a toy inside a basket, a robot should be able to generalize this concept using a spoon and a cup. This requires a robot to have the flexibility to learn arbitrary relations in a lifelong manner, making it challenging for an expert to pre-program it with sufficient knowledge to do so beforehand. In this paper, we address the problem of learning spatial relations by introducing a novel method from the perspective of distance metric learning. Our approach enables a robot to reason about the similarity between pairwise spatial relations, thereby enabling it to use its previous knowledge when presented with a new relation to imitate. We show how this makes it possible to learn arbitrary spatial relations from non-expert users using a small number of examples and in an interactive manner. Our extensive evaluation with real-world data demonstrates the effectiveness of our method in reasoning about a continuous spectrum of spatial relations and generalizing them to new objects.\n    ",
        "submission_date": "2017-03-06T00:00:00",
        "last_modified_date": "2017-07-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.02000",
        "title": "Activation Maximization Generative Adversarial Nets",
        "authors": [
            "Zhiming Zhou",
            "Han Cai",
            "Shu Rong",
            "Yuxuan Song",
            "Kan Ren",
            "Weinan Zhang",
            "Yong Yu",
            "Jun Wang"
        ],
        "abstract": "Class labels have been empirically shown useful in improving the sample quality of generative adversarial nets (GANs). In this paper, we mathematically study the properties of the current variants of GANs that make use of class label information. With class aware gradient and cross-entropy decomposition, we reveal how class labels and associated losses influence GAN's training. Based on that, we propose Activation Maximization Generative Adversarial Networks (AM-GAN) as an advanced solution. Comprehensive experiments have been conducted to validate our analysis and evaluate the effectiveness of our solution, where AM-GAN outperforms other strong baselines and achieves state-of-the-art Inception Score (8.91) on CIFAR-10. In addition, we demonstrate that, with the Inception ImageNet classifier, Inception Score mainly tracks the diversity of the generator, and there is, however, no reliable evidence that it can reflect the true sample quality. We thus propose a new metric, called AM Score, to provide a more accurate estimation of the sample quality. Our proposed model also outperforms the baseline methods in the new metric.\n    ",
        "submission_date": "2017-03-06T00:00:00",
        "last_modified_date": "2018-11-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.02100",
        "title": "Guarantees for Greedy Maximization of Non-submodular Functions with Applications",
        "authors": [
            "Andrew An Bian",
            "Joachim M. Buhmann",
            "Andreas Krause",
            "Sebastian Tschiatschek"
        ],
        "abstract": "We investigate the performance of the standard Greedy algorithm for cardinality constrained maximization of non-submodular nondecreasing set functions. While there are strong theoretical guarantees on the performance of Greedy for maximizing submodular functions, there are few guarantees for non-submodular ones. However, Greedy enjoys strong empirical performance for many important non-submodular functions, e.g., the Bayesian A-optimality objective in experimental design. We prove theoretical guarantees supporting the empirical performance. Our guarantees are characterized by a combination of the (generalized) curvature $\\alpha$ and the submodularity ratio $\\gamma$. In particular, we prove that Greedy enjoys a tight approximation guarantee of $\\frac{1}{\\alpha}(1- e^{-\\gamma\\alpha})$ for cardinality constrained maximization. In addition, we bound the submodularity ratio and curvature for several important real-world objectives, including the Bayesian A-optimality objective, the determinantal function of a square submatrix and certain linear programs with combinatorial constraints. We experimentally validate our theoretical findings for both synthetic and real-world applications.\n    ",
        "submission_date": "2017-03-06T00:00:00",
        "last_modified_date": "2019-05-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.02156",
        "title": "On the Limits of Learning Representations with Label-Based Supervision",
        "authors": [
            "Jiaming Song",
            "Russell Stewart",
            "Shengjia Zhao",
            "Stefano Ermon"
        ],
        "abstract": "Advances in neural network based classifiers have transformed automatic feature learning from a pipe dream of stronger AI to a routine and expected property of practical systems. Since the emergence of AlexNet every winning submission of the ImageNet challenge has employed end-to-end representation learning, and due to the utility of good representations for transfer learning, representation learning has become as an important and distinct task from supervised learning. At present, this distinction is inconsequential, as supervised methods are state-of-the-art in learning transferable representations. But recent work has shown that generative models can also be powerful agents of representation learning. Will the representations learned from these generative methods ever rival the quality of those from their supervised competitors? In this work, we argue in the affirmative, that from an information theoretic perspective, generative models have greater potential for representation learning. Based on several experimentally validated assumptions, we show that supervised learning is upper bounded in its capacity for representation learning in ways that certain generative models, such as Generative Adversarial Networks (GANs) are not. We hope that our analysis will provide a rigorous motivation for further exploration of generative representation learning.\n    ",
        "submission_date": "2017-03-07T00:00:00",
        "last_modified_date": "2017-03-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.02507",
        "title": "Unsupervised Learning of Sentence Embeddings using Compositional n-Gram Features",
        "authors": [
            "Matteo Pagliardini",
            "Prakhar Gupta",
            "Martin Jaggi"
        ],
        "abstract": "The recent tremendous success of unsupervised word embeddings in a multitude of applications raises the obvious question if similar methods could be derived to improve embeddings (i.e. semantic representations) of word sequences as well. We present a simple but efficient unsupervised objective to train distributed representations of sentences. Our method outperforms the state-of-the-art unsupervised models on most benchmark tasks, highlighting the robustness of the produced general-purpose sentence embeddings.\n    ",
        "submission_date": "2017-03-07T00:00:00",
        "last_modified_date": "2018-12-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.02610",
        "title": "Multi-Robot Active Information Gathering with Periodic Communication",
        "authors": [
            "Mikko Lauri",
            "Eero Hein\u00e4nen",
            "Simone Frintrop"
        ],
        "abstract": "A team of robots sharing a common goal can benefit from coordination of the activities of team members, helping the team to reach the goal more reliably or quickly. We address the problem of coordinating the actions of a team of robots with periodic communication capability executing an information gathering task. We cast the problem as a multi-agent optimal decision-making problem with an information theoretic objective function. We show that appropriate techniques for solving decentralized partially observable Markov decision processes (Dec-POMDPs) are applicable in such information gathering problems. We quantify the usefulness of coordinated information gathering through simulation studies, and demonstrate the feasibility of the method in a real-world target tracking domain.\n    ",
        "submission_date": "2017-03-07T00:00:00",
        "last_modified_date": "2017-03-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.02660",
        "title": "Towards Generalization and Simplicity in Continuous Control",
        "authors": [
            "Aravind Rajeswaran",
            "Kendall Lowrey",
            "Emanuel Todorov",
            "Sham Kakade"
        ],
        "abstract": "This work shows that policies with simple linear and RBF parameterizations can be trained to solve a variety of continuous control tasks, including the OpenAI gym benchmarks. The performance of these trained policies are competitive with state of the art results, obtained with more elaborate parameterizations such as fully connected neural networks. Furthermore, existing training and testing scenarios are shown to be very limited and prone to over-fitting, thus giving rise to only trajectory-centric policies. Training with a diverse initial state distribution is shown to produce more global policies with better generalization. This allows for interactive control scenarios where the system recovers from large on-line perturbations; as shown in the supplementary video.\n    ",
        "submission_date": "2017-03-08T00:00:00",
        "last_modified_date": "2018-03-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.02702",
        "title": "Robust Adversarial Reinforcement Learning",
        "authors": [
            "Lerrel Pinto",
            "James Davidson",
            "Rahul Sukthankar",
            "Abhinav Gupta"
        ],
        "abstract": "Deep neural networks coupled with fast simulation and improved computation have led to recent successes in the field of reinforcement learning (RL). However, most current RL-based approaches fail to generalize since: (a) the gap between simulation and real world is so large that policy-learning approaches fail to transfer; (b) even if policy learning is done in real world, the data scarcity leads to failed generalization from training to test scenarios (e.g., due to different friction or object masses). Inspired from H-infinity control methods, we note that both modeling errors and differences in training and test scenarios can be viewed as extra forces/disturbances in the system. This paper proposes the idea of robust adversarial reinforcement learning (RARL), where we train an agent to operate in the presence of a destabilizing adversary that applies disturbance forces to the system. The jointly trained adversary is reinforced -- that is, it learns an optimal destabilization policy. We formulate the policy learning as a zero-sum, minimax objective function. Extensive experiments in multiple environments (InvertedPendulum, HalfCheetah, Swimmer, Hopper and Walker2d) conclusively demonstrate that our method (a) improves training stability; (b) is robust to differences in training/test conditions; and c) outperform the baseline even in the absence of the adversary.\n    ",
        "submission_date": "2017-03-08T00:00:00",
        "last_modified_date": "2017-03-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.02819",
        "title": "Introduction to Formal Concept Analysis and Its Applications in Information Retrieval and Related Fields",
        "authors": [
            "Dmitry I. Ignatov"
        ],
        "abstract": "This paper is a tutorial on Formal Concept Analysis (FCA) and its applications. FCA is an applied branch of Lattice Theory, a mathematical discipline which enables formalisation of concepts as basic units of human thinking and analysing data in the object-attribute form. Originated in early 80s, during the last three decades, it became a popular human-centred tool for knowledge representation and data analysis with numerous applications. Since the tutorial was specially prepared for RuSSIR 2014, the covered FCA topics include Information Retrieval with a focus on visualisation aspects, Machine Learning, Data Mining and Knowledge Discovery, Text Mining and several others.\n    ",
        "submission_date": "2017-03-08T00:00:00",
        "last_modified_date": "2017-03-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.02905",
        "title": "Learning a Unified Control Policy for Safe Falling",
        "authors": [
            "Visak CV Kumar",
            "Sehoon Ha",
            "C Karen Liu"
        ],
        "abstract": "Being able to fall safely is a necessary motor skill for humanoids performing highly dynamic tasks, such as running and jumping. We propose a new method to learn a policy that minimizes the maximal impulse during the fall. The optimization solves for both a discrete contact planning problem and a continuous optimal control problem. Once trained, the policy can compute the optimal next contacting body part (e.g. left foot, right foot, or hands), contact location and timing, and the required joint actuation. We represent the policy as a mixture of actor-critic neural network, which consists of n control policies and the corresponding value functions. Each pair of actor-critic is associated with one of the n possible contacting body parts. During execution, the policy corresponding to the highest value function will be executed while the associated body part will be the next contact with the ground. With this mixture of actor-critic architecture, the discrete contact sequence planning is solved through the selection of the best critics while the continuous control problem is solved by the optimization of actors. We show that our policy can achieve comparable, sometimes even higher, rewards than a recursive search of the action space using dynamic programming, while enjoying 50 to 400 times of speed gain during online execution.\n    ",
        "submission_date": "2017-03-08T00:00:00",
        "last_modified_date": "2017-04-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.03041",
        "title": "Combining Bayesian Approaches and Evolutionary Techniques for the Inference of Breast Cancer Networks",
        "authors": [
            "Stefano Beretta",
            "Mauro Castelli",
            "Ivo Goncalves",
            "Ivan Merelli",
            "Daniele Ramazzotti"
        ],
        "abstract": "Gene and protein networks are very important to model complex large-scale systems in molecular biology. Inferring or reverseengineering such networks can be defined as the process of identifying gene/protein interactions from experimental data through computational analysis. However, this task is typically complicated by the enormously large scale of the unknowns in a rather small sample size. Furthermore, when the goal is to study causal relationships within the network, tools capable of overcoming the limitations of correlation networks are required. In this work, we make use of Bayesian Graphical Models to attach this problem and, specifically, we perform a comparative study of different state-of-the-art heuristics, analyzing their performance in inferring the structure of the Bayesian Network from breast cancer data.\n    ",
        "submission_date": "2017-03-08T00:00:00",
        "last_modified_date": "2017-03-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.03054",
        "title": "Deep Variation-structured Reinforcement Learning for Visual Relationship and Attribute Detection",
        "authors": [
            "Xiaodan Liang",
            "Lisa Lee",
            "Eric P. Xing"
        ],
        "abstract": "Despite progress in visual perception tasks such as image classification and detection, computers still struggle to understand the interdependency of objects in the scene as a whole, e.g., relations between objects or their attributes. Existing methods often ignore global context cues capturing the interactions among different object instances, and can only recognize a handful of types by exhaustively training individual detectors for all possible relationships. To capture such global interdependency, we propose a deep Variation-structured Reinforcement Learning (VRL) framework to sequentially discover object relationships and attributes in the whole image. First, a directed semantic action graph is built using language priors to provide a rich and compact representation of semantic correlations between object categories, predicates, and attributes. Next, we use a variation-structured traversal over the action graph to construct a small, adaptive action set for each step based on the current state and historical actions. In particular, an ambiguity-aware object mining scheme is used to resolve semantic ambiguity among object categories that the object detector fails to distinguish. We then make sequential predictions using a deep RL framework, incorporating global context cues and semantic embeddings of previously extracted phrases in the state vector. Our experiments on the Visual Relationship Detection (VRD) dataset and the large-scale Visual Genome dataset validate the superiority of VRL, which can achieve significantly better detection results on datasets involving thousands of relationship and attribute types. We also demonstrate that VRL is able to predict unseen types embedded in our action graph by learning correlations on shared graph nodes.\n    ",
        "submission_date": "2017-03-08T00:00:00",
        "last_modified_date": "2017-03-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.03055",
        "title": "Interpretable Structure-Evolving LSTM",
        "authors": [
            "Xiaodan Liang",
            "Liang Lin",
            "Xiaohui Shen",
            "Jiashi Feng",
            "Shuicheng Yan",
            "Eric P. Xing"
        ],
        "abstract": "This paper develops a general framework for learning interpretable data representation via Long Short-Term Memory (LSTM) recurrent neural networks over hierarchal graph structures. Instead of learning LSTM models over the pre-fixed structures, we propose to further learn the intermediate interpretable multi-level graph structures in a progressive and stochastic way from data during the LSTM network optimization. We thus call this model the structure-evolving LSTM. In particular, starting with an initial element-level graph representation where each node is a small data element, the structure-evolving LSTM gradually evolves the multi-level graph representations by stochastically merging the graph nodes with high compatibilities along the stacked LSTM layers. In each LSTM layer, we estimate the compatibility of two connected nodes from their corresponding LSTM gate outputs, which is used to generate a merging probability. The candidate graph structures are accordingly generated where the nodes are grouped into cliques with their merging probabilities. We then produce the new graph structure with a Metropolis-Hasting algorithm, which alleviates the risk of getting stuck in local optimums by stochastic sampling with an acceptance probability. Once a graph structure is accepted, a higher-level graph is then constructed by taking the partitioned cliques as its nodes. During the evolving process, representation becomes more abstracted in higher-levels where redundant information is filtered out, allowing more efficient propagation of long-range data dependencies. We evaluate the effectiveness of structure-evolving LSTM in the application of semantic object parsing and demonstrate its advantage over state-of-the-art LSTM models on standard benchmarks.\n    ",
        "submission_date": "2017-03-08T00:00:00",
        "last_modified_date": "2017-03-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.03074",
        "title": "Efficient computational strategies to learn the structure of probabilistic graphical models of cumulative phenomena",
        "authors": [
            "Daniele Ramazzotti",
            "Marco S. Nobile",
            "Marco Antoniotti",
            "Alex Graudenzi"
        ],
        "abstract": "Structural learning of Bayesian Networks (BNs) is a NP-hard problem, which is further complicated by many theoretical issues, such as the I-equivalence among different structures. In this work, we focus on a specific subclass of BNs, named Suppes-Bayes Causal Networks (SBCNs), which include specific structural constraints based on Suppes' probabilistic causation to efficiently model cumulative phenomena. Here we compare the performance, via extensive simulations, of various state-of-the-art search strategies, such as local search techniques and Genetic Algorithms, as well as of distinct regularization methods. The assessment is performed on a large number of simulated datasets from topologies with distinct levels of complexity, various sample size and different rates of errors in the data. Among the main results, we show that the introduction of Suppes' constraints dramatically improve the inference accuracy, by reducing the solution space and providing a temporal ordering on the variables. We also report on trade-offs among different search techniques that can be efficiently employed in distinct experimental settings. This manuscript is an extended version of the paper \"Structural Learning of Probabilistic Graphical Models of Cumulative Phenomena\" presented at the 2018 International Conference on Computational Science.\n    ",
        "submission_date": "2017-03-08T00:00:00",
        "last_modified_date": "2018-10-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.03076",
        "title": "Causal Data Science for Financial Stress Testing",
        "authors": [
            "Gelin Gao",
            "Bud Mishra",
            "Daniele Ramazzotti"
        ],
        "abstract": "The most recent financial upheavals have cast doubt on the adequacy of some of the conventional quantitative risk management strategies, such as VaR (Value at Risk), in many common situations. Consequently, there has been an increasing need for verisimilar financial stress testings, namely simulating and analyzing financial portfolios in extreme, albeit rare scenarios. Unlike conventional risk management which exploits statistical correlations among financial instruments, here we focus our analysis on the notion of probabilistic causation, which is embodied by Suppes-Bayes Causal Networks (SBCNs); SBCNs are probabilistic graphical models that have many attractive features in terms of more accurate causal analysis for generating financial stress scenarios. In this paper, we present a novel approach for conducting stress testing of financial portfolios based on SBCNs in combination with classical machine learning classification tools. The resulting method is shown to be capable of correctly discovering the causal relationships among financial factors that affect the portfolios and thus, simulating stress testing scenarios with a higher accuracy and lower computational complexity than conventional Monte Carlo Simulations.\n    ",
        "submission_date": "2017-03-08T00:00:00",
        "last_modified_date": "2018-04-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.03097",
        "title": "Information Extraction in Illicit Domains",
        "authors": [
            "Mayank Kejriwal",
            "Pedro Szekely"
        ],
        "abstract": "Extracting useful entities and attribute values from illicit domains such as human trafficking is a challenging problem with the potential for widespread social impact. Such domains employ atypical language models, have `long tails' and suffer from the problem of concept drift. In this paper, we propose a lightweight, feature-agnostic Information Extraction (IE) paradigm specifically designed for such domains. Our approach uses raw, unlabeled text from an initial corpus, and a few (12-120) seed annotations per domain-specific attribute, to learn robust IE models for unobserved pages and websites. Empirically, we demonstrate that our approach can outperform feature-centric Conditional Random Field baselines by over 18\\% F-Measure on five annotated sets of real-world human trafficking datasets in both low-supervision and high-supervision settings. We also show that our approach is demonstrably robust to concept drift, and can be efficiently bootstrapped even in a serial computing environment.\n    ",
        "submission_date": "2017-03-09T00:00:00",
        "last_modified_date": "2017-03-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.03130",
        "title": "A Structured Self-attentive Sentence Embedding",
        "authors": [
            "Zhouhan Lin",
            "Minwei Feng",
            "Cicero Nogueira dos Santos",
            "Mo Yu",
            "Bing Xiang",
            "Bowen Zhou",
            "Yoshua Bengio"
        ],
        "abstract": "This paper proposes a new model for extracting an interpretable sentence embedding by introducing self-attention. Instead of using a vector, we use a 2-D matrix to represent the embedding, with each row of the matrix attending on a different part of the sentence. We also propose a self-attention mechanism and a special regularization term for the model. As a side effect, the embedding comes with an easy way of visualizing what specific parts of the sentence are encoded into the embedding. We evaluate our model on 3 different tasks: author profiling, sentiment classification, and textual entailment. Results show that our model yields a significant performance gain compared to other sentence embedding methods in all of the 3 tasks.\n    ",
        "submission_date": "2017-03-09T00:00:00",
        "last_modified_date": "2017-03-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.03161",
        "title": "Behavior-based Navigation of Mobile Robot in Unknown Environments Using Fuzzy Logic and Multi-Objective Optimization",
        "authors": [
            "Thi Thanh Van Nguyen",
            "Manh Duong Phung",
            "Quang Vinh Tran"
        ],
        "abstract": "This study proposes behavior-based navigation architecture, named BBFM, to deal with the problem of navigating the mobile robot in unknown environments in the presence of obstacles and local minimum regions. In the architecture, the complex navigation task is split into principal sub-tasks or behaviors. Each behavior is implemented by a fuzzy controller and executed independently to deal with a specific problem of navigation. The fuzzy controller is modified to contain only the fuzzification and inference procedures so that its output is a membership function representing the behavior's objective. The membership functions of all controllers are then used as the objective functions for a multi-objective optimization process to coordinate all behaviors. The result of this process is an overall control signal, which is Pareto-optimal, used to control the robot. A number of simulations, comparisons, and experiments were conducted. The results show that the proposed architecture outperforms some popular behavior-based architectures in term of accuracy, smoothness, traveled distance, and time response.\n    ",
        "submission_date": "2017-03-09T00:00:00",
        "last_modified_date": "2017-03-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.03372",
        "title": "LesionSeg: Semantic segmentation of skin lesions using Deep Convolutional Neural Network",
        "authors": [
            "Dhanesh Ramachandram",
            "Terrance DeVries"
        ],
        "abstract": "We present a method for skin lesion segmentation for the ISIC 2017 Skin Lesion Segmentation Challenge. Our approach is based on a Fully Convolutional Network architecture which is trained end to end, from scratch, on a limited dataset. Our semantic segmentation architecture utilizes several recent innovations in particularly in the combined use of (i) use of atrous convolutions to increase the effective field of view of the network's receptive field without increasing the number of parameters, (ii) the use of network-in-network $1\\times1$ convolution layers to add capacity to the network and (iii) state-of-art super-resolution upsampling of predictions using subpixel CNN layers. We reported a mean IOU score of 0.642 on the validation set provided by the organisers.\n    ",
        "submission_date": "2017-03-09T00:00:00",
        "last_modified_date": "2017-03-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.03400",
        "title": "Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks",
        "authors": [
            "Chelsea Finn",
            "Pieter Abbeel",
            "Sergey Levine"
        ],
        "abstract": "We propose an algorithm for meta-learning that is model-agnostic, in the sense that it is compatible with any model trained with gradient descent and applicable to a variety of different learning problems, including classification, regression, and reinforcement learning. The goal of meta-learning is to train a model on a variety of learning tasks, such that it can solve new learning tasks using only a small number of training samples. In our approach, the parameters of the model are explicitly trained such that a small number of gradient steps with a small amount of training data from a new task will produce good generalization performance on that task. In effect, our method trains the model to be easy to fine-tune. We demonstrate that this approach leads to state-of-the-art performance on two few-shot image classification benchmarks, produces good results on few-shot regression, and accelerates fine-tuning for policy gradient reinforcement learning with neural network policies.\n    ",
        "submission_date": "2017-03-09T00:00:00",
        "last_modified_date": "2017-07-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.03524",
        "title": "The Ontological Multidimensional Data Model",
        "authors": [
            "Leopoldo Bertossi",
            "Mostafa Milani"
        ],
        "abstract": "In this extended abstract we describe, mainly by examples, the main elements of the Ontological Multidimensional Data Model, which considerably extends a relational reconstruction of the multidimensional data model proposed by Hurtado and Mendelzon by means of tuple-generating dependencies, equality-generating dependencies, and negative constraints as found in Datalog+-. We briefly mention some good computational properties of the model.\n    ",
        "submission_date": "2017-03-10T00:00:00",
        "last_modified_date": "2017-05-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.03633",
        "title": "Learning Gradient Descent: Better Generalization and Longer Horizons",
        "authors": [
            "Kaifeng Lv",
            "Shunhua Jiang",
            "Jian Li"
        ],
        "abstract": "Training deep neural networks is a highly nontrivial task, involving carefully selecting appropriate training algorithms, scheduling step sizes and tuning other hyperparameters. Trying different combinations can be quite labor-intensive and time consuming. Recently, researchers have tried to use deep learning algorithms to exploit the landscape of the loss function of the training problem of interest, and learn how to optimize over it in an automatic way. In this paper, we propose a new learning-to-learn model and some useful and practical tricks. Our optimizer outperforms generic, hand-crafted optimization algorithms and state-of-the-art learning-to-learn optimizers by DeepMind in many tasks. We demonstrate the effectiveness of our algorithms on a number of tasks, including deep MLPs, CNNs, and simple LSTMs.\n    ",
        "submission_date": "2017-03-10T00:00:00",
        "last_modified_date": "2017-06-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.03714",
        "title": "Applying the Wizard-of-Oz Technique to Multimodal Human-Robot Dialogue",
        "authors": [
            "Matthew Marge",
            "Claire Bonial",
            "Brendan Byrne",
            "Taylor Cassidy",
            "A. William Evans",
            "Susan G. Hill",
            "Clare Voss"
        ],
        "abstract": "Our overall program objective is to provide more natural ways for soldiers to interact and communicate with robots, much like how soldiers communicate with other soldiers today. We describe how the Wizard-of-Oz (WOz) method can be applied to multimodal human-robot dialogue in a collaborative exploration task. While the WOz method can help design robot behaviors, traditional approaches place the burden of decisions on a single wizard. In this work, we consider two wizards to stand in for robot navigation and dialogue management software components. The scenario used to elicit data is one in which a human-robot team is tasked with exploring an unknown environment: a human gives verbal instructions from a remote location and the robot follows them, clarifying possible misunderstandings as needed via dialogue. We found the division of labor between wizards to be workable, which holds promise for future software development.\n    ",
        "submission_date": "2017-03-10T00:00:00",
        "last_modified_date": "2017-03-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.03717",
        "title": "Right for the Right Reasons: Training Differentiable Models by Constraining their Explanations",
        "authors": [
            "Andrew Slavin Ross",
            "Michael C. Hughes",
            "Finale Doshi-Velez"
        ],
        "abstract": "Neural networks are among the most accurate supervised learning methods in use today, but their opacity makes them difficult to trust in critical applications, especially when conditions in training differ from those in test. Recent work on explanations for black-box models has produced tools (e.g. LIME) to show the implicit rules behind predictions, which can help us identify when models are right for the wrong reasons. However, these methods do not scale to explaining entire datasets and cannot correct the problems they reveal. We introduce a method for efficiently explaining and regularizing differentiable models by examining and selectively penalizing their input gradients, which provide a normal to the decision boundary. We apply these penalties both based on expert annotation and in an unsupervised fashion that encourages diverse models with qualitatively different decision boundaries for the same classification problem. On multiple datasets, we show our approach generates faithful explanations and models that generalize much better when conditions differ between training and test.\n    ",
        "submission_date": "2017-03-10T00:00:00",
        "last_modified_date": "2017-05-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.03854",
        "title": "Convolutional Spike Timing Dependent Plasticity based Feature Learning in Spiking Neural Networks",
        "authors": [
            "Priyadarshini Panda",
            "Gopalakrishnan Srinivasan",
            "Kaushik Roy"
        ],
        "abstract": "Brain-inspired learning models attempt to mimic the cortical architecture and computations performed in the neurons and synapses constituting the human brain to achieve its efficiency in cognitive tasks. In this work, we present convolutional spike timing dependent plasticity based feature learning with biologically plausible leaky-integrate-and-fire neurons in Spiking Neural Networks (SNNs). We use shared weight kernels that are trained to encode representative features underlying the input patterns thereby improving the sparsity as well as the robustness of the learning model. We demonstrate that the proposed unsupervised learning methodology learns several visual categories for object recognition with fewer number of examples and outperforms traditional fully-connected SNN architectures while yielding competitive accuracy. Additionally, we observe that the learning model performs out-of-set generalization further making the proposed biologically plausible framework a viable and efficient architecture for future neuromorphic applications.\n    ",
        "submission_date": "2017-03-10T00:00:00",
        "last_modified_date": "2017-03-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.03864",
        "title": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning",
        "authors": [
            "Tim Salimans",
            "Jonathan Ho",
            "Xi Chen",
            "Szymon Sidor",
            "Ilya Sutskever"
        ],
        "abstract": "We explore the use of Evolution Strategies (ES), a class of black box optimization algorithms, as an alternative to popular MDP-based RL techniques such as Q-learning and Policy Gradients. Experiments on MuJoCo and Atari show that ES is a viable solution strategy that scales extremely well with the number of CPUs available: By using a novel communication strategy based on common random numbers, our ES implementation only needs to communicate scalars, making it possible to scale to over a thousand parallel workers. This allows us to solve 3D humanoid walking in 10 minutes and obtain competitive results on most Atari games after one hour of training. In addition, we highlight several advantages of ES as a black box optimization technique: it is invariant to action frequency and delayed rewards, tolerant of extremely long horizons, and does not need temporal discounting or value function approximation.\n    ",
        "submission_date": "2017-03-10T00:00:00",
        "last_modified_date": "2017-09-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.03888",
        "title": "Segmentation of skin lesions based on fuzzy classification of pixels and histogram thresholding",
        "authors": [
            "Jose Luis Garcia-Arroyo",
            "Begonya Garcia-Zapirain"
        ],
        "abstract": "This paper proposes an innovative method for segmentation of skin lesions in dermoscopy images developed by the authors, based on fuzzy classification of pixels and histogram thresholding.\n    ",
        "submission_date": "2017-03-11T00:00:00",
        "last_modified_date": "2017-03-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.03912",
        "title": "Mitigating the Curse of Correlation in Security Games by Entropy Maximization",
        "authors": [
            "Haifeng Xu",
            "Milind Tambe",
            "Shaddin Dughmi",
            "Venil Loyd Noronha"
        ],
        "abstract": "In Stackelberg security games, a defender seeks to randomly allocate limited security resources to protect critical targets from an attack. In this paper, we study a fundamental, yet underexplored, phenomenon in security games, which we term the \\emph{Curse of Correlation} (CoC). Specifically, we observe that there are inevitable correlations among the protection status of different targets. Such correlation is a crucial concern, especially in \\emph{spatio-temporal} domains like conservation area patrolling, where attackers can surveil patrollers at certain areas and then infer their patrolling routes using such correlations. To mitigate this issue, we propose to design entropy-maximizing defending strategies for spatio-temporal security games, which frequently suffer from CoC. We prove that the problem is \\#P-hard in general. However, it admits efficient algorithms in well-motivated special settings. Our experiments show significant advantages of max-entropy algorithms over previous algorithms. A scalable implementation of our algorithm is currently under pre-deployment testing for integration into FAMS software to improve the scheduling of US federal air marshals.\n    ",
        "submission_date": "2017-03-11T00:00:00",
        "last_modified_date": "2018-01-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.03921",
        "title": "Gait Pattern Recognition Using Accelerometers",
        "authors": [
            "Vahid Alizadeh"
        ],
        "abstract": "Motion ability is one of the most important human properties, including gait as a basis of human transitional movement. Gait, as a biometric for recognizing human identities, can be non-intrusively captured signals using wearable or portable smart devices. In this study gait patterns is collected using a wireless platform of two sensors located at chest and right ankle of the subjects. Then the raw data has undergone some preprocessing methods and segmented into 5 seconds windows. Some time and frequency domain features is extracted and the performance evaluated by 5 different classifiers. Decision Tree (with all features) and K-Nearest Neighbors (with 10 selected features) classifiers reached 99.4% and 100% respectively.\n    ",
        "submission_date": "2017-03-11T00:00:00",
        "last_modified_date": "2017-03-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.03924",
        "title": "Real-Time Machine Learning: The Missing Pieces",
        "authors": [
            "Robert Nishihara",
            "Philipp Moritz",
            "Stephanie Wang",
            "Alexey Tumanov",
            "William Paul",
            "Johann Schleier-Smith",
            "Richard Liaw",
            "Mehrdad Niknami",
            "Michael I. Jordan",
            "Ion Stoica"
        ],
        "abstract": "Machine learning applications are increasingly deployed not only to serve predictions using static models, but also as tightly-integrated components of feedback loops involving dynamic, real-time decision making. These applications pose a new set of requirements, none of which are difficult to achieve in isolation, but the combination of which creates a challenge for existing distributed execution frameworks: computation with millisecond latency at high throughput, adaptive construction of arbitrary task graphs, and execution of heterogeneous kernels over diverse sets of resources. We assert that a new distributed execution framework is needed for such ML applications and propose a candidate approach with a proof-of-concept architecture that achieves a 63x performance improvement over a state-of-the-art execution framework for a representative application.\n    ",
        "submission_date": "2017-03-11T00:00:00",
        "last_modified_date": "2017-05-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.04070",
        "title": "Prediction and Control with Temporal Segment Models",
        "authors": [
            "Nikhil Mishra",
            "Pieter Abbeel",
            "Igor Mordatch"
        ],
        "abstract": "We introduce a method for learning the dynamics of complex nonlinear systems based on deep generative models over temporal segments of states and actions. Unlike dynamics models that operate over individual discrete timesteps, we learn the distribution over future state trajectories conditioned on past state, past action, and planned future action trajectories, as well as a latent prior over action trajectories. Our approach is based on convolutional autoregressive models and variational autoencoders. It makes stable and accurate predictions over long horizons for complex, stochastic systems, effectively expressing uncertainty and modeling the effects of collisions, sensory noise, and action delays. The learned dynamics model and action prior can be used for end-to-end, fully differentiable trajectory optimization and model-based policy optimization, which we use to evaluate the performance and sample-efficiency of our method.\n    ",
        "submission_date": "2017-03-12T00:00:00",
        "last_modified_date": "2017-07-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.04071",
        "title": "A Compact DNN: Approaching GoogLeNet-Level Accuracy of Classification and Domain Adaptation",
        "authors": [
            "Chunpeng Wu",
            "Wei Wen",
            "Tariq Afzal",
            "Yongmei Zhang",
            "Yiran Chen",
            "Hai Li"
        ],
        "abstract": "Recently, DNN model compression based on network architecture design, e.g., SqueezeNet, attracted a lot attention. No accuracy drop on image classification is observed on these extremely compact networks, compared to well-known models. An emerging question, however, is whether these model compression techniques hurt DNN's learning ability other than classifying images on a single dataset. Our preliminary experiment shows that these compression methods could degrade domain adaptation (DA) ability, though the classification performance is preserved. Therefore, we propose a new compact network architecture and unsupervised DA method in this paper. The DNN is built on a new basic module Conv-M which provides more diverse feature extractors without significantly increasing parameters. The unified framework of our DA method will simultaneously learn invariance across domains, reduce divergence of feature representations, and adapt label prediction. Our DNN has 4.1M parameters, which is only 6.7% of AlexNet or 59% of GoogLeNet. Experiments show that our DNN obtains GoogLeNet-level accuracy both on classification and DA, and our DA method slightly outperforms previous competitive ones. Put all together, our DA strategy based on our DNN achieves state-of-the-art on sixteen of total eighteen DA tasks on popular Office-31 and Office-Caltech datasets.\n    ",
        "submission_date": "2017-03-12T00:00:00",
        "last_modified_date": "2017-04-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.04221",
        "title": "A Hierarchical Framework of Cloud Resource Allocation and Power Management Using Deep Reinforcement Learning",
        "authors": [
            "Ning Liu",
            "Zhe Li",
            "Zhiyuan Xu",
            "Jielong Xu",
            "Sheng Lin",
            "Qinru Qiu",
            "Jian Tang",
            "Yanzhi Wang"
        ],
        "abstract": "Automatic decision-making approaches, such as reinforcement learning (RL), have been applied to (partially) solve the resource allocation problem adaptively in the cloud computing system. However, a complete cloud resource allocation framework exhibits high dimensions in state and action spaces, which prohibit the usefulness of traditional RL techniques. In addition, high power consumption has become one of the critical concerns in design and control of cloud computing systems, which degrades system reliability and increases cooling cost. An effective dynamic power management (DPM) policy should minimize power consumption while maintaining performance degradation within an acceptable level. Thus, a joint virtual machine (VM) resource allocation and power management framework is critical to the overall cloud computing system. Moreover, novel solution framework is necessary to address the even higher dimensions in state and action spaces. In this paper, we propose a novel hierarchical framework for solving the overall resource allocation and power management problem in cloud computing systems. The proposed hierarchical framework comprises a global tier for VM resource allocation to the servers and a local tier for distributed power management of local servers. The emerging deep reinforcement learning (DRL) technique, which can deal with complicated control problems with large state space, is adopted to solve the global tier problem. Furthermore, an autoencoder and a novel weight sharing structure are adopted to handle the high-dimensional state space and accelerate the convergence speed. On the other hand, the local tier of distributed server power managements comprises an LSTM based workload predictor and a model-free RL based power manager, operating in a distributed manner.\n    ",
        "submission_date": "2017-03-13T00:00:00",
        "last_modified_date": "2017-08-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.04363",
        "title": "Deep Value Networks Learn to Evaluate and Iteratively Refine Structured Outputs",
        "authors": [
            "Michael Gygli",
            "Mohammad Norouzi",
            "Anelia Angelova"
        ],
        "abstract": "We approach structured output prediction by optimizing a deep value network (DVN) to precisely estimate the task loss on different output configurations for a given input. Once the model is trained, we perform inference by gradient descent on the continuous relaxations of the output variables to find outputs with promising scores from the value network. When applied to image segmentation, the value network takes an image and a segmentation mask as inputs and predicts a scalar estimating the intersection over union between the input and ground truth masks. For multi-label classification, the DVN's objective is to correctly predict the F1 score for any potential label configuration. The DVN framework achieves the state-of-the-art results on multi-label prediction and image segmentation benchmarks.\n    ",
        "submission_date": "2017-03-13T00:00:00",
        "last_modified_date": "2017-08-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.04389",
        "title": "Bayesian Optimization with Gradients",
        "authors": [
            "Jian Wu",
            "Matthias Poloczek",
            "Andrew Gordon Wilson",
            "Peter I. Frazier"
        ],
        "abstract": "Bayesian optimization has been successful at global optimization of expensive-to-evaluate multimodal objective functions. However, unlike most optimization methods, Bayesian optimization typically does not use derivative information. In this paper we show how Bayesian optimization can exploit derivative information to decrease the number of objective function evaluations required for good performance. In particular, we develop a novel Bayesian optimization algorithm, the derivative-enabled knowledge-gradient (dKG), for which we show one-step Bayes-optimality, asymptotic consistency, and greater one-step value of information than is possible in the derivative-free setting. Our procedure accommodates noisy and incomplete derivative information, comes in both sequential and batch forms, and can optionally reduce the computational cost of inference through automatically selected retention of a single directional derivative. We also compute the d-KG acquisition function and its gradient using a novel fast discretization-free technique. We show d-KG provides state-of-the-art performance compared to a wide range of optimization procedures with and without gradients, on benchmarks including logistic regression, deep learning, kernel learning, and k-nearest neighbors.\n    ",
        "submission_date": "2017-03-13T00:00:00",
        "last_modified_date": "2018-02-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.04489",
        "title": "Reinforcement Learning for Transition-Based Mention Detection",
        "authors": [
            "Georgiana Dinu",
            "Wael Hamza",
            "Radu Florian"
        ],
        "abstract": "This paper describes an application of reinforcement learning to the mention detection task. We define a novel action-based formulation for the mention detection task, in which a model can flexibly revise past labeling decisions by grouping together tokens and assigning partial mention labels. We devise a method to create mention-level episodes and we train a model by rewarding correctly labeled complete mentions, irrespective of the inner structure created. The model yields results which are on par with a competitive supervised counterpart while being more flexible in terms of achieving targeted behavior through reward modeling and generating internal mention structure, especially on longer mentions.\n    ",
        "submission_date": "2017-03-13T00:00:00",
        "last_modified_date": "2017-03-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.04498",
        "title": "High-Throughput and Language-Agnostic Entity Disambiguation and Linking on User Generated Data",
        "authors": [
            "Preeti Bhargava",
            "Nemanja Spasojevic",
            "Guoning Hu"
        ],
        "abstract": "The Entity Disambiguation and Linking (EDL) task matches entity mentions in text to a unique Knowledge Base (KB) identifier such as a Wikipedia or Freebase id. It plays a critical role in the construction of a high quality information network, and can be further leveraged for a variety of information retrieval and NLP tasks such as text categorization and document tagging. EDL is a complex and challenging problem due to ambiguity of the mentions and real world text being multi-lingual. Moreover, EDL systems need to have high throughput and should be lightweight in order to scale to large datasets and run on off-the-shelf machines. More importantly, these systems need to be able to extract and disambiguate dense annotations from the data in order to enable an Information Retrieval or Extraction task running on the data to be more efficient and accurate. In order to address all these challenges, we present the Lithium EDL system and algorithm - a high-throughput, lightweight, language-agnostic EDL system that extracts and correctly disambiguates 75% more entities than state-of-the-art EDL systems and is significantly faster than them.\n    ",
        "submission_date": "2017-03-13T00:00:00",
        "last_modified_date": "2017-03-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.04529",
        "title": "Task-based End-to-end Model Learning in Stochastic Optimization",
        "authors": [
            "Priya L. Donti",
            "Brandon Amos",
            "J. Zico Kolter"
        ],
        "abstract": "With the increasing popularity of machine learning techniques, it has become common to see prediction algorithms operating within some larger process. However, the criteria by which we train these algorithms often differ from the ultimate criteria on which we evaluate them. This paper proposes an end-to-end approach for learning probabilistic machine learning models in a manner that directly captures the ultimate task-based objective for which they will be used, within the context of stochastic programming. We present three experimental evaluations of the proposed approach: a classical inventory stock problem, a real-world electrical grid scheduling task, and a real-world energy storage arbitrage task. We show that the proposed approach can outperform both traditional modeling and purely black-box policy optimization approaches in these applications.\n    ",
        "submission_date": "2017-03-13T00:00:00",
        "last_modified_date": "2019-04-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.04565",
        "title": "Fuzzy Model Tree For Early Effort Estimation",
        "authors": [
            "Mohammad Azzeh",
            "Ali Bou Nassif"
        ],
        "abstract": "Use Case Points (UCP) is a well-known method to estimate the project size, based on Use Case diagram, at early phases of software development. Although the Use Case diagram is widely accepted as a de-facto model for analyzing object oriented software requirements over the world, UCP method did not take sufficient amount of attention because, as yet, there is no consensus on how to produce software effort from UCP. This paper aims to study the potential of using Fuzzy Model Tree to derive effort estimates based on UCP size measure using a dataset collected for that purpose. The proposed approach has been validated against Treeboost model, Multiple Linear Regression and classical effort estimation based on the UCP model. The obtained results are promising and show better performance than those obtained by classical UCP, Multiple Linear Regression and slightly better than those obtained by Tree boost model.\n    ",
        "submission_date": "2017-03-11T00:00:00",
        "last_modified_date": "2017-03-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.04567",
        "title": "Learning best K analogies from data distribution for case-based software effort estimation",
        "authors": [
            "Mohammad Azzeh",
            "Yousef Elsheikh"
        ],
        "abstract": "Case-Based Reasoning (CBR) has been widely used to generate good software effort estimates. The predictive performance of CBR is a dataset dependent and subject to extremely large space of configuration possibilities. Regardless of the type of adaptation technique, deciding on the optimal number of similar cases to be used before applying CBR is a key challenge. In this paper we propose a new technique based on Bisecting k-medoids clustering algorithm to better understanding the structure of a dataset and discovering the the optimal cases for each individual project by excluding irrelevant cases. Results obtained showed that understanding of the data characteristic prior prediction stage can help in automatically finding the best number of cases for each test project. Performance figures of the proposed estimation method are better than those of other regular K-based CBR methods.\n    ",
        "submission_date": "2017-03-11T00:00:00",
        "last_modified_date": "2017-03-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.04677",
        "title": "A computational investigation of sources of variability in sentence comprehension difficulty in aphasia",
        "authors": [
            "Paul M\u00e4tzig",
            "Shravan Vasishth",
            "Felix Engelmann",
            "David Caplan"
        ],
        "abstract": "We present a computational evaluation of three hypotheses about sources of deficit in sentence comprehension in aphasia: slowed processing, intermittent deficiency, and resource reduction. The ACT-R based Lewis and Vasishth (2005) model is used to implement these three proposals. Slowed processing is implemented as slowed default production-rule firing time; intermittent deficiency as increased random noise in activation of chunks in memory; and resource reduction as reduced goal activation. As data, we considered subject vs. object rela- tives whose matrix clause contained either an NP or a reflexive, presented in a self-paced listening modality to 56 individuals with aphasia (IWA) and 46 matched controls. The participants heard the sentences and carried out a picture verification task to decide on an interpretation of the sentence. These response accuracies are used to identify the best parameters (for each participant) that correspond to the three hypotheses mentioned above. We show that controls have more tightly clustered (less variable) parameter values than IWA; specifically, compared to controls, among IWA there are more individuals with low goal activations, high noise, and slow default action times. This suggests that (i) individual patients show differential amounts of deficit along the three dimensions of slowed processing, intermittent deficient, and resource reduction, (ii) overall, there is evidence for all three sources of deficit playing a role, and (iii) IWA have a more variable range of parameter values than controls. In sum, this study contributes a proof of concept of a quantitative implementation of, and evidence for, these three accounts of comprehension deficits in aphasia.\n    ",
        "submission_date": "2017-03-14T00:00:00",
        "last_modified_date": "2017-05-31T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.04730",
        "title": "Understanding Black-box Predictions via Influence Functions",
        "authors": [
            "Pang Wei Koh",
            "Percy Liang"
        ],
        "abstract": "How can we explain the predictions of a black-box model? In this paper, we use influence functions -- a classic technique from robust statistics -- to trace a model's prediction through the learning algorithm and back to its training data, thereby identifying training points most responsible for a given prediction. To scale up influence functions to modern machine learning settings, we develop a simple, efficient implementation that requires only oracle access to gradients and Hessian-vector products. We show that even on non-convex and non-differentiable models where the theory breaks down, approximations to influence functions can still provide valuable information. On linear models and convolutional neural networks, we demonstrate that influence functions are useful for multiple purposes: understanding model behavior, debugging models, detecting dataset errors, and even creating visually-indistinguishable training-set attacks.\n    ",
        "submission_date": "2017-03-14T00:00:00",
        "last_modified_date": "2020-12-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.04756",
        "title": "Weighted Voting Via No-Regret Learning",
        "authors": [
            "Nika Haghtalab",
            "Ritesh Noothigattu",
            "Ariel D. Procaccia"
        ],
        "abstract": "Voting systems typically treat all voters equally. We argue that perhaps they should not: Voters who have supported good choices in the past should be given higher weight than voters who have supported bad ones. To develop a formal framework for desirable weighting schemes, we draw on no-regret learning. Specifically, given a voting rule, we wish to design a weighting scheme such that applying the voting rule, with voters weighted by the scheme, leads to choices that are almost as good as those endorsed by the best voter in hindsight. We derive possibility and impossibility results for the existence of such weighting schemes, depending on whether the voting rule and the weighting scheme are deterministic or randomized, as well as on the social choice axioms satisfied by the voting rule.\n    ",
        "submission_date": "2017-03-14T00:00:00",
        "last_modified_date": "2017-03-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.04816",
        "title": "Making Neural QA as Simple as Possible but not Simpler",
        "authors": [
            "Dirk Weissenborn",
            "Georg Wiese",
            "Laura Seiffe"
        ],
        "abstract": "Recent development of large-scale question answering (QA) datasets triggered a substantial amount of research into end-to-end neural architectures for QA. Increasingly complex systems have been conceived without comparison to simpler neural baseline systems that would justify their complexity. In this work, we propose a simple heuristic that guides the development of neural baseline systems for the extractive QA task. We find that there are two ingredients necessary for building a high-performing neural QA system: first, the awareness of question words while processing the context and second, a composition function that goes beyond simple bag-of-words modeling, such as recurrent neural networks. Our results show that FastQA, a system that meets these two requirements, can achieve very competitive performance compared with existing models. We argue that this surprising finding puts results of previous systems and the complexity of recent QA datasets into perspective.\n    ",
        "submission_date": "2017-03-14T00:00:00",
        "last_modified_date": "2017-06-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.04940",
        "title": "Resilience: A Criterion for Learning in the Presence of Arbitrary Outliers",
        "authors": [
            "Jacob Steinhardt",
            "Moses Charikar",
            "Gregory Valiant"
        ],
        "abstract": "We introduce a criterion, resilience, which allows properties of a dataset (such as its mean or best low rank approximation) to be robustly computed, even in the presence of a large fraction of arbitrary additional data. Resilience is a weaker condition than most other properties considered so far in the literature, and yet enables robust estimation in a broader variety of settings. We provide new information-theoretic results on robust distribution learning, robust estimation of stochastic block models, and robust mean estimation under bounded $k$th moments. We also provide new algorithmic results on robust distribution learning, as well as robust mean estimation in $\\ell_p$-norms. Among our proof techniques is a method for pruning a high-dimensional distribution with bounded $1$st moments to a stable \"core\" with bounded $2$nd moments, which may be of independent interest.\n    ",
        "submission_date": "2017-03-15T00:00:00",
        "last_modified_date": "2017-11-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.05260",
        "title": "InScript: Narrative texts annotated with script information",
        "authors": [
            "Ashutosh Modi",
            "Tatjana Anikina",
            "Simon Ostermann",
            "Manfred Pinkal"
        ],
        "abstract": "This paper presents the InScript corpus (Narrative Texts Instantiating Script structure). InScript is a corpus of 1,000 stories centered around 10 different scenarios. Verbs and noun phrases are annotated with event and participant types, respectively. Additionally, the text is annotated with coreference information. The corpus shows rich lexical variation and will serve as a unique resource for the study of the role of script knowledge in natural language processing.\n    ",
        "submission_date": "2017-03-15T00:00:00",
        "last_modified_date": "2017-03-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.05320",
        "title": "Legal Question Answering using Ranking SVM and Deep Convolutional Neural Network",
        "authors": [
            "Phong-Khac Do",
            "Huy-Tien Nguyen",
            "Chien-Xuan Tran",
            "Minh-Tien Nguyen",
            "Minh-Le Nguyen"
        ],
        "abstract": "This paper presents a study of employing Ranking SVM and Convolutional Neural Network for two missions: legal information retrieval and question answering in the Competition on Legal Information Extraction/Entailment. For the first task, our proposed model used a triple of features (LSI, Manhattan, Jaccard), and is based on paragraph level instead of article level as in previous studies. In fact, each single-paragraph article corresponds to a particular paragraph in a huge multiple-paragraph article. For the legal question answering task, additional statistical features from information retrieval task integrated into Convolutional Neural Network contribute to higher accuracy.\n    ",
        "submission_date": "2017-03-16T00:00:00",
        "last_modified_date": "2017-03-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.05390",
        "title": "Convolutional Recurrent Neural Networks for Small-Footprint Keyword Spotting",
        "authors": [
            "Sercan O. Arik",
            "Markus Kliegl",
            "Rewon Child",
            "Joel Hestness",
            "Andrew Gibiansky",
            "Chris Fougner",
            "Ryan Prenger",
            "Adam Coates"
        ],
        "abstract": "Keyword spotting (KWS) constitutes a major component of human-technology interfaces. Maximizing the detection accuracy at a low false alarm (FA) rate, while minimizing the footprint size, latency and complexity are the goals for KWS. Towards achieving them, we study Convolutional Recurrent Neural Networks (CRNNs). Inspired by large-scale state-of-the-art speech recognition systems, we combine the strengths of convolutional layers and recurrent layers to exploit local structure and long-range context. We analyze the effect of architecture parameters, and propose training strategies to improve performance. With only ~230k parameters, our CRNN model yields acceptably low latency, and achieves 97.71% accuracy at 0.5 FA/hour for 5 dB signal-to-noise ratio.\n    ",
        "submission_date": "2017-03-15T00:00:00",
        "last_modified_date": "2017-07-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.05446",
        "title": "Look into Person: Self-supervised Structure-sensitive Learning and A New Benchmark for Human Parsing",
        "authors": [
            "Ke Gong",
            "Xiaodan Liang",
            "Dongyu Zhang",
            "Xiaohui Shen",
            "Liang Lin"
        ],
        "abstract": "Human parsing has recently attracted a lot of research interests due to its huge application potentials. However existing datasets have limited number of images and annotations, and lack the variety of human appearances and the coverage of challenging cases in unconstrained environment. In this paper, we introduce a new benchmark \"Look into Person (LIP)\" that makes a significant advance in terms of scalability, diversity and difficulty, a contribution that we feel is crucial for future developments in human-centric analysis. This comprehensive dataset contains over 50,000 elaborately annotated images with 19 semantic part labels, which are captured from a wider range of viewpoints, occlusions and background complexity. Given these rich annotations we perform detailed analyses of the leading human parsing approaches, gaining insights into the success and failures of these methods. Furthermore, in contrast to the existing efforts on improving the feature discriminative capability, we solve human parsing by exploring a novel self-supervised structure-sensitive learning approach, which imposes human pose structures into parsing results without resorting to extra supervision (i.e., no need for specifically labeling human joints in model training). Our self-supervised learning framework can be injected into any advanced neural networks to help incorporate rich high-level knowledge regarding human joints from a global perspective and improve the parsing results. Extensive evaluations on our LIP and the public PASCAL-Person-Part dataset demonstrate the superiority of our method.\n    ",
        "submission_date": "2017-03-16T00:00:00",
        "last_modified_date": "2017-07-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.05449",
        "title": "Minimax Regret Bounds for Reinforcement Learning",
        "authors": [
            "Mohammad Gheshlaghi Azar",
            "Ian Osband",
            "R\u00e9mi Munos"
        ],
        "abstract": "We consider the problem of provably optimal exploration in reinforcement learning for finite horizon MDPs. We show that an optimistic modification to value iteration achieves a regret bound of $\\tilde{O}( \\sqrt{HSAT} + H^2S^2A+H\\sqrt{T})$ where $H$ is the time horizon, $S$ the number of states, $A$ the number of actions and $T$ the number of time-steps. This result improves over the best previous known bound $\\tilde{O}(HS \\sqrt{AT})$ achieved by the UCRL2 algorithm of Jaksch et al., 2010. The key significance of our new results is that when $T\\geq H^3S^3A$ and $SA\\geq H$, it leads to a regret of $\\tilde{O}(\\sqrt{HSAT})$ that matches the established lower bound of $\\Omega(\\sqrt{HSAT})$ up to a logarithmic factor. Our analysis contains two key insights. We use careful application of concentration inequalities to the optimal value function as a whole, rather than to the transitions probabilities (to improve scaling in $S$), and we define Bernstein-based \"exploration bonuses\" that use the empirical variance of the estimated values at the next states (to improve scaling in $H$).\n    ",
        "submission_date": "2017-03-16T00:00:00",
        "last_modified_date": "2017-07-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.05468",
        "title": "Database Learning: Toward a Database that Becomes Smarter Every Time",
        "authors": [
            "Yongjoo Park",
            "Ahmad Shahab Tajik",
            "Michael Cafarella",
            "Barzan Mozafari"
        ],
        "abstract": "In today's databases, previous query answers rarely benefit answering future queries. For the first time, to the best of our knowledge, we change this paradigm in an approximate query processing (AQP) context. We make the following observation: the answer to each query reveals some degree of knowledge about the answer to another query because their answers stem from the same underlying distribution that has produced the entire dataset. Exploiting and refining this knowledge should allow us to answer queries more analytically, rather than by reading enormous amounts of raw data. Also, processing more queries should continuously enhance our knowledge of the underlying distribution, and hence lead to increasingly faster response times for future queries.\n",
        "submission_date": "2017-03-16T00:00:00",
        "last_modified_date": "2017-03-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.05820",
        "title": "Particle Value Functions",
        "authors": [
            "Chris J. Maddison",
            "Dieterich Lawson",
            "George Tucker",
            "Nicolas Heess",
            "Arnaud Doucet",
            "Andriy Mnih",
            "Yee Whye Teh"
        ],
        "abstract": "The policy gradients of the expected return objective can react slowly to rare rewards. Yet, in some cases agents may wish to emphasize the low or high returns regardless of their probability. Borrowing from the economics and control literature, we review the risk-sensitive value function that arises from an exponential utility and illustrate its effects on an example. This risk-sensitive value function is not always applicable to reinforcement learning problems, so we introduce the particle value function defined by a particle filter over the distributions of an agent's experience, which bounds the risk-sensitive one. We illustrate the benefit of the policy gradients of this objective in Cliffworld.\n    ",
        "submission_date": "2017-03-16T00:00:00",
        "last_modified_date": "2017-03-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.06103",
        "title": "Modeling Relational Data with Graph Convolutional Networks",
        "authors": [
            "Michael Schlichtkrull",
            "Thomas N. Kipf",
            "Peter Bloem",
            "Rianne van den Berg",
            "Ivan Titov",
            "Max Welling"
        ],
        "abstract": "Knowledge graphs enable a wide variety of applications, including question answering and information retrieval. Despite the great effort invested in their creation and maintenance, even the largest (e.g., Yago, DBPedia or Wikidata) remain incomplete. We introduce Relational Graph Convolutional Networks (R-GCNs) and apply them to two standard knowledge base completion tasks: Link prediction (recovery of missing facts, i.e. subject-predicate-object triples) and entity classification (recovery of missing entity attributes). R-GCNs are related to a recent class of neural networks operating on graphs, and are developed specifically to deal with the highly multi-relational data characteristic of realistic knowledge bases. We demonstrate the effectiveness of R-GCNs as a stand-alone model for entity classification. We further show that factorization models for link prediction such as DistMult can be significantly improved by enriching them with an encoder model to accumulate evidence over multiple inference steps in the relational graph, demonstrating a large improvement of 29.8% on FB15k-237 over a decoder-only baseline.\n    ",
        "submission_date": "2017-03-17T00:00:00",
        "last_modified_date": "2017-10-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.06109",
        "title": "Generalised Reichenbachian Common Cause Systems",
        "authors": [
            "Claudio Mazzola"
        ],
        "abstract": "The principle of the common cause claims that if an improbable coincidence has occurred, there must exist a common cause. This is generally taken to mean that positive correlations between non-causally related events should disappear when conditioning on the action of some underlying common cause. The extended interpretation of the principle, by contrast, urges that common causes should be called for in order to explain positive deviations between the estimated correlation of two events and the expected value of their correlation. The aim of this paper is to provide the extended reading of the principle with a general probabilistic model, capturing the simultaneous action of a system of multiple common causes. To this end, two distinct models are elaborated, and the necessary and sufficient conditions for their existence are determined.\n    ",
        "submission_date": "2017-03-16T00:00:00",
        "last_modified_date": "2017-03-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.06182",
        "title": "Deep Decentralized Multi-task Multi-Agent Reinforcement Learning under Partial Observability",
        "authors": [
            "Shayegan Omidshafiei",
            "Jason Pazis",
            "Christopher Amato",
            "Jonathan P. How",
            "John Vian"
        ],
        "abstract": "Many real-world tasks involve multiple agents with partial observability and limited communication. Learning is challenging in these settings due to local viewpoints of agents, which perceive the world as non-stationary due to concurrently-exploring teammates. Approaches that learn specialized policies for individual tasks face problems when applied to the real world: not only do agents have to learn and store distinct policies for each task, but in practice identities of tasks are often non-observable, making these approaches inapplicable. This paper formalizes and addresses the problem of multi-task multi-agent reinforcement learning under partial observability. We introduce a decentralized single-task learning approach that is robust to concurrent interactions of teammates, and present an approach for distilling single-task policies into a unified policy that performs well across multiple related tasks, without explicit provision of task identity.\n    ",
        "submission_date": "2017-03-17T00:00:00",
        "last_modified_date": "2017-07-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.06283",
        "title": "Expecting the Unexpected: Training Detectors for Unusual Pedestrians with Adversarial Imposters",
        "authors": [
            "Shiyu Huang",
            "Deva Ramanan"
        ],
        "abstract": "As autonomous vehicles become an every-day reality, high-accuracy pedestrian detection is of paramount practical importance. Pedestrian detection is a highly researched topic with mature methods, but most datasets focus on common scenes of people engaged in typical walking poses on sidewalks. But performance is most crucial for dangerous scenarios, such as children playing in the street or people using bicycles/skateboards in unexpected ways. Such \"in-the-tail\" data is notoriously hard to observe, making both training and testing difficult. To analyze this problem, we have collected a novel annotated dataset of dangerous scenarios called the Precarious Pedestrian dataset. Even given a dedicated collection effort, it is relatively small by contemporary standards (around 1000 images). To allow for large-scale data-driven learning, we explore the use of synthetic data generated by a game engine. A significant challenge is selected the right \"priors\" or parameters for synthesis: we would like realistic data with poses and object configurations that mimic true Precarious Pedestrians. Inspired by Generative Adversarial Networks (GANs), we generate a massive amount of synthetic data and train a discriminative classifier to select a realistic subset, which we deem the Adversarial Imposters. We demonstrate that this simple pipeline allows one to synthesize realistic training data by making use of rendering/animation engines within a GAN framework. Interestingly, we also demonstrate that such data can be used to rank algorithms, suggesting that Adversarial Imposters can also be used for \"in-the-tail\" validation at test-time, a notoriously difficult challenge for real-world deployment.\n    ",
        "submission_date": "2017-03-18T00:00:00",
        "last_modified_date": "2017-04-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.06452",
        "title": "Algorithms for Semantic Segmentation of Multispectral Remote Sensing Imagery using Deep Learning",
        "authors": [
            "Ronald Kemker",
            "Carl Salvaggio",
            "Christopher Kanan"
        ],
        "abstract": "Deep convolutional neural networks (DCNNs) have been used to achieve state-of-the-art performance on many computer vision tasks (e.g., object recognition, object detection, semantic segmentation) thanks to a large repository of annotated image data. Large labeled datasets for other sensor modalities, e.g., multispectral imagery (MSI), are not available due to the large cost and manpower required. In this paper, we adapt state-of-the-art DCNN frameworks in computer vision for semantic segmentation for MSI imagery. To overcome label scarcity for MSI data, we substitute real MSI for generated synthetic MSI in order to initialize a DCNN framework. We evaluate our network initialization scheme on the new RIT-18 dataset that we present in this paper. This dataset contains very-high resolution MSI collected by an unmanned aircraft system. The models initialized with synthetic imagery were less prone to over-fitting and provide a state-of-the-art baseline for future work.\n    ",
        "submission_date": "2017-03-19T00:00:00",
        "last_modified_date": "2018-05-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.06503",
        "title": "CLTune: A Generic Auto-Tuner for OpenCL Kernels",
        "authors": [
            "Cedric Nugteren",
            "Valeriu Codreanu"
        ],
        "abstract": "This work presents CLTune, an auto-tuner for OpenCL kernels. It evaluates and tunes kernel performance of a generic, user-defined search space of possible parameter-value combinations. Example parameters include the OpenCL workgroup size, vector data-types, tile sizes, and loop unrolling factors. CLTune can be used in the following scenarios: 1) when there are too many tunable parameters to explore manually, 2) when performance portability across OpenCL devices is desired, or 3) when the optimal parameters change based on input argument values (e.g. matrix dimensions). The auto-tuner is generic, easy to use, open-source, and supports multiple search strategies including simulated annealing and particle swarm optimisation. CLTune is evaluated on two GPU case-studies inspired by the recent successes in deep learning: 2D convolution and matrix-multiplication (GEMM). For 2D convolution, we demonstrate the need for auto-tuning by optimizing for different filter sizes, achieving performance on-par or better than the state-of-the-art. For matrix-multiplication, we use CLTune to explore a parameter space of more than two-hundred thousand configurations, we show the need for device-specific tuning, and outperform the clBLAS library on NVIDIA, AMD and Intel GPUs.\n    ",
        "submission_date": "2017-03-19T00:00:00",
        "last_modified_date": "2017-03-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.06554",
        "title": "Object category understanding via eye fixations on freehand sketches",
        "authors": [
            "Ravi Kiran Sarvadevabhatla",
            "Sudharshan Suresh",
            "R. Venkatesh Babu"
        ],
        "abstract": "The study of eye gaze fixations on photographic images is an active research area. In contrast, the image subcategory of freehand sketches has not received as much attention for such studies. In this paper, we analyze the results of a free-viewing gaze fixation study conducted on 3904 freehand sketches distributed across 160 object categories. Our analysis shows that fixation sequences exhibit marked consistency within a sketch, across sketches of a category and even across suitably grouped sets of categories. This multi-level consistency is remarkable given the variability in depiction and extreme image content sparsity that characterizes hand-drawn object sketches. In our paper, we show that the multi-level consistency in the fixation data can be exploited to (a) predict a test sketch's category given only its fixation sequence and (b) build a computational model which predicts part-labels underlying fixations on objects. We hope that our findings motivate the community to deem sketch-like representations worthy of gaze-based studies vis-a-vis photographic images.\n    ",
        "submission_date": "2017-03-20T00:00:00",
        "last_modified_date": "2017-03-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.06585",
        "title": "Learning Cooperative Visual Dialog Agents with Deep Reinforcement Learning",
        "authors": [
            "Abhishek Das",
            "Satwik Kottur",
            "Jos\u00e9 M. F. Moura",
            "Stefan Lee",
            "Dhruv Batra"
        ],
        "abstract": "We introduce the first goal-driven training for visual question answering and dialog agents. Specifically, we pose a cooperative 'image guessing' game between two agents -- Qbot and Abot -- who communicate in natural language dialog so that Qbot can select an unseen image from a lineup of images. We use deep reinforcement learning (RL) to learn the policies of these agents end-to-end -- from pixels to multi-agent multi-round dialog to game reward.\n",
        "submission_date": "2017-03-20T00:00:00",
        "last_modified_date": "2017-03-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.06931",
        "title": "Learning Correspondence Structures for Person Re-identification",
        "authors": [
            "Weiyao Lin",
            "Yang Shen",
            "Junchi Yan",
            "Mingliang Xu",
            "Jianxin Wu",
            "Jingdong Wang",
            "Ke Lu"
        ],
        "abstract": "This paper addresses the problem of handling spatial misalignments due to camera-view changes or human-pose variations in person re-identification. We first introduce a boosting-based approach to learn a correspondence structure which indicates the patch-wise matching probabilities between images from a target camera pair. The learned correspondence structure can not only capture the spatial correspondence pattern between cameras but also handle the viewpoint or human-pose variation in individual images. We further introduce a global constraint-based matching process. It integrates a global matching constraint over the learned correspondence structure to exclude cross-view misalignments during the image patch matching process, hence achieving a more reliable matching score between images. Finally, we also extend our approach by introducing a multi-structure scheme, which learns a set of local correspondence structures to capture the spatial correspondence sub-patterns between a camera pair, so as to handle the spatial misalignments between individual images in a more precise way. Experimental results on various datasets demonstrate the effectiveness of our approach.\n    ",
        "submission_date": "2017-03-20T00:00:00",
        "last_modified_date": "2017-04-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.07022",
        "title": "Recurrent Topic-Transition GAN for Visual Paragraph Generation",
        "authors": [
            "Xiaodan Liang",
            "Zhiting Hu",
            "Hao Zhang",
            "Chuang Gan",
            "Eric P. Xing"
        ],
        "abstract": "A natural image usually conveys rich semantic content and can be viewed from different angles. Existing image description methods are largely restricted by small sets of biased visual paragraph annotations, and fail to cover rich underlying semantics. In this paper, we investigate a semi-supervised paragraph generative framework that is able to synthesize diverse and semantically coherent paragraph descriptions by reasoning over local semantic regions and exploiting linguistic knowledge. The proposed Recurrent Topic-Transition Generative Adversarial Network (RTT-GAN) builds an adversarial framework between a structured paragraph generator and multi-level paragraph discriminators. The paragraph generator generates sentences recurrently by incorporating region-based visual and language attention mechanisms at each step. The quality of generated paragraph sentences is assessed by multi-level adversarial discriminators from two aspects, namely, plausibility at sentence level and topic-transition coherence at paragraph level. The joint adversarial training of RTT-GAN drives the model to generate realistic paragraphs with smooth logical transition between sentence topics. Extensive quantitative experiments on image and video paragraph datasets demonstrate the effectiveness of our RTT-GAN in both supervised and semi-supervised settings. Qualitative results on telling diverse stories for an image also verify the interpretability of RTT-GAN.\n    ",
        "submission_date": "2017-03-21T00:00:00",
        "last_modified_date": "2017-03-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.07055",
        "title": "Investigation of Language Understanding Impact for Reinforcement Learning Based Dialogue Systems",
        "authors": [
            "Xiujun Li",
            "Yun-Nung Chen",
            "Lihong Li",
            "Jianfeng Gao",
            "Asli Celikyilmaz"
        ],
        "abstract": "Language understanding is a key component in a spoken dialogue system. In this paper, we investigate how the language understanding module influences the dialogue system performance by conducting a series of systematic experiments on a task-oriented neural dialogue system in a reinforcement learning based setting. The empirical study shows that among different types of language understanding errors, slot-level errors can have more impact on the overall performance of a dialogue system compared to intent-level errors. In addition, our experiments demonstrate that the reinforcement learning based dialogue system is able to learn when and what to confirm in order to achieve better performance and greater robustness.\n    ",
        "submission_date": "2017-03-21T00:00:00",
        "last_modified_date": "2017-03-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.07116",
        "title": "Interest-Driven Discovery of Local Process Models",
        "authors": [
            "Niek Tax",
            "Benjamin Dalmas",
            "Natalia Sidorova",
            "Wil M P van der Aalst",
            "Sylvie Norre"
        ],
        "abstract": "Local Process Models (LPM) describe structured fragments of process behavior occurring in the context of less structured business processes. Traditional LPM discovery aims to generate a collection of process models that describe highly frequent behavior, but these models do not always provide useful answers for questions posed by process analysts aiming at business process improvement. We propose a framework for goal-driven LPM discovery, based on utility functions and constraints. We describe four scopes on which these utility functions and constrains can be defined, and show that utility functions and constraints on different scopes can be combined to form composite utility functions/constraints. Finally, we demonstrate the applicability of our approach by presenting several actionable business insights discovered with LPM discovery on two real life data sets.\n    ",
        "submission_date": "2017-03-21T00:00:00",
        "last_modified_date": "2017-03-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.07255",
        "title": "ZM-Net: Real-time Zero-shot Image Manipulation Network",
        "authors": [
            "Hao Wang",
            "Xiaodan Liang",
            "Hao Zhang",
            "Dit-Yan Yeung",
            "Eric P. Xing"
        ],
        "abstract": "Many problems in image processing and computer vision (e.g. colorization, style transfer) can be posed as 'manipulating' an input image into a corresponding output image given a user-specified guiding signal. A holy-grail solution towards generic image manipulation should be able to efficiently alter an input image with any personalized signals (even signals unseen during training), such as diverse paintings and arbitrary descriptive attributes. However, existing methods are either inefficient to simultaneously process multiple signals (let alone generalize to unseen signals), or unable to handle signals from other modalities. In this paper, we make the first attempt to address the zero-shot image manipulation task. We cast this problem as manipulating an input image according to a parametric model whose key parameters can be conditionally generated from any guiding signal (even unseen ones). To this end, we propose the Zero-shot Manipulation Net (ZM-Net), a fully-differentiable architecture that jointly optimizes an image-transformation network (TNet) and a parameter network (PNet). The PNet learns to generate key transformation parameters for the TNet given any guiding signal while the TNet performs fast zero-shot image manipulation according to both signal-dependent parameters from the PNet and signal-invariant parameters from the TNet itself. Extensive experiments show that our ZM-Net can perform high-quality image manipulation conditioned on different forms of guiding signals (e.g. style images and attributes) in real-time (tens of milliseconds per image) even for unseen signals. Moreover, a large-scale style dataset with over 20,000 style images is also constructed to promote further research.\n    ",
        "submission_date": "2017-03-21T00:00:00",
        "last_modified_date": "2017-03-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.07381",
        "title": "Improving Statistical Multimedia Information Retrieval Model by using Ontology",
        "authors": [
            "Gagandeep Singh Narula",
            "Vishal Jain"
        ],
        "abstract": "A typical IR system that delivers and stores information is affected by problem of matching between user query and available content on web. Use of Ontology represents the extracted terms in form of network graph consisting of nodes, edges, index terms etc. The above mentioned IR approaches provide relevance thus satisfying users query. The paper also emphasis on analyzing multimedia documents and performs calculation for extracted terms using different statistical formulas. The proposed model developed reduces semantic gap and satisfies user needs efficiently.\n    ",
        "submission_date": "2017-03-21T00:00:00",
        "last_modified_date": "2017-03-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.07384",
        "title": "Ontology Based Pivoted normalization using Vector Based Approach for information Retrieval",
        "authors": [
            "Vishal Jain",
            "Dr. Mayank Singh"
        ],
        "abstract": "The proposed methodology is procedural i.e. it follows finite number of steps that extracts relevant documents according to users query. It is based on principles of Data Mining for analyzing web data. Data Mining first adapts integration of data to generate warehouse. Then, it extracts useful information with the help of algorithm. The task of representing extracted documents is done by using Vector Based Statistical Approach that represents each document in set of Terms.\n    ",
        "submission_date": "2017-03-21T00:00:00",
        "last_modified_date": "2017-03-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.07394",
        "title": "Deep Learning for Explicitly Modeling Optimization Landscapes",
        "authors": [
            "Shumeet Baluja"
        ],
        "abstract": "In all but the most trivial optimization problems, the structure of the solutions exhibit complex interdependencies between the input parameters. Decades of research with stochastic search techniques has shown the benefit of explicitly modeling the interactions between sets of parameters and the overall quality of the solutions discovered. We demonstrate a novel method, based on learning deep networks, to model the global landscapes of optimization problems. To represent the search space concisely and accurately, the deep networks must encode information about the underlying parameter interactions and their contributions to the quality of the solution. Once the networks are trained, the networks are probed to reveal parameter combinations with high expected performance with respect to the optimization task. These estimates are used to initialize fast, randomized, local search algorithms, which in turn expose more information about the search space that is subsequently used to refine the models. We demonstrate the technique on multiple optimization problems that have arisen in a variety of real-world domains, including: packing, graphics, job scheduling, layout and compression. The problems include combinatoric search spaces, discontinuous and highly non-linear spaces, and span binary, higher-cardinality discrete, as well as continuous parameters. Strengths, limitations, and extensions of the approach are extensively discussed and demonstrated.\n    ",
        "submission_date": "2017-03-21T00:00:00",
        "last_modified_date": "2017-03-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.07608",
        "title": "Deep Exploration via Randomized Value Functions",
        "authors": [
            "Ian Osband",
            "Benjamin Van Roy",
            "Daniel Russo",
            "Zheng Wen"
        ],
        "abstract": "We study the use of randomized value functions to guide deep exploration in reinforcement learning. This offers an elegant means for synthesizing statistically and computationally efficient exploration with common practical approaches to value function learning. We present several reinforcement learning algorithms that leverage randomized value functions and demonstrate their efficacy through computational studies. We also prove a regret bound that establishes statistical efficiency with a tabular representation.\n    ",
        "submission_date": "2017-03-22T00:00:00",
        "last_modified_date": "2019-09-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.07710",
        "title": "Unifying PAC and Regret: Uniform PAC Bounds for Episodic Reinforcement Learning",
        "authors": [
            "Christoph Dann",
            "Tor Lattimore",
            "Emma Brunskill"
        ],
        "abstract": "Statistical performance bounds for reinforcement learning (RL) algorithms can be critical for high-stakes applications like healthcare. This paper introduces a new framework for theoretically measuring the performance of such algorithms called Uniform-PAC, which is a strengthening of the classical Probably Approximately Correct (PAC) framework. In contrast to the PAC framework, the uniform version may be used to derive high probability regret guarantees and so forms a bridge between the two setups that has been missing in the literature. We demonstrate the benefits of the new framework for finite-state episodic MDPs with a new algorithm that is Uniform-PAC and simultaneously achieves optimal regret and PAC guarantees except for a factor of the horizon.\n    ",
        "submission_date": "2017-03-22T00:00:00",
        "last_modified_date": "2018-01-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.07758",
        "title": "Sample and Computationally Efficient Learning Algorithms under S-Concave Distributions",
        "authors": [
            "Maria-Florina Balcan",
            "Hongyang Zhang"
        ],
        "abstract": "We provide new results for noise-tolerant and sample-efficient learning algorithms under $s$-concave distributions. The new class of $s$-concave distributions is a broad and natural generalization of log-concavity, and includes many important additional distributions, e.g., the Pareto distribution and $t$-distribution. This class has been studied in the context of efficient sampling, integration, and optimization, but much remains unknown about the geometry of this class of distributions and their applications in the context of learning. The challenge is that unlike the commonly used distributions in learning (uniform or more generally log-concave distributions), this broader class is not closed under the marginalization operator and many such distributions are fat-tailed. In this work, we introduce new convex geometry tools to study the properties of $s$-concave distributions and use these properties to provide bounds on quantities of interest to learning including the probability of disagreement between two halfspaces, disagreement outside a band, and the disagreement coefficient. We use these results to significantly generalize prior results for margin-based active learning, disagreement-based active learning, and passive learning of intersections of halfspaces. Our analysis of geometric properties of $s$-concave distributions might be of independent interest to optimization more broadly.\n    ",
        "submission_date": "2017-03-22T00:00:00",
        "last_modified_date": "2018-01-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.07805",
        "title": "Supervised Typing of Big Graphs using Semantic Embeddings",
        "authors": [
            "Mayank Kejriwal",
            "Pedro Szekely"
        ],
        "abstract": "We propose a supervised algorithm for generating type embeddings in the same semantic vector space as a given set of entity embeddings. The algorithm is agnostic to the derivation of the underlying entity embeddings. It does not require any manual feature engineering, generalizes well to hundreds of types and achieves near-linear scaling on Big Graphs containing many millions of triples and instances by virtue of an incremental execution. We demonstrate the utility of the embeddings on a type recommendation task, outperforming a non-parametric feature-agnostic baseline while achieving 15x speedup and near-constant memory usage on a full partition of DBpedia. Using state-of-the-art visualization, we illustrate the agreement of our extensionally derived DBpedia type embeddings with the manually curated domain ontology. Finally, we use the embeddings to probabilistically cluster about 4 million DBpedia instances into 415 types in the DBpedia ontology.\n    ",
        "submission_date": "2017-03-22T00:00:00",
        "last_modified_date": "2017-03-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.07822",
        "title": "Information-theoretic Model Identification and Policy Search using Physics Engines with Application to Robotic Manipulation",
        "authors": [
            "Shaojun Zhu",
            "Andrew Kimmel",
            "Abdeslam Boularias"
        ],
        "abstract": "We consider the problem of a robot learning the mechanical properties of objects through physical interaction with the object, and introduce a practical, data-efficient approach for identifying the motion models of these objects. The proposed method utilizes a physics engine, where the robot seeks to identify the inertial and friction parameters of the object by simulating its motion under different values of the parameters and identifying those that result in a simulation which matches the observed real motions. The problem is solved in a Bayesian optimization framework. The same framework is used for both identifying the model of an object online and searching for a policy that would minimize a given cost function according to the identified model. Experimental results both in simulation and using a real robot indicate that the proposed method outperforms state-of-the-art model-free reinforcement learning approaches.\n    ",
        "submission_date": "2017-03-22T00:00:00",
        "last_modified_date": "2017-03-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.07928",
        "title": "Self corrective Perturbations for Semantic Segmentation and Classification",
        "authors": [
            "Swami Sankaranarayanan",
            "Arpit Jain",
            "Ser Nam Lim"
        ],
        "abstract": "Convolutional Neural Networks have been a subject of great importance over the past decade and great strides have been made in their utility for producing state of the art performance in many computer vision problems. However, the behavior of deep networks is yet to be fully understood and is still an active area of research. In this work, we present an intriguing behavior: pre-trained CNNs can be made to improve their predictions by structurally perturbing the input. We observe that these perturbations - referred as Guided Perturbations - enable a trained network to improve its prediction performance without any learning or change in network weights. We perform various ablative experiments to understand how these perturbations affect the local context and feature representations. Furthermore, we demonstrate that this idea can improve performance of several existing approaches on semantic segmentation and scene labeling tasks on the PASCAL VOC dataset and supervised classification tasks on MNIST and CIFAR10 datasets.\n    ",
        "submission_date": "2017-03-23T00:00:00",
        "last_modified_date": "2017-08-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.07940",
        "title": "Unsupervised Basis Function Adaptation for Reinforcement Learning",
        "authors": [
            "Edward Barker",
            "Charl Ras"
        ],
        "abstract": "When using reinforcement learning (RL) algorithms it is common, given a large state space, to introduce some form of approximation architecture for the value function (VF). The exact form of this architecture can have a significant effect on an agent's performance, however, and determining a suitable approximation architecture can often be a highly complex task. Consequently there is currently interest among researchers in the potential for allowing RL algorithms to adaptively generate (i.e. to learn) approximation architectures. One relatively unexplored method of adapting approximation architectures involves using feedback regarding the frequency with which an agent has visited certain states to guide which areas of the state space to approximate with greater detail. In this article we will: (a) informally discuss the potential advantages offered by such methods; (b) introduce a new algorithm based on such methods which adapts a state aggregation approximation architecture on-line and is designed for use in conjunction with SARSA; (c) provide theoretical results, in a policy evaluation setting, regarding this particular algorithm's complexity, convergence properties and potential to reduce VF error; and finally (d) test experimentally the extent to which this algorithm can improve performance given a number of different test problems. Taken together our results suggest that our algorithm (and potentially such methods more generally) can provide a versatile and computationally lightweight means of significantly boosting RL performance given suitable conditions which are commonly encountered in practice.\n    ",
        "submission_date": "2017-03-23T00:00:00",
        "last_modified_date": "2019-02-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.07948",
        "title": "Fast Stochastic Variance Reduced Gradient Method with Momentum Acceleration for Machine Learning",
        "authors": [
            "Fanhua Shang",
            "Yuanyuan Liu",
            "James Cheng",
            "Jiacheng Zhuo"
        ],
        "abstract": "Recently, research on accelerated stochastic gradient descent methods (e.g., SVRG) has made exciting progress (e.g., linear convergence for strongly convex problems). However, the best-known methods (e.g., Katyusha) requires at least two auxiliary variables and two momentum parameters. In this paper, we propose a fast stochastic variance reduction gradient (FSVRG) method, in which we design a novel update rule with the Nesterov's momentum and incorporate the technique of growing epoch size. FSVRG has only one auxiliary variable and one momentum weight, and thus it is much simpler and has much lower per-iteration complexity. We prove that FSVRG achieves linear convergence for strongly convex problems and the optimal $\\mathcal{O}(1/T^2)$ convergence rate for non-strongly convex problems, where $T$ is the number of outer-iterations. We also extend FSVRG to directly solve the problems with non-smooth component functions, such as SVM. Finally, we empirically study the performance of FSVRG for solving various machine learning problems such as logistic regression, ridge regression, Lasso and SVM. Our results show that FSVRG outperforms the state-of-the-art stochastic methods, including Katyusha.\n    ",
        "submission_date": "2017-03-23T00:00:00",
        "last_modified_date": "2017-04-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.07994",
        "title": "Containment for Rule-Based Ontology-Mediated Queries",
        "authors": [
            "Pablo Barcelo",
            "Gerald Berger",
            "Andreas Pieris"
        ],
        "abstract": "Many efforts have been dedicated to identifying restrictions on ontologies expressed as tuple-generating dependencies (tgds), a.k.a. existential rules, that lead to the decidability for the problem of answering ontology-mediated queries (OMQs). This has given rise to three families of formalisms: guarded, non-recursive, and sticky sets of tgds. In this work, we study the containment problem for OMQs expressed in such formalisms, which is a key ingredient for solving static analysis tasks associated with them. Our main contribution is the development of specially tailored techniques for OMQ containment under the classes of tgds stated above. This enables us to obtain sharp complexity bounds for the problems at hand, which in turn allow us to delimitate its practical applicability. We also apply our techniques to pinpoint the complexity of problems associated with two emerging applications of OMQ containment: distribution over components and UCQ rewritability of OMQs.\n    ",
        "submission_date": "2017-03-23T00:00:00",
        "last_modified_date": "2017-04-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.08041",
        "title": "Resolving the Complexity of Some Fundamental Problems in Computational Social Choice",
        "authors": [
            "Palash Dey"
        ],
        "abstract": "This thesis is in the area called computational social choice which is an intersection area of algorithms and social choice theory.\n    ",
        "submission_date": "2017-03-23T00:00:00",
        "last_modified_date": "2017-03-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.08044",
        "title": "Multilinear compressive sensing and an application to convolutional linear networks",
        "authors": [
            "Fran\u00e7ois Malgouyres",
            "Joseph Landsberg"
        ],
        "abstract": "We study a deep linear network endowed with a structure. It takes the form of a matrix $X$ obtained by multiplying $K$ matrices (called factors and corresponding to the action of the layers). The action of each layer (i.e. a factor) is obtained by applying a fixed linear operator to a vector of parameters satisfying a constraint. The number of layers is not limited. Assuming that $X$ is given and factors have been estimated, the error between the product of the estimated factors and $X$ (i.e. the reconstruction error) is either the statistical or the empirical risk.   In this paper, we provide necessary and sufficient conditions on the network topology under which a stability property holds. The stability property requires that the error on the parameters defining the factors (i.e. the stability of the recovered parameters) scales linearly with the reconstruction error (i.e. the risk). Therefore, under these conditions on the network topology, any successful learning task leads to stably defined features and therefore interpretable layers/network.In order to do so, we first evaluate how the Segre embedding and its inverse distort distances. Then, we show that  any deep structured linear network can be cast as a generic multilinear problem (that uses the Segre embedding). This is the {\\em tensorial lifting}. Using the tensorial lifting, we  provide necessary and sufficient conditions for the identifiability of the factors (up to a scale rearrangement). We finally provide the necessary and sufficient condition called \\NSPlong~(because of the analogy with the usual Null Space Property in the compressed sensing framework) which guarantees that  the stability property holds. We illustrate the theory with a practical example where the deep structured linear network is a convolutional linear network. As expected, the conditions are rather strong but not empty. A simple test on the network topology can be implemented to test if the condition holds.\n    ",
        "submission_date": "2017-03-23T00:00:00",
        "last_modified_date": "2023-02-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.08098",
        "title": "A survey of embedding models of entities and relationships for knowledge graph completion",
        "authors": [
            "Dat Quoc Nguyen"
        ],
        "abstract": "Knowledge graphs (KGs) of real-world facts about entities and their relationships are useful resources for a variety of natural language processing tasks. However, because knowledge graphs are typically incomplete, it is useful to perform knowledge graph completion or link prediction, i.e. predict whether a relationship not in the knowledge graph is likely to be true. This paper serves as a comprehensive survey of embedding models of entities and relationships for knowledge graph completion, summarizing up-to-date experimental results on standard benchmark datasets and pointing out potential future research directions.\n    ",
        "submission_date": "2017-03-23T00:00:00",
        "last_modified_date": "2020-10-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.08100",
        "title": "Semi-supervised Embedding in Attributed Networks with Outliers",
        "authors": [
            "Jiongqian Liang",
            "Peter Jacobs",
            "Jiankai Sun",
            "Srinivasan Parthasarathy"
        ],
        "abstract": "In this paper, we propose a novel framework, called Semi-supervised Embedding in Attributed Networks with Outliers (SEANO), to learn a low-dimensional vector representation that systematically captures the topological proximity, attribute affinity and label similarity of vertices in a partially labeled attributed network (PLAN). Our method is designed to work in both transductive and inductive settings while explicitly alleviating noise effects from outliers. Experimental results on various datasets drawn from the web, text and image domains demonstrate the advantages of SEANO over state-of-the-art methods in semi-supervised classification under transductive as well as inductive settings. We also show that a subset of parameters in SEANO is interpretable as outlier score and can significantly outperform baseline methods when applied for detecting network outliers. Finally, we present the use of SEANO in a challenging real-world setting -- flood mapping of satellite images and show that it is able to outperform modern remote sensing algorithms for this task.\n    ",
        "submission_date": "2017-03-23T00:00:00",
        "last_modified_date": "2018-04-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.08262",
        "title": "Supervisor Synthesis of POMDP based on Automata Learning",
        "authors": [
            "Xiaobin Zhang",
            "Bo Wu",
            "Hai Lin"
        ],
        "abstract": "As a general and thus popular model for autonomous systems, partially observable Markov decision process (POMDP) can capture uncertainties from different sources like sensing noises, actuation errors, and uncertain environments. However, its comprehensiveness makes the planning and control in POMDP difficult. Traditional POMDP planning problems target to find the optimal policy to maximize the expectation of accumulated rewards. But for safety critical applications, guarantees of system performance described by formal specifications are desired, which motivates us to consider formal methods to synthesize supervisor for POMDP. With system specifications given by Probabilistic Computation Tree Logic (PCTL), we propose a supervisory control framework with a type of deterministic finite automata (DFA), za-DFA, as the controller form. While the existing work mainly relies on optimization techniques to learn fixed-size finite state controllers (FSCs), we develop an $L^*$ learning based algorithm to determine both space and transitions of za-DFA. Membership queries and different oracles for conjectures are defined. The learning algorithm is sound and complete. An example is given in detailed steps to illustrate the supervisor synthesis algorithm.\n    ",
        "submission_date": "2017-03-24T00:00:00",
        "last_modified_date": "2017-03-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.08428",
        "title": "Calendar.help: Designing a Workflow-Based Scheduling Agent with Humans in the Loop",
        "authors": [
            "Justin Cranshaw",
            "Emad Elwany",
            "Todd Newman",
            "Rafal Kocielnik",
            "Bowen Yu",
            "Sandeep Soni",
            "Jaime Teevan",
            "Andr\u00e9s Monroy-Hern\u00e1ndez"
        ],
        "abstract": "Although information workers may complain about meetings, they are an essential part of their work life. Consequently, busy people spend a significant amount of time scheduling meetings. We present ",
        "submission_date": "2017-03-24T00:00:00",
        "last_modified_date": "2017-03-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.08475",
        "title": "Overcoming Catastrophic Forgetting by Incremental Moment Matching",
        "authors": [
            "Sang-Woo Lee",
            "Jin-Hwa Kim",
            "Jaehyun Jun",
            "Jung-Woo Ha",
            "Byoung-Tak Zhang"
        ],
        "abstract": "Catastrophic forgetting is a problem of neural networks that loses the information of the first task after training the second task. Here, we propose a method, i.e. incremental moment matching (IMM), to resolve this problem. IMM incrementally matches the moment of the posterior distribution of the neural network which is trained on the first and the second task, respectively. To make the search space of posterior parameter smooth, the IMM procedure is complemented by various transfer learning techniques including weight transfer, L2-norm of the old and the new parameter, and a variant of dropout with the old parameter. We analyze our approach on a variety of datasets including the MNIST, CIFAR-10, Caltech-UCSD-Birds, and Lifelog datasets. The experimental results show that IMM achieves state-of-the-art performance by balancing the information between an old and a new network.\n    ",
        "submission_date": "2017-03-24T00:00:00",
        "last_modified_date": "2018-01-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.08705",
        "title": "Comparing Rule-Based and Deep Learning Models for Patient Phenotyping",
        "authors": [
            "Sebastian Gehrmann",
            "Franck Dernoncourt",
            "Yeran Li",
            "Eric T. Carlson",
            "Joy T. Wu",
            "Jonathan Welt",
            "John Foote Jr.",
            "Edward T. Moseley",
            "David W. Grant",
            "Patrick D. Tyler",
            "Leo Anthony Celi"
        ],
        "abstract": "Objective: We investigate whether deep learning techniques for natural language processing (NLP) can be used efficiently for patient phenotyping. Patient phenotyping is a classification task for determining whether a patient has a medical condition, and is a crucial part of secondary analysis of healthcare data. We assess the performance of deep learning algorithms and compare them with classical NLP approaches.\n",
        "submission_date": "2017-03-25T00:00:00",
        "last_modified_date": "2017-03-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.08769",
        "title": "Open Vocabulary Scene Parsing",
        "authors": [
            "Hang Zhao",
            "Xavier Puig",
            "Bolei Zhou",
            "Sanja Fidler",
            "Antonio Torralba"
        ],
        "abstract": "Recognizing arbitrary objects in the wild has been a challenging problem due to the limitations of existing classification models and datasets. In this paper, we propose a new task that aims at parsing scenes with a large and open vocabulary, and several evaluation metrics are explored for this problem. Our proposed approach to this problem is a joint image pixel and word concept embeddings framework, where word concepts are connected by semantic relations. We validate the open vocabulary prediction ability of our framework on ADE20K dataset which covers a wide variety of scenes and objects. We further explore the trained joint embedding space to show its interpretability.\n    ",
        "submission_date": "2017-03-26T00:00:00",
        "last_modified_date": "2017-04-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.08825",
        "title": "Multi-Period Flexibility Forecast for Low Voltage Prosumers",
        "authors": [
            "Rui Pinto",
            "Ricardo Bessa",
            "Manuel Matos"
        ],
        "abstract": "Near-future electric distribution grids operation will have to rely on demand-side flexibility, both by implementation of demand response strategies and by taking advantage of the intelligent management of increasingly common small-scale energy storage. The Home energy management system (HEMS), installed at low voltage residential clients, will play a crucial role on the flexibility provision to both system operators and market players like aggregators. Modeling and forecasting multi-period flexibility from residential prosumers, such as battery storage and electric water heater, while complying with internal constraints (comfort levels, data privacy) and uncertainty is a complex task. This papers describes a computational method that is capable of efficiently learn and define the feasibility flexibility space from controllable resources connected to a HEMS. An Evolutionary Particle Swarm Optimization (EPSO) algorithm is adopted and reshaped to derive a set of feasible temporal trajectories for the residential net-load, considering storage, flexible appliances, and predefined costumer preferences, as well as load and photovoltaic (PV) forecast uncertainty. A support vector data description (SVDD) algorithm is used to build models capable of classifying feasible and non-feasible HEMS operating trajectories upon request from an optimization/control algorithm operated by a DSO or market player.\n    ",
        "submission_date": "2017-03-26T00:00:00",
        "last_modified_date": "2017-11-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.08840",
        "title": "InfoGAIL: Interpretable Imitation Learning from Visual Demonstrations",
        "authors": [
            "Yunzhu Li",
            "Jiaming Song",
            "Stefano Ermon"
        ],
        "abstract": "The goal of imitation learning is to mimic expert behavior without access to an explicit reward signal. Expert demonstrations provided by humans, however, often show significant variability due to latent factors that are typically not explicitly modeled. In this paper, we propose a new algorithm that can infer the latent structure of expert demonstrations in an unsupervised way. Our method, built on top of Generative Adversarial Imitation Learning, can not only imitate complex behaviors, but also learn interpretable and meaningful representations of complex behavioral data, including visual demonstrations. In the driving domain, we show that a model learned from human demonstrations is able to both accurately reproduce a variety of behaviors and accurately anticipate human actions using raw visual inputs. Compared with various baselines, our method can better capture the latent structure underlying expert demonstrations, often recovering semantically meaningful factors of variation in the data.\n    ",
        "submission_date": "2017-03-26T00:00:00",
        "last_modified_date": "2017-11-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.08862",
        "title": "Socially Aware Motion Planning with Deep Reinforcement Learning",
        "authors": [
            "Yu Fan Chen",
            "Michael Everett",
            "Miao Liu",
            "Jonathan P. How"
        ],
        "abstract": "For robotic vehicles to navigate safely and efficiently in pedestrian-rich environments, it is important to model subtle human behaviors and navigation rules (e.g., passing on the right). However, while instinctive to humans, socially compliant navigation is still difficult to quantify due to the stochasticity in people's behaviors. Existing works are mostly focused on using feature-matching techniques to describe and imitate human paths, but often do not generalize well since the feature values can vary from person to person, and even run to run. This work notes that while it is challenging to directly specify the details of what to do (precise mechanisms of human navigation), it is straightforward to specify what not to do (violations of social norms). Specifically, using deep reinforcement learning, this work develops a time-efficient navigation policy that respects common social norms. The proposed method is shown to enable fully autonomous navigation of a robotic vehicle moving at human walking speed in an environment with many pedestrians.\n    ",
        "submission_date": "2017-03-26T00:00:00",
        "last_modified_date": "2018-05-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.08944",
        "title": "Intelligent bidirectional rapidly-exploring random trees for optimal motion planning in complex cluttered environments",
        "authors": [
            "Ahmed Hussain Qureshi",
            "Yasar Ayaz"
        ],
        "abstract": "The sampling based motion planning algorithm known as Rapidly-exploring Random Trees (RRT) has gained the attention of many researchers due to their computational efficiency and effectiveness. Recently, a variant of RRT called RRT* has been proposed that ensures asymptotic optimality. Subsequently its bidirectional version has also been introduced in the literature known as Bidirectional-RRT* (B-RRT*). We introduce a new variant called Intelligent Bidirectional-RRT* (IB-RRT*) which is an improved variant of the optimal RRT* and bidirectional version of RRT* (B-RRT*) algorithms and is specially designed for complex cluttered environments. IB-RRT* utilizes the bidirectional trees approach and introduces intelligent sample insertion heuristic for fast convergence to the optimal path solution using uniform sampling heuristics. The proposed algorithm is evaluated theoretically and experimental results are presented that compares IB-RRT* with RRT* and B-RRT*. Moreover, experimental results demonstrate the superior efficiency of IB-RRT* in comparison with RRT* and B-RRT in complex cluttered environments.\n    ",
        "submission_date": "2017-03-27T00:00:00",
        "last_modified_date": "2017-03-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.09179",
        "title": "Transfer learning for music classification and regression tasks",
        "authors": [
            "Keunwoo Choi",
            "Gy\u00f6rgy Fazekas",
            "Mark Sandler",
            "Kyunghyun Cho"
        ],
        "abstract": "In this paper, we present a transfer learning approach for music classification and regression tasks. We propose to use a pre-trained convnet feature, a concatenated feature vector using the activations of feature maps of multiple layers in a trained convolutional network. We show how this convnet feature can serve as general-purpose music representation. In the experiments, a convnet is trained for music tagging and then transferred to other music-related classification and regression tasks. The convnet feature outperforms the baseline MFCC feature in all the considered tasks and several previous approaches that are aggregating MFCCs as well as low- and high-level music features.\n    ",
        "submission_date": "2017-03-27T00:00:00",
        "last_modified_date": "2017-09-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.09310",
        "title": "Adaptive Simulation-based Training of AI Decision-makers using Bayesian Optimization",
        "authors": [
            "Brett W. Israelsen",
            "Nisar Ahmed",
            "Kenneth Center",
            "Roderick Green",
            "Winston Bennett Jr"
        ],
        "abstract": "This work studies how an AI-controlled dog-fighting agent with tunable decision-making parameters can learn to optimize performance against an intelligent adversary, as measured by a stochastic objective function evaluated on simulated combat engagements. Gaussian process Bayesian optimization (GPBO) techniques are developed to automatically learn global Gaussian Process (GP) surrogate models, which provide statistical performance predictions in both explored and unexplored areas of the parameter space. This allows a learning engine to sample full-combat simulations at parameter values that are most likely to optimize performance and also provide highly informative data points for improving future predictions. However, standard GPBO methods do not provide a reliable surrogate model for the highly volatile objective functions found in aerial combat, and thus do not reliably identify global maxima. These issues are addressed by novel Repeat Sampling (RS) and Hybrid Repeat/Multi-point Sampling (HRMS) techniques. Simulation studies show that HRMS improves the accuracy of GP surrogate models, allowing AI decision-makers to more accurately predict performance and efficiently tune parameters.\n    ",
        "submission_date": "2017-03-27T00:00:00",
        "last_modified_date": "2017-07-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.09370",
        "title": "Ensembles of Deep LSTM Learners for Activity Recognition using Wearables",
        "authors": [
            "Yu Guan",
            "Thomas Ploetz"
        ],
        "abstract": "Recently, deep learning (DL) methods have been introduced very successfully into human activity recognition (HAR) scenarios in ubiquitous and wearable computing. Especially the prospect of overcoming the need for manual feature design combined with superior classification capabilities render deep neural networks very attractive for real-life HAR application. Even though DL-based approaches now outperform the state-of-the-art in a number of recognitions tasks of the field, yet substantial challenges remain. Most prominently, issues with real-life datasets, typically including imbalanced datasets and problematic data quality, still limit the effectiveness of activity recognition using wearables. In this paper we tackle such challenges through Ensembles of deep Long Short Term Memory (LSTM) networks. We have developed modified training procedures for LSTM networks and combine sets of diverse LSTM learners into classifier collectives. We demonstrate, both formally and empirically, that Ensembles of deep LSTM learners outperform the individual LSTM networks. Through an extensive experimental evaluation on three standard benchmarks (Opportunity, PAMAP2, Skoda) we demonstrate the excellent recognition capabilities of our approach and its potential for real-life applications of human activity recognition.\n    ",
        "submission_date": "2017-03-28T00:00:00",
        "last_modified_date": "2017-03-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.09387",
        "title": "Adversarial Transformation Networks: Learning to Generate Adversarial Examples",
        "authors": [
            "Shumeet Baluja",
            "Ian Fischer"
        ],
        "abstract": "Multiple different approaches of generating adversarial examples have been proposed to attack deep neural networks. These approaches involve either directly computing gradients with respect to the image pixels, or directly solving an optimization on the image pixels. In this work, we present a fundamentally new method for generating adversarial examples that is fast to execute and provides exceptional diversity of output. We efficiently train feed-forward neural networks in a self-supervised manner to generate adversarial examples against a target network or set of networks. We call such a network an Adversarial Transformation Network (ATN). ATNs are trained to generate adversarial examples that minimally modify the classifier's outputs given the original input, while constraining the new classification to match an adversarial target class. We present methods to train ATNs and analyze their effectiveness targeting a variety of MNIST classifiers as well as the latest state-of-the-art ImageNet classifier Inception ResNet v2.\n    ",
        "submission_date": "2017-03-28T00:00:00",
        "last_modified_date": "2017-03-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.09527",
        "title": "Is This a Joke? Detecting Humor in Spanish Tweets",
        "authors": [
            "Santiago Castro",
            "Mat\u00edas Cubero",
            "Diego Garat",
            "Guillermo Moncecchi"
        ],
        "abstract": "While humor has been historically studied from a psychological, cognitive and linguistic standpoint, its study from a computational perspective is an area yet to be explored in Computational Linguistics. There exist some previous works, but a characterization of humor that allows its automatic recognition and generation is far from being specified. In this work we build a crowdsourced corpus of labeled tweets, annotated according to its humor value, letting the annotators subjectively decide which are humorous. A humor classifier for Spanish tweets is assembled based on supervised learning, reaching a precision of 84% and a recall of 69%.\n    ",
        "submission_date": "2017-03-28T00:00:00",
        "last_modified_date": "2017-03-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.09684",
        "title": "An Analysis of Visual Question Answering Algorithms",
        "authors": [
            "Kushal Kafle",
            "Christopher Kanan"
        ],
        "abstract": "In visual question answering (VQA), an algorithm must answer text-based questions about images. While multiple datasets for VQA have been created since late 2014, they all have flaws in both their content and the way algorithms are evaluated on them. As a result, evaluation scores are inflated and predominantly determined by answering easier questions, making it difficult to compare different methods. In this paper, we analyze existing VQA algorithms using a new dataset. It contains over 1.6 million questions organized into 12 different categories. We also introduce questions that are meaningless for a given image to force a VQA system to reason about image content. We propose new evaluation schemes that compensate for over-represented question-types and make it easier to study the strengths and weaknesses of algorithms. We analyze the performance of both baseline and state-of-the-art VQA models, including multi-modal compact bilinear pooling (MCB), neural module networks, and recurrent answering units. Our experiments establish how attention helps certain categories more than others, determine which models work better than others, and explain how simple models (e.g. MLP) can surpass more complex models (MCB) by simply learning to answer large, easy question categories.\n    ",
        "submission_date": "2017-03-28T00:00:00",
        "last_modified_date": "2017-09-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.09700",
        "title": "Inverse Reinforcement Learning from Summary Data",
        "authors": [
            "Antti Kangasr\u00e4\u00e4si\u00f6",
            "Samuel Kaski"
        ],
        "abstract": "Inverse reinforcement learning (IRL) aims to explain observed strategic behavior by fitting reinforcement learning models to behavioral data. However, traditional IRL methods are only applicable when the observations are in the form of state-action paths. This assumption may not hold in many real-world modeling settings, where only partial or summarized observations are available. In general, we may assume that there is a summarizing function $\\sigma$, which acts as a filter between us and the true state-action paths that constitute the demonstration. Some initial approaches to extending IRL to such situations have been presented, but with very specific assumptions about the structure of $\\sigma$, such as that only certain state observations are missing. This paper instead focuses on the most general case of the problem, where no assumptions are made about the summarizing function, except that it can be evaluated. We demonstrate that inference is still possible. The paper presents exact and approximate inference algorithms that allow full posterior inference, which is particularly important for assessing parameter uncertainty in this challenging inference situation. Empirical scalability is demonstrated to reasonably sized problems, and practical applicability is demonstrated by estimating the posterior for a cognitive science RL model based on an observed user's task completion time only.\n    ",
        "submission_date": "2017-03-28T00:00:00",
        "last_modified_date": "2018-06-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.09784",
        "title": "Perception Driven Texture Generation",
        "authors": [
            "Yanhai Gan",
            "Huifang Chi",
            "Ying Gao",
            "Jun Liu",
            "Guoqiang Zhong",
            "Junyu Dong"
        ],
        "abstract": "This paper investigates a novel task of generating texture images from perceptual descriptions. Previous work on texture generation focused on either synthesis from examples or generation from procedural models. Generating textures from perceptual attributes have not been well studied yet. Meanwhile, perceptual attributes, such as directionality, regularity and roughness are important factors for human observers to describe a texture. In this paper, we propose a joint deep network model that combines adversarial training and perceptual feature regression for texture generation, while only random noise and user-defined perceptual attributes are required as input. In this model, a preliminary trained convolutional neural network is essentially integrated with the adversarial framework, which can drive the generated textures to possess given perceptual attributes. An important aspect of the proposed model is that, if we change one of the input perceptual features, the corresponding appearance of the generated textures will also be changed. We design several experiments to validate the effectiveness of the proposed method. The results show that the proposed method can produce high quality texture images with desired perceptual properties.\n    ",
        "submission_date": "2017-03-24T00:00:00",
        "last_modified_date": "2017-03-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.09794",
        "title": "Probabilistic Models for Computerized Adaptive Testing",
        "authors": [
            "Martin Plajner"
        ],
        "abstract": "In this paper we follow our previous research in the area of Computerized Adaptive Testing (CAT). We present three different methods for CAT. One of them, the item response theory, is a well established method, while the other two, Bayesian and neural networks, are new in the area of educational testing. In the first part of this paper, we present the concept of CAT and its advantages and disadvantages. We collected data from paper tests performed with grammar school students. We provide the summary of data used for our experiments in the second part. Next, we present three different model types for CAT. They are based on the item response theory, Bayesian networks, and neural networks. The general theory associated with each type is briefly explained and the utilization of these models for CAT is analyzed. Future research is outlined in the concluding part of the paper. It shows many interesting research paths that are important not only for CAT but also for other areas of artificial intelligence.\n    ",
        "submission_date": "2017-03-26T00:00:00",
        "last_modified_date": "2017-03-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.09845",
        "title": "Bringing Salary Transparency to the World: Computing Robust Compensation Insights via LinkedIn Salary",
        "authors": [
            "Krishnaram Kenthapadi",
            "Stuart Ambler",
            "Liang Zhang",
            "Deepak Agarwal"
        ],
        "abstract": "The recently launched LinkedIn Salary product has been designed with the goal of providing compensation insights to the world's professionals and thereby helping them optimize their earning potential. We describe the overall design and architecture of the statistical modeling system underlying this product. We focus on the unique data mining challenges while designing and implementing the system, and describe the modeling components such as Bayesian hierarchical smoothing that help to compute and present robust compensation insights to users. We report on extensive evaluation with nearly one year of de-identified compensation data collected from over one million LinkedIn users, thereby demonstrating the efficacy of the statistical models. We also highlight the lessons learned through the deployment of our system at LinkedIn.\n    ",
        "submission_date": "2017-03-29T00:00:00",
        "last_modified_date": "2017-09-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.09891",
        "title": "LabelBank: Revisiting Global Perspectives for Semantic Segmentation",
        "authors": [
            "Hexiang Hu",
            "Zhiwei Deng",
            "Guang-Tong Zhou",
            "Fei Sha",
            "Greg Mori"
        ],
        "abstract": "Semantic segmentation requires a detailed labeling of image pixels by object category. Information derived from local image patches is necessary to describe the detailed shape of individual objects. However, this information is ambiguous and can result in noisy labels. Global inference of image content can instead capture the general semantic concepts present. We advocate that holistic inference of image concepts provides valuable information for detailed pixel labeling. We propose a generic framework to leverage holistic information in the form of a LabelBank for pixel-level segmentation.\n",
        "submission_date": "2017-03-29T00:00:00",
        "last_modified_date": "2017-03-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.09902",
        "title": "Survey of the State of the Art in Natural Language Generation: Core tasks, applications and evaluation",
        "authors": [
            "Albert Gatt",
            "Emiel Krahmer"
        ],
        "abstract": "This paper surveys the current state of the art in Natural Language Generation (NLG), defined as the task of generating text or speech from non-linguistic input. A survey of NLG is timely in view of the changes that the field has undergone over the past decade or so, especially in relation to new (usually data-driven) methods, as well as new applications of NLG technology. This survey therefore aims to (a) give an up-to-date synthesis of research on the core tasks in NLG and the architectures adopted in which such tasks are organised; (b) highlight a number of relatively recent research topics that have arisen partly as a result of growing synergies between NLG and other areas of artificial intelligence; (c) draw attention to the challenges in NLG evaluation, relating them to similar challenges faced in other areas of Natural Language Processing, with an emphasis on different evaluation methods and the relationships between them.\n    ",
        "submission_date": "2017-03-29T00:00:00",
        "last_modified_date": "2018-01-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.10121",
        "title": "The Top 10 Topics in Machine Learning Revisited: A Quantitative Meta-Study",
        "authors": [
            "Patrick Glauner",
            "Manxing Du",
            "Victor Paraschiv",
            "Andrey Boytsov",
            "Isabel Lopez Andrade",
            "Jorge Meira",
            "Petko Valtchev",
            "Radu State"
        ],
        "abstract": "Which topics of machine learning are most commonly addressed in research? This question was initially answered in 2007 by doing a qualitative survey among distinguished researchers. In our study, we revisit this question from a quantitative perspective. Concretely, we collect 54K abstracts of papers published between 2007 and 2016 in leading machine learning journals and conferences. We then use machine learning in order to determine the top 10 topics in machine learning. We not only include models, but provide a holistic view across optimization, data, features, etc. This quantitative approach allows reducing the bias of surveys. It reveals new and up-to-date insights into what the 10 most prolific topics in machine learning research are. This allows researchers to identify popular topics as well as new and rising topics for their research.\n    ",
        "submission_date": "2017-03-29T00:00:00",
        "last_modified_date": "2017-03-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.10251",
        "title": "Dialectical Rough Sets, Parthood and Figures of Opposition-1",
        "authors": [
            "A. Mani"
        ],
        "abstract": "In one perspective, the main theme of this research revolves around the inverse problem in the context of general rough sets that concerns the existence of rough basis for given approximations in a context. Granular operator spaces and variants were recently introduced by the present author as an optimal framework for anti-chain based algebraic semantics of general rough sets and the inverse problem. In the framework, various sub-types of crisp and non-crisp objects are identifiable that may be missed in more restrictive formalism. This is also because in the latter cases concepts of complementation and negation are taken for granted - while in reality they have a complicated dialectical basis. This motivates a general approach to dialectical rough sets building on previous work of the present author and figures of opposition. In this paper dialectical rough logics are invented from a semantic perspective, a concept of dialectical predicates is formalised, connection with dialetheias and glutty negation are established, parthood analyzed and studied from the viewpoint of classical and dialectical figures of opposition by the present author. Her methods become more geometrical and encompass parthood as a primary relation (as opposed to roughly equivalent objects) for algebraic semantics.\n    ",
        "submission_date": "2017-03-29T00:00:00",
        "last_modified_date": "2018-11-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.10254",
        "title": "Bandit-Based Model Selection for Deformable Object Manipulation",
        "authors": [
            "Dale McConachie",
            "Dmitry Berenson"
        ],
        "abstract": "We present a novel approach to deformable object manipulation that does not rely on highly-accurate modeling. The key contribution of this paper is to formulate the task as a Multi-Armed Bandit problem, with each arm representing a model of the deformable object. To \"pull\" an arm and evaluate its utility, we use the arm's model to generate a velocity command for the gripper(s) holding the object and execute it. As the task proceeds and the object deforms, the utility of each model can change. Our framework estimates these changes and balances exploration of the model set with exploitation of high-utility models. We also propose an approach based on Kalman Filtering for Non-stationary Multi-armed Normal Bandits (KF-MANB) to leverage the coupling between models to learn more from each arm pull. We demonstrate that our method outperforms previous methods on synthetic trials, and performs competitively on several manipulation tasks in simulation.\n    ",
        "submission_date": "2017-03-29T00:00:00",
        "last_modified_date": "2017-03-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.10371",
        "title": "Born to Learn: the Inspiration, Progress, and Future of Evolved Plastic Artificial Neural Networks",
        "authors": [
            "Andrea Soltoggio",
            "Kenneth O. Stanley",
            "Sebastian Risi"
        ],
        "abstract": "Biological plastic neural networks are systems of extraordinary computational capabilities shaped by evolution, development, and lifetime learning. The interplay of these elements leads to the emergence of adaptive behavior and intelligence. Inspired by such intricate natural phenomena, Evolved Plastic Artificial Neural Networks (EPANNs) use simulated evolution in-silico to breed plastic neural networks with a large variety of dynamics, architectures, and plasticity rules: these artificial systems are composed of inputs, outputs, and plastic components that change in response to experiences in an environment. These systems may autonomously discover novel adaptive algorithms, and lead to hypotheses on the emergence of biological adaptation. EPANNs have seen considerable progress over the last two decades. Current scientific and technological advances in artificial neural networks are now setting the conditions for radically new approaches and results. In particular, the limitations of hand-designed networks could be overcome by more flexible and innovative solutions. This paper brings together a variety of inspiring ideas that define the field of EPANNs. The main methods and results are reviewed. Finally, new opportunities and developments are presented.\n    ",
        "submission_date": "2017-03-30T00:00:00",
        "last_modified_date": "2018-08-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.10476",
        "title": "Speaking the Same Language: Matching Machine to Human Captions by Adversarial Training",
        "authors": [
            "Rakshith Shetty",
            "Marcus Rohrbach",
            "Lisa Anne Hendricks",
            "Mario Fritz",
            "Bernt Schiele"
        ],
        "abstract": "While strong progress has been made in image captioning over the last years, machine and human captions are still quite distinct. A closer look reveals that this is due to the deficiencies in the generated word distribution, vocabulary size, and strong bias in the generators towards frequent captions. Furthermore, humans -- rightfully so -- generate multiple, diverse captions, due to the inherent ambiguity in the captioning task which is not considered in today's systems.\n",
        "submission_date": "2017-03-30T00:00:00",
        "last_modified_date": "2017-11-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.10545",
        "title": "FairJudge: Trustworthy User Prediction in Rating Platforms",
        "authors": [
            "Srijan Kumar",
            "Bryan Hooi",
            "Disha Makhija",
            "Mohit Kumar",
            "Christos Faloutsos",
            "V.S. Subrahamanian"
        ],
        "abstract": "Rating platforms enable large-scale collection of user opinion about items (products, other users, etc.). However, many untrustworthy users give fraudulent ratings for excessive monetary gains. In the paper, we present FairJudge, a system to identify such fraudulent users. We propose three metrics: (i) the fairness of a user that quantifies how trustworthy the user is in rating the products, (ii) the reliability of a rating that measures how reliable the rating is, and (iii) the goodness of a product that measures the quality of the product. Intuitively, a user is fair if it provides reliable ratings that are close to the goodness of the product. We formulate a mutually recursive definition of these metrics, and further address cold start problems and incorporate behavioral properties of users and products in the formulation. We propose an iterative algorithm, FairJudge, to predict the values of the three metrics. We prove that FairJudge is guaranteed to converge in a bounded number of iterations, with linear time complexity. By conducting five different experiments on five rating platforms, we show that FairJudge significantly outperforms nine existing algorithms in predicting fair and unfair users. We reported the 100 most unfair users in the Flipkart network to their review fraud investigators, and 80 users were correctly identified (80% accuracy). The FairJudge algorithm is already being deployed at Flipkart.\n    ",
        "submission_date": "2017-03-30T00:00:00",
        "last_modified_date": "2017-03-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.10571",
        "title": "Bootstrapping Labelled Dataset Construction for Cow Tracking and Behavior Analysis",
        "authors": [
            "Aram Ter-Sarkisov",
            "Robert Ross",
            "John Kelleher"
        ],
        "abstract": "This paper introduces a new approach to the long-term tracking of an object in a challenging environment. The object is a cow and the environment is an enclosure in a cowshed. Some of the key challenges in this domain are a cluttered background, low contrast and high similarity between moving objects which greatly reduces the efficiency of most existing approaches, including those based on background subtraction. Our approach is split into object localization, instance segmentation, learning and tracking stages. Our solution is compared to a range of semi-supervised object tracking algorithms and we show that the performance is strong and well suited to subsequent analysis. We present our solution as a first step towards broader tracking and behavior monitoring for cows in precision agriculture with the ultimate objective of early detection of lameness.\n    ",
        "submission_date": "2017-03-30T00:00:00",
        "last_modified_date": "2017-03-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.10651",
        "title": "Reliable Decision Support using Counterfactual Models",
        "authors": [
            "Peter Schulam",
            "Suchi Saria"
        ],
        "abstract": "Decision-makers are faced with the challenge of estimating what is likely to happen when they take an action. For instance, if I choose not to treat this patient, are they likely to die? Practitioners commonly use supervised learning algorithms to fit predictive models that help decision-makers reason about likely future outcomes, but we show that this approach is unreliable, and sometimes even dangerous. The key issue is that supervised learning algorithms are highly sensitive to the policy used to choose actions in the training data, which causes the model to capture relationships that do not generalize. We propose using a different learning objective that predicts counterfactuals instead of predicting outcomes under an existing action policy as in supervised learning. To support decision-making in temporal settings, we introduce the Counterfactual Gaussian Process (CGP) to predict the counterfactual future progression of continuous-time trajectories under sequences of future actions. We demonstrate the benefits of the CGP on two important decision-support tasks: risk prediction and \"what if?\" reasoning for individualized treatment planning.\n    ",
        "submission_date": "2017-03-30T00:00:00",
        "last_modified_date": "2018-02-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.10847",
        "title": "MidiNet: A Convolutional Generative Adversarial Network for Symbolic-domain Music Generation",
        "authors": [
            "Li-Chia Yang",
            "Szu-Yu Chou",
            "Yi-Hsuan Yang"
        ],
        "abstract": "Most existing neural network models for music generation use recurrent neural networks. However, the recent WaveNet model proposed by DeepMind shows that convolutional neural networks (CNNs) can also generate realistic musical waveforms in the audio domain. Following this light, we investigate using CNNs for generating melody (a series of MIDI notes) one bar after another in the symbolic domain. In addition to the generator, we use a discriminator to learn the distributions of melodies, making it a generative adversarial network (GAN). Moreover, we propose a novel conditional mechanism to exploit available prior knowledge, so that the model can generate melodies either from scratch, by following a chord sequence, or by conditioning on the melody of previous bars (e.g. a priming melody), among other possibilities. The resulting model, named MidiNet, can be expanded to generate music with multiple MIDI channels (i.e. tracks). We conduct a user study to compare the melody of eight-bar long generated by MidiNet and by Google's MelodyRNN models, each time using the same priming melody. Result shows that MidiNet performs comparably with MelodyRNN models in being realistic and pleasant to listen to, yet MidiNet's melodies are reported to be much more interesting.\n    ",
        "submission_date": "2017-03-31T00:00:00",
        "last_modified_date": "2017-07-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.10926",
        "title": "EMULATOR vs REAL PHONE: Android Malware Detection Using Machine Learning",
        "authors": [
            "Mohammed K. Alzaylaee",
            "Suleiman Y. Yerima",
            "Sakir Sezer"
        ],
        "abstract": "The Android operating system has become the most popular operating system for smartphones and tablets leading to a rapid rise in malware. Sophisticated Android malware employ detection avoidance techniques in order to hide their malicious activities from analysis tools. These include a wide range of anti-emulator techniques, where the malware programs attempt to hide their malicious activities by detecting the emulator. For this reason, countermeasures against antiemulation are becoming increasingly important in Android malware detection. Analysis and detection based on real devices can alleviate the problems of anti-emulation as well as improve the effectiveness of dynamic analysis. Hence, in this paper we present an investigation of machine learning based malware detection using dynamic analysis on real devices. A tool is implemented to automatically extract dynamic features from Android phones and through several experiments, a comparative analysis of emulator based vs. device based detection by means of several machine learning algorithms is undertaken. Our study shows that several features could be extracted more effectively from the on-device dynamic analysis compared to emulators. It was also found that approximately 24% more apps were successfully analysed on the phone. Furthermore, all of the studied machine learning based detection performed better when applied to features extracted from the on-device dynamic analysis.\n    ",
        "submission_date": "2017-03-31T00:00:00",
        "last_modified_date": "2017-03-31T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.10960",
        "title": "Learning Discourse-level Diversity for Neural Dialog Models using Conditional Variational Autoencoders",
        "authors": [
            "Tiancheng Zhao",
            "Ran Zhao",
            "Maxine Eskenazi"
        ],
        "abstract": "While recent neural encoder-decoder models have shown great promise in modeling open-domain conversations, they often generate dull and generic responses. Unlike past work that has focused on diversifying the output of the decoder at word-level to alleviate this problem, we present a novel framework based on conditional variational autoencoders that captures the discourse-level diversity in the encoder. Our model uses latent variables to learn a distribution over potential conversational intents and generates diverse responses using only greedy decoders. We have further developed a novel variant that is integrated with linguistic prior knowledge for better performance. Finally, the training procedure is improved by introducing a bag-of-word loss. Our proposed models have been validated to generate significantly more diverse responses than baseline approaches and exhibit competence in discourse-level decision-making.\n    ",
        "submission_date": "2017-03-31T00:00:00",
        "last_modified_date": "2017-10-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1703.11000",
        "title": "Learning Visual Servoing with Deep Features and Fitted Q-Iteration",
        "authors": [
            "Alex X. Lee",
            "Sergey Levine",
            "Pieter Abbeel"
        ],
        "abstract": "Visual servoing involves choosing actions that move a robot in response to observations from a camera, in order to reach a goal configuration in the world. Standard visual servoing approaches typically rely on manually designed features and analytical dynamics models, which limits their generalization capability and often requires extensive application-specific feature and model engineering. In this work, we study how learned visual features, learned predictive dynamics models, and reinforcement learning can be combined to learn visual servoing mechanisms. We focus on target following, with the goal of designing algorithms that can learn a visual servo using low amounts of data of the target in question, to enable quick adaptation to new targets. Our approach is based on servoing the camera in the space of learned visual features, rather than image pixels or manually-designed keypoints. We demonstrate that standard deep features, in our case taken from a model trained for object classification, can be used together with a bilinear predictive model to learn an effective visual servo that is robust to visual variation, changes in viewing angle and appearance, and occlusions. A key component of our approach is to use a sample-efficient fitted Q-iteration algorithm to learn which features are best suited for the task at hand. We show that we can learn an effective visual servo on a complex synthetic car following benchmark using just 20 training trajectory samples for reinforcement learning. We demonstrate substantial improvement over a conventional approach based on image pixels or hand-designed keypoints, and we show an improvement in sample-efficiency of more than two orders of magnitude over standard model-free deep reinforcement learning algorithms. Videos are available at ",
        "submission_date": "2017-03-31T00:00:00",
        "last_modified_date": "2017-07-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.00023",
        "title": "On the Reliable Detection of Concept Drift from Streaming Unlabeled Data",
        "authors": [
            "Tegjyot Singh Sethi",
            "Mehmed Kantardzic"
        ],
        "abstract": "Classifiers deployed in the real world operate in a dynamic environment, where the data distribution can change over time. These changes, referred to as concept drift, can cause the predictive performance of the classifier to drop over time, thereby making it obsolete. To be of any real use, these classifiers need to detect drifts and be able to adapt to them, over time. Detecting drifts has traditionally been approached as a supervised task, with labeled data constantly being used for validating the learned model. Although effective in detecting drifts, these techniques are impractical, as labeling is a difficult, costly and time consuming activity. On the other hand, unsupervised change detection techniques are unreliable, as they produce a large number of false alarms. The inefficacy of the unsupervised techniques stems from the exclusion of the characteristics of the learned classifier, from the detection process. In this paper, we propose the Margin Density Drift Detection (MD3) algorithm, which tracks the number of samples in the uncertainty region of a classifier, as a metric to detect drift. The MD3 algorithm is a distribution independent, application independent, model independent, unsupervised and incremental algorithm for reliably detecting drifts from data streams. Experimental evaluation on 6 drift induced datasets and 4 additional datasets from the cybersecurity domain demonstrates that the MD3 approach can reliably detect drifts, with significantly fewer false alarms compared to unsupervised feature based drift detectors. The reduced false alarms enables the signaling of drifts only when they are most likely to affect classification performance. As such, the MD3 approach leads to a detection scheme which is credible, label efficient and general in its applicability.\n    ",
        "submission_date": "2017-03-31T00:00:00",
        "last_modified_date": "2017-03-31T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.00115",
        "title": "Ontological Multidimensional Data Models and Contextual Data Qality",
        "authors": [
            "Leopoldo Bertossi",
            "Mostafa Milani"
        ],
        "abstract": "Data quality assessment and data cleaning are context-dependent activities. Motivated by this observation, we propose the Ontological Multidimensional Data Model (OMD model), which can be used to model and represent contexts as logic-based ontologies. The data under assessment is mapped into the context, for additional analysis, processing, and quality data extraction. The resulting contexts allow for the representation of dimensions, and multidimensional data quality assessment becomes possible. At the core of a multidimensional context we include a generalized multidimensional data model and a Datalog+/- ontology with provably good properties in terms of query answering. These main components are used to represent dimension hierarchies, dimensional constraints, dimensional rules, and define predicates for quality data specification. Query answering relies upon and triggers navigation through dimension hierarchies, and becomes the basic tool for the extraction of quality data. The OMD model is interesting per se, beyond applications to data quality. It allows for a logic-based, and computationally tractable representation of multidimensional data, extending previous multidimensional data models with additional expressive power and functionalities.\n    ",
        "submission_date": "2017-04-01T00:00:00",
        "last_modified_date": "2017-08-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.00217",
        "title": "Adversarial Connective-exploiting Networks for Implicit Discourse Relation Classification",
        "authors": [
            "Lianhui Qin",
            "Zhisong Zhang",
            "Hai Zhao",
            "Zhiting Hu",
            "Eric P. Xing"
        ],
        "abstract": "Implicit discourse relation classification is of great challenge due to the lack of connectives as strong linguistic cues, which motivates the use of annotated implicit connectives to improve the recognition. We propose a feature imitation framework in which an implicit relation network is driven to learn from another neural network with access to connectives, and thus encouraged to extract similarly salient features for accurate classification. We develop an adversarial model to enable an adaptive imitation scheme through competition between the implicit network and a rival feature discriminator. Our method effectively transfers discriminability of connectives to the implicit features, and achieves state-of-the-art performance on the PDTB benchmark.\n    ",
        "submission_date": "2017-04-01T00:00:00",
        "last_modified_date": "2017-04-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.00260",
        "title": "Aligned Image-Word Representations Improve Inductive Transfer Across Vision-Language Tasks",
        "authors": [
            "Tanmay Gupta",
            "Kevin Shih",
            "Saurabh Singh",
            "Derek Hoiem"
        ],
        "abstract": "An important goal of computer vision is to build systems that learn visual representations over time that can be applied to many tasks. In this paper, we investigate a vision-language embedding as a core representation and show that it leads to better cross-task transfer than standard multi-task learning. In particular, the task of visual recognition is aligned to the task of visual question answering by forcing each to use the same word-region embeddings. We show this leads to greater inductive transfer from recognition to VQA than standard multitask learning. Visual recognition also improves, especially for categories that have relatively few recognition training labels but appear often in the VQA setting. Thus, our paper takes a small step towards creating more general vision systems by showing the benefit of interpretable, flexible, and trainable core representations.\n    ",
        "submission_date": "2017-04-02T00:00:00",
        "last_modified_date": "2017-10-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.00264",
        "title": "Potential Functions based Sampling Heuristic For Optimal Path Planning",
        "authors": [
            "Ahmed Hussain Qureshi",
            "Yasar Ayaz"
        ],
        "abstract": "Rapidly-exploring Random Tree Star(RRT*) is a recently proposed extension of Rapidly-exploring Random Tree (RRT) algorithm that provides a collision-free, asymptotically optimal path regardless of obstacle's geometry in a given environment. However, one of the limitations in the RRT* algorithm is slow convergence to optimal path solution. As a result, it consumes high memory as well as time due to a large number of iterations utilised in achieving optimal path solution. To overcome these limitations, we propose the Potential Function Based-RRT* (P-RRT*) that incorporates the Artificial Potential Field Algorithm in RRT*. The proposed algorithm allows a considerable decrease in the number of iterations and thus leads to more efficient memory utilization and an accelerated convergence rate. In order to illustrate the usefulness of the proposed algorithm in terms of space execution and convergence rate, this paper presents rigorous simulation based comparisons between the proposed techniques and RRT* under different environmental conditions. Moreover, both algorithms are also tested and compared under non-holonomic differential constraints.\n    ",
        "submission_date": "2017-04-02T00:00:00",
        "last_modified_date": "2017-04-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.00514",
        "title": "Multi-Task Learning of Keyphrase Boundary Classification",
        "authors": [
            "Isabelle Augenstein",
            "Anders S\u00f8gaard"
        ],
        "abstract": "Keyphrase boundary classification (KBC) is the task of detecting keyphrases in scientific articles and labelling them with respect to predefined types. Although important in practice, this task is so far underexplored, partly due to the lack of labelled data. To overcome this, we explore several auxiliary tasks, including semantic super-sense tagging and identification of multi-word expressions, and cast the task as a multi-task learning problem with deep recurrent neural networks. Our multi-task models perform significantly better than previous state of the art approaches on two scientific KBC datasets, particularly for long keyphrases.\n    ",
        "submission_date": "2017-04-03T00:00:00",
        "last_modified_date": "2017-04-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.00616",
        "title": "Chained Multi-stream Networks Exploiting Pose, Motion, and Appearance for Action Classification and Detection",
        "authors": [
            "Mohammadreza Zolfaghari",
            "Gabriel L. Oliveira",
            "Nima Sedaghat",
            "Thomas Brox"
        ],
        "abstract": "General human action recognition requires understanding of various visual cues. In this paper, we propose a network architecture that computes and integrates the most important visual cues for action recognition: pose, motion, and the raw images. For the integration, we introduce a Markov chain model which adds cues successively. The resulting approach is efficient and applicable to action classification as well as to spatial and temporal action localization. The two contributions clearly improve the performance over respective baselines. The overall approach achieves state-of-the-art action classification performance on HMDB51, J-HMDB and NTU RGB+D datasets. Moreover, it yields state-of-the-art spatio-temporal action localization results on UCF101 and J-HMDB.\n    ",
        "submission_date": "2017-04-03T00:00:00",
        "last_modified_date": "2017-05-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.00637",
        "title": "Semi-Supervised Generation with Cluster-aware Generative Models",
        "authors": [
            "Lars Maal\u00f8e",
            "Marco Fraccaro",
            "Ole Winther"
        ],
        "abstract": "Deep generative models trained with large amounts of unlabelled data have proven to be powerful within the domain of unsupervised learning. Many real life data sets contain a small amount of labelled data points, that are typically disregarded when training generative models. We propose the Cluster-aware Generative Model, that uses unlabelled information to infer a latent representation that models the natural clustering of the data, and additional labelled data points to refine this clustering. The generative performances of the model significantly improve when labelled information is exploited, obtaining a log-likelihood of -79.38 nats on permutation invariant MNIST, while also achieving competitive semi-supervised classification accuracies. The model can also be trained fully unsupervised, and still improve the log-likelihood performance with respect to related methods.\n    ",
        "submission_date": "2017-04-03T00:00:00",
        "last_modified_date": "2017-04-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.00717",
        "title": "It Takes Two to Tango: Towards Theory of AI's Mind",
        "authors": [
            "Arjun Chandrasekaran",
            "Deshraj Yadav",
            "Prithvijit Chattopadhyay",
            "Viraj Prabhu",
            "Devi Parikh"
        ],
        "abstract": "Theory of Mind is the ability to attribute mental states (beliefs, intents, knowledge, perspectives, etc.) to others and recognize that these mental states may differ from one's own. Theory of Mind is critical to effective communication and to teams demonstrating higher collective performance. To effectively leverage the progress in Artificial Intelligence (AI) to make our lives more productive, it is important for humans and AI to work well together in a team. Traditionally, there has been much emphasis on research to make AI more accurate, and (to a lesser extent) on having it better understand human intentions, tendencies, beliefs, and contexts. The latter involves making AI more human-like and having it develop a theory of our minds. In this work, we argue that for human-AI teams to be effective, humans must also develop a theory of AI's mind (ToAIM) - get to know its strengths, weaknesses, beliefs, and quirks. We instantiate these ideas within the domain of Visual Question Answering (VQA). We find that using just a few examples (50), lay people can be trained to better predict responses and oncoming failures of a complex VQA model. We further evaluate the role existing explanation (or interpretability) modalities play in helping humans build ToAIM. Explainable AI has received considerable scientific and popular attention in recent times. Surprisingly, we find that having access to the model's internal states - its confidence in its top-k predictions, explicit or implicit attention maps which highlight regions in the image (and words in the question) the model is looking at (and listening to) while answering a question about an image - do not help people better predict its behavior.\n    ",
        "submission_date": "2017-04-03T00:00:00",
        "last_modified_date": "2017-10-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.00725",
        "title": "Reprogramming Matter, Life, and Purpose",
        "authors": [
            "Hector Zenil"
        ],
        "abstract": "Reprogramming matter may sound far-fetched, but we have been doing it with increasing power and staggering efficiency for at least 60 years, and for centuries we have been paving the way toward the ultimate reprogrammed fate of the universe, the vessel of all programs. How will we be doing it in 60 years' time and how will it impact life and the purpose both of machines and of humans?\n    ",
        "submission_date": "2017-04-02T00:00:00",
        "last_modified_date": "2017-08-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.00756",
        "title": "Multi-Advisor Reinforcement Learning",
        "authors": [
            "Romain Laroche",
            "Mehdi Fatemi",
            "Joshua Romoff",
            "Harm van Seijen"
        ],
        "abstract": "We consider tackling a single-agent RL problem by distributing it to $n$ learners. These learners, called advisors, endeavour to solve the problem from a different focus. Their advice, taking the form of action values, is then communicated to an aggregator, which is in control of the system. We show that the local planning method for the advisors is critical and that none of the ones found in the literature is flawless: the egocentric planning overestimates values of states where the other advisors disagree, and the agnostic planning is inefficient around danger zones. We introduce a novel approach called empathic and discuss its theoretical aspects. We empirically examine and validate our theoretical findings on a fruit collection task.\n    ",
        "submission_date": "2017-04-03T00:00:00",
        "last_modified_date": "2017-11-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.00917",
        "title": "Deriving Probability Density Functions from Probabilistic Functional Programs",
        "authors": [
            "Sooraj Bhat",
            "Johannes Borgstr\u00f6m",
            "Andrew D. Gordon",
            "Claudio Russo"
        ],
        "abstract": "The probability density function of a probability distribution is a fundamental concept in probability theory and a key ingredient in various widely used machine learning methods. However, the necessary framework for compiling probabilistic functional programs to density functions has only recently been developed. In this work, we present a density compiler for a probabilistic language with failure and both discrete and continuous distributions, and provide a proof of its soundness. The compiler greatly reduces the development effort of domain experts, which we demonstrate by solving inference problems from various scientific applications, such as modelling the global carbon cycle, using a standard Markov chain Monte Carlo framework.\n    ",
        "submission_date": "2017-04-04T00:00:00",
        "last_modified_date": "2017-06-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.01074",
        "title": "Emotional Chatting Machine: Emotional Conversation Generation with Internal and External Memory",
        "authors": [
            "Hao Zhou",
            "Minlie Huang",
            "Tianyang Zhang",
            "Xiaoyan Zhu",
            "Bing Liu"
        ],
        "abstract": "Perception and expression of emotion are key factors to the success of dialogue systems or conversational agents. However, this problem has not been studied in large-scale conversation generation so far. In this paper, we propose Emotional Chatting Machine (ECM) that can generate appropriate responses not only in content (relevant and grammatical) but also in emotion (emotionally consistent). To the best of our knowledge, this is the first work that addresses the emotion factor in large-scale conversation generation. ECM addresses the factor using three new mechanisms that respectively (1) models the high-level abstraction of emotion expressions by embedding emotion categories, (2) captures the change of implicit internal emotion states, and (3) uses explicit emotion expressions with an external emotion vocabulary. Experiments show that the proposed model can generate responses appropriate not only in content but also in emotion.\n    ",
        "submission_date": "2017-04-04T00:00:00",
        "last_modified_date": "2018-06-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.01148",
        "title": "The Qualia-Singularity Correspondence Theory (QSCT): A Topological Account of Consciousness",
        "authors": [
            "T.R. Lima"
        ],
        "abstract": "Why does anything feel like anything at all? This \"hard problem\" of consciousness has haunted philosophy and science for centuries. The Qualia-Singularity Correspondence Theory (QSCT) proposes that conscious experience emerges precisely where quantitative description fails in a specific, structured way. QSCT identifies consciousness with Q-singularities -- moments when a system's dynamics undergo simultaneous collapse (rank-drop) of two mathematical structures: the Fisher-Rao metric (governing external distinguishability) and the Jacobian matrix (governing internal dynamics). At these points, the system becomes simultaneously unmeasurable from outside and causally knotted within, with only its own trajectory surviving. This dual collapse naturally produces consciousness's five hallmarks: privacy, unity, ineffability, subjectivity, and causal efficacy. Such singularities are vanishingly rare outside of highly recurrent, near-critical systems like brains and potentially advanced neural networks -- the very systems known to exhibit, or suspected to be capable of exhibiting, consciousness. We hypothesize that the topological structure around each singularity maps onto differences in experience. QSCT makes testable predictions: specific neural signatures should coincide with reported conscious moments; artificially induced Q-singularities should generate predictable experiences. The theory also explores a conjectural extension suggesting that self-modeling systems may necessarily produce Q-singularities. In short, QSCT proposes that where the quantitative fabric of the world tears, qualitative experience emerges.\n    ",
        "submission_date": "2017-04-04T00:00:00",
        "last_modified_date": "2025-07-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.01279",
        "title": "Neural Audio Synthesis of Musical Notes with WaveNet Autoencoders",
        "authors": [
            "Jesse Engel",
            "Cinjon Resnick",
            "Adam Roberts",
            "Sander Dieleman",
            "Douglas Eck",
            "Karen Simonyan",
            "Mohammad Norouzi"
        ],
        "abstract": "Generative models in vision have seen rapid progress due to algorithmic improvements and the availability of high-quality image datasets. In this paper, we offer contributions in both these areas to enable similar progress in audio modeling. First, we detail a powerful new WaveNet-style autoencoder model that conditions an autoregressive decoder on temporal codes learned from the raw audio waveform. Second, we introduce NSynth, a large-scale and high-quality dataset of musical notes that is an order of magnitude larger than comparable public datasets. Using NSynth, we demonstrate improved qualitative and quantitative performance of the WaveNet autoencoder over a well-tuned spectral autoencoder baseline. Finally, we show that the model learns a manifold of embeddings that allows for morphing between instruments, meaningfully interpolating in timbre to create new types of sounds that are realistic and expressive.\n    ",
        "submission_date": "2017-04-05T00:00:00",
        "last_modified_date": "2017-04-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.01383",
        "title": "Finite-Time Stabilization of Longitudinal Control for Autonomous Vehicles via a Model-Free Approach",
        "authors": [
            "Philip Polack",
            "Brigitte d'Andr\u00e9a-Novel",
            "Michel Fliess",
            "Arnaud de la Fortelle",
            "Lghani Menhour"
        ],
        "abstract": "This communication presents a longitudinal model-free control approach for computing the wheel torque command to be applied on a vehicle. This setting enables us to overcome the problem of unknown vehicle parameters for generating a suitable control law. An important parameter in this control setting is made time-varying for ensuring finite-time stability. Several convincing computer simulations are displayed and discussed. Overshoots become therefore smaller. The driving comfort is increased and the robustness to time-delays is improved.\n    ",
        "submission_date": "2017-04-05T00:00:00",
        "last_modified_date": "2017-04-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.01415",
        "title": "Multi-Label Learning with Global and Local Label Correlation",
        "authors": [
            "Yue Zhu",
            "James T. Kwok",
            "Zhi-Hua Zhou"
        ],
        "abstract": "It is well-known that exploiting label correlations is important to multi-label learning. Existing approaches either assume that the label correlations are global and shared by all instances; or that the label correlations are local and shared only by a data subset. In fact, in the real-world applications, both cases may occur that some label correlations are globally applicable and some are shared only in a local group of instances. Moreover, it is also a usual case that only partial labels are observed, which makes the exploitation of the label correlations much more difficult. That is, it is hard to estimate the label correlations when many labels are absent. In this paper, we propose a new multi-label approach GLOCAL dealing with both the full-label and the missing-label cases, exploiting global and local label correlations simultaneously, through learning a latent label representation and optimizing label manifolds. The extensive experimental studies validate the effectiveness of our approach on both full-label and missing-label data.\n    ",
        "submission_date": "2017-04-04T00:00:00",
        "last_modified_date": "2017-04-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.01523",
        "title": "MIT at SemEval-2017 Task 10: Relation Extraction with Convolutional Neural Networks",
        "authors": [
            "Ji Young Lee",
            "Franck Dernoncourt",
            "Peter Szolovits"
        ],
        "abstract": "Over 50 million scholarly articles have been published: they constitute a unique repository of knowledge. In particular, one may infer from them relations between scientific concepts, such as synonyms and hyponyms. Artificial neural networks have been recently explored for relation extraction. In this work, we continue this line of work and present a system based on a convolutional neural network to extract relations. Our model ranked first in the SemEval-2017 task 10 (ScienceIE) for relation extraction in scientific articles (subtask C).\n    ",
        "submission_date": "2017-04-05T00:00:00",
        "last_modified_date": "2017-04-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.01568",
        "title": "Best Practices for Applying Deep Learning to Novel Applications",
        "authors": [
            "Leslie N. Smith"
        ],
        "abstract": "This report is targeted to groups who are subject matter experts in their application but deep learning novices. It contains practical advice for those interested in testing the use of deep neural networks on applications that are novel for deep learning. We suggest making your project more manageable by dividing it into phases. For each phase this report contains numerous recommendations and insights to assist novice practitioners.\n    ",
        "submission_date": "2017-04-05T00:00:00",
        "last_modified_date": "2017-04-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.01631",
        "title": "Multitask Learning with Low-Level Auxiliary Tasks for Encoder-Decoder Based Speech Recognition",
        "authors": [
            "Shubham Toshniwal",
            "Hao Tang",
            "Liang Lu",
            "Karen Livescu"
        ],
        "abstract": "End-to-end training of deep learning-based models allows for implicit learning of intermediate representations based on the final task loss. However, the end-to-end approach ignores the useful domain knowledge encoded in explicit intermediate-level supervision. We hypothesize that using intermediate representations as auxiliary supervision at lower levels of deep networks may be a good way of combining the advantages of end-to-end training and more traditional pipeline approaches. We present experiments on conversational speech recognition where we use lower-level tasks, such as phoneme recognition, in a multitask training approach with an encoder-decoder model for direct character transcription. We compare multiple types of lower-level tasks and analyze the effects of the auxiliary tasks. Our results on the Switchboard corpus show that this approach improves recognition accuracy over a standard encoder-decoder model on the Eval2000 test set.\n    ",
        "submission_date": "2017-04-05T00:00:00",
        "last_modified_date": "2017-04-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.01759",
        "title": "A Multi-view Context-aware Approach to Android Malware Detection and Malicious Code Localization",
        "authors": [
            "Annamalai Narayanan",
            "Mahinthan Chandramohan",
            "Lihui Chen",
            "Yang Liu"
        ],
        "abstract": "Existing Android malware detection approaches use a variety of features such as security sensitive APIs, system calls, control-flow structures and information flows in conjunction with Machine Learning classifiers to achieve accurate detection. Each of these feature sets provides a unique semantic perspective (or view) of apps' behaviours with inherent strengths and limitations. Meaning, some views are more amenable to detect certain attacks but may not be suitable to characterise several other attacks. Most of the existing malware detection approaches use only one (or a selected few) of the aforementioned feature sets which prevent them from detecting a vast majority of attacks. Addressing this limitation, we propose MKLDroid, a unified framework that systematically integrates multiple views of apps for performing comprehensive malware detection and malicious code localisation. The rationale is that, while a malware app can disguise itself in some views, disguising in every view while maintaining malicious intent will be much harder.\n",
        "submission_date": "2017-04-06T00:00:00",
        "last_modified_date": "2017-04-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.01859",
        "title": "Tackling Dynamic Vehicle Routing Problem with Time Windows by means of Ant Colony System",
        "authors": [
            "Raluca Necula",
            "Mihaela Breaban",
            "Madalina Raschip"
        ],
        "abstract": "The Dynamic Vehicle Routing Problem with Time Windows (DVRPTW) is an extension of the well-known Vehicle Routing Problem (VRP), which takes into account the dynamic nature of the problem. This aspect requires the vehicle routes to be updated in an ongoing manner as new customer requests arrive in the system and must be incorporated into an evolving schedule during the working day. Besides the vehicle capacity constraint involved in the classical VRP, DVRPTW considers in addition time windows, which are able to better capture real-world situations. Despite this, so far, few studies have focused on tackling this problem of greater practical importance. To this end, this study devises for the resolution of DVRPTW, an ant colony optimization based algorithm, which resorts to a joint solution construction mechanism, able to construct in parallel the vehicle routes. This method is coupled with a local search procedure, aimed to further improve the solutions built by ants, and with an insertion heuristics, which tries to reduce the number of vehicles used to service the available customers. The experiments indicate that the proposed algorithm is competitive and effective, and on DVRPTW instances with a higher dynamicity level, it is able to yield better results compared to existing ant-based approaches.\n    ",
        "submission_date": "2017-04-06T00:00:00",
        "last_modified_date": "2017-04-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.01864",
        "title": "Robust Causal Estimation in the Large-Sample Limit without Strict Faithfulness",
        "authors": [
            "Ioan Gabriel Bucur",
            "Tom Claassen",
            "Tom Heskes"
        ],
        "abstract": "Causal effect estimation from observational data is an important and much studied research topic. The instrumental variable (IV) and local causal discovery (LCD) patterns are canonical examples of settings where a closed-form expression exists for the causal effect of one variable on another, given the presence of a third variable. Both rely on faithfulness to infer that the latter only influences the target effect via the cause variable. In reality, it is likely that this assumption only holds approximately and that there will be at least some form of weak interaction. This brings about the paradoxical situation that, in the large-sample limit, no predictions are made, as detecting the weak edge invalidates the setting. We introduce an alternative approach by replacing strict faithfulness with a prior that reflects the existence of many 'weak' (irrelevant) and 'strong' interactions. We obtain a posterior distribution over the target causal effect estimator which shows that, in many cases, we can still make good estimates. We demonstrate the approach in an application on a simple linear-Gaussian setting, using the MultiNest sampling algorithm, and compare it with established techniques to show our method is robust even when strict faithfulness is violated.\n    ",
        "submission_date": "2017-04-06T00:00:00",
        "last_modified_date": "2017-04-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.01886",
        "title": "Landmark Guided Probabilistic Roadmap Queries",
        "authors": [
            "Brian Paden",
            "Yannik Nager",
            "Emilio Frazzoli"
        ],
        "abstract": "A landmark based heuristic is investigated for reducing query phase run-time of the probabilistic roadmap (\\PRM) motion planning method. The heuristic is generated by storing minimum spanning trees from a small number of vertices within the \\PRM graph and using these trees to approximate the cost of a shortest path between any two vertices of the graph. The intermediate step of preprocessing the graph increases the time and memory requirements of the classical motion planning technique in exchange for speeding up individual queries making the method advantageous in multi-query applications. This paper investigates these trade-offs on \\PRM graphs constructed in randomized environments as well as a practical manipulator ",
        "submission_date": "2017-04-06T00:00:00",
        "last_modified_date": "2017-04-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.01889",
        "title": "Conformative Filtering for Implicit Feedback Data",
        "authors": [
            "Farhan Khawar",
            "Nevin L. Zhang"
        ],
        "abstract": "Implicit feedback is the simplest form of user feedback that can be used for item recommendation. It is easy to collect and is domain independent. However, there is a lack of negative examples. Previous work tackles this problem by assuming that users are not interested or not as much interested in the unconsumed items. Those assumptions are often severely violated since non-consumption can be due to factors like unawareness or lack of resources. Therefore, non-consumption by a user does not always mean disinterest or irrelevance. In this paper, we propose a novel method called Conformative Filtering (CoF) to address the issue. The motivating observation is that if there is a large group of users who share the same taste and none of them have consumed an item before, then it is likely that the item is not of interest to the group. We perform multidimensional clustering on implicit feedback data using hierarchical latent tree analysis (HLTA) to identify user `tastes' groups and make recommendations for a user based on her memberships in the groups and on the past behavior of the groups. Experiments on two real-world datasets from different domains show that CoF has superior performance compared to several common baselines.\n    ",
        "submission_date": "2017-04-06T00:00:00",
        "last_modified_date": "2019-04-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.01920",
        "title": "Encoder Based Lifelong Learning",
        "authors": [
            "Amal Rannen Triki",
            "Rahaf Aljundi",
            "Mathew B. Blaschko",
            "Tinne Tuytelaars"
        ],
        "abstract": "This paper introduces a new lifelong learning solution where a single model is trained for a sequence of tasks. The main challenge that vision systems face in this context is catastrophic forgetting: as they tend to adapt to the most recently seen task, they lose performance on the tasks that were learned previously. Our method aims at preserving the knowledge of the previous tasks while learning a new one by using autoencoders. For each task, an under-complete autoencoder is learned, capturing the features that are crucial for its achievement. When a new task is presented to the system, we prevent the reconstructions of the features with these autoencoders from changing, which has the effect of preserving the information on which the previous tasks are mainly relying. At the same time, the features are given space to adjust to the most recent environment as only their projection into a low dimension submanifold is controlled. The proposed system is evaluated on image classification tasks and shows a reduction of forgetting over the state-of-the-art\n    ",
        "submission_date": "2017-04-06T00:00:00",
        "last_modified_date": "2017-04-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.01975",
        "title": "An Automated Text Categorization Framework based on Hyperparameter Optimization",
        "authors": [
            "Eric S. Tellez",
            "Daniela Moctezuma",
            "Sabino Miranda-J\u00edmenez",
            "Mario Graff"
        ],
        "abstract": "A great variety of text tasks such as topic or spam identification, user profiling, and sentiment analysis can be posed as a supervised learning problem and tackle using a text classifier. A text classifier consists of several subprocesses, some of them are general enough to be applied to any supervised learning problem, whereas others are specifically designed to tackle a particular task, using complex and computational expensive processes such as lemmatization, syntactic analysis, etc. Contrary to traditional approaches, we propose a minimalistic and wide system able to tackle text classification tasks independent of domain and language, namely microTC. It is composed by some easy to implement text transformations, text representations, and a supervised learning algorithm. These pieces produce a competitive classifier even in the domain of informally written text. We provide a detailed description of microTC along with an extensive experimental comparison with relevant state-of-the-art methods. mircoTC was compared on 30 different datasets. Regarding accuracy, microTC obtained the best performance in 20 datasets while achieves competitive results in the remaining 10. The compared datasets include several problems like topic and polarity classification, spam detection, user profiling and authorship attribution. Furthermore, it is important to state that our approach allows the usage of the technology even without knowledge of machine learning and natural language processing.\n    ",
        "submission_date": "2017-04-06T00:00:00",
        "last_modified_date": "2017-09-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.02038",
        "title": "Treatment-Response Models for Counterfactual Reasoning with Continuous-time, Continuous-valued Interventions",
        "authors": [
            "Hossein Soleimani",
            "Adarsh Subbaswamy",
            "Suchi Saria"
        ],
        "abstract": "Treatment effects can be estimated from observational data as the difference in potential outcomes. In this paper, we address the challenge of estimating the potential outcome when treatment-dose levels can vary continuously over time. Further, the outcome variable may not be measured at a regular frequency. Our proposed solution represents the treatment response curves using linear time-invariant dynamical systems---this provides a flexible means for modeling response over time to highly variable dose curves. Moreover, for multivariate data, the proposed method: uncovers shared structure in treatment response and the baseline across multiple markers; and, flexibly models challenging correlation structure both across and within signals over time. For this, we build upon the framework of multiple-output Gaussian Processes. On simulated and a challenging clinical dataset, we show significant gains in accuracy over state-of-the-art models.\n    ",
        "submission_date": "2017-04-06T00:00:00",
        "last_modified_date": "2017-11-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.02081",
        "title": "Evolution in Groups: A deeper look at synaptic cluster driven evolution of deep neural networks",
        "authors": [
            "Mohammad Javad Shafiee",
            "Elnaz Barshan",
            "Alexander Wong"
        ],
        "abstract": "A promising paradigm for achieving highly efficient deep neural networks is the idea of evolutionary deep intelligence, which mimics biological evolution processes to progressively synthesize more efficient networks. A crucial design factor in evolutionary deep intelligence is the genetic encoding scheme used to simulate heredity and determine the architectures of offspring networks. In this study, we take a deeper look at the notion of synaptic cluster-driven evolution of deep neural networks which guides the evolution process towards the formation of a highly sparse set of synaptic clusters in offspring networks. Utilizing a synaptic cluster-driven genetic encoding, the probabilistic encoding of synaptic traits considers not only individual synaptic properties but also inter-synaptic relationships within a deep neural network. This process results in highly sparse offspring networks which are particularly tailored for parallel computational devices such as GPUs and deep neural network accelerator chips. Comprehensive experimental results using four well-known deep neural network architectures (LeNet-5, AlexNet, ResNet-56, and DetectNet) on two different tasks (object categorization and object detection) demonstrate the efficiency of the proposed method. Cluster-driven genetic encoding scheme synthesizes networks that can achieve state-of-the-art performance with significantly smaller number of synapses than that of the original ancestor network. ($\\sim$125-fold decrease in synapses for MNIST). Furthermore, the improved cluster efficiency in the generated offspring networks ($\\sim$9.71-fold decrease in clusters for MNIST and a $\\sim$8.16-fold decrease in clusters for KITTI) is particularly useful for accelerated performance on parallel computing hardware architectures such as those in GPUs and deep neural network accelerator chips.\n    ",
        "submission_date": "2017-04-07T00:00:00",
        "last_modified_date": "2017-04-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.02312",
        "title": "A Constrained Sequence-to-Sequence Neural Model for Sentence Simplification",
        "authors": [
            "Yaoyuan Zhang",
            "Zhenxu Ye",
            "Yansong Feng",
            "Dongyan Zhao",
            "Rui Yan"
        ],
        "abstract": "Sentence simplification reduces semantic complexity to benefit people with language impairments. Previous simplification studies on the sentence level and word level have achieved promising results but also meet great challenges. For sentence-level studies, sentences after simplification are fluent but sometimes are not really simplified. For word-level studies, words are simplified but also have potential grammar errors due to different usages of words before and after simplification. In this paper, we propose a two-step simplification framework by combining both the word-level and the sentence-level simplifications, making use of their corresponding advantages. Based on the two-step framework, we implement a novel constrained neural generation model to simplify sentences given simplified words. The final results on Wikipedia and Simple Wikipedia aligned datasets indicate that our method yields better performance than various baselines.\n    ",
        "submission_date": "2017-04-07T00:00:00",
        "last_modified_date": "2017-04-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.02375",
        "title": "AppLP: A Dialogue on Applications of Logic Programming",
        "authors": [
            "David S. Warren",
            "Yanhong A. Liu"
        ],
        "abstract": "This document describes the contributions of the 2016 Applications of Logic Programming Workshop (AppLP), which was held on October 17 and associated with the International Conference on Logic Programming (ICLP) in Flushing, New York City.\n    ",
        "submission_date": "2017-04-07T00:00:00",
        "last_modified_date": "2017-04-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.02712",
        "title": "Adaptive Relaxed ADMM: Convergence Theory and Practical Implementation",
        "authors": [
            "Zheng Xu",
            "Mario A. T. Figueiredo",
            "Xiaoming Yuan",
            "Christoph Studer",
            "Tom Goldstein"
        ],
        "abstract": "Many modern computer vision and machine learning applications rely on solving difficult optimization problems that involve non-differentiable objective functions and constraints. The alternating direction method of multipliers (ADMM) is a widely used approach to solve such problems. Relaxed ADMM is a generalization of ADMM that often achieves better performance, but its efficiency depends strongly on algorithm parameters that must be chosen by an expert user. We propose an adaptive method that automatically tunes the key algorithm parameters to achieve optimal performance without user oversight. Inspired by recent work on adaptivity, the proposed adaptive relaxed ADMM (ARADMM) is derived by assuming a Barzilai-Borwein style linear gradient. A detailed convergence analysis of ARADMM is provided, and numerical results on several applications demonstrate fast practical convergence.\n    ",
        "submission_date": "2017-04-10T00:00:00",
        "last_modified_date": "2017-04-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.02853",
        "title": "SemEval 2017 Task 10: ScienceIE - Extracting Keyphrases and Relations from Scientific Publications",
        "authors": [
            "Isabelle Augenstein",
            "Mrinal Das",
            "Sebastian Riedel",
            "Lakshmi Vikraman",
            "Andrew McCallum"
        ],
        "abstract": "We describe the SemEval task of extracting keyphrases and relations between them from scientific documents, which is crucial for understanding which publications describe which processes, tasks and materials. Although this was a new task, we had a total of 26 submissions across 3 evaluation scenarios. We expect the task and the findings reported in this paper to be relevant for researchers working on understanding scientific content, as well as the broader knowledge base population and information extraction communities.\n    ",
        "submission_date": "2017-04-10T00:00:00",
        "last_modified_date": "2017-05-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.02906",
        "title": "Multi-Agent Diverse Generative Adversarial Networks",
        "authors": [
            "Arnab Ghosh",
            "Viveka Kulharia",
            "Vinay Namboodiri",
            "Philip H. S. Torr",
            "Puneet K. Dokania"
        ],
        "abstract": "We propose MAD-GAN, an intuitive generalization to the Generative Adversarial Networks (GANs) and its conditional variants to address the well known problem of mode collapse. First, MAD-GAN is a multi-agent GAN architecture incorporating multiple generators and one discriminator. Second, to enforce that different generators capture diverse high probability modes, the discriminator of MAD-GAN is designed such that along with finding the real and fake samples, it is also required to identify the generator that generated the given fake sample. Intuitively, to succeed in this task, the discriminator must learn to push different generators towards different identifiable modes. We perform extensive experiments on synthetic and real datasets and compare MAD-GAN with different variants of GAN. We show high quality diverse sample generations for challenging tasks such as image-to-image translation and face generation. In addition, we also show that MAD-GAN is able to disentangle different modalities when trained using highly challenging diverse-class dataset (e.g. dataset with images of forests, icebergs, and bedrooms). In the end, we show its efficacy on the unsupervised feature representation task. In Appendix, we introduce a similarity based competing objective (MAD-GAN-Sim) which encourages different generators to generate diverse samples based on a user defined similarity metric. We show its performance on the image-to-image translation, and also show its effectiveness on the unsupervised feature representation task.\n    ",
        "submission_date": "2017-04-10T00:00:00",
        "last_modified_date": "2018-07-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.02923",
        "title": "Pay Attention to Those Sets! Learning Quantification from Images",
        "authors": [
            "Ionut Sorodoc",
            "Sandro Pezzelle",
            "Aur\u00e9lie Herbelot",
            "Mariella Dimiccoli",
            "Raffaella Bernardi"
        ],
        "abstract": "Major advances have recently been made in merging language and vision representations. But most tasks considered so far have confined themselves to the processing of objects and lexicalised relations amongst objects (content words). We know, however, that humans (even pre-school children) can abstract over raw data to perform certain types of higher-level reasoning, expressed in natural language by function words. A case in point is given by their ability to learn quantifiers, i.e. expressions like 'few', 'some' and 'all'. From formal semantics and cognitive linguistics, we know that quantifiers are relations over sets which, as a simplification, we can see as proportions. For instance, in 'most fish are red', most encodes the proportion of fish which are red fish. In this paper, we study how well current language and vision strategies model such relations. We show that state-of-the-art attention mechanisms coupled with a traditional linguistic formalisation of quantifiers gives best performance on the task. Additionally, we provide insights on the role of 'gist' representations in quantification. A 'logical' strategy to tackle the task would be to first obtain a numerosity estimation for the two involved sets and then compare their cardinalities. We however argue that precisely identifying the composition of the sets is not only beyond current state-of-the-art models but perhaps even detrimental to a task that is most efficiently performed by refining the approximate numerosity estimator of the system.\n    ",
        "submission_date": "2017-04-10T00:00:00",
        "last_modified_date": "2017-04-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.02963",
        "title": "Exploring Word Embeddings for Unsupervised Textual User-Generated Content Normalization",
        "authors": [
            "Thales Felipe Costa Bertaglia",
            "Maria das Gra\u00e7as Volpe Nunes"
        ],
        "abstract": "Text normalization techniques based on rules, lexicons or supervised training requiring large corpora are not scalable nor domain interchangeable, and this makes them unsuitable for normalizing user-generated content (UGC). Current tools available for Brazilian Portuguese make use of such techniques. In this work we propose a technique based on distributed representation of words (or word embeddings). It generates continuous numeric vectors of high-dimensionality to represent words. The vectors explicitly encode many linguistic regularities and patterns, as well as syntactic and semantic word relationships. Words that share semantic similarity are represented by similar vectors. Based on these features, we present a totally unsupervised, expandable and language and domain independent method for learning normalization lexicons from word embeddings. Our approach obtains high correction rate of orthographic errors and internet slang in product reviews, outperforming the current available tools for Brazilian Portuguese.\n    ",
        "submission_date": "2017-04-10T00:00:00",
        "last_modified_date": "2017-04-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.03039",
        "title": "Semantically Consistent Regularization for Zero-Shot Recognition",
        "authors": [
            "Pedro Morgado",
            "Nuno Vasconcelos"
        ],
        "abstract": "The role of semantics in zero-shot learning is considered. The effectiveness of previous approaches is analyzed according to the form of supervision provided. While some learn semantics independently, others only supervise the semantic subspace explained by training classes. Thus, the former is able to constrain the whole space but lacks the ability to model semantic correlations. The latter addresses this issue but leaves part of the semantic space unsupervised. This complementarity is exploited in a new convolutional neural network (CNN) framework, which proposes the use of semantics as constraints for ",
        "submission_date": "2017-04-10T00:00:00",
        "last_modified_date": "2017-04-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.03079",
        "title": "WRPN: Training and Inference using Wide Reduced-Precision Networks",
        "authors": [
            "Asit Mishra",
            "Jeffrey J Cook",
            "Eriko Nurvitadhi",
            "Debbie Marr"
        ],
        "abstract": "For computer vision applications, prior works have shown the efficacy of reducing the numeric precision of model parameters (network weights) in deep neural networks but also that reducing the precision of activations hurts model accuracy much more than reducing the precision of model parameters. We study schemes to train networks from scratch using reduced-precision activations without hurting the model accuracy. We reduce the precision of activation maps (along with model parameters) using a novel quantization scheme and increase the number of filter maps in a layer, and find that this scheme compensates or surpasses the accuracy of the baseline full-precision network. As a result, one can significantly reduce the dynamic memory footprint, memory bandwidth, computational energy and speed up the training and inference process with appropriate hardware support. We call our scheme WRPN - wide reduced-precision networks. We report results using our proposed schemes and show that our results are better than previously reported accuracies on ILSVRC-12 dataset while being computationally less expensive compared to previously reported reduced-precision networks.\n    ",
        "submission_date": "2017-04-10T00:00:00",
        "last_modified_date": "2017-04-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.03084",
        "title": "Composite Task-Completion Dialogue Policy Learning via Hierarchical Deep Reinforcement Learning",
        "authors": [
            "Baolin Peng",
            "Xiujun Li",
            "Lihong Li",
            "Jianfeng Gao",
            "Asli Celikyilmaz",
            "Sungjin Lee",
            "Kam-Fai Wong"
        ],
        "abstract": "Building a dialogue agent to fulfill complex tasks, such as travel planning, is challenging because the agent has to learn to collectively complete multiple subtasks. For example, the agent needs to reserve a hotel and book a flight so that there leaves enough time for commute between arrival and hotel check-in. This paper addresses this challenge by formulating the task in the mathematical framework of options over Markov Decision Processes (MDPs), and proposing a hierarchical deep reinforcement learning approach to learning a dialogue manager that operates at different temporal scales. The dialogue manager consists of: (1) a top-level dialogue policy that selects among subtasks or options, (2) a low-level dialogue policy that selects primitive actions to complete the subtask given by the top-level policy, and (3) a global state tracker that helps ensure all cross-subtask constraints be satisfied. Experiments on a travel planning task with simulated and real users show that our approach leads to significant improvements over three baselines, two based on handcrafted rules and the other based on flat deep reinforcement learning.\n    ",
        "submission_date": "2017-04-10T00:00:00",
        "last_modified_date": "2017-07-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.03103",
        "title": "Minkowski Operations of Sets with Application to Robot Localization",
        "authors": [
            "Benoit Desrochers",
            "Luc Jaulin"
        ],
        "abstract": "This papers shows that using separators, which is a pair of two complementary contractors, we can easily and efficiently solve the localization problem of a robot with sonar measurements in an unstructured environment. We introduce separators associated with the Minkowski sum and the Minkowski difference in order to facilitate the resolution. A test-case is given in order to illustrate the principle of the approach.\n    ",
        "submission_date": "2017-04-11T00:00:00",
        "last_modified_date": "2017-04-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.03275",
        "title": "Scavenger 0.1: A Theorem Prover Based on Conflict Resolution",
        "authors": [
            "Daniyar Itegulov",
            "John Slaney",
            "Bruno Woltzenlogel Paleo"
        ],
        "abstract": "This paper introduces Scavenger, the first theorem prover for pure first-order logic without equality based on the new conflict resolution calculus. Conflict resolution has a restricted resolution inference rule that resembles (a first-order generalization of) unit propagation as well as a rule for assuming decision literals and a rule for deriving new clauses by (a first-order generalization of) conflict-driven clause learning.\n    ",
        "submission_date": "2017-04-11T00:00:00",
        "last_modified_date": "2017-10-31T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.03296",
        "title": "Interpretable Explanations of Black Boxes by Meaningful Perturbation",
        "authors": [
            "Ruth Fong",
            "Andrea Vedaldi"
        ],
        "abstract": "As machine learning algorithms are increasingly applied to high impact yet high risk tasks, such as medical diagnosis or autonomous driving, it is critical that researchers can explain how such algorithms arrived at their predictions. In recent years, a number of image saliency methods have been developed to summarize where highly complex neural networks \"look\" in an image for evidence for their predictions. However, these techniques are limited by their heuristic nature and architectural constraints. In this paper, we make two main contributions: First, we propose a general framework for learning different kinds of explanations for any black box algorithm. Second, we specialise the framework to find the part of an image most responsible for a classifier decision. Unlike previous works, our method is model-agnostic and testable because it is grounded in explicit and interpretable image perturbations.\n    ",
        "submission_date": "2017-04-11T00:00:00",
        "last_modified_date": "2021-12-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.03373",
        "title": "Quality Aware Network for Set to Set Recognition",
        "authors": [
            "Yu Liu",
            "Junjie Yan",
            "Wanli Ouyang"
        ],
        "abstract": "This paper targets on the problem of set to set recognition, which learns the metric between two image sets. Images in each set belong to the same identity. Since images in a set can be complementary, they hopefully lead to higher accuracy in practical applications. However, the quality of each sample cannot be guaranteed, and samples with poor quality will hurt the metric. In this paper, the quality aware network (QAN) is proposed to confront this problem, where the quality of each sample can be automatically learned although such information is not explicitly provided in the training stage. The network has two branches, where the first branch extracts appearance feature embedding for each sample and the other branch predicts quality score for each sample. Features and quality scores of all samples in a set are then aggregated to generate the final feature embedding. We show that the two branches can be trained in an end-to-end manner given only the set-level identity annotation. Analysis on gradient spread of this mechanism indicates that the quality learned by the network is beneficial to set-to-set recognition and simplifies the distribution that the network needs to fit. Experiments on both face verification and person re-identification show advantages of the proposed QAN. The source code and network structure can be downloaded at ",
        "submission_date": "2017-04-11T00:00:00",
        "last_modified_date": "2017-04-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.03520",
        "title": "Unsupervised Event Abstraction using Pattern Abstraction and Local Process Models",
        "authors": [
            "Felix Mannhardt",
            "Niek Tax"
        ],
        "abstract": "Process mining analyzes business processes based on events stored in event logs. However, some recorded events may correspond to activities on a very low level of abstraction. When events are recorded on a too low level of granularity, process discovery methods tend to generate overgeneralizing process models. Grouping low-level events to higher level activities, i.e., event abstraction, can be used to discover better process models. Existing event abstraction methods are mainly based on common sub-sequences and clustering techniques. In this paper, we propose to first discover local process models and then use those models to lift the event log to a higher level of abstraction. Our conjecture is that process models discovered on the obtained high-level event log return process models of higher quality: their fitness and precision scores are more balanced. We show this with preliminary results on several real-life event logs.\n    ",
        "submission_date": "2017-04-11T00:00:00",
        "last_modified_date": "2017-05-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.03627",
        "title": "Real-time On-Demand Crowd-powered Entity Extraction",
        "authors": [
            "Ting-Hao 'Kenneth' Huang",
            "Yun-Nung Chen",
            "Jeffrey P. Bigham"
        ],
        "abstract": "Output-agreement mechanisms such as ESP Game have been widely used in human computation to obtain reliable human-generated labels. In this paper, we argue that a \"time-limited\" output-agreement mechanism can be used to create a fast and robust crowd-powered component in interactive systems, particularly dialogue systems, to extract key information from user utterances on the fly. Our experiments on Amazon Mechanical Turk using the Airline Travel Information System (ATIS) dataset showed that the proposed approach achieves high-quality results with an average response time shorter than 9 seconds.\n    ",
        "submission_date": "2017-04-12T00:00:00",
        "last_modified_date": "2017-12-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.03767",
        "title": "Parallelized Kendall's Tau Coefficient Computation via SIMD Vectorized Sorting On Many-Integrated-Core Processors",
        "authors": [
            "Yongchao Liu",
            "Tony Pan",
            "Oded Green",
            "Srinivas Aluru"
        ],
        "abstract": "Pairwise association measure is an important operation in data analytics. Kendall's tau coefficient is one widely used correlation coefficient identifying non-linear relationships between ordinal variables. In this paper, we investigated a parallel algorithm accelerating all-pairs Kendall's tau coefficient computation via single instruction multiple data (SIMD) vectorized sorting on Intel Xeon Phis by taking advantage of many processing cores and 512-bit SIMD vector instructions. To facilitate workload balancing and overcome on-chip memory limitation, we proposed a generic framework for symmetric all-pairs computation by building provable bijective functions between job identifier and coordinate space. Performance evaluation demonstrated that our algorithm on one 5110P Phi achieves two orders-of-magnitude speedups over 16-threaded MATLAB and three orders-of-magnitude speedups over sequential R, both running on high-end CPUs. Besides, our algorithm exhibited rather good distributed computing scalability with respect to number of Phis. Source code and datasets are publicly available at ",
        "submission_date": "2017-04-12T00:00:00",
        "last_modified_date": "2017-04-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.03899",
        "title": "Deep Reinforcement Learning-based Image Captioning with Embedding Reward",
        "authors": [
            "Zhou Ren",
            "Xiaoyu Wang",
            "Ning Zhang",
            "Xutao Lv",
            "Li-Jia Li"
        ],
        "abstract": "Image captioning is a challenging problem owing to the complexity in understanding the image content and diverse ways of describing it in natural language. Recent advances in deep neural networks have substantially improved the performance of this task. Most state-of-the-art approaches follow an encoder-decoder framework, which generates captions using a sequential recurrent prediction model. However, in this paper, we introduce a novel decision-making framework for image captioning. We utilize a \"policy network\" and a \"value network\" to collaboratively generate captions. The policy network serves as a local guidance by providing the confidence of predicting the next word according to the current state. Additionally, the value network serves as a global and lookahead guidance by evaluating all possible extensions of the current state. In essence, it adjusts the goal of predicting the correct words towards the goal of generating captions similar to the ground truth captions. We train both networks using an actor-critic reinforcement learning model, with a novel reward defined by visual-semantic embedding. Extensive experiments and analyses on the Microsoft COCO dataset show that the proposed framework outperforms state-of-the-art approaches across different evaluation metrics.\n    ",
        "submission_date": "2017-04-12T00:00:00",
        "last_modified_date": "2017-04-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.03926",
        "title": "Value Directed Exploration in Multi-Armed Bandits with Structured Priors",
        "authors": [
            "Bence Cserna",
            "Marek Petrik",
            "Reazul Hasan Russel",
            "Wheeler Ruml"
        ],
        "abstract": "Multi-armed bandits are a quintessential machine learning problem requiring the balancing of exploration and exploitation. While there has been progress in developing algorithms with strong theoretical guarantees, there has been less focus on practical near-optimal finite-time performance. In this paper, we propose an algorithm for Bayesian multi-armed bandits that utilizes value-function-driven online planning techniques. Building on previous work on UCB and Gittins index, we introduce linearly-separable value functions that take both the expected return and the benefit of exploration into consideration to perform n-step lookahead. The algorithm enjoys a sub-linear performance guarantee and we present simulation results that confirm its strength in problems with structured priors. The simplicity and generality of our approach makes it a strong candidate for analyzing more complex multi-armed bandit problems.\n    ",
        "submission_date": "2017-04-12T00:00:00",
        "last_modified_date": "2017-05-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.03992",
        "title": "Fully Distributed and Asynchronized Stochastic Gradient Descent for Networked Systems",
        "authors": [
            "Ying Zhang"
        ],
        "abstract": "This paper considers a general data-fitting problem over a networked system, in which many computing nodes are connected by an undirected graph. This kind of problem can find many real-world applications and has been studied extensively in the literature. However, existing solutions either need a central controller for information sharing or requires slot synchronization among different nodes, which increases the difficulty of practical implementations, especially for a very large and heterogeneous system.\n",
        "submission_date": "2017-04-13T00:00:00",
        "last_modified_date": "2017-04-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.04058",
        "title": "Solving ill-posed inverse problems using iterative deep neural networks",
        "authors": [
            "Jonas Adler",
            "Ozan \u00d6ktem"
        ],
        "abstract": "We propose a partially learned approach for the solution of ill posed inverse problems with not necessarily linear forward operators. The method builds on ideas from classical regularization theory and recent advances in deep learning to perform learning while making use of prior information about the inverse problem encoded in the forward operator, noise model and a regularizing functional. The method results in a gradient-like iterative scheme, where the \"gradient\" component is learned using a convolutional network that includes the gradients of the data discrepancy and regularizer as input in each iteration. We present results of such a partially learned gradient scheme on a non-linear tomographic inversion problem with simulated data from both the Sheep-Logan phantom as well as a head CT. The outcome is compared against FBP and TV reconstruction and the proposed method provides a 5.4 dB PSNR improvement over the TV reconstruction while being significantly faster, giving reconstructions of 512 x 512 volumes in about 0.4 seconds using a single GPU.\n    ",
        "submission_date": "2017-04-13T00:00:00",
        "last_modified_date": "2017-05-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.04133",
        "title": "Explaining the Unexplained: A CLass-Enhanced Attentive Response (CLEAR) Approach to Understanding Deep Neural Networks",
        "authors": [
            "Devinder Kumar",
            "Alexander Wong",
            "Graham W. Taylor"
        ],
        "abstract": "In this work, we propose CLass-Enhanced Attentive Response (CLEAR): an approach to visualize and understand the decisions made by deep neural networks (DNNs) given a specific input. CLEAR facilitates the visualization of attentive regions and levels of interest of DNNs during the decision-making process. It also enables the visualization of the most dominant classes associated with these attentive regions of interest. As such, CLEAR can mitigate some of the shortcomings of heatmap-based methods associated with decision ambiguity, and allows for better insights into the decision-making process of DNNs. Quantitative and qualitative experiments across three different datasets demonstrate the efficacy of CLEAR for gaining a better understanding of the inner workings of DNNs during the decision-making process.\n    ",
        "submission_date": "2017-04-13T00:00:00",
        "last_modified_date": "2017-05-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.04313",
        "title": "CBinfer: Change-Based Inference for Convolutional Neural Networks on Video Data",
        "authors": [
            "Lukas Cavigelli",
            "Philippe Degen",
            "Luca Benini"
        ],
        "abstract": "Extracting per-frame features using convolutional neural networks for real-time processing of video data is currently mainly performed on powerful GPU-accelerated workstations and compute clusters. However, there are many applications such as smart surveillance cameras that require or would benefit from on-site processing. To this end, we propose and evaluate a novel algorithm for change-based evaluation of CNNs for video data recorded with a static camera setting, exploiting the spatio-temporal sparsity of pixel changes. We achieve an average speed-up of 8.6x over a cuDNN baseline on a realistic benchmark with a negligible accuracy loss of less than 0.1% and no retraining of the network. The resulting energy efficiency is 10x higher than that of per-frame evaluation and reaches an equivalent of 328 GOp/s/W on the Tegra X1 platform.\n    ",
        "submission_date": "2017-04-14T00:00:00",
        "last_modified_date": "2017-06-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.04379",
        "title": "Ultrafast photonic reinforcement learning based on laser chaos",
        "authors": [
            "Makoto Naruse",
            "Yuta Terashima",
            "Atsushi Uchida",
            "Song-Ju Kim"
        ],
        "abstract": "Reinforcement learning involves decision making in dynamic and uncertain environments, and constitutes one important element of artificial intelligence (AI). In this paper, we experimentally demonstrate that the ultrafast chaotic oscillatory dynamics of lasers efficiently solve the multi-armed bandit problem (MAB), which requires decision making concerning a class of difficult trade-offs called the exploration-exploitation dilemma. To solve the MAB, a certain degree of randomness is required for exploration purposes. However, pseudo-random numbers generated using conventional electronic circuitry encounter severe limitations in terms of their data rate and the quality of randomness due to their algorithmic foundations. We generate laser chaos signals using a semiconductor laser sampled at a maximum rate of 100 GSample/s, and combine it with a simple decision-making principle called tug-of-war with a variable threshold, to ensure ultrafast, adaptive and accurate decision making at a maximum adaptation speed of 1 GHz. We found that decision-making performance was maximized with an optimal sampling interval, and we highlight the exact coincidence between the negative autocorrelation inherent in laser chaos and decision-making performance. This study paves the way for a new realm of ultrafast photonics in the age of AI, where the ultrahigh bandwidth of photons can provide new value.\n    ",
        "submission_date": "2017-04-14T00:00:00",
        "last_modified_date": "2017-04-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.04451",
        "title": "Optimizing Differentiable Relaxations of Coreference Evaluation Metrics",
        "authors": [
            "Phong Le",
            "Ivan Titov"
        ],
        "abstract": "Coreference evaluation metrics are hard to optimize directly as they are non-differentiable functions, not easily decomposable into elementary decisions. Consequently, most approaches optimize objectives only indirectly related to the end goal, resulting in suboptimal performance. Instead, we propose a differentiable relaxation that lends itself to gradient-based optimisation, thus bypassing the need for reinforcement learning or heuristic modification of cross-entropy. We show that by modifying the training objective of a competitive neural coreference system, we obtain a substantial gain in performance. This suggests that our approach can be regarded as a viable alternative to using reinforcement learning or more computationally expensive imitation learning.\n    ",
        "submission_date": "2017-04-14T00:00:00",
        "last_modified_date": "2017-06-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.04478",
        "title": "Graphical Models: An Extension to Random Graphs, Trees, and Other Objects",
        "authors": [
            "Neil Hallonquist"
        ],
        "abstract": "In this work, we consider an extension of graphical models to random graphs, trees, and other objects. To do this, many fundamental concepts for multivariate random variables (e.g., marginal variables, Gibbs distribution, Markov properties) must be extended to other mathematical objects; it turns out that this extension is possible, as we will discuss, if we have a consistent, complete system of projections on a given object. Each projection defines a marginal random variable, allowing one to specify independence assumptions between them. Furthermore, these independencies can be specified in terms of a small subset of these marginal variables (which we call the atomic variables), allowing the compact representation of independencies by a directed graph. Projections also define factors, functions on the projected object space, and hence a projection family defines a set of possible factorizations for a distribution; these can be compactly represented by an undirected graph.\n",
        "submission_date": "2017-04-14T00:00:00",
        "last_modified_date": "2017-05-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.04517",
        "title": "ShapeWorld - A new test methodology for multimodal language understanding",
        "authors": [
            "Alexander Kuhnle",
            "Ann Copestake"
        ],
        "abstract": "We introduce a novel framework for evaluating multimodal deep learning models with respect to their language understanding and generalization abilities. In this approach, artificial data is automatically generated according to the experimenter's specifications. The content of the data, both during training and evaluation, can be controlled in detail, which enables tasks to be created that require true generalization abilities, in particular the combination of previously introduced concepts in novel ways. We demonstrate the potential of our methodology by evaluating various visual question answering models on four different tasks, and show how our framework gives us detailed insights into their capabilities and limitations. By open-sourcing our framework, we hope to stimulate progress in the field of multimodal language understanding.\n    ",
        "submission_date": "2017-04-14T00:00:00",
        "last_modified_date": "2017-04-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.04576",
        "title": "NEXT: A Neural Network Framework for Next POI Recommendation",
        "authors": [
            "Zhiqian Zhang",
            "Chenliang Li",
            "Zhiyong Wu",
            "Aixin Sun",
            "Dengpan Ye",
            "Xiangyang Luo"
        ],
        "abstract": "The task of next POI recommendation has been studied extensively in recent years. However, developing an unified recommendation framework to incorporate multiple factors associated with both POIs and users remains challenging, because of the heterogeneity nature of these information. Further, effective mechanisms to handle cold-start and endow the system with interpretability are also difficult topics. Inspired by the recent success of neural networks in many areas, in this paper, we present a simple but effective neural network framework for next POI recommendation, named NEXT. NEXT is an unified framework to learn the hidden intent regarding user's next move, by incorporating different factors in an unified manner. Specifically, in NEXT, we incorporate meta-data information and two kinds of temporal contexts (i.e., time interval and visit time). To leverage sequential relations and geographical influence, we propose to adopt DeepWalk, a network representation learning technique, to encode such knowledge. We evaluate the effectiveness of NEXT against state-of-the-art alternatives and neural networks based solutions. Experimental results over three publicly available datasets demonstrate that NEXT significantly outperforms baselines in real-time next POI recommendation. Further experiments demonstrate the superiority of NEXT in handling cold-start. More importantly, we show that NEXT provides meaningful explanation of the dimensions in hidden intent space.\n    ",
        "submission_date": "2017-04-15T00:00:00",
        "last_modified_date": "2017-04-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.04683",
        "title": "RACE: Large-scale ReAding Comprehension Dataset From Examinations",
        "authors": [
            "Guokun Lai",
            "Qizhe Xie",
            "Hanxiao Liu",
            "Yiming Yang",
            "Eduard Hovy"
        ],
        "abstract": "We present RACE, a new dataset for benchmark evaluation of methods in the reading comprehension task. Collected from the English exams for middle and high school Chinese students in the age range between 12 to 18, RACE consists of near 28,000 passages and near 100,000 questions generated by human experts (English instructors), and covers a variety of topics which are carefully designed for evaluating the students' ability in understanding and reasoning. In particular, the proportion of questions that requires reasoning is much larger in RACE than that in other benchmark datasets for reading comprehension, and there is a significant gap between the performance of the state-of-the-art models (43%) and the ceiling human performance (95%). We hope this new dataset can serve as a valuable resource for research and evaluation in machine comprehension. The dataset is freely available at ",
        "submission_date": "2017-04-15T00:00:00",
        "last_modified_date": "2017-12-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.04684",
        "title": "Generic LSH Families for the Angular Distance Based on Johnson-Lindenstrauss Projections and Feature Hashing LSH",
        "authors": [
            "Luis Argerich",
            "Natalia Golmar"
        ],
        "abstract": "In this paper we propose the creation of generic LSH families for the angular distance based on Johnson-Lindenstrauss projections. We show that feature hashing is a valid J-L projection and propose two new LSH families based on feature hashing. These new LSH families are tested on both synthetic and real datasets with very good results and a considerable performance improvement over other LSH families. While the theoretical analysis is done for the angular distance, these families can also be used in practice for the euclidean distance with excellent results [2]. Our tests using real datasets show that the proposed LSH functions work well for the euclidean distance.\n    ",
        "submission_date": "2017-04-15T00:00:00",
        "last_modified_date": "2017-04-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.04712",
        "title": "Learn-Memorize-Recall-Reduce A Robotic Cloud Computing Paradigm",
        "authors": [
            "Shaoshan Liu",
            "Bolin Ding",
            "Jie Tang",
            "Dawei Sun",
            "Zhe Zhang",
            "Grace Tsai",
            "Jean-Luc Gaudiot"
        ],
        "abstract": "The rise of robotic applications has led to the generation of a huge volume of unstructured data, whereas the current cloud infrastructure was designed to process limited amounts of structured data. To address this problem, we propose a learn-memorize-recall-reduce paradigm for robotic cloud computing. The learning stage converts incoming unstructured data into structured data; the memorization stage provides effective storage for the massive amount of data; the recall stage provides efficient means to retrieve the raw data; while the reduction stage provides means to make sense of this massive amount of unstructured data with limited computing resources.\n    ",
        "submission_date": "2017-04-16T00:00:00",
        "last_modified_date": "2017-04-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.04782",
        "title": "A Security Monitoring Framework For Virtualization Based HEP Infrastructures",
        "authors": [
            "A. Gomez Ramirez",
            "M. Martinez Pedreira",
            "C. Grigoras",
            "L. Betev",
            "C. Lara",
            "U. Kebschull"
        ],
        "abstract": "High Energy Physics (HEP) distributed computing infrastructures require automatic tools to monitor, analyze and react to potential security incidents. These tools should collect and inspect data such as resource consumption, logs and sequence of system calls for detecting anomalies that indicate the presence of a malicious agent. They should also be able to perform automated reactions to attacks without administrator intervention. We describe a novel framework that accomplishes these requirements, with a proof of concept implementation for the ALICE experiment at CERN. We show how we achieve a fully virtualized environment that improves the security by isolating services and Jobs without a significant performance impact. We also describe a collected dataset for Machine Learning based Intrusion Prevention and Detection Systems on Grid computing. This dataset is composed of resource consumption measurements (such as CPU, RAM and network traffic), logfiles from operating system services, and system call data collected from production Jobs running in an ALICE Grid test site and a big set of malware. This malware was collected from security research sites. Based on this dataset, we will proceed to develop Machine Learning algorithms able to detect malicious Jobs.\n    ",
        "submission_date": "2017-04-16T00:00:00",
        "last_modified_date": "2017-04-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.04810",
        "title": "A Novel Experimental Platform for In-Vessel Multi-Chemical Molecular Communications",
        "authors": [
            "Nariman Farsad",
            "David Pan",
            "Andrea Goldsmith"
        ],
        "abstract": "This work presents a new multi-chemical experimental platform for molecular communication where the transmitter can release different chemicals. This platform is designed to be inexpensive and accessible, and it can be expanded to simulate different environments including the cardiovascular system and complex network of pipes in industrial complexes and city infrastructures. To demonstrate the capabilities of the platform, we implement a time-slotted binary communication system where a bit-0 is represented by an acid pulse, a bit-1 by a base pulse, and information is carried via pH signals. The channel model for this system, which is nonlinear and has long memories, is unknown. Therefore, we devise novel detection algorithms that use techniques from machine learning and deep learning to train a maximum-likelihood detector. Using these algorithms the bit error rate improves by an order of magnitude relative to the approach used in previous works. Moreover, our system achieves a data rate that is an order of magnitude higher than any of the previous molecular communication platforms.\n    ",
        "submission_date": "2017-04-16T00:00:00",
        "last_modified_date": "2017-04-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.04866",
        "title": "Effective Warm Start for the Online Actor-Critic Reinforcement Learning based mHealth Intervention",
        "authors": [
            "Feiyun Zhu",
            "Peng Liao"
        ],
        "abstract": "Online reinforcement learning (RL) is increasingly popular for the personalized mobile health (mHealth) intervention. It is able to personalize the type and dose of interventions according to user's ongoing statuses and changing needs. However, at the beginning of online learning, there are usually too few samples to support the RL updating, which leads to poor performances. A delay in good performance of the online learning algorithms can be especially detrimental in the mHealth, where users tend to quickly disengage with the mHealth app. To address this problem, we propose a new online RL methodology that focuses on an effective warm start. The main idea is to make full use of the data accumulated and the decision rule achieved in a former study. As a result, we can greatly enrich the data size at the beginning of online learning in our method. Such case accelerates the online learning process for new users to achieve good performances not only at the beginning of online learning but also through the whole online learning process. Besides, we use the decision rules achieved in a previous study to initialize the parameter in our online RL model for new users. It provides a good initialization for the proposed online RL algorithm. Experiment results show that promising improvements have been achieved by our method compared with the state-of-the-art method.\n    ",
        "submission_date": "2017-04-17T00:00:00",
        "last_modified_date": "2017-05-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.04966",
        "title": "Larger is Better: The Effect of Learning Rates Enjoyed by Stochastic Optimization with Progressive Variance Reduction",
        "authors": [
            "Fanhua Shang"
        ],
        "abstract": "In this paper, we propose a simple variant of the original stochastic variance reduction gradient (SVRG), where hereafter we refer to as the variance reduced stochastic gradient descent (VR-SGD). Different from the choices of the snapshot point and starting point in SVRG and its proximal variant, Prox-SVRG, the two vectors of each epoch in VR-SGD are set to the average and last iterate of the previous epoch, respectively. This setting allows us to use much larger learning rates or step sizes than SVRG, e.g., 3/(7L) for VR-SGD vs 1/(10L) for SVRG, and also makes our convergence analysis more challenging. In fact, a larger learning rate enjoyed by VR-SGD means that the variance of its stochastic gradient estimator asymptotically approaches zero more rapidly. Unlike common stochastic methods such as SVRG and proximal stochastic methods such as Prox-SVRG, we design two different update rules for smooth and non-smooth objective functions, respectively. In other words, VR-SGD can tackle non-smooth and/or non-strongly convex problems directly without using any reduction techniques such as quadratic regularizers. Moreover, we analyze the convergence properties of VR-SGD for strongly convex problems, which show that VR-SGD attains a linear convergence rate. We also provide the convergence guarantees of VR-SGD for non-strongly convex problems. Experimental results show that the performance of VR-SGD is significantly better than its counterparts, SVRG and Prox-SVRG, and it is also much better than the best known stochastic method, Katyusha.\n    ",
        "submission_date": "2017-04-17T00:00:00",
        "last_modified_date": "2017-04-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.05136",
        "title": "The Causality/Repair Connection in Databases: Causality-Programs",
        "authors": [
            "Leopoldo Bertossi"
        ],
        "abstract": "In this work, answer-set programs that specify repairs of databases are used as a basis for solving computational and reasoning problems about causes for query answers from databases.\n    ",
        "submission_date": "2017-04-17T00:00:00",
        "last_modified_date": "2017-06-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.05443",
        "title": "Approximations from Anywhere and General Rough Sets",
        "authors": [
            "A. Mani"
        ],
        "abstract": "Not all approximations arise from information systems. The problem of fitting approximations, subjected to some rules (and related data), to information systems in a rough scheme of things is known as the \\emph{inverse problem}. The inverse problem is more general than the duality (or abstract representation) problems and was introduced by the present author in her earlier papers. From the practical perspective, a few (as opposed to one) theoretical frameworks may be suitable for formulating the problem itself. \\emph{Granular operator spaces} have been recently introduced and investigated by the present author in her recent work in the context of antichain based and dialectical semantics for general rough sets. The nature of the inverse problem is examined from number-theoretic and combinatorial perspectives in a higher order variant of granular operator spaces and some necessary conditions are proved. The results and the novel approach would be useful in a number of unsupervised and semi supervised learning contexts and algorithms.\n    ",
        "submission_date": "2017-04-18T00:00:00",
        "last_modified_date": "2017-04-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.05477",
        "title": "Generalized Ideals and Co-Granular Rough Sets",
        "authors": [
            "A Mani"
        ],
        "abstract": "Lattice-theoretic ideals have been used to define and generate non granular rough approximations over general approximation spaces over the last few years by few authors. The goal of these studies, in relation based rough sets, have been to obtain nice properties comparable to those of classical rough approximations. In this research paper, these ideas are generalized in a severe way by the present author and associated semantic features are investigated by her. Granules are used in the construction of approximations in implicit ways and so a concept of co-granularity is introduced. Knowledge interpretation associable with the approaches is also investigated. This research will be of relevance for a number of logico-algebraic approaches to rough sets that proceed from point-wise definitions of approximations and also for using alternative approximations in spatial mereological contexts involving actual contact relations. The antichain based semantics invented in earlier papers by the present author also applies to the contexts considered.\n    ",
        "submission_date": "2017-04-18T00:00:00",
        "last_modified_date": "2017-04-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.05513",
        "title": "25 Tweets to Know You: A New Model to Predict Personality with Social Media",
        "authors": [
            "Pierre-Hadrien Arnoux",
            "Anbang Xu",
            "Neil Boyette",
            "Jalal Mahmud",
            "Rama Akkiraju",
            "Vibha Sinha"
        ],
        "abstract": "Predicting personality is essential for social applications supporting human-centered activities, yet prior modeling methods with users written text require too much input data to be realistically used in the context of social media. In this work, we aim to drastically reduce the data requirement for personality modeling and develop a model that is applicable to most users on Twitter. Our model integrates Word Embedding features with Gaussian Processes regression. Based on the evaluation of over 1.3K users on Twitter, we find that our model achieves comparable or better accuracy than state of the art techniques with 8 times fewer data.\n    ",
        "submission_date": "2017-04-18T00:00:00",
        "last_modified_date": "2017-04-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.05543",
        "title": "Coordinating Collaborative Chat in Massive Open Online Courses",
        "authors": [
            "Gaurav Singh Tomar",
            "Sreecharan Sankaranarayanan",
            "Xu Wang",
            "Carolyn Penstein Ros\u00e9"
        ],
        "abstract": "An earlier study of a collaborative chat intervention in a Massive Open Online Course (MOOC) identified negative effects on attrition stemming from a requirement for students to be matched with exactly one partner prior to beginning the activity. That study raised questions about how to orchestrate a collaborative chat intervention in a MOOC context in order to provide the benefit of synchronous social engagement without the coordination difficulties. In this paper we present a careful analysis of an intervention designed to overcome coordination difficulties by welcoming students into the chat on a rolling basis as they arrive rather than requiring them to be matched with a partner before beginning. The results suggest the most positive impact when experiencing a chat with exactly one partner rather than more or less. A qualitative analysis of the chat data reveals differential experiences between these configurations that suggests a potential explanation for the effect and raises questions for future research.\n    ",
        "submission_date": "2017-04-18T00:00:00",
        "last_modified_date": "2017-04-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.05566",
        "title": "Simultaneous Policy Learning and Latent State Inference for Imitating Driver Behavior",
        "authors": [
            "Jeremy Morton",
            "Mykel J. Kochenderfer"
        ],
        "abstract": "In this work, we propose a method for learning driver models that account for variables that cannot be observed directly. When trained on a synthetic dataset, our models are able to learn encodings for vehicle trajectories that distinguish between four distinct classes of driver behavior. Such encodings are learned without any knowledge of the number of driver classes or any objective that directly requires the models to learn encodings for each class. We show that driving policies trained with knowledge of latent variables are more effective than baseline methods at imitating the driver behavior that they are trained to replicate. Furthermore, we demonstrate that the actions chosen by our policy are heavily influenced by the latent variable settings that are provided to them.\n    ",
        "submission_date": "2017-04-19T00:00:00",
        "last_modified_date": "2017-04-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.05579",
        "title": "A Large Self-Annotated Corpus for Sarcasm",
        "authors": [
            "Mikhail Khodak",
            "Nikunj Saunshi",
            "Kiran Vodrahalli"
        ],
        "abstract": "We introduce the Self-Annotated Reddit Corpus (SARC), a large corpus for sarcasm research and for training and evaluating systems for sarcasm detection. The corpus has 1.3 million sarcastic statements -- 10 times more than any previous dataset -- and many times more instances of non-sarcastic statements, allowing for learning in both balanced and unbalanced label regimes. Each statement is furthermore self-annotated -- sarcasm is labeled by the author, not an independent annotator -- and provided with user, topic, and conversation context. We evaluate the corpus for accuracy, construct benchmarks for sarcasm detection, and evaluate baseline methods.\n    ",
        "submission_date": "2017-04-19T00:00:00",
        "last_modified_date": "2018-03-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.05591",
        "title": "OCRAPOSE II: An OCR-based indoor positioning system using mobile phone images",
        "authors": [
            "Hamed Sadeghi",
            "Shahrokh Valaee",
            "Shahram Shirani"
        ],
        "abstract": "In this paper, we propose an OCR (optical character recognition)-based localization system called OCRAPOSE II, which is applicable in a number of indoor scenarios including office buildings, parkings, airports, grocery stores, etc. In these scenarios, characters (i.e. texts or numbers) can be used as suitable distinctive landmarks for localization. The proposed system takes advantage of OCR to read these characters in the query still images and provides a rough location estimate using a floor plan. Then, it finds depth and angle-of-view of the query using the information provided by the OCR engine in order to refine the location estimate. We derive novel formulas for the query angle-of-view and depth estimation using image line segments and the OCR box information. We demonstrate the applicability and effectiveness of the proposed system through experiments in indoor scenarios. It is shown that our system demonstrates better performance compared to the state-of-the-art benchmarks in terms of location recognition rate and average localization error specially under sparse database condition.\n    ",
        "submission_date": "2017-04-19T00:00:00",
        "last_modified_date": "2017-04-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.05712",
        "title": "Universal Adversarial Perturbations Against Semantic Image Segmentation",
        "authors": [
            "Jan Hendrik Metzen",
            "Mummadi Chaithanya Kumar",
            "Thomas Brox",
            "Volker Fischer"
        ],
        "abstract": "While deep learning is remarkably successful on perceptual tasks, it was also shown to be vulnerable to adversarial perturbations of the input. These perturbations denote noise added to the input that was generated specifically to fool the system while being quasi-imperceptible for humans. More severely, there even exist universal perturbations that are input-agnostic but fool the network on the majority of inputs. While recent work has focused on image classification, this work proposes attacks against semantic image segmentation: we present an approach for generating (universal) adversarial perturbations that make the network yield a desired target segmentation as output. We show empirically that there exist barely perceptible universal noise patterns which result in nearly the same predicted segmentation for arbitrary inputs. Furthermore, we also show the existence of universal noise which removes a target class (e.g., all pedestrians) from the segmentation while leaving the segmentation mostly unchanged otherwise.\n    ",
        "submission_date": "2017-04-19T00:00:00",
        "last_modified_date": "2017-07-31T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.05796",
        "title": "Network Dissection: Quantifying Interpretability of Deep Visual Representations",
        "authors": [
            "David Bau",
            "Bolei Zhou",
            "Aditya Khosla",
            "Aude Oliva",
            "Antonio Torralba"
        ],
        "abstract": "We propose a general framework called Network Dissection for quantifying the interpretability of latent representations of CNNs by evaluating the alignment between individual hidden units and a set of semantic concepts. Given any CNN model, the proposed method draws on a broad data set of visual concepts to score the semantics of hidden units at each intermediate convolutional layer. The units with semantics are given labels across a range of objects, parts, scenes, textures, materials, and colors. We use the proposed method to test the hypothesis that interpretability of units is equivalent to random linear combinations of units, then we apply our method to compare the latent representations of various networks when trained to solve different supervised and self-supervised training tasks. We further analyze the effect of training iterations, compare networks trained with different initializations, examine the impact of network depth and width, and measure the effect of dropout and batch normalization on the interpretability of deep visual representations. We demonstrate that the proposed method can shed light on characteristics of CNN models and training methods that go beyond measurements of their discriminative power.\n    ",
        "submission_date": "2017-04-19T00:00:00",
        "last_modified_date": "2017-04-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.05908",
        "title": "An Interpretable Knowledge Transfer Model for Knowledge Base Completion",
        "authors": [
            "Qizhe Xie",
            "Xuezhe Ma",
            "Zihang Dai",
            "Eduard Hovy"
        ],
        "abstract": "Knowledge bases are important resources for a variety of natural language processing tasks but suffer from incompleteness. We propose a novel embedding model, \\emph{ITransF}, to perform knowledge base completion. Equipped with a sparse attention mechanism, ITransF discovers hidden concepts of relations and transfer statistical strength through the sharing of concepts. Moreover, the learned associations between relations and concepts, which are represented by sparse attention vectors, can be interpreted easily. We evaluate ITransF on two benchmark datasets---WN18 and FB15k for knowledge base completion and obtains improvements on both the mean rank and Hits@10 metrics, over all baselines that do not use additional information.\n    ",
        "submission_date": "2017-04-19T00:00:00",
        "last_modified_date": "2017-05-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.05915",
        "title": "User-driven Intelligent Interface on the Basis of Multimodal Augmented Reality and Brain-Computer Interaction for People with Functional Disabilities",
        "authors": [
            "S. Stirenko",
            "Yu. Gordienko",
            "T. Shemsedinov",
            "O. Alienin",
            "Yu. Kochura",
            "N. Gordienko",
            "A. Rojbi",
            "J.R. L\u00f3pez Benito",
            "E. Artetxe Gonz\u00e1lez"
        ],
        "abstract": "The analysis of the current integration attempts of some modes and use cases of user-machine interaction is presented. The new concept of the user-driven intelligent interface is proposed on the basis of multimodal augmented reality and brain-computer interaction for various applications: in disabilities studies, education, home care, health care, etc. The several use cases of multimodal augmentation are presented. The perspectives of the better human comprehension by the immediate feedback through neurophysical channels by means of brain-computer interaction are outlined. It is shown that brain-computer interface (BCI) technology provides new strategies to overcome limits of the currently available user interfaces, especially for people with functional disabilities. The results of the previous studies of the low end consumer and open-source BCI-devices allow us to conclude that combination of machine learning (ML), multimodal interactions (visual, sound, tactile) with BCI will profit from the immediate feedback from the actual neurophysical reactions classified by ML methods. In general, BCI in combination with other modes of AR interaction can deliver much more information than these types of interaction themselves. Even in the current state the combined AR-BCI interfaces could provide the highly adaptable and personal services, especially for people with functional disabilities.\n    ",
        "submission_date": "2017-04-12T00:00:00",
        "last_modified_date": "2017-08-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.05963",
        "title": "Monte Carlo Tree Search with Sampled Information Relaxation Dual Bounds",
        "authors": [
            "Daniel R. Jiang",
            "Lina Al-Kanj",
            "Warren B. Powell"
        ],
        "abstract": "Monte Carlo Tree Search (MCTS), most famously used in game-play artificial intelligence (e.g., the game of Go), is a well-known strategy for constructing approximate solutions to sequential decision problems. Its primary innovation is the use of a heuristic, known as a default policy, to obtain Monte Carlo estimates of downstream values for states in a decision tree. This information is used to iteratively expand the tree towards regions of states and actions that an optimal policy might visit. However, to guarantee convergence to the optimal action, MCTS requires the entire tree to be expanded asymptotically. In this paper, we propose a new technique called Primal-Dual MCTS that utilizes sampled information relaxation upper bounds on potential actions, creating the possibility of \"ignoring\" parts of the tree that stem from highly suboptimal choices. This allows us to prove that despite converging to a partial decision tree in the limit, the recommended action from Primal-Dual MCTS is optimal. The new approach shows significant promise when used to optimize the behavior of a single driver navigating a graph while operating on a ride-sharing platform. Numerical experiments on a real dataset of 7,000 trips in New Jersey suggest that Primal-Dual MCTS improves upon standard MCTS by producing deeper decision trees and exhibits a reduced sensitivity to the size of the action space.\n    ",
        "submission_date": "2017-04-20T00:00:00",
        "last_modified_date": "2017-04-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.05972",
        "title": "SemEval-2017 Task 8: RumourEval: Determining rumour veracity and support for rumours",
        "authors": [
            "Leon Derczynski",
            "Kalina Bontcheva",
            "Maria Liakata",
            "Rob Procter",
            "Geraldine Wong Sak Hoi",
            "Arkaitz Zubiaga"
        ],
        "abstract": "Media is full of false claims. Even Oxford Dictionaries named \"post-truth\" as the word of 2016. This makes it more important than ever to build systems that can identify the veracity of a story, and the kind of discourse there is around it. RumourEval is a SemEval shared task that aims to identify and handle rumours and reactions to them, in text. We present an annotation scheme, a large dataset covering multiple topics - each having their own families of claims and replies - and use these to pose two concrete challenges as well as the results achieved by participants on these challenges.\n    ",
        "submission_date": "2017-04-20T00:00:00",
        "last_modified_date": "2017-04-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.06033",
        "title": "Predicting Cognitive Decline with Deep Learning of Brain Metabolism and Amyloid Imaging",
        "authors": [
            "Hongyoon Choi",
            "Kyong Hwan Jin"
        ],
        "abstract": "For effective treatment of Alzheimer disease (AD), it is important to identify subjects who are most likely to exhibit rapid cognitive decline. Herein, we developed a novel framework based on a deep convolutional neural network which can predict future cognitive decline in mild cognitive impairment (MCI) patients using flurodeoxyglucose and florbetapir positron emission tomography (PET). The architecture of the network only relies on baseline PET studies of AD and normal subjects as the training dataset. Feature extraction and complicated image preprocessing including nonlinear warping are unnecessary for our approach. Accuracy of prediction (84.2%) for conversion to AD in MCI patients outperformed conventional feature-based quantification approaches. ROC analyses revealed that performance of CNN-based approach was significantly higher than that of the conventional quantification methods (p < 0.05). Output scores of the network were strongly correlated with the longitudinal change in cognitive measurements. These results show the feasibility of deep learning as a tool for predicting disease outcome using brain images.\n    ",
        "submission_date": "2017-04-20T00:00:00",
        "last_modified_date": "2017-04-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.06193",
        "title": "Intrusion Prevention and Detection in Grid Computing - The ALICE Case",
        "authors": [
            "Andres Gomez",
            "Camilo Lara",
            "Udo Kebschull"
        ],
        "abstract": "Grids allow users flexible on-demand usage of computing resources through remote communication networks. A remarkable example of a Grid in High Energy Physics (HEP) research is used in the ALICE experiment at European Organization for Nuclear Research CERN. Physicists can submit jobs used to process the huge amount of particle collision data produced by the Large Hadron Collider (LHC). Grids face complex security challenges. They are interesting targets for attackers seeking for huge computational resources. Since users can execute arbitrary code in the worker nodes on the Grid sites, special care should be put in this environment. Automatic tools to harden and monitor this scenario are required. Currently, there is no integrated solution for such requirement. This paper describes a new security framework to allow execution of job payloads in a sandboxed context. It also allows process behavior monitoring to detect intrusions, even when new attack methods or zero day vulnerabilities are exploited, by a Machine Learning approach. We plan to implement the proposed framework as a software prototype that will be tested as a component of the ALICE Grid middleware.\n    ",
        "submission_date": "2017-04-20T00:00:00",
        "last_modified_date": "2017-04-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.06194",
        "title": "Improved Neural Relation Detection for Knowledge Base Question Answering",
        "authors": [
            "Mo Yu",
            "Wenpeng Yin",
            "Kazi Saidul Hasan",
            "Cicero dos Santos",
            "Bing Xiang",
            "Bowen Zhou"
        ],
        "abstract": "Relation detection is a core component for many NLP applications including Knowledge Base Question Answering (KBQA). In this paper, we propose a hierarchical recurrent neural network enhanced by residual learning that detects KB relations given an input question. Our method uses deep residual bidirectional LSTMs to compare questions and relation names via different hierarchies of abstraction. Additionally, we propose a simple KBQA system that integrates entity linking and our proposed relation detector to enable one enhance another. Experimental results evidence that our approach achieves not only outstanding relation detection performance, but more importantly, it helps our KBQA system to achieve state-of-the-art accuracy for both single-relation (SimpleQuestions) and multi-relation (WebQSP) QA benchmarks.\n    ",
        "submission_date": "2017-04-20T00:00:00",
        "last_modified_date": "2017-05-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.06215",
        "title": "On Singleton Arc Consistency for CSPs Defined by Monotone Patterns",
        "authors": [
            "Clement Carbonnel",
            "David A. Cohen",
            "Martin C. Cooper",
            "Stanislav Zivny"
        ],
        "abstract": "Singleton arc consistency is an important type of local consistency which has been recently shown to solve all constraint satisfaction problems (CSPs) over constraint languages of bounded width. We aim to characterise all classes of CSPs defined by a forbidden pattern that are solved by singleton arc consistency and closed under removing constraints. We identify five new patterns whose absence ensures solvability by singleton arc consistency, four of which are provably maximal and three of which generalise 2-SAT. Combined with simple counter-examples for other patterns, we make significant progress towards a complete classification.\n    ",
        "submission_date": "2017-04-20T00:00:00",
        "last_modified_date": "2018-08-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.06259",
        "title": "A Semantic QA-Based Approach for Text Summarization Evaluation",
        "authors": [
            "Ping Chen",
            "Fei Wu",
            "Tong Wang",
            "Wei Ding"
        ],
        "abstract": "Many Natural Language Processing and Computational Linguistics applications involves the generation of new texts based on some existing texts, such as summarization, text simplification and machine translation. However, there has been a serious problem haunting these applications for decades, that is, how to automatically and accurately assess quality of these applications. In this paper, we will present some preliminary results on one especially useful and challenging problem in NLP system evaluation: how to pinpoint content differences of two text passages (especially for large pas-sages such as articles and books). Our idea is intuitive and very different from existing approaches. We treat one text passage as a small knowledge base, and ask it a large number of questions to exhaustively identify all content points in it. By comparing the correctly answered questions from two text passages, we will be able to compare their content precisely. The experiment using 2007 DUC summarization corpus clearly shows promising results.\n    ",
        "submission_date": "2017-04-21T00:00:00",
        "last_modified_date": "2018-04-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.06857",
        "title": "A Review on Deep Learning Techniques Applied to Semantic Segmentation",
        "authors": [
            "Alberto Garcia-Garcia",
            "Sergio Orts-Escolano",
            "Sergiu Oprea",
            "Victor Villena-Martinez",
            "Jose Garcia-Rodriguez"
        ],
        "abstract": "Image semantic segmentation is more and more being of interest for computer vision and machine learning researchers. Many applications on the rise need accurate and efficient segmentation mechanisms: autonomous driving, indoor navigation, and even virtual or augmented reality systems to name a few. This demand coincides with the rise of deep learning approaches in almost every field or application target related to computer vision, including semantic segmentation or scene understanding. This paper provides a review on deep learning methods for semantic segmentation applied to various application areas. Firstly, we describe the terminology of this field as well as mandatory background concepts. Next, the main datasets and challenges are exposed to help researchers decide which are the ones that best suit their needs and their targets. Then, existing methods are reviewed, highlighting their contributions and their significance in the field. Finally, quantitative results are given for the described methods and the datasets in which they were evaluated, following up with a discussion of the results. At last, we point out a set of promising future works and draw our own conclusions about the state of the art of semantic segmentation using deep learning techniques.\n    ",
        "submission_date": "2017-04-22T00:00:00",
        "last_modified_date": "2017-04-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.06885",
        "title": "A General Theory for Training Learning Machine",
        "authors": [
            "Hong Zhao"
        ],
        "abstract": "Though the deep learning is pushing the machine learning to a new stage, basic theories of machine learning are still limited. The principle of learning, the role of the a prior knowledge, the role of neuron bias, and the basis for choosing neural transfer function and cost function, etc., are still far from clear. In this paper, we present a general theoretical framework for machine learning. We classify the prior knowledge into common and problem-dependent parts, and consider that the aim of learning is to maximally incorporate them. The principle we suggested for maximizing the former is the design risk minimization principle, while the neural transfer function, the cost function, as well as pretreatment of samples, are endowed with the role for maximizing the latter. The role of the neuron bias is explained from a different angle. We develop a Monte Carlo algorithm to establish the input-output responses, and we control the input-output sensitivity of a learning machine by controlling that of individual neurons. Applications of function approaching and smoothing, pattern recognition and classification, are provided to illustrate how to train general learning machines based on our theory and algorithm. Our method may in addition induce new applications, such as the transductive inference.\n    ",
        "submission_date": "2017-04-23T00:00:00",
        "last_modified_date": "2017-04-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.06956",
        "title": "Naturalizing a Programming Language via Interactive Learning",
        "authors": [
            "Sida I. Wang",
            "Samuel Ginn",
            "Percy Liang",
            "Christoper D. Manning"
        ],
        "abstract": "Our goal is to create a convenient natural language interface for performing well-specified but complex actions such as analyzing data, manipulating text, and querying databases. However, existing natural language interfaces for such tasks are quite primitive compared to the power one wields with a programming language. To bridge this gap, we start with a core programming language and allow users to \"naturalize\" the core language incrementally by defining alternative, more natural syntax and increasingly complex concepts in terms of compositions of simpler ones. In a voxel world, we show that a community of users can simultaneously teach a common system a diverse language and use it to build hundreds of complex voxel structures. Over the course of three days, these users went from using only the core language to using the naturalized language in 85.9\\% of the last 10K utterances.\n    ",
        "submission_date": "2017-04-23T00:00:00",
        "last_modified_date": "2017-04-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.07121",
        "title": "Being Negative but Constructively: Lessons Learnt from Creating Better Visual Question Answering Datasets",
        "authors": [
            "Wei-Lun Chao",
            "Hexiang Hu",
            "Fei Sha"
        ],
        "abstract": "Visual question answering (Visual QA) has attracted a lot of attention lately, seen essentially as a form of (visual) Turing test that artificial intelligence should strive to achieve. In this paper, we study a crucial component of this task: how can we design good datasets for the task? We focus on the design of multiple-choice based datasets where the learner has to select the right answer from a set of candidate ones including the target (\\ie the correct one) and the decoys (\\ie the incorrect ones). Through careful analysis of the results attained by state-of-the-art learning models and human annotators on existing datasets, we show that the design of the decoy answers has a significant impact on how and what the learning models learn from the datasets. In particular, the resulting learner can ignore the visual information, the question, or both while still doing well on the task. Inspired by this, we propose automatic procedures to remedy such design deficiencies. We apply the procedures to re-construct decoy answers for two popular Visual QA datasets as well as to create a new Visual QA dataset from the Visual Genome project, resulting in the largest dataset for this task. Extensive empirical studies show that the design deficiencies have been alleviated in the remedied datasets and the performance on them is likely a more faithful indicator of the difference among learning models. The datasets are released and publicly available via ",
        "submission_date": "2017-04-24T00:00:00",
        "last_modified_date": "2018-06-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.07221",
        "title": "Turing at SemEval-2017 Task 8: Sequential Approach to Rumour Stance Classification with Branch-LSTM",
        "authors": [
            "Elena Kochkina",
            "Maria Liakata",
            "Isabelle Augenstein"
        ],
        "abstract": "This paper describes team Turing's submission to SemEval 2017 RumourEval: Determining rumour veracity and support for rumours (SemEval 2017 Task 8, Subtask A). Subtask A addresses the challenge of rumour stance classification, which involves identifying the attitude of Twitter users towards the truthfulness of the rumour they are discussing. Stance classification is considered to be an important step towards rumour verification, therefore performing well in this task is expected to be useful in debunking false rumours. In this work we classify a set of Twitter posts discussing rumours into either supporting, denying, questioning or commenting on the underlying rumours. We propose a LSTM-based sequential model that, through modelling the conversational structure of tweets, which achieves an accuracy of 0.784 on the RumourEval test set outperforming all other systems in Subtask A.\n    ",
        "submission_date": "2017-04-24T00:00:00",
        "last_modified_date": "2017-04-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.07402",
        "title": "Towards Instance Segmentation with Object Priority: Prominent Object Detection and Recognition",
        "authors": [
            "Hamed R. Tavakoli",
            "Jorma Laaksonen"
        ],
        "abstract": "This manuscript introduces the problem of prominent object detection and recognition inspired by the fact that human seems to priorities perception of scene elements. The problem deals with finding the most important region of interest, segmenting the relevant item/object in that area, and assigning it an object class label. In other words, we are solving the three problems of saliency modeling, saliency detection, and object recognition under one umbrella. The motivation behind such a problem formulation is (1) the benefits to the knowledge representation-based vision pipelines, and (2) the potential improvements in emulating bio-inspired vision systems by solving these three problems together. We are foreseeing extending this problem formulation to fully semantically segmented scenes with instance object priority for high-level inferences in various applications including assistive vision. Along with a new problem definition, we also propose a method to achieve such a task. The proposed model predicts the most important area in the image, segments the associated objects, and labels them. The proposed problem and method are evaluated against human fixations, annotated segmentation masks, and object class categories. We define a chance level for each of the evaluation criterion to compare the proposed algorithm with. Despite the good performance of the proposed baseline, the overall evaluations indicate that the problem of prominent object detection and recognition is a challenging task that is still worth investigating further.\n    ",
        "submission_date": "2017-04-24T00:00:00",
        "last_modified_date": "2017-08-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.07434",
        "title": "Paying Attention to Descriptions Generated by Image Captioning Models",
        "authors": [
            "Hamed R. Tavakoli",
            "Rakshith Shetty",
            "Ali Borji",
            "Jorma Laaksonen"
        ],
        "abstract": "To bridge the gap between humans and machines in image understanding and describing, we need further insight into how people describe a perceived scene. In this paper, we study the agreement between bottom-up saliency-based visual attention and object referrals in scene description constructs. We investigate the properties of human-written descriptions and machine-generated ones. We then propose a saliency-boosted image captioning model in order to investigate benefits from low-level cues in language models. We learn that (1) humans mention more salient objects earlier than less salient ones in their descriptions, (2) the better a captioning model performs, the better attention agreement it has with human descriptions, (3) the proposed saliency-boosted model, compared to its baseline form, does not improve significantly on the MS COCO database, indicating explicit bottom-up boosting does not help when the task is well learnt and tuned on a data, (4) a better generalization is, however, observed for the saliency-boosted model on unseen data.\n    ",
        "submission_date": "2017-04-24T00:00:00",
        "last_modified_date": "2017-08-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.07468",
        "title": "GaKCo: a Fast GApped k-mer string Kernel using COunting",
        "authors": [
            "Ritambhara Singh",
            "Arshdeep Sekhon",
            "Kamran Kowsari",
            "Jack Lanchantin",
            "Beilun Wang",
            "Yanjun Qi"
        ],
        "abstract": "String Kernel (SK) techniques, especially those using gapped $k$-mers as features (gk), have obtained great success in classifying sequences like DNA, protein, and text. However, the state-of-the-art gk-SK runs extremely slow when we increase the dictionary size ($\\Sigma$) or allow more mismatches ($M$). This is because current gk-SK uses a trie-based algorithm to calculate co-occurrence of mismatched substrings resulting in a time cost proportional to $O(\\Sigma^{M})$. We propose a \\textbf{fast} algorithm for calculating \\underline{Ga}pped $k$-mer \\underline{K}ernel using \\underline{Co}unting (GaKCo). GaKCo uses associative arrays to calculate the co-occurrence of substrings using cumulative counting. This algorithm is fast, scalable to larger $\\Sigma$ and $M$, and naturally parallelizable. We provide a rigorous asymptotic analysis that compares GaKCo with the state-of-the-art gk-SK. Theoretically, the time cost of GaKCo is independent of the $\\Sigma^{M}$ term that slows down the trie-based approach. Experimentally, we observe that GaKCo achieves the same accuracy as the state-of-the-art and outperforms its speed by factors of 2, 100, and 4, on classifying sequences of DNA (5 datasets), protein (12 datasets), and character-based English text (2 datasets), respectively.\n",
        "submission_date": "2017-04-24T00:00:00",
        "last_modified_date": "2017-09-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.07489",
        "title": "Multi-Task Video Captioning with Video and Entailment Generation",
        "authors": [
            "Ramakanth Pasunuru",
            "Mohit Bansal"
        ],
        "abstract": "Video captioning, the task of describing the content of a video, has seen some promising improvements in recent years with sequence-to-sequence models, but accurately learning the temporal and logical dynamics involved in the task still remains a challenge, especially given the lack of sufficient annotated data. We improve video captioning by sharing knowledge with two related directed-generation tasks: a temporally-directed unsupervised video prediction task to learn richer context-aware video encoder representations, and a logically-directed language entailment generation task to learn better video-entailed caption decoder representations. For this, we present a many-to-many multi-task learning model that shares parameters across the encoders and decoders of the three tasks. We achieve significant improvements and the new state-of-the-art on several standard video captioning datasets using diverse automatic and human evaluations. We also show mutual multi-task improvements on the entailment generation task.\n    ",
        "submission_date": "2017-04-24T00:00:00",
        "last_modified_date": "2017-08-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.07499",
        "title": "PPMF: A Patient-based Predictive Modeling Framework for Early ICU Mortality Prediction",
        "authors": [
            "Mohammad Amin Morid",
            "Olivia R. Liu Sheng",
            "Samir Abdelrahman"
        ],
        "abstract": "To date, developing a good model for early intensive care unit (ICU) mortality prediction is still challenging. This paper presents a patient based predictive modeling framework (PPMF) to improve the performance of ICU mortality prediction using data collected during the first 48 hours of ICU admission. PPMF consists of three main components verifying three related research hypotheses. The first component captures dynamic changes of patients status in the ICU using their time series data (e.g., vital signs and laboratory tests). The second component is a local approximation algorithm that classifies patients based on their similarities. The third component is a Gradient Decent wrapper that updates feature weights according to the classification feedback. Experiments using data from MIMICIII show that PPMF significantly outperforms: (1) the severity score systems, namely SASP III, APACHE IV, and MPM0III, (2) the aggregation based classifiers that utilize summarized time series, and (3) baseline feature selection methods.\n    ",
        "submission_date": "2017-04-25T00:00:00",
        "last_modified_date": "2017-04-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.07535",
        "title": "Abstract Syntax Networks for Code Generation and Semantic Parsing",
        "authors": [
            "Maxim Rabinovich",
            "Mitchell Stern",
            "Dan Klein"
        ],
        "abstract": "Tasks like code generation and semantic parsing require mapping unstructured (or partially structured) inputs to well-formed, executable outputs. We introduce abstract syntax networks, a modeling framework for these problems. The outputs are represented as abstract syntax trees (ASTs) and constructed by a decoder with a dynamically-determined modular structure paralleling the structure of the output tree. On the benchmark Hearthstone dataset for code generation, our model obtains 79.2 BLEU and 22.7% exact match accuracy, compared to previous state-of-the-art values of 67.1 and 6.1%. Furthermore, we perform competitively on the Atis, Jobs, and Geo semantic parsing datasets with no task-specific engineering.\n    ",
        "submission_date": "2017-04-25T00:00:00",
        "last_modified_date": "2017-04-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.07624",
        "title": "280 Birds with One Stone: Inducing Multilingual Taxonomies from Wikipedia using Character-level Classification",
        "authors": [
            "Amit Gupta",
            "R\u00e9mi Lebret",
            "Hamza Harkous",
            "Karl Aberer"
        ],
        "abstract": "We propose a simple, yet effective, approach towards inducing multilingual taxonomies from Wikipedia. Given an English taxonomy, our approach leverages the interlanguage links of Wikipedia followed by character-level classifiers to induce high-precision, high-coverage taxonomies in other languages. Through experiments, we demonstrate that our approach significantly outperforms the state-of-the-art, heuristics-heavy approaches for six languages. As a consequence of our work, we release presumably the largest and the most accurate multilingual taxonomic resource spanning over 280 languages.\n    ",
        "submission_date": "2017-04-25T00:00:00",
        "last_modified_date": "2017-09-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.07751",
        "title": "Fine-Grained Entity Typing with High-Multiplicity Assignments",
        "authors": [
            "Maxim Rabinovich",
            "Dan Klein"
        ],
        "abstract": "As entity type systems become richer and more fine-grained, we expect the number of types assigned to a given entity to increase. However, most fine-grained typing work has focused on datasets that exhibit a low degree of type multiplicity. In this paper, we consider the high-multiplicity regime inherent in data sources such as Wikipedia that have semi-open type systems. We introduce a set-prediction approach to this problem and show that our model outperforms unstructured baselines on a new Wikipedia-based fine-grained typing corpus.\n    ",
        "submission_date": "2017-04-25T00:00:00",
        "last_modified_date": "2017-04-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.08045",
        "title": "The loss surface of deep and wide neural networks",
        "authors": [
            "Quynh Nguyen",
            "Matthias Hein"
        ],
        "abstract": "While the optimization problem behind deep neural networks is highly non-convex, it is frequently observed in practice that training deep networks seems possible without getting stuck in suboptimal points. It has been argued that this is the case as all local minima are close to being globally optimal. We show that this is (almost) true, in fact almost all local minima are globally optimal, for a fully connected network with squared loss and analytic activation function given that the number of hidden units of one layer of the network is larger than the number of training points and the network structure from this layer on is pyramidal.\n    ",
        "submission_date": "2017-04-26T00:00:00",
        "last_modified_date": "2017-06-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.08092",
        "title": "A Recurrent Neural Model with Attention for the Recognition of Chinese Implicit Discourse Relations",
        "authors": [
            "Samuel R\u00f6nnqvist",
            "Niko Schenk",
            "Christian Chiarcos"
        ],
        "abstract": "We introduce an attention-based Bi-LSTM for Chinese implicit discourse relations and demonstrate that modeling argument pairs as a joint sequence can outperform word order-agnostic approaches. Our model benefits from a partial sampling scheme and is conceptually simple, yet achieves state-of-the-art performance on the Chinese Discourse Treebank. We also visualize its attention activity to illustrate the model's ability to selectively focus on the relevant parts of an input sequence.\n    ",
        "submission_date": "2017-04-26T00:00:00",
        "last_modified_date": "2017-04-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.08101",
        "title": "Event Stream-Based Process Discovery using Abstract Representations",
        "authors": [
            "Sebastiaan J. van Zelst",
            "Boudewijn F. van Dongen",
            "Wil M.P. van der Aalst"
        ],
        "abstract": "The aim of process discovery, originating from the area of process mining, is to discover a process model based on business process execution data. A majority of process discovery techniques relies on an event log as an input. An event log is a static source of historical data capturing the execution of a business process. In this paper we focus on process discovery relying on online streams of business process execution events. Learning process models from event streams poses both challenges and opportunities, i.e. we need to handle unlimited amounts of data using finite memory and, preferably, constant time. We propose a generic architecture that allows for adopting several classes of existing process discovery techniques in context of event streams. Moreover, we provide several instantiations of the architecture, accompanied by implementations in the process mining tool-kit ProM (",
        "submission_date": "2017-04-25T00:00:00",
        "last_modified_date": "2017-04-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.08165",
        "title": "A Generalization of Convolutional Neural Networks to Graph-Structured Data",
        "authors": [
            "Yotam Hechtlinger",
            "Purvasha Chakravarti",
            "Jining Qin"
        ],
        "abstract": "This paper introduces a generalization of Convolutional Neural Networks (CNNs) from low-dimensional grid data, such as images, to graph-structured data. We propose a novel spatial convolution utilizing a random walk to uncover the relations within the input, analogous to the way the standard convolution uses the spatial neighborhood of a pixel on the grid. The convolution has an intuitive interpretation, is efficient and scalable and can also be used on data with varying graph structure. Furthermore, this generalization can be applied to many standard regression or classification problems, by learning the the underlying graph. We empirically demonstrate the performance of the proposed CNN on MNIST, and challenge the state-of-the-art on Merck molecular activity data set.\n    ",
        "submission_date": "2017-04-26T00:00:00",
        "last_modified_date": "2017-04-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.08224",
        "title": "Punny Captions: Witty Wordplay in Image Descriptions",
        "authors": [
            "Arjun Chandrasekaran",
            "Devi Parikh",
            "Mohit Bansal"
        ],
        "abstract": "Wit is a form of rich interaction that is often grounded in a specific situation (e.g., a comment in response to an event). In this work, we attempt to build computational models that can produce witty descriptions for a given image. Inspired by a cognitive account of humor appreciation, we employ linguistic wordplay, specifically puns, in image descriptions. We develop two approaches which involve retrieving witty descriptions for a given image from a large corpus of sentences, or generating them via an encoder-decoder neural network architecture. We compare our approach against meaningful baseline approaches via human studies and show substantial improvements. We find that when a human is subject to similar constraints as the model regarding word usage and style, people vote the image descriptions generated by our model to be slightly wittier than human-written witty descriptions. Unsurprisingly, humans are almost always wittier than the model when they are free to choose the vocabulary, style, etc.\n    ",
        "submission_date": "2017-04-26T00:00:00",
        "last_modified_date": "2018-05-31T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.08243",
        "title": "C-VQA: A Compositional Split of the Visual Question Answering (VQA) v1.0 Dataset",
        "authors": [
            "Aishwarya Agrawal",
            "Aniruddha Kembhavi",
            "Dhruv Batra",
            "Devi Parikh"
        ],
        "abstract": "Visual Question Answering (VQA) has received a lot of attention over the past couple of years. A number of deep learning models have been proposed for this task. However, it has been shown that these models are heavily driven by superficial correlations in the training data and lack compositionality -- the ability to answer questions about unseen compositions of seen concepts. This compositionality is desirable and central to intelligence. In this paper, we propose a new setting for Visual Question Answering where the test question-answer pairs are compositionally novel compared to training question-answer pairs. To facilitate developing models under this setting, we present a new compositional split of the VQA v1.0 dataset, which we call Compositional VQA (C-VQA). We analyze the distribution of questions and answers in the C-VQA splits. Finally, we evaluate several existing VQA models under this new setting and show that the performances of these models degrade by a significant amount compared to the original VQA setting.\n    ",
        "submission_date": "2017-04-26T00:00:00",
        "last_modified_date": "2017-04-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.08424",
        "title": "Multimodal Word Distributions",
        "authors": [
            "Ben Athiwaratkun",
            "Andrew Gordon Wilson"
        ],
        "abstract": "Word embeddings provide point representations of words containing useful semantic information. We introduce multimodal word distributions formed from Gaussian mixtures, for multiple word meanings, entailment, and rich uncertainty information. To learn these distributions, we propose an energy-based max-margin objective. We show that the resulting approach captures uniquely expressive semantic information, and outperforms alternatives, such as word2vec skip-grams, and Gaussian embeddings, on benchmark datasets such as word similarity and entailment.\n    ",
        "submission_date": "2017-04-27T00:00:00",
        "last_modified_date": "2019-09-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.08483",
        "title": "No, This is not a Circle",
        "authors": [
            "Zolt\u00e1n Kov\u00e1cs"
        ],
        "abstract": "A popular curve shown in introductory maths textbooks, seems like a circle. But it is actually a different curve. This paper discusses some elementary approaches to identify the geometric object, including novel technological means by using GeoGebra. We demonstrate two ways to refute the false impression, two suggestions to find a correct conjecture, and four ways to confirm the result by proving it rigorously.\n",
        "submission_date": "2017-04-27T00:00:00",
        "last_modified_date": "2017-05-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.08509",
        "title": "No More Discrimination: Cross City Adaptation of Road Scene Segmenters",
        "authors": [
            "Yi-Hsin Chen",
            "Wei-Yu Chen",
            "Yu-Ting Chen",
            "Bo-Cheng Tsai",
            "Yu-Chiang Frank Wang",
            "Min Sun"
        ],
        "abstract": "Despite the recent success of deep-learning based semantic segmentation, deploying a pre-trained road scene segmenter to a city whose images are not presented in the training set would not achieve satisfactory performance due to dataset biases. Instead of collecting a large number of annotated images of each city of interest to train or refine the segmenter, we propose an unsupervised learning approach to adapt road scene segmenters across different cities. By utilizing Google Street View and its time-machine feature, we can collect unannotated images for each road scene at different times, so that the associated static-object priors can be extracted accordingly. By advancing a joint global and class-specific domain adversarial learning framework, adaptation of pre-trained segmenters to that city can be achieved without the need of any user annotation or interaction. We show that our method improves the performance of semantic segmentation in multiple cities across continents, while it performs favorably against state-of-the-art approaches requiring annotated training data.\n    ",
        "submission_date": "2017-04-27T00:00:00",
        "last_modified_date": "2017-04-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.08544",
        "title": "Network-based coverage of mutational profiles reveals cancer genes",
        "authors": [
            "Borislav H. Hristov",
            "Mona Singh"
        ],
        "abstract": "A central goal in cancer genomics is to identify the somatic alterations that underpin tumor initiation and progression. This task is challenging as the mutational profiles of cancer genomes exhibit vast heterogeneity, with many alterations observed within each individual, few shared somatically mutated genes across individuals, and important roles in cancer for both frequently and infrequently mutated genes. While commonly mutated cancer genes are readily identifiable, those that are rarely mutated across samples are difficult to distinguish from the large numbers of other infrequently mutated genes. Here, we introduce a method that considers per-individual mutational profiles within the context of protein-protein interaction networks in order to identify small connected subnetworks of genes that, while not individually frequently mutated, comprise pathways that are perturbed across (i.e., \"cover\") a large fraction of the individuals. We devise a simple yet intuitive objective function that balances identifying a small subset of genes with covering a large fraction of individuals. We show how to solve this problem optimally using integer linear programming and also give a fast heuristic algorithm that works well in practice. We perform a large-scale evaluation of our resulting method, nCOP, on 6,038 TCGA tumor samples across 24 different cancer types. We demonstrate that our approach nCOP is more effective in identifying cancer genes than both methods that do not utilize any network information as well as state-of-the-art network-based methods that aggregate mutational information across individuals. Overall, our work demonstrates the power of combining per-individual mutational information with interaction networks in order to uncover genes functionally relevant in cancers, and in particular those genes that are less frequently mutated.\n    ",
        "submission_date": "2017-04-26T00:00:00",
        "last_modified_date": "2017-04-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.08676",
        "title": "Learning the structure of Bayesian Networks: A quantitative assessment of the effect of different algorithmic schemes",
        "authors": [
            "Stefano Beretta",
            "Mauro Castelli",
            "Ivo Goncalves",
            "Roberto Henriques",
            "Daniele Ramazzotti"
        ],
        "abstract": "One of the most challenging tasks when adopting Bayesian Networks (BNs) is the one of learning their structure from data. This task is complicated by the huge search space of possible solutions, and by the fact that the problem is NP-hard. Hence, full enumeration of all the possible solutions is not always feasible and approximations are often required. However, to the best of our knowledge, a quantitative analysis of the performance and characteristics of the different heuristics to solve this problem has never been done before.\n",
        "submission_date": "2017-04-27T00:00:00",
        "last_modified_date": "2018-08-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.08716",
        "title": "Artificial Intelligence Based Malware Analysis",
        "authors": [
            "Avi Pfeffer",
            "Brian Ruttenberg",
            "Lee Kellogg",
            "Michael Howard",
            "Catherine Call",
            "Alison O'Connor",
            "Glenn Takata",
            "Scott Neal Reilly",
            "Terry Patten",
            "Jason Taylor",
            "Robert Hall",
            "Arun Lakhotia",
            "Craig Miles",
            "Dan Scofield",
            "Jared Frank"
        ],
        "abstract": "Artificial intelligence methods have often been applied to perform specific functions or tasks in the cyber-defense realm. However, as adversary methods become more complex and difficult to divine, piecemeal efforts to understand cyber-attacks, and malware-based attacks in particular, are not providing sufficient means for malware analysts to understand the past, present and future characteristics of malware.\n",
        "submission_date": "2017-04-27T00:00:00",
        "last_modified_date": "2017-04-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.08772",
        "title": "Deep Face Deblurring",
        "authors": [
            "Grigorios G. Chrysos",
            "Stefanos Zafeiriou"
        ],
        "abstract": "Blind deblurring consists a long studied task, however the outcomes of generic methods are not effective in real world blurred images. Domain-specific methods for deblurring targeted object categories, e.g. text or faces, frequently outperform their generic counterparts, hence they are attracting an increasing amount of attention. In this work, we develop such a domain-specific method to tackle deblurring of human faces, henceforth referred to as face deblurring. Studying faces is of tremendous significance in computer vision, however face deblurring has yet to demonstrate some convincing results. This can be partly attributed to the combination of i) poor texture and ii) highly structure shape that yield the contour/gradient priors (that are typically used) sub-optimal. In our work instead of making assumptions over the prior, we adopt a learning approach by inserting weak supervision that exploits the well-documented structure of the face. Namely, we utilise a deep network to perform the deblurring and employ a face alignment technique to pre-process each face. We additionally surpass the requirement of the deep network for thousands training samples, by introducing an efficient framework that allows the generation of a large dataset. We utilised this framework to create 2MF2, a dataset of over two million frames. We conducted experiments with real world blurred facial images and report that our method returns a result close to the sharp natural latent image.\n    ",
        "submission_date": "2017-04-27T00:00:00",
        "last_modified_date": "2017-05-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.08847",
        "title": "Parseval Networks: Improving Robustness to Adversarial Examples",
        "authors": [
            "Moustapha Cisse",
            "Piotr Bojanowski",
            "Edouard Grave",
            "Yann Dauphin",
            "Nicolas Usunier"
        ],
        "abstract": "We introduce Parseval networks, a form of deep neural networks in which the Lipschitz constant of linear, convolutional and aggregation layers is constrained to be smaller than 1. Parseval networks are empirically and theoretically motivated by an analysis of the robustness of the predictions made by deep neural networks when their input is subject to an adversarial perturbation. The most important feature of Parseval networks is to maintain weight matrices of linear and convolutional layers to be (approximately) Parseval tight frames, which are extensions of orthogonal matrices to non-square matrices. We describe how these constraints can be maintained efficiently during SGD. We show that Parseval networks match the state-of-the-art in terms of accuracy on CIFAR-10/100 and Street View House Numbers (SVHN) while being more robust than their vanilla counterpart against adversarial examples. Incidentally, Parseval networks also tend to train faster and make a better usage of the full capacity of the networks.\n    ",
        "submission_date": "2017-04-28T00:00:00",
        "last_modified_date": "2017-05-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.08914",
        "title": "Past, Present, Future: A Computational Investigation of the Typology of Tense in 1000 Languages",
        "authors": [
            "Ehsaneddin Asgari",
            "Hinrich Sch\u00fctze"
        ],
        "abstract": "We present SuperPivot, an analysis method for low-resource languages that occur in a superparallel corpus, i.e., in a corpus that contains an order of magnitude more languages than parallel corpora currently in use. We show that SuperPivot performs well for the crosslingual analysis of the linguistic phenomenon of tense. We produce analysis results for more than 1000 languages, conducting - to the best of our knowledge - the largest crosslingual computational study performed to date. We extend existing methodology for leveraging parallel corpora for typological analysis by overcoming a limiting assumption of earlier work: We only require that a linguistic feature is overtly marked in a few of thousands of languages as opposed to requiring that it be marked in all languages under investigation.\n    ",
        "submission_date": "2017-04-28T00:00:00",
        "last_modified_date": "2017-09-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1704.08966",
        "title": "Not All Dialogues are Created Equal: Instance Weighting for Neural Conversational Models",
        "authors": [
            "Pierre Lison",
            "Serge Bibauw"
        ],
        "abstract": "Neural conversational models require substantial amounts of dialogue data for their parameter estimation and are therefore usually learned on large corpora such as chat forums or movie subtitles. These corpora are, however, often challenging to work with, notably due to their frequent lack of turn segmentation and the presence of multiple references external to the dialogue itself. This paper shows that these challenges can be mitigated by adding a weighting model into the architecture. The weighting model, which is itself estimated from dialogue data, associates each training example to a numerical weight that reflects its intrinsic quality for dialogue modelling. At training time, these sample weights are included into the empirical loss to be minimised. Evaluation results on retrieval-based models trained on movie and TV subtitles demonstrate that the inclusion of such a weighting model improves the model performance on unsupervised metrics.\n    ",
        "submission_date": "2017-04-28T00:00:00",
        "last_modified_date": "2017-07-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.00094",
        "title": "The Impact of Coevolution and Abstention on the Emergence of Cooperation",
        "authors": [
            "Marcos Cardinot",
            "Colm O'Riordan",
            "Josephine Griffith"
        ],
        "abstract": "This paper explores the Coevolutionary Optional Prisoner's Dilemma (COPD) game, which is a simple model to coevolve game strategy and link weights of agents playing the Optional Prisoner's Dilemma game. We consider a population of agents placed in a lattice grid with boundary conditions. A number of Monte Carlo simulations are performed to investigate the impacts of the COPD game on the emergence of cooperation. Results show that the coevolutionary rules enable cooperators to survive and even dominate, with the presence of abstainers in the population playing a key role in the protection of cooperators against exploitation from defectors. We observe that in adverse conditions such as when the initial population of abstainers is too scarce/abundant, or when the temptation to defect is very high, cooperation has no chance of emerging. However, when the simple coevolutionary rules are applied, cooperators flourish.\n    ",
        "submission_date": "2017-04-28T00:00:00",
        "last_modified_date": "2017-04-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.00106",
        "title": "Learning to Ask: Neural Question Generation for Reading Comprehension",
        "authors": [
            "Xinya Du",
            "Junru Shao",
            "Claire Cardie"
        ],
        "abstract": "We study automatic question generation for sentences from text passages in reading comprehension. We introduce an attention-based sequence learning model for the task and investigate the effect of encoding sentence- vs. paragraph-level information. In contrast to all previous work, our model does not rely on hand-crafted rules or a sophisticated NLP pipeline; it is instead trainable end-to-end via sequence-to-sequence learning. Automatic evaluation results show that our system significantly outperforms the state-of-the-art rule-based system. In human evaluations, questions generated by our system are also rated as being more natural (i.e., grammaticality, fluency) and as more difficult to answer (in terms of syntactic and lexical divergence from the original text and reasoning needed to answer).\n    ",
        "submission_date": "2017-04-29T00:00:00",
        "last_modified_date": "2017-04-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.00335",
        "title": "Quantifying Mental Health from Social Media with Neural User Embeddings",
        "authors": [
            "Silvio Amir",
            "Glen Coppersmith",
            "Paula Carvalho",
            "M\u00e1rio J. Silva",
            "Byron C. Wallace"
        ],
        "abstract": "Mental illnesses adversely affect a significant proportion of the population worldwide. However, the methods traditionally used for estimating and characterizing the prevalence of mental health conditions are time-consuming and expensive. Consequently, best-available estimates concerning the prevalence of mental health conditions are often years out of date. Automated approaches to supplement these survey methods with broad, aggregated information derived from social media content provides a potential means for near real-time estimates at scale. These may, in turn, provide grist for supporting, evaluating and iteratively improving upon public health programs and interventions.\n",
        "submission_date": "2017-04-30T00:00:00",
        "last_modified_date": "2017-04-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.00341",
        "title": "Deriving Quests from Open World Mechanics",
        "authors": [
            "Ryan Alexander",
            "Chris Martens"
        ],
        "abstract": "Open world games present players with more freedom than games with linear progression structures. However, without clearly-defined objectives, they often leave players without a sense of purpose. Most of the time, quests and objectives are hand-authored and overlaid atop an open world's mechanics. But what if they could be generated organically from the gameplay itself? The goal of our project was to develop a model of the mechanics in Minecraft that could be used to determine the ideal placement of objectives in an open world setting. We formalized the game logic of Minecraft in terms of logical rules that can be manipulated in two ways: they may be executed to generate graphs representative of the player experience when playing an open world game with little developer direction; and they may be statically analyzed to determine dependency orderings, feedback loops, and bottlenecks. These analyses may then be used to place achievements on gameplay actions algorithmically.\n    ",
        "submission_date": "2017-04-30T00:00:00",
        "last_modified_date": "2017-04-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.00561",
        "title": "WebAPIRec: Recommending Web APIs to Software Projects via Personalized Ranking",
        "authors": [
            "Ferdian Thung",
            "Richard J. Oentaryo",
            "David Lo",
            "Yuan Tian"
        ],
        "abstract": "Application programming interfaces (APIs) offer a plethora of functionalities for developers to reuse without reinventing the wheel. Identifying the appropriate APIs given a project requirement is critical for the success of a project, as many functionalities can be reused to achieve faster development. However, the massive number of APIs would often hinder the developers' ability to quickly find the right APIs. In this light, we propose a new, automated approach called WebAPIRec that takes as input a project profile and outputs a ranked list of {web} APIs that can be used to implement the project. At its heart, WebAPIRec employs a personalized ranking model that ranks web APIs specific (personalized) to a project. Based on the historical data of {web} API usages, WebAPIRec learns a model that minimizes the incorrect ordering of web APIs, i.e., when a used {web} API is ranked lower than an unused (or a not-yet-used) web API. We have evaluated our approach on a dataset comprising 9,883 web APIs and 4,315 web application projects from ProgrammableWeb with promising results. For 84.0% of the projects, WebAPIRec is able to successfully return correct APIs that are used to implement the projects in the top-5 positions. This is substantially better than the recommendations provided by ProgrammableWeb's native search functionality. WebAPIRec also outperforms McMillan et al.'s application search engine and popularity-based recommendation.\n    ",
        "submission_date": "2017-05-01T00:00:00",
        "last_modified_date": "2017-05-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.00597",
        "title": "Towards well-specified semi-supervised model-based classifiers via structural adaptation",
        "authors": [
            "Zhaocai Sun",
            "William K. Cheung",
            "Xiaofeng Zhang",
            "Jun Yang"
        ],
        "abstract": "Semi-supervised learning plays an important role in large-scale machine learning. Properly using additional unlabeled data (largely available nowadays) often can improve the machine learning accuracy. However, if the machine learning model is misspecified for the underlying true data distribution, the model performance could be seriously jeopardized. This issue is known as model misspecification. To address this issue, we focus on generative models and propose a criterion to detect the onset of model misspecification by measuring the performance difference between models obtained using supervised and semi-supervised learning. Then, we propose to automatically modify the generative models during model training to achieve an unbiased generative model. Rigorous experiments were carried out to evaluate the proposed method using two image classification data sets PASCAL VOC'07 and MIR Flickr. Our proposed method has been demonstrated to outperform a number of state-of-the-art semi-supervised learning approaches for the classification task.\n    ",
        "submission_date": "2017-05-01T00:00:00",
        "last_modified_date": "2017-05-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.00697",
        "title": "From Imitation to Prediction, Data Compression vs Recurrent Neural Networks for Natural Language Processing",
        "authors": [
            "Juan Andr\u00e9s Laura",
            "Gabriel Masi",
            "Luis Argerich"
        ],
        "abstract": "In recent studies [1][13][12] Recurrent Neural Networks were used for generative processes and their surprising performance can be explained by their ability to create good predictions. In addition, data compression is also based on predictions. What the problem comes down to is whether a data compressor could be used to perform as well as recurrent neural networks in natural language processing tasks. If this is possible,then the problem comes down to determining if a compression algorithm is even more intelligent than a neural network in specific tasks related to human language. In our journey we discovered what we think is the fundamental difference between a Data Compression Algorithm and a Recurrent Neural Network.\n    ",
        "submission_date": "2017-05-01T00:00:00",
        "last_modified_date": "2017-05-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.00732",
        "title": "Argumentation-based Security for Social Good",
        "authors": [
            "Erisa Karafili",
            "Antonis C. Kakas",
            "Nikolaos I. Spanoudakis",
            "Emil C. Lupu"
        ],
        "abstract": "The increase of connectivity and the impact it has in every day life is raising new and existing security problems that are becoming important for social good. We introduce two particular problems: cyber attack attribution and regulatory data sharing. For both problems, decisions about which rules to apply, should be taken under incomplete and context dependent information. The solution we propose is based on argumentation reasoning, that is a well suited technique for implementing decision making mechanisms under conflicting and incomplete information. Our proposal permits us to identify the attacker of a cyber attack and decide the regulation rule that should be used while using and sharing data. We illustrate our solution through concrete examples.\n    ",
        "submission_date": "2017-05-01T00:00:00",
        "last_modified_date": "2017-05-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.00930",
        "title": "Show, Adapt and Tell: Adversarial Training of Cross-domain Image Captioner",
        "authors": [
            "Tseng-Hung Chen",
            "Yuan-Hong Liao",
            "Ching-Yao Chuang",
            "Wan-Ting Hsu",
            "Jianlong Fu",
            "Min Sun"
        ],
        "abstract": "Impressive image captioning results are achieved in domains with plenty of training image and sentence pairs (e.g., MSCOCO). However, transferring to a target domain with significant domain shifts but no paired training data (referred to as cross-domain image captioning) remains largely unexplored. We propose a novel adversarial training procedure to leverage unpaired data in the target domain. Two critic networks are introduced to guide the captioner, namely domain critic and multi-modal critic. The domain critic assesses whether the generated sentences are indistinguishable from sentences in the target domain. The multi-modal critic assesses whether an image and its generated sentence are a valid pair. During training, the critics and captioner act as adversaries -- captioner aims to generate indistinguishable sentences, whereas critics aim at distinguishing them. The assessment improves the captioner through policy gradient updates. During inference, we further propose a novel critic-based planning method to select high-quality sentences without additional supervision (e.g., tags). To evaluate, we use MSCOCO as the source domain and four other datasets (CUB-200-2011, Oxford-102, TGIF, and Flickr30k) as the target domains. Our method consistently performs well on all datasets. In particular, on CUB-200-2011, we achieve 21.8% CIDEr-D improvement after adaptation. Utilizing critics during inference further gives another 4.5% boost.\n    ",
        "submission_date": "2017-05-02T00:00:00",
        "last_modified_date": "2017-08-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.01013",
        "title": "Quantum Mechanical Approach to Modelling Reliability of Sensor Reports",
        "authors": [
            "Zichang He",
            "Wen Jiang"
        ],
        "abstract": "Dempster-Shafer evidence theory is wildly applied in multi-sensor data fusion. However, lots of uncertainty and interference exist in practical situation, especially in the battle field. It is still an open issue to model the reliability of sensor reports. Many methods are proposed based on the relationship among collected data. In this letter, we proposed a quantum mechanical approach to evaluate the reliability of sensor reports, which is based on the properties of a sensor itself. The proposed method is used to modify the combining of evidences.\n    ",
        "submission_date": "2017-04-17T00:00:00",
        "last_modified_date": "2017-04-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.01040",
        "title": "Maximum Resilience of Artificial Neural Networks",
        "authors": [
            "Chih-Hong Cheng",
            "Georg N\u00fchrenberg",
            "Harald Ruess"
        ],
        "abstract": "The deployment of Artificial Neural Networks (ANNs) in safety-critical applications poses a number of new verification and certification challenges. In particular, for ANN-enabled self-driving vehicles it is important to establish properties about the resilience of ANNs to noisy or even maliciously manipulated sensory input. We are addressing these challenges by defining resilience properties of ANN-based classifiers as the maximal amount of input or sensor perturbation which is still tolerated. This problem of computing maximal perturbation bounds for ANNs is then reduced to solving mixed integer optimization problems (MIP). A number of MIP encoding heuristics are developed for drastically reducing MIP-solver runtimes, and using parallelization of MIP-solvers results in an almost linear speed-up in the number (up to a certain limit) of computing cores in our experiments. We demonstrate the effectiveness and scalability of our approach by means of computing maximal resilience bounds for a number of ANN benchmark sets ranging from typical image recognition scenarios to the autonomous maneuvering of robots.\n    ",
        "submission_date": "2017-04-28T00:00:00",
        "last_modified_date": "2017-07-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.01187",
        "title": "Towards Full Automated Drive in Urban Environments: A Demonstration in GoMentum Station, California",
        "authors": [
            "Akansel Cosgun",
            "Lichao Ma",
            "Jimmy Chiu",
            "Jiawei Huang",
            "Mahmut Demir",
            "Alexandre Miranda Anon",
            "Thang Lian",
            "Hasan Tafish",
            "Samir Al-Stouhi"
        ],
        "abstract": "Each year, millions of motor vehicle traffic accidents all over the world cause a large number of fatalities, injuries and significant material loss. Automated Driving (AD) has potential to drastically reduce such accidents. In this work, we focus on the technical challenges that arise from AD in urban environments. We present the overall architecture of an AD system and describe in detail the perception and planning modules. The AD system, built on a modified Acura RLX, was demonstrated in a course in GoMentum Station in California. We demonstrated autonomous handling of 4 scenarios: traffic lights, cross-traffic at intersections, construction zones and pedestrians. The AD vehicle displayed safe behavior and performed consistently in repeated demonstrations with slight variations in conditions. Overall, we completed 44 runs, encompassing 110km of automated driving with only 3 cases where the driver intervened the control of the vehicle, mostly due to error in GPS positioning. Our demonstration showed that robust and consistent behavior in urban scenarios is possible, yet more investigation is necessary for full scale roll-out on public roads.\n    ",
        "submission_date": "2017-05-02T00:00:00",
        "last_modified_date": "2017-05-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.01197",
        "title": "Analyzing Knowledge Transfer in Deep Q-Networks for Autonomously Handling Multiple Intersections",
        "authors": [
            "David Isele",
            "Akansel Cosgun",
            "Kikuo Fujimura"
        ],
        "abstract": "We analyze how the knowledge to autonomously handle one type of intersection, represented as a Deep Q-Network, translates to other types of intersections (tasks). We view intersection handling as a deep reinforcement learning problem, which approximates the state action Q function as a deep neural network. Using a traffic simulator, we show that directly copying a network trained for one type of intersection to another type of intersection decreases the success rate. We also show that when a network that is pre-trained on Task A and then is fine-tuned on a Task B, the resulting network not only performs better on the Task B than an network exclusively trained on Task A, but also retained knowledge on the Task A. Finally, we examine a lifelong learning setting, where we train a single network on five different types of intersections sequentially and show that the resulting network exhibited catastrophic forgetting of knowledge on previous tasks. This result suggests a need for a long-term memory component to preserve knowledge.\n    ",
        "submission_date": "2017-05-02T00:00:00",
        "last_modified_date": "2017-05-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.01209",
        "title": "Lifelong Metric Learning",
        "authors": [
            "Gan Sun",
            "Yang Cong",
            "Ji Liu",
            "Xiaowei Xu"
        ],
        "abstract": "The state-of-the-art online learning approaches are only capable of learning the metric for predefined tasks. In this paper, we consider lifelong learning problem to mimic \"human learning\", i.e., endowing a new capability to the learned metric for a new task from new online samples and incorporating previous experiences and knowledge. Therefore, we propose a new metric learning framework: lifelong metric learning (LML), which only utilizes the data of the new task to train the metric model while preserving the original capabilities. More specifically, the proposed LML maintains a common subspace for all learned metrics, named lifelong dictionary, transfers knowledge from the common subspace to each new metric task with task-specific idiosyncrasy, and redefines the common subspace over time to maximize performance across all metric tasks. For model optimization, we apply online passive aggressive optimization algorithm to solve the proposed LML framework, where the lifelong dictionary and task-specific partition are optimized alternatively and consecutively. Finally, we evaluate our approach by analyzing several multi-task metric learning datasets. Extensive experimental results demonstrate effectiveness and efficiency of the proposed framework.\n    ",
        "submission_date": "2017-05-03T00:00:00",
        "last_modified_date": "2017-06-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.01228",
        "title": "A Versatile, Sound Tool for Simplifying Definitions",
        "authors": [
            "Alessandro Coglio",
            "Matt Kaufmann",
            "Eric W. Smith"
        ],
        "abstract": "We present a tool, simplify-defun, that transforms the definition of a given function into a simplified definition of a new function, providing a proof checked by ACL2 that the old and new functions are equivalent. When appropriate it also generates termination and guard proofs for the new function.  We explain how the tool is engineered so that these proofs will succeed.  Examples illustrate its utility, in particular for program transformation in synthesis and verification.\n    ",
        "submission_date": "2017-05-03T00:00:00",
        "last_modified_date": "2017-05-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.01320",
        "title": "Formal Verification of Piece-Wise Linear Feed-Forward Neural Networks",
        "authors": [
            "Ruediger Ehlers"
        ],
        "abstract": "We present an approach for the verification of feed-forward neural networks in which all nodes have a piece-wise linear activation function. Such networks are often used in deep learning and have been shown to be hard to verify for modern satisfiability modulo theory (SMT) and integer linear programming (ILP) solvers.\n",
        "submission_date": "2017-05-03T00:00:00",
        "last_modified_date": "2017-08-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.01485",
        "title": "Efficient Spatio-Temporal Gaussian Regression via Kalman Filtering",
        "authors": [
            "Marco Todescato",
            "Andrea Carron",
            "Ruggero Carli",
            "Gianluigi Pillonetto",
            "Luca Schenato"
        ],
        "abstract": "In this work we study the non-parametric reconstruction of spatio-temporal dynamical Gaussian processes (GPs) via GP regression from sparse and noisy data. GPs have been mainly applied to spatial regression where they represent one of the most powerful estimation approaches also thanks to their universal representing properties. Their extension to dynamical processes has been instead elusive so far since classical implementations lead to unscalable algorithms. We then propose a novel procedure to address this problem by coupling GP regression and Kalman filtering. In particular, assuming space/time separability of the covariance (kernel) of the process and rational time spectrum, we build a finite-dimensional discrete-time state-space process representation amenable of Kalman filtering. With sampling over a finite set of fixed spatial locations, our major finding is that the Kalman filter state at instant $t_k$ represents a sufficient statistic to compute the minimum variance estimate of the process at any $t \\geq t_k$ over the entire spatial domain. This result can be interpreted as a novel Kalman representer theorem for dynamical GPs. We then extend the study to situations where the set of spatial input locations can vary over time. The proposed algorithms are finally tested on both synthetic and real field data, also providing comparisons with standard GP and truncated GP regression techniques.\n    ",
        "submission_date": "2017-05-03T00:00:00",
        "last_modified_date": "2017-05-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.01736",
        "title": "Of the People: Voting Is More Effective with Representative Candidates",
        "authors": [
            "Yu Cheng",
            "Shaddin Dughmi",
            "David Kempe"
        ],
        "abstract": "In light of the classic impossibility results of Arrow and Gibbard and Satterthwaite regarding voting with ordinal rules, there has been recent interest in characterizing how well common voting rules approximate the social optimum. In order to quantify the quality of approximation, it is natural to consider the candidates and voters as embedded within a common metric space, and to ask how much further the chosen candidate is from the population as compared to the socially optimal one. We use this metric preference model to explore a fundamental and timely question: does the social welfare of a population improve when candidates are representative of the population? If so, then by how much, and how does the answer depend on the complexity of the metric space?\n",
        "submission_date": "2017-05-04T00:00:00",
        "last_modified_date": "2017-08-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.01813",
        "title": "Fast k-means based on KNN Graph",
        "authors": [
            "Cheng-Hao Deng",
            "Wan-Lei Zhao"
        ],
        "abstract": "In the era of big data, k-means clustering has been widely adopted as a basic processing tool in various contexts. However, its computational cost could be prohibitively high as the data size and the cluster number are large. It is well known that the processing bottleneck of k-means lies in the operation of seeking closest centroid in each iteration. In this paper, a novel solution towards the scalability issue of k-means is presented. In the proposal, k-means is supported by an approximate k-nearest neighbors graph. In the k-means iteration, each data sample is only compared to clusters that its nearest neighbors reside. Since the number of nearest neighbors we consider is much less than k, the processing cost in this step becomes minor and irrelevant to k. The processing bottleneck is therefore overcome. The most interesting thing is that k-nearest neighbor graph is constructed by iteratively calling the fast $k$-means itself. Comparing with existing fast k-means variants, the proposed algorithm achieves hundreds to thousands times speed-up while maintaining high clustering quality. As it is tested on 10 million 512-dimensional data, it takes only 5.2 hours to produce 1 million clusters. In contrast, to fulfill the same scale of clustering, it would take 3 years for traditional k-means.\n    ",
        "submission_date": "2017-05-04T00:00:00",
        "last_modified_date": "2017-05-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.01968",
        "title": "A Workflow for Visual Diagnostics of Binary Classifiers using Instance-Level Explanations",
        "authors": [
            "Josua Krause",
            "Aritra Dasgupta",
            "Jordan Swartz",
            "Yindalon Aphinyanaphongs",
            "Enrico Bertini"
        ],
        "abstract": "Human-in-the-loop data analysis applications necessitate greater transparency in machine learning models for experts to understand and trust their decisions. To this end, we propose a visual analytics workflow to help data scientists and domain experts explore, diagnose, and understand the decisions made by a binary classifier. The approach leverages \"instance-level explanations\", measures of local feature relevance that explain single instances, and uses them to build a set of visual representations that guide the users in their investigation. The workflow is based on three main visual representations and steps: one based on aggregate statistics to see how data distributes across correct / incorrect decisions; one based on explanations to understand which features are used to make these decisions; and one based on raw data, to derive insights on potential root causes for the observed patterns. The workflow is derived from a long-term collaboration with a group of machine learning and healthcare professionals who used our method to make sense of machine learning models they developed. The case study from this collaboration demonstrates that the proposed workflow helps experts derive useful knowledge about the model and the phenomena it describes, thus experts can generate useful hypotheses on how a model can be improved.\n    ",
        "submission_date": "2017-05-04T00:00:00",
        "last_modified_date": "2017-10-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.02212",
        "title": "Group invariance principles for causal generative models",
        "authors": [
            "Michel Besserve",
            "Naji Shajarisales",
            "Bernhard Sch\u00f6lkopf",
            "Dominik Janzing"
        ],
        "abstract": "The postulate of independence of cause and mechanism (ICM) has recently led to several new causal discovery algorithms. The interpretation of independence and the way it is utilized, however, varies across these methods. Our aim in this paper is to propose a group theoretic framework for ICM to unify and generalize these approaches. In our setting, the cause-mechanism relationship is assessed by comparing it against a null hypothesis through the application of random generic group transformations. We show that the group theoretic view provides a very general tool to study the structure of data generating mechanisms with direct applications to machine learning.\n    ",
        "submission_date": "2017-05-05T00:00:00",
        "last_modified_date": "2017-05-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.02245",
        "title": "Data Readiness Levels",
        "authors": [
            "Neil D. Lawrence"
        ],
        "abstract": "Application of models to data is fraught. Data-generating collaborators often only have a very basic understanding of the complications of collating, processing and curating data. Challenges include: poor data collection practices, missing values, inconvenient storage mechanisms, intellectual property, security and privacy. All these aspects obstruct the sharing and interconnection of data, and the eventual interpretation of data through machine learning or other approaches. In project reporting, a major challenge is in encapsulating these problems and enabling goals to be built around the processing of data. Project overruns can occur due to failure to account for the amount of time required to curate and collate. But to understand these failures we need to have a common language for assessing the readiness of a particular data set. This position paper proposes the use of data readiness levels: it gives a rough outline of three stages of data preparedness and speculates on how formalisation of these levels into a common language for data readiness could facilitate project management.\n    ",
        "submission_date": "2017-05-05T00:00:00",
        "last_modified_date": "2017-05-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.02426",
        "title": "Analogical Inference for Multi-Relational Embeddings",
        "authors": [
            "Hanxiao Liu",
            "Yuexin Wu",
            "Yiming Yang"
        ],
        "abstract": "Large-scale multi-relational embedding refers to the task of learning the latent representations for entities and relations in large knowledge graphs. An effective and scalable solution for this problem is crucial for the true success of knowledge-based inference in a broad range of applications. This paper proposes a novel framework for optimizing the latent representations with respect to the \\textit{analogical} properties of the embedded entities and relations. By formulating the learning objective in a differentiable fashion, our model enjoys both theoretical power and computational scalability, and significantly outperformed a large number of representative baseline methods on benchmark datasets. Furthermore, the model offers an elegant unification of several well-known methods in multi-relational embedding, which can be proven to be special instantiations of our framework.\n    ",
        "submission_date": "2017-05-06T00:00:00",
        "last_modified_date": "2017-07-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.02636",
        "title": "TrajectoryNet: An Embedded GPS Trajectory Representation for Point-based Classification Using Recurrent Neural Networks",
        "authors": [
            "Xiang Jiang",
            "Erico N de Souza",
            "Ahmad Pesaranghader",
            "Baifan Hu",
            "Daniel L. Silver",
            "Stan Matwin"
        ],
        "abstract": "Understanding and discovering knowledge from GPS (Global Positioning System) traces of human activities is an essential topic in mobility-based urban computing. We propose TrajectoryNet-a neural network architecture for point-based trajectory classification to infer real world human transportation modes from GPS traces. To overcome the challenge of capturing the underlying latent factors in the low-dimensional and heterogeneous feature space imposed by GPS data, we develop a novel representation that embeds the original feature space into another space that can be understood as a form of basis expansion. We also enrich the feature space via segment-based information and use Maxout activations to improve the predictive power of Recurrent Neural Networks (RNNs). We achieve over 98% classification accuracy when detecting four types of transportation modes, outperforming existing models without additional sensory data or location-based prior knowledge.\n    ",
        "submission_date": "2017-05-07T00:00:00",
        "last_modified_date": "2017-08-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.02670",
        "title": "Metacontrol for Adaptive Imagination-Based Optimization",
        "authors": [
            "Jessica B. Hamrick",
            "Andrew J. Ballard",
            "Razvan Pascanu",
            "Oriol Vinyals",
            "Nicolas Heess",
            "Peter W. Battaglia"
        ],
        "abstract": "Many machine learning systems are built to solve the hardest examples of a particular task, which often makes them large and expensive to run---especially with respect to the easier examples, which might require much less computation. For an agent with a limited computational budget, this \"one-size-fits-all\" approach may result in the agent wasting valuable computation on easy examples, while not spending enough on hard examples. Rather than learning a single, fixed policy for solving all instances of a task, we introduce a metacontroller which learns to optimize a sequence of \"imagined\" internal simulations over predictive models of the world in order to construct a more informed, and more economical, solution. The metacontroller component is a model-free reinforcement learning agent, which decides both how many iterations of the optimization procedure to run, as well as which model to consult on each iteration. The models (which we call \"experts\") can be state transition models, action-value functions, or any other mechanism that provides information useful for solving the task, and can be learned on-policy or off-policy in parallel with the metacontroller. When the metacontroller, controller, and experts were trained with \"interaction networks\" (Battaglia et al., 2016) as expert models, our approach was able to solve a challenging decision-making problem under complex non-linear dynamics. The metacontroller learned to adapt the amount of computation it performed to the difficulty of the task, and learned how to choose which experts to consult by factoring in both their reliability and individual computational resource costs. This allowed the metacontroller to achieve a lower overall cost (task loss plus computational cost) than more traditional fixed policy approaches. These results demonstrate that our approach is a powerful framework for using rich forward models for efficient model-based reinforcement learning.\n    ",
        "submission_date": "2017-05-07T00:00:00",
        "last_modified_date": "2017-05-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.02687",
        "title": "Finding Bottlenecks: Predicting Student Attrition with Unsupervised Classifier",
        "authors": [
            "Seyed Sajjadi",
            "Bruce Shapiro",
            "Christopher McKinlay",
            "Allen Sarkisyan",
            "Carol Shubin",
            "Efunwande Osoba"
        ],
        "abstract": "With pressure to increase graduation rates and reduce time to degree in higher education, it is important to identify at-risk students early. Automated early warning systems are therefore highly desirable. In this paper, we use unsupervised clustering techniques to predict the graduation status of declared majors in five departments at California State University Northridge (CSUN), based on a minimal number of lower division courses in each major. In addition, we use the detected clusters to identify hidden bottleneck courses.\n    ",
        "submission_date": "2017-05-07T00:00:00",
        "last_modified_date": "2017-05-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.02689",
        "title": "AirDraw: Leveraging Smart Watch Motion Sensors for Mobile Human Computer Interactions",
        "authors": [
            "Seyed A Sajjadi",
            "Danial Moazen",
            "Ani Nahapetian"
        ],
        "abstract": "Wearable computing is one of the fastest growing technologies today. Smart watches are poised to take over at least of half the wearable devices market in the near future. Smart watch screen size, however, is a limiting factor for growth, as it restricts practical text input. On the other hand, wearable devices have some features, such as consistent user interaction and hands-free, heads-up operations, which pave the way for gesture recognition methods of text entry. This paper proposes a new text input method for smart watches, which utilizes motion sensor data and machine learning approaches to detect letters written in the air by a user. This method is less computationally intensive and less expensive when compared to computer vision approaches. It is also not affected by lighting factors, which limit computer vision solutions. The AirDraw system prototype developed to test this approach is presented. Additionally, experimental results close to 71% accuracy are presented.\n    ",
        "submission_date": "2017-05-07T00:00:00",
        "last_modified_date": "2017-05-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.02694",
        "title": "Multimodal Affect Analysis for Product Feedback Assessment",
        "authors": [
            "Amol S Patwardhan",
            "Gerald M Knapp"
        ],
        "abstract": "Consumers often react expressively to products such as food samples, perfume, jewelry, sunglasses, and clothing accessories. This research discusses a multimodal affect recognition system developed to classify whether a consumer likes or dislikes a product tested at a counter or kiosk, by analyzing the consumer's facial expression, body posture, hand gestures, and voice after testing the product. A depth-capable camera and microphone system - Kinect for Windows - is utilized. An emotion identification engine has been developed to analyze the images and voice to determine affective state of the customer. The image is segmented using skin color and adaptive threshold. Face, body and hands are detected using the Haar cascade classifier. Canny edges are identified and the lip, body and hand contours are extracted using spatial filtering. Edge count and orientation around the mouth, cheeks, eyes, shoulders, fingers and the location of the edges are used as features. Classification is done by an emotion template mapping algorithm and training a classifier using support vector machines. The real-time performance, accuracy and feasibility for multimodal affect recognition in feedback assessment are evaluated.\n    ",
        "submission_date": "2017-05-07T00:00:00",
        "last_modified_date": "2017-05-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.02772",
        "title": "Scene Text Eraser",
        "authors": [
            "Toshiki Nakamura",
            "Anna Zhu",
            "Keiji Yanai",
            "Seiichi Uchida"
        ],
        "abstract": "The character information in natural scene images contains various personal information, such as telephone numbers, home addresses, etc. It is a high risk of leakage the information if they are published. In this paper, we proposed a scene text erasing method to properly hide the information via an inpainting convolutional neural network (CNN) model. The input is a scene text image, and the output is expected to be text erased image with all the character regions filled up the colors of the surrounding background pixels. This work is accomplished by a CNN model through convolution to deconvolution with interconnection process. The training samples and the corresponding inpainting images are considered as teaching signals for training. To evaluate the text erasing performance, the output images are detected by a novel scene text detection method. Subsequently, the same measurement on text detection is utilized for testing the images in benchmark dataset ICDAR2013. Compared with direct text detection way, the scene text erasing process demonstrates a drastically decrease on the precision, recall and f-score. That proves the effectiveness of proposed method for erasing the text in natural scene images.\n    ",
        "submission_date": "2017-05-08T00:00:00",
        "last_modified_date": "2017-05-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.02894",
        "title": "Geometric GAN",
        "authors": [
            "Jae Hyun Lim",
            "Jong Chul Ye"
        ],
        "abstract": "Generative Adversarial Nets (GANs) represent an important milestone for effective generative models, which has inspired numerous variants seemingly different from each other. One of the main contributions of this paper is to reveal a unified geometric structure in GAN and its variants. Specifically, we show that the adversarial generative model training can be decomposed into three geometric steps: separating hyperplane search, discriminator parameter update away from the separating hyperplane, and the generator update along the normal vector direction of the separating hyperplane. This geometric intuition reveals the limitations of the existing approaches and leads us to propose a new formulation called geometric GAN using SVM separating hyperplane that maximizes the margin. Our theoretical analysis shows that the geometric GAN converges to a Nash equilibrium between the discriminator and generator. In addition, extensive numerical results show that the superior performance of geometric GAN.\n    ",
        "submission_date": "2017-05-08T00:00:00",
        "last_modified_date": "2017-05-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.03127",
        "title": "Word and Phrase Translation with word2vec",
        "authors": [
            "Stefan Jansen"
        ],
        "abstract": "Word and phrase tables are key inputs to machine translations, but costly to produce. New unsupervised learning methods represent words and phrases in a high-dimensional vector space, and these monolingual embeddings have been shown to encode syntactic and semantic relationships between language elements. The information captured by these embeddings can be exploited for bilingual translation by learning a transformation matrix that allows matching relative positions across two monolingual vector spaces. This method aims to identify high-quality candidates for word and phrase translation more cost-effectively from unlabeled data.\n",
        "submission_date": "2017-05-09T00:00:00",
        "last_modified_date": "2018-04-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.03175",
        "title": "Emotional Metaheuristics For in-situ Foraging Using Sensor Constrained Robot Swarms",
        "authors": [
            "Esh Vckay",
            "Debasish Ghose"
        ],
        "abstract": "We present a new social animal inspired emotional swarm intelligence technique. This technique is used to solve a variant of the popular collective robots problem called foraging. We show with a simulation study how simple interaction rules based on sensations like hunger and loneliness can lead to globally coherent emergent behavior which allows sensor constrained robots to solve the given problem\n    ",
        "submission_date": "2017-05-09T00:00:00",
        "last_modified_date": "2019-06-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.03176",
        "title": "Solving a Path Planning Problem in a Partially Known Environment using a Swarm Algorithm",
        "authors": [
            "Esh Vckay",
            "Mansimar Aneja",
            "Dipti Deodhare"
        ],
        "abstract": "This paper proposes a path planning strategy for an Autonomous Ground Vehicle (AGV) navigating in a partially known environment. Global path planning is performed by first using a spatial database of the region to be traversed containing selected attributes such as height data and soil information from a suitable spatial database. The database is processed using a biomimetic swarm algorithm that is inspired by the nest building strategies followed by termites. Local path planning is performed online utilizing information regarding contingencies that affect the safe navigation of the AGV from various sensors. The simulation discussed has been implemented on the open source Player-Stage-Gazebo platform.\n    ",
        "submission_date": "2017-05-09T00:00:00",
        "last_modified_date": "2019-06-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.03303",
        "title": "The Imprecisions of Precision Measures in Process Mining",
        "authors": [
            "Niek Tax",
            "Xixi Lu",
            "Natalia Sidorova",
            "Dirk Fahland",
            "Wil M. P. van der Aalst"
        ],
        "abstract": "In process mining, precision measures are used to quantify how much a process model overapproximates the behavior seen in an event log. Although several measures have been proposed throughout the years, no research has been done to validate whether these measures achieve the intended aim of quantifying over-approximation in a consistent way for all models and logs. This paper fills this gap by postulating a number of axioms for quantifying precision consistently for any log and any model. Further, we show through counter-examples that none of the existing measures consistently quantifies precision.\n    ",
        "submission_date": "2017-05-03T00:00:00",
        "last_modified_date": "2017-05-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.03338",
        "title": "Model Complexity-Accuracy Trade-off for a Convolutional Neural Network",
        "authors": [
            "Atul Dhingra"
        ],
        "abstract": "Convolutional Neural Networks(CNN) has had a great success in the recent past, because of the advent of faster GPUs and memory access. CNNs are really powerful as they learn the features from data in layers such that they exhibit the structure of the V-1 features of the human brain. A huge bottleneck, in this case, is that CNNs are very large and have a very high memory footprint, and hence they cannot be employed on devices with limited storage such as mobile phone, IoT etc. In this work, we study the model complexity versus accuracy trade-off on MNSIT dataset, and give a concrete framework for handling such a problem, given the worst case accuracy that a system can tolerate. In our work, we reduce the model complexity by 236 times, and memory footprint by 19.5 times compared to the base model while achieving worst case accuracy threshold.\n    ",
        "submission_date": "2017-05-09T00:00:00",
        "last_modified_date": "2017-05-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.03454",
        "title": "The Pragmatics of Indirect Commands in Collaborative Discourse",
        "authors": [
            "Matthew Lamm",
            "Mihail Eric"
        ],
        "abstract": "Today's artificial assistants are typically prompted to perform tasks through direct, imperative commands such as \\emph{Set a timer} or \\emph{Pick up the box}. However, to progress toward more natural exchanges between humans and these assistants, it is important to understand the way non-imperative utterances can indirectly elicit action of an addressee. In this paper, we investigate command types in the setting of a grounded, collaborative game. We focus on a less understood family of utterances for eliciting agent action, locatives like \\emph{The chair is in the other room}, and demonstrate how these utterances indirectly command in specific game state contexts. Our work shows that models with domain-specific grounding can effectively realize the pragmatic reasoning that is necessary for more robust natural language interaction.\n    ",
        "submission_date": "2017-05-08T00:00:00",
        "last_modified_date": "2017-09-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.03455",
        "title": "Sequential Dialogue Context Modeling for Spoken Language Understanding",
        "authors": [
            "Ankur Bapna",
            "Gokhan Tur",
            "Dilek Hakkani-Tur",
            "Larry Heck"
        ],
        "abstract": "Spoken Language Understanding (SLU) is a key component of goal oriented dialogue systems that would parse user utterances into semantic frame representations. Traditionally SLU does not utilize the dialogue history beyond the previous system turn and contextual ambiguities are resolved by the downstream components. In this paper, we explore novel approaches for modeling dialogue context in a recurrent neural network (RNN) based language understanding system. We propose the Sequential Dialogue Encoder Network, that allows encoding context from the dialogue history in chronological order. We compare the performance of our proposed architecture with two context models, one that uses just the previous turn context and another that encodes dialogue context in a memory network, but loses the order of utterances in the dialogue history. Experiments with a multi-domain dialogue dataset demonstrate that the proposed architecture results in reduced semantic frame error rates.\n    ",
        "submission_date": "2017-05-08T00:00:00",
        "last_modified_date": "2017-07-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.03550",
        "title": "CORe50: a New Dataset and Benchmark for Continuous Object Recognition",
        "authors": [
            "Vincenzo Lomonaco",
            "Davide Maltoni"
        ],
        "abstract": "Continuous/Lifelong learning of high-dimensional data streams is a challenging research problem. In fact, fully retraining models each time new data become available is infeasible, due to computational and storage issues, while na\u00efve incremental strategies have been shown to suffer from catastrophic forgetting. In the context of real-world object recognition applications (e.g., robotic vision), where continuous learning is crucial, very few datasets and benchmarks are available to evaluate and compare emerging techniques. In this work we propose a new dataset and benchmark CORe50, specifically designed for continuous object recognition, and introduce baseline approaches for different continuous learning scenarios.\n    ",
        "submission_date": "2017-05-09T00:00:00",
        "last_modified_date": "2017-05-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.03562",
        "title": "Deep Episodic Value Iteration for Model-based Meta-Reinforcement Learning",
        "authors": [
            "Steven Stenberg Hansen"
        ],
        "abstract": "We present a new deep meta reinforcement learner, which we call Deep Episodic Value Iteration (DEVI). DEVI uses a deep neural network to learn a similarity metric for a non-parametric model-based reinforcement learning algorithm. Our model is trained end-to-end via back-propagation. Despite being trained using the model-free Q-learning objective, we show that DEVI's model-based internal structure provides `one-shot' transfer to changes in reward and transition structure, even for tasks with very high-dimensional state spaces.\n    ",
        "submission_date": "2017-05-09T00:00:00",
        "last_modified_date": "2017-05-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.03865",
        "title": "Survey of Visual Question Answering: Datasets and Techniques",
        "authors": [
            "Akshay Kumar Gupta"
        ],
        "abstract": "Visual question answering (or VQA) is a new and exciting problem that combines natural language processing and computer vision techniques. We present a survey of the various datasets and models that have been used to tackle this task. The first part of the survey details the various datasets for VQA and compares them along some common factors. The second part of this survey details the different approaches for VQA, classified into four types: non-deep learning models, deep learning models without attention, deep learning models with attention, and other models which do not fit into the first three. Finally, we compare the performances of these approaches and provide some directions for future work.\n    ",
        "submission_date": "2017-05-10T00:00:00",
        "last_modified_date": "2017-05-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.03916",
        "title": "Solving Distributed Constraint Optimization Problems Using Logic Programming",
        "authors": [
            "Tiep Le",
            "Tran Cao Son",
            "Enrico Pontelli",
            "William Yeoh"
        ],
        "abstract": "This paper explores the use of Answer Set Programming (ASP) in solving Distributed Constraint Optimization Problems (DCOPs). The paper provides the following novel contributions: (1) It shows how one can formulate DCOPs as logic programs; (2) It introduces ASP-DPOP, the first DCOP algorithm that is based on logic programming; (3) It experimentally shows that ASP-DPOP can be up to two orders of magnitude faster than DPOP (its imperative programming counterpart) as well as solve some problems that DPOP fails to solve, due to memory limitations; and (4) It demonstrates the applicability of ASP in a wide array of multi-agent problems currently modeled as DCOPs. Under consideration in Theory and Practice of Logic Programming (TPLP).\n    ",
        "submission_date": "2017-05-10T00:00:00",
        "last_modified_date": "2017-05-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.04282",
        "title": "Learning to see people like people",
        "authors": [
            "Amanda Song",
            "Linjie Li",
            "Chad Atalla",
            "Garrison Cottrell"
        ],
        "abstract": "Humans make complex inferences on faces, ranging from objective properties (gender, ethnicity, expression, age, identity, etc) to subjective judgments (facial attractiveness, trustworthiness, sociability, friendliness, etc). While the objective aspects of face perception have been extensively studied, relatively fewer computational models have been developed for the social impressions of faces. Bridging this gap, we develop a method to predict human impressions of faces in 40 subjective social dimensions, using deep representations from state-of-the-art neural networks. We find that model performance grows as the human consensus on a face trait increases, and that model predictions outperform human groups in correlation with human averages. This illustrates the learnability of subjective social perception of faces, especially when there is high human consensus. Our system can be used to decide which photographs from a personal collection will make the best impression. The results are significant for the field of social robotics, demonstrating that robots can learn the subjective judgments defining the underlying fabric of human interaction.\n    ",
        "submission_date": "2017-05-05T00:00:00",
        "last_modified_date": "2017-05-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.04448",
        "title": "R2-D2: ColoR-inspired Convolutional NeuRal Network (CNN)-based AndroiD Malware Detections",
        "authors": [
            "TonTon Hsien-De Huang",
            "Hung-Yu Kao"
        ],
        "abstract": "The influence of Deep Learning on image identification and natural language processing has attracted enormous attention globally. The convolution neural network that can learn without prior extraction of features fits well in response to the rapid iteration of Android malware. The traditional solution for detecting Android malware requires continuous learning through pre-extracted features to maintain high performance of identifying the malware. In order to reduce the manpower of feature engineering prior to the condition of not to extract pre-selected features, we have developed a coloR-inspired convolutional neuRal networks (CNN)-based AndroiD malware Detection (R2-D2) system. The system can convert the bytecode of ",
        "submission_date": "2017-05-12T00:00:00",
        "last_modified_date": "2018-11-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.04524",
        "title": "Long-term Blood Pressure Prediction with Deep Recurrent Neural Networks",
        "authors": [
            "Peng Su",
            "Xiao-Rong Ding",
            "Yuan-Ting Zhang",
            "Jing Liu",
            "Fen Miao",
            "Ni Zhao"
        ],
        "abstract": "Existing methods for arterial blood pressure (BP) estimation directly map the input physiological signals to output BP values without explicitly modeling the underlying temporal dependencies in BP dynamics. As a result, these models suffer from accuracy decay over a long time and thus require frequent calibration. In this work, we address this issue by formulating BP estimation as a sequence prediction problem in which both the input and target are temporal sequences. We propose a novel deep recurrent neural network (RNN) consisting of multilayered Long Short-Term Memory (LSTM) networks, which are incorporated with (1) a bidirectional structure to access larger-scale context information of input sequence, and (2) residual connections to allow gradients in deep RNN to propagate more effectively. The proposed deep RNN model was tested on a static BP dataset, and it achieved root mean square error (RMSE) of 3.90 and 2.66 mmHg for systolic BP (SBP) and diastolic BP (DBP) prediction respectively, surpassing the accuracy of traditional BP prediction models. On a multi-day BP dataset, the deep RNN achieved RMSE of 3.84, 5.25, 5.80 and 5.81 mmHg for the 1st day, 2nd day, 4th day and 6th month after the 1st day SBP prediction, and 1.80, 4.78, 5.0, 5.21 mmHg for corresponding DBP prediction, respectively, which outperforms all previous models with notable improvement. The experimental results suggest that modeling the temporal dependencies in BP dynamics significantly improves the long-term BP prediction accuracy.\n    ",
        "submission_date": "2017-05-12T00:00:00",
        "last_modified_date": "2018-01-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.04662",
        "title": "Monaural Audio Speaker Separation with Source Contrastive Estimation",
        "authors": [
            "Cory Stephenson",
            "Patrick Callier",
            "Abhinav Ganesh",
            "Karl Ni"
        ],
        "abstract": "We propose an algorithm to separate simultaneously speaking persons from each other, the \"cocktail party problem\", using a single microphone. Our approach involves a deep recurrent neural networks regression to a vector space that is descriptive of independent speakers. Such a vector space can embed empirically determined speaker characteristics and is optimized by distinguishing between speaker masks. We call this technique source-contrastive estimation. The methodology is inspired by negative sampling, which has seen success in natural language processing, where an embedding is learned by correlating and de-correlating a given input vector with output weights. Although the matrix determined by the output weights is dependent on a set of known speakers, we only use the input vectors during inference. Doing so will ensure that source separation is explicitly speaker-independent. Our approach is similar to recent deep neural network clustering and permutation-invariant training research; we use weighted spectral features and masks to augment individual speaker frequencies while filtering out other speakers. We avoid, however, the severe computational burden of other approaches with our technique. Furthermore, by training a vector space rather than combinations of different speakers or differences thereof, we avoid the so-called permutation problem during training. Our algorithm offers an intuitive, computationally efficient response to the cocktail party problem, and most importantly boasts better empirical performance than other current techniques.\n    ",
        "submission_date": "2017-05-12T00:00:00",
        "last_modified_date": "2017-05-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.04724",
        "title": "Person Re-Identification by Deep Joint Learning of Multi-Loss Classification",
        "authors": [
            "Wei Li",
            "Xiatian Zhu",
            "Shaogang Gong"
        ],
        "abstract": "Existing person re-identification (re-id) methods rely mostly on either localised or global feature representation alone. This ignores their joint benefit and mutual complementary effects. In this work, we show the advantages of jointly learning local and global features in a Convolutional Neural Network (CNN) by aiming to discover correlated local and global features in different context. Specifically, we formulate a method for joint learning of local and global feature selection losses designed to optimise person re-id when using only generic matching metrics such as the L2 distance. We design a novel CNN architecture for Jointly Learning Multi-Loss (JLML) of local and global discriminative feature optimisation subject concurrently to the same re-id labelled information. Extensive comparative evaluations demonstrate the advantages of this new JLML model for person re-id over a wide range of state-of-the-art re-id methods on five benchmarks (VIPeR, GRID, CUHK01, CUHK03, Market-1501).\n    ",
        "submission_date": "2017-05-12T00:00:00",
        "last_modified_date": "2017-05-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.04970",
        "title": "Relaxation heuristics for the set multicover problem with generalized upper bound constraints",
        "authors": [
            "Shunji Umetani",
            "Masanao Arakawa",
            "Mutsunori Yagiura"
        ],
        "abstract": "We consider an extension of the set covering problem (SCP) introducing (i)~multicover and (ii)~generalized upper bound (GUB)~constraints. For the conventional SCP, the pricing method has been introduced to reduce the size of instances, and several efficient heuristic algorithms based on such reduction techniques have been developed to solve large-scale instances. However, GUB constraints often make the pricing method less effective, because they often prevent solutions from containing highly evaluated variables together. To overcome this problem, we develop heuristic algorithms to reduce the size of instances, in which new evaluation schemes of variables are introduced taking account of GUB constraints. We also develop an efficient implementation of a 2-flip neighborhood local search algorithm that reduces the number of candidates in the neighborhood without sacrificing the solution quality. In order to guide the search to visit a wide variety of good solutions, we also introduce a path relinking method that generates new solutions by combining two or more solutions obtained so far. According to computational comparison on benchmark instances, the proposed method succeeds in selecting a small number of promising variables properly and performs quite effectively even for large-scale instances having hard GUB constraints.\n    ",
        "submission_date": "2017-05-14T00:00:00",
        "last_modified_date": "2018-01-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.05035",
        "title": "Discrete Sequential Prediction of Continuous Actions for Deep RL",
        "authors": [
            "Luke Metz",
            "Julian Ibarz",
            "Navdeep Jaitly",
            "James Davidson"
        ],
        "abstract": "It has long been assumed that high dimensional continuous control problems cannot be solved effectively by discretizing individual dimensions of the action space due to the exponentially large number of bins over which policies would have to be learned. In this paper, we draw inspiration from the recent success of sequence-to-sequence models for structured prediction problems to develop policies over discretized spaces. Central to this method is the realization that complex functions over high dimensional spaces can be modeled by neural networks that predict one dimension at a time. Specifically, we show how Q-values and policies over continuous spaces can be modeled using a next step prediction model over discretized dimensions. With this parameterization, it is possible to both leverage the compositional structure of action spaces during learning, as well as compute maxima over action spaces (approximately). On a simple example task we demonstrate empirically that our method can perform global search, which effectively gets around the local optimization issues that plague DDPG. We apply the technique to off-policy (Q-learning) methods and show that our method can achieve the state-of-the-art for off-policy methods on several continuous control tasks.\n    ",
        "submission_date": "2017-05-14T00:00:00",
        "last_modified_date": "2019-06-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.05065",
        "title": "AirSim: High-Fidelity Visual and Physical Simulation for Autonomous Vehicles",
        "authors": [
            "Shital Shah",
            "Debadeepta Dey",
            "Chris Lovett",
            "Ashish Kapoor"
        ],
        "abstract": "Developing and testing algorithms for autonomous vehicles in real world is an expensive and time consuming process. Also, in order to utilize recent advances in machine intelligence and deep learning we need to collect a large amount of annotated training data in a variety of conditions and environments. We present a new simulator built on Unreal Engine that offers physically and visually realistic simulations for both of these goals. Our simulator includes a physics engine that can operate at a high frequency for real-time hardware-in-the-loop (HITL) simulations with support for popular protocols (e.g. MavLink). The simulator is designed from the ground up to be extensible to accommodate new types of vehicles, hardware platforms and software protocols. In addition, the modular design enables various components to be easily usable independently in other projects. We demonstrate the simulator by first implementing a quadrotor as an autonomous vehicle and then experimentally comparing the software components with real-world flights.\n    ",
        "submission_date": "2017-05-15T00:00:00",
        "last_modified_date": "2017-07-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.05088",
        "title": "Towards Automated Network Mitigation Analysis (extended)",
        "authors": [
            "Patrick Speicher",
            "Marcel Steinmetz",
            "J\u00f6rg Hoffmann",
            "Michael Backes",
            "Robert K\u00fcnnemann"
        ],
        "abstract": "Penetration testing is a well-established practical concept for the identification of potentially exploitable security weaknesses and an important component of a security audit. Providing a holistic security assessment for networks consisting of several hundreds hosts is hardly feasible though without some sort of mechanization. Mitigation, prioritizing counter-measures subject to a given budget, currently lacks a solid theoretical understanding and is hence more art than science. In this work, we propose the first approach for conducting comprehensive what-if analyses in order to reason about mitigation in a conceptually well-founded manner. To evaluate and compare mitigation strategies, we use simulated penetration testing, i.e., automated attack-finding, based on a network model to which a subset of a given set of mitigation actions, e.g., changes to the network topology, system updates, configuration changes etc. is applied. Using Stackelberg planning, we determine optimal combinations that minimize the maximal attacker success (similar to a Stackelberg game), and thus provide a well-founded basis for a holistic mitigation strategy. We show that these Stackelberg planning models can largely be derived from network scan, public vulnerability databases and manual inspection with various degrees of automation and detail, and we simulate mitigation analysis on networks of different size and vulnerability.\n    ",
        "submission_date": "2017-05-15T00:00:00",
        "last_modified_date": "2019-01-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.05108",
        "title": "Kernel Truncated Regression Representation for Robust Subspace Clustering",
        "authors": [
            "Liangli Zhen",
            "Dezhong Peng",
            "Wei Wang",
            "Xin Yao"
        ],
        "abstract": "Subspace clustering aims to group data points into multiple clusters of which each corresponds to one subspace. Most existing subspace clustering approaches assume that input data lie on linear subspaces. In practice, however, this assumption usually does not hold. To achieve nonlinear subspace clustering, we propose a novel method, called kernel truncated regression representation. Our method consists of the following four steps: 1) projecting the input data into a hidden space, where each data point can be linearly represented by other data points; 2) calculating the linear representation coefficients of the data representations in the hidden space; 3) truncating the trivial coefficients to achieve robustness and block-diagonality; and 4) executing the graph cutting operation on the coefficient matrix by solving a graph Laplacian problem. Our method has the advantages of a closed-form solution and the capacity of clustering data points that lie on nonlinear subspaces. The first advantage makes our method efficient in handling large-scale datasets, and the second one enables the proposed method to conquer the nonlinear subspace clustering challenge. Extensive experiments on six benchmarks demonstrate the effectiveness and the efficiency of the proposed method in comparison with current state-of-the-art approaches.\n    ",
        "submission_date": "2017-05-15T00:00:00",
        "last_modified_date": "2020-03-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.05116",
        "title": "Tuning Modular Networks with Weighted Losses for Hand-Eye Coordination",
        "authors": [
            "Fangyi Zhang",
            "J\u00fcrgen Leitner",
            "Michael Milford",
            "Peter I. Corke"
        ],
        "abstract": "This paper introduces an end-to-end fine-tuning method to improve hand-eye coordination in modular deep visuo-motor policies (modular networks) where each module is trained independently. Benefiting from weighted losses, the fine-tuning method significantly improves the performance of the policies for a robotic planar reaching task.\n    ",
        "submission_date": "2017-05-15T00:00:00",
        "last_modified_date": "2017-05-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.05172",
        "title": "Emotion in Reinforcement Learning Agents and Robots: A Survey",
        "authors": [
            "Thomas M. Moerland",
            "Joost Broekens",
            "Catholijn M. Jonker"
        ],
        "abstract": "This article provides the first survey of computational models of emotion in reinforcement learning (RL) agents. The survey focuses on agent/robot emotions, and mostly ignores human user emotions. Emotions are recognized as functional in decision-making by influencing motivation and action selection. Therefore, computational emotion models are usually grounded in the agent's decision making architecture, of which RL is an important subclass. Studying emotions in RL-based agents is useful for three research fields. For machine learning (ML) researchers, emotion models may improve learning efficiency. For the interactive ML and human-robot interaction (HRI) community, emotions can communicate state and enhance user investment. Lastly, it allows affective modelling (AM) researchers to investigate their emotion theories in a successful AI agent class. This survey provides background on emotion theory and RL. It systematically addresses 1) from what underlying dimensions (e.g., homeostasis, appraisal) emotions can be derived and how these can be modelled in RL-agents, 2) what types of emotions have been derived from these dimensions, and 3) how these emotions may either influence the learning efficiency of the agent or be useful as social signals. We also systematically compare evaluation criteria, and draw connections to important RL sub-domains like (intrinsic) motivation and model-based RL. In short, this survey provides both a practical overview for engineers wanting to implement emotions in their RL agents, and identifies challenges and directions for future emotion-RL research.\n    ",
        "submission_date": "2017-05-15T00:00:00",
        "last_modified_date": "2017-05-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.05206",
        "title": "ResumeVis: A Visual Analytics System to Discover Semantic Information in Semi-structured Resume Data",
        "authors": [
            "Chen Zhang",
            "Hao Wang",
            "Yingcai Wu"
        ],
        "abstract": "Massive public resume data emerging on the WWW indicates individual-related characteristics in terms of profile and career experiences. Resume Analysis (RA) provides opportunities for many applications, such as talent seeking and evaluation. Existing RA studies based on statistical analyzing have primarily focused on talent recruitment by identifying explicit attributes. However, they failed to discover the implicit semantic information, i.e., individual career progress patterns and social-relations, which are vital to comprehensive understanding of career development. Besides, how to visualize them for better human cognition is also challenging. To tackle these issues, we propose a visual analytics system ResumeVis to mine and visualize resume data. Firstly, a text-mining based approach is presented to extract semantic information. Then, a set of visualizations are devised to represent the semantic information in multiple perspectives. By interactive exploration on ResumeVis performed by domain experts, the following tasks can be accomplished: to trace individual career evolving trajectory; to mine latent social-relations among individuals; and to hold the full picture of massive resumes' collective mobility. Case studies with over 2500 online officer resumes demonstrate the effectiveness of our system. We provide a demonstration video.\n    ",
        "submission_date": "2017-05-15T00:00:00",
        "last_modified_date": "2017-05-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.05249",
        "title": "CLBlast: A Tuned OpenCL BLAS Library",
        "authors": [
            "Cedric Nugteren"
        ],
        "abstract": "This work introduces CLBlast, an open-source BLAS library providing optimized OpenCL routines to accelerate dense linear algebra for a wide variety of devices. It is targeted at machine learning and HPC applications and thus provides a fast matrix-multiplication routine (GEMM) to accelerate the core of many applications (e.g. deep learning, iterative solvers, astrophysics, computational fluid dynamics, quantum chemistry). CLBlast has five main advantages over other OpenCL BLAS libraries: 1) it is optimized for and tested on a large variety of OpenCL devices including less commonly used devices such as embedded and low-power GPUs, 2) it can be explicitly tuned for specific problem-sizes on specific hardware platforms, 3) it can perform operations in half-precision floating-point FP16 saving bandwidth, time and energy, 4) it has an optional CUDA back-end, 5) and it can combine multiple operations in a single batched routine, accelerating smaller problems significantly. This paper describes the library and demonstrates the advantages of CLBlast experimentally for different use-cases on a wide variety of OpenCL hardware.\n    ",
        "submission_date": "2017-05-12T00:00:00",
        "last_modified_date": "2018-04-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.05363",
        "title": "Curiosity-driven Exploration by Self-supervised Prediction",
        "authors": [
            "Deepak Pathak",
            "Pulkit Agrawal",
            "Alexei A. Efros",
            "Trevor Darrell"
        ],
        "abstract": "In many real-world scenarios, rewards extrinsic to the agent are extremely sparse, or absent altogether. In such cases, curiosity can serve as an intrinsic reward signal to enable the agent to explore its environment and learn skills that might be useful later in its life. We formulate curiosity as the error in an agent's ability to predict the consequence of its own actions in a visual feature space learned by a self-supervised inverse dynamics model. Our formulation scales to high-dimensional continuous state spaces like images, bypasses the difficulties of directly predicting pixels, and, critically, ignores the aspects of the environment that cannot affect the agent. The proposed approach is evaluated in two environments: VizDoom and Super Mario Bros. Three broad settings are investigated: 1) sparse extrinsic reward, where curiosity allows for far fewer interactions with the environment to reach the goal; 2) exploration with no extrinsic reward, where curiosity pushes the agent to explore more efficiently; and 3) generalization to unseen scenarios (e.g. new levels of the same game) where the knowledge gained from earlier experience helps the agent explore new places much faster than starting from scratch. Demo video and code available at ",
        "submission_date": "2017-05-15T00:00:00",
        "last_modified_date": "2017-05-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.05394",
        "title": "Probabilistically Safe Policy Transfer",
        "authors": [
            "David Held",
            "Zoe McCarthy",
            "Michael Zhang",
            "Fred Shentu",
            "Pieter Abbeel"
        ],
        "abstract": "Although learning-based methods have great potential for robotics, one concern is that a robot that updates its parameters might cause large amounts of damage before it learns the optimal policy. We formalize the idea of safe learning in a probabilistic sense by defining an optimization problem: we desire to maximize the expected return while keeping the expected damage below a given safety limit. We study this optimization for the case of a robot manipulator with safety-based torque limits. We would like to ensure that the damage constraint is maintained at every step of the optimization and not just at convergence. To achieve this aim, we introduce a novel method which predicts how modifying the torque limit, as well as how updating the policy parameters, might affect the robot's safety. We show through a number of experiments that our approach allows the robot to improve its performance while ensuring that the expected damage constraint is not violated during the learning process.\n    ",
        "submission_date": "2017-05-15T00:00:00",
        "last_modified_date": "2017-05-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.05396",
        "title": "Learning Probabilistic Programs Using Backpropagation",
        "authors": [
            "Avi Pfeffer"
        ],
        "abstract": "Probabilistic modeling enables combining domain knowledge with learning from data, thereby supporting learning from fewer training instances than purely data-driven methods. However, learning probabilistic models is difficult and has not achieved the level of performance of methods such as deep neural networks on many tasks. In this paper, we attempt to address this issue by presenting a method for learning the parameters of a probabilistic program using backpropagation. Our approach opens the possibility to building deep probabilistic programming models that are trained in a similar way to neural networks.\n    ",
        "submission_date": "2017-05-15T00:00:00",
        "last_modified_date": "2017-05-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.05681",
        "title": "Optimal Warping Paths are unique for almost every Pair of Time Series",
        "authors": [
            "Brijnesh J. Jain",
            "David Schultz"
        ],
        "abstract": "Update rules for learning in dynamic time warping spaces are based on optimal warping paths between parameter and input time series. In general, optimal warping paths are not unique resulting in adverse effects in theory and practice. Under the assumption of squared error local costs, we show that no two warping paths have identical costs almost everywhere in a measure-theoretic sense. Two direct consequences of this result are: (i) optimal warping paths are unique almost everywhere, and (ii) the set of all pairs of time series with multiple equal-cost warping paths coincides with the union of exponentially many zero sets of quadratic forms. One implication of the proposed results is that typical distance-based cost functions such as the k-means objective are differentiable almost everywhere and can be minimized by subgradient methods.\n    ",
        "submission_date": "2017-05-16T00:00:00",
        "last_modified_date": "2018-03-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.05720",
        "title": "Subjective Knowledge Acquisition and Enrichment Powered By Crowdsourcing",
        "authors": [
            "Rui Meng",
            "Hao Xin",
            "Lei Chen",
            "Yangqiu Song"
        ],
        "abstract": "Knowledge bases (KBs) have attracted increasing attention due to its great success in various areas, such as Web and mobile ",
        "submission_date": "2017-05-16T00:00:00",
        "last_modified_date": "2017-05-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.05735",
        "title": "Comparison-Based Choices",
        "authors": [
            "Jon Kleinberg",
            "Sendhil Mullainathan",
            "Johan Ugander"
        ],
        "abstract": "A broad range of on-line behaviors are mediated by interfaces in which people make choices among sets of options. A rich and growing line of work in the behavioral sciences indicate that human choices follow not only from the utility of alternatives, but also from the choice set in which alternatives are presented. In this work we study comparison-based choice functions, a simple but surprisingly rich class of functions capable of exhibiting so-called choice-set effects. Motivated by the challenge of predicting complex choices, we study the query complexity of these functions in a variety of settings. We consider settings that allow for active queries or passive observation of a stream of queries, and give analyses both at the granularity of individuals or populations that might exhibit heterogeneous choice behavior. Our main result is that any comparison-based choice function in one dimension can be inferred as efficiently as a basic maximum or minimum choice function across many query contexts, suggesting that choice-set effects need not entail any fundamental algorithmic barriers to inference. We also introduce a class of choice functions we call distance-comparison-based functions, and briefly discuss the analysis of such functions. The framework we outline provides intriguing connections between human choice behavior and a range of questions in the theory of sorting.\n    ",
        "submission_date": "2017-05-16T00:00:00",
        "last_modified_date": "2017-05-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.05884",
        "title": "Static Gesture Recognition using Leap Motion",
        "authors": [
            "Babak Toghiani-Rizi",
            "Christofer Lind",
            "Maria Svensson",
            "Marcus Windmark"
        ],
        "abstract": "In this report, an automated bartender system was developed for making orders in a bar using hand gestures. The gesture recognition of the system was developed using Machine Learning techniques, where the model was trained to classify gestures using collected data. The final model used in the system reached an average accuracy of 95%. The system raised ethical concerns both in terms of user interaction and having such a system in a real world scenario, but it could initially work as a complement to a real bartender.\n    ",
        "submission_date": "2017-05-16T00:00:00",
        "last_modified_date": "2017-05-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.05935",
        "title": "Rise of the humanbot",
        "authors": [
            "Ricard Sole"
        ],
        "abstract": "The accelerated path of technological development, particularly at the interface between hardware and biology has been suggested as evidence for future major technological breakthroughs associated to our potential to overcome biological constraints. This includes the potential of becoming immortal, having expanded cognitive capacities thanks to hardware implants or the creation of intelligent machines. Here I argue that several relevant evolutionary and structural constraints might prevent achieving most (if not all) these innovations. Instead, the coming future will bring novelties that will challenge many other aspects of our life and that can be seen as other feasible singularities. One particularly important one has to do with the evolving interactions between humans and non-intelligent robots capable of learning and communication. Here I argue that a long term interaction can lead to a new class of \"agent\" (the humanbot). The way shared memories get tangled over time will inevitably have important consequences for both sides of the pair, whose identity as separated entities might become blurred and ultimately vanish. Understanding such hybrid systems requires a second-order neuroscience approach while posing serious conceptual challenges, including the definition of consciousness.\n    ",
        "submission_date": "2017-05-16T00:00:00",
        "last_modified_date": "2017-05-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.06243",
        "title": "Learning to Represent Haptic Feedback for Partially-Observable Tasks",
        "authors": [
            "Jaeyong Sung",
            "J. Kenneth Salisbury",
            "Ashutosh Saxena"
        ],
        "abstract": "The sense of touch, being the earliest sensory system to develop in a human body [1], plays a critical part of our daily interaction with the environment. In order to successfully complete a task, many manipulation interactions require incorporating haptic feedback. However, manually designing a feedback mechanism can be extremely challenging. In this work, we consider manipulation tasks that need to incorporate tactile sensor feedback in order to modify a provided nominal plan. To incorporate partial observation, we present a new framework that models the task as a partially observable Markov decision process (POMDP) and learns an appropriate representation of haptic feedback which can serve as the state for a POMDP model. The model, that is parametrized by deep recurrent neural networks, utilizes variational Bayes methods to optimize the approximate posterior. Finally, we build on deep Q-learning to be able to select the optimal action in each state without access to a simulator. We test our model on a PR2 robot for multiple tasks of turning a knob until it clicks.\n    ",
        "submission_date": "2017-05-17T00:00:00",
        "last_modified_date": "2017-05-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.06273",
        "title": "Transfer Learning for Named-Entity Recognition with Neural Networks",
        "authors": [
            "Ji Young Lee",
            "Franck Dernoncourt",
            "Peter Szolovits"
        ],
        "abstract": "Recent approaches based on artificial neural networks (ANNs) have shown promising results for named-entity recognition (NER). In order to achieve high performances, ANNs need to be trained on a large labeled dataset. However, labels might be difficult to obtain for the dataset on which the user wants to perform NER: label scarcity is particularly pronounced for patient note de-identification, which is an instance of NER. In this work, we analyze to what extent transfer learning may address this issue. In particular, we demonstrate that transferring an ANN model trained on a large labeled dataset to another dataset with a limited number of labels improves upon the state-of-the-art results on two different datasets for patient note de-identification.\n    ",
        "submission_date": "2017-05-17T00:00:00",
        "last_modified_date": "2017-05-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.06338",
        "title": "Distributed Vector Representation Of Shopping Items, The Customer And Shopping Cart To Build A Three Fold Recommendation System",
        "authors": [
            "Bibek Behera",
            "Manoj Joshi",
            "Abhilash KK",
            "Mohammad Ansari Ismail"
        ],
        "abstract": "The main idea of this paper is to represent shopping items through vectors because these vectors act as the base for building em- beddings for customers and shopping carts. Also, these vectors are input to the mathematical models that act as either a recommendation engine or help in targeting potential customers. We have used exponential family embeddings as the tool to construct two basic vectors - product embeddings and context vectors. Using the basic vectors, we build combined embeddings, trip embeddings and customer embeddings. Combined embeddings mix linguistic properties of product names with their shopping patterns. The customer embeddings establish an understand- ing of the buying pattern of customers in a group and help in building customer profile. For example a customer profile can represent customers frequently buying pet-food. Identifying such profiles can help us bring out offers and discounts. Similarly, trip embeddings are used to build trip profiles. People happen to buy similar set of products in a trip and hence their trip embeddings can be used to predict the next product they would like to buy. This is a novel technique and the first of its kind to make recommendation using product, trip and customer embeddings.\n    ",
        "submission_date": "2017-05-17T00:00:00",
        "last_modified_date": "2017-05-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.06366",
        "title": "Automatic Goal Generation for Reinforcement Learning Agents",
        "authors": [
            "Carlos Florensa",
            "David Held",
            "Xinyang Geng",
            "Pieter Abbeel"
        ],
        "abstract": "Reinforcement learning is a powerful technique to train an agent to perform a task. However, an agent that is trained using reinforcement learning is only capable of achieving the single task that is specified via its reward function. Such an approach does not scale well to settings in which an agent needs to perform a diverse set of tasks, such as navigating to varying positions in a room or moving objects to varying locations. Instead, we propose a method that allows an agent to automatically discover the range of tasks that it is capable of performing. We use a generator network to propose tasks for the agent to try to achieve, specified as goal states. The generator network is optimized using adversarial training to produce tasks that are always at the appropriate level of difficulty for the agent. Our method thus automatically produces a curriculum of tasks for the agent to learn. We show that, by using this framework, an agent can efficiently and automatically learn to perform a wide set of tasks without requiring any prior knowledge of its environment. Our method can also learn to achieve tasks with sparse rewards, which traditionally pose significant challenges.\n    ",
        "submission_date": "2017-05-17T00:00:00",
        "last_modified_date": "2018-07-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.06431",
        "title": "Vehicle Routing with Drones",
        "authors": [
            "Rami Daknama",
            "Elisabeth Kraus"
        ],
        "abstract": "We introduce a package service model where trucks as well as drones can deliver packages. Drones can travel on trucks or fly; but while flying, drones can only carry one package at a time and have to return to a truck to charge after each delivery. We present a heuristic algorithm to solve the problem of finding a good schedule for all drones and trucks. The algorithm is based on two nested local searches, thus the definition of suitable neighbourhoods of solutions is crucial for the algorithm. Empirical tests show that our algorithm performs significantly better than a natural Greedy algorithm. Moreover, the savings compared to solutions without drones turn out to be substantial, suggesting that delivery systems might considerably benefit from using drones in addition to trucks.\n    ",
        "submission_date": "2017-05-18T00:00:00",
        "last_modified_date": "2017-05-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.06460",
        "title": "Evolving Ensemble Fuzzy Classifier",
        "authors": [
            "Mahardhika Pratama",
            "Witold Pedrycz",
            "Edwin Lughofer"
        ],
        "abstract": "The concept of ensemble learning offers a promising avenue in learning from data streams under complex environments because it addresses the bias and variance dilemma better than its single model counterpart and features a reconfigurable structure, which is well suited to the given context. While various extensions of ensemble learning for mining non-stationary data streams can be found in the literature, most of them are crafted under a static base classifier and revisits preceding samples in the sliding window for a retraining step. This feature causes computationally prohibitive complexity and is not flexible enough to cope with rapidly changing environments. Their complexities are often demanding because it involves a large collection of offline classifiers due to the absence of structural complexities reduction mechanisms and lack of an online feature selection mechanism. A novel evolving ensemble classifier, namely Parsimonious Ensemble pENsemble, is proposed in this paper. pENsemble differs from existing architectures in the fact that it is built upon an evolving classifier from data streams, termed Parsimonious Classifier pClass. pENsemble is equipped by an ensemble pruning mechanism, which estimates a localized generalization error of a base classifier. A dynamic online feature selection scenario is integrated into the pENsemble. This method allows for dynamic selection and deselection of input features on the fly. pENsemble adopts a dynamic ensemble structure to output a final classification decision where it features a novel drift detection scenario to grow the ensemble structure. The efficacy of the pENsemble has been numerically demonstrated through rigorous numerical studies with dynamic and evolving data streams where it delivers the most encouraging performance in attaining a tradeoff between accuracy and complexity.\n    ",
        "submission_date": "2017-05-18T00:00:00",
        "last_modified_date": "2019-12-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.06573",
        "title": "Online learnability of Statistical Relational Learning in anomaly detection",
        "authors": [
            "Magnus J\u00e4ndel",
            "Pontus Svenson",
            "Niclas Wadstr\u00f6mer"
        ],
        "abstract": "Statistical Relational Learning (SRL) methods for anomaly detection are introduced via a security-related application. Operational requirements for online learning stability are outlined and compared to mathematical definitions as applied to the learning process of a representative SRL method - Bayesian Logic Programs (BLP). Since a formal proof of online stability appears to be impossible, tentative common sense requirements are formulated and tested by theoretical and experimental analysis of a simple and analytically tractable BLP model. It is found that learning algorithms in initial stages of online learning can lock on unstable false predictors that nevertheless comply with our tentative stability requirements and thus masquerade as bona fide solutions. The very expressiveness of SRL seems to cause significant stability issues in settings with many variables and scarce data. We conclude that reliable anomaly detection with SRL-methods requires monitoring by an overarching framework that may involve a comprehensive context knowledge base or human supervision.\n    ",
        "submission_date": "2017-05-18T00:00:00",
        "last_modified_date": "2017-05-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.06694",
        "title": "I Probe, Therefore I Am: Designing a Virtual Journalist with Human Emotions",
        "authors": [
            "Kevin K. Bowden",
            "Tommy Nilsson",
            "Christine P. Spencer",
            "Kubra Cengiz",
            "Alexandru Ghitulescu",
            "Jelte B. van Waterschoot"
        ],
        "abstract": "By utilizing different communication channels, such as verbal language, gestures or facial expressions, virtually embodied interactive humans hold a unique potential to bridge the gap between human-computer interaction and actual interhuman communication. The use of virtual humans is consequently becoming increasingly popular in a wide range of areas where such a natural communication might be beneficial, including entertainment, education, mental health research and beyond. Behind this development lies a series of technological advances in a multitude of disciplines, most notably natural language processing, computer vision, and speech synthesis. In this paper we discuss a Virtual Human Journalist, a project employing a number of novel solutions from these disciplines with the goal to demonstrate their viability by producing a humanoid conversational agent capable of naturally eliciting and reacting to information from a human user. A set of qualitative and quantitative evaluation sessions demonstrated the technical feasibility of the system whilst uncovering a number of deficits in its capacity to engage users in a way that would be perceived as natural and emotionally engaging. We argue that naturalness should not always be seen as a desirable goal and suggest that deliberately suppressing the naturalness of virtual human interactions, such as by altering its personality cues, might in some cases yield more desirable results.\n    ",
        "submission_date": "2017-05-18T00:00:00",
        "last_modified_date": "2017-05-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.06709",
        "title": "Learning Spatiotemporal Features for Infrared Action Recognition with 3D Convolutional Neural Networks",
        "authors": [
            "Zhuolin Jiang",
            "Viktor Rozgic",
            "Sancar Adali"
        ],
        "abstract": "Infrared (IR) imaging has the potential to enable more robust action recognition systems compared to visible spectrum cameras due to lower sensitivity to lighting conditions and appearance variability. While the action recognition task on videos collected from visible spectrum imaging has received much attention, action recognition in IR videos is significantly less explored. Our objective is to exploit imaging data in this modality for the action recognition task. In this work, we propose a novel two-stream 3D convolutional neural network (CNN) architecture by introducing the discriminative code layer and the corresponding discriminative code loss function. The proposed network processes IR image and the IR-based optical flow field sequences. We pretrain the 3D CNN model on the visible spectrum Sports-1M action dataset and finetune it on the Infrared Action Recognition (InfAR) dataset. To our best knowledge, this is the first application of the 3D CNN to action recognition in the IR domain. We conduct an elaborate analysis of different fusion schemes (weighted average, single and double-layer neural nets) applied to different 3D CNN outputs. Experimental results demonstrate that our approach can achieve state-of-the-art average precision (AP) performances on the InfAR dataset: (1) the proposed two-stream 3D CNN achieves the best reported 77.5% AP, and (2) our 3D CNN model applied to the optical flow fields achieves the best reported single stream 75.42% AP.\n    ",
        "submission_date": "2017-05-18T00:00:00",
        "last_modified_date": "2017-05-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.06715",
        "title": "Continuous Implicit Authentication for Mobile Devices based on Adaptive Neuro-Fuzzy Inference System",
        "authors": [
            "Feng Yao",
            "Suleiman Y. Yerima",
            "BooJoong Kang",
            "Sakir Sezer"
        ],
        "abstract": "As mobile devices have become indispensable in modern life, mobile security is becoming much more important. Traditional password or PIN-like point-of-entry security measures score low on usability and are vulnerable to brute force and other types of attacks. In order to improve mobile security, an adaptive neuro-fuzzy inference system(ANFIS)-based implicit authentication system is proposed in this paper to provide authentication in a continuous and transparent ",
        "submission_date": "2017-05-18T00:00:00",
        "last_modified_date": "2017-05-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.06769",
        "title": "Feature Control as Intrinsic Motivation for Hierarchical Reinforcement Learning",
        "authors": [
            "Nat Dilokthanakul",
            "Christos Kaplanis",
            "Nick Pawlowski",
            "Murray Shanahan"
        ],
        "abstract": "The problem of sparse rewards is one of the hardest challenges in contemporary reinforcement learning. Hierarchical reinforcement learning (HRL) tackles this problem by using a set of temporally-extended actions, or options, each of which has its own subgoal. These subgoals are normally handcrafted for specific tasks. Here, though, we introduce a generic class of subgoals with broad applicability in the visual domain. Underlying our approach (in common with work using \"auxiliary tasks\") is the hypothesis that the ability to control aspects of the environment is an inherently useful skill to have. We incorporate such subgoals in an end-to-end hierarchical reinforcement learning system and test two variants of our algorithm on a number of games from the Atari suite. We highlight the advantage of our approach in one of the hardest games -- Montezuma's revenge -- for which the ability to handle sparse rewards is key. Our agent learns several times faster than the current state-of-the-art HRL agent in this game, reaching a similar level of performance. UPDATE 22/11/17: We found that a standard A3C agent with a simple shaped reward, i.e. extrinsic reward + feature control intrinsic reward, has comparable performance to our agent in Montezuma Revenge. In light of the new experiments performed, the advantage of our HRL approach can be attributed more to its ability to learn useful features from intrinsic rewards rather than its ability to explore and reuse abstracted skills with hierarchical components. This has led us to a new conclusion about the result.\n    ",
        "submission_date": "2017-05-18T00:00:00",
        "last_modified_date": "2017-11-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.06936",
        "title": "Atari games and Intel processors",
        "authors": [
            "Robert Adamski",
            "Tomasz Grel",
            "Maciej Klimek",
            "Henryk Michalewski"
        ],
        "abstract": "The asynchronous nature of the state-of-the-art reinforcement learning algorithms such as the Asynchronous Advantage Actor-Critic algorithm, makes them exceptionally suitable for CPU computations. However, given the fact that deep reinforcement learning often deals with interpreting visual information, a large part of the train and inference time is spent performing convolutions. In this work we present our results on learning strategies in Atari games using a Convolutional Neural Network, the Math Kernel Library and TensorFlow 0.11rc0 machine learning framework. We also analyze effects of asynchronous computations on the convergence of reinforcement learning algorithms.\n    ",
        "submission_date": "2017-05-19T00:00:00",
        "last_modified_date": "2017-05-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.07086",
        "title": "Estimating Accuracy from Unlabeled Data: A Probabilistic Logic Approach",
        "authors": [
            "Emmanouil A. Platanios",
            "Hoifung Poon",
            "Tom M. Mitchell",
            "Eric Horvitz"
        ],
        "abstract": "We propose an efficient method to estimate the accuracy of classifiers using only unlabeled data. We consider a setting with multiple classification problems where the target classes may be tied together through logical constraints. For example, a set of classes may be mutually exclusive, meaning that a data instance can belong to at most one of them. The proposed method is based on the intuition that: (i) when classifiers agree, they are more likely to be correct, and (ii) when the classifiers make a prediction that violates the constraints, at least one classifier must be making an error. Experiments on four real-world data sets produce accuracy estimates within a few percent of the true accuracy, using solely unlabeled data. Our models also outperform existing state-of-the-art solutions in both estimating accuracies, and combining multiple classifier outputs. The results emphasize the utility of logical constraints in estimating accuracy, thus validating our intuition.\n    ",
        "submission_date": "2017-05-19T00:00:00",
        "last_modified_date": "2017-05-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.07114",
        "title": "A Comparison of Reinforcement Learning Techniques for Fuzzy Cloud Auto-Scaling",
        "authors": [
            "Hamid Arabnejad",
            "Claus Pahl",
            "Pooyan Jamshidi",
            "Giovani Estrada"
        ],
        "abstract": "A goal of cloud service management is to design self-adaptable auto-scaler to react to workload fluctuations and changing the resources assigned. The key problem is how and when to add/remove resources in order to meet agreed service-level agreements. Reducing application cost and guaranteeing service-level agreements (SLAs) are two critical factors of dynamic controller design. In this paper, we compare two dynamic learning strategies based on a fuzzy logic system, which learns and modifies fuzzy scaling rules at runtime. A self-adaptive fuzzy logic controller is combined with two reinforcement learning (RL) approaches: (i) Fuzzy SARSA learning (FSL) and (ii) Fuzzy Q-learning (FQL). As an off-policy approach, Q-learning learns independent of the policy currently followed, whereas SARSA as an on-policy always incorporates the actual agent's behavior and leads to faster learning. Both approaches are implemented and compared in their advantages and disadvantages, here in the OpenStack cloud platform. We demonstrate that both auto-scaling approaches can handle various load traffic situations, sudden and periodic, and delivering resources on demand while reducing operating costs and preventing SLA violations. The experimental results demonstrate that FSL and FQL have acceptable performance in terms of adjusted number of virtual machine targeted to optimize SLA compliance and response time.\n    ",
        "submission_date": "2017-05-19T00:00:00",
        "last_modified_date": "2017-05-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.07120",
        "title": "VAE with a VampPrior",
        "authors": [
            "Jakub M. Tomczak",
            "Max Welling"
        ],
        "abstract": "Many different methods to train deep generative models have been introduced in the past. In this paper, we propose to extend the variational auto-encoder (VAE) framework with a new type of prior which we call \"Variational Mixture of Posteriors\" prior, or VampPrior for short. The VampPrior consists of a mixture distribution (e.g., a mixture of Gaussians) with components given by variational posteriors conditioned on learnable pseudo-inputs. We further extend this prior to a two layer hierarchical model and show that this architecture with a coupled prior and posterior, learns significantly better models. The model also avoids the usual local optima issues related to useless latent dimensions that plague VAEs. We provide empirical studies on six datasets, namely, static and binary MNIST, OMNIGLOT, Caltech 101 Silhouettes, Frey Faces and Histopathology patches, and show that applying the hierarchical VampPrior delivers state-of-the-art results on all datasets in the unsupervised permutation invariant setting and the best results or comparable to SOTA methods for the approach with convolutional networks.\n    ",
        "submission_date": "2017-05-19T00:00:00",
        "last_modified_date": "2018-02-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.07224",
        "title": "AIDE: An algorithm for measuring the accuracy of probabilistic inference algorithms",
        "authors": [
            "Marco F. Cusumano-Towner",
            "Vikash K. Mansinghka"
        ],
        "abstract": "Approximate probabilistic inference algorithms are central to many fields. Examples include sequential Monte Carlo inference in robotics, variational inference in machine learning, and Markov chain Monte Carlo inference in statistics. A key problem faced by practitioners is measuring the accuracy of an approximate inference algorithm on a specific data set. This paper introduces the auxiliary inference divergence estimator (AIDE), an algorithm for measuring the accuracy of approximate inference algorithms. AIDE is based on the observation that inference algorithms can be treated as probabilistic models and the random variables used within the inference algorithm can be viewed as auxiliary variables. This view leads to a new estimator for the symmetric KL divergence between the approximating distributions of two inference algorithms. The paper illustrates application of AIDE to algorithms for inference in regression, hidden Markov, and Dirichlet process mixture models. The experiments show that AIDE captures the qualitative behavior of a broad class of inference algorithms and can detect failure modes of inference algorithms that are missed by standard heuristics.\n    ",
        "submission_date": "2017-05-19T00:00:00",
        "last_modified_date": "2017-11-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.07262",
        "title": "Batch Reinforcement Learning on the Industrial Benchmark: First Experiences",
        "authors": [
            "Daniel Hein",
            "Steffen Udluft",
            "Michel Tokic",
            "Alexander Hentschel",
            "Thomas A. Runkler",
            "Volkmar Sterzing"
        ],
        "abstract": "The Particle Swarm Optimization Policy (PSO-P) has been recently introduced and proven to produce remarkable results on interacting with academic reinforcement learning benchmarks in an off-policy, batch-based setting. To further investigate the properties and feasibility on real-world applications, this paper investigates PSO-P on the so-called Industrial Benchmark (IB), a novel reinforcement learning (RL) benchmark that aims at being realistic by including a variety of aspects found in industrial applications, like continuous state and action spaces, a high dimensional, partially observable state space, delayed effects, and complex stochasticity. The experimental results of PSO-P on IB are compared to results of closed-form control policies derived from the model-based Recurrent Control Neural Network (RCNN) and the model-free Neural Fitted Q-Iteration (NFQ). Experiments show that PSO-P is not only of interest for academic benchmarks, but also for real-world industrial applications, since it also yielded the best performing policy in our IB setting. Compared to other well established RL techniques, PSO-P produced outstanding results in performance and robustness, requiring only a relatively low amount of effort in finding adequate parameters or making complex design decisions.\n    ",
        "submission_date": "2017-05-20T00:00:00",
        "last_modified_date": "2017-07-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.07267",
        "title": "Search Engine Guided Non-Parametric Neural Machine Translation",
        "authors": [
            "Jiatao Gu",
            "Yong Wang",
            "Kyunghyun Cho",
            "Victor O.K. Li"
        ],
        "abstract": "In this paper, we extend an attention-based neural machine translation (NMT) model by allowing it to access an entire training set of parallel sentence pairs even after training. The proposed approach consists of two stages. In the first stage--retrieval stage--, an off-the-shelf, black-box search engine is used to retrieve a small subset of sentence pairs from a training set given a source sentence. These pairs are further filtered based on a fuzzy matching score based on edit distance. In the second stage--translation stage--, a novel translation model, called translation memory enhanced NMT (TM-NMT), seamlessly uses both the source sentence and a set of retrieved sentence pairs to perform the translation. Empirical evaluation on three language pairs (En-Fr, En-De, and En-Es) shows that the proposed approach significantly outperforms the baseline approach and the improvement is more significant when more relevant sentence pairs were retrieved.\n    ",
        "submission_date": "2017-05-20T00:00:00",
        "last_modified_date": "2018-03-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.07269",
        "title": "Learning to Factor Policies and Action-Value Functions: Factored Action Space Representations for Deep Reinforcement learning",
        "authors": [
            "Sahil Sharma",
            "Aravind Suresh",
            "Rahul Ramesh",
            "Balaraman Ravindran"
        ],
        "abstract": "Deep Reinforcement Learning (DRL) methods have performed well in an increasing numbering of high-dimensional visual decision making domains. Among all such visual decision making problems, those with discrete action spaces often tend to have underlying compositional structure in the said action space. Such action spaces often contain actions such as go left, go up as well as go diagonally up and left (which is a composition of the former two actions). The representations of control policies in such domains have traditionally been modeled without exploiting this inherent compositional structure in the action spaces. We propose a new learning paradigm, Factored Action space Representations (FAR) wherein we decompose a control policy learned using a Deep Reinforcement Learning Algorithm into independent components, analogous to decomposing a vector in terms of some orthogonal basis vectors. This architectural modification of the control policy representation allows the agent to learn about multiple actions simultaneously, while executing only one of them. We demonstrate that FAR yields considerable improvements on top of two DRL algorithms in Atari 2600: FARA3C outperforms A3C (Asynchronous Advantage Actor Critic) in 9 out of 14 tasks and FARAQL outperforms AQL (Asynchronous n-step Q-Learning) in 9 out of 13 tasks.\n    ",
        "submission_date": "2017-05-20T00:00:00",
        "last_modified_date": "2017-05-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.07325",
        "title": "Fast Change Point Detection on Dynamic Social Networks",
        "authors": [
            "Yu Wang",
            "Aniket Chakrabarti",
            "David Sivakoff",
            "Srinivasan Parthasarathy"
        ],
        "abstract": "A number of real world problems in many domains (e.g. sociology, biology, political science and communication networks) can be modeled as dynamic networks with nodes representing entities of interest and edges representing interactions among the entities at different points in time. A common representation for such models is the snapshot model - where a network is defined at logical time-stamps. An important problem under this model is change point detection. In this work we devise an effective and efficient three-step-approach for detecting change points in dynamic networks under the snapshot model. Our algorithm achieves up to 9X speedup over the state-of-the-art while improving quality on both synthetic and real world networks.\n    ",
        "submission_date": "2017-05-20T00:00:00",
        "last_modified_date": "2017-06-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.07347",
        "title": "Ensemble Sampling",
        "authors": [
            "Xiuyuan Lu",
            "Benjamin Van Roy"
        ],
        "abstract": "Thompson sampling has emerged as an effective heuristic for a broad range of online decision problems. In its basic form, the algorithm requires computing and sampling from a posterior distribution over models, which is tractable only for simple special cases. This paper develops ensemble sampling, which aims to approximate Thompson sampling while maintaining tractability even in the face of complex models such as neural networks. Ensemble sampling dramatically expands on the range of applications for which Thompson sampling is viable. We establish a theoretical basis that supports the approach and present computational results that offer further insight.\n    ",
        "submission_date": "2017-05-20T00:00:00",
        "last_modified_date": "2023-04-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.07368",
        "title": "Mixed Membership Word Embeddings for Computational Social Science",
        "authors": [
            "James Foulds"
        ],
        "abstract": "Word embeddings improve the performance of NLP systems by revealing the hidden structural relationships between words. Despite their success in many applications, word embeddings have seen very little use in computational social science NLP tasks, presumably due to their reliance on big data, and to a lack of interpretability. I propose a probabilistic model-based word embedding method which can recover interpretable embeddings, without big data. The key insight is to leverage mixed membership modeling, in which global representations are shared, but individual entities (i.e. dictionary words) are free to use these representations to uniquely differing degrees. I show how to train the model using a combination of state-of-the-art training techniques for word embeddings and topic models. The experimental results show an improvement in predictive language modeling of up to 63% in MRR over the skip-gram, and demonstrate that the representations are beneficial for supervised learning. I illustrate the interpretability of the models with computational social science case studies on State of the Union addresses and NIPS articles.\n    ",
        "submission_date": "2017-05-20T00:00:00",
        "last_modified_date": "2018-02-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.07445",
        "title": "Learning to Mix n-Step Returns: Generalizing lambda-Returns for Deep Reinforcement Learning",
        "authors": [
            "Sahil Sharma",
            "Girish Raguvir J",
            "Srivatsan Ramesh",
            "Balaraman Ravindran"
        ],
        "abstract": "Reinforcement Learning (RL) can model complex behavior policies for goal-directed sequential decision making tasks. A hallmark of RL algorithms is Temporal Difference (TD) learning: value function for the current state is moved towards a bootstrapped target that is estimated using next state's value function. $\\lambda$-returns generalize beyond 1-step returns and strike a balance between Monte Carlo and TD learning methods. While lambda-returns have been extensively studied in RL, they haven't been explored a lot in Deep RL. This paper's first contribution is an exhaustive benchmarking of lambda-returns. Although mathematically tractable, the use of exponentially decaying weighting of n-step returns based targets in lambda-returns is a rather ad-hoc design choice. Our second major contribution is that we propose a generalization of lambda-returns called Confidence-based Autodidactic Returns (CAR), wherein the RL agent learns the weighting of the n-step returns in an end-to-end manner. This allows the agent to learn to decide how much it wants to weigh the n-step returns based targets. In contrast, lambda-returns restrict RL agents to use an exponentially decaying weighting scheme. Autodidactic returns can be used for improving any RL algorithm which uses TD learning. We empirically demonstrate that using sophisticated weighted mixtures of multi-step returns (like CAR and lambda-returns) considerably outperforms the use of n-step returns. We perform our experiments on the Asynchronous Advantage Actor Critic (A3C) algorithm in the Atari 2600 domain.\n    ",
        "submission_date": "2017-05-21T00:00:00",
        "last_modified_date": "2017-11-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.07477",
        "title": "Statistical inference using SGD",
        "authors": [
            "Tianyang Li",
            "Liu Liu",
            "Anastasios Kyrillidis",
            "Constantine Caramanis"
        ],
        "abstract": "We present a novel method for frequentist statistical inference in $M$-estimation problems, based on stochastic gradient descent (SGD) with a fixed step size: we demonstrate that the average of such SGD sequences can be used for statistical inference, after proper scaling. An intuitive analysis using the Ornstein-Uhlenbeck process suggests that such averages are asymptotically normal. From a practical perspective, our SGD-based inference procedure is a first order method, and is well-suited for large scale problems. To show its merits, we apply it to both synthetic and real datasets, and demonstrate that its accuracy is comparable to classical statistical methods, while requiring potentially far less computation.\n    ",
        "submission_date": "2017-05-21T00:00:00",
        "last_modified_date": "2017-11-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.07558",
        "title": "Note on Evolution and Forecasting of Requirements: Communications Example",
        "authors": [
            "Mark Sh. Levin"
        ],
        "abstract": "Combinatorial evolution and forecasting of system requirements is examined. The morphological model is used for a hierarchical requirements system (i.e., system parts, design alternatives for the system parts, ordinal estimates for the alternatives). A set of system changes involves changes of the system structure, component alternatives and their estimates. The composition process of the forecast is based on combinatorial synthesis (knapsack problem, multiple choice problem, hierarchical morphological design). An illustrative numerical example for four-phase evolution and forecasting of requirements to communications is described.\n    ",
        "submission_date": "2017-05-22T00:00:00",
        "last_modified_date": "2017-05-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.07798",
        "title": "A unified view of entropy-regularized Markov decision processes",
        "authors": [
            "Gergely Neu",
            "Anders Jonsson",
            "Vicen\u00e7 G\u00f3mez"
        ],
        "abstract": "We propose a general framework for entropy-regularized average-reward reinforcement learning in Markov decision processes (MDPs). Our approach is based on extending the linear-programming formulation of policy optimization in MDPs to accommodate convex regularization functions. Our key result is showing that using the conditional entropy of the joint state-action distributions as regularization yields a dual optimization problem closely resembling the Bellman optimality equations. This result enables us to formalize a number of state-of-the-art entropy-regularized reinforcement learning algorithms as approximate variants of Mirror Descent or Dual Averaging, and thus to argue about the convergence properties of these methods. In particular, we show that the exact version of the TRPO algorithm of Schulman et al. (2015) actually converges to the optimal policy, while the entropy-regularized policy gradient methods of Mnih et al. (2016) may fail to converge to a fixed point. Finally, we illustrate empirically the effects of using various regularization techniques on learning performance in a simple reinforcement learning setup.\n    ",
        "submission_date": "2017-05-22T00:00:00",
        "last_modified_date": "2017-05-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.07830",
        "title": "Ask the Right Questions: Active Question Reformulation with Reinforcement Learning",
        "authors": [
            "Christian Buck",
            "Jannis Bulian",
            "Massimiliano Ciaramita",
            "Wojciech Gajewski",
            "Andrea Gesmundo",
            "Neil Houlsby",
            "Wei Wang"
        ],
        "abstract": "We frame Question Answering (QA) as a Reinforcement Learning task, an approach that we call Active Question Answering. We propose an agent that sits between the user and a black box QA system and learns to reformulate questions to elicit the best possible answers. The agent probes the system with, potentially many, natural language reformulations of an initial question and aggregates the returned evidence to yield the best answer. The reformulation system is trained end-to-end to maximize answer quality using policy gradient. We evaluate on SearchQA, a dataset of complex questions extracted from Jeopardy!. The agent outperforms a state-of-the-art base model, playing the role of the environment, and other benchmarks. We also analyze the language that the agent has learned while interacting with the question answering system. We find that successful question reformulations look quite different from natural language paraphrases. The agent is able to discover non-trivial reformulation strategies that resemble classic information retrieval techniques such as term re-weighting (tf-idf) and stemming.\n    ",
        "submission_date": "2017-05-22T00:00:00",
        "last_modified_date": "2018-03-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.07904",
        "title": "Semantically Decomposing the Latent Spaces of Generative Adversarial Networks",
        "authors": [
            "Chris Donahue",
            "Zachary C. Lipton",
            "Akshay Balsubramani",
            "Julian McAuley"
        ],
        "abstract": "We propose a new algorithm for training generative adversarial networks that jointly learns latent codes for both identities (e.g. individual humans) and observations (e.g. specific photographs). By fixing the identity portion of the latent codes, we can generate diverse images of the same subject, and by fixing the observation portion, we can traverse the manifold of subjects while maintaining contingent aspects such as lighting and pose. Our algorithm features a pairwise training scheme in which each sample from the generator consists of two images with a common identity code. Corresponding samples from the real dataset consist of two distinct photographs of the same subject. In order to fool the discriminator, the generator must produce pairs that are photorealistic, distinct, and appear to depict the same individual. We augment both the DCGAN and BEGAN approaches with Siamese discriminators to facilitate pairwise training. Experiments with human judges and an off-the-shelf face verification system demonstrate our algorithm's ability to generate convincing, identity-matched photographs.\n    ",
        "submission_date": "2017-05-22T00:00:00",
        "last_modified_date": "2018-02-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.07962",
        "title": "pix2code: Generating Code from a Graphical User Interface Screenshot",
        "authors": [
            "Tony Beltramelli"
        ],
        "abstract": "Transforming a graphical user interface screenshot created by a designer into computer code is a typical task conducted by a developer in order to build customized software, websites, and mobile applications. In this paper, we show that deep learning methods can be leveraged to train a model end-to-end to automatically generate code from a single input image with over 77% of accuracy for three different platforms (i.e. iOS, Android and web-based technologies).\n    ",
        "submission_date": "2017-05-22T00:00:00",
        "last_modified_date": "2017-09-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.08044",
        "title": "Detection Algorithms for Communication Systems Using Deep Learning",
        "authors": [
            "Nariman Farsad",
            "Andrea Goldsmith"
        ],
        "abstract": "The design and analysis of communication systems typically rely on the development of mathematical models that describe the underlying communication channel, which dictates the relationship between the transmitted and the received signals. However, in some systems, such as molecular communication systems where chemical signals are used for transfer of information, it is not possible to accurately model this relationship. In these scenarios, because of the lack of mathematical channel models, a completely new approach to design and analysis is required. In this work, we focus on one important aspect of communication systems, the detection algorithms, and demonstrate that by borrowing tools from deep learning, it is possible to train detectors that perform well, without any knowledge of the underlying channel models. We evaluate these algorithms using experimental data that is collected by a chemical communication platform, where the channel model is unknown and difficult to model analytically. We show that deep learning algorithms perform significantly better than a simple detector that was used in previous works, which also did not assume any knowledge of the channel.\n    ",
        "submission_date": "2017-05-22T00:00:00",
        "last_modified_date": "2017-07-31T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.08142",
        "title": "Latent Multi-task Architecture Learning",
        "authors": [
            "Sebastian Ruder",
            "Joachim Bingel",
            "Isabelle Augenstein",
            "Anders S\u00f8gaard"
        ],
        "abstract": "Multi-task learning (MTL) allows deep neural networks to learn from related tasks by sharing parameters with other networks. In practice, however, MTL involves searching an enormous space of possible parameter sharing architectures to find (a) the layers or subspaces that benefit from sharing, (b) the appropriate amount of sharing, and (c) the appropriate relative weights of the different task losses. Recent work has addressed each of the above problems in isolation. In this work we present an approach that learns a latent multi-task architecture that jointly addresses (a)--(c). We present experiments on synthetic data and data from OntoNotes 5.0, including four different tasks and seven different domains. Our extension consistently outperforms previous approaches to learning latent architectures for multi-task problems and achieves up to 15% average error reductions over common approaches to MTL.\n    ",
        "submission_date": "2017-05-23T00:00:00",
        "last_modified_date": "2018-11-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.08369",
        "title": "Her2 Challenge Contest: A Detailed Assessment of Automated Her2 Scoring Algorithms in Whole Slide Images of Breast Cancer Tissues",
        "authors": [
            "Talha Qaiser",
            "Abhik Mukherjee",
            "Chaitanya Reddy Pb",
            "Sai Dileep Munugoti",
            "Vamsi Tallam",
            "Tomi Pitk\u00e4aho",
            "Taina Lehtim\u00e4ki",
            "Thomas Naughton",
            "Matt Berseth",
            "An\u00edbal Pedraza",
            "Ramakrishnan Mukundan",
            "Matthew Smith",
            "Abhir Bhalerao",
            "Erik Rodner",
            "Marcel Simon",
            "Joachim Denzler",
            "Chao-Hui Huang",
            "Gloria Bueno",
            "David Snead",
            "Ian Ellis",
            "Mohammad Ilyas",
            "Nasir Rajpoot"
        ],
        "abstract": "Evaluating expression of the Human epidermal growth factor receptor 2 (Her2) by visual examination of immunohistochemistry (IHC) on invasive breast cancer (BCa) is a key part of the diagnostic assessment of BCa due to its recognised importance as a predictive and prognostic marker in clinical practice. However, visual scoring of Her2 is subjective and consequently prone to inter-observer variability. Given the prognostic and therapeutic implications of Her2 scoring, a more objective method is required. In this paper, we report on a recent automated Her2 scoring contest, held in conjunction with the annual PathSoc meeting held in Nottingham in June 2016, aimed at systematically comparing and advancing the state-of-the-art Artificial Intelligence (AI) based automated methods for Her2 scoring. The contest dataset comprised of digitised whole slide images (WSI) of sections from 86 cases of invasive breast carcinoma stained with both Haematoxylin & Eosin (H&E) and IHC for Her2. The contesting algorithms automatically predicted scores of the IHC slides for an unseen subset of the dataset and the predicted scores were compared with the 'ground truth' (a consensus score from at least two experts). We also report on a simple Man vs Machine contest for the scoring of Her2 and show that the automated methods could beat the pathology experts on this contest dataset. This paper presents a benchmark for comparing the performance of automated algorithms for scoring of Her2. It also demonstrates the enormous potential of automated algorithms in assisting the pathologist with objective IHC scoring.\n    ",
        "submission_date": "2017-05-23T00:00:00",
        "last_modified_date": "2017-07-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.08395",
        "title": "Continual Learning in Generative Adversarial Nets",
        "authors": [
            "Ari Seff",
            "Alex Beatson",
            "Daniel Suo",
            "Han Liu"
        ],
        "abstract": "Developments in deep generative models have allowed for tractable learning of high-dimensional data distributions. While the employed learning procedures typically assume that training data is drawn i.i.d. from the distribution of interest, it may be desirable to model distinct distributions which are observed sequentially, such as when different classes are encountered over time. Although conditional variations of deep generative models permit multiple distributions to be modeled by a single network in a disentangled fashion, they are susceptible to catastrophic forgetting when the distributions are encountered sequentially. In this paper, we adapt recent work in reducing catastrophic forgetting to the task of training generative adversarial networks on a sequence of distinct distributions, enabling continual generative modeling.\n    ",
        "submission_date": "2017-05-23T00:00:00",
        "last_modified_date": "2017-05-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.08426",
        "title": "Symbolic LTLf Synthesis",
        "authors": [
            "Shufang Zhu",
            "Lucas M. Tabajara",
            "Jianwen Li",
            "Geguang Pu",
            "Moshe Y. Vardi"
        ],
        "abstract": "LTLf synthesis is the process of finding a strategy that satisfies a linear temporal specification over finite traces. An existing solution to this problem relies on a reduction to a DFA game. In this paper, we propose a symbolic framework for LTLf synthesis based on this technique, by performing the computation over a representation of the DFA as a boolean formula rather than as an explicit graph. This approach enables strategy generation by utilizing the mechanism of boolean synthesis. We implement this symbolic synthesis method in a tool called Syft, and demonstrate by experiments on scalable benchmarks that the symbolic approach scales better than the explicit one.\n    ",
        "submission_date": "2017-05-23T00:00:00",
        "last_modified_date": "2017-09-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.08475",
        "title": "Formal Guarantees on the Robustness of a Classifier against Adversarial Manipulation",
        "authors": [
            "Matthias Hein",
            "Maksym Andriushchenko"
        ],
        "abstract": "Recent work has shown that state-of-the-art classifiers are quite brittle, in the sense that a small adversarial change of an originally with high confidence correctly classified input leads to a wrong classification again with high confidence. This raises concerns that such classifiers are vulnerable to attacks and calls into question their usage in safety-critical systems. We show in this paper for the first time formal guarantees on the robustness of a classifier by giving instance-specific lower bounds on the norm of the input manipulation required to change the classifier decision. Based on this analysis we propose the Cross-Lipschitz regularization functional. We show that using this form of regularization in kernel methods resp. neural networks improves the robustness of the classifier without any loss in prediction performance.\n    ",
        "submission_date": "2017-05-23T00:00:00",
        "last_modified_date": "2017-11-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.08488",
        "title": "Second-Order Word Embeddings from Nearest Neighbor Topological Features",
        "authors": [
            "Denis Newman-Griffis",
            "Eric Fosler-Lussier"
        ],
        "abstract": "We introduce second-order vector representations of words, induced from nearest neighborhood topological features in pre-trained contextual word embeddings. We then analyze the effects of using second-order embeddings as input features in two deep natural language processing models, for named entity recognition and recognizing textual entailment, as well as a linear model for paraphrase recognition. Surprisingly, we find that nearest neighbor information alone is sufficient to capture most of the performance benefits derived from using pre-trained word embeddings. Furthermore, second-order embeddings are able to handle highly heterogeneous data better than first-order representations, though at the cost of some specificity. Additionally, augmenting contextual embeddings with second-order information further improves model performance in some cases. Due to variance in the random initializations of word embeddings, utilizing nearest neighbor features from multiple first-order embedding samples can also contribute to downstream performance gains. Finally, we identify intriguing characteristics of second-order embedding spaces for further research, including much higher density and different semantic interpretations of cosine similarity.\n    ",
        "submission_date": "2017-05-23T00:00:00",
        "last_modified_date": "2017-05-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.08500",
        "title": "Selective Classification for Deep Neural Networks",
        "authors": [
            "Yonatan Geifman",
            "Ran El-Yaniv"
        ],
        "abstract": "Selective classification techniques (also known as reject option) have not yet been considered in the context of deep neural networks (DNNs). These techniques can potentially significantly improve DNNs prediction performance by trading-off coverage. In this paper we propose a method to construct a selective classifier given a trained neural network. Our method allows a user to set a desired risk level. At test time, the classifier rejects instances as needed, to grant the desired risk (with high probability). Empirical results over CIFAR and ImageNet convincingly demonstrate the viability of our method, which opens up possibilities to operate DNNs in mission-critical applications. For example, using our method an unprecedented 2% error in top-5 ImageNet classification can be guaranteed with probability 99.9%, and almost 60% test coverage.\n    ",
        "submission_date": "2017-05-23T00:00:00",
        "last_modified_date": "2017-06-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.08508",
        "title": "Vehicle Traffic Driven Camera Placement for Better Metropolis Security Surveillance",
        "authors": [
            "Yihui He",
            "Xiaobo Ma",
            "Xiapu Luo",
            "Jianfeng Li",
            "Mengchen Zhao",
            "Bo An",
            "Xiaohong Guan"
        ],
        "abstract": "Security surveillance is one of the most important issues in smart cities, especially in an era of terrorism. Deploying a number of (video) cameras is a common surveillance approach. Given the never-ending power offered by vehicles to metropolises, exploiting vehicle traffic to design camera placement strategies could potentially facilitate security surveillance. This article constitutes the first effort toward building the linkage between vehicle traffic and security surveillance, which is a critical problem for smart cities. We expect our study could influence the decision making of surveillance camera placement, and foster more research of principled ways of security surveillance beneficial to our physical-world life. Code has been made publicly available.\n    ",
        "submission_date": "2017-04-01T00:00:00",
        "last_modified_date": "2018-08-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.08551",
        "title": "Safe Model-based Reinforcement Learning with Stability Guarantees",
        "authors": [
            "Felix Berkenkamp",
            "Matteo Turchetta",
            "Angela P. Schoellig",
            "Andreas Krause"
        ],
        "abstract": "Reinforcement learning is a powerful paradigm for learning optimal policies from experimental data. However, to find optimal policies, most reinforcement learning algorithms explore all possible actions, which may be harmful for real-world systems. As a consequence, learning algorithms are rarely applied on safety-critical systems in the real world. In this paper, we present a learning algorithm that explicitly considers safety, defined in terms of stability guarantees. Specifically, we extend control-theoretic results on Lyapunov stability verification and show how to use statistical models of the dynamics to obtain high-performance control policies with provable stability certificates. Moreover, under additional regularity assumptions in terms of a Gaussian process prior, we prove that one can effectively and safely collect data in order to learn about the dynamics and thus both improve control performance and expand the safe region of the state space. In our experiments, we show how the resulting algorithm can safely optimize a neural network policy on a simulated inverted pendulum, without the pendulum ever falling down.\n    ",
        "submission_date": "2017-05-23T00:00:00",
        "last_modified_date": "2017-11-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.08584",
        "title": "MMD GAN: Towards Deeper Understanding of Moment Matching Network",
        "authors": [
            "Chun-Liang Li",
            "Wei-Cheng Chang",
            "Yu Cheng",
            "Yiming Yang",
            "Barnab\u00e1s P\u00f3czos"
        ],
        "abstract": "Generative moment matching network (GMMN) is a deep generative model that differs from Generative Adversarial Network (GAN) by replacing the discriminator in GAN with a two-sample test based on kernel maximum mean discrepancy (MMD). Although some theoretical guarantees of MMD have been studied, the empirical performance of GMMN is still not as competitive as that of GAN on challenging and large benchmark datasets. The computational efficiency of GMMN is also less desirable in comparison with GAN, partially due to its requirement for a rather large batch size during the training. In this paper, we propose to improve both the model expressiveness of GMMN and its computational efficiency by introducing adversarial kernel learning techniques, as the replacement of a fixed Gaussian kernel in the original GMMN. The new approach combines the key ideas in both GMMN and GAN, hence we name it MMD GAN. The new distance measure in MMD GAN is a meaningful loss that enjoys the advantage of weak topology and can be optimized via gradient descent with relatively small batch sizes. In our evaluation on multiple benchmark datasets, including MNIST, CIFAR- 10, CelebA and LSUN, the performance of MMD-GAN significantly outperforms GMMN, and is competitive with other representative GAN works.\n    ",
        "submission_date": "2017-05-24T00:00:00",
        "last_modified_date": "2017-11-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.08804",
        "title": "Beyond Parity: Fairness Objectives for Collaborative Filtering",
        "authors": [
            "Sirui Yao",
            "Bert Huang"
        ],
        "abstract": "We study fairness in collaborative-filtering recommender systems, which are sensitive to discrimination that exists in historical data. Biased data can lead collaborative-filtering methods to make unfair predictions for users from minority groups. We identify the insufficiency of existing fairness metrics and propose four new metrics that address different forms of unfairness. These fairness metrics can be optimized by adding fairness terms to the learning objective. Experiments on synthetic and real data show that our new metrics can better measure fairness than the baseline, and that the fairness objectives effectively help reduce unfairness.\n    ",
        "submission_date": "2017-05-24T00:00:00",
        "last_modified_date": "2017-11-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.08850",
        "title": "Semi-supervised Learning with GANs: Manifold Invariance with Improved Inference",
        "authors": [
            "Abhishek Kumar",
            "Prasanna Sattigeri",
            "P. Thomas Fletcher"
        ],
        "abstract": "Semi-supervised learning methods using Generative Adversarial Networks (GANs) have shown promising empirical success recently. Most of these methods use a shared discriminator/classifier which discriminates real examples from fake while also predicting the class label. Motivated by the ability of the GANs generator to capture the data manifold well, we propose to estimate the tangent space to the data manifold using GANs and employ it to inject invariances into the classifier. In the process, we propose enhancements over existing methods for learning the inverse mapping (i.e., the encoder) which greatly improves in terms of semantic similarity of the reconstructed sample with the input sample. We observe considerable empirical gains in semi-supervised learning over baselines, particularly in the cases when the number of labeled examples is low. We also provide insights into how fake examples influence the semi-supervised learning procedure.\n    ",
        "submission_date": "2017-05-24T00:00:00",
        "last_modified_date": "2017-12-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.08868",
        "title": "Flow-GAN: Combining Maximum Likelihood and Adversarial Learning in Generative Models",
        "authors": [
            "Aditya Grover",
            "Manik Dhar",
            "Stefano Ermon"
        ],
        "abstract": "Adversarial learning of probabilistic models has recently emerged as a promising alternative to maximum likelihood. Implicit models such as generative adversarial networks (GAN) often generate better samples compared to explicit models trained by maximum likelihood. Yet, GANs sidestep the characterization of an explicit density which makes quantitative evaluations challenging. To bridge this gap, we propose Flow-GANs, a generative adversarial network for which we can perform exact likelihood evaluation, thus supporting both adversarial and maximum likelihood training. When trained adversarially, Flow-GANs generate high-quality samples but attain extremely poor log-likelihood scores, inferior even to a mixture model memorizing the training data; the opposite is true when trained by maximum likelihood. Results on MNIST and CIFAR-10 demonstrate that hybrid training can attain high held-out likelihoods while retaining visual fidelity in the generated samples.\n    ",
        "submission_date": "2017-05-24T00:00:00",
        "last_modified_date": "2018-01-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.08927",
        "title": "Compiling quantum circuits to realistic hardware architectures using temporal planners",
        "authors": [
            "Davide Venturelli",
            "Minh Do",
            "Eleanor Rieffel",
            "Jeremy Frank"
        ],
        "abstract": "To run quantum algorithms on emerging gate-model quantum hardware, quantum circuits must be compiled to take into account constraints on the hardware. For near-term hardware, with only limited means to mitigate decoherence, it is critical to minimize the duration of the circuit. We investigate the application of temporal planners to the problem of compiling quantum circuits to newly emerging quantum hardware. While our approach is general, we focus on compiling to superconducting hardware architectures with nearest neighbor constraints. Our initial experiments focus on compiling Quantum Alternating Operator Ansatz (QAOA) circuits whose high number of commuting gates allow great flexibility in the order in which the gates can be applied. That freedom makes it more challenging to find optimal compilations but also means there is a greater potential win from more optimized compilation than for less flexible circuits. We map this quantum circuit compilation problem to a temporal planning problem, and generated a test suite of compilation problems for QAOA circuits of various sizes to a realistic hardware architecture. We report compilation results from several state-of-the-art temporal planners on this test set. This early empirical evaluation demonstrates that temporal planning is a viable approach to quantum circuit compilation.\n    ",
        "submission_date": "2017-05-24T00:00:00",
        "last_modified_date": "2017-12-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.08982",
        "title": "Modeling The Intensity Function Of Point Process Via Recurrent Neural Networks",
        "authors": [
            "Shuai Xiao",
            "Junchi Yan",
            "Stephen M. Chu",
            "Xiaokang Yang",
            "Hongyuan Zha"
        ],
        "abstract": "Event sequence, asynchronously generated with random timestamp, is ubiquitous among applications. The precise and arbitrary timestamp can carry important clues about the underlying dynamics, and has lent the event data fundamentally different from the time-series whereby series is indexed with fixed and equal time interval. One expressive mathematical tool for modeling event is point process. The intensity functions of many point processes involve two components: the background and the effect by the history. Due to its inherent spontaneousness, the background can be treated as a time series while the other need to handle the history events. In this paper, we model the background by a Recurrent Neural Network (RNN) with its units aligned with time series indexes while the history effect is modeled by another RNN whose units are aligned with asynchronous events to capture the long-range dynamics. The whole model with event type and timestamp prediction output layers can be trained end-to-end. Our approach takes an RNN perspective to point process, and models its background and history effect. For utility, our method allows a black-box treatment for modeling the intensity which is often a pre-defined parametric form in point processes. Meanwhile end-to-end training opens the venue for reusing existing rich techniques in deep network for point process modeling. We apply our model to the predictive maintenance problem using a log dataset by more than 1000 ATMs from a global bank headquartered in North America.\n    ",
        "submission_date": "2017-05-24T00:00:00",
        "last_modified_date": "2017-05-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.09011",
        "title": "Principled Hybrids of Generative and Discriminative Domain Adaptation",
        "authors": [
            "Han Zhao",
            "Zhenyao Zhu",
            "Junjie Hu",
            "Adam Coates",
            "Geoff Gordon"
        ],
        "abstract": "We propose a probabilistic framework for domain adaptation that blends both generative and discriminative modeling in a principled way. Under this framework, generative and discriminative models correspond to specific choices of the prior over parameters. This provides us a very general way to interpolate between generative and discriminative extremes through different choices of priors. By maximizing both the marginal and the conditional log-likelihoods, models derived from this framework can use both labeled instances from the source domain as well as unlabeled instances from both source and target domains. Under this framework, we show that the popular reconstruction loss of autoencoder corresponds to an upper bound of the negative marginal log-likelihoods of unlabeled instances, where marginal distributions are given by proper kernel density estimations. This provides a way to interpret the empirical success of autoencoders in domain adaptation and semi-supervised learning. We instantiate our framework using neural networks, and build a concrete model, DAuto. Empirically, we demonstrate the effectiveness of DAuto on text, image and speech datasets, showing that it outperforms related competitors when domain adaptation is possible.\n    ",
        "submission_date": "2017-05-25T00:00:00",
        "last_modified_date": "2017-10-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.09026",
        "title": "Best-Choice Edge Grafting for Efficient Structure Learning of Markov Random Fields",
        "authors": [
            "Walid Chaabene",
            "Bert Huang"
        ],
        "abstract": "Incremental methods for structure learning of pairwise Markov random fields (MRFs), such as grafting, improve scalability by avoiding inference over the entire feature space in each optimization step. Instead, inference is performed over an incrementally grown active set of features. In this paper, we address key computational bottlenecks that current incremental techniques still suffer by introducing best-choice edge grafting, an incremental, structured method that activates edges as groups of features in a streaming setting. The method uses a reservoir of edges that satisfy an activation condition, approximating the search for the optimal edge to activate. It also reorganizes the search space using search-history and structure heuristics. Experiments show a significant speedup for structure learning and a controllable trade-off between the speed and quality of learning.\n    ",
        "submission_date": "2017-05-25T00:00:00",
        "last_modified_date": "2018-05-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.09207",
        "title": "Learning Structured Text Representations",
        "authors": [
            "Yang Liu",
            "Mirella Lapata"
        ],
        "abstract": "In this paper, we focus on learning structure-aware document representations from data without recourse to a discourse parser or additional annotations. Drawing inspiration from recent efforts to empower neural networks with a structural bias, we propose a model that can encode a document while automatically inducing rich structural dependencies. Specifically, we embed a differentiable non-projective parsing algorithm into a neural model and use attention mechanisms to incorporate the structural biases. Experimental evaluation across different tasks and datasets shows that the proposed model achieves state-of-the-art results on document modeling tasks while inducing intermediate structures which are both interpretable and meaningful.\n    ",
        "submission_date": "2017-05-25T00:00:00",
        "last_modified_date": "2018-02-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.09279",
        "title": "Filtering Variational Objectives",
        "authors": [
            "Chris J. Maddison",
            "Dieterich Lawson",
            "George Tucker",
            "Nicolas Heess",
            "Mohammad Norouzi",
            "Andriy Mnih",
            "Arnaud Doucet",
            "Yee Whye Teh"
        ],
        "abstract": "When used as a surrogate objective for maximum likelihood estimation in latent variable models, the evidence lower bound (ELBO) produces state-of-the-art results. Inspired by this, we consider the extension of the ELBO to a family of lower bounds defined by a particle filter's estimator of the marginal likelihood, the filtering variational objectives (FIVOs). FIVOs take the same arguments as the ELBO, but can exploit a model's sequential structure to form tighter bounds. We present results that relate the tightness of FIVO's bound to the variance of the particle filter's estimator by considering the generic case of bounds defined as log-transformed likelihood estimators. Experimentally, we show that training with FIVO results in substantial improvements over training the same model architecture with the ELBO on sequential data.\n    ",
        "submission_date": "2017-05-25T00:00:00",
        "last_modified_date": "2017-11-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.09328",
        "title": "Operation Frames and Clubs in Kidney Exchange",
        "authors": [
            "Gabriele Farina",
            "John P. Dickerson",
            "Tuomas Sandholm"
        ],
        "abstract": "A kidney exchange is a centrally-administered barter market where patients swap their willing yet incompatible donors. Modern kidney exchanges use 2-cycles, 3-cycles, and chains initiated by non-directed donors (altruists who are willing to give a kidney to anyone) as the means for swapping.\n",
        "submission_date": "2017-05-25T00:00:00",
        "last_modified_date": "2017-05-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.09359",
        "title": "Generating Time-Based Label Refinements to Discover More Precise Process Models",
        "authors": [
            "Niek Tax",
            "Emin Alasgarov",
            "Natalia Sidorova",
            "Wil M.P. van der Aalst",
            "Reinder Haakma"
        ],
        "abstract": "Process mining is a research field focused on the analysis of event data with the aim of extracting insights related to dynamic behavior. Applying process mining techniques on data from smart home environments has the potential to provide valuable insights in (un)healthy habits and to contribute to ambient assisted living solutions. Finding the right event labels to enable the application of process mining techniques is however far from trivial, as simply using the triggering sensor as the label for sensor events results in uninformative models that allow for too much behavior (overgeneralizing). Refinements of sensor level event labels suggested by domain experts have been shown to enable discovery of more precise and insightful process models. However, there exists no automated approach to generate refinements of event labels in the context of process mining. In this paper we propose a framework for the automated generation of label refinements based on the time attribute of events, allowing us to distinguish behaviourally different instances of the same event type based on their time attribute. We show on a case study with real life smart home event data that using automatically generated refined labels in process discovery, we can find more specific, and therefore more insightful, process models. We observe that one label refinement could have an effect on the usefulness of other label refinements when used together. Therefore, we explore four strategies to generate useful combinations of multiple label refinements and evaluate those on three real life smart home event logs.\n    ",
        "submission_date": "2017-05-25T00:00:00",
        "last_modified_date": "2017-10-31T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.09382",
        "title": "Distributed Robust Subspace Recovery",
        "authors": [
            "Vahan Huroyan",
            "Gilad Lerman"
        ],
        "abstract": "We propose distributed solutions to the problem of Robust Subspace Recovery (RSR). Our setting assumes a huge dataset in an ad hoc network without a central processor, where each node has access only to one chunk of the dataset. Furthermore, part of the whole dataset lies around a low-dimensional subspace and the other part is composed of outliers that lie away from that subspace. The goal is to recover the underlying subspace for the whole dataset, without transferring the data itself between the nodes. We first apply the Consensus-Based Gradient method to the Geometric Median Subspace algorithm for RSR. For this purpose, we propose an iterative solution for the local dual minimization problem and establish its r-linear convergence. We then explain how to distributedly implement the Reaper and Fast Median Subspace algorithms for RSR. The proposed algorithms display competitive performance on both synthetic and real data.\n    ",
        "submission_date": "2017-05-25T00:00:00",
        "last_modified_date": "2018-07-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.09391",
        "title": "Discovering Reliable Approximate Functional Dependencies",
        "authors": [
            "Panagiotis Mandros",
            "Mario Boley",
            "Jilles Vreeken"
        ],
        "abstract": "Given a database and a target attribute of interest, how can we tell whether there exists a functional, or approximately functional dependence of the target on any set of other attributes in the data? How can we reliably, without bias to sample size or dimensionality, measure the strength of such a dependence? And, how can we efficiently discover the optimal or $\\alpha$-approximate top-$k$ dependencies? These are exactly the questions we answer in this paper.\n",
        "submission_date": "2017-05-25T00:00:00",
        "last_modified_date": "2017-06-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.09436",
        "title": "Human Trajectory Prediction using Spatially aware Deep Attention Models",
        "authors": [
            "Daksh Varshneya",
            "G. Srinivasaraghavan"
        ],
        "abstract": "Trajectory Prediction of dynamic objects is a widely studied topic in the field of artificial intelligence. Thanks to a large number of applications like predicting abnormal events, navigation system for the blind, etc. there have been many approaches to attempt learning patterns of motion directly from data using a wide variety of techniques ranging from hand-crafted features to sophisticated deep learning models for unsupervised feature learning. All these approaches have been limited by problems like inefficient features in the case of hand crafted features, large error propagation across the predicted trajectory and no information of static artefacts around the dynamic moving objects. We propose an end to end deep learning model to learn the motion patterns of humans using different navigational modes directly from data using the much popular sequence to sequence model coupled with a soft attention mechanism. We also propose a novel approach to model the static artefacts in a scene and using these to predict the dynamic trajectories. The proposed method, tested on trajectories of pedestrians, consistently outperforms previously proposed state of the art approaches on a variety of large scale data sets. We also show how our architecture can be naturally extended to handle multiple modes of movement (say pedestrians, skaters, bikers and buses) simultaneously.\n    ",
        "submission_date": "2017-05-26T00:00:00",
        "last_modified_date": "2017-05-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.09515",
        "title": "ASR error management for improving spoken language understanding",
        "authors": [
            "Edwin Simonnet",
            "Sahar Ghannay",
            "Nathalie Camelin",
            "Yannick Est\u00e8ve",
            "Renato De Mori"
        ],
        "abstract": "This paper addresses the problem of automatic speech recognition (ASR) error detection and their use for improving spoken language understanding (SLU) systems. In this study, the SLU task consists in automatically extracting, from ASR transcriptions , semantic concepts and concept/values pairs in a e.g touristic information system. An approach is proposed for enriching the set of semantic labels with error specific labels and by using a recently proposed neural approach based on word embeddings to compute well calibrated ASR confidence measures. Experimental results are reported showing that it is possible to decrease significantly the Concept/Value Error Rate with a state of the art system, outperforming previously published results performance on the same experimental data. It also shown that combining an SLU approach based on conditional random fields with a neural encoder/decoder attention based architecture , it is possible to effectively identifying confidence islands and uncertain semantic output segments useful for deciding appropriate error handling actions by the dialogue manager strategy .\n    ",
        "submission_date": "2017-05-26T00:00:00",
        "last_modified_date": "2017-05-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.09552",
        "title": "Classification regions of deep neural networks",
        "authors": [
            "Alhussein Fawzi",
            "Seyed-Mohsen Moosavi-Dezfooli",
            "Pascal Frossard",
            "Stefano Soatto"
        ],
        "abstract": "The goal of this paper is to analyze the geometric properties of deep neural network classifiers in the input space. We specifically study the topology of classification regions created by deep networks, as well as their associated decision boundary. Through a systematic empirical investigation, we show that state-of-the-art deep nets learn connected classification regions, and that the decision boundary in the vicinity of datapoints is flat along most directions. We further draw an essential connection between two seemingly unrelated properties of deep networks: their sensitivity to additive perturbations in the inputs, and the curvature of their decision boundary. The directions where the decision boundary is curved in fact remarkably characterize the directions to which the classifier is the most vulnerable. We finally leverage a fundamental asymmetry in the curvature of the decision boundary of deep nets, and propose a method to discriminate between original images, and images perturbed with small adversarial examples. We show the effectiveness of this purely geometric approach for detecting small adversarial perturbations in images, and for recovering the labels of perturbed images.\n    ",
        "submission_date": "2017-05-26T00:00:00",
        "last_modified_date": "2017-05-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.09554",
        "title": "Robustness of classifiers to universal perturbations: a geometric perspective",
        "authors": [
            "Seyed-Mohsen Moosavi-Dezfooli",
            "Alhussein Fawzi",
            "Omar Fawzi",
            "Pascal Frossard",
            "Stefano Soatto"
        ],
        "abstract": "Deep networks have recently been shown to be vulnerable to universal perturbations: there exist very small image-agnostic perturbations that cause most natural images to be misclassified by such classifiers. In this paper, we propose the first quantitative analysis of the robustness of classifiers to universal perturbations, and draw a formal link between the robustness to universal perturbations, and the geometry of the decision boundary. Specifically, we establish theoretical bounds on the robustness of classifiers under two decision boundary models (flat and curved models). We show in particular that the robustness of deep networks to universal perturbations is driven by a key property of their curvature: there exists shared directions along which the decision boundary of deep networks is systematically positively curved. Under such conditions, we prove the existence of small universal perturbations. Our analysis further provides a novel geometric method for computing universal perturbations, in addition to explaining their properties.\n    ",
        "submission_date": "2017-05-26T00:00:00",
        "last_modified_date": "2021-03-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.09558",
        "title": "Bayesian GAN",
        "authors": [
            "Yunus Saatchi",
            "Andrew Gordon Wilson"
        ],
        "abstract": "Generative adversarial networks (GANs) can implicitly learn rich distributions over images, audio, and data which are hard to model with an explicit likelihood. We present a practical Bayesian formulation for unsupervised and semi-supervised learning with GANs. Within this framework, we use stochastic gradient Hamiltonian Monte Carlo to marginalize the weights of the generator and discriminator networks. The resulting approach is straightforward and obtains good performance without any standard interventions such as feature matching, or mini-batch discrimination. By exploring an expressive posterior over the parameters of the generator, the Bayesian GAN avoids mode-collapse, produces interpretable and diverse candidate samples, and provides state-of-the-art quantitative results for semi-supervised learning on benchmarks including SVHN, CelebA, and CIFAR-10, outperforming DCGAN, Wasserstein GANs, and DCGAN ensembles.\n    ",
        "submission_date": "2017-05-26T00:00:00",
        "last_modified_date": "2017-11-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.09580",
        "title": "Risk-Sensitive Cooperative Games for Human-Machine Systems",
        "authors": [
            "Agostino Capponi",
            "Reza Ghanadan",
            "Matt Stern"
        ],
        "abstract": "Autonomous systems can substantially enhance a human's efficiency and effectiveness in complex environments. Machines, however, are often unable to observe the preferences of the humans that they serve. Despite the fact that the human's and machine's objectives are aligned, asymmetric information, along with heterogeneous sensitivities to risk by the human and machine, make their joint optimization process a game with strategic interactions. We propose a framework based on risk-sensitive dynamic games; the human seeks to optimize her risk-sensitive criterion according to her true preferences, while the machine seeks to adaptively learn the human's preferences and at the same time provide a good service to the human. We develop a class of performance measures for the proposed framework based on the concept of regret. We then evaluate their dependence on the risk-sensitivity and the degree of uncertainty. We present applications of our framework to self-driving taxis, and robo-financial advising.\n    ",
        "submission_date": "2017-05-26T00:00:00",
        "last_modified_date": "2017-05-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.09644",
        "title": "Learning Causal Structures Using Regression Invariance",
        "authors": [
            "AmirEmad Ghassami",
            "Saber Salehkaleybar",
            "Negar Kiyavash",
            "Kun Zhang"
        ],
        "abstract": "We study causal inference in a multi-environment setting, in which the functional relations for producing the variables from their direct causes remain the same across environments, while the distribution of exogenous noises may vary. We introduce the idea of using the invariance of the functional relations of the variables to their causes across a set of environments. We define a notion of completeness for a causal inference algorithm in this setting and prove the existence of such algorithm by proposing the baseline algorithm. Additionally, we present an alternate algorithm that has significantly improved computational and sample complexity compared to the baseline algorithm. The experiment results show that the proposed algorithm outperforms the other existing algorithms.\n    ",
        "submission_date": "2017-05-26T00:00:00",
        "last_modified_date": "2017-05-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.09650",
        "title": "Anomaly Detection in a Digital Video Broadcasting System Using Timed Automata",
        "authors": [
            "Xiaoran Liu",
            "Qin Lin",
            "Sicco Verwer",
            "Dmitri Jarnikov"
        ],
        "abstract": "This paper focuses on detecting anomalies in a digital video broadcasting (DVB) system from providers' perspective. We learn a probabilistic deterministic real timed automaton profiling benign behavior of encryption control in the DVB control access system. This profile is used as a one-class classifier. Anomalous items in a testing sequence are detected when the sequence is not accepted by the learned model.\n    ",
        "submission_date": "2017-05-24T00:00:00",
        "last_modified_date": "2017-05-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.09684",
        "title": "Multiple Source Domain Adaptation with Adversarial Training of Neural Networks",
        "authors": [
            "Han Zhao",
            "Shanghang Zhang",
            "Guanhang Wu",
            "Jo\u00e3o P. Costeira",
            "Jos\u00e9 M. F. Moura",
            "Geoffrey J. Gordon"
        ],
        "abstract": "While domain adaptation has been actively researched in recent years, most theoretical results and algorithms focus on the single-source-single-target adaptation setting. Naive application of such algorithms on multiple source domain adaptation problem may lead to suboptimal solutions. As a step toward bridging the gap, we propose a new generalization bound for domain adaptation when there are multiple source domains with labeled instances and one target domain with unlabeled instances. Compared with existing bounds, the new bound does not require expert knowledge about the target distribution, nor the optimal combination rule for multisource domains. Interestingly, our theory also leads to an efficient learning strategy using adversarial neural networks: we show how to interpret it as learning feature representations that are invariant to the multiple domain shifts while still being discriminative for the learning task. To this end, we propose two models, both of which we call multisource domain adversarial networks (MDANs): the first model optimizes directly our bound, while the second model is a smoothed approximation of the first one, leading to a more data-efficient and task-adaptive model. The optimization tasks of both models are minimax saddle point problems that can be optimized by adversarial training. To demonstrate the effectiveness of MDANs, we conduct extensive experiments showing superior adaptation performance on three real-world datasets: sentiment analysis, digit classification, and vehicle counting.\n    ",
        "submission_date": "2017-05-26T00:00:00",
        "last_modified_date": "2017-10-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.09783",
        "title": "Good Semi-supervised Learning that Requires a Bad GAN",
        "authors": [
            "Zihang Dai",
            "Zhilin Yang",
            "Fan Yang",
            "William W. Cohen",
            "Ruslan Salakhutdinov"
        ],
        "abstract": "Semi-supervised learning methods based on generative adversarial networks (GANs) obtained strong empirical results, but it is not clear 1) how the discriminator benefits from joint training with a generator, and 2) why good semi-supervised classification performance and a good generator cannot be obtained at the same time. Theoretically, we show that given the discriminator objective, good semisupervised learning indeed requires a bad generator, and propose the definition of a preferred generator. Empirically, we derive a novel formulation based on our analysis that substantially improves over feature matching GANs, obtaining state-of-the-art results on multiple benchmark datasets.\n    ",
        "submission_date": "2017-05-27T00:00:00",
        "last_modified_date": "2017-11-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.09786",
        "title": "AMPNet: Asynchronous Model-Parallel Training for Dynamic Neural Networks",
        "authors": [
            "Alexander L. Gaunt",
            "Matthew A. Johnson",
            "Maik Riechert",
            "Daniel Tarlow",
            "Ryota Tomioka",
            "Dimitrios Vytiniotis",
            "Sam Webster"
        ],
        "abstract": "New types of machine learning hardware in development and entering the market hold the promise of revolutionizing deep learning in a manner as profound as GPUs. However, existing software frameworks and training algorithms for deep learning have yet to evolve to fully leverage the capability of the new wave of silicon. We already see the limitations of existing algorithms for models that exploit structured input via complex and instance-dependent control flow, which prohibits minibatching. We present an asynchronous model-parallel (AMP) training algorithm that is specifically motivated by training on networks of interconnected devices. Through an implementation on multi-core CPUs, we show that AMP training converges to the same accuracy as conventional synchronous training algorithms in a similar number of epochs, but utilizes the available hardware more efficiently even for small minibatch sizes, resulting in significantly shorter overall training times. Our framework opens the door for scaling up a new class of deep learning models that cannot be efficiently trained today.\n    ",
        "submission_date": "2017-05-27T00:00:00",
        "last_modified_date": "2017-06-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.10092",
        "title": "Role Playing Learning for Socially Concomitant Mobile Robot Navigation",
        "authors": [
            "Mingming Li",
            "Rui Jiang",
            "Shuzhi Sam Ge",
            "Tong Heng Lee"
        ],
        "abstract": "In this paper, we present the Role Playing Learning (RPL) scheme for a mobile robot to navigate socially with its human companion in populated environments. Neural networks (NN) are constructed to parameterize a stochastic policy that directly maps sensory data collected by the robot to its velocity outputs, while respecting a set of social norms. An efficient simulative learning environment is built with maps and pedestrians trajectories collected from a number of real-world crowd data sets. In each learning iteration, a robot equipped with the NN policy is created virtually in the learning environment to play itself as a companied pedestrian and navigate towards a goal in a socially concomitant manner. Thus, we call this process Role Playing Learning, which is formulated under a reinforcement learning (RL) framework. The NN policy is optimized end-to-end using Trust Region Policy Optimization (TRPO), with consideration of the imperfectness of robot's sensor measurements. Simulative and experimental results are provided to demonstrate the efficacy and superiority of our method.\n    ",
        "submission_date": "2017-05-29T00:00:00",
        "last_modified_date": "2017-05-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.10119",
        "title": "Kernel Implicit Variational Inference",
        "authors": [
            "Jiaxin Shi",
            "Shengyang Sun",
            "Jun Zhu"
        ],
        "abstract": "Recent progress in variational inference has paid much attention to the flexibility of variational posteriors. One promising direction is to use implicit distributions, i.e., distributions without tractable densities as the variational posterior. However, existing methods on implicit posteriors still face challenges of noisy estimation and computational infeasibility when applied to models with high-dimensional latent variables. In this paper, we present a new approach named Kernel Implicit Variational Inference that addresses these challenges. As far as we know, for the first time implicit variational inference is successfully applied to Bayesian neural networks, which shows promising results on both regression and classification tasks.\n    ",
        "submission_date": "2017-05-29T00:00:00",
        "last_modified_date": "2018-02-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.10202",
        "title": "Mining Process Model Descriptions of Daily Life through Event Abstraction",
        "authors": [
            "Niek Tax",
            "Natalia Sidorova",
            "Reinder Haakma",
            "Wil M.P. van der Aalst"
        ],
        "abstract": "Process mining techniques focus on extracting insight in processes from event logs. Process mining has the potential to provide valuable insights in (un)healthy habits and to contribute to ambient assisted living solutions when applied on data from smart home environments. However, events recorded in smart home environments are on the level of sensor triggers, at which process discovery algorithms produce overgeneralizing process models that allow for too much behavior and that are difficult to interpret for human experts. We show that abstracting the events to a higher-level interpretation can enable discovery of more precise and more comprehensible models. We present a framework for the extraction of features that can be used for abstraction with supervised learning methods that is based on the XES IEEE standard for event logs. This framework can automatically abstract sensor-level events to their interpretation at the human activity level, after training it on training data for which both the sensor and human activity events are known. We demonstrate our abstraction framework on three real-life smart home event logs and show that the process models that can be discovered after abstraction are more precise indeed.\n    ",
        "submission_date": "2017-05-25T00:00:00",
        "last_modified_date": "2017-05-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.10279",
        "title": "Towards Visual Ego-motion Learning in Robots",
        "authors": [
            "Sudeep Pillai",
            "John J. Leonard"
        ],
        "abstract": "Many model-based Visual Odometry (VO) algorithms have been proposed in the past decade, often restricted to the type of camera optics, or the underlying motion manifold observed. We envision robots to be able to learn and perform these tasks, in a minimally supervised setting, as they gain more experience. To this end, we propose a fully trainable solution to visual ego-motion estimation for varied camera optics. We propose a visual ego-motion learning architecture that maps observed optical flow vectors to an ego-motion density estimate via a Mixture Density Network (MDN). By modeling the architecture as a Conditional Variational Autoencoder (C-VAE), our model is able to provide introspective reasoning and prediction for ego-motion induced scene-flow. Additionally, our proposed model is especially amenable to bootstrapped ego-motion learning in robots where the supervision in ego-motion estimation for a particular camera sensor can be obtained from standard navigation-based sensor fusion strategies (GPS/INS and wheel-odometry fusion). Through experiments, we show the utility of our proposed approach in enabling the concept of self-supervised learning for visual ego-motion estimation in autonomous robots.\n    ",
        "submission_date": "2017-05-29T00:00:00",
        "last_modified_date": "2017-05-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.10301",
        "title": "Contextual Explanation Networks",
        "authors": [
            "Maruan Al-Shedivat",
            "Avinava Dubey",
            "Eric P. Xing"
        ],
        "abstract": "Modern learning algorithms excel at producing accurate but complex models of the data. However, deploying such models in the real-world requires extra care: we must ensure their reliability, robustness, and absence of undesired biases. This motivates the development of models that are equally accurate but can be also easily inspected and assessed beyond their predictive performance. To this end, we introduce contextual explanation networks (CEN)---a class of architectures that learn to predict by generating and utilizing intermediate, simplified probabilistic models. Specifically, CENs generate parameters for intermediate graphical models which are further used for prediction and play the role of explanations. Contrary to the existing post-hoc model-explanation tools, CENs learn to predict and to explain simultaneously. Our approach offers two major advantages: (i) for each prediction valid, instance-specific explanation is generated with no computational overhead and (ii) prediction via explanation acts as a regularizer and boosts performance in data-scarce settings. We analyze the proposed framework theoretically and experimentally. Our results on image and text classification and survival analysis tasks demonstrate that CENs are not only competitive with the state-of-the-art methods but also offer additional insights behind each prediction, that can be valuable for decision support. We also show that while post-hoc methods may produce misleading explanations in certain cases, CENs are consistent and allow to detect such cases systematically.\n    ",
        "submission_date": "2017-05-29T00:00:00",
        "last_modified_date": "2020-09-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.10422",
        "title": "Learning End-to-end Multimodal Sensor Policies for Autonomous Navigation",
        "authors": [
            "Guan-Horng Liu",
            "Avinash Siravuru",
            "Sai Prabhakar",
            "Manuela Veloso",
            "George Kantor"
        ],
        "abstract": "Multisensory polices are known to enhance both state estimation and target tracking. However, in the space of end-to-end sensorimotor control, this multi-sensor outlook has received limited attention. Moreover, systematic ways to make policies robust to partial sensor failure are not well explored. In this work, we propose a specific customization of Dropout, called \\textit{Sensor Dropout}, to improve multisensory policy robustness and handle partial failure in the sensor-set. We also introduce an additional auxiliary loss on the policy network in order to reduce variance in the band of potential multi- and uni-sensory policies to reduce jerks during policy switching triggered by an abrupt sensor failure or deactivation/activation. Finally, through the visualization of gradients, we show that the learned policies are conditioned on the same latent states representation despite having diverse observations spaces - a hallmark of true sensor-fusion. Simulation results of the multisensory policy, as visualized in TORCS racing game, can be seen here: ",
        "submission_date": "2017-05-30T00:00:00",
        "last_modified_date": "2017-11-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.10480",
        "title": "Preliminary results on Ontology-based Open Data Publishing",
        "authors": [
            "Gianluca Cima"
        ],
        "abstract": "Despite the current interest in Open Data publishing, a formal and comprehensive methodology supporting an organization in deciding which data to publish and carrying out precise procedures for publishing high-quality data, is still missing. In this paper we argue that the Ontology-based Data Management paradigm can provide a formal basis for a principled approach to publish high quality, semantically annotated Open Data. We describe two main approaches to using an ontology for this endeavor, and then we present some technical results on one of the approaches, called bottom-up, where the specification of the data to be published is given in terms of the sources, and specific techniques allow deriving suitable annotations for interpreting the published data under the light of the ontology.\n    ",
        "submission_date": "2017-05-30T00:00:00",
        "last_modified_date": "2017-07-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.10694",
        "title": "Deep Learning is Robust to Massive Label Noise",
        "authors": [
            "David Rolnick",
            "Andreas Veit",
            "Serge Belongie",
            "Nir Shavit"
        ],
        "abstract": "Deep neural networks trained on large supervised datasets have led to impressive results in image classification and other tasks. However, well-annotated datasets can be time-consuming and expensive to collect, lending increased interest to larger but noisy datasets that are more easily obtained. In this paper, we show that deep neural networks are capable of generalizing from training data for which true labels are massively outnumbered by incorrect labels. We demonstrate remarkably high test performance after training on corrupted data from MNIST, CIFAR, and ImageNet. For example, on MNIST we obtain test accuracy above 90 percent even after each clean training example has been diluted with 100 randomly-labeled examples. Such behavior holds across multiple patterns of label noise, even when erroneous labels are biased towards confusing classes. We show that training in this regime requires a significant but manageable increase in dataset size that is related to the factor by which correct labels have been diluted. Finally, we provide an analysis of our results that shows how increasing noise decreases the effective batch size.\n    ",
        "submission_date": "2017-05-30T00:00:00",
        "last_modified_date": "2018-02-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.10744",
        "title": "Knowledge Base Completion: Baselines Strike Back",
        "authors": [
            "Rudolf Kadlec",
            "Ondrej Bajgar",
            "Jan Kleindienst"
        ],
        "abstract": "Many papers have been published on the knowledge base completion task in the past few years. Most of these introduce novel architectures for relation learning that are evaluated on standard datasets such as FB15k and WN18. This paper shows that the accuracy of almost all models published on the FB15k can be outperformed by an appropriately tuned baseline - our reimplementation of the DistMult model. Our findings cast doubt on the claim that the performance improvements of recent models are due to architectural changes as opposed to hyper-parameter tuning or different training objectives. This should prompt future research to re-consider how the performance of models is evaluated and reported.\n    ",
        "submission_date": "2017-05-30T00:00:00",
        "last_modified_date": "2017-05-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.10786",
        "title": "Semi-Supervised Learning for Detecting Human Trafficking",
        "authors": [
            "Hamidreza Alvari",
            "Paulo Shakarian",
            "J.E. Kelly Snyder"
        ],
        "abstract": "Human trafficking is one of the most atrocious crimes and among the challenging problems facing law enforcement which demands attention of global magnitude. In this study, we leverage textual data from the website \"Backpage\"- used for classified advertisement- to discern potential patterns of human trafficking activities which manifest online and identify advertisements of high interest to law enforcement. Due to the lack of ground truth, we rely on a human analyst from law enforcement, for hand-labeling a small portion of the crawled data. We extend the existing Laplacian SVM and present S3VM-R, by adding a regularization term to exploit exogenous information embedded in our feature space in favor of the task at hand. We train the proposed method using labeled and unlabeled data and evaluate it on a fraction of the unlabeled data, herein referred to as unseen data, with our expert's further verification. Results from comparisons between our method and other semi-supervised and supervised approaches on the labeled data demonstrate that our learner is effective in identifying advertisements of high interest to law enforcement\n    ",
        "submission_date": "2017-05-30T00:00:00",
        "last_modified_date": "2017-05-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.10882",
        "title": "Morphological Error Detection in 3D Segmentations",
        "authors": [
            "David Rolnick",
            "Yaron Meirovitch",
            "Toufiq Parag",
            "Hanspeter Pfister",
            "Viren Jain",
            "Jeff W. Lichtman",
            "Edward S. Boyden",
            "Nir Shavit"
        ],
        "abstract": "Deep learning algorithms for connectomics rely upon localized classification, rather than overall morphology. This leads to a high incidence of erroneously merged objects. Humans, by contrast, can easily detect such errors by acquiring intuition for the correct morphology of objects. Biological neurons have complicated and variable shapes, which are challenging to learn, and merge errors take a multitude of different forms. We present an algorithm, MergeNet, that shows 3D ConvNets can, in fact, detect merge errors from high-level neuronal morphology. MergeNet follows unsupervised training and operates across datasets. We demonstrate the performance of MergeNet both on a variety of connectomics data and on a dataset created from merged MNIST images.\n    ",
        "submission_date": "2017-05-30T00:00:00",
        "last_modified_date": "2017-05-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.10915",
        "title": "Unsupervised Learning of Disentangled Representations from Video",
        "authors": [
            "Remi Denton",
            "Vighnesh Birodkar"
        ],
        "abstract": "  We present a new model DrNET that learns disentangled image representations from video. Our approach leverages the temporal coherence of video and a novel adversarial loss to learn a representation that factorizes each frame into a stationary part and a temporally varying component. The disentangled representation can be used for a range of tasks. For example, applying a standard LSTM to the time-vary components enables prediction of future frames. We evaluate our approach on a range of synthetic and real videos, demonstrating the ability to coherently generate hundreds of steps into the future.\n    ",
        "submission_date": "2017-05-31T00:00:00",
        "last_modified_date": "2017-05-31T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.10929",
        "title": "Adversarial Generation of Natural Language",
        "authors": [
            "Sai Rajeswar",
            "Sandeep Subramanian",
            "Francis Dutil",
            "Christopher Pal",
            "Aaron Courville"
        ],
        "abstract": "Generative Adversarial Networks (GANs) have gathered a lot of attention from the computer vision community, yielding impressive results for image generation. Advances in the adversarial generation of natural language from noise however are not commensurate with the progress made in generating images, and still lag far behind likelihood based methods. In this paper, we take a step towards generating natural language with a GAN objective alone. We introduce a simple baseline that addresses the discrete output space problem without relying on gradient estimators and show that it is able to achieve state-of-the-art results on a Chinese poem generation dataset. We present quantitative results on generating sentences from context-free and probabilistic context-free grammars, and qualitative language modeling results. A conditional version is also described that can generate sequences conditioned on sentence characteristics.\n    ",
        "submission_date": "2017-05-31T00:00:00",
        "last_modified_date": "2017-05-31T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.10993",
        "title": "Non-Markovian Control with Gated End-to-End Memory Policy Networks",
        "authors": [
            "Julien Perez",
            "Tomi Silander"
        ],
        "abstract": "Partially observable environments present an important open challenge in the domain of sequential control learning with delayed rewards. Despite numerous attempts during the two last decades, the majority of reinforcement learning algorithms and associated approximate models, applied to this context, still assume Markovian state transitions. In this paper, we explore the use of a recently proposed attention-based model, the Gated End-to-End Memory Network, for sequential control. We call the resulting model the Gated End-to-End Memory Policy Network. More precisely, we use a model-free value-based algorithm to learn policies for partially observed domains using this memory-enhanced neural network. This model is end-to-end learnable and it features unbounded memory. Indeed, because of its attention mechanism and associated non-parametric memory, the proposed model allows us to define an attention mechanism over the observation stream unlike recurrent models. We show encouraging results that illustrate the capability of our attention-based model in the context of the continuous-state non-stationary control problem of stock trading. We also present an OpenAI Gym environment for simulated stock exchange and explain its relevance as a benchmark for the field of non-Markovian decision process learning.\n    ",
        "submission_date": "2017-05-31T00:00:00",
        "last_modified_date": "2017-05-31T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.11040",
        "title": "End-to-End Differentiable Proving",
        "authors": [
            "Tim Rockt\u00e4schel",
            "Sebastian Riedel"
        ],
        "abstract": "We introduce neural networks for end-to-end differentiable proving of queries to knowledge bases by operating on dense vector representations of symbols. These neural networks are constructed recursively by taking inspiration from the backward chaining algorithm as used in Prolog. Specifically, we replace symbolic unification with a differentiable computation on vector representations of symbols using a radial basis function kernel, thereby combining symbolic reasoning with learning subsymbolic vector representations. By using gradient descent, the resulting neural network can be trained to infer facts from a given incomplete knowledge base. It learns to (i) place representations of similar symbols in close proximity in a vector space, (ii) make use of such similarities to prove queries, (iii) induce logical rules, and (iv) use provided and induced logical rules for multi-hop reasoning. We demonstrate that this architecture outperforms ComplEx, a state-of-the-art neural link prediction model, on three out of four benchmark knowledge bases while at the same time inducing interpretable function-free first-order logic rules.\n    ",
        "submission_date": "2017-05-31T00:00:00",
        "last_modified_date": "2017-12-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.11122",
        "title": "Controllable Invariance through Adversarial Feature Learning",
        "authors": [
            "Qizhe Xie",
            "Zihang Dai",
            "Yulun Du",
            "Eduard Hovy",
            "Graham Neubig"
        ],
        "abstract": "Learning meaningful representations that maintain the content necessary for a particular task while filtering away detrimental variations is a problem of great interest in machine learning. In this paper, we tackle the problem of learning representations invariant to a specific factor or trait of data. The representation learning process is formulated as an adversarial minimax game. We analyze the optimal equilibrium of such a game and find that it amounts to maximizing the uncertainty of inferring the detrimental factor given the representation while maximizing the certainty of making task-specific predictions. On three benchmark tasks, namely fair and bias-free classification, language-independent generation, and lighting-independent image classification, we show that the proposed framework induces an invariant representation, and leads to better generalization evidenced by the improved performance.\n    ",
        "submission_date": "2017-05-31T00:00:00",
        "last_modified_date": "2018-01-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1705.11190",
        "title": "The Morphospace of Consciousness",
        "authors": [
            "Xerxes D. Arsiwalla",
            "Ricard Sole",
            "Clement Moulin-Frier",
            "Ivan Herreros",
            "Marti Sanchez-Fibla",
            "Paul Verschure"
        ],
        "abstract": "We construct a complexity-based morphospace to study systems-level properties of conscious & intelligent systems. The axes of this space label 3 complexity types: autonomous, cognitive & social. Given recent proposals to synthesize consciousness, a generic complexity-based conceptualization provides a useful framework for identifying defining features of conscious & synthetic systems. Based on current clinical scales of consciousness that measure cognitive awareness and wakefulness, we take a perspective on how contemporary artificially intelligent machines & synthetically engineered life forms measure on these scales. It turns out that awareness & wakefulness can be associated to computational & autonomous complexity respectively. Subsequently, building on insights from cognitive robotics, we examine the function that consciousness serves, & argue the role of consciousness as an evolutionary game-theoretic strategy. This makes the case for a third type of complexity for describing consciousness: social complexity. Having identified these complexity types, allows for a representation of both, biological & synthetic systems in a common morphospace. A consequence of this classification is a taxonomy of possible conscious machines. We identify four types of consciousness, based on embodiment: (i) biological consciousness, (ii) synthetic consciousness, (iii) group consciousness (resulting from group interactions), & (iv) simulated consciousness (embodied by virtual agents within a simulated reality). This taxonomy helps in the investigation of comparative signatures of consciousness across domains, in order to highlight design principles necessary to engineer conscious machines. This is particularly relevant in the light of recent developments at the crossroads of cognitive neuroscience, biomedical engineering, artificial intelligence & biomimetics.\n    ",
        "submission_date": "2017-05-31T00:00:00",
        "last_modified_date": "2018-11-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.00007",
        "title": "A Learning Based Optimal Human Robot Collaboration with Linear Temporal Logic Constraints",
        "authors": [
            "Bo Wu",
            "Bin Hu",
            "Hai Lin"
        ],
        "abstract": "This paper considers an optimal task allocation problem for human robot collaboration in human robot systems with persistent tasks. Such human robot systems consist of human operators and intelligent robots collaborating with each other to accomplish complex tasks that cannot be done by either part alone. The system objective is to maximize the probability of successfully executing persistent tasks that are formulated as linear temporal logic specifications and minimize the average cost between consecutive visits of a particular proposition. This paper proposes to model the human robot collaboration under a framework with the composition of multiple Markov Decision Process (MDP) with possibly unknown transition probabilities, which characterizes how human cognitive states, such as human trust and fatigue, stochastically change with the robot performance. Under the unknown MDP models, an algorithm is developed to learn the model and obtain an optimal task allocation policy that minimizes the expected average cost for each task cycle and maximizes the probability of satisfying linear temporal logic constraints. Moreover, this paper shows that the difference between the optimal policy based on the learned model and that based on the underlying ground truth model can be bounded by arbitrarily small constant and large confidence level with sufficient samples. The case study of an assembly process demonstrates the effectiveness and benefits of our proposed learning based human robot collaboration.\n    ",
        "submission_date": "2017-05-31T00:00:00",
        "last_modified_date": "2017-05-31T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.00061",
        "title": "The Sample Complexity of Online One-Class Collaborative Filtering",
        "authors": [
            "Reinhard Heckel",
            "Kannan Ramchandran"
        ],
        "abstract": "We consider the online one-class collaborative filtering (CF) problem that consists of recommending items to users over time in an online fashion based on positive ratings only. This problem arises when users respond only occasionally to a recommendation with a positive rating, and never with a negative one. We study the impact of the probability of a user responding to a recommendation, p_f, on the sample complexity, i.e., the number of ratings required to make `good' recommendations, and ask whether receiving positive and negative ratings, instead of positive ratings only, improves the sample complexity. Both questions arise in the design of recommender systems. We introduce a simple probabilistic user model, and analyze the performance of an online user-based CF algorithm. We prove that after an initial cold start phase, where recommendations are invested in exploring the user's preferences, this algorithm makes---up to a fraction of the recommendations required for updating the user's preferences---perfect recommendations. The number of ratings required for the cold start phase is nearly proportional to 1/p_f, and that for updating the user's preferences is essentially independent of p_f. As a consequence we find that, receiving positive and negative ratings instead of only positive ones improves the number of ratings required for initial exploration by a factor of 1/p_f, which can be significant.\n    ",
        "submission_date": "2017-05-31T00:00:00",
        "last_modified_date": "2017-05-31T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.00074",
        "title": "Free energy-based reinforcement learning using a quantum processor",
        "authors": [
            "Anna Levit",
            "Daniel Crawford",
            "Navid Ghadermarzy",
            "Jaspreet S. Oberoi",
            "Ehsan Zahedinejad",
            "Pooya Ronagh"
        ],
        "abstract": "Recent theoretical and experimental results suggest the possibility of using current and near-future quantum hardware in challenging sampling tasks. In this paper, we introduce free energy-based reinforcement learning (FERL) as an application of quantum hardware. We propose a method for processing a quantum annealer's measured qubit spin configurations in approximating the free energy of a quantum Boltzmann machine (QBM). We then apply this method to perform reinforcement learning on the grid-world problem using the D-Wave 2000Q quantum annealer. The experimental results show that our technique is a promising method for harnessing the power of quantum sampling in reinforcement learning tasks.\n    ",
        "submission_date": "2017-05-29T00:00:00",
        "last_modified_date": "2017-05-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.00130",
        "title": "Teaching Machines to Describe Images via Natural Language Feedback",
        "authors": [
            "Huan Ling",
            "Sanja Fidler"
        ],
        "abstract": "Robots will eventually be part of every household. It is thus critical to enable algorithms to learn from and be guided by non-expert users. In this paper, we bring a human in the loop, and enable a human teacher to give feedback to a learning agent in the form of natural language. We argue that a descriptive sentence can provide a much stronger learning signal than a numeric reward in that it can easily point to where the mistakes are and how to correct them. We focus on the problem of image captioning in which the quality of the output can easily be judged by non-experts. We propose a hierarchical phrase-based captioning model trained with policy gradients, and design a feedback network that provides reward to the learner by conditioning on the human-provided feedback. We show that by exploiting descriptive feedback our model learns to perform better than when given independently written human captions.\n    ",
        "submission_date": "2017-06-01T00:00:00",
        "last_modified_date": "2017-06-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.00327",
        "title": "One button machine for automating feature engineering in relational databases",
        "authors": [
            "Hoang Thanh Lam",
            "Johann-Michael Thiebaut",
            "Mathieu Sinn",
            "Bei Chen",
            "Tiep Mai",
            "Oznur Alkan"
        ],
        "abstract": "Feature engineering is one of the most important and time consuming tasks in predictive analytics projects. It involves understanding domain knowledge and data exploration to discover relevant hand-crafted features from raw data. In this paper, we introduce a system called One Button Machine, or OneBM for short, which automates feature discovery in relational databases. OneBM automatically performs a key activity of data scientists, namely, joining of database tables and applying advanced data transformations to extract useful features from data. We validated OneBM in Kaggle competitions in which OneBM achieved performance as good as top 16% to 24% data scientists in three Kaggle competitions. More importantly, OneBM outperformed the state-of-the-art system in a Kaggle competition in terms of prediction accuracy and ranking on Kaggle leaderboard. The results show that OneBM can be useful for both data scientists and non-experts. It helps data scientists reduce data exploration time allowing them to try and error many ideas in short time. On the other hand, it enables non-experts, who are not familiar with data science, to quickly extract value from their data with a little effort, time and cost.\n    ",
        "submission_date": "2017-06-01T00:00:00",
        "last_modified_date": "2017-06-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.00342",
        "title": "On the stable recovery of deep structured linear networks under sparsity constraints",
        "authors": [
            "Francois Malgouyres"
        ],
        "abstract": "We consider a deep structured linear network under sparsity constraints. We study sharp conditions guaranteeing the stability of the optimal parameters defining the network. More precisely, we provide sharp  conditions on the network architecture and the sample under which the error on the parameters defining the network  scales linearly with the reconstruction error (i.e. the risk). Therefore, under these conditions, the weights obtained with a successful algorithms are well defined and only depend on the architecture of the network and the sample. The features in the latent spaces are stably defined. The stability property is required in order to interpret the features defined in the latent spaces. It can also lead to a guarantee on the statistical risk. This is what motivates this study.    The analysis is based on the recently proposed Tensorial Lifting. The particularity of this paper is to consider a sparsity prior. This leads to a better stability constant. As an illustration, we detail the analysis and provide sharp stability guarantees for convolutional linear network under sparsity prior. In this analysis, we distinguish the role of the network architecture and the sample input. This  highlights the requirements on the data in connection to parameter stability.\n    ",
        "submission_date": "2017-05-31T00:00:00",
        "last_modified_date": "2020-05-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.00359",
        "title": "Discovering Discrete Latent Topics with Neural Variational Inference",
        "authors": [
            "Yishu Miao",
            "Edward Grefenstette",
            "Phil Blunsom"
        ],
        "abstract": "Topic models have been widely explored as probabilistic generative models of documents. Traditional inference methods have sought closed-form derivations for updating the models, however as the expressiveness of these models grows, so does the difficulty of performing fast and accurate inference over their parameters. This paper presents alternative neural approaches to topic modelling by providing parameterisable distributions over topics which permit training by backpropagation in the framework of neural variational inference. In addition, with the help of a stick-breaking construction, we propose a recurrent network that is able to discover a notionally unbounded number of topics, analogous to Bayesian non-parametric topic models. Experimental results on the MXM Song Lyrics, 20NewsGroups and Reuters News datasets demonstrate the effectiveness and efficiency of these neural topic models.\n    ",
        "submission_date": "2017-06-01T00:00:00",
        "last_modified_date": "2018-05-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.00374",
        "title": "Semantic Specialisation of Distributional Word Vector Spaces using Monolingual and Cross-Lingual Constraints",
        "authors": [
            "Nikola Mrk\u0161i\u0107",
            "Ivan Vuli\u0107",
            "Diarmuid \u00d3 S\u00e9aghdha",
            "Ira Leviant",
            "Roi Reichart",
            "Milica Ga\u0161i\u0107",
            "Anna Korhonen",
            "Steve Young"
        ],
        "abstract": "We present Attract-Repel, an algorithm for improving the semantic quality of word vectors by injecting constraints extracted from lexical resources. Attract-Repel facilitates the use of constraints from mono- and cross-lingual resources, yielding semantically specialised cross-lingual vector spaces. Our evaluation shows that the method can make use of existing cross-lingual lexicons to construct high-quality vector spaces for a plethora of different languages, facilitating semantic transfer from high- to lower-resource ones. The effectiveness of our approach is demonstrated with state-of-the-art results on semantic similarity datasets in six languages. We next show that Attract-Repel-specialised vectors boost performance in the downstream task of dialogue state tracking (DST) across multiple languages. Finally, we show that cross-lingual vector spaces produced by our algorithm facilitate the training of multilingual DST models, which brings further performance improvements.\n    ",
        "submission_date": "2017-06-01T00:00:00",
        "last_modified_date": "2017-06-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.00387",
        "title": "Interpolated Policy Gradient: Merging On-Policy and Off-Policy Gradient Estimation for Deep Reinforcement Learning",
        "authors": [
            "Shixiang Gu",
            "Timothy Lillicrap",
            "Zoubin Ghahramani",
            "Richard E. Turner",
            "Bernhard Sch\u00f6lkopf",
            "Sergey Levine"
        ],
        "abstract": "Off-policy model-free deep reinforcement learning methods using previously collected data can improve sample efficiency over on-policy policy gradient techniques. On the other hand, on-policy algorithms are often more stable and easier to use. This paper examines, both theoretically and empirically, approaches to merging on- and off-policy updates for deep reinforcement learning. Theoretical results show that off-policy updates with a value function estimator can be interpolated with on-policy policy gradient updates whilst still satisfying performance bounds. Our analysis uses control variate methods to produce a family of policy gradient algorithms, with several recently proposed algorithms being special cases of this family. We then provide an empirical comparison of these techniques with the remaining algorithmic details fixed, and show how different mixing of off-policy gradient estimates with on-policy samples contribute to improvements in empirical performance. The final algorithm provides a generalization and unification of existing deep policy gradient techniques, has theoretical guarantees on the bias introduced by off-policy updates, and improves on the state-of-the-art model-free deep RL methods on a number of OpenAI Gym continuous control benchmarks.\n    ",
        "submission_date": "2017-06-01T00:00:00",
        "last_modified_date": "2017-06-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.00400",
        "title": "Learning Disentangled Representations with Semi-Supervised Deep Generative Models",
        "authors": [
            "N. Siddharth",
            "Brooks Paige",
            "Jan-Willem van de Meent",
            "Alban Desmaison",
            "Noah D. Goodman",
            "Pushmeet Kohli",
            "Frank Wood",
            "Philip H.S. Torr"
        ],
        "abstract": "Variational autoencoders (VAEs) learn representations of data by jointly training a probabilistic encoder and decoder network. Typically these models encode all features of the data into a single variable. Here we are interested in learning disentangled representations that encode distinct aspects of the data into separate variables. We propose to learn such representations using model architectures that generalise from standard VAEs, employing a general graphical model structure in the encoder and decoder. This allows us to train partially-specified models that make relatively strong assumptions about a subset of interpretable variables and rely on the flexibility of neural networks to learn representations for the remaining variables. We further define a general objective for semi-supervised learning in this model class, which can be approximated using an importance sampling procedure. We evaluate our framework's ability to learn disentangled representations, both by qualitative exploration of its generative capacity, and quantitative evaluation of its discriminative ability on a variety of models and datasets.\n    ",
        "submission_date": "2017-06-01T00:00:00",
        "last_modified_date": "2017-11-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.00764",
        "title": "Hyperparameter Optimization: A Spectral Approach",
        "authors": [
            "Elad Hazan",
            "Adam Klivans",
            "Yang Yuan"
        ],
        "abstract": "We give a simple, fast algorithm for hyperparameter optimization inspired by techniques from the analysis of Boolean functions. We focus on the high-dimensional regime where the canonical example is training a neural network with a large number of hyperparameters. The algorithm --- an iterative application of compressed sensing techniques for orthogonal polynomials --- requires only uniform sampling of the hyperparameters and is thus easily parallelizable.\n",
        "submission_date": "2017-06-02T00:00:00",
        "last_modified_date": "2018-01-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.00868",
        "title": "Active learning machine learns to create new quantum experiments",
        "authors": [
            "Alexey A. Melnikov",
            "Hendrik Poulsen Nautrup",
            "Mario Krenn",
            "Vedran Dunjko",
            "Markus Tiersch",
            "Anton Zeilinger",
            "Hans J. Briegel"
        ],
        "abstract": "How useful can machine learning be in a quantum laboratory? Here we raise the question of the potential of intelligent machines in the context of scientific research. A major motivation for the present work is the unknown reachability of various entanglement classes in quantum experiments. We investigate this question by using the projective simulation model, a physics-oriented approach to artificial intelligence. In our approach, the projective simulation system is challenged to design complex photonic quantum experiments that produce high-dimensional entangled multiphoton states, which are of high interest in modern quantum experiments. The artificial intelligence system learns to create a variety of entangled states, and improves the efficiency of their realization. In the process, the system autonomously (re)discovers experimental techniques which are only now becoming standard in modern quantum optical experiments - a trait which was not explicitly demanded from the system but emerged through the process of learning. Such features highlight the possibility that machines could have a significantly more creative role in future research.\n    ",
        "submission_date": "2017-06-02T00:00:00",
        "last_modified_date": "2018-02-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.00989",
        "title": "Visuospatial Skill Learning for Robots",
        "authors": [
            "S. Reza Ahmadzadeh",
            "Fulvio Mastrogiovanni",
            "Petar Kormushev"
        ],
        "abstract": "A novel skill learning approach is proposed that allows a robot to acquire human-like visuospatial skills for object manipulation tasks. Visuospatial skills are attained by observing spatial relationships among objects through demonstrations. The proposed Visuospatial Skill Learning (VSL) is a goal-based approach that focuses on achieving a desired goal configuration of objects relative to one another while maintaining the sequence of operations. VSL is capable of learning and generalizing multi-operation skills from a single demonstration, while requiring minimum prior knowledge about the objects and the environment. In contrast to many existing approaches, VSL offers simplicity, efficiency and user-friendly human-robot interaction. We also show that VSL can be easily extended towards 3D object manipulation tasks, simply by employing point cloud processing techniques. In addition, a robot learning framework, VSL-SP, is proposed by integrating VSL, Imitation Learning, and a conventional planning method. In VSL-SP, the sequence of performed actions are learned using VSL, while the sensorimotor skills are learned using a conventional trajectory-based learning approach. such integration easily extends robot capabilities to novel situations, even by users without programming ability. In VSL-SP the internal planner of VSL is integrated with an existing action-level symbolic planner. Using the underlying constraints of the task and extracted symbolic predicates, identified by VSL, symbolic representation of the task is updated. Therefore the planner maintains a generalized representation of each skill as a reusable action, which can be used in planning and performed independently during the learning phase. The proposed approach is validated through several real-world experiments.\n    ",
        "submission_date": "2017-06-03T00:00:00",
        "last_modified_date": "2017-06-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.01284",
        "title": "Towards Synthesizing Complex Programs from Input-Output Examples",
        "authors": [
            "Xinyun Chen",
            "Chang Liu",
            "Dawn Song"
        ],
        "abstract": "In recent years, deep learning techniques have been developed to improve the performance of program synthesis from input-output examples. Albeit its significant progress, the programs that can be synthesized by state-of-the-art approaches are still simple in terms of their complexity. In this work, we move a significant step forward along this direction by proposing a new class of challenging tasks in the domain of program synthesis from input-output examples: learning a context-free parser from pairs of input programs and their parse trees. We show that this class of tasks are much more challenging than previously studied tasks, and the test accuracy of existing approaches is almost 0%.\n",
        "submission_date": "2017-06-05T00:00:00",
        "last_modified_date": "2018-03-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.01322",
        "title": "Deep learning evaluation using deep linguistic processing",
        "authors": [
            "Alexander Kuhnle",
            "Ann Copestake"
        ],
        "abstract": "We discuss problems with the standard approaches to evaluation for tasks like visual question answering, and argue that artificial data can be used to address these as a complement to current practice. We demonstrate that with the help of existing 'deep' linguistic processing technology we are able to create challenging abstract datasets, which enable us to investigate the language understanding abilities of multimodal deep learning models in detail, as compared to a single performance value on a static and monolithic dataset.\n    ",
        "submission_date": "2017-06-05T00:00:00",
        "last_modified_date": "2018-05-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.01331",
        "title": "Event Representations for Automated Story Generation with Deep Neural Nets",
        "authors": [
            "Lara J. Martin",
            "Prithviraj Ammanabrolu",
            "Xinyu Wang",
            "William Hancock",
            "Shruti Singh",
            "Brent Harrison",
            "Mark O. Riedl"
        ],
        "abstract": "Automated story generation is the problem of automatically selecting a sequence of events, actions, or words that can be told as a story. We seek to develop a system that can generate stories by learning everything it needs to know from textual story corpora. To date, recurrent neural networks that learn language models at character, word, or sentence levels have had little success generating coherent stories. We explore the question of event representations that provide a mid-level of abstraction between words and sentences in order to retain the semantic information of the original data while minimizing event sparsity. We present a technique for preprocessing textual story data into event sequences. We then present a technique for automated story generation whereby we decompose the problem into the generation of successive events (event2event) and the generation of natural language sentences from events (event2sentence). We give empirical results comparing different event representations and their effects on event successor generation and the translation of events to natural language.\n    ",
        "submission_date": "2017-06-05T00:00:00",
        "last_modified_date": "2017-09-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.01350",
        "title": "Emergence of Invariance and Disentanglement in Deep Representations",
        "authors": [
            "Alessandro Achille",
            "Stefano Soatto"
        ],
        "abstract": "Using established principles from Statistics and Information Theory, we show that invariance to nuisance factors in a deep neural network is equivalent to information minimality of the learned representation, and that stacking layers and injecting noise during training naturally bias the network towards learning invariant representations. We then decompose the cross-entropy loss used during training and highlight the presence of an inherent overfitting term. We propose regularizing the loss by bounding such a term in two equivalent ways: One with a Kullbach-Leibler term, which relates to a PAC-Bayes perspective; the other using the information in the weights as a measure of complexity of a learned model, yielding a novel Information Bottleneck for the weights. Finally, we show that invariance and independence of the components of the representation learned by the network are bounded above and below by the information in the weights, and therefore are implicitly optimized during training. The theory enables us to quantify and predict sharp phase transitions between underfitting and overfitting of random labels when using our regularized loss, which we verify in experiments, and sheds light on the relation between the geometry of the loss function, invariance properties of the learned representation, and generalization error.\n    ",
        "submission_date": "2017-06-05T00:00:00",
        "last_modified_date": "2018-06-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.01450",
        "title": "A Joint Model for Question Answering and Question Generation",
        "authors": [
            "Tong Wang",
            "Xingdi Yuan",
            "Adam Trischler"
        ],
        "abstract": "We propose a generative machine comprehension model that learns jointly to ask and answer questions based on documents. The proposed model uses a sequence-to-sequence framework that encodes the document and generates a question (answer) given an answer (question). Significant improvement in model performance is observed empirically on the SQuAD corpus, confirming our hypothesis that the model benefits from jointly learning to perform both tasks. We believe the joint model's novelty offers a new perspective on machine comprehension beyond architectural engineering, and serves as a first step towards autonomous information seeking.\n    ",
        "submission_date": "2017-06-05T00:00:00",
        "last_modified_date": "2017-06-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.01554",
        "title": "Best of Both Worlds: Transferring Knowledge from Discriminative Learning to a Generative Visual Dialog Model",
        "authors": [
            "Jiasen Lu",
            "Anitha Kannan",
            "Jianwei Yang",
            "Devi Parikh",
            "Dhruv Batra"
        ],
        "abstract": "We present a novel training framework for neural sequence models, particularly for grounded dialog generation. The standard training paradigm for these models is maximum likelihood estimation (MLE), or minimizing the cross-entropy of the human responses. Across a variety of domains, a recurring problem with MLE trained generative neural dialog models (G) is that they tend to produce 'safe' and generic responses (\"I don't know\", \"I can't tell\"). In contrast, discriminative dialog models (D) that are trained to rank a list of candidate human responses outperform their generative counterparts; in terms of automatic metrics, diversity, and informativeness of the responses. However, D is not useful in practice since it cannot be deployed to have real conversations with users.\n",
        "submission_date": "2017-06-05T00:00:00",
        "last_modified_date": "2017-10-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.01574",
        "title": "Extracting Hierarchies of Search Tasks & Subtasks via a Bayesian Nonparametric Approach",
        "authors": [
            "Rishabh Mehrotra",
            "Emine Yilmaz"
        ],
        "abstract": "A significant amount of search queries originate from some real world information need or tasks. In order to improve the search experience of the end users, it is important to have accurate representations of tasks. As a result, significant amount of research has been devoted to extracting proper representations of tasks in order to enable search systems to help users complete their tasks, as well as providing the end user with better query suggestions, for better recommendations, for satisfaction prediction, and for improved personalization in terms of tasks. Most existing task extraction methodologies focus on representing tasks as flat structures. However, tasks often tend to have multiple subtasks associated with them and a more naturalistic representation of tasks would be in terms of a hierarchy, where each task can be composed of multiple (sub)tasks. To this end, we propose an efficient Bayesian nonparametric model for extracting hierarchies of such tasks \\& subtasks. We evaluate our method based on real world query log data both through quantitative and crowdsourced experiments and highlight the importance of considering task/subtask hierarchies.\n    ",
        "submission_date": "2017-06-06T00:00:00",
        "last_modified_date": "2017-06-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.01758",
        "title": "A WL-SPPIM Semantic Model for Document Classification",
        "authors": [
            "Ming Li",
            "Peilun Xiao",
            "Ju Zhang"
        ],
        "abstract": "In this paper, we explore SPPIM-based text classification method, and the experiment reveals that the SPPIM method is equal to or even superior than SGNS method in text classification task on three international and standard text datasets, namely 20newsgroups, Reuters52 and WebKB. Comparing to SGNS, although SPPMI provides a better solution, it is not necessarily better than SGNS in text classification tasks. Based on our analysis, SGNS takes into the consideration of weight calculation during decomposition process, so it has better performance than SPPIM in some standard datasets. Inspired by this, we propose a WL-SPPIM semantic model based on SPPIM model, and experiment shows that WL-SPPIM approach has better classification and higher scalability in the text classification task compared with LDA, SGNS and SPPIM approaches.\n    ",
        "submission_date": "2017-05-26T00:00:00",
        "last_modified_date": "2017-05-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.01763",
        "title": "Adversarial-Playground: A Visualization Suite for Adversarial Sample Generation",
        "authors": [
            "Andrew Norton",
            "Yanjun Qi"
        ],
        "abstract": "With growing interest in adversarial machine learning, it is important for machine learning practitioners and users to understand how their models may be attacked. We propose a web-based visualization tool, Adversarial-Playground, to demonstrate the efficacy of common adversarial methods against a deep neural network (DNN) model, built on top of the TensorFlow library. Adversarial-Playground provides users an efficient and effective experience in exploring techniques generating adversarial examples, which are inputs crafted by an adversary to fool a machine learning system. To enable Adversarial-Playground to generate quick and accurate responses for users, we use two primary tactics: (1) We propose a faster variant of the state-of-the-art Jacobian saliency map approach that maintains a comparable evasion rate. (2) Our visualization does not transmit the generated adversarial images to the client, but rather only the matrix describing the sample and the vector representing classification likelihoods.\n",
        "submission_date": "2017-06-06T00:00:00",
        "last_modified_date": "2017-06-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.01863",
        "title": "Marmara Turkish Coreference Corpus and Coreference Resolution Baseline",
        "authors": [
            "Peter Sch\u00fcller",
            "K\u00fcbra C\u0131ng\u0131ll\u0131",
            "Ferit Tun\u00e7er",
            "Bar\u0131\u015f G\u00fcn S\u00fcrmeli",
            "Ay\u015feg\u00fcl Pekel",
            "Ay\u015fe Hande Karatay",
            "Hacer Ezgi Karaka\u015f"
        ],
        "abstract": "We describe the Marmara Turkish Coreference Corpus, which is an annotation of the whole METU-Sabanci Turkish Treebank with mentions and coreference chains. Collecting eight or more independent annotations for each document allowed for fully automatic adjudication. We provide a baseline system for Turkish mention detection and coreference resolution and evaluate it on the corpus.\n    ",
        "submission_date": "2017-06-06T00:00:00",
        "last_modified_date": "2018-07-31T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.01905",
        "title": "Parameter Space Noise for Exploration",
        "authors": [
            "Matthias Plappert",
            "Rein Houthooft",
            "Prafulla Dhariwal",
            "Szymon Sidor",
            "Richard Y. Chen",
            "Xi Chen",
            "Tamim Asfour",
            "Pieter Abbeel",
            "Marcin Andrychowicz"
        ],
        "abstract": "Deep reinforcement learning (RL) methods generally engage in exploratory behavior through noise injection in the action space. An alternative is to add noise directly to the agent's parameters, which can lead to more consistent exploration and a richer set of behaviors. Methods such as evolutionary strategies use parameter perturbations, but discard all temporal structure in the process and require significantly more samples. Combining parameter noise with traditional RL methods allows to combine the best of both worlds. We demonstrate that both off- and on-policy methods benefit from this approach through experimental comparison of DQN, DDPG, and TRPO on high-dimensional discrete action environments as well as continuous control tasks. Our results show that RL with parameter noise learns more efficiently than traditional RL with action space noise and evolutionary strategies individually.\n    ",
        "submission_date": "2017-06-06T00:00:00",
        "last_modified_date": "2018-01-31T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.02109",
        "title": "Guided Interaction Exploration in Artifact-centric Process Models",
        "authors": [
            "Maikel L. van Eck",
            "Natalia Sidorova",
            "Wil M.P. van der Aalst"
        ],
        "abstract": "Artifact-centric process models aim to describe complex processes as a collection of interacting artifacts. Recent development in process mining allow for the discovery of such models. However, the focus is often on the representation of the individual artifacts rather than their interactions. Based on event data we can automatically discover composite state machines representing artifact-centric processes. Moreover, we provide ways of visualizing and quantifying interactions among different artifacts. For example, we are able to highlight strongly correlated behaviours in different artifacts. The approach has been fully implemented as a ProM plug-in; the CSM Miner provides an interactive artifact-centric process discovery tool focussing on interactions. The approach has been evaluated using real life data sets, including the personal loan and overdraft process of a Dutch financial institution.\n    ",
        "submission_date": "2017-06-07T00:00:00",
        "last_modified_date": "2017-06-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.02141",
        "title": "How Important is Syntactic Parsing Accuracy? An Empirical Evaluation on Rule-Based Sentiment Analysis",
        "authors": [
            "Carlos G\u00f3mez-Rodr\u00edguez",
            "Iago Alonso-Alonso",
            "David Vilares"
        ],
        "abstract": "Syntactic parsing, the process of obtaining the internal structure of sentences in natural languages, is a crucial task for artificial intelligence applications that need to extract meaning from natural language text or speech. Sentiment analysis is one example of application for which parsing has recently proven useful.\n",
        "submission_date": "2017-06-07T00:00:00",
        "last_modified_date": "2017-10-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.02179",
        "title": "Learning to Represent Mechanics via Long-term Extrapolation and Interpolation",
        "authors": [
            "S\u00e9bastien Ehrhardt",
            "Aron Monszpart",
            "Andrea Vedaldi",
            "Niloy Mitra"
        ],
        "abstract": "While the basic laws of Newtonian mechanics are well understood, explaining a physical scenario still requires manually modeling the problem with suitable equations and associated parameters. In order to adopt such models for artificial intelligence, researchers have handcrafted the relevant states, and then used neural networks to learn the state transitions using simulation runs as training data. Unfortunately, such approaches can be unsuitable for modeling complex real-world scenarios, where manually authoring relevant state spaces tend to be challenging. In this work, we investigate if neural networks can implicitly learn physical states of real-world mechanical processes only based on visual data, and thus enable long-term physical extrapolation. We develop a recurrent neural network architecture for this task and also characterize resultant uncertainties in the form of evolving variance estimates. We evaluate our setup to extrapolate motion of a rolling ball on bowl of varying shape and orientation using only images as input, and report competitive results with approaches that assume access to internal physics models and parameters.\n    ",
        "submission_date": "2017-06-06T00:00:00",
        "last_modified_date": "2017-06-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.02209",
        "title": "Improving Max-Sum through Decimation to Solve Loopy Distributed Constraint Optimization Problems",
        "authors": [
            "Jes\u00fas Cerquides",
            "R\u00e9mi Emonet",
            "Gauthier Picard",
            "Juan A. Rodr\u00edguez-Aguilar"
        ],
        "abstract": "In the context of solving large distributed constraint optimization problems (DCOP), belief-propagation and approximate inference algorithms are candidates of choice. However, in general, when the factor graph is very loopy (i.e. cyclic), these solution methods suffer from bad performance, due to non-convergence and many exchanged messages. As to improve performances of the Max-Sum inference algorithm when solving loopy constraint optimization problems, we propose here to take inspiration from the belief-propagation-guided dec-imation used to solve sparse random graphs (k-satisfiability). We propose the novel DeciMaxSum method, which is parameterized in terms of policies to decide when to trigger decimation, which variables to decimate, and which values to assign to decimated variables. Based on an empirical evaluation on a classical BP benchmark (the Ising model), some of these combinations of policies exhibit better performance than state-of-the-art competitors.\n    ",
        "submission_date": "2017-06-07T00:00:00",
        "last_modified_date": "2017-06-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.02240",
        "title": "Recurrent computations for visual pattern completion",
        "authors": [
            "Hanlin Tang",
            "Martin Schrimpf",
            "Bill Lotter",
            "Charlotte Moerman",
            "Ana Paredes",
            "Josue Ortega Caro",
            "Walter Hardesty",
            "David Cox",
            "Gabriel Kreiman"
        ],
        "abstract": "Making inferences from partial information constitutes a critical aspect of cognition. During visual perception, pattern completion enables recognition of poorly visible or occluded objects. We combined psychophysics, physiology and computational models to test the hypothesis that pattern completion is implemented by recurrent computations and present three pieces of evidence that are consistent with this hypothesis. First, subjects robustly recognized objects even when rendered <15% visible, but recognition was largely impaired when processing was interrupted by backward masking. Second, invasive physiological responses along the human ventral cortex exhibited visually selective responses to partially visible objects that were delayed compared to whole objects, suggesting the need for additional computations. These physiological delays were correlated with the effects of backward masking. Third, state-of-the-art feed-forward computational architectures were not robust to partial visibility. However, recognition performance was recovered when the model was augmented with attractor-based recurrent connectivity. These results provide a strong argument of plausibility for the role of recurrent computations in making visual inferences from partial information.\n    ",
        "submission_date": "2017-06-07T00:00:00",
        "last_modified_date": "2018-04-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.02257",
        "title": "Driver Action Prediction Using Deep (Bidirectional) Recurrent Neural Network",
        "authors": [
            "Oluwatobi Olabiyi",
            "Eric Martinson",
            "Vijay Chintalapudi",
            "Rui Guo"
        ],
        "abstract": "Advanced driver assistance systems (ADAS) can be significantly improved with effective driver action prediction (DAP). Predicting driver actions early and accurately can help mitigate the effects of potentially unsafe driving behaviors and avoid possible accidents. In this paper, we formulate driver action prediction as a timeseries anomaly prediction problem. While the anomaly (driver actions of interest) detection might be trivial in this context, finding patterns that consistently precede an anomaly requires searching for or extracting features across multi-modal sensory inputs. We present such a driver action prediction system, including a real-time data acquisition, processing and learning framework for predicting future or impending driver action. The proposed system incorporates camera-based knowledge of the driving environment and the driver themselves, in addition to traditional vehicle dynamics. It then uses a deep bidirectional recurrent neural network (DBRNN) to learn the correlation between sensory inputs and impending driver behavior achieving accurate and high horizon action prediction. The proposed system performs better than other existing systems on driver action prediction tasks and can accurately predict key driver actions including acceleration, braking, lane change and turning at durations of 5sec before the action is executed by the driver.\n    ",
        "submission_date": "2017-06-07T00:00:00",
        "last_modified_date": "2017-06-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.02262",
        "title": "InfoVAE: Information Maximizing Variational Autoencoders",
        "authors": [
            "Shengjia Zhao",
            "Jiaming Song",
            "Stefano Ermon"
        ],
        "abstract": "A key advance in learning generative models is the use of amortized inference distributions that are jointly trained with the models. We find that existing training objectives for variational autoencoders can lead to inaccurate amortized inference distributions and, in some cases, improving the objective provably degrades the inference quality. In addition, it has been observed that variational autoencoders tend to ignore the latent variables when combined with a decoding distribution that is too flexible. We again identify the cause in existing training criteria and propose a new class of objectives (InfoVAE) that mitigate these problems. We show that our model can significantly improve the quality of the variational posterior and can make effective use of the latent features regardless of the flexibility of the decoding distribution. Through extensive qualitative and quantitative analyses, we demonstrate that our models outperform competing approaches on multiple performance metrics.\n    ",
        "submission_date": "2017-06-07T00:00:00",
        "last_modified_date": "2018-05-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.02275",
        "title": "Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments",
        "authors": [
            "Ryan Lowe",
            "Yi Wu",
            "Aviv Tamar",
            "Jean Harb",
            "Pieter Abbeel",
            "Igor Mordatch"
        ],
        "abstract": "We explore deep reinforcement learning methods for multi-agent domains. We begin by analyzing the difficulty of traditional algorithms in the multi-agent case: Q-learning is challenged by an inherent non-stationarity of the environment, while policy gradient suffers from a variance that increases as the number of agents grows. We then present an adaptation of actor-critic methods that considers action policies of other agents and is able to successfully learn policies that require complex multi-agent coordination. Additionally, we introduce a training regimen utilizing an ensemble of policies for each agent that leads to more robust multi-agent policies. We show the strength of our approach compared to existing methods in cooperative as well as competitive scenarios, where agent populations are able to discover various physical and informational coordination strategies.\n    ",
        "submission_date": "2017-06-07T00:00:00",
        "last_modified_date": "2020-03-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.02416",
        "title": "Generalized Value Iteration Networks: Life Beyond Lattices",
        "authors": [
            "Sufeng Niu",
            "Siheng Chen",
            "Hanyu Guo",
            "Colin Targonski",
            "Melissa C. Smith",
            "Jelena Kova\u010devi\u0107"
        ],
        "abstract": "In this paper, we introduce a generalized value iteration network (GVIN), which is an end-to-end neural network planning module. GVIN emulates the value iteration algorithm by using a novel graph convolution operator, which enables GVIN to learn and plan on irregular spatial graphs. We propose three novel differentiable kernels as graph convolution operators and show that the embedding based kernel achieves the best performance. We further propose episodic Q-learning, an improvement upon traditional n-step Q-learning that stabilizes training for networks that contain a planning module. Lastly, we evaluate GVIN on planning problems in 2D mazes, irregular graphs, and real-world street networks, showing that GVIN generalizes well for both arbitrary graphs and unseen graphs of larger scale and outperforms a naive generalization of VIN (discretizing a spatial graph into a 2D image).\n    ",
        "submission_date": "2017-06-08T00:00:00",
        "last_modified_date": "2017-10-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.02490",
        "title": "Where is my forearm? Clustering of body parts from simultaneous tactile and linguistic input using sequential mapping",
        "authors": [
            "Karla Stepanova",
            "Matej Hoffmann",
            "Zdenek Straka",
            "Frederico B. Klein",
            "Angelo Cangelosi",
            "Michal Vavrecka"
        ],
        "abstract": "Humans and animals are constantly exposed to a continuous stream of sensory information from different modalities. At the same time, they form more compressed representations like concepts or symbols. In species that use language, this process is further structured by this interaction, where a mapping between the sensorimotor concepts and linguistic elements needs to be established. There is evidence that children might be learning language by simply disambiguating potential meanings based on multiple exposures to utterances in different contexts (cross-situational learning). In existing models, the mapping between modalities is usually found in a single step by directly using frequencies of referent and meaning co-occurrences. In this paper, we present an extension of this one-step mapping and introduce a newly proposed sequential mapping algorithm together with a publicly available Matlab implementation. For demonstration, we have chosen a less typical scenario: instead of learning to associate objects with their names, we focus on body representations. A humanoid robot is receiving tactile stimulations on its body, while at the same time listening to utterances of the body part names (e.g., hand, forearm and torso). With the goal at arriving at the correct \"body categories\", we demonstrate how a sequential mapping algorithm outperforms one-step mapping. In addition, the effect of data set size and noise in the linguistic input are studied.\n    ",
        "submission_date": "2017-06-08T00:00:00",
        "last_modified_date": "2017-06-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.02591",
        "title": "Dynamic Discovery of Type Classes and Relations in Semantic Web Data",
        "authors": [
            "Serkan Ayvaz",
            "Mehmet Aydar"
        ],
        "abstract": "The continuing development of Semantic Web technologies and the increasing user adoption in the recent years have accelerated the progress incorporating explicit semantics with data on the Web. With the rapidly growing RDF (Resource Description Framework) data on the Semantic Web, processing large semantic graph data have become more challenging. Constructing a summary graph structure from the raw RDF can help obtain semantic type relations and reduce the computational complexity for graph processing purposes. In this paper, we addressed the problem of graph summarization in RDF graphs, and we proposed an approach for building summary graph structures automatically from RDF graph data. Moreover, we introduced a measure to help discover optimum class dissimilarity thresholds and an effective method to discover the type classes automatically. In future work, we plan to investigate further improvement options on the scalability of the proposed method.\n    ",
        "submission_date": "2017-05-31T00:00:00",
        "last_modified_date": "2017-05-31T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.02596",
        "title": "Dynamic Integration of Background Knowledge in Neural NLU Systems",
        "authors": [
            "Dirk Weissenborn",
            "Tom\u00e1\u0161 Ko\u010disk\u00fd",
            "Chris Dyer"
        ],
        "abstract": "Common-sense and background knowledge is required to understand natural language, but in most neural natural language understanding (NLU) systems, this knowledge must be acquired from training corpora during learning, and then it is static at test time. We introduce a new architecture for the dynamic integration of explicit background knowledge in NLU models. A general-purpose reading module reads background knowledge in the form of free-text statements (together with task-specific text inputs) and yields refined word representations to a task-specific NLU architecture that reprocesses the task inputs with these representations. Experiments on document question answering (DQA) and recognizing textual entailment (RTE) demonstrate the effectiveness and flexibility of the approach. Analysis shows that our model learns to exploit knowledge in a semantically appropriate way.\n    ",
        "submission_date": "2017-06-08T00:00:00",
        "last_modified_date": "2018-08-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.02621",
        "title": "Design and Implementation of Modified Fuzzy based CPU Scheduling Algorithm",
        "authors": [
            "Rajani Kumari",
            "Vivek Kumar Sharma",
            "Sandeep Kumar"
        ],
        "abstract": "CPU Scheduling is the base of multiprogramming. Scheduling is a process which decides order of task from a set of multiple tasks that are ready to execute. There are number of CPU scheduling algorithms available, but it is very difficult task to decide which one is better. This paper discusses the design and implementation of modified fuzzy based CPU scheduling algorithm. This paper present a new set of fuzzy rules. It demonstrates that scheduling done with new priority improves average waiting time and average turnaround time.\n    ",
        "submission_date": "2017-05-26T00:00:00",
        "last_modified_date": "2017-05-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.02985",
        "title": "Stock Trading Using PE ratio: A Dynamic Bayesian Network Modeling on Behavioral Finance and Fundamental Investment",
        "authors": [
            "Haizhen Wang",
            "Ratthachat Chatpatanasiri",
            "Pairote Sattayatham"
        ],
        "abstract": "On a daily investment decision in a security market, the price earnings (PE) ratio is one of the most widely applied methods being used as a firm valuation tool by investment experts. Unfortunately, recent academic developments in financial econometrics and machine learning rarely look at this tool. In practice, fundamental PE ratios are often estimated only by subjective expert opinions. The purpose of this research is to formalize a process of fundamental PE estimation by employing advanced dynamic Bayesian network (DBN) methodology. The estimated PE ratio from our model can be used either as a information support for an expert to make investment decisions, or as an automatic trading system illustrated in experiments. Forward-backward inference and EM parameter estimation algorithms are derived with respect to the proposed DBN structure. Unlike existing works in literatures, the economic interpretation of our DBN model is well-justified by behavioral finance evidences of volatility. A simple but practical trading strategy is invented based on the result of Bayesian inference. Extensive experiments show that our trading strategy equipped with the inferenced PE ratios consistently outperforms standard investment benchmarks.\n    ",
        "submission_date": "2017-05-25T00:00:00",
        "last_modified_date": "2017-05-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.02999",
        "title": "Symmetry Learning for Function Approximation in Reinforcement Learning",
        "authors": [
            "Anuj Mahajan",
            "Theja Tulabandhula"
        ],
        "abstract": "In this paper we explore methods to exploit symmetries for ensuring sample efficiency in reinforcement learning (RL), this problem deserves ever increasing attention with the recent advances in the use of deep networks for complex RL tasks which require large amount of training data. We introduce a novel method to detect symmetries using reward trails observed during episodic experience and prove its completeness. We also provide a framework to incorporate the discovered symmetries for functional approximation. Finally we show that the use of potential based reward shaping is especially effective for our symmetry exploitation mechanism. Experiments on various classical problems show that our method improves the learning performance significantly by utilizing symmetry information.\n    ",
        "submission_date": "2017-06-09T00:00:00",
        "last_modified_date": "2017-06-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.03065",
        "title": "Towards balanced clustering - part 1 (preliminaries)",
        "authors": [
            "Mark Sh. Levin"
        ],
        "abstract": "The article contains a preliminary glance at balanced clustering problems. Basic balanced structures and combinatorial balanced problems are briefly described. A special attention is targeted to various balance/unbalance indices (including some new versions of the indices): by cluster cardinality, by cluster weights, by inter-cluster edge/arc weights, by cluster element structure (for element multi-type clustering). Further, versions of optimization clustering problems are suggested (including multicriteria problem formulations). Illustrative numerical examples describe calculation of balance indices and element multi-type balance clustering problems (including example for design of student teams).\n    ",
        "submission_date": "2017-06-09T00:00:00",
        "last_modified_date": "2017-06-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.03146",
        "title": "Rethinking Skip-thought: A Neighborhood based Approach",
        "authors": [
            "Shuai Tang",
            "Hailin Jin",
            "Chen Fang",
            "Zhaowen Wang",
            "Virginia R. de Sa"
        ],
        "abstract": "We study the skip-thought model with neighborhood information as weak supervision. More specifically, we propose a skip-thought neighbor model to consider the adjacent sentences as a neighborhood. We train our skip-thought neighbor model on a large corpus with continuous sentences, and then evaluate the trained model on 7 tasks, which include semantic relatedness, paraphrase detection, and classification benchmarks. Both quantitative comparison and qualitative investigation are conducted. We empirically show that, our skip-thought neighbor model performs as well as the skip-thought model on evaluation tasks. In addition, we found that, incorporating an autoencoder path in our model didn't aid our model to perform better, while it hurts the performance of the skip-thought model.\n    ",
        "submission_date": "2017-06-09T00:00:00",
        "last_modified_date": "2017-06-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.03205",
        "title": "Item Silk Road: Recommending Items from Information Domains to Social Users",
        "authors": [
            "Xiang Wang",
            "Xiangnan He",
            "Liqiang Nie",
            "Tat-Seng Chua"
        ],
        "abstract": "Online platforms can be divided into information-oriented and social-oriented domains. The former refers to forums or E-commerce sites that emphasize user-item interactions, like ",
        "submission_date": "2017-06-10T00:00:00",
        "last_modified_date": "2017-06-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.03416",
        "title": "Learning Large-Scale Topological Maps Using Sum-Product Networks",
        "authors": [
            "Kaiyu Zheng"
        ],
        "abstract": "In order to perform complex actions in human environments, an autonomous robot needs the ability to understand the environment, that is, to gather and maintain spatial knowledge. Topological map is commonly used for representing large scale, global maps such as floor plans. Although much work has been done in topological map extraction, we have found little previous work on the problem of learning the topological map using a probabilistic model. Learning a topological map means learning the structure of the large-scale space and dependency between places, for example, how the evidence of a group of places influence the attributes of other places. This is an important step towards planning complex actions in the environment. In this thesis, we consider the problem of using probabilistic deep learning model to learn the topological map, which is essentially a sparse undirected graph where nodes represent places annotated with their semantic attributes (e.g. place category). We propose to use a novel probabilistic deep model, Sum-Product Networks (SPNs), due to their unique properties. We present two methods for learning topological maps using SPNs: the place grid method and the template-based method. We contribute an algorithm that builds SPNs for graphs using template models. Our experiments evaluate the ability of our models to enable robots to infer semantic attributes and detect maps with novel semantic attribute arrangements. Our results demonstrate their understanding of the topological map structure and spatial relations between places.\n    ",
        "submission_date": "2017-06-11T00:00:00",
        "last_modified_date": "2017-07-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.03459",
        "title": "Optimal Auctions through Deep Learning: Advances in Differentiable Economics",
        "authors": [
            "Paul D\u00fctting",
            "Zhe Feng",
            "Harikrishna Narasimhan",
            "David C. Parkes",
            "Sai Srivatsa Ravindranath"
        ],
        "abstract": "Designing an incentive compatible auction that maximizes expected revenue is an intricate task. The single-item case was resolved in a seminal piece of work by Myerson in 1981, but more than 40 years later a full analytical understanding of the optimal design still remains elusive for settings with two or more items. In this work, we initiate the exploration of the use of tools from deep learning for the automated design of optimal auctions. We model an auction as a multi-layer neural network, frame optimal auction design as a constrained learning problem, and show how it can be solved using standard machine learning pipelines. In addition to providing generalization bounds, we present extensive experimental results, recovering essentially all known solutions that come from the theoretical analysis of optimal auction design problems and obtaining novel mechanisms for settings in which the optimal mechanism is unknown.\n    ",
        "submission_date": "2017-06-12T00:00:00",
        "last_modified_date": "2022-10-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.03471",
        "title": "YellowFin and the Art of Momentum Tuning",
        "authors": [
            "Jian Zhang",
            "Ioannis Mitliagkas"
        ],
        "abstract": "Hyperparameter tuning is one of the most time-consuming workloads in deep learning. State-of-the-art optimizers, such as AdaGrad, RMSProp and Adam, reduce this labor by adaptively tuning an individual learning rate for each variable. Recently researchers have shown renewed interest in simpler methods like momentum SGD as they may yield better test metrics. Motivated by this trend, we ask: can simple adaptive methods based on SGD perform as well or better? We revisit the momentum SGD algorithm and show that hand-tuning a single learning rate and momentum makes it competitive with Adam. We then analyze its robustness to learning rate misspecification and objective curvature variation. Based on these insights, we design YellowFin, an automatic tuner for momentum and learning rate in SGD. YellowFin optionally uses a negative-feedback loop to compensate for the momentum dynamics in asynchronous settings on the fly. We empirically show that YellowFin can converge in fewer iterations than Adam on ResNets and LSTMs for image recognition, language modeling and constituency parsing, with a speedup of up to 3.28x in synchronous and up to 2.69x in asynchronous settings.\n    ",
        "submission_date": "2017-06-12T00:00:00",
        "last_modified_date": "2018-02-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.03610",
        "title": "Neural Domain Adaptation for Biomedical Question Answering",
        "authors": [
            "Georg Wiese",
            "Dirk Weissenborn",
            "Mariana Neves"
        ],
        "abstract": "Factoid question answering (QA) has recently benefited from the development of deep learning (DL) systems. Neural network models outperform traditional approaches in domains where large datasets exist, such as SQuAD (ca. 100,000 questions) for Wikipedia articles. However, these systems have not yet been applied to QA in more specific domains, such as biomedicine, because datasets are generally too small to train a DL system from scratch. For example, the BioASQ dataset for biomedical QA comprises less then 900 factoid (single answer) and list (multiple answers) QA instances. In this work, we adapt a neural QA system trained on a large open-domain dataset (SQuAD, source) to a biomedical dataset (BioASQ, target) by employing various transfer learning techniques. Our network architecture is based on a state-of-the-art QA system, extended with biomedical word embeddings and a novel mechanism to answer list questions. In contrast to existing biomedical QA systems, our system does not rely on domain-specific ontologies, parsers or entity taggers, which are expensive to create. Despite this fact, our systems achieve state-of-the-art results on factoid questions and competitive results on list questions.\n    ",
        "submission_date": "2017-06-12T00:00:00",
        "last_modified_date": "2017-06-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.03741",
        "title": "Deep reinforcement learning from human preferences",
        "authors": [
            "Paul Christiano",
            "Jan Leike",
            "Tom B. Brown",
            "Miljan Martic",
            "Shane Legg",
            "Dario Amodei"
        ],
        "abstract": "For sophisticated reinforcement learning (RL) systems to interact usefully with real-world environments, we need to communicate complex goals to these systems. In this work, we explore goals defined in terms of (non-expert) human preferences between pairs of trajectory segments. We show that this approach can effectively solve complex RL tasks without access to the reward function, including Atari games and simulated robot locomotion, while providing feedback on less than one percent of our agent's interactions with the environment. This reduces the cost of human oversight far enough that it can be practically applied to state-of-the-art RL systems. To demonstrate the flexibility of our approach, we show that we can successfully train complex novel behaviors with about an hour of human time. These behaviors and environments are considerably more complex than any that have been previously learned from human feedback.\n    ",
        "submission_date": "2017-06-12T00:00:00",
        "last_modified_date": "2023-02-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.03757",
        "title": "Semantic Entity Retrieval Toolkit",
        "authors": [
            "Christophe Van Gysel",
            "Maarten de Rijke",
            "Evangelos Kanoulas"
        ],
        "abstract": "Unsupervised learning of low-dimensional, semantic representations of words and entities has recently gained attention. In this paper we describe the Semantic Entity Retrieval Toolkit (SERT) that provides implementations of our previously published entity representation models. The toolkit provides a unified interface to different representation learning algorithms, fine-grained parsing configuration and can be used transparently with GPUs. In addition, users can easily modify existing models or implement their own models in the framework. After model training, SERT can be used to rank entities according to a textual query and extract the learned entity/word representation for use in downstream algorithms, such as clustering or recommendation.\n    ",
        "submission_date": "2017-06-12T00:00:00",
        "last_modified_date": "2017-07-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.03768",
        "title": "Causal Discovery in the Presence of Measurement Error: Identifiability Conditions",
        "authors": [
            "Kun Zhang",
            "Mingming Gong",
            "Joseph Ramsey",
            "Kayhan Batmanghelich",
            "Peter Spirtes",
            "Clark Glymour"
        ],
        "abstract": "Measurement error in the observed values of the variables can greatly change the output of various causal discovery methods. This problem has received much attention in multiple fields, but it is not clear to what extent the causal model for the measurement-error-free variables can be identified in the presence of measurement error with unknown variance. In this paper, we study precise sufficient identifiability conditions for the measurement-error-free causal model and show what information of the causal model can be recovered from observed data. In particular, we present two different sets of identifiability conditions, based on the second-order statistics and higher-order statistics of the data, respectively. The former was inspired by the relationship between the generating model of the measurement-error-contaminated data and the factor analysis model, and the latter makes use of the identifiability result of the over-complete independent component analysis problem.\n    ",
        "submission_date": "2017-06-10T00:00:00",
        "last_modified_date": "2017-06-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.03946",
        "title": "A Supervised Approach to Extractive Summarisation of Scientific Papers",
        "authors": [
            "Ed Collins",
            "Isabelle Augenstein",
            "Sebastian Riedel"
        ],
        "abstract": "Automatic summarisation is a popular approach to reduce a document to its main arguments. Recent research in the area has focused on neural approaches to summarisation, which can be very data-hungry. However, few large datasets exist and none for the traditionally popular domain of scientific publications, which opens up challenging research avenues centered on encoding large, complex documents. In this paper, we introduce a new dataset for summarisation of computer science publications by exploiting a large resource of author provided summaries and show straightforward ways of extending it further. We develop models on the dataset making use of both neural sentence encoding and traditionally used summarisation features and show that models which encode sentences as well as their local and global context perform best, significantly outperforming well-established baseline methods.\n    ",
        "submission_date": "2017-06-13T00:00:00",
        "last_modified_date": "2017-06-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.03993",
        "title": "Getting deep recommenders fit: Bloom embeddings for sparse binary input/output networks",
        "authors": [
            "Joan Serr\u00e0",
            "Alexandros Karatzoglou"
        ],
        "abstract": "Recommendation algorithms that incorporate techniques from deep learning are becoming increasingly popular. Due to the structure of the data coming from recommendation domains (i.e., one-hot-encoded vectors of item preferences), these algorithms tend to have large input and output dimensionalities that dominate their overall size. This makes them difficult to train, due to the limited memory of graphical processing units, and difficult to deploy on mobile devices with limited hardware. To address these difficulties, we propose Bloom embeddings, a compression technique that can be applied to the input and output of neural network models dealing with sparse high-dimensional binary-coded instances. Bloom embeddings are computationally efficient, and do not seriously compromise the accuracy of the model up to 1/5 compression ratios. In some cases, they even improve over the original accuracy, with relative increases up to 12%. We evaluate Bloom embeddings on 7 data sets and compare it against 4 alternative methods, obtaining favorable results. We also discuss a number of further advantages of Bloom embeddings, such as 'on-the-fly' constant-time operation, zero or marginal space requirements, training time speedups, or the fact that they do not require any change to the core model architecture or training configuration.\n    ",
        "submission_date": "2017-06-13T00:00:00",
        "last_modified_date": "2017-06-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.04115",
        "title": "Zero-Shot Relation Extraction via Reading Comprehension",
        "authors": [
            "Omer Levy",
            "Minjoon Seo",
            "Eunsol Choi",
            "Luke Zettlemoyer"
        ],
        "abstract": "We show that relation extraction can be reduced to answering simple reading comprehension questions, by associating one or more natural-language questions with each relation slot. This reduction has several advantages: we can (1) learn relation-extraction models by extending recent neural reading-comprehension techniques, (2) build very large training sets for those models by combining relation-specific crowd-sourced questions with distant supervision, and even (3) do zero-shot learning by extracting new relation types that are only specified at test-time, for which we have no labeled training examples. Experiments on a Wikipedia slot-filling task demonstrate that the approach can generalize to new questions for known relation types with high accuracy, and that zero-shot generalization to unseen relation types is possible, at lower accuracy levels, setting the bar for future work on this task.\n    ",
        "submission_date": "2017-06-13T00:00:00",
        "last_modified_date": "2017-06-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.04156",
        "title": "Gradient descent GAN optimization is locally stable",
        "authors": [
            "Vaishnavh Nagarajan",
            "J. Zico Kolter"
        ],
        "abstract": "Despite the growing prominence of generative adversarial networks (GANs), optimization in GANs is still a poorly understood topic. In this paper, we analyze the \"gradient descent\" form of GAN optimization i.e., the natural setting where we simultaneously take small gradient steps in both generator and discriminator parameters. We show that even though GAN optimization does not correspond to a convex-concave game (even for simple parameterizations), under proper conditions, equilibrium points of this optimization procedure are still \\emph{locally asymptotically stable} for the traditional GAN formulation. On the other hand, we show that the recently proposed Wasserstein GAN can have non-convergent limit cycles near equilibrium. Motivated by this stability analysis, we propose an additional regularization term for gradient descent GAN updates, which \\emph{is} able to guarantee local stability for both the WGAN and the traditional GAN, and also shows practical promise in speeding up convergence and addressing mode collapse.\n    ",
        "submission_date": "2017-06-13T00:00:00",
        "last_modified_date": "2018-01-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.04189",
        "title": "Autonomous Reactive Mission Scheduling and Task-Path Planning Architecture for Autonomous Underwater Vehicle",
        "authors": [
            "Somaiyeh Mahmoud.Zadeh"
        ],
        "abstract": "An Autonomous Underwater Vehicle (AUV) should carry out complex tasks in a limited time interval. Since existing AUVs have limited battery capacity and restricted endurance, they should autonomously manage mission time and the resources to perform effective persistent deployment in longer missions. Task assignment requires making decisions subject to resource constraints, while tasks are assigned with costs and/or values that are budgeted in advance. Tasks are distributed in a particular operation zone and mapped by a waypoint covered network. Thus, design an efficient routing-task priority assign framework considering vehicle's availabilities and properties is essential for increasing mission productivity and on-time mission completion. This depends strongly on the order and priority of the tasks that are located between node-like waypoints in an operation network. On the other hand, autonomous operation of AUVs in an unfamiliar dynamic underwater and performing quick response to sudden environmental changes is a complicated process. Water current instabilities can deflect the vehicle to an undesired direction and perturb AUVs safety. The vehicle's robustness to strong environmental variations is extremely crucial for its safe and optimum operations in an uncertain and dynamic environment. To this end, the AUV needs to have a general overview of the environment in top level to perform an autonomous action selection (task selection) and a lower level local motion planner to operate successfully in dealing with continuously changing situations. This research deals with developing a novel reactive control architecture to provide a higher level of decision autonomy for the AUV operation that enables a single vehicle to accomplish multiple tasks in a single mission in the face of periodic disturbances in a turbulent and highly uncertain environment.\n    ",
        "submission_date": "2017-06-13T00:00:00",
        "last_modified_date": "2017-06-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.04262",
        "title": "Optimization by a quantum reinforcement algorithm",
        "authors": [
            "A. Ramezanpour"
        ],
        "abstract": "A reinforcement algorithm solves a classical optimization problem by introducing a feedback to the system which slowly changes the energy landscape and converges the algorithm to an optimal solution in the configuration space. Here, we use this strategy to concentrate (localize) preferentially the wave function of a quantum particle, which explores the configuration space of the problem, on an optimal configuration. We examine the method by solving numerically the equations governing the evolution of the system, which are similar to the nonlinear Schr\u00f6dinger equations, for small problem sizes. In particular, we observe that reinforcement increases the minimal energy gap of the system in a quantum annealing algorithm. Our numerical simulations and the latter observation show that such kind of quantum feedbacks might be helpful in solving a computationally hard optimization problem by a quantum reinforcement algorithm.\n    ",
        "submission_date": "2017-06-13T00:00:00",
        "last_modified_date": "2017-11-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.04399",
        "title": "Enhanced discrete particle swarm optimization path planning for UAV vision-based surface inspection",
        "authors": [
            "Manh Duong Phung",
            "Cong Hoang Quach",
            "Tran Hiep Dinh",
            "Quang Ha"
        ],
        "abstract": "In built infrastructure monitoring, an efficient path planning algorithm is essential for robotic inspection of large surfaces using computer vision. In this work, we first formulate the inspection path planning problem as an extended travelling salesman problem (TSP) in which both the coverage and obstacle avoidance were taken into account. An enhanced discrete particle swarm optimization (DPSO) algorithm is then proposed to solve the TSP, with performance improvement by using deterministic initialization, random mutation, and edge exchange. Finally, we take advantage of parallel computing to implement the DPSO in a GPU-based framework so that the computation time can be significantly reduced while keeping the hardware requirement unchanged. To show the effectiveness of the proposed algorithm, experimental results are included for datasets obtained from UAV inspection of an office building and a bridge.\n    ",
        "submission_date": "2017-06-14T00:00:00",
        "last_modified_date": "2017-06-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.04486",
        "title": "Learning and Evaluating Musical Features with Deep Autoencoders",
        "authors": [
            "Mason Bretan",
            "Sageev Oore",
            "Doug Eck",
            "Larry Heck"
        ],
        "abstract": "In this work we describe and evaluate methods to learn musical embeddings. Each embedding is a vector that represents four contiguous beats of music and is derived from a symbolic representation. We consider autoencoding-based methods including denoising autoencoders, and context reconstruction, and evaluate the resulting embeddings on a forward prediction and a classification task.\n    ",
        "submission_date": "2017-06-14T00:00:00",
        "last_modified_date": "2017-06-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.04560",
        "title": "Neural Models for Key Phrase Detection and Question Generation",
        "authors": [
            "Sandeep Subramanian",
            "Tong Wang",
            "Xingdi Yuan",
            "Saizheng Zhang",
            "Yoshua Bengio",
            "Adam Trischler"
        ],
        "abstract": "We propose a two-stage neural model to tackle question generation from documents. First, our model estimates the probability that word sequences in a document are ones that a human would pick when selecting candidate answers by training a neural key-phrase extractor on the answers in a question-answering corpus. Predicted key phrases then act as target answers and condition a sequence-to-sequence question-generation model with a copy mechanism. Empirically, our key-phrase extraction model significantly outperforms an entity-tagging baseline and existing rule-based approaches. We further demonstrate that our question generation system formulates fluent, answerable questions from key phrases. This two-stage system could be used to augment or generate reading comprehension datasets, which may be leveraged to improve machine reading systems or in educational settings.\n    ",
        "submission_date": "2017-06-14T00:00:00",
        "last_modified_date": "2018-05-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.04652",
        "title": "Learning a visuomotor controller for real world robotic grasping using simulated depth images",
        "authors": [
            "Ulrich Viereck",
            "Andreas ten Pas",
            "Kate Saenko",
            "Robert Platt"
        ],
        "abstract": "We want to build robots that are useful in unstructured real world applications, such as doing work in the household. Grasping in particular is an important skill in this domain, yet it remains a challenge. One of the key hurdles is handling unexpected changes or motion in the objects being grasped and kinematic noise or other errors in the robot. This paper proposes an approach to learning a closed-loop controller for robotic grasping that dynamically guides the gripper to the object. We use a wrist-mounted sensor to acquire depth images in front of the gripper and train a convolutional neural network to learn a distance function to true grasps for grasp configurations over an image. The training sensor data is generated in simulation, a major advantage over previous work that uses real robot experience, which is costly to obtain. Despite being trained in simulation, our approach works well on real noisy sensor images. We compare our controller in simulated and real robot experiments to a strong baseline for grasp pose detection, and find that our approach significantly outperforms the baseline in the presence of kinematic noise, perceptual errors and disturbances of the object during grasping.\n    ",
        "submission_date": "2017-06-14T00:00:00",
        "last_modified_date": "2017-11-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.04972",
        "title": "Device Placement Optimization with Reinforcement Learning",
        "authors": [
            "Azalia Mirhoseini",
            "Hieu Pham",
            "Quoc V. Le",
            "Benoit Steiner",
            "Rasmus Larsen",
            "Yuefeng Zhou",
            "Naveen Kumar",
            "Mohammad Norouzi",
            "Samy Bengio",
            "Jeff Dean"
        ],
        "abstract": "The past few years have witnessed a growth in size and computational requirements for training and inference with neural networks. Currently, a common approach to address these requirements is to use a heterogeneous distributed environment with a mixture of hardware devices such as CPUs and GPUs. Importantly, the decision of placing parts of the neural models on devices is often made by human experts based on simple heuristics and intuitions. In this paper, we propose a method which learns to optimize device placement for TensorFlow computational graphs. Key to our method is the use of a sequence-to-sequence model to predict which subsets of operations in a TensorFlow graph should run on which of the available devices. The execution time of the predicted placements is then used as the reward signal to optimize the parameters of the sequence-to-sequence model. Our main result is that on Inception-V3 for ImageNet classification, and on RNN LSTM, for language modeling and neural machine translation, our model finds non-trivial device placements that outperform hand-crafted heuristics and traditional algorithmic methods.\n    ",
        "submission_date": "2017-06-13T00:00:00",
        "last_modified_date": "2017-06-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.05075",
        "title": "Joint Extraction of Entities and Relations Based on a Novel Tagging Scheme",
        "authors": [
            "Suncong Zheng",
            "Feng Wang",
            "Hongyun Bao",
            "Yuexing Hao",
            "Peng Zhou",
            "Bo Xu"
        ],
        "abstract": "Joint extraction of entities and relations is an important task in information extraction. To tackle this problem, we firstly propose a novel tagging scheme that can convert the joint extraction task to a tagging problem. Then, based on our tagging scheme, we study different end-to-end models to extract entities and their relations directly, without identifying entities and relations separately. We conduct experiments on a public dataset produced by distant supervision method and the experimental results show that the tagging based methods are better than most of the existing pipelined and joint learning methods. What's more, the end-to-end model proposed in this paper, achieves the best results on the public dataset.\n    ",
        "submission_date": "2017-06-07T00:00:00",
        "last_modified_date": "2017-06-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.05086",
        "title": "Evaluating Noisy Optimisation Algorithms: First Hitting Time is Problematic",
        "authors": [
            "Simon M. Lucas",
            "Jialin Liu",
            "Diego P\u00e9rez-Li\u00e9bana"
        ],
        "abstract": "A key part of any evolutionary algorithm is fitness evaluation. When fitness evaluations are corrupted by noise, as happens in many real-world problems as a consequence of various types of uncertainty, a strategy is needed in order to cope with this. Resampling is one of the most common strategies, whereby each solution is evaluated many times in order to reduce the variance of the fitness estimates. When evaluating the performance of a noisy optimisation algorithm, a key consideration is the stopping condition for the algorithm. A frequently used stopping condition in runtime analysis, known as \"First Hitting Time\", is to stop the algorithm as soon as it encounters the optimal solution. However, this is unrealistic for real-world problems, as if the optimal solution were already known, there would be no need to search for it. This paper argues that the use of First Hitting Time, despite being a commonly used approach, is significantly flawed and overestimates the quality of many algorithms in real-world cases, where the optimum is not known in advance and has to be genuinely searched for. A better alternative is to measure the quality of the solution an algorithm returns after a fixed evaluation budget, i.e., to focus on final solution quality. This paper argues that focussing on final solution quality is more realistic and demonstrates cases where the results produced by each algorithm evaluation method lead to very different conclusions regarding the quality of each noisy optimisation algorithm.\n    ",
        "submission_date": "2017-06-13T00:00:00",
        "last_modified_date": "2017-07-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.05098",
        "title": "An Overview of Multi-Task Learning in Deep Neural Networks",
        "authors": [
            "Sebastian Ruder"
        ],
        "abstract": "Multi-task learning (MTL) has led to successes in many applications of machine learning, from natural language processing and speech recognition to computer vision and drug discovery. This article aims to give a general overview of MTL, particularly in deep neural networks. It introduces the two most common methods for MTL in Deep Learning, gives an overview of the literature, and discusses recent advances. In particular, it seeks to help ML practitioners apply MTL by shedding light on how MTL works and providing guidelines for choosing appropriate auxiliary tasks.\n    ",
        "submission_date": "2017-06-15T00:00:00",
        "last_modified_date": "2017-06-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.05122",
        "title": "Bib2vec: An Embedding-based Search System for Bibliographic Information",
        "authors": [
            "Takuma Yoneda",
            "Koki Mori",
            "Makoto Miwa",
            "Yutaka Sasaki"
        ],
        "abstract": "We propose a novel embedding model that represents relationships among several elements in bibliographic information with high representation ability and flexibility. Based on this model, we present a novel search system that shows the relationships among the elements in the ACL Anthology Reference Corpus. The evaluation results show that our model can achieve a high prediction ability and produce reasonable search results.\n    ",
        "submission_date": "2017-06-16T00:00:00",
        "last_modified_date": "2018-04-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.05143",
        "title": "AI-Powered Social Bots",
        "authors": [
            "Terrence Adams"
        ],
        "abstract": "This paper gives an overview of impersonation bots that generate output in one, or possibly, multiple modalities. We also discuss rapidly advancing areas of machine learning and artificial intelligence that could lead to frighteningly powerful new multi-modal social bots. Our main conclusion is that most commonly known bots are one dimensional (i.e., chatterbot), and far from deceiving serious interrogators. However, using recent advances in machine learning, it is possible to unleash incredibly powerful, human-like armies of social bots, in potentially well coordinated campaigns of deception and influence.\n    ",
        "submission_date": "2017-06-16T00:00:00",
        "last_modified_date": "2017-06-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.05198",
        "title": "Structured Best Arm Identification with Fixed Confidence",
        "authors": [
            "Ruitong Huang",
            "Mohammad M. Ajallooeian",
            "Csaba Szepesv\u00e1ri",
            "Martin M\u00fcller"
        ],
        "abstract": "We study the problem of identifying the best action among a set of possible options when the value of each action is given by a mapping from a number of noisy micro-observables in the so-called fixed confidence setting. Our main motivation is the application to the minimax game search, which has been a major topic of interest in artificial intelligence. In this paper we introduce an abstract setting to clearly describe the essential properties of the problem. While previous work only considered a two-move game tree search problem, our abstract setting can be applied to the general minimax games where the depth can be non-uniform and arbitrary, and transpositions are allowed. We introduce a new algorithm (LUCB-micro) for the abstract setting, and give its lower and upper sample complexity results. Our bounds recover some previous results, which were only available in more limited settings, while they also shed further light on how the structure of minimax problems influence sample complexity.\n    ",
        "submission_date": "2017-06-16T00:00:00",
        "last_modified_date": "2017-06-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.05254",
        "title": "Collaborative vehicle routing: a survey",
        "authors": [
            "Margaretha Gansterer",
            "Richard F. Hartl"
        ],
        "abstract": "In horizontal collaborations, carriers form coalitions in order to perform parts of their logistics operations jointly. By exchanging transportation requests among each other, they can operate more efficiently and in a more sustainable way. Collaborative vehicle routing has been extensively discussed in the literature. We identify three major streams of research: (i) centralized collaborative planning, (ii) decentralized planning without auctions, and (ii) auction-based decentralized planning. For each of them we give a structured overview on the state of knowledge and discuss future research directions.\n    ",
        "submission_date": "2017-06-13T00:00:00",
        "last_modified_date": "2017-06-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.05477",
        "title": "Bayesian Conditional Generative Adverserial Networks",
        "authors": [
            "M. Ehsan Abbasnejad",
            "Qinfeng Shi",
            "Iman Abbasnejad",
            "Anton van den Hengel",
            "Anthony Dick"
        ],
        "abstract": "Traditional GANs use a deterministic generator function (typically a neural network) to transform a random noise input $z$ to a sample $\\mathbf{x}$ that the discriminator seeks to distinguish. We propose a new GAN called Bayesian Conditional Generative Adversarial Networks (BC-GANs) that use a random generator function to transform a deterministic input $y'$ to a sample $\\mathbf{x}$. Our BC-GANs extend traditional GANs to a Bayesian framework, and naturally handle unsupervised learning, supervised learning, and semi-supervised learning problems. Experiments show that the proposed BC-GANs outperforms the state-of-the-arts.\n    ",
        "submission_date": "2017-06-17T00:00:00",
        "last_modified_date": "2017-06-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.05507",
        "title": "Variants of RMSProp and Adagrad with Logarithmic Regret Bounds",
        "authors": [
            "Mahesh Chandra Mukkamala",
            "Matthias Hein"
        ],
        "abstract": "Adaptive gradient methods have become recently very popular, in particular as they have been shown to be useful in the training of deep neural networks. In this paper we have analyzed RMSProp, originally proposed for the training of deep neural networks, in the context of online convex optimization and show $\\sqrt{T}$-type regret bounds. Moreover, we propose two variants SC-Adagrad and SC-RMSProp for which we show logarithmic regret bounds for strongly convex functions. Finally, we demonstrate in the experiments that these new variants outperform other adaptive gradient techniques or stochastic gradient descent in the optimization of strongly convex functions as well as in training of deep neural networks.\n    ",
        "submission_date": "2017-06-17T00:00:00",
        "last_modified_date": "2017-11-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.05585",
        "title": "Accelerating Innovation Through Analogy Mining",
        "authors": [
            "Tom Hope",
            "Joel Chan",
            "Aniket Kittur",
            "Dafna Shahaf"
        ],
        "abstract": "The availability of large idea repositories (e.g., the U.S. patent database) could significantly accelerate innovation and discovery by providing people with inspiration from solutions to analogous problems. However, finding useful analogies in these large, messy, real-world repositories remains a persistent challenge for either human or automated methods. Previous approaches include costly hand-created databases that have high relational structure (e.g., predicate calculus representations) but are very sparse. Simpler machine-learning/information-retrieval similarity metrics can scale to large, natural-language datasets, but struggle to account for structural similarity, which is central to analogy. In this paper we explore the viability and value of learning simpler structural representations, specifically, \"problem schemas\", which specify the purpose of a product and the mechanisms by which it achieves that purpose. Our approach combines crowdsourcing and recurrent neural networks to extract purpose and mechanism vector representations from product descriptions. We demonstrate that these learned vectors allow us to find analogies with higher precision and recall than traditional information-retrieval methods. In an ideation experiment, analogies retrieved by our models significantly increased people's likelihood of generating creative ideas compared to analogies retrieved by traditional methods. Our results suggest a promising approach to enabling computational analogy at scale is to learn and leverage weaker structural representations.\n    ",
        "submission_date": "2017-06-17T00:00:00",
        "last_modified_date": "2017-06-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.05744",
        "title": "Learning Hierarchical Information Flow with Recurrent Neural Modules",
        "authors": [
            "Danijar Hafner",
            "Alex Irpan",
            "James Davidson",
            "Nicolas Heess"
        ],
        "abstract": "We propose ThalNet, a deep learning model inspired by neocortical communication via the thalamus. Our model consists of recurrent neural modules that send features through a routing center, endowing the modules with the flexibility to share features over multiple time steps. We show that our model learns to route information hierarchically, processing input data by a chain of modules. We observe common architectures, such as feed forward neural networks and skip connections, emerging as special cases of our architecture, while novel connectivity patterns are learned for the text8 compression task. Our model outperforms standard recurrent neural networks on several sequential benchmarks.\n    ",
        "submission_date": "2017-06-18T00:00:00",
        "last_modified_date": "2017-11-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.05749",
        "title": "Dex: Incremental Learning for Complex Environments in Deep Reinforcement Learning",
        "authors": [
            "Nick Erickson",
            "Qi Zhao"
        ],
        "abstract": "This paper introduces Dex, a reinforcement learning environment toolkit specialized for training and evaluation of continual learning methods as well as general reinforcement learning problems. We also present the novel continual learning method of incremental learning, where a challenging environment is solved using optimal weight initialization learned from first solving a similar easier environment. We show that incremental learning can produce vastly superior results than standard methods by providing a strong baseline method across ten Dex environments. We finally develop a saliency method for qualitative analysis of reinforcement learning, which shows the impact incremental learning has on network attention.\n    ",
        "submission_date": "2017-06-19T00:00:00",
        "last_modified_date": "2017-06-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.05826",
        "title": "Capacity Releasing Diffusion for Speed and Locality",
        "authors": [
            "Di Wang",
            "Kimon Fountoulakis",
            "Monika Henzinger",
            "Michael W. Mahoney",
            "Satish Rao"
        ],
        "abstract": "Diffusions and related random walk procedures are of central importance in many areas of machine learning, data analysis, and applied mathematics. Because they spread mass agnostically at each step in an iterative manner, they can sometimes spread mass \"too aggressively,\" thereby failing to find the \"right\" clusters. We introduce a novel Capacity Releasing Diffusion (CRD) Process, which is both faster and stays more local than the classical spectral diffusion process. As an application, we use our CRD Process to develop an improved local algorithm for graph clustering. Our local graph clustering method can find local clusters in a model of clustering where one begins the CRD Process in a cluster whose vertices are connected better internally than externally by an $O(\\log^2 n)$ factor, where $n$ is the number of nodes in the cluster. Thus, our CRD Process is the first local graph clustering algorithm that is not subject to the well-known quadratic Cheeger barrier. Our result requires a certain smoothness condition, which we expect to be an artifact of our analysis. Our empirical evaluation demonstrates improved results, in particular for realistic social graphs where there are moderately good---but not very good---clusters.\n    ",
        "submission_date": "2017-06-19T00:00:00",
        "last_modified_date": "2018-06-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.05928",
        "title": "Modified Frank-Wolfe Algorithm for Enhanced Sparsity in Support Vector Machine Classifiers",
        "authors": [
            "Carlos M. Ala\u00edz",
            "Johan A. K. Suykens"
        ],
        "abstract": "This work proposes a new algorithm for training a re-weighted L2 Support Vector Machine (SVM), inspired on the re-weighted Lasso algorithm of Cand\u00e8s et al. and on the equivalence between Lasso and SVM shown recently by Jaggi. In particular, the margin required for each training vector is set independently, defining a new weighted SVM model. These weights are selected to be binary, and they are automatically adapted during the training of the model, resulting in a variation of the Frank-Wolfe optimization algorithm with essentially the same computational complexity as the original algorithm. As shown experimentally, this algorithm is computationally cheaper to apply since it requires less iterations to converge, and it produces models with a sparser representation in terms of support vectors and which are more stable with respect to the selection of the regularization hyper-parameter.\n    ",
        "submission_date": "2017-06-19T00:00:00",
        "last_modified_date": "2018-04-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.06120",
        "title": "Multi-Label Annotation Aggregation in Crowdsourcing",
        "authors": [
            "Xuan Wei",
            "Daniel Dajun Zeng",
            "Junming Yin"
        ],
        "abstract": "As a means of human-based computation, crowdsourcing has been widely used to annotate large-scale unlabeled datasets. One of the obvious challenges is how to aggregate these possibly noisy labels provided by a set of heterogeneous annotators. Another challenge stems from the difficulty in evaluating the annotator reliability without even knowing the ground truth, which can be used to build incentive mechanisms in crowdsourcing platforms. When each instance is associated with many possible labels simultaneously, the problem becomes even harder because of its combinatorial nature. In this paper, we present new flexible Bayesian models and efficient inference algorithms for multi-label annotation aggregation by taking both annotator reliability and label dependency into account. Extensive experiments on real-world datasets confirm that the proposed methods outperform other competitive alternatives, and the model can recover the type of the annotators with high accuracy.\n    ",
        "submission_date": "2017-06-19T00:00:00",
        "last_modified_date": "2020-10-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.06122",
        "title": "VAIN: Attentional Multi-agent Predictive Modeling",
        "authors": [
            "Yedid Hoshen"
        ],
        "abstract": "Multi-agent predictive modeling is an essential step for understanding physical, social and team-play systems. Recently, Interaction Networks (INs) were proposed for the task of modeling multi-agent physical systems, INs scale with the number of interactions in the system (typically quadratic or higher order in the number of agents). In this paper we introduce VAIN, a novel attentional architecture for multi-agent predictive modeling that scales linearly with the number of agents. We show that VAIN is effective for multi-agent predictive modeling. Our method is evaluated on tasks from challenging multi-agent prediction domains: chess and soccer, and outperforms competing multi-agent approaches.\n    ",
        "submission_date": "2017-06-19T00:00:00",
        "last_modified_date": "2018-09-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.06197",
        "title": "meProp: Sparsified Back Propagation for Accelerated Deep Learning with Reduced Overfitting",
        "authors": [
            "Xu Sun",
            "Xuancheng Ren",
            "Shuming Ma",
            "Houfeng Wang"
        ],
        "abstract": "We propose a simple yet effective technique for neural network learning. The forward propagation is computed as usual. In back propagation, only a small subset of the full gradient is computed to update the model parameters. The gradient vectors are sparsified in such a way that only the top-$k$ elements (in terms of magnitude) are kept. As a result, only $k$ rows or columns (depending on the layout) of the weight matrix are modified, leading to a linear reduction ($k$ divided by the vector dimension) in the computational cost. Surprisingly, experimental results demonstrate that we can update only 1-4% of the weights at each back propagation pass. This does not result in a larger number of training iterations. More interestingly, the accuracy of the resulting models is actually improved rather than degraded, and a detailed analysis is given. The code is available at ",
        "submission_date": "2017-06-19T00:00:00",
        "last_modified_date": "2019-03-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.06210",
        "title": "Sub-domain Modelling for Dialogue Management with Hierarchical Reinforcement Learning",
        "authors": [
            "Pawe\u0142 Budzianowski",
            "Stefan Ultes",
            "Pei-Hao Su",
            "Nikola Mrk\u0161i\u0107",
            "Tsung-Hsien Wen",
            "I\u00f1igo Casanueva",
            "Lina Rojas-Barahona",
            "Milica Ga\u0161i\u0107"
        ],
        "abstract": "Human conversation is inherently complex, often spanning many different topics/domains. This makes policy learning for dialogue systems very challenging. Standard flat reinforcement learning methods do not provide an efficient framework for modelling such dialogues. In this paper, we focus on the under-explored problem of multi-domain dialogue management. First, we propose a new method for hierarchical reinforcement learning using the option framework. Next, we show that the proposed architecture learns faster and arrives at a better policy than the existing flat ones do. Moreover, we show how pretrained policies can be adapted to more complex systems with an additional set of new actions. In doing that, we show that our approach has the potential to facilitate policy optimisation for more sophisticated multi-domain dialogue systems.\n    ",
        "submission_date": "2017-06-19T00:00:00",
        "last_modified_date": "2017-07-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.06216",
        "title": "Dualing GANs",
        "authors": [
            "Yujia Li",
            "Alexander Schwing",
            "Kuan-Chieh Wang",
            "Richard Zemel"
        ],
        "abstract": "Generative adversarial nets (GANs) are a promising technique for modeling a distribution from samples. It is however well known that GAN training suffers from instability due to the nature of its maximin formulation. In this paper, we explore ways to tackle the instability problem by dualizing the discriminator. We start from linear discriminators in which case conjugate duality provides a mechanism to reformulate the saddle point objective into a maximization problem, such that both the generator and the discriminator of this 'dualing GAN' act in concert. We then demonstrate how to extend this intuition to non-linear formulations. For GANs with linear discriminators our approach is able to remove the instability in training, while for GANs with nonlinear discriminators our approach provides an alternative to the commonly used GAN training algorithm.\n    ",
        "submission_date": "2017-06-19T00:00:00",
        "last_modified_date": "2017-06-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.06462",
        "title": "Towards Proof Synthesis Guided by Neural Machine Translation for Intuitionistic Propositional Logic",
        "authors": [
            "Taro Sekiyama",
            "Akifumi Imanishi",
            "Kohei Suenaga"
        ],
        "abstract": "Inspired by the recent evolution of deep neural networks (DNNs) in machine learning, we explore their application to PL-related topics. This paper is the first step towards this goal; we propose a proof-synthesis method for the negation-free propositional logic in which we use a DNN to obtain a guide of proof search. The idea is to view the proof-synthesis problem as a translation from a proposition to its proof. We train seq2seq, which is a popular network in neural machine translation, so that it generates a proof encoded as a $\\lambda$-term of a given proposition. We implement the whole framework and empirically observe that a generated proof term is close to a correct proof in terms of the tree edit distance of AST. This observation justifies using the output from a trained seq2seq model as a guide for proof search.\n    ",
        "submission_date": "2017-06-20T00:00:00",
        "last_modified_date": "2017-06-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.06511",
        "title": "Optimal modularity and memory capacity of neural reservoirs",
        "authors": [
            "Nathaniel Rodriguez",
            "Eduardo Izquierdo",
            "Yong-Yeol Ahn"
        ],
        "abstract": "The neural network is a powerful computing framework that has been exploited by biological evolution and by humans for solving diverse problems. Although the computational capabilities of neural networks are determined by their structure, the current understanding of the relationships between a neural network's architecture and function is still primitive. Here we reveal that neural network's modular architecture plays a vital role in determining the neural dynamics and memory performance of the network of threshold neurons. In particular, we demonstrate that there exists an optimal modularity for memory performance, where a balance between local cohesion and global connectivity is established, allowing optimally modular networks to remember longer. Our results suggest that insights from dynamical analysis of neural networks and information spreading processes can be leveraged to better design neural networks and may shed light on the brain's modular organization.\n    ",
        "submission_date": "2017-06-20T00:00:00",
        "last_modified_date": "2019-03-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.06525",
        "title": "A Hybrid Approach with Multi-channel I-Vectors and Convolutional Neural Networks for Acoustic Scene Classification",
        "authors": [
            "Hamid Eghbal-zadeh",
            "Bernhard Lehner",
            "Matthias Dorfer",
            "Gerhard Widmer"
        ],
        "abstract": "In Acoustic Scene Classification (ASC) two major approaches have been followed . While one utilizes engineered features such as mel-frequency-cepstral-coefficients (MFCCs), the other uses learned features that are the outcome of an optimization algorithm. I-vectors are the result of a modeling technique that usually takes engineered features as input. It has been shown that standard MFCCs extracted from monaural audio signals lead to i-vectors that exhibit poor performance, especially on indoor acoustic scenes. At the same time, Convolutional Neural Networks (CNNs) are well known for their ability to learn features by optimizing their filters. They have been applied on ASC and have shown promising results. In this paper, we first propose a novel multi-channel i-vector extraction and scoring scheme for ASC, improving their performance on indoor and outdoor scenes. Second, we propose a CNN architecture that achieves promising ASC results. Further, we show that i-vectors and CNNs capture complementary information from acoustic scenes. Finally, we propose a hybrid system for ASC using multi-channel i-vectors and CNNs by utilizing a score fusion technique. Using our method, we participated in the ASC task of the DCASE-2016 challenge. Our hybrid approach achieved 1 st rank among 49 submissions, substantially improving the previous state of the art.\n    ",
        "submission_date": "2017-06-20T00:00:00",
        "last_modified_date": "2017-06-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.06544",
        "title": "Robust and Efficient Transfer Learning with Hidden-Parameter Markov Decision Processes",
        "authors": [
            "Taylor Killian",
            "Samuel Daulton",
            "George Konidaris",
            "Finale Doshi-Velez"
        ],
        "abstract": "We introduce a new formulation of the Hidden Parameter Markov Decision Process (HiP-MDP), a framework for modeling families of related tasks using low-dimensional latent embeddings. Our new framework correctly models the joint uncertainty in the latent parameters and the state space. We also replace the original Gaussian Process-based model with a Bayesian Neural Network, enabling more scalable inference. Thus, we expand the scope of the HiP-MDP to applications with higher dimensions and more complex dynamics.\n    ",
        "submission_date": "2017-06-20T00:00:00",
        "last_modified_date": "2017-10-31T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.06617",
        "title": "Observational Learning by Reinforcement Learning",
        "authors": [
            "Diana Borsa",
            "Bilal Piot",
            "R\u00e9mi Munos",
            "Olivier Pietquin"
        ],
        "abstract": "Observational learning is a type of learning that occurs as a function of observing, retaining and possibly replicating or imitating the behaviour of another agent. It is a core mechanism appearing in various instances of social learning and has been found to be employed in several intelligent species, including humans. In this paper, we investigate to what extent the explicit modelling of other agents is necessary to achieve observational learning through machine learning. Especially, we argue that observational learning can emerge from pure Reinforcement Learning (RL), potentially coupled with memory. Through simple scenarios, we demonstrate that an RL agent can leverage the information provided by the observations of an other agent performing a task in a shared environment. The other agent is only observed through the effect of its actions on the environment and never explicitly modeled. Two key aspects are borrowed from observational learning: i) the observer behaviour needs to change as a result of viewing a 'teacher' (another agent) and ii) the observer needs to be motivated somehow to engage in making use of the other agent's behaviour. The later is naturally modeled by RL, by correlating the learning agent's reward with the teacher agent's behaviour.\n    ",
        "submission_date": "2017-06-20T00:00:00",
        "last_modified_date": "2017-06-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.06636",
        "title": "Word-Entity Duet Representations for Document Ranking",
        "authors": [
            "Chenyan Xiong",
            "Jamie Callan",
            "Tie-Yan Liu"
        ],
        "abstract": "This paper presents a word-entity duet framework for utilizing knowledge bases in ad-hoc retrieval. In this work, the query and documents are modeled by word-based representations and entity-based representations. Ranking features are generated by the interactions between the two representations, incorporating information from the word space, the entity space, and the cross-space connections through the knowledge graph. To handle the uncertainties from the automatically constructed entity representations, an attention-based ranking model AttR-Duet is developed. With back-propagation from ranking labels, the model learns simultaneously how to demote noisy entities and how to rank documents with the word-entity duet. Evaluation results on TREC Web Track ad-hoc task demonstrate that all of the four-way interactions in the duet are useful, the attention mechanism successfully steers the model away from noisy entities, and together they significantly outperform both word-based and entity-based learning to rank systems.\n    ",
        "submission_date": "2017-06-20T00:00:00",
        "last_modified_date": "2017-06-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.06689",
        "title": "Chemception: A Deep Neural Network with Minimal Chemistry Knowledge Matches the Performance of Expert-developed QSAR/QSPR Models",
        "authors": [
            "Garrett B. Goh",
            "Charles Siegel",
            "Abhinav Vishnu",
            "Nathan O. Hodas",
            "Nathan Baker"
        ],
        "abstract": "In the last few years, we have seen the transformative impact of deep learning in many applications, particularly in speech recognition and computer vision. Inspired by Google's Inception-ResNet deep convolutional neural network (CNN) for image classification, we have developed \"Chemception\", a deep CNN for the prediction of chemical properties, using just the images of 2D drawings of molecules. We develop Chemception without providing any additional explicit chemistry knowledge, such as basic concepts like periodicity, or advanced features like molecular descriptors and fingerprints. We then show how Chemception can serve as a general-purpose neural network architecture for predicting toxicity, activity, and solvation properties when trained on a modest database of 600 to 40,000 compounds. When compared to multi-layer perceptron (MLP) deep neural networks trained with ECFP fingerprints, Chemception slightly outperforms in activity and solvation prediction and slightly underperforms in toxicity prediction. Having matched the performance of expert-developed QSAR/QSPR deep learning models, our work demonstrates the plausibility of using deep neural networks to assist in computational chemistry research, where the feature engineering process is performed primarily by a deep learning algorithm.\n    ",
        "submission_date": "2017-06-20T00:00:00",
        "last_modified_date": "2017-06-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.06695",
        "title": "Toward Real-Time Decentralized Reinforcement Learning using Finite Support Basis Functions",
        "authors": [
            "Kenzo Lobos-Tsunekawa",
            "David L. Leottau",
            "Javier Ruiz-del-Solar"
        ],
        "abstract": "This paper addresses the design and implementation of complex Reinforcement Learning (RL) behaviors where multi-dimensional action spaces are involved, as well as the need to execute the behaviors in real-time using robotic platforms with limited computational resources and training times. For this purpose, we propose the use of decentralized RL, in combination with finite support basis functions as alternatives to Gaussian RBF, in order to alleviate the effects of the curse of dimensionality on the action and state spaces respectively, and to reduce the computation time. As testbed, a RL based controller for the in-walk kick in NAO robots, a challenging and critical problem for soccer robotics, is used. The reported experiments show empirically that our solution saves up to 99.94% of execution time and 98.82% of memory consumption during execution, without diminishing performance compared to classical approaches.\n    ",
        "submission_date": "2017-06-20T00:00:00",
        "last_modified_date": "2017-06-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.06783",
        "title": "NPGLM: A Non-Parametric Method for Temporal Link Prediction",
        "authors": [
            "Sina Sajadmanesh",
            "Jiawei Zhang",
            "Hamid R. Rabiee"
        ],
        "abstract": "In this paper, we try to solve the problem of temporal link prediction in information networks. This implies predicting the time it takes for a link to appear in the future, given its features that have been extracted at the current network snapshot. To this end, we introduce a probabilistic non-parametric approach, called \"Non-Parametric Generalized Linear Model\" (NP-GLM), which infers the hidden underlying probability distribution of the link advent time given its features. We then present a learning algorithm for NP-GLM and an inference method to answer time-related queries. Extensive experiments conducted on both synthetic data and real-world Sina Weibo social network demonstrate the effectiveness of NP-GLM in solving temporal link prediction problem vis-a-vis competitive baselines.\n    ",
        "submission_date": "2017-06-21T00:00:00",
        "last_modified_date": "2017-06-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.06927",
        "title": "Combined Task and Motion Planning as Classical AI Planning",
        "authors": [
            "Jonathan Ferrer-Mestres",
            "Guillem Franc\u00e8s",
            "Hector Geffner"
        ],
        "abstract": "Planning in robotics is often split into task and motion planning. The high-level, symbolic task planner decides what needs to be done, while the motion planner checks feasibility and fills up geometric detail. It is known however that such a decomposition is not effective in general as the symbolic and geometrical components are not independent. In this work, we show that it is possible to compile task and motion planning problems into classical AI planning problems; i.e., planning problems over finite and discrete state spaces with a known initial state, deterministic actions, and goal states to be reached. The compilation is sound, meaning that classical plans are valid robot plans, and probabilistically complete, meaning that valid robot plans are classical plans when a sufficient number of configurations is sampled. In this approach, motion planners and collision checkers are used for the compilation, but not at planning time. The key elements that make the approach effective are 1) expressive classical AI planning languages for representing the compiled problems in compact form, that unlike PDDL make use of functions and state constraints, and 2) general width-based search algorithms capable of finding plans over huge combinatorial spaces using weak heuristics only. Empirical results are presented for a PR2 robot manipulating tens of objects, for which long plans are required.\n    ",
        "submission_date": "2017-06-21T00:00:00",
        "last_modified_date": "2017-06-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.06954",
        "title": "Web-STAR: Towards a Visual Web-Based IDE for a Story Comprehension System",
        "authors": [
            "Christos Rodosthenous",
            "Loizos Michael"
        ],
        "abstract": "In this work, we present Web-STAR, an online platform for story understanding built on top of the STAR (STory comprehension through ARgumentation) reasoning engine. This platform includes a web-based IDE, integration with the STAR system and a web service infrastructure to support integration with other systems that rely on story understanding functionality to complete their tasks. The platform also delivers a number of \"social\" features like public story sharing with a built-in commenting system, a public repository for sharing stories with the community and collaboration tools that can be used from both project team members for development and educators for teaching. Moreover, we discuss the ongoing work on adding new features and functionality to this platform.\n    ",
        "submission_date": "2017-06-20T00:00:00",
        "last_modified_date": "2017-06-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.07147",
        "title": "A Useful Motif for Flexible Task Learning in an Embodied Two-Dimensional Visual Environment",
        "authors": [
            "Kevin T. Feigelis",
            "Daniel L. K. Yamins"
        ],
        "abstract": "Animals (especially humans) have an amazing ability to learn new tasks quickly, and switch between them flexibly. How brains support this ability is largely unknown, both neuroscientifically and algorithmically. One reasonable supposition is that modules drawing on an underlying general-purpose sensory representation are dynamically allocated on a per-task basis. Recent results from neuroscience and artificial intelligence suggest the role of the general purpose visual representation may be played by a deep convolutional neural network, and give some clues how task modules based on such a representation might be discovered and constructed. In this work, we investigate module architectures in an embodied two-dimensional touchscreen environment, in which an agent's learning must occur via interactions with an environment that emits images and rewards, and accepts touches as input. This environment is designed to capture the physical structure of the task environments that are commonly deployed in visual neuroscience and psychophysics. We show that in this context, very simple changes in the nonlinear activations used by such a module can significantly influence how fast it is at learning visual tasks and how suitable it is for switching to new tasks.\n    ",
        "submission_date": "2017-06-22T00:00:00",
        "last_modified_date": "2017-06-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.07206",
        "title": "Explaining Recurrent Neural Network Predictions in Sentiment Analysis",
        "authors": [
            "Leila Arras",
            "Gr\u00e9goire Montavon",
            "Klaus-Robert M\u00fcller",
            "Wojciech Samek"
        ],
        "abstract": "Recently, a technique called Layer-wise Relevance Propagation (LRP) was shown to deliver insightful explanations in the form of input space relevances for understanding feed-forward neural network classification decisions. In the present work, we extend the usage of LRP to recurrent neural networks. We propose a specific propagation rule applicable to multiplicative connections as they arise in recurrent network architectures such as LSTMs and GRUs. We apply our technique to a word-based bi-directional LSTM model on a five-class sentiment prediction task, and evaluate the resulting LRP relevances both qualitatively and quantitatively, obtaining better results than a gradient-based related method which was used in previous work.\n    ",
        "submission_date": "2017-06-22T00:00:00",
        "last_modified_date": "2017-08-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.07230",
        "title": "Gated-Attention Architectures for Task-Oriented Language Grounding",
        "authors": [
            "Devendra Singh Chaplot",
            "Kanthashree Mysore Sathyendra",
            "Rama Kumar Pasumarthi",
            "Dheeraj Rajagopal",
            "Ruslan Salakhutdinov"
        ],
        "abstract": "To perform tasks specified by natural language instructions, autonomous agents need to extract semantically meaningful representations of language and map it to visual elements and actions in the environment. This problem is called task-oriented language grounding. We propose an end-to-end trainable neural architecture for task-oriented language grounding in 3D environments which assumes no prior linguistic or perceptual knowledge and requires only raw pixels from the environment and the natural language instruction as input. The proposed model combines the image and text representations using a Gated-Attention mechanism and learns a policy to execute the natural language instruction using standard reinforcement and imitation learning methods. We show the effectiveness of the proposed model on unseen instructions as well as unseen maps, both quantitatively and qualitatively. We also introduce a novel environment based on a 3D game engine to simulate the challenges of task-oriented language grounding over a rich set of instructions and environment states.\n    ",
        "submission_date": "2017-06-22T00:00:00",
        "last_modified_date": "2018-01-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.07294",
        "title": "A Framework for Accurate Drought Forecasting System Using Semantics-Based Data Integration Middleware",
        "authors": [
            "A. K. Akanbi",
            "M. Masinde"
        ],
        "abstract": "Technological advancement in Wireless Sensor Networks (WSN) has made it become an invaluable component of a reliable environmental monitoring system; they form the digital skin' through which to 'sense' and collect the context of the surroundings and provides information on the process leading to complex events such as drought. However, these environmental properties are measured by various heterogeneous sensors of different modalities in distributed locations making up the WSN, using different abstruse terms and vocabulary in most cases to denote the same observed property, causing data heterogeneity. Adding semantics and understanding the relationships that exist between the observed properties, and augmenting it with local indigenous knowledge is necessary for an accurate drought forecasting system. In this paper, we propose the framework for the semantic representation of sensor data and integration with indigenous knowledge on drought using a middleware for an efficient drought forecasting system.\n    ",
        "submission_date": "2017-06-20T00:00:00",
        "last_modified_date": "2017-06-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.07412",
        "title": "Rational coordination with no communication or conventions",
        "authors": [
            "Valentin Goranko",
            "Antti Kuusisto",
            "Raine R\u00f6nnholm"
        ],
        "abstract": "We study pure coordination games where in every outcome, all players have identical payoffs, 'win' or 'lose'. We identify and discuss a range of 'purely rational principles' guiding the reasoning of rational players in such games and analyze which classes of coordination games can be solved by such players with no preplay communication or conventions. We observe that it is highly nontrivial to delineate a boundary between purely rational principles and other decision methods, such as conventions, for solving such coordination games.\n    ",
        "submission_date": "2017-06-22T00:00:00",
        "last_modified_date": "2021-03-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.07506",
        "title": "Inter-Session Modeling for Session-Based Recommendation",
        "authors": [
            "Massimiliano Ruocco",
            "Ole Steinar Lillest\u00f8l Skrede",
            "Helge Langseth"
        ],
        "abstract": "In recent years, research has been done on applying Recurrent Neural Networks (RNNs) as recommender systems. Results have been promising, especially in the session-based setting where RNNs have been shown to outperform state-of-the-art models. In many of these experiments, the RNN could potentially improve the recommendations by utilizing information about the user's past sessions, in addition to its own interactions in the current session. A problem for session-based recommendation, is how to produce accurate recommendations at the start of a session, before the system has learned much about the user's current interests. We propose a novel approach that extends a RNN recommender to be able to process the user's recent sessions, in order to improve recommendations. This is done by using a second RNN to learn from recent sessions, and predict the user's interest in the current session. By feeding this information to the original RNN, it is able to improve its recommendations. Our experiments on two different datasets show that the proposed approach can significantly improve recommendations throughout the sessions, compared to a single RNN working only on the current session. The proposed model especially improves recommendations at the start of sessions, and is therefore able to deal with the cold start problem within sessions.\n    ",
        "submission_date": "2017-06-22T00:00:00",
        "last_modified_date": "2017-06-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.07515",
        "title": "Comparing Neural and Attractiveness-based Visual Features for Artwork Recommendation",
        "authors": [
            "Vicente Dominguez",
            "Pablo Messina",
            "Denis Parra",
            "Domingo Mery",
            "Christoph Trattner",
            "Alvaro Soto"
        ],
        "abstract": "Advances in image processing and computer vision in the latest years have brought about the use of visual features in artwork recommendation. Recent works have shown that visual features obtained from pre-trained deep neural networks (DNNs) perform very well for recommending digital art. Other recent works have shown that explicit visual features (EVF) based on attractiveness can perform well in preference prediction tasks, but no previous work has compared DNN features versus specific attractiveness-based visual features (e.g. brightness, texture) in terms of recommendation performance. In this work, we study and compare the performance of DNN and EVF features for the purpose of physical artwork recommendation using transactional data from UGallery, an online store of physical paintings. In addition, we perform an exploratory analysis to understand if DNN embedded features have some relation with certain EVF. Our results show that DNN features outperform EVF, that certain EVF features are more suited for physical artwork recommendation and, finally, we show evidence that certain neurons in the DNN might be partially encoding visual features such as brightness, providing an opportunity for explaining recommendations based on visual neural models.\n    ",
        "submission_date": "2017-06-22T00:00:00",
        "last_modified_date": "2017-07-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.07561",
        "title": "A-NICE-MC: Adversarial Training for MCMC",
        "authors": [
            "Jiaming Song",
            "Shengjia Zhao",
            "Stefano Ermon"
        ],
        "abstract": "Existing Markov Chain Monte Carlo (MCMC) methods are either based on general-purpose and domain-agnostic schemes which can lead to slow convergence, or hand-crafting of problem-specific proposals by an expert. We propose A-NICE-MC, a novel method to train flexible parametric Markov chain kernels to produce samples with desired properties. First, we propose an efficient likelihood-free adversarial training method to train a Markov chain and mimic a given data distribution. Then, we leverage flexible volume preserving flows to obtain parametric kernels for MCMC. Using a bootstrap approach, we show how to train efficient Markov chains to sample from a prescribed posterior distribution by iteratively improving the quality of both the model and the samples. A-NICE-MC provides the first framework to automatically design efficient domain-specific MCMC proposals. Empirical results demonstrate that A-NICE-MC combines the strong guarantees of MCMC with the expressiveness of deep neural networks, and is able to significantly outperform competing methods such as Hamiltonian Monte Carlo.\n    ",
        "submission_date": "2017-06-23T00:00:00",
        "last_modified_date": "2018-03-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.08146",
        "title": "Compressed Factorization: Fast and Accurate Low-Rank Factorization of Compressively-Sensed Data",
        "authors": [
            "Vatsal Sharan",
            "Kai Sheng Tai",
            "Peter Bailis",
            "Gregory Valiant"
        ],
        "abstract": "What learning algorithms can be run directly on compressively-sensed data? In this work, we consider the question of accurately and efficiently computing low-rank matrix or tensor factorizations given data compressed via random projections. We examine the approach of first performing factorization in the compressed domain, and then reconstructing the original high-dimensional factors from the recovered (compressed) factors. In both the matrix and tensor settings, we establish conditions under which this natural approach will provably recover the original factors. While it is well-known that random projections preserve a number of geometric properties of a dataset, our work can be viewed as showing that they can also preserve certain solutions of non-convex, NP-Hard problems like non-negative matrix factorization. We support these theoretical results with experiments on synthetic data and demonstrate the practical applicability of compressed factorization on real-world gene expression and EEG time series datasets.\n    ",
        "submission_date": "2017-06-25T00:00:00",
        "last_modified_date": "2019-05-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.08325",
        "title": "An adaptive prefix-assignment technique for symmetry reduction",
        "authors": [
            "Tommi Junttila",
            "Matti Karppa",
            "Petteri Kaski",
            "Jukka Kohonen"
        ],
        "abstract": "This paper presents a technique for symmetry reduction that adaptively assigns a prefix of variables in a system of constraints so that the generated prefix-assignments are pairwise nonisomorphic under the action of the symmetry group of the system. The technique is based on McKay's canonical extension framework [J.~Algorithms 26 (1998), no.~2, 306--324]. Among key features of the technique are (i) adaptability---the prefix sequence can be user-prescribed and truncated for compatibility with the group of symmetries; (ii) parallelizability---prefix-assignments can be processed in parallel independently of each other; (iii) versatility---the method is applicable whenever the group of symmetries can be concisely represented as the automorphism group of a vertex-colored graph; and (iv) implementability---the method can be implemented relying on a canonical labeling map for vertex-colored graphs as the only nontrivial subroutine. To demonstrate the practical applicability of our technique, we have prepared an experimental open-source implementation of the technique and carry out a set of experiments that demonstrate ability to reduce symmetry on hard instances. Furthermore, we demonstrate that the implementation effectively parallelizes to compute clusters with multiple nodes via a message-passing interface.\n    ",
        "submission_date": "2017-06-26T00:00:00",
        "last_modified_date": "2018-09-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.08329",
        "title": "The Boolean Solution Problem from the Perspective of Predicate Logic -- Extended Version",
        "authors": [
            "Christoph Wernhard"
        ],
        "abstract": "Finding solution values for unknowns in Boolean equations was a principal reasoning mode in the Algebra of Logic of the 19th century. Schr\u00f6der investigated it as Aufl\u00f6sungsproblem (solution problem). It is closely related to the modern notion of Boolean unification. Today it is commonly presented in an algebraic setting, but seems potentially useful also in knowledge representation based on predicate logic. We show that it can be modeled on the basis of first-order logic extended by second-order quantification. A wealth of classical results transfers, foundations for algorithms unfold, and connections with second-order quantifier elimination and Craig interpolation become apparent. Although for first-order inputs the set of solutions is recursively enumerable, the development of constructive methods remains a challenge. We identify some cases that allow constructions, most of them based on Craig interpolation.\n    ",
        "submission_date": "2017-06-26T00:00:00",
        "last_modified_date": "2025-07-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.08476",
        "title": "Generative Encoder-Decoder Models for Task-Oriented Spoken Dialog Systems with Chatting Capability",
        "authors": [
            "Tiancheng Zhao",
            "Allen Lu",
            "Kyusong Lee",
            "Maxine Eskenazi"
        ],
        "abstract": "Generative encoder-decoder models offer great promise in developing domain-general dialog systems. However, they have mainly been applied to open-domain conversations. This paper presents a practical and novel framework for building task-oriented dialog systems based on encoder-decoder models. This framework enables encoder-decoder models to accomplish slot-value independent decision-making and interact with external databases. Moreover, this paper shows the flexibility of the proposed method by interleaving chatting capability with a slot-filling system for better out-of-domain recovery. The models were trained on both real-user data from a bus information system and human-human chat data. Results show that the proposed framework achieves good performance in both offline evaluation metrics and in task success rate with human users.\n    ",
        "submission_date": "2017-06-26T00:00:00",
        "last_modified_date": "2017-06-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.08493",
        "title": "Towards the Evolution of Multi-Layered Neural Networks: A Dynamic Structured Grammatical Evolution Approach",
        "authors": [
            "Filipe Assun\u00e7\u00e3o",
            "Nuno Louren\u00e7o",
            "Penousal Machado",
            "Bernardete Ribeiro"
        ],
        "abstract": "Current grammar-based NeuroEvolution approaches have several shortcomings. On the one hand, they do not allow the generation of Artificial Neural Networks (ANNs composed of more than one hidden-layer. On the other, there is no way to evolve networks with more than one output neuron. To properly evolve ANNs with more than one hidden-layer and multiple output nodes there is the need to know the number of neurons available in previous layers. In this paper we introduce Dynamic Structured Grammatical Evolution (DSGE): a new genotypic representation that overcomes the aforementioned limitations. By enabling the creation of dynamic rules that specify the connection possibilities of each neuron, the methodology enables the evolution of multi-layered ANNs with more than one output neuron. Results in different classification problems show that DSGE evolves effective single and multi-layered ANNs, with a varying number of output neurons.\n    ",
        "submission_date": "2017-06-26T00:00:00",
        "last_modified_date": "2017-06-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.08501",
        "title": "A Simulator for Hedonic Games",
        "authors": [
            "Luke Harold Miles"
        ],
        "abstract": "Hedonic games are meant to model how coalitions of people form and break apart in the real world. However, it is difficult to run simulations when everything must be done by hand on paper. We present an online software that allows fast and visual simulation of several types of hedonic games. ",
        "submission_date": "2017-06-26T00:00:00",
        "last_modified_date": "2017-07-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.08502",
        "title": "Natural Language Does Not Emerge 'Naturally' in Multi-Agent Dialog",
        "authors": [
            "Satwik Kottur",
            "Jos\u00e9 M.F. Moura",
            "Stefan Lee",
            "Dhruv Batra"
        ],
        "abstract": "A number of recent works have proposed techniques for end-to-end learning of communication protocols among cooperative multi-agent populations, and have simultaneously found the emergence of grounded human-interpretable language in the protocols developed by the agents, all learned without any human supervision!\n",
        "submission_date": "2017-06-26T00:00:00",
        "last_modified_date": "2017-08-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.08514",
        "title": "Well-supported phylogenies using largest subsets of core-genes by discrete particle swarm optimization",
        "authors": [
            "Reem Alsrraj",
            "Bassam AlKindy",
            "Christophe Guyeux",
            "Laurent Philippe",
            "Jean-Fran\u00e7ois Couchot"
        ],
        "abstract": "The number of complete chloroplastic genomes increases day after day, making it possible to rethink plants phylogeny at the biomolecular era. Given a set of close plants sharing in the order of one hundred of core chloroplastic genes, this article focuses on how to extract the largest subset of sequences in order to obtain the most supported species tree. Due to computational complexity, a discrete and distributed Particle Swarm Optimization (DPSO) is proposed. It is finally applied to the core genes of Rosales order.\n    ",
        "submission_date": "2017-06-25T00:00:00",
        "last_modified_date": "2017-06-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.08568",
        "title": "Neural Question Answering at BioASQ 5B",
        "authors": [
            "Georg Wiese",
            "Dirk Weissenborn",
            "Mariana Neves"
        ],
        "abstract": "This paper describes our submission to the 2017 BioASQ challenge. We participated in Task B, Phase B which is concerned with biomedical question answering (QA). We focus on factoid and list question, using an extractive QA model, that is, we restrict our system to output substrings of the provided text snippets. At the core of our system, we use FastQA, a state-of-the-art neural QA system. We extended it with biomedical word embeddings and changed its answer layer to be able to answer list questions in addition to factoid questions. We pre-trained the model on a large-scale open-domain QA dataset, SQuAD, and then fine-tuned the parameters on the BioASQ training set. With our approach, we achieve state-of-the-art results on factoid questions and competitive results on list questions.\n    ",
        "submission_date": "2017-06-26T00:00:00",
        "last_modified_date": "2017-06-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.08605",
        "title": "Developing Bug-Free Machine Learning Systems With Formal Mathematics",
        "authors": [
            "Daniel Selsam",
            "Percy Liang",
            "David L. Dill"
        ],
        "abstract": "Noisy data, non-convex objectives, model misspecification, and numerical instability can all cause undesired behaviors in machine learning systems. As a result, detecting actual implementation errors can be extremely difficult. We demonstrate a methodology in which developers use an interactive proof assistant to both implement their system and to state a formal theorem defining what it means for their system to be correct. The process of proving this theorem interactively in the proof assistant exposes all implementation errors since any error in the program would cause the proof to fail. As a case study, we implement a new system, Certigrad, for optimizing over stochastic computation graphs, and we generate a formal (i.e. machine-checkable) proof that the gradients sampled by the system are unbiased estimates of the true mathematical gradients. We train a variational autoencoder using Certigrad and find the performance comparable to training the same model in TensorFlow.\n    ",
        "submission_date": "2017-06-26T00:00:00",
        "last_modified_date": "2017-06-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.08840",
        "title": "Gradient Episodic Memory for Continual Learning",
        "authors": [
            "David Lopez-Paz",
            "Marc'Aurelio Ranzato"
        ],
        "abstract": "One major obstacle towards AI is the poor ability of models to solve new problems quicker, and without forgetting previously acquired knowledge. To better understand this issue, we study the problem of continual learning, where the model observes, once and one by one, examples concerning a sequence of tasks. First, we propose a set of metrics to evaluate models learning over a continuum of data. These metrics characterize models not only by their test accuracy, but also in terms of their ability to transfer knowledge across tasks. Second, we propose a model for continual learning, called Gradient Episodic Memory (GEM) that alleviates forgetting, while allowing beneficial transfer of knowledge to previous tasks. Our experiments on variants of the MNIST and CIFAR-100 datasets demonstrate the strong performance of GEM when compared to the state-of-the-art.\n    ",
        "submission_date": "2017-06-26T00:00:00",
        "last_modified_date": "2022-09-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.08948",
        "title": "Training a Fully Convolutional Neural Network to Route Integrated Circuits",
        "authors": [
            "Sambhav R. Jain",
            "Kye Okabe"
        ],
        "abstract": "We present a deep, fully convolutional neural network that learns to route a circuit layout net with appropriate choice of metal tracks and wire class combinations. Inputs to the network are the encoded layouts containing spatial location of pins to be routed. After 15 fully convolutional stages followed by a score comparator, the network outputs 8 layout layers (corresponding to 4 route layers, 3 via layers and an identity-mapped pin layer) which are then decoded to obtain the routed layouts. We formulate this as a binary segmentation problem on a per-pixel per-layer basis, where the network is trained to correctly classify pixels in each layout layer to be 'on' or 'off'. To demonstrate learnability of layout design rules, we train the network on a dataset of 50,000 train and 10,000 validation samples that we generate based on certain pre-defined layout constraints. Precision, recall and $F_1$ score metrics are used to track the training progress. Our network achieves $F_1\\approx97\\%$ on the train set and $F_1\\approx92\\%$ on the validation set. We use PyTorch for implementing our model. Code is made publicly available at ",
        "submission_date": "2017-06-27T00:00:00",
        "last_modified_date": "2017-09-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.09248",
        "title": "Logic Programming for an Introductory Computer Science Course for High School Students",
        "authors": [
            "Timothy Yuen",
            "Maritz Reyes",
            "Yuanlin Zhang"
        ],
        "abstract": "This paper investigates how high school students approach computing through an introductory computer science course situated in the Logic Programming (LP) paradigm. This study shows how novice students operate within the LP paradigm while engaging in foundational computing concepts and skills, and presents a case for LP as a viable paradigm choice for introductory CS courses.\n    ",
        "submission_date": "2017-06-20T00:00:00",
        "last_modified_date": "2017-06-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.09262",
        "title": "Hierarchical Attentive Recurrent Tracking",
        "authors": [
            "Adam R. Kosiorek",
            "Alex Bewley",
            "Ingmar Posner"
        ],
        "abstract": "Class-agnostic object tracking is particularly difficult in cluttered environments as target specific discriminative models cannot be learned a priori. Inspired by how the human visual cortex employs spatial attention and separate \"where\" and \"what\" processing pathways to actively suppress irrelevant visual features, this work develops a hierarchical attentive recurrent model for single object tracking in videos. The first layer of attention discards the majority of background by selecting a region containing the object of interest, while the subsequent layers tune in on visual features particular to the tracked object. This framework is fully differentiable and can be trained in a purely data driven fashion by gradient methods. To improve training convergence, we augment the loss function with terms for a number of auxiliary tasks relevant for tracking. Evaluation of the proposed model is performed on two datasets: pedestrian tracking on the KTH activity recognition dataset and the more difficult KITTI object tracking dataset.\n    ",
        "submission_date": "2017-06-28T00:00:00",
        "last_modified_date": "2017-09-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.09370",
        "title": "DynASP2.5: Dynamic Programming on Tree Decompositions in Action",
        "authors": [
            "Johannes K. Fichte",
            "Markus Hecher",
            "Michael Morak",
            "Stefan Woltran"
        ],
        "abstract": "A vibrant theoretical research area are efficient exact parameterized algorithms. Very recent solving competitions such as the PACE challenge show that there is also increasing practical interest in the parameterized algorithms community. An important research question is whether dedicated parameterized exact algorithms exhibit certain practical relevance and one can even beat well-established problem solvers. We consider the logic-based declarative modeling language and problem solving framework Answer Set Programming (ASP). State-of-the-art ASP solvers rely considerably on Sat-based algorithms. An ASP solver (DynASP2), which is based on a classical dynamic programming on tree decompositions, has been published very recently. Unfortunately, DynASP2 can outperform modern ASP solvers on programs of small treewidth only if the question of interest is to count the number of solutions. In this paper, we describe underlying concepts of our new implementation (DynASP2.5) that shows competitive behavior to state-of-the-art ASP solvers even for finding just one solution when solving problems as the Steiner tree problem that have been modeled in ASP on graphs with low treewidth. Our implementation is based on a novel approach that we call multi-pass dynamic programming (M-DPSINC).\n    ",
        "submission_date": "2017-06-28T00:00:00",
        "last_modified_date": "2017-06-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.09520",
        "title": "Neural SLAM: Learning to Explore with External Memory",
        "authors": [
            "Jingwei Zhang",
            "Lei Tai",
            "Ming Liu",
            "Joschka Boedecker",
            "Wolfram Burgard"
        ],
        "abstract": "We present an approach for agents to learn representations of a global map from sensor data, to aid their exploration in new environments. To achieve this, we embed procedures mimicking that of traditional Simultaneous Localization and Mapping (SLAM) into the soft attention based addressing of external memory architectures, in which the external memory acts as an internal representation of the environment. This structure encourages the evolution of SLAM-like behaviors inside a completely differentiable deep neural network. We show that this approach can help reinforcement learning agents to successfully explore new environments where long-term memory is essential. We validate our approach in both challenging grid-world environments and preliminary Gazebo experiments. A video of our experiments can be found at: ",
        "submission_date": "2017-06-29T00:00:00",
        "last_modified_date": "2020-12-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.09838",
        "title": "New Fairness Metrics for Recommendation that Embrace Differences",
        "authors": [
            "Sirui Yao",
            "Bert Huang"
        ],
        "abstract": "We study fairness in collaborative-filtering recommender systems, which are sensitive to discrimination that exists in historical data. Biased data can lead collaborative filtering methods to make unfair predictions against minority groups of users. We identify the insufficiency of existing fairness metrics and propose four new metrics that address different forms of unfairness. These fairness metrics can be optimized by adding fairness terms to the learning objective. Experiments on synthetic and real data show that our new metrics can better measure fairness than the baseline, and that the fairness objectives effectively help reduce unfairness.\n    ",
        "submission_date": "2017-06-29T00:00:00",
        "last_modified_date": "2017-12-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.10059",
        "title": "A Deep Reinforcement Learning Framework for the Financial Portfolio Management Problem",
        "authors": [
            "Zhengyao Jiang",
            "Dixing Xu",
            "Jinjun Liang"
        ],
        "abstract": "Financial portfolio management is the process of constant redistribution of a fund into different financial products. This paper presents a financial-model-free Reinforcement Learning framework to provide a deep machine learning solution to the portfolio management problem. The framework consists of the Ensemble of Identical Independent Evaluators (EIIE) topology, a Portfolio-Vector Memory (PVM), an Online Stochastic Batch Learning (OSBL) scheme, and a fully exploiting and explicit reward function. This framework is realized in three instants in this work with a Convolutional Neural Network (CNN), a basic Recurrent Neural Network (RNN), and a Long Short-Term Memory (LSTM). They are, along with a number of recently reviewed or published portfolio-selection strategies, examined in three back-test experiments with a trading period of 30 minutes in a cryptocurrency market. Cryptocurrencies are electronic and decentralized alternatives to government-issued money, with Bitcoin as the best-known example of a cryptocurrency. All three instances of the framework monopolize the top three positions in all experiments, outdistancing other compared trading algorithms. Although with a high commission rate of 0.25% in the backtests, the framework is able to achieve at least 4-fold returns in 50 days.\n    ",
        "submission_date": "2017-06-30T00:00:00",
        "last_modified_date": "2017-07-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.10102",
        "title": "Tableaux for Policy Synthesis for MDPs with PCTL* Constraints",
        "authors": [
            "Peter Baumgartner",
            "Sylvie Thi\u00e9baux",
            "Felipe Trevizan"
        ],
        "abstract": "Markov decision processes (MDPs) are the standard formalism for modelling sequential decision making in stochastic environments. Policy synthesis addresses the problem of how to control or limit the decisions an agent makes so that a given specification is met. In this paper we consider PCTL*, the probabilistic counterpart of CTL*, as the specification language. Because in general the policy synthesis problem for PCTL* is undecidable, we restrict to policies whose execution history memory is finitely bounded a priori.\n",
        "submission_date": "2017-06-30T00:00:00",
        "last_modified_date": "2017-10-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.10151",
        "title": "A ROS multi-ontology references services: OWL reasoners and application prototyping issues",
        "authors": [
            "Luca Buoncompagni",
            "Alessio Capitanelli",
            "Fulvio Mastrogiovanni"
        ],
        "abstract": "This paper introduces a ROS Multi Ontology References (ARMOR) service, a general-purpose and scalable interface between robot architectures and OWL reasoners. ARMOR addresses synchronisation and communication issues among heterogeneous and distributed software components. As a guiding scenario, we consider a prototyping approach for the use of symbolic reasoning in human-robot interaction applications.\n    ",
        "submission_date": "2017-06-30T00:00:00",
        "last_modified_date": "2019-05-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.10177",
        "title": "Statistical Analysis of Dice CAPTCHA Usability",
        "authors": [
            "Darko Brodi\u0107",
            "Alessia Amelio",
            "Ivo R. Draganov"
        ],
        "abstract": "In this paper the elements of the CAPTCHA usability are analyzed. CAPTCHA, as a time progressive element in computer science, has been under constant interest of ordinary, professional as well as the scientific users of the Internet. The analysis is given based on the usability elements of CAPTCHA which are abbreviated as user-centric approach to the CAPTCHA. To demonstrate it, the specific type of Dice CAPTCHA is used in the experiment. The experiment is conducted on 190 Internet users with different demographic characteristics on laptop and tablet computers. The obtained results are statistically processed. At the end, the results are compared and conclusion of their use is drawn.\n    ",
        "submission_date": "2017-06-30T00:00:00",
        "last_modified_date": "2017-06-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.10188",
        "title": "A reliability-based approach for influence maximization using the evidence theory",
        "authors": [
            "Siwar Jendoubi",
            "Arnaud Martin"
        ],
        "abstract": "The influence maximization is the problem of finding a set of social network users, called influencers, that can trigger a large cascade of propagation. Influencers are very beneficial to make a marketing campaign goes viral through social networks for example. In this paper, we propose an influence measure that combines many influence indicators. Besides, we consider the reliability of each influence indicator and we present a distance-based process that allows to estimate the reliability of each indicator. The proposed measure is defined under the framework of the theory of belief functions. Furthermore, the reliability-based influence measure is used with an influence maximization model to select a set of users that are able to maximize the influence in the network. Finally, we present a set of experiments on a dataset collected from Twitter. These experiments show the performance of the proposed solution in detecting social influencers with good quality.\n    ",
        "submission_date": "2017-06-30T00:00:00",
        "last_modified_date": "2017-06-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.10234",
        "title": "Probabilistic Active Learning of Functions in Structural Causal Models",
        "authors": [
            "Paul K. Rubenstein",
            "Ilya Tolstikhin",
            "Philipp Hennig",
            "Bernhard Schoelkopf"
        ],
        "abstract": "We consider the problem of learning the functions computing children from parents in a Structural Causal Model once the underlying causal graph has been identified. This is in some sense the second step after causal discovery. Taking a probabilistic approach to estimating these functions, we derive a natural myopic active learning scheme that identifies the intervention which is optimally informative about all of the unknown functions jointly, given previously observed data. We test the derived algorithms on simple examples, to demonstrate that they produce a structured exploration policy that significantly improves on unstructured base-lines.\n    ",
        "submission_date": "2017-06-30T00:00:00",
        "last_modified_date": "2017-06-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1706.10239",
        "title": "Towards Understanding Generalization of Deep Learning: Perspective of Loss Landscapes",
        "authors": [
            "Lei Wu",
            "Zhanxing Zhu",
            "Weinan E"
        ],
        "abstract": "It is widely observed that deep learning models with learned parameters generalize well, even with much more model parameters than the number of training samples. We systematically investigate the underlying reasons why deep neural networks often generalize well, and reveal the difference between the minima (with the same training error) that generalize well and those they don't. We show that it is the characteristics the landscape of the loss function that explains the good generalization capability. For the landscape of loss function for deep networks, the volume of basin of attraction of good minima dominates over that of poor minima, which guarantees optimization methods with random initialization to converge to good minima. We theoretically justify our findings through analyzing 2-layer neural networks; and show that the low-complexity solutions have a small norm of Hessian matrix with respect to model parameters. For deeper networks, extensive numerical evidence helps to support our arguments.\n    ",
        "submission_date": "2017-06-30T00:00:00",
        "last_modified_date": "2017-11-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.00081",
        "title": "Synthesizing Deep Neural Network Architectures using Biological Synaptic Strength Distributions",
        "authors": [
            "A. H. Karimi",
            "M. J. Shafiee",
            "A. Ghodsi",
            "A. Wong"
        ],
        "abstract": "In this work, we perform an exploratory study on synthesizing deep neural networks using biological synaptic strength distributions, and the potential influence of different distributions on modelling performance particularly for the scenario associated with small data sets. Surprisingly, a CNN with convolutional layer synaptic strengths drawn from biologically-inspired distributions such as log-normal or correlated center-surround distributions performed relatively well suggesting a possibility for designing deep neural network architectures that do not require many data samples to learn, and can sidestep current training procedures while maintaining or boosting modelling performance.\n    ",
        "submission_date": "2017-07-01T00:00:00",
        "last_modified_date": "2017-07-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.00130",
        "title": "Sample-efficient Actor-Critic Reinforcement Learning with Supervised Data for Dialogue Management",
        "authors": [
            "Pei-Hao Su",
            "Pawel Budzianowski",
            "Stefan Ultes",
            "Milica Gasic",
            "Steve Young"
        ],
        "abstract": "Deep reinforcement learning (RL) methods have significant potential for dialogue policy optimisation. However, they suffer from a poor performance in the early stages of learning. This is especially problematic for on-line learning with real users. Two approaches are introduced to tackle this problem. Firstly, to speed up the learning process, two sample-efficient neural networks algorithms: trust region actor-critic with experience replay (TRACER) and episodic natural actor-critic with experience replay (eNACER) are presented. For TRACER, the trust region helps to control the learning step size and avoid catastrophic model changes. For eNACER, the natural gradient identifies the steepest ascent direction in policy space to speed up the convergence. Both models employ off-policy learning with experience replay to improve sample-efficiency. Secondly, to mitigate the cold start issue, a corpus of demonstration data is utilised to pre-train the models prior to on-line reinforcement learning. Combining these two approaches, we demonstrate a practical approach to learn deep RL-based dialogue policies and demonstrate their effectiveness in a task-oriented information seeking domain.\n    ",
        "submission_date": "2017-07-01T00:00:00",
        "last_modified_date": "2017-07-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.00183",
        "title": "Teacher-Student Curriculum Learning",
        "authors": [
            "Tambet Matiisen",
            "Avital Oliver",
            "Taco Cohen",
            "John Schulman"
        ],
        "abstract": "We propose Teacher-Student Curriculum Learning (TSCL), a framework for automatic curriculum learning, where the Student tries to learn a complex task and the Teacher automatically chooses subtasks from a given set for the Student to train on. We describe a family of Teacher algorithms that rely on the intuition that the Student should practice more those tasks on which it makes the fastest progress, i.e. where the slope of the learning curve is highest. In addition, the Teacher algorithms address the problem of forgetting by also choosing tasks where the Student's performance is getting worse. We demonstrate that TSCL matches or surpasses the results of carefully hand-crafted curricula in two tasks: addition of decimal numbers with LSTM and navigation in Minecraft. Using our automatically generated curriculum enabled to solve a Minecraft maze that could not be solved at all when training directly on solving the maze, and the learning was an order of magnitude faster than uniform sampling of subtasks.\n    ",
        "submission_date": "2017-07-01T00:00:00",
        "last_modified_date": "2017-11-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.00355",
        "title": "Evaluating Ising Processing Units with Integer Programming",
        "authors": [
            "Carleton Coffrin",
            "Harsha Nagarajan",
            "Russell Bent"
        ],
        "abstract": "The recent emergence of novel computational devices, such as adiabatic quantum computers, CMOS annealers, and optical parametric oscillators, present new opportunities for hybrid-optimization algorithms that are hardware accelerated by these devices. In this work, we propose the idea of an Ising processing unit as a computational abstraction for reasoning about these emerging devices. The challenges involved in using and benchmarking these devices are presented and commercial mixed integer programming solvers are proposed as a valuable tool for the validation of these disparate hardware platforms. The proposed validation methodology is demonstrated on a D-Wave 2X adiabatic quantum computer, one example of an Ising processing unit. The computational results demonstrate that the D-Wave hardware consistently produces high-quality solutions and suggests that as IPU technology matures it could become a valuable co-processor in hybrid-optimization algorithms.\n    ",
        "submission_date": "2017-07-02T00:00:00",
        "last_modified_date": "2019-06-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.00524",
        "title": "Hashing over Predicted Future Frames for Informed Exploration of Deep Reinforcement Learning",
        "authors": [
            "Haiyan Yin",
            "Jianda Chen",
            "Sinno Jialin Pan"
        ],
        "abstract": "In deep reinforcement learning (RL) tasks, an efficient exploration mechanism should be able to encourage an agent to take actions that lead to less frequent states which may yield higher accumulative future return. However, both knowing about the future and evaluating the frequentness of states are non-trivial tasks, especially for deep RL domains, where a state is represented by high-dimensional image frames. In this paper, we propose a novel informed exploration framework for deep RL, where we build the capability for an RL agent to predict over the future transitions and evaluate the frequentness for the predicted future frames in a meaningful manner. To this end, we train a deep prediction model to predict future frames given a state-action pair, and a convolutional autoencoder model to hash over the seen frames. In addition, to utilize the counts derived from the seen frames to evaluate the frequentness for the predicted frames, we tackle the challenge of matching the predicted future frames and their corresponding seen frames at the latent feature level. In this way, we derive a reliable metric for evaluating the novelty of the future direction pointed by each action, and hence inform the agent to explore the least frequent one.\n    ",
        "submission_date": "2017-07-03T00:00:00",
        "last_modified_date": "2018-04-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.00561",
        "title": "Identifying hazardousness of sewer pipeline gas mixture using classification methods: a comparative study",
        "authors": [
            "Varun Kumar Ojha",
            "Paramartha Dutta",
            "Atal Chaudhuri"
        ],
        "abstract": "In this work, we formulated a real-world problem related to sewer pipeline gas detection using the classification-based approaches. The primary goal of this work was to identify the hazardousness of sewer pipeline to offer safe and non-hazardous access to sewer pipeline workers so that the human fatalities, which occurs due to the toxic exposure of sewer gas components, can be avoided. The dataset acquired through laboratory tests, experiments, and various literature sources was organized to design a predictive model that was able to identify/classify hazardous and non-hazardous situation of sewer pipeline. To design such prediction model, several classification algorithms were used and their performances were evaluated and compared, both empirically and statistically, over the collected dataset. In addition, the performances of several ensemble methods were analyzed to understand the extent of improvement offered by these methods. The result of this comprehensive study showed that the instance-based learning algorithm performed better than many other algorithms such as multilayer perceptron, radial basis function network, support vector machine, reduced pruning tree. Similarly, it was observed that multi-scheme ensemble approach enhanced the performance of base predictors.\n    ",
        "submission_date": "2017-05-16T00:00:00",
        "last_modified_date": "2017-05-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.00703",
        "title": "Automated Problem Identification: Regression vs Classification via Evolutionary Deep Networks",
        "authors": [
            "Emmanuel Dufourq",
            "Bruce A. Bassett"
        ],
        "abstract": "Regression or classification? This is perhaps the most basic question faced when tackling a new supervised learning problem. We present an Evolutionary Deep Learning (EDL) algorithm that automatically solves this by identifying the question type with high accuracy, along with a proposed deep architecture. Typically, a significant amount of human insight and preparation is required prior to executing machine learning algorithms. For example, when creating deep neural networks, the number of parameters must be selected in advance and furthermore, a lot of these choices are made based upon pre-existing knowledge of the data such as the use of a categorical cross entropy loss function. Humans are able to study a dataset and decide whether it represents a classification or a regression problem, and consequently make decisions which will be applied to the execution of the neural network. We propose the Automated Problem Identification (API) algorithm, which uses an evolutionary algorithm interface to TensorFlow to manipulate a deep neural network to decide if a dataset represents a classification or a regression problem. We test API on 16 different classification, regression and sentiment analysis datasets with up to 10,000 features and up to 17,000 unique target values. API achieves an average accuracy of $96.3\\%$ in identifying the problem type without hardcoding any insights about the general characteristics of regression or classification problems. For example, API successfully identifies classification problems even with 1000 target values. Furthermore, the algorithm recommends which loss function to use and also recommends a neural network architecture. Our work is therefore a step towards fully automated machine learning.\n    ",
        "submission_date": "2017-07-03T00:00:00",
        "last_modified_date": "2017-07-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.00819",
        "title": "Causal Consistency of Structural Equation Models",
        "authors": [
            "Paul K. Rubenstein",
            "Sebastian Weichwald",
            "Stephan Bongers",
            "Joris M. Mooij",
            "Dominik Janzing",
            "Moritz Grosse-Wentrup",
            "Bernhard Sch\u00f6lkopf"
        ],
        "abstract": "Complex systems can be modelled at various levels of detail. Ideally, causal models of the same system should be consistent with one another in the sense that they agree in their predictions of the effects of interventions. We formalise this notion of consistency in the case of Structural Equation Models (SEMs) by introducing exact transformations between SEMs. This provides a general language to consider, for instance, the different levels of description in the following three scenarios: (a) models with large numbers of variables versus models in which the `irrelevant' or unobservable variables have been marginalised out; (b) micro-level models versus macro-level models in which the macro-variables are aggregate features of the micro-variables; (c) dynamical time series models versus models of their stationary behaviour. Our analysis stresses the importance of well specified interventions in the causal modelling process and sheds light on the interpretation of cyclic SEMs.\n    ",
        "submission_date": "2017-07-04T00:00:00",
        "last_modified_date": "2017-07-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.00836",
        "title": "DeepStory: Video Story QA by Deep Embedded Memory Networks",
        "authors": [
            "Kyung-Min Kim",
            "Min-Oh Heo",
            "Seong-Ho Choi",
            "Byoung-Tak Zhang"
        ],
        "abstract": "Question-answering (QA) on video contents is a significant challenge for achieving human-level intelligence as it involves both vision and language in real-world settings. Here we demonstrate the possibility of an AI agent performing video story QA by learning from a large amount of cartoon videos. We develop a video-story learning model, i.e. Deep Embedded Memory Networks (DEMN), to reconstruct stories from a joint scene-dialogue video stream using a latent embedding space of observed data. The video stories are stored in a long-term memory component. For a given question, an LSTM-based attention model uses the long-term memory to recall the best question-story-answer triplet by focusing on specific words containing key information. We trained the DEMN on a novel QA dataset of children's cartoon video series, Pororo. The dataset contains 16,066 scene-dialogue pairs of 20.5-hour videos, 27,328 fine-grained sentences for scene description, and 8,913 story-related QA pairs. Our experimental results show that the DEMN outperforms other QA models. This is mainly due to 1) the reconstruction of video stories in a scene-dialogue combined form that utilize the latent embedding and 2) attention. DEMN also achieved state-of-the-art results on the MovieQA benchmark.\n    ",
        "submission_date": "2017-07-04T00:00:00",
        "last_modified_date": "2017-07-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.00860",
        "title": "Conditional generation of multi-modal data using constrained embedding space mapping",
        "authors": [
            "Subhajit Chaudhury",
            "Sakyasingha Dasgupta",
            "Asim Munawar",
            "Md. A. Salam Khan",
            "Ryuki Tachibana"
        ],
        "abstract": "We present a conditional generative model that maps low-dimensional embeddings of multiple modalities of data to a common latent space hence extracting semantic relationships between them. The embedding specific to a modality is first extracted and subsequently a constrained optimization procedure is performed to project the two embedding spaces to a common manifold. The individual embeddings are generated back from this common latent space. However, in order to enable independent conditional inference for separately extracting the corresponding embeddings from the common latent space representation, we deploy a proxy variable trick - wherein, the single shared latent space is replaced by the respective separate latent spaces of each modality. We design an objective function, such that, during training we can force these separate spaces to lie close to each other, by minimizing the distance between their probability distribution functions. Experimental results demonstrate that the learned joint model can generalize to learning concepts of double MNIST digits with additional attributes of colors,from both textual and speech input.\n    ",
        "submission_date": "2017-07-04T00:00:00",
        "last_modified_date": "2017-07-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.01164",
        "title": "Kernel Feature Selection via Conditional Covariance Minimization",
        "authors": [
            "Jianbo Chen",
            "Mitchell Stern",
            "Martin J. Wainwright",
            "Michael I. Jordan"
        ],
        "abstract": "We propose a method for feature selection that employs kernel-based measures of independence to find a subset of covariates that is maximally predictive of the response. Building on past work in kernel dimension reduction, we show how to perform feature selection via a constrained optimization problem involving the trace of the conditional covariance operator. We prove various consistency results for this procedure, and also demonstrate that our method compares favorably with other state-of-the-art algorithms on a variety of synthetic and real data sets.\n    ",
        "submission_date": "2017-07-04T00:00:00",
        "last_modified_date": "2018-10-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.01166",
        "title": "Unsupervised Submodular Rank Aggregation on Score-based Permutations",
        "authors": [
            "Jun Qi",
            "Xu Liu",
            "Javier Tejedor",
            "Shunsuke Kamijo"
        ],
        "abstract": "Unsupervised rank aggregation on score-based permutations, which is widely used in many applications, has not been deeply explored yet. This work studies the use of submodular optimization for rank aggregation on score-based permutations in an unsupervised way. Specifically, we propose an unsupervised approach based on the Lovasz Bregman divergence for setting up linear structured convex and nested structured concave objective functions. In addition, stochastic optimization methods are applied in the training process and efficient algorithms for inference can be guaranteed. The experimental results from Information Retrieval, Combining Distributed Neural Networks, Influencers in Social Networks, and Distributed Automatic Speech Recognition tasks demonstrate the effectiveness of the proposed methods.\n    ",
        "submission_date": "2017-07-04T00:00:00",
        "last_modified_date": "2017-09-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.01184",
        "title": "Sentiment Identification in Code-Mixed Social Media Text",
        "authors": [
            "Souvick Ghosh",
            "Satanu Ghosh",
            "Dipankar Das"
        ],
        "abstract": "Sentiment analysis is the Natural Language Processing (NLP) task dealing with the detection and classification of sentiments in texts. While some tasks deal with identifying the presence of sentiment in the text (Subjectivity analysis), other tasks aim at determining the polarity of the text categorizing them as positive, negative and neutral. Whenever there is a presence of sentiment in the text, it has a source (people, group of people or any entity) and the sentiment is directed towards some entity, object, event or person. Sentiment analysis tasks aim to determine the subject, the target and the polarity or valence of the sentiment. In our work, we try to automatically extract sentiment (positive or negative) from Facebook posts using a machine learning ",
        "submission_date": "2017-07-04T00:00:00",
        "last_modified_date": "2017-07-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.01195",
        "title": "The impossibility of \"fairness\": a generalized impossibility result for decisions",
        "authors": [
            "Thomas Miconi"
        ],
        "abstract": "Various measures can be used to estimate bias or unfairness in a predictor. Previous work has already established that some of these measures are incompatible with each other. Here we show that, when groups differ in prevalence of the predicted event, several intuitive, reasonable measures of fairness (probability of positive prediction given occurrence or non-occurrence; probability of occurrence given prediction or non-prediction; and ratio of predictions over occurrences for each group) are all mutually exclusive: if one of them is equal among groups, the other two must differ. The only exceptions are for perfect, or trivial (always-positive or always-negative) predictors. As a consequence, any non-perfect, non-trivial predictor must necessarily be \"unfair\" under two out of three reasonable sets of criteria. This result readily generalizes to a wide range of well-known statistical quantities (sensitivity, specificity, false positive rate, precision, etc.), all of which can be divided into three mutually exclusive groups. Importantly, The results applies to all predictors, whether algorithmic or human. We conclude with possible ways to handle this effect when assessing and designing prediction methods.\n    ",
        "submission_date": "2017-07-05T00:00:00",
        "last_modified_date": "2017-09-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.01250",
        "title": "Graph Based Recommendations: From Data Representation to Feature Extraction and Application",
        "authors": [
            "Amit Tiroshi",
            "Tsvi Kuflik",
            "Shlomo Berkovsky",
            "Mohamed Ali Kaafar"
        ],
        "abstract": "Modeling users for the purpose of identifying their preferences and then personalizing services on the basis of these models is a complex task, primarily due to the need to take into consideration various explicit and implicit signals, missing or uncertain information, contextual aspects, and more. In this study, a novel generic approach for uncovering latent preference patterns from user data is proposed and evaluated. The approach relies on representing the data using graphs, and then systematically extracting graph-based features and using them to enrich the original user models. The extracted features encapsulate complex relationships between users, items, and metadata. The enhanced user models can then serve as an input to any recommendation algorithm. The proposed approach is domain-independent (demonstrated on data from movies, music, and business recommender systems), and is evaluated using several state-of-the-art machine learning methods, on different recommendation tasks, and using different evaluation metrics. The results show a unanimous improvement in the recommendation accuracy across tasks and domains. In addition, the evaluation provides a deeper analysis regarding the performance of the approach in special scenarios, including high sparsity and variability of ratings.\n    ",
        "submission_date": "2017-07-05T00:00:00",
        "last_modified_date": "2017-07-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.01357",
        "title": "Improving Content-Invariance in Gated Autoencoders for 2D and 3D Object Rotation",
        "authors": [
            "Stefan Lattner",
            "Maarten Grachten"
        ],
        "abstract": "Content-invariance in mapping codes learned by GAEs is a useful feature for various relation learning tasks. In this paper we show that the content-invariance of mapping codes for images of 2D and 3D rotated objects can be substantially improved by extending the standard GAE loss (symmetric reconstruction error) with a regularization term that penalizes the symmetric cross-reconstruction error. This error term involves reconstruction of pairs with mapping codes obtained from other pairs exhibiting similar transformations. Although this would principally require knowledge of the transformations exhibited by training pairs, our experiments show that a bootstrapping approach can sidestep this issue, and that the regularization term can effectively be used in an unsupervised setting.\n    ",
        "submission_date": "2017-07-05T00:00:00",
        "last_modified_date": "2017-07-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.01495",
        "title": "Hindsight Experience Replay",
        "authors": [
            "Marcin Andrychowicz",
            "Filip Wolski",
            "Alex Ray",
            "Jonas Schneider",
            "Rachel Fong",
            "Peter Welinder",
            "Bob McGrew",
            "Josh Tobin",
            "Pieter Abbeel",
            "Wojciech Zaremba"
        ],
        "abstract": "Dealing with sparse rewards is one of the biggest challenges in Reinforcement Learning (RL). We present a novel technique called Hindsight Experience Replay which allows sample-efficient learning from rewards which are sparse and binary and therefore avoid the need for complicated reward engineering. It can be combined with an arbitrary off-policy RL algorithm and may be seen as a form of implicit curriculum.\n",
        "submission_date": "2017-07-05T00:00:00",
        "last_modified_date": "2018-02-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.01550",
        "title": "Information-gain computation",
        "authors": [
            "Anthony Di Franco"
        ],
        "abstract": "Despite large incentives, ecorrectness in software remains an elusive goal. Declarative programming techniques, where algorithms are derived from a specification of the desired behavior, offer hope to address this problem, since there is a combinatorial reduction in complexity in programming in terms of specifications instead of algorithms, and arbitrary desired properties can be expressed and enforced in specifications directly. However, limitations on performance have prevented programming with declarative specifications from becoming a mainstream technique for general-purpose programming. To address the performance bottleneck in deriving an algorithm from a specification, I propose information-gain computation, a framework where an adaptive evaluation strategy is used to efficiently perform a search which derives algorithms that provide information about a query most directly. Within this framework, opportunities to compress the search space present themselves, which suggest that information-theoretic bounds on the performance of such a system might be articulated and a system designed to achieve them. In a preliminary empirical study of adaptive evaluation for a simple test program, the evaluation strategy adapts successfully to evaluate a query efficiently.\n    ",
        "submission_date": "2017-07-05T00:00:00",
        "last_modified_date": "2017-08-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.01555",
        "title": "A Deep Network with Visual Text Composition Behavior",
        "authors": [
            "Hongyu Guo"
        ],
        "abstract": "While natural languages are compositional, how state-of-the-art neural models achieve compositionality is still unclear. We propose a deep network, which not only achieves competitive accuracy for text classification, but also exhibits compositional behavior. That is, while creating hierarchical representations of a piece of text, such as a sentence, the lower layers of the network distribute their layer-specific attention weights to individual words. In contrast, the higher layers compose meaningful phrases and clauses, whose lengths increase as the networks get deeper until fully composing the sentence.\n    ",
        "submission_date": "2017-07-05T00:00:00",
        "last_modified_date": "2017-07-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.01606",
        "title": "Multimedia Semantic Integrity Assessment Using Joint Embedding Of Images And Text",
        "authors": [
            "Ayush Jaiswal",
            "Ekraam Sabir",
            "Wael AbdAlmageed",
            "Premkumar Natarajan"
        ],
        "abstract": "Real world multimedia data is often composed of multiple modalities such as an image or a video with associated text (e.g. captions, user comments, etc.) and metadata. Such multimodal data packages are prone to manipulations, where a subset of these modalities can be altered to misrepresent or repurpose data packages, with possible malicious intent. It is, therefore, important to develop methods to assess or verify the integrity of these multimedia packages. Using computer vision and natural language processing methods to directly compare the image (or video) and the associated caption to verify the integrity of a media package is only possible for a limited set of objects and scenes. In this paper, we present a novel deep learning-based approach for assessing the semantic integrity of multimedia packages containing images and captions, using a reference set of multimedia packages. We construct a joint embedding of images and captions with deep multimodal representation learning on the reference dataset in a framework that also provides image-caption consistency scores (ICCSs). The integrity of query media packages is assessed as the inlierness of the query ICCSs with respect to the reference dataset. We present the MultimodAl Information Manipulation dataset (MAIM), a new dataset of media packages from Flickr, which we make available to the research community. We use both the newly created dataset as well as Flickr30K and MS COCO datasets to quantitatively evaluate our proposed approach. The reference dataset does not contain unmanipulated versions of tampered query packages. Our method is able to achieve F1 scores of 0.75, 0.89 and 0.94 on MAIM, Flickr30K and MS COCO, respectively, for detecting semantically incoherent media packages.\n    ",
        "submission_date": "2017-07-06T00:00:00",
        "last_modified_date": "2018-06-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.01625",
        "title": "Optimal Vehicle Dispatching Schemes via Dynamic Pricing",
        "authors": [
            "Mengjing Chen",
            "Weiran Shen",
            "Pingzhong Tang",
            "Song Zuo"
        ],
        "abstract": "Over the past few years, ride-sharing has emerged as an effective way to relieve traffic congestion. A key problem for these platforms is to come up with a revenue-optimal (or GMV-optimal) pricing scheme and an induced vehicle dispatching policy that incorporate geographic and temporal information. In this paper, we aim to tackle this problem via an economic approach.\n",
        "submission_date": "2017-07-06T00:00:00",
        "last_modified_date": "2018-03-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.01647",
        "title": "Convergence Analysis of Optimization Algorithms",
        "authors": [
            "HyoungSeok Kim",
            "JiHoon Kang",
            "WooMyoung Park",
            "SukHyun Ko",
            "YoonHo Cho",
            "DaeSung Yu",
            "YoungSook Song",
            "JungWon Choi"
        ],
        "abstract": "The regret bound of an optimization algorithms is one of the basic criteria for evaluating the performance of the given algorithm. By inspecting the differences between the regret bounds of traditional algorithms and adaptive one, we provide a guide for choosing an optimizer with respect to the given data set and the loss function. For analysis, we assume that the loss function is convex and its gradient is Lipschitz continuous.\n    ",
        "submission_date": "2017-07-06T00:00:00",
        "last_modified_date": "2017-07-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.01700",
        "title": "CNN features are also great at unsupervised classification",
        "authors": [
            "Joris Gu\u00e9rin",
            "Olivier Gibaru",
            "St\u00e9phane Thiery",
            "Eric Nyiri"
        ],
        "abstract": "This paper aims at providing insight on the transferability of deep CNN features to unsupervised problems. We study the impact of different pretrained CNN feature extractors on the problem of image set clustering for object classification as well as fine-grained classification. We propose a rather straightforward pipeline combining deep-feature extraction using a CNN pretrained on ImageNet and a classic clustering algorithm to classify sets of images. This approach is compared to state-of-the-art algorithms in image-clustering and provides better results. These results strengthen the belief that supervised training of deep CNN on large datasets, with a large variability of classes, extracts better features than most carefully designed engineering approaches, even for unsupervised tasks. We also validate our approach on a robotic application, consisting in sorting and storing objects smartly based on clustering.\n    ",
        "submission_date": "2017-07-06T00:00:00",
        "last_modified_date": "2018-09-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.01736",
        "title": "Cross-linguistic differences and similarities in image descriptions",
        "authors": [
            "Emiel van Miltenburg",
            "Desmond Elliott",
            "Piek Vossen"
        ],
        "abstract": "Automatic image description systems are commonly trained and evaluated on large image description datasets. Recently, researchers have started to collect such datasets for languages other than English. An unexplored question is how different these datasets are from English and, if there are any differences, what causes them to differ. This paper provides a cross-linguistic comparison of Dutch, English, and German image descriptions. We find that these descriptions are similar in many respects, but the familiarity of crowd workers with the subjects of the images has a noticeable influence on description specificity.\n    ",
        "submission_date": "2017-07-06T00:00:00",
        "last_modified_date": "2017-08-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.01865",
        "title": "An Online Development Environment for Answer Set Programming",
        "authors": [
            "Elias Marcopoulos",
            "Christian Reotutar",
            "Yuanlin Zhang"
        ],
        "abstract": "Recent progress in logic programming (e.g., the development of the Answer Set Programming paradigm) has made it possible to teach it to general undergraduate and even high school students. Given the limited exposure of these students to computer science, the complexity of downloading, installing and using tools for writing logic programs could be a major barrier for logic programming to reach a much wider audience. We developed an online answer set programming environment with a self contained file system and a simple interface, allowing users to write logic programs and perform several tasks over the programs.\n    ",
        "submission_date": "2017-06-20T00:00:00",
        "last_modified_date": "2017-06-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.01961",
        "title": "Long-Term Memory Networks for Question Answering",
        "authors": [
            "Fenglong Ma",
            "Radha Chitta",
            "Saurabh Kataria",
            "Jing Zhou",
            "Palghat Ramesh",
            "Tong Sun",
            "Jing Gao"
        ],
        "abstract": "Question answering is an important and difficult task in the natural language processing domain, because many basic natural language processing tasks can be cast into a question answering task. Several deep neural network architectures have been developed recently, which employ memory and inference components to memorize and reason over text information, and generate answers to questions. However, a major drawback of many such models is that they are capable of only generating single-word answers. In addition, they require large amount of training data to generate accurate answers. In this paper, we introduce the Long-Term Memory Network (LTMN), which incorporates both an external memory module and a Long Short-Term Memory (LSTM) module to comprehend the input data and generate multi-word answers. The LTMN model can be trained end-to-end using back-propagation and requires minimal supervision. We test our model on two synthetic data sets (based on Facebook's bAbI data set) and the real-world Stanford question answering data set, and show that it can achieve state-of-the-art performance.\n    ",
        "submission_date": "2017-07-06T00:00:00",
        "last_modified_date": "2017-07-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.02033",
        "title": "Networked Fairness in Cake Cutting",
        "authors": [
            "Xiaohui Bei",
            "Youming Qiao",
            "Shengyu Zhang"
        ],
        "abstract": "We introduce a graphical framework for fair division in cake cutting, where comparisons between agents are limited by an underlying network structure. We generalize the classical fairness notions of envy-freeness and proportionality to this graphical setting. Given a simple undirected graph G, an allocation is envy-free on G if no agent envies any of her neighbor's share, and is proportional on G if every agent values her own share no less than the average among her neighbors, with respect to her own measure. These generalizations open new research directions in developing simple and efficient algorithms that can produce fair allocations under specific graph structures.\n",
        "submission_date": "2017-07-07T00:00:00",
        "last_modified_date": "2017-07-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.02174",
        "title": "Methods for finding leader--follower equilibria with multiple followers",
        "authors": [
            "Nicola Basilico",
            "Stefano Coniglio",
            "Nicola Gatti"
        ],
        "abstract": "The concept of leader--follower (or Stackelberg) equilibrium plays a central role in a number of real--world applications of game theory. While the case with a single follower has been thoroughly investigated, results with multiple followers are only sporadic and the problem of designing and evaluating computationally tractable equilibrium-finding algorithms is still largely open. In this work, we focus on the fundamental case where multiple followers play a Nash equilibrium once the leader has committed to a strategy---as we illustrate, the corresponding equilibrium finding problem can be easily shown to be $\\mathcal{FNP}$--hard and not in Poly--$\\mathcal{APX}$ unless $\\mathcal{P} = \\mathcal{NP}$ and therefore it is one among the hardest problems to solve and approximate. We propose nonconvex mathematical programming formulations and global optimization methods to find both exact and approximate equilibria, as well as a heuristic black box algorithm. All the methods and formulations that we introduce are thoroughly evaluated computationally.\n    ",
        "submission_date": "2017-07-07T00:00:00",
        "last_modified_date": "2017-07-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.02275",
        "title": "A parallel corpus of Python functions and documentation strings for automated code documentation and code generation",
        "authors": [
            "Antonio Valerio Miceli Barone",
            "Rico Sennrich"
        ],
        "abstract": "Automated documentation of programming source code and automated code generation from natural language are challenging tasks of both practical and scientific interest. Progress in these areas has been limited by the low availability of parallel corpora of code and natural language descriptions, which tend to be small and constrained to specific domains.\n",
        "submission_date": "2017-07-07T00:00:00",
        "last_modified_date": "2017-07-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.02353",
        "title": "Evaluating race and sex diversity in the world's largest companies using deep neural networks",
        "authors": [
            "Konstantin Chekanov",
            "Polina Mamoshina",
            "Roman V. Yampolskiy",
            "Radu Timofte",
            "Morten Scheibye-Knudsen",
            "Alex Zhavoronkov"
        ],
        "abstract": "Diversity is one of the fundamental properties for the survival of species, populations, and organizations. Recent advances in deep learning allow for the rapid and automatic assessment of organizational diversity and possible discrimination by race, sex, age and other parameters. Automating the process of assessing the organizational diversity using the deep neural networks and eliminating the human factor may provide a set of real-time unbiased reports to all stakeholders. In this pilot study we applied the deep-learned predictors of race and sex to the executive management and board member profiles of the 500 largest companies from the 2016 Forbes Global 2000 list and compared the predicted ratios to the ratios within each company's country of origin and ranked them by the sex-, age- and race- diversity index (DI). While the study has many limitations and no claims are being made concerning the individual companies, it demonstrates a method for the rapid and impartial assessment of organizational diversity using deep neural networks.\n    ",
        "submission_date": "2017-07-09T00:00:00",
        "last_modified_date": "2017-07-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.02385",
        "title": "Evaluating Social Networks Using Task-Focused Network Inference",
        "authors": [
            "Ivan Brugere",
            "Chris Kanich",
            "Tanya Y. Berger-Wolf"
        ],
        "abstract": "Networks are representations of complex underlying social processes. However, the same given network may be more suitable to model one behavior of individuals than another. In many cases, aggregate population models may be more effective than modeling on the network. We present a general framework for evaluating the suitability of given networks for a set of predictive tasks of interest, compared against alternative, networks inferred from data. We present several interpretable network models and measures for our comparison. We apply this general framework to the case study on collective classification of music preferences in a newly available dataset of the ",
        "submission_date": "2017-07-08T00:00:00",
        "last_modified_date": "2017-07-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.02459",
        "title": "Improving Multilingual Named Entity Recognition with Wikipedia Entity Type Mapping",
        "authors": [
            "Jian Ni",
            "Radu Florian"
        ],
        "abstract": "The state-of-the-art named entity recognition (NER) systems are statistical machine learning models that have strong generalization capability (i.e., can recognize unseen entities that do not appear in training data) based on lexical and contextual information. However, such a model could still make mistakes if its features favor a wrong entity type. In this paper, we utilize Wikipedia as an open knowledge base to improve multilingual NER systems. Central to our approach is the construction of high-accuracy, high-coverage multilingual Wikipedia entity type mappings. These mappings are built from weakly annotated data and can be extended to new languages with no human annotation or language-dependent knowledge involved. Based on these mappings, we develop several approaches to improve an NER system. We evaluate the performance of the approaches via experiments on NER systems trained for 6 languages. Experimental results show that the proposed approaches are effective in improving the accuracy of such systems on unseen entities, especially when a system is applied to a new domain or it is trained with little training data (up to 18.3 F1 score improvement).\n    ",
        "submission_date": "2017-07-08T00:00:00",
        "last_modified_date": "2017-07-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.02657",
        "title": "PELESent: Cross-domain polarity classification using distant supervision",
        "authors": [
            "Edilson A. Corr\u00eaa Jr",
            "Vanessa Q. Marinho",
            "Leandro B. dos Santos",
            "Thales F. C. Bertaglia",
            "Marcos V. Treviso",
            "Henrico B. Brum"
        ],
        "abstract": "The enormous amount of texts published daily by Internet users has fostered the development of methods to analyze this content in several natural language processing areas, such as sentiment analysis. The main goal of this task is to classify the polarity of a message. Even though many approaches have been proposed for sentiment analysis, some of the most successful ones rely on the availability of large annotated corpus, which is an expensive and time-consuming process. In recent years, distant supervision has been used to obtain larger datasets. So, inspired by these techniques, in this paper we extend such approaches to incorporate popular graphic symbols used in electronic messages, the emojis, in order to create a large sentiment corpus for Portuguese. Trained on almost one million tweets, several models were tested in both same domain and cross-domain corpora. Our methods obtained very competitive results in five annotated corpora from mixed domains (Twitter and product reviews), which proves the domain-independent property of such approach. In addition, our results suggest that the combination of emoticons and emojis is able to properly capture the sentiment of a message.\n    ",
        "submission_date": "2017-07-09T00:00:00",
        "last_modified_date": "2017-07-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.02774",
        "title": "Understanding State Preferences With Text As Data: Introducing the UN General Debate Corpus",
        "authors": [
            "Alexander Baturo",
            "Niheer Dasandi",
            "Slava J. Mikhaylov"
        ],
        "abstract": "Every year at the United Nations, member states deliver statements during the General Debate discussing major issues in world politics. These speeches provide invaluable information on governments' perspectives and preferences on a wide range of issues, but have largely been overlooked in the study of international politics. This paper introduces a new dataset consisting of over 7,701 English-language country statements from 1970-2016. We demonstrate how the UN General Debate Corpus (UNGDC) can be used to derive country positions on different policy dimensions using text analytic methods. The paper provides applications of these estimates, demonstrating the contribution the UNGDC can make to the study of international politics.\n    ",
        "submission_date": "2017-07-10T00:00:00",
        "last_modified_date": "2017-07-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.02812",
        "title": "Towards Crafting Text Adversarial Samples",
        "authors": [
            "Suranjana Samanta",
            "Sameep Mehta"
        ],
        "abstract": "Adversarial samples are strategically modified samples, which are crafted with the purpose of fooling a classifier at hand. An attacker introduces specially crafted adversarial samples to a deployed classifier, which are being mis-classified by the classifier. However, the samples are perceived to be drawn from entirely different classes and thus it becomes hard to detect the adversarial samples. Most of the prior works have been focused on synthesizing adversarial samples in the image domain. In this paper, we propose a new method of crafting adversarial text samples by modification of the original samples. Modifications of the original text samples are done by deleting or replacing the important or salient words in the text or by introducing new words in the text sample. Our algorithm works best for the datasets which have sub-categories within each of the classes of examples. While crafting adversarial samples, one of the key constraint is to generate meaningful sentences which can at pass off as legitimate from language (English) viewpoint. Experimental results on IMDB movie review dataset for sentiment analysis and Twitter dataset for gender detection show the efficiency of our proposed method.\n    ",
        "submission_date": "2017-07-10T00:00:00",
        "last_modified_date": "2017-07-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.02919",
        "title": "A Brief Survey of Text Mining: Classification, Clustering and Extraction Techniques",
        "authors": [
            "Mehdi Allahyari",
            "Seyedamin Pouriyeh",
            "Mehdi Assefi",
            "Saied Safaei",
            "Elizabeth D. Trippe",
            "Juan B. Gutierrez",
            "Krys Kochut"
        ],
        "abstract": "The amount of text that is generated every day is increasing dramatically. This tremendous volume of mostly unstructured text cannot be simply processed and perceived by computers. Therefore, efficient and effective techniques and algorithms are required to discover useful patterns. Text mining is the task of extracting meaningful information from text, which has gained significant attentions in recent years. In this paper, we describe several of the most fundamental text mining tasks and techniques including text pre-processing, classification and clustering. Additionally, we briefly explain text mining in biomedical and health care domains.\n    ",
        "submission_date": "2017-07-10T00:00:00",
        "last_modified_date": "2017-07-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.02920",
        "title": "Vision-Based Multi-Task Manipulation for Inexpensive Robots Using End-To-End Learning from Demonstration",
        "authors": [
            "Rouhollah Rahmatizadeh",
            "Pooya Abolghasemi",
            "Ladislau B\u00f6l\u00f6ni",
            "Sergey Levine"
        ],
        "abstract": "We propose a technique for multi-task learning from demonstration that trains the controller of a low-cost robotic arm to accomplish several complex picking and placing tasks, as well as non-prehensile manipulation. The controller is a recurrent neural network using raw images as input and generating robot arm trajectories, with the parameters shared across the tasks. The controller also combines VAE-GAN-based reconstruction with autoregressive multimodal action prediction. Our results demonstrate that it is possible to learn complex manipulation tasks, such as picking up a towel, wiping an object, and depositing the towel to its previous position, entirely from raw images with direct behavior cloning. We show that weight sharing and reconstruction-based regularization substantially improve generalization and robustness, and training on multiple tasks simultaneously increases the success rate on all tasks.\n    ",
        "submission_date": "2017-07-10T00:00:00",
        "last_modified_date": "2018-04-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.02968",
        "title": "Revisiting Unreasonable Effectiveness of Data in Deep Learning Era",
        "authors": [
            "Chen Sun",
            "Abhinav Shrivastava",
            "Saurabh Singh",
            "Abhinav Gupta"
        ],
        "abstract": "The success of deep learning in vision can be attributed to: (a) models with high capacity; (b) increased computational power; and (c) availability of large-scale labeled data. Since 2012, there have been significant advances in representation capabilities of the models and computational capabilities of GPUs. But the size of the biggest dataset has surprisingly remained constant. What will happen if we increase the dataset size by 10x or 100x? This paper takes a step towards clearing the clouds of mystery surrounding the relationship between `enormous data' and visual deep learning. By exploiting the JFT-300M dataset which has more than 375M noisy labels for 300M images, we investigate how the performance of current vision tasks would change if this data was used for representation learning. Our paper delivers some surprising (and some expected) findings. First, we find that the performance on vision tasks increases logarithmically based on volume of training data size. Second, we show that representation learning (or pre-training) still holds a lot of promise. One can improve performance on many vision tasks by just training a better base model. Finally, as expected, we present new state-of-the-art results for different vision tasks including image classification, object detection, semantic segmentation and human pose estimation. Our sincere hope is that this inspires vision community to not undervalue the data and develop collective efforts in building larger datasets.\n    ",
        "submission_date": "2017-07-10T00:00:00",
        "last_modified_date": "2017-08-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.03017",
        "title": "Learning Visual Reasoning Without Strong Priors",
        "authors": [
            "Ethan Perez",
            "Harm de Vries",
            "Florian Strub",
            "Vincent Dumoulin",
            "Aaron Courville"
        ],
        "abstract": "Achieving artificial visual reasoning - the ability to answer image-related questions which require a multi-step, high-level process - is an important step towards artificial general intelligence. This multi-modal task requires learning a question-dependent, structured reasoning process over images from language. Standard deep learning approaches tend to exploit biases in the data rather than learn this underlying structure, while leading methods learn to visually reason successfully but are hand-crafted for reasoning. We show that a general-purpose, Conditional Batch Normalization approach achieves state-of-the-art results on the CLEVR Visual Reasoning benchmark with a 2.4% error rate. We outperform the next best end-to-end method (4.5%) and even methods that use extra supervision (3.1%). We probe our model to shed light on how it reasons, showing it has learned a question-dependent, multi-step process. Previous work has operated under the assumption that visual reasoning calls for a specialized architecture, but we show that a general architecture with proper conditioning can learn to visually reason effectively.\n    ",
        "submission_date": "2017-07-10T00:00:00",
        "last_modified_date": "2017-12-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.03034",
        "title": "Learning Heuristic Search via Imitation",
        "authors": [
            "Mohak Bhardwaj",
            "Sanjiban Choudhury",
            "Sebastian Scherer"
        ],
        "abstract": "Robotic motion planning problems are typically solved by constructing a search tree of valid maneuvers from a start to a goal configuration. Limited onboard computation and real-time planning constraints impose a limit on how large this search tree can grow. Heuristics play a crucial role in such situations by guiding the search towards potentially good directions and consequently minimizing search effort. Moreover, it must infer such directions in an efficient manner using only the information uncovered by the search up until that time. However, state of the art methods do not address the problem of computing a heuristic that explicitly minimizes search effort. In this paper, we do so by training a heuristic policy that maps the partial information from the search to decide which node of the search tree to expand. Unfortunately, naively training such policies leads to slow convergence and poor local minima. We present SaIL, an efficient algorithm that trains heuristic policies by imitating \"clairvoyant oracles\" - oracles that have full information about the world and demonstrate decisions that minimize search effort. We leverage the fact that such oracles can be efficiently computed using dynamic programming and derive performance guarantees for the learnt heuristic. We validate the approach on a spectrum of environments which show that SaIL consistently outperforms state of the art algorithms. Our approach paves the way forward for learning heuristics that demonstrate an anytime nature - finding feasible solutions quickly and incrementally refining it over time.\n    ",
        "submission_date": "2017-07-10T00:00:00",
        "last_modified_date": "2017-07-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.03167",
        "title": "RegNet: Multimodal Sensor Registration Using Deep Neural Networks",
        "authors": [
            "Nick Schneider",
            "Florian Piewak",
            "Christoph Stiller",
            "Uwe Franke"
        ],
        "abstract": "In this paper, we present RegNet, the first deep convolutional neural network (CNN) to infer a 6 degrees of freedom (DOF) extrinsic calibration between multimodal sensors, exemplified using a scanning LiDAR and a monocular camera. Compared to existing approaches, RegNet casts all three conventional calibration steps (feature extraction, feature matching and global regression) into a single real-time capable CNN. Our method does not require any human interaction and bridges the gap between classical offline and target-less online calibration approaches as it provides both a stable initial estimation as well as a continuous online correction of the extrinsic parameters. During training we randomly decalibrate our system in order to train RegNet to infer the correspondence between projected depth measurements and RGB image and finally regress the extrinsic calibration. Additionally, with an iterative execution of multiple CNNs, that are trained on different magnitudes of decalibration, our approach compares favorably to state-of-the-art methods in terms of a mean calibration error of 0.28 degrees for the rotational and 6 cm for the translation components even for large decalibrations up to 1.5 m and 20 degrees.\n    ",
        "submission_date": "2017-07-11T00:00:00",
        "last_modified_date": "2017-07-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.03374",
        "title": "Imitation from Observation: Learning to Imitate Behaviors from Raw Video via Context Translation",
        "authors": [
            "YuXuan Liu",
            "Abhishek Gupta",
            "Pieter Abbeel",
            "Sergey Levine"
        ],
        "abstract": "Imitation learning is an effective approach for autonomous systems to acquire control policies when an explicit reward function is unavailable, using supervision provided as demonstrations from an expert, typically a human operator. However, standard imitation learning methods assume that the agent receives examples of observation-action tuples that could be provided, for instance, to a supervised learning algorithm. This stands in contrast to how humans and animals imitate: we observe another person performing some behavior and then figure out which actions will realize that behavior, compensating for changes in viewpoint, surroundings, object positions and types, and other factors. We term this kind of imitation learning \"imitation-from-observation,\" and propose an imitation learning method based on video prediction with context translation and deep reinforcement learning. This lifts the assumption in imitation learning that the demonstration should consist of observations in the same environment configuration, and enables a variety of interesting applications, including learning robotic skills that involve tool use simply by observing videos of human tool use. Our experimental results show the effectiveness of our approach in learning a wide range of real-world robotic tasks modeled after common household chores from videos of a human demonstrator, including sweeping, ladling almonds, pushing objects as well as a number of tasks in simulation.\n    ",
        "submission_date": "2017-07-11T00:00:00",
        "last_modified_date": "2018-06-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.03490",
        "title": "Detecting Policy Preferences and Dynamics in the UN General Debate with Neural Word Embeddings",
        "authors": [
            "Stefano Gurciullo",
            "Slava Mikhaylov"
        ],
        "abstract": "Foreign policy analysis has been struggling to find ways to measure policy preferences and paradigm shifts in international political systems. This paper presents a novel, potential solution to this challenge, through the application of a neural word embedding (Word2vec) model on a dataset featuring speeches by heads of state or government in the United Nations General Debate. The paper provides three key contributions based on the output of the Word2vec model. First, it presents a set of policy attention indices, synthesizing the semantic proximity of political speeches to specific policy themes. Second, it introduces country-specific semantic centrality indices, based on topological analyses of countries' semantic positions with respect to each other. Third, it tests the hypothesis that there exists a statistical relation between the semantic content of political speeches and UN voting behavior, falsifying it and suggesting that political speeches contain information of different nature then the one behind voting outcomes. The paper concludes with a discussion of the practical use of its results and consequences for foreign policy analysis, public accountability, and transparency.\n    ",
        "submission_date": "2017-07-11T00:00:00",
        "last_modified_date": "2017-07-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.03501",
        "title": "NO Need to Worry about Adversarial Examples in Object Detection in Autonomous Vehicles",
        "authors": [
            "Jiajun Lu",
            "Hussein Sibai",
            "Evan Fabry",
            "David Forsyth"
        ],
        "abstract": "It has been shown that most machine learning algorithms are susceptible to adversarial perturbations. Slightly perturbing an image in a carefully chosen direction in the image space may cause a trained neural network model to misclassify it. Recently, it was shown that physical adversarial examples exist: printing perturbed images then taking pictures of them would still result in misclassification. This raises security and safety concerns.\n",
        "submission_date": "2017-07-12T00:00:00",
        "last_modified_date": "2017-07-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.03502",
        "title": "Deep Learning for Sensor-based Activity Recognition: A Survey",
        "authors": [
            "Jindong Wang",
            "Yiqiang Chen",
            "Shuji Hao",
            "Xiaohui Peng",
            "Lisha Hu"
        ],
        "abstract": "Sensor-based activity recognition seeks the profound high-level knowledge about human activities from multitudes of low-level sensor readings. Conventional pattern recognition approaches have made tremendous progress in the past years. However, those methods often heavily rely on heuristic hand-crafted feature extraction, which could hinder their generalization performance. Additionally, existing methods are undermined for unsupervised and incremental learning tasks. Recently, the recent advancement of deep learning makes it possible to perform automatic high-level feature extraction thus achieves promising performance in many areas. Since then, deep learning based methods have been widely adopted for the sensor-based activity recognition tasks. This paper surveys the recent advance of deep learning based sensor-based activity recognition. We summarize existing literature from three aspects: sensor modality, deep model, and application. We also present detailed insights on existing work and propose grand challenges for future research.\n    ",
        "submission_date": "2017-07-12T00:00:00",
        "last_modified_date": "2017-12-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.03804",
        "title": "Source-Target Inference Models for Spatial Instruction Understanding",
        "authors": [
            "Hao Tan",
            "Mohit Bansal"
        ],
        "abstract": "Models that can execute natural language instructions for situated robotic tasks such as assembly and navigation have several useful applications in homes, offices, and remote scenarios. We study the semantics of spatially-referred configuration and arrangement instructions, based on the challenging Bisk-2016 blank-labeled block dataset. This task involves finding a source block and moving it to the target position (mentioned via a reference block and offset), where the blocks have no names or colors and are just referred to via spatial location features. We present novel models for the subtasks of source block classification and target position regression, based on joint-loss language and spatial-world representation learning, as well as CNN-based and dual attention models to compute the alignment between the world blocks and the instruction phrases. For target position prediction, we compare two inference approaches: annealed sampling via policy gradient versus expectation inference via supervised regression. Our models achieve the new state-of-the-art on this task, with an improvement of 47% on source block accuracy and 22% on target position distance.\n    ",
        "submission_date": "2017-07-12T00:00:00",
        "last_modified_date": "2017-11-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.03938",
        "title": "Representation Learning for Grounded Spatial Reasoning",
        "authors": [
            "Michael Janner",
            "Karthik Narasimhan",
            "Regina Barzilay"
        ],
        "abstract": "The interpretation of spatial references is highly contextual, requiring joint inference over both language and the environment. We consider the task of spatial reasoning in a simulated environment, where an agent can act and receive rewards. The proposed model learns a representation of the world steered by instruction text. This design allows for precise alignment of local neighborhoods with corresponding verbalizations, while also handling global references in the instructions. We train our model with reinforcement learning using a variant of generalized value iteration. The model outperforms state-of-the-art approaches on several metrics, yielding a 45% reduction in goal localization error.\n    ",
        "submission_date": "2017-07-13T00:00:00",
        "last_modified_date": "2017-11-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.03981",
        "title": "Learning Photography Aesthetics with Deep CNNs",
        "authors": [
            "Gautam Malu",
            "Raju S. Bapi",
            "Bipin Indurkhya"
        ],
        "abstract": "Automatic photo aesthetic assessment is a challenging artificial intelligence task. Existing computational approaches have focused on modeling a single aesthetic score or a class (good or bad), however these do not provide any details on why the photograph is good or bad, or which attributes contribute to the quality of the photograph. To obtain both accuracy and human interpretation of the score, we advocate learning the aesthetic attributes along with the prediction of the overall score. For this purpose, we propose a novel multitask deep convolution neural network, which jointly learns eight aesthetic attributes along with the overall aesthetic score. We report near human performance in the prediction of the overall aesthetic score. To understand the internal representation of these attributes in the learned model, we also develop the visualization technique using back propagation of gradients. These visualizations highlight the important image regions for the corresponding attributes, thus providing insights about model's representation of these attributes. We showcase the diversity and complexity associated with different attributes through a qualitative analysis of the activation maps.\n    ",
        "submission_date": "2017-07-13T00:00:00",
        "last_modified_date": "2017-07-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.04035",
        "title": "Kafnets: kernel-based non-parametric activation functions for neural networks",
        "authors": [
            "Simone Scardapane",
            "Steven Van Vaerenbergh",
            "Simone Totaro",
            "Aurelio Uncini"
        ],
        "abstract": "Neural networks are generally built by interleaving (adaptable) linear layers with (fixed) nonlinear activation functions. To increase their flexibility, several authors have proposed methods for adapting the activation functions themselves, endowing them with varying degrees of flexibility. None of these approaches, however, have gained wide acceptance in practice, and research in this topic remains open. In this paper, we introduce a novel family of flexible activation functions that are based on an inexpensive kernel expansion at every neuron. Leveraging over several properties of kernel-based models, we propose multiple variations for designing and initializing these kernel activation functions (KAFs), including a multidimensional scheme allowing to nonlinearly combine information from different paths in the network. The resulting KAFs can approximate any mapping defined over a subset of the real line, either convex or nonconvex. Furthermore, they are smooth over their entire domain, linear in their parameters, and they can be regularized using any known scheme, including the use of $\\ell_1$ penalties to enforce sparseness. To the best of our knowledge, no other known model satisfies all these properties simultaneously. In addition, we provide a relatively complete overview on alternative techniques for adapting the activation functions, which is currently lacking in the literature. A large set of experiments validates our proposal.\n    ",
        "submission_date": "2017-07-13T00:00:00",
        "last_modified_date": "2017-11-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.04046",
        "title": "Stable Distribution Alignment Using the Dual of the Adversarial Distance",
        "authors": [
            "Ben Usman",
            "Kate Saenko",
            "Brian Kulis"
        ],
        "abstract": "Methods that align distributions by minimizing an adversarial distance between them have recently achieved impressive results. However, these approaches are difficult to optimize with gradient descent and they often do not converge well without careful hyperparameter tuning and proper initialization. We investigate whether turning the adversarial min-max problem into an optimization problem by replacing the maximization part with its dual improves the quality of the resulting alignment and explore its connections to Maximum Mean Discrepancy. Our empirical results suggest that using the dual formulation for the restricted family of linear discriminators results in a more stable convergence to a desirable solution when compared with the performance of a primal min-max GAN-like objective and an MMD objective under the same restrictions. We test our hypothesis on the problem of aligning two synthetic point clouds on a plane and on a real-image domain adaptation problem on digits. In both cases, the dual formulation yields an iterative procedure that gives more stable and monotonic improvement over time.\n    ",
        "submission_date": "2017-07-13T00:00:00",
        "last_modified_date": "2018-01-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.04092",
        "title": "Disentangling Motion, Foreground and Background Features in Videos",
        "authors": [
            "Xunyu Lin",
            "Victor Campos",
            "Xavier Giro-i-Nieto",
            "Jordi Torres",
            "Cristian Canton Ferrer"
        ],
        "abstract": "This paper introduces an unsupervised framework to extract semantically rich features for video representation. Inspired by how the human visual system groups objects based on motion cues, we propose a deep convolutional neural network that disentangles motion, foreground and background information. The proposed architecture consists of a 3D convolutional feature encoder for blocks of 16 frames, which is trained for reconstruction tasks over the first and last frames of the sequence. A preliminary supervised experiment was conducted to verify the feasibility of proposed method by training the model with a fraction of videos from the UCF-101 dataset taking as ground truth the bounding boxes around the activity regions. Qualitative results indicate that the network can successfully segment foreground and background in videos as well as update the foreground appearance based on disentangled motion features. The benefits of these learned features are shown in a discriminative classification task, where initializing the network with the proposed pretraining method outperforms both random initialization and autoencoder pretraining. Our model and source code are publicly available at ",
        "submission_date": "2017-07-13T00:00:00",
        "last_modified_date": "2017-07-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.04242",
        "title": "Neural Networks for Information Retrieval",
        "authors": [
            "Tom Kenter",
            "Alexey Borisov",
            "Christophe Van Gysel",
            "Mostafa Dehghani",
            "Maarten de Rijke",
            "Bhaskar Mitra"
        ],
        "abstract": "Machine learning plays a role in many aspects of modern IR systems, and deep learning is applied in all of them. The fast pace of modern-day research has given rise to many different approaches for many different IR problems. The amount of information available can be overwhelming both for junior students and for experienced researchers looking for new research topics and directions. Additionally, it is interesting to see what key insights into IR problems the new technologies are able to give us. The aim of this full-day tutorial is to give a clear overview of current tried-and-trusted neural methods in IR and how they benefit IR research. It covers key architectures, as well as the most promising future directions.\n    ",
        "submission_date": "2017-07-13T00:00:00",
        "last_modified_date": "2017-07-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.04245",
        "title": "Hot-Rodding the Browser Engine: Automatic Configuration of JavaScript Compilers",
        "authors": [
            "Chris Fawcett",
            "Lars Kotthoff",
            "Holger H. Hoos"
        ],
        "abstract": "Modern software systems in many application areas offer to the user a multitude of parameters, switches and other customisation hooks. Humans tend to have difficulties determining the best configurations for particular applications. Modern optimising compilers are an example of such software systems; their many parameters need to be tuned for optimal performance, but are often left at the default values for convenience. In this work, we automatically determine compiler parameter settings that result in optimised performance for particular applications. Specifically, we apply a state-of-the-art automated parameter configuration procedure based on cutting-edge machine learning and optimisation techniques to two prominent JavaScript compilers and demonstrate that significant performance improvements, more than 35% in some cases, can be achieved over the default parameter settings on a diverse set of benchmarks.\n    ",
        "submission_date": "2017-07-11T00:00:00",
        "last_modified_date": "2017-07-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.04291",
        "title": "Predicting Abandonment in Online Coding Tutorials",
        "authors": [
            "An Yan",
            "Michael J. Lee",
            "Andrew J. Ko"
        ],
        "abstract": "Learners regularly abandon online coding tutorials when they get bored or frustrated, but there are few techniques for anticipating this abandonment to intervene. In this paper, we examine the feasibility of predicting abandonment with machine-learned classifiers. Using interaction logs from an online programming game, we extracted a collection of features that are potentially related to learner abandonment and engagement, then developed classifiers for each level. Across the first five levels of the game, our classifiers successfully predicted 61% to 76% of learners who did not complete the next level, achieving an average AUC of 0.68. In these classifiers, features negatively associated with abandonment included account activation and help-seeking behaviors, whereas features positively associated with abandonment included features indicating difficulty and disengagement. These findings highlight the feasibility of providing timely intervention to learners likely to quit.\n    ",
        "submission_date": "2017-07-13T00:00:00",
        "last_modified_date": "2017-07-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.04314",
        "title": "Bayesian Optimization for Probabilistic Programs",
        "authors": [
            "Tom Rainforth",
            "Tuan Anh Le",
            "Jan-Willem van de Meent",
            "Michael A. Osborne",
            "Frank Wood"
        ],
        "abstract": "We present the first general purpose framework for marginal maximum a posteriori estimation of probabilistic program variables. By using a series of code transformations, the evidence of any probabilistic program, and therefore of any graphical model, can be optimized with respect to an arbitrary subset of its sampled variables. To carry out this optimization, we develop the first Bayesian optimization package to directly exploit the source code of its target, leading to innovations in problem-independent hyperpriors, unbounded optimization, and implicit constraint satisfaction; delivering significant performance improvements over prominent existing packages. We present applications of our method to a number of tasks including engineering design and parameter optimization.\n    ",
        "submission_date": "2017-07-13T00:00:00",
        "last_modified_date": "2017-07-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.04347",
        "title": "Weakly Submodular Maximization Beyond Cardinality Constraints: Does Randomization Help Greedy?",
        "authors": [
            "Lin Chen",
            "Moran Feldman",
            "Amin Karbasi"
        ],
        "abstract": "Submodular functions are a broad class of set functions, which naturally arise in diverse areas. Many algorithms have been suggested for the maximization of these functions. Unfortunately, once the function deviates from submodularity, the known algorithms may perform arbitrarily poorly. Amending this issue, by obtaining approximation results for set functions generalizing submodular functions, has been the focus of recent works.\n",
        "submission_date": "2017-07-13T00:00:00",
        "last_modified_date": "2017-07-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.04373",
        "title": "Comparison of Multiple Features and Modeling Methods for Text-dependent Speaker Verification",
        "authors": [
            "Yi Liu",
            "Liang He",
            "Yao Tian",
            "Zhuzi Chen",
            "Jia Liu",
            "Michael T. Johnson"
        ],
        "abstract": "Text-dependent speaker verification is becoming popular in the speaker recognition society. However, the conventional i-vector framework which has been successful for speaker identification and other similar tasks works relatively poorly in this task. Researchers have proposed several new methods to improve performance, but it is still unclear that which model is the best choice, especially when the pass-phrases are prompted during enrollment and test. In this paper, we introduce four modeling methods and compare their performance on the newly published RedDots dataset. To further explore the influence of different frame alignments, Viterbi and forward-backward algorithms are both used in the HMM-based models. Several bottleneck features are also investigated. Our experiments show that, by explicitly modeling the lexical content, the HMM-based modeling achieves good results in the fixed-phrase condition. In the prompted-phrase condition, GMM-HMM and i-vector/HMM are not as successful. In both conditions, the forward-backward algorithm brings more benefits to the i-vector/HMM system. Additionally, we also find that even though bottleneck features perform well for text-independent speaker verification, they do not outperform MFCCs on the most challenging Imposter-Correct trials on RedDots.\n    ",
        "submission_date": "2017-07-14T00:00:00",
        "last_modified_date": "2017-09-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.04402",
        "title": "Lenient Multi-Agent Deep Reinforcement Learning",
        "authors": [
            "Gregory Palmer",
            "Karl Tuyls",
            "Daan Bloembergen",
            "Rahul Savani"
        ],
        "abstract": "Much of the success of single agent deep reinforcement learning (DRL) in recent years can be attributed to the use of experience replay memories (ERM), which allow Deep Q-Networks (DQNs) to be trained efficiently through sampling stored state transitions. However, care is required when using ERMs for multi-agent deep reinforcement learning (MA-DRL), as stored transitions can become outdated because agents update their policies in parallel [11]. In this work we apply leniency [23] to MA-DRL. Lenient agents map state-action pairs to decaying temperature values that control the amount of leniency applied towards negative policy updates that are sampled from the ERM. This introduces optimism in the value-function update, and has been shown to facilitate cooperation in tabular fully-cooperative multi-agent reinforcement learning problems. We evaluate our Lenient-DQN (LDQN) empirically against the related Hysteretic-DQN (HDQN) algorithm [22] as well as a modified version we call scheduled-HDQN, that uses average reward learning near terminal states. Evaluations take place in extended variations of the Coordinated Multi-Agent Object Transportation Problem (CMOTP) [8] which include fully-cooperative sub-tasks and stochastic rewards. We find that LDQN agents are more likely to converge to the optimal policy in a stochastic reward CMOTP compared to standard and scheduled-HDQN agents.\n    ",
        "submission_date": "2017-07-14T00:00:00",
        "last_modified_date": "2018-02-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.04459",
        "title": "Fast Detection of Community Structures using Graph Traversal in Social Networks",
        "authors": [
            "Partha Basuchowdhuri",
            "Satyaki Sikdar",
            "Varsha Nagarajan",
            "Khusbu Mishra",
            "Surabhi Gupta",
            "Subhashis Majumder"
        ],
        "abstract": "Finding community structures in social networks is considered to be a challenging task as many of the proposed algorithms are computationally expensive and does not scale well for large graphs. Most of the community detection algorithms proposed till date are unsuitable for applications that would require detection of communities in real-time, especially for massive networks. The Louvain method, which uses modularity maximization to detect clusters, is usually considered to be one of the fastest community detection algorithms even without any provable bound on its running time. We propose a novel graph traversal-based community detection framework, which not only runs faster than the Louvain method but also generates clusters of better quality for most of the benchmark datasets. We show that our algorithms run in O(|V | + |E|) time to create an initial cover before using modularity maximization to get the final cover.\n",
        "submission_date": "2017-07-14T00:00:00",
        "last_modified_date": "2018-05-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.04588",
        "title": "GLSR-VAE: Geodesic Latent Space Regularization for Variational AutoEncoder Architectures",
        "authors": [
            "Ga\u00ebtan Hadjeres",
            "Frank Nielsen",
            "Fran\u00e7ois Pachet"
        ],
        "abstract": "VAEs (Variational AutoEncoders) have proved to be powerful in the context of density modeling and have been used in a variety of contexts for creative purposes. In many settings, the data we model possesses continuous attributes that we would like to take into account at generation time. We propose in this paper GLSR-VAE, a Geodesic Latent Space Regularization for the Variational AutoEncoder architecture and its generalizations which allows a fine control on the embedding of the data into the latent space. When augmenting the VAE loss with this regularization, changes in the learned latent space reflects changes of the attributes of the data. This deeper understanding of the VAE latent space structure offers the possibility to modulate the attributes of the generated data in a continuous way. We demonstrate its efficiency on a monophonic music generation task where we manage to generate variations of discrete sequences in an intended and playful way.\n    ",
        "submission_date": "2017-07-14T00:00:00",
        "last_modified_date": "2017-07-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.04679",
        "title": "Ternary Residual Networks",
        "authors": [
            "Abhisek Kundu",
            "Kunal Banerjee",
            "Naveen Mellempudi",
            "Dheevatsa Mudigere",
            "Dipankar Das",
            "Bharat Kaul",
            "Pradeep Dubey"
        ],
        "abstract": "Sub-8-bit representation of DNNs incur some discernible loss of accuracy despite rigorous (re)training at low-precision. Such loss of accuracy essentially makes them equivalent to a much shallower counterpart, diminishing the power of being deep networks. To address this problem of accuracy drop we introduce the notion of \\textit{residual networks} where we add more low-precision edges to sensitive branches of the sub-8-bit network to compensate for the lost accuracy. Further, we present a perturbation theory to identify such sensitive edges. Aided by such an elegant trade-off between accuracy and compute, the 8-2 model (8-bit activations, ternary weights), enhanced by ternary residual edges, turns out to be sophisticated enough to achieve very high accuracy ($\\sim 1\\%$ drop from our FP-32 baseline), despite $\\sim 1.6\\times$ reduction in model size, $\\sim 26\\times$ reduction in number of multiplications, and potentially $\\sim 2\\times$ power-performance gain comparing to 8-8 representation, on the state-of-the-art deep network ResNet-101 pre-trained on ImageNet dataset. Moreover, depending on the varying accuracy requirements in a dynamic environment, the deployed low-precision model can be upgraded/downgraded on-the-fly by partially enabling/disabling residual connections. For example, disabling the least important residual connections in the above enhanced network, the accuracy drop is $\\sim 2\\%$ (from FP32), despite $\\sim 1.9\\times$ reduction in model size, $\\sim 32\\times$ reduction in number of multiplications, and potentially $\\sim 2.3\\times$ power-performance gain comparing to 8-8 representation. Finally, all the ternary connections are sparse in nature, and the ternary residual conversion can be done in a resource-constraint setting with no low-precision (re)training.\n    ",
        "submission_date": "2017-07-15T00:00:00",
        "last_modified_date": "2017-10-31T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.04780",
        "title": "Scalable Training of Artificial Neural Networks with Adaptive Sparse Connectivity inspired by Network Science",
        "authors": [
            "Decebal Constantin Mocanu",
            "Elena Mocanu",
            "Peter Stone",
            "Phuong H. Nguyen",
            "Madeleine Gibescu",
            "Antonio Liotta"
        ],
        "abstract": "Through the success of deep learning in various domains, artificial neural networks are currently among the most used artificial intelligence methods. Taking inspiration from the network properties of biological neural networks (e.g. sparsity, scale-freeness), we argue that (contrary to general practice) artificial neural networks, too, should not have fully-connected layers. Here we propose sparse evolutionary training of artificial neural networks, an algorithm which evolves an initial sparse topology (Erd\u0151s-R\u00e9nyi random graph) of two consecutive layers of neurons into a scale-free topology, during learning. Our method replaces artificial neural networks fully-connected layers with sparse ones before training, reducing quadratically the number of parameters, with no decrease in accuracy. We demonstrate our claims on restricted Boltzmann machines, multi-layer perceptrons, and convolutional neural networks for unsupervised and supervised learning on 15 datasets. Our approach has the potential to enable artificial neural networks to scale up beyond what is currently possible.\n    ",
        "submission_date": "2017-07-15T00:00:00",
        "last_modified_date": "2018-06-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.04822",
        "title": "Block-Normalized Gradient Method: An Empirical Study for Training Deep Neural Network",
        "authors": [
            "Adams Wei Yu",
            "Lei Huang",
            "Qihang Lin",
            "Ruslan Salakhutdinov",
            "Jaime Carbonell"
        ],
        "abstract": "In this paper, we propose a generic and simple strategy for utilizing stochastic gradient information in optimization. The technique essentially contains two consecutive steps in each iteration: 1) computing and normalizing each block (layer) of the mini-batch stochastic gradient; 2) selecting appropriate step size to update the decision variable (parameter) towards the negative of the block-normalized gradient. We conduct extensive empirical studies on various non-convex neural network optimization problems, including multi-layer perceptron, convolution neural networks and recurrent neural networks. The results indicate the block-normalized gradient can help accelerate the training of neural networks. In particular, we observe that the normalized gradient methods having constant step size with occasionally decay, such as SGD with momentum, have better performance in the deep convolution neural networks, while those with adaptive step sizes, such as Adam, perform better in recurrent neural networks. Besides, we also observe this line of methods can lead to solutions with better generalization properties, which is confirmed by the performance improvement over strong baselines.\n    ",
        "submission_date": "2017-07-16T00:00:00",
        "last_modified_date": "2018-04-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.04873",
        "title": "Efficient Architecture Search by Network Transformation",
        "authors": [
            "Han Cai",
            "Tianyao Chen",
            "Weinan Zhang",
            "Yong Yu",
            "Jun Wang"
        ],
        "abstract": "Techniques for automatically designing deep neural network architectures such as reinforcement learning based approaches have recently shown promising results. However, their success is based on vast computational resources (e.g. hundreds of GPUs), making them difficult to be widely used. A noticeable limitation is that they still design and train each network from scratch during the exploration of the architecture space, which is highly inefficient. In this paper, we propose a new framework toward efficient architecture search by exploring the architecture space based on the current network and reusing its weights. We employ a reinforcement learning agent as the meta-controller, whose action is to grow the network depth or layer width with function-preserving transformations. As such, the previously validated networks can be reused for further exploration, thus saves a large amount of computational cost. We apply our method to explore the architecture space of the plain convolutional neural networks (no skip-connections, branching etc.) on image benchmark datasets (CIFAR-10, SVHN) with restricted computational resources (5 GPUs). Our method can design highly competitive networks that outperform existing networks using the same design scheme. On CIFAR-10, our model without skip-connections achieves 4.23\\% test error rate, exceeding a vast majority of modern architectures and approaching DenseNet. Furthermore, by applying our method to explore the DenseNet architecture space, we are able to achieve more accurate networks with fewer parameters.\n    ",
        "submission_date": "2017-07-16T00:00:00",
        "last_modified_date": "2017-11-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.05101",
        "title": "On consistency of optimal pricing algorithms in repeated posted-price auctions with strategic buyer",
        "authors": [
            "Alexey Drutsa"
        ],
        "abstract": "We study revenue optimization learning algorithms for repeated posted-price auctions where a seller interacts with a single strategic buyer that holds a fixed private valuation for a good and seeks to maximize his cumulative discounted surplus. For this setting, first, we propose a novel algorithm that never decreases offered prices and has a tight strategic regret bound in $\\Theta(\\log\\log T)$ under some mild assumptions on the buyer surplus discounting. This result closes the open research question on the existence of a no-regret horizon-independent weakly consistent pricing. The proposed algorithm is inspired by our observation that a double decrease of offered prices in a weakly consistent algorithm is enough to cause a linear regret. This motivates us to construct a novel transformation that maps a right-consistent algorithm to a weakly consistent one that never decreases offered prices.\n",
        "submission_date": "2017-07-17T00:00:00",
        "last_modified_date": "2018-02-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.05115",
        "title": "The Power of Constraint Grammars Revisited",
        "authors": [
            "Anssi Yli-Jyr\u00e4"
        ],
        "abstract": "Sequential Constraint Grammar (SCG) (Karlsson, 1990) and its extensions have lacked clear connections to formal language theory. The purpose of this article is to lay a foundation for these connections by simplifying the definition of strings processed by the grammar and by showing that Nonmonotonic SCG is undecidable and that derivations similar to the Generative Phonology exist. The current investigations propose resource bounds that restrict the generative power of SCG to a subset of context sensitive languages and present a strong finite-state condition for grammars as wholes. We show that a grammar is equivalent to a finite-state transducer if it is implemented with a Turing machine that runs in o(n log n) time. This condition opens new finite-state hypotheses and avenues for deeper analysis of SCG instances in the way inspired by Finite-State Phonology.\n    ",
        "submission_date": "2017-07-17T00:00:00",
        "last_modified_date": "2017-07-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.05224",
        "title": "Detection, Recognition and Tracking of Moving Objects from Real-time Video via Visual Vocabulary Model and Species Inspired PSO",
        "authors": [
            "Kumar S. Ray",
            "Anit Chakraborty",
            "Sayandip Dutta"
        ],
        "abstract": "In this paper, we address the basic problem of recognizing moving objects in video images using Visual Vocabulary model and Bag of Words and track our object of interest in the subsequent video frames using species inspired PSO. Initially, the shadow free images are obtained by background modelling followed by foreground modeling to extract the blobs of our object of interest. Subsequently, we train a cubic SVM with human body datasets in accordance with our domain of interest for recognition and tracking. During training, using the principle of Bag of Words we extract necessary features of certain domains and objects for classification. Subsequently, matching these feature sets with those of the extracted object blobs that are obtained by subtracting the shadow free background from the foreground, we detect successfully our object of interest from the test domain. The performance of the classification by cubic SVM is satisfactorily represented by confusion matrix and ROC curve reflecting the accuracy of each module. After classification, our object of interest is tracked in the test domain using species inspired PSO. By combining the adaptive learning tools with the efficient classification of description, we achieve optimum accuracy in recognition of the moving objects. We evaluate our algorithm benchmark datasets: iLIDS, VIVID, Walking2, Woman. Comparative analysis of our algorithm against the existing state-of-the-art trackers shows very satisfactory and competitive results.\n    ",
        "submission_date": "2017-06-02T00:00:00",
        "last_modified_date": "2017-06-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.05228",
        "title": "Object Tracking based on Quantum Particle Swarm Optimization",
        "authors": [
            "Rajesh Misra",
            "Kumar S. Ray"
        ],
        "abstract": "In Computer Vision domain, moving Object Tracking considered as one of the toughest ",
        "submission_date": "2017-05-24T00:00:00",
        "last_modified_date": "2017-05-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.05340",
        "title": "PDD Graph: Bridging Electronic Medical Records and Biomedical Knowledge Graphs via Entity Linking",
        "authors": [
            "Meng Wang",
            "Jiaheng Zhang",
            "Jun Liu",
            "Wei Hu",
            "Sen Wang",
            "Xue Li",
            "Wenqiang Liu"
        ],
        "abstract": "Electronic medical records contain multi-format electronic medical data that consist of an abundance of medical knowledge. Facing with patient's symptoms, experienced caregivers make right medical decisions based on their professional knowledge that accurately grasps relationships between symptoms, diagnosis and corresponding treatments. In this paper, we aim to capture these relationships by constructing a large and high-quality heterogenous graph linking patients, diseases, and drugs (PDD) in EMRs. Specifically, we propose a novel framework to extract important medical entities from MIMIC-III (Medical Information Mart for Intensive Care III) and automatically link them with the existing biomedical knowledge graphs, including ICD-9 ontology and DrugBank. The PDD graph presented in this paper is accessible on the Web via the SPARQL endpoint, and provides a pathway for medical discovery and applications, such as effective treatment recommendations.\n    ",
        "submission_date": "2017-07-17T00:00:00",
        "last_modified_date": "2017-07-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.05373",
        "title": "Houdini: Fooling Deep Structured Prediction Models",
        "authors": [
            "Moustapha Cisse",
            "Yossi Adi",
            "Natalia Neverova",
            "Joseph Keshet"
        ],
        "abstract": "Generating adversarial examples is a critical step for evaluating and improving the robustness of learning machines. So far, most existing methods only work for classification and are not designed to alter the true performance measure of the problem at hand. We introduce a novel flexible approach named Houdini for generating adversarial examples specifically tailored for the final performance measure of the task considered, be it combinatorial and non-decomposable. We successfully apply Houdini to a range of applications such as speech recognition, pose estimation and semantic segmentation. In all cases, the attacks based on Houdini achieve higher success rate than those based on the traditional surrogates used to train the models while using a less perceptible adversarial perturbation.\n    ",
        "submission_date": "2017-07-17T00:00:00",
        "last_modified_date": "2017-07-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.05493",
        "title": "ARREST: A RSSI Based Approach for Mobile Sensing and Tracking of a Moving Object",
        "authors": [
            "Pradipta Ghosh",
            "Jason A. Tran",
            "Bhaskar Krishnamachari"
        ],
        "abstract": "We present Autonomous Rssi based RElative poSitioning and Tracking (ARREST), a new robotic sensing system for tracking and following a moving, RF-emitting object, which we refer to as the Leader, solely based on signal strength information. This kind of system can expand the horizon of autonomous mobile tracking and distributed robotics into many scenarios with limited visibility such as nighttime, dense forests, and cluttered environments. Our proposed tracking agent, which we refer to as the TrackBot, uses a single rotating, off-the-shelf, directional antenna, novel angle and relative speed estimation algorithms, and Kalman filtering to continually estimate the relative position of the Leader with decimeter level accuracy (which is comparable to a state-of-the-art multiple access point based RF-localization system) and the relative speed of the Leader with accuracy on the order of 1 m/s. The TrackBot feeds the relative position and speed estimates into a Linear Quadratic Gaussian (LQG) controller to generate a set of control outputs to control the orientation and the movement of the TrackBot. We perform an extensive set of real world experiments with a full-fledged prototype to demonstrate that the TrackBot is able to stay within 5m of the Leader with: (1) more than $99\\%$ probability in line of sight scenarios, and (2) more than $70\\%$ probability in no line of sight scenarios, when it moves 1.8X faster than the Leader. For ground truth estimation in real world experiments, we also developed an integrated TDoA based distance and angle estimation system with centimeter level localization accuracy in line of sight scenarios. While providing a first proof of concept, our work opens the door to future research aimed at further improvements of autonomous RF-based tracking.\n    ",
        "submission_date": "2017-07-18T00:00:00",
        "last_modified_date": "2017-10-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.05499",
        "title": "A Machine Learning Approach for Evaluating Creative Artifacts",
        "authors": [
            "Disha Shrivastava",
            "Saneem Ahmed CG",
            "Anirban Laha",
            "Karthik Sankaranarayanan"
        ],
        "abstract": "Much work has been done in understanding human creativity and defining measures to evaluate creativity. This is necessary mainly for the reason of having an objective and automatic way of quantifying creative artifacts. In this work, we propose a regression-based learning framework which takes into account quantitatively the essential criteria for creativity like novelty, influence, value and unexpectedness. As it is often the case with most creative domains, there is no clear ground truth available for creativity. Our proposed learning framework is applicable to all creative domains; yet we evaluate it on a dataset of movies created from IMDb and Rotten Tomatoes due to availability of audience and critic scores, which can be used as proxy ground truth labels for creativity. We report promising results and observations from our experiments in the following ways : 1) Correlation of creative criteria with critic scores, 2) Improvement in movie rating prediction with inclusion of various creative criteria, and 3) Identification of creative movies.\n    ",
        "submission_date": "2017-07-18T00:00:00",
        "last_modified_date": "2017-07-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.05720",
        "title": "Grounding Spatio-Semantic Referring Expressions for Human-Robot Interaction",
        "authors": [
            "Mohit Shridhar",
            "David Hsu"
        ],
        "abstract": "The human language is one of the most natural interfaces for humans to interact with robots. This paper presents a robot system that retrieves everyday objects with unconstrained natural language descriptions. A core issue for the system is semantic and spatial grounding, which is to infer objects and their spatial relationships from images and natural language expressions. We introduce a two-stage neural-network grounding pipeline that maps natural language referring expressions directly to objects in the images. The first stage uses visual descriptions in the referring expressions to generate a candidate set of relevant objects. The second stage examines all pairwise relationships between the candidates and predicts the most likely referred object according to the spatial descriptions in the referring expressions. A key feature of our system is that by leveraging a large dataset of images labeled with text descriptions, it allows unrestricted object types and natural language referring expressions. Preliminary results indicate that our system outperforms a near state-of-the-art object comprehension system on standard benchmark datasets. We also present a robot system that follows voice commands to pick and place previously unseen objects.\n    ",
        "submission_date": "2017-07-18T00:00:00",
        "last_modified_date": "2017-07-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.05729",
        "title": "Robust Bayesian Optimization with Student-t Likelihood",
        "authors": [
            "Ruben Martinez-Cantin",
            "Michael McCourt",
            "Kevin Tee"
        ],
        "abstract": "Bayesian optimization has recently attracted the attention of the automatic machine learning community for its excellent results in hyperparameter tuning. BO is characterized by the sample efficiency with which it can optimize expensive black-box functions. The efficiency is achieved in a similar fashion to the learning to learn methods: surrogate models (typically in the form of Gaussian processes) learn the target function and perform intelligent sampling. This surrogate model can be applied even in the presence of noise; however, as with most regression methods, it is very sensitive to outlier data. This can result in erroneous predictions and, in the case of BO, biased and inefficient exploration. In this work, we present a GP model that is robust to outliers which uses a Student-t likelihood to segregate outliers and robustly conduct Bayesian optimization. We present numerical results evaluating the proposed method in both artificial functions and real problems.\n    ",
        "submission_date": "2017-07-18T00:00:00",
        "last_modified_date": "2017-07-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.05733",
        "title": "Choosing Smartly: Adaptive Multimodal Fusion for Object Detection in Changing Environments",
        "authors": [
            "Oier Mees",
            "Andreas Eitel",
            "Wolfram Burgard"
        ],
        "abstract": "Object detection is an essential task for autonomous robots operating in dynamic and changing environments. A robot should be able to detect objects in the presence of sensor noise that can be induced by changing lighting conditions for cameras and false depth readings for range sensors, especially RGB-D cameras. To tackle these challenges, we propose a novel adaptive fusion approach for object detection that learns weighting the predictions of different sensor modalities in an online manner. Our approach is based on a mixture of convolutional neural network (CNN) experts and incorporates multiple modalities including appearance, depth and motion. We test our method in extensive robot experiments, in which we detect people in a combined indoor and outdoor scenario from RGB-D data, and we demonstrate that our method can adapt to harsh lighting changes and severe camera motion blur. Furthermore, we present a new RGB-D dataset for people detection in mixed in- and outdoor environments, recorded with a mobile robot. Code, pretrained models and dataset are available at ",
        "submission_date": "2017-07-18T00:00:00",
        "last_modified_date": "2019-11-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.05878",
        "title": "On-line Building Energy Optimization using Deep Reinforcement Learning",
        "authors": [
            "Elena Mocanu",
            "Decebal Constantin Mocanu",
            "Phuong H. Nguyen",
            "Antonio Liotta",
            "Michael E. Webber",
            "Madeleine Gibescu",
            "J.G. Slootweg"
        ],
        "abstract": "Unprecedented high volumes of data are becoming available with the growth of the advanced metering infrastructure. These are expected to benefit planning and operation of the future power system, and to help the customers transition from a passive to an active role. In this paper, we explore for the first time in the smart grid context the benefits of using Deep Reinforcement Learning, a hybrid type of methods that combines Reinforcement Learning with Deep Learning, to perform on-line optimization of schedules for building energy management systems. The learning procedure was explored using two methods, Deep Q-learning and Deep Policy Gradient, both of them being extended to perform multiple actions simultaneously. The proposed approach was validated on the large-scale Pecan Street Inc. database. This highly-dimensional database includes information about photovoltaic power generation, electric vehicles as well as buildings appliances. Moreover, these on-line energy scheduling strategies could be used to provide real-time feedback to consumers to encourage more efficient use of electricity.\n    ",
        "submission_date": "2017-07-18T00:00:00",
        "last_modified_date": "2017-07-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.06175",
        "title": "Deformable Part-based Fully Convolutional Network for Object Detection",
        "authors": [
            "Taylor Mordan",
            "Nicolas Thome",
            "Matthieu Cord",
            "Gilles Henaff"
        ],
        "abstract": "Existing region-based object detectors are limited to regions with fixed box geometry to represent objects, even if those are highly non-rectangular. In this paper we introduce DP-FCN, a deep model for object detection which explicitly adapts to shapes of objects with deformable parts. Without additional annotations, it learns to focus on discriminative elements and to align them, and simultaneously brings more invariance for classification and geometric information to refine localization. DP-FCN is composed of three main modules: a Fully Convolutional Network to efficiently maintain spatial resolution, a deformable part-based RoI pooling layer to optimize positions of parts and build invariance, and a deformation-aware localization module explicitly exploiting displacements of parts to improve accuracy of bounding box regression. We experimentally validate our model and show significant gains. DP-FCN achieves state-of-the-art performances of 83.1% and 80.9% on PASCAL VOC 2007 and 2012 with VOC data only.\n    ",
        "submission_date": "2017-07-19T00:00:00",
        "last_modified_date": "2017-07-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.06203",
        "title": "Imagination-Augmented Agents for Deep Reinforcement Learning",
        "authors": [
            "Th\u00e9ophane Weber",
            "S\u00e9bastien Racani\u00e8re",
            "David P. Reichert",
            "Lars Buesing",
            "Arthur Guez",
            "Danilo Jimenez Rezende",
            "Adria Puigdom\u00e8nech Badia",
            "Oriol Vinyals",
            "Nicolas Heess",
            "Yujia Li",
            "Razvan Pascanu",
            "Peter Battaglia",
            "Demis Hassabis",
            "David Silver",
            "Daan Wierstra"
        ],
        "abstract": "We introduce Imagination-Augmented Agents (I2As), a novel architecture for deep reinforcement learning combining model-free and model-based aspects. In contrast to most existing model-based reinforcement learning and planning methods, which prescribe how a model should be used to arrive at a policy, I2As learn to interpret predictions from a learned environment model to construct implicit plans in arbitrary ways, by using the predictions as additional context in deep policy networks. I2As show improved data efficiency, performance, and robustness to model misspecification compared to several baselines.\n    ",
        "submission_date": "2017-07-19T00:00:00",
        "last_modified_date": "2018-02-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.06209",
        "title": "Crowdsourcing Multiple Choice Science Questions",
        "authors": [
            "Johannes Welbl",
            "Nelson F. Liu",
            "Matt Gardner"
        ],
        "abstract": "We present a novel method for obtaining high-quality, domain-targeted multiple choice questions from crowd workers. Generating these questions can be difficult without trading away originality, relevance or diversity in the answer options. Our method addresses these problems by leveraging a large corpus of domain-specific text and a small set of existing questions. It produces model suggestions for document selection and answer distractor choice which aid the human question generation process. With this method we have assembled SciQ, a dataset of 13.7K multiple choice science exam questions (Dataset available at ",
        "submission_date": "2017-07-19T00:00:00",
        "last_modified_date": "2017-07-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.06217",
        "title": "Worst-case vs Average-case Design for Estimation from Fixed Pairwise Comparisons",
        "authors": [
            "Ashwin Pananjady",
            "Cheng Mao",
            "Vidya Muthukumar",
            "Martin J. Wainwright",
            "Thomas A. Courtade"
        ],
        "abstract": "Pairwise comparison data arises in many domains, including tournament rankings, web search, and preference elicitation. Given noisy comparisons of a fixed subset of pairs of items, we study the problem of estimating the underlying comparison probabilities under the assumption of strong stochastic transitivity (SST). We also consider the noisy sorting subclass of the SST model. We show that when the assignment of items to the topology is arbitrary, these permutation-based models, unlike their parametric counterparts, do not admit consistent estimation for most comparison topologies used in practice. We then demonstrate that consistent estimation is possible when the assignment of items to the topology is randomized, thus establishing a dichotomy between worst-case and average-case designs. We propose two estimators in the average-case setting and analyze their risk, showing that it depends on the comparison topology only through the degree sequence of the topology. The rates achieved by these estimators are shown to be optimal for a large class of graphs. Our results are corroborated by simulations on multiple comparison topologies.\n    ",
        "submission_date": "2017-07-19T00:00:00",
        "last_modified_date": "2017-07-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.06226",
        "title": "The Role of Conversation Context for Sarcasm Detection in Online Interactions",
        "authors": [
            "Debanjan Ghosh",
            "Alexander Richard Fabbri",
            "Smaranda Muresan"
        ],
        "abstract": "Computational models for sarcasm detection have often relied on the content of utterances in isolation. However, speaker's sarcastic intent is not always obvious without additional context. Focusing on social media discussions, we investigate two issues: (1) does modeling of conversation context help in sarcasm detection and (2) can we understand what part of conversation context triggered the sarcastic reply. To address the first issue, we investigate several types of Long Short-Term Memory (LSTM) networks that can model both the conversation context and the sarcastic response. We show that the conditional LSTM network (Rocktaschel et al., 2015) and LSTM networks with sentence level attention on context and response outperform the LSTM model that reads only the response. To address the second issue, we present a qualitative analysis of attention weights produced by the LSTM models with attention and discuss the results compared with human performance on the task.\n    ",
        "submission_date": "2017-07-19T00:00:00",
        "last_modified_date": "2017-07-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.06334",
        "title": "Fully Decentralized Policies for Multi-Agent Systems: An Information Theoretic Approach",
        "authors": [
            "Roel Dobbe",
            "David Fridovich-Keil",
            "Claire Tomlin"
        ],
        "abstract": "Learning cooperative policies for multi-agent systems is often challenged by partial observability and a lack of coordination. In some settings, the structure of a problem allows a distributed solution with limited communication. Here, we consider a scenario where no communication is available, and instead we learn local policies for all agents that collectively mimic the solution to a centralized multi-agent static optimization problem. Our main contribution is an information theoretic framework based on rate distortion theory which facilitates analysis of how well the resulting fully decentralized policies are able to reconstruct the optimal solution. Moreover, this framework provides a natural extension that addresses which nodes an agent should communicate with to improve the performance of its individual policy.\n    ",
        "submission_date": "2017-07-20T00:00:00",
        "last_modified_date": "2017-07-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.06355",
        "title": "Video Question Answering via Attribute-Augmented Attention Network Learning",
        "authors": [
            "Yunan Ye",
            "Zhou Zhao",
            "Yimeng Li",
            "Long Chen",
            "Jun Xiao",
            "Yueting Zhuang"
        ],
        "abstract": "Video Question Answering is a challenging problem in visual information retrieval, which provides the answer to the referenced video content according to the question. However, the existing visual question answering approaches mainly tackle the problem of static image question, which may be ineffectively for video question answering due to the insufficiency of modeling the temporal dynamics of video contents. In this paper, we study the problem of video question answering by modeling its temporal dynamics with frame-level attention mechanism. We propose the attribute-augmented attention network learning framework that enables the joint frame-level attribute detection and unified video representation learning for video question answering. We then incorporate the multi-step reasoning process for our proposed attention network to further improve the performance. We construct a large-scale video question answering dataset. We conduct the experiments on both multiple-choice and open-ended video question answering tasks to show the effectiveness of the proposed method.\n    ",
        "submission_date": "2017-07-20T00:00:00",
        "last_modified_date": "2017-07-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.06541",
        "title": "Discretization-free Knowledge Gradient Methods for Bayesian Optimization",
        "authors": [
            "Jian Wu",
            "Peter I. Frazier"
        ],
        "abstract": "This paper studies Bayesian ranking and selection (R&S) problems with correlated prior beliefs and continuous domains, i.e. Bayesian optimization (BO). Knowledge gradient methods [Frazier et al., 2008, 2009] have been widely studied for discrete R&S problems, which sample the one-step Bayes-optimal point. When used over continuous domains, previous work on the knowledge gradient [Scott et al., 2011, Wu and Frazier, 2016, Wu et al., 2017] often rely on a discretized finite approximation. However, the discretization introduces error and scales poorly as the dimension of domain grows. In this paper, we develop a fast discretization-free knowledge gradient method for Bayesian optimization. Our method is not restricted to the fully sequential setting, but useful in all settings where knowledge gradient can be used over continuous domains. We show how our method can be generalized to handle (i) batch of points suggestion (parallel knowledge gradient); (ii) the setting where derivative information is available in the optimization process (derivative-enabled knowledge gradient). In numerical experiments, we demonstrate that the discretization-free knowledge gradient method finds global optima significantly faster than previous Bayesian optimization algorithms on both synthetic test functions and real-world applications, especially when function evaluations are noisy; and derivative-enabled knowledge gradient can further improve the performances, even outperforming the gradient-based optimizer such as BFGS when derivative information is available.\n    ",
        "submission_date": "2017-07-20T00:00:00",
        "last_modified_date": "2017-07-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.06543",
        "title": "An All-in-One Network for Dehazing and Beyond",
        "authors": [
            "Boyi Li",
            "Xiulian Peng",
            "Zhangyang Wang",
            "Jizheng Xu",
            "Dan Feng"
        ],
        "abstract": "This paper proposes an image dehazing model built with a convolutional neural network (CNN), called All-in-One Dehazing Network (AOD-Net). It is designed based on a re-formulated atmospheric scattering model. Instead of estimating the transmission matrix and the atmospheric light separately as most previous models did, AOD-Net directly generates the clean image through a light-weight CNN. Such a novel end-to-end design makes it easy to embed AOD-Net into other deep models, e.g., Faster R-CNN, for improving high-level task performance on hazy images. Experimental results on both synthesized and natural hazy image datasets demonstrate our superior performance than the state-of-the-art in terms of PSNR, SSIM and the subjective visual quality. Furthermore, when concatenating AOD-Net with Faster R-CNN and training the joint pipeline from end to end, we witness a large improvement of the object detection performance on hazy images.\n    ",
        "submission_date": "2017-07-20T00:00:00",
        "last_modified_date": "2017-07-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.06658",
        "title": "RAIL: Risk-Averse Imitation Learning",
        "authors": [
            "Anirban Santara",
            "Abhishek Naik",
            "Balaraman Ravindran",
            "Dipankar Das",
            "Dheevatsa Mudigere",
            "Sasikanth Avancha",
            "Bharat Kaul"
        ],
        "abstract": "Imitation learning algorithms learn viable policies by imitating an expert's behavior when reward signals are not available. Generative Adversarial Imitation Learning (GAIL) is a state-of-the-art algorithm for learning policies when the expert's behavior is available as a fixed set of trajectories. We evaluate in terms of the expert's cost function and observe that the distribution of trajectory-costs is often more heavy-tailed for GAIL-agents than the expert at a number of benchmark continuous-control tasks. Thus, high-cost trajectories, corresponding to tail-end events of catastrophic failure, are more likely to be encountered by the GAIL-agents than the expert. This makes the reliability of GAIL-agents questionable when it comes to deployment in risk-sensitive applications like robotic surgery and autonomous driving. In this work, we aim to minimize the occurrence of tail-end events by minimizing tail risk within the GAIL framework. We quantify tail risk by the Conditional-Value-at-Risk (CVaR) of trajectories and develop the Risk-Averse Imitation Learning (RAIL) algorithm. We observe that the policies learned with RAIL show lower tail-end risk than those of vanilla GAIL. Thus the proposed RAIL algorithm appears as a potent alternative to GAIL for improved reliability in risk-sensitive applications.\n    ",
        "submission_date": "2017-07-20T00:00:00",
        "last_modified_date": "2017-11-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.06690",
        "title": "DeepPath: A Reinforcement Learning Method for Knowledge Graph Reasoning",
        "authors": [
            "Wenhan Xiong",
            "Thien Hoang",
            "William Yang Wang"
        ],
        "abstract": "We study the problem of learning to reason in large scale knowledge graphs (KGs). More specifically, we describe a novel reinforcement learning framework for learning multi-hop relational paths: we use a policy-based agent with continuous states based on knowledge graph embeddings, which reasons in a KG vector space by sampling the most promising relation to extend its path. In contrast to prior work, our approach includes a reward function that takes the accuracy, diversity, and efficiency into consideration. Experimentally, we show that our proposed method outperforms a path-ranking based algorithm and knowledge graph embedding methods on Freebase and Never-Ending Language Learning datasets.\n    ",
        "submission_date": "2017-07-20T00:00:00",
        "last_modified_date": "2018-07-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.06742",
        "title": "Machine Teaching: A New Paradigm for Building Machine Learning Systems",
        "authors": [
            "Patrice Y. Simard",
            "Saleema Amershi",
            "David M. Chickering",
            "Alicia Edelman Pelton",
            "Soroush Ghorashi",
            "Christopher Meek",
            "Gonzalo Ramos",
            "Jina Suh",
            "Johan Verwey",
            "Mo Wang",
            "John Wernsing"
        ],
        "abstract": "The current processes for building machine learning systems require practitioners with deep knowledge of machine learning. This significantly limits the number of machine learning systems that can be created and has led to a mismatch between the demand for machine learning systems and the ability for organizations to build them. We believe that in order to meet this growing demand for machine learning systems we must significantly increase the number of individuals that can teach machines. We postulate that we can achieve this goal by making the process of teaching machines easy, fast and above all, universally accessible.\n",
        "submission_date": "2017-07-21T00:00:00",
        "last_modified_date": "2017-08-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.06756",
        "title": "An Infinite Hidden Markov Model With Similarity-Biased Transitions",
        "authors": [
            "Colin Reimer Dawson",
            "Chaofan Huang",
            "Clayton T. Morrison"
        ],
        "abstract": "We describe a generalization of the Hierarchical Dirichlet Process Hidden Markov Model (HDP-HMM) which is able to encode prior information that state transitions are more likely between \"nearby\" states. This is accomplished by defining a similarity function on the state space and scaling transition probabilities by pair-wise similarities, thereby inducing correlations among the transition distributions. We present an augmented data representation of the model as a Markov Jump Process in which: (1) some jump attempts fail, and (2) the probability of success is proportional to the similarity between the source and destination states. This augmentation restores conditional conjugacy and admits a simple Gibbs sampler. We evaluate the model and inference method on a speaker diarization task and a \"harmonic parsing\" task using four-part chorale data, as well as on several synthetic datasets, achieving favorable comparisons to existing models.\n    ",
        "submission_date": "2017-07-21T00:00:00",
        "last_modified_date": "2017-07-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.06813",
        "title": "On the Computation of Paracoherent Answer Sets",
        "authors": [
            "Giovanni Amendola",
            "Carmine Dodaro",
            "Wolfgang Faber",
            "Nicola Leone",
            "Francesco Ricca"
        ],
        "abstract": "Answer Set Programming (ASP) is a well-established formalism for nonmonotonic reasoning. An ASP program can have no answer set due to cyclic default negation. In this case, it is not possible to draw any conclusion, even if this is not intended. Recently, several paracoherent semantics have been proposed that address this issue, and several potential applications for these semantics have been identified. However, paracoherent semantics have essentially been inapplicable in practice, due to the lack of efficient algorithms and implementations. In this paper, this lack is addressed, and several different algorithms to compute semi-stable and semi-equilibrium models are proposed and implemented into an answer set solving framework. An empirical performance comparison among the new algorithms on benchmarks from ASP competitions is given as well.\n    ",
        "submission_date": "2017-07-21T00:00:00",
        "last_modified_date": "2017-07-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.06887",
        "title": "A Distributional Perspective on Reinforcement Learning",
        "authors": [
            "Marc G. Bellemare",
            "Will Dabney",
            "R\u00e9mi Munos"
        ],
        "abstract": "In this paper we argue for the fundamental importance of the value distribution: the distribution of the random return received by a reinforcement learning agent. This is in contrast to the common approach to reinforcement learning which models the expectation of this return, or value. Although there is an established body of literature studying the value distribution, thus far it has always been used for a specific purpose such as implementing risk-aware behaviour. We begin with theoretical results in both the policy evaluation and control settings, exposing a significant distributional instability in the latter. We then use the distributional perspective to design a new algorithm which applies Bellman's equation to the learning of approximate value distributions. We evaluate our algorithm using the suite of games from the Arcade Learning Environment. We obtain both state-of-the-art results and anecdotal evidence demonstrating the importance of the value distribution in approximate reinforcement learning. Finally, we combine theoretical and empirical evidence to highlight the ways in which the value distribution impacts learning in the approximate setting.\n    ",
        "submission_date": "2017-07-21T00:00:00",
        "last_modified_date": "2017-07-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.06992",
        "title": "Ideological Sublations: Resolution of Dialectic in Population-based Optimization",
        "authors": [
            "S. Hossein Hosseini",
            "Afshin Ebrahimi"
        ],
        "abstract": "A population-based optimization algorithm was designed, inspired by two main thinking modes in philosophy, both based on dialectic concept and thesis-antithesis paradigm. They impose two different kinds of dialectics. Idealistic and materialistic antitheses are formulated as optimization models. Based on the models, the population is coordinated for dialectical interactions. At the population-based context, the formulated optimization models are reduced to a simple detection problem for each thinker (particle). According to the assigned thinking mode to each thinker and her/his measurements of corresponding dialectic with other candidate particles, they deterministically decide to interact with a thinker in maximum dialectic with their theses. The position of a thinker at maximum dialectic is known as an available antithesis among the existing solutions. The dialectical interactions at each ideological community are distinguished by meaningful distributions of step-sizes for each thinking mode. In fact, the thinking modes are regarded as exploration and exploitation elements of the proposed algorithm. The result is a delicate balance without any requirement for adjustment of step-size coefficients. Main parameter of the proposed algorithm is the number of particles appointed to each thinking modes, or equivalently for each kind of motions. An additional integer parameter is defined to boost the stability of the final algorithm in some particular problems. The proposed algorithm is evaluated by a testbed of 12 single-objective continuous benchmark functions. Moreover, its performance and speed were highlighted in sparse reconstruction and antenna selection problems, at the context of compressed sensing and massive MIMO, respectively. The results indicate fast and efficient performance in comparison with well-known evolutionary algorithms and dedicated state-of-the-art algorithms.\n    ",
        "submission_date": "2017-07-21T00:00:00",
        "last_modified_date": "2017-09-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.07048",
        "title": "Progressive Joint Modeling in Unsupervised Single-channel Overlapped Speech Recognition",
        "authors": [
            "Zhehuai Chen",
            "Jasha Droppo",
            "Jinyu Li",
            "Wayne Xiong"
        ],
        "abstract": "Unsupervised single-channel overlapped speech recognition is one of the hardest problems in automatic speech recognition (ASR). Permutation invariant training (PIT) is a state of the art model-based approach, which applies a single neural network to solve this single-input, multiple-output modeling problem. We propose to advance the current state of the art by imposing a modular structure on the neural network, applying a progressive pretraining regimen, and improving the objective function with transfer learning and a discriminative training criterion. The modular structure splits the problem into three sub-tasks: frame-wise interpreting, utterance-level speaker tracing, and speech recognition. The pretraining regimen uses these modules to solve progressively harder tasks. Transfer learning leverages parallel clean speech to improve the training targets for the network. Our discriminative training formulation is a modification of standard formulations, that also penalizes competing outputs of the system. Experiments are conducted on the artificial overlapped Switchboard and hub5e-swb dataset. The proposed framework achieves over 30% relative improvement of WER over both a strong jointly trained system, PIT for ASR, and a separately optimized system, PIT for speech separation with clean speech ASR model. The improvement comes from better model generalization, training efficiency and the sequence level linguistic knowledge integration.\n    ",
        "submission_date": "2017-07-21T00:00:00",
        "last_modified_date": "2017-10-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.07341",
        "title": "Prediction-Constrained Training for Semi-Supervised Mixture and Topic Models",
        "authors": [
            "Michael C. Hughes",
            "Leah Weiner",
            "Gabriel Hope",
            "Thomas H. McCoy Jr.",
            "Roy H. Perlis",
            "Erik B. Sudderth",
            "Finale Doshi-Velez"
        ],
        "abstract": "Supervisory signals have the potential to make low-dimensional data representations, like those learned by mixture and topic models, more interpretable and useful. We propose a framework for training latent variable models that explicitly balances two goals: recovery of faithful generative explanations of high-dimensional data, and accurate prediction of associated semantic labels. Existing approaches fail to achieve these goals due to an incomplete treatment of a fundamental asymmetry: the intended application is always predicting labels from data, not data from labels. Our prediction-constrained objective for training generative models coherently integrates loss-based supervisory signals while enabling effective semi-supervised learning from partially labeled data. We derive learning algorithms for semi-supervised mixture and topic models using stochastic gradient descent with automatic differentiation. We demonstrate improved prediction quality compared to several previous supervised topic models, achieving predictions competitive with high-dimensional logistic regression on text sentiment analysis and electronic health records tasks while simultaneously learning interpretable topics.\n    ",
        "submission_date": "2017-07-23T00:00:00",
        "last_modified_date": "2017-07-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.07402",
        "title": "Reinforcement Learning for Bandit Neural Machine Translation with Simulated Human Feedback",
        "authors": [
            "Khanh Nguyen",
            "Hal Daum\u00e9 III",
            "Jordan Boyd-Graber"
        ],
        "abstract": "Machine translation is a natural candidate problem for reinforcement learning from human feedback: users provide quick, dirty ratings on candidate translations to guide a system to improve. Yet, current neural machine translation training focuses on expensive human-generated reference translations. We describe a reinforcement learning algorithm that improves neural machine translation systems from simulated human feedback. Our algorithm combines the advantage actor-critic algorithm (Mnih et al., 2016) with the attention-based neural encoder-decoder architecture (Luong et al., 2015). This algorithm (a) is well-designed for problems with a large action space and delayed rewards, (b) effectively optimizes traditional corpus-level machine translation metrics, and (c) is robust to skewed, high-variance, granular feedback modeled after actual human behaviors.\n    ",
        "submission_date": "2017-07-24T00:00:00",
        "last_modified_date": "2017-11-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.07530",
        "title": "Likelihood Estimation for Generative Adversarial Networks",
        "authors": [
            "Hamid Eghbal-zadeh",
            "Gerhard Widmer"
        ],
        "abstract": "We present a simple method for assessing the quality of generated images in Generative Adversarial Networks (GANs). The method can be applied in any kind of GAN without interfering with the learning procedure or affecting the learning objective. The central idea is to define a likelihood function that correlates with the quality of the generated images. In particular, we derive a Gaussian likelihood function from the distribution of the embeddings (hidden activations) of the real images in the discriminator, and based on this, define two simple measures of how likely it is that the embeddings of generated images are from the distribution of the embeddings of the real images. This yields a simple measure of fitness for generated images, for all varieties of GANs. Empirical results on CIFAR-10 demonstrate a strong correlation between the proposed measures and the perceived quality of the generated images.\n    ",
        "submission_date": "2017-07-24T00:00:00",
        "last_modified_date": "2017-07-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.07554",
        "title": "Learning Rare Word Representations using Semantic Bridging",
        "authors": [
            "Victor Prokhorov",
            "Mohammad Taher Pilehvar",
            "Dimitri Kartsaklis",
            "Pietro Li\u00f3",
            "Nigel Collier"
        ],
        "abstract": "We propose a methodology that adapts graph embedding techniques (DeepWalk (Perozzi et al., 2014) and node2vec (Grover and Leskovec, 2016)) as well as cross-lingual vector space mapping approaches (Least Squares and Canonical Correlation Analysis) in order to merge the corpus and ontological sources of lexical knowledge. We also perform comparative analysis of the used algorithms in order to identify the best combination for the proposed system. We then apply this to the task of enhancing the coverage of an existing word embedding's vocabulary with rare and unseen words. We show that our technique can provide considerable extra coverage (over 99%), leading to consistent performance gain (around 10% absolute gain is achieved with w2v-gn-500K cf.\u00a73.3) on the Rare Word Similarity dataset.\n    ",
        "submission_date": "2017-07-24T00:00:00",
        "last_modified_date": "2017-07-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.07605",
        "title": "Share your Model instead of your Data: Privacy Preserving Mimic Learning for Ranking",
        "authors": [
            "Mostafa Dehghani",
            "Hosein Azarbonyad",
            "Jaap Kamps",
            "Maarten de Rijke"
        ],
        "abstract": "Deep neural networks have become a primary tool for solving problems in many fields. They are also used for addressing information retrieval problems and show strong performance in several tasks. Training these models requires large, representative datasets and for most IR tasks, such data contains sensitive information from users. Privacy and confidentiality concerns prevent many data owners from sharing the data, thus today the research community can only benefit from research on large-scale datasets in a limited manner. In this paper, we discuss privacy preserving mimic learning, i.e., using predictions from a privacy preserving trained model instead of labels from the original sensitive training data as a supervision signal. We present the results of preliminary experiments in which we apply the idea of mimic learning and privacy preserving mimic learning for the task of document re-ranking as one of the core IR tasks. This research is a step toward laying the ground for enabling researchers from data-rich environments to share knowledge learned from actual users' data, which should facilitate research collaborations.\n    ",
        "submission_date": "2017-07-24T00:00:00",
        "last_modified_date": "2017-07-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.07662",
        "title": "Towards Real-Time Search Planning in Subsea Environments",
        "authors": [
            "James McMahon",
            "Harun Yetkin",
            "Artur Wolek",
            "Zachary Waters",
            "Dan Stilwell"
        ],
        "abstract": "We address the challenge of computing search paths in real-time for subsea applications where the goal is to locate an unknown number of targets on the seafloor. Our approach maximizes a formal definition of search effectiveness given finite search effort. We account for false positive measurements and variation in the performance of the search sensor due to geographic variation of the seafloor. We compare near-optimal search paths that can be computed in real-time with optimal search paths for which real-time computation is infeasible. We show how sonar data acquired for locating targets at a specific location can also be used to characterize the performance of the search sonar at that location. Our approach is illustrated with numerical experiments where search paths are planned using sonar data previously acquired from Boston Harbor.\n    ",
        "submission_date": "2017-07-24T00:00:00",
        "last_modified_date": "2017-07-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.07930",
        "title": "Structural Regularities in Text-based Entity Vector Spaces",
        "authors": [
            "Christophe Van Gysel",
            "Maarten de Rijke",
            "Evangelos Kanoulas"
        ],
        "abstract": "Entity retrieval is the task of finding entities such as people or products in response to a query, based solely on the textual documents they are associated with. Recent semantic entity retrieval algorithms represent queries and experts in finite-dimensional vector spaces, where both are constructed from text sequences.\n",
        "submission_date": "2017-07-25T00:00:00",
        "last_modified_date": "2017-07-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.08029",
        "title": "Price and Profit Awareness in Recommender Systems",
        "authors": [
            "Dietmar Jannach",
            "Gediminas Adomavicius"
        ],
        "abstract": "Academic research in the field of recommender systems mainly focuses on the problem of maximizing the users' utility by trying to identify the most relevant items for each user. However, such items are not necessarily the ones that maximize the utility of the service provider (e.g., an online retailer) in terms of the business value, such as profit. One approach to increasing the providers' utility is to incorporate purchase-oriented information, e.g., the price, sales probabilities, and the resulting profit, into the recommendation algorithms. In this paper we specifically focus on price- and profit-aware recommender systems. We provide a brief overview of the relevant literature and use numerical simulations to illustrate the potential business benefit of such approaches.\n    ",
        "submission_date": "2017-07-25T00:00:00",
        "last_modified_date": "2017-07-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.08114",
        "title": "A Survey on Multi-Task Learning",
        "authors": [
            "Yu Zhang",
            "Qiang Yang"
        ],
        "abstract": "Multi-Task Learning (MTL) is a learning paradigm in machine learning and its aim is to leverage useful information contained in multiple related tasks to help improve the generalization performance of all the tasks. In this paper, we give a survey for MTL from the perspective of algorithmic modeling, applications and theoretical analyses. For algorithmic modeling, we give a definition of MTL and then classify different MTL algorithms into five categories, including feature learning approach, low-rank approach, task clustering approach, task relation learning approach and decomposition approach as well as discussing the characteristics of each approach. In order to improve the performance of learning tasks further, MTL can be combined with other learning paradigms including semi-supervised learning, active learning, unsupervised learning, reinforcement learning, multi-view learning and graphical models. When the number of tasks is large or the data dimensionality is high, we review online, parallel and distributed MTL models as well as dimensionality reduction and feature hashing to reveal their computational and storage advantages. Many real-world applications use MTL to boost their performance and we review representative works in this paper. Finally, we present theoretical analyses and discuss several future directions for MTL.\n    ",
        "submission_date": "2017-07-25T00:00:00",
        "last_modified_date": "2021-03-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.08167",
        "title": "On The Robustness of a Neural Network",
        "authors": [
            "El Mahdi El Mhamdi",
            "Rachid Guerraoui",
            "Sebastien Rouault"
        ],
        "abstract": "With the development of neural networks based machine learning and their usage in mission critical applications, voices are rising against the \\textit{black box} aspect of neural networks as it becomes crucial to understand their limits and capabilities. With the rise of neuromorphic hardware, it is even more critical to understand how a neural network, as a distributed system, tolerates the failures of its computing nodes, neurons, and its communication channels, synapses. Experimentally assessing the robustness of neural networks involves the quixotic venture of testing all the possible failures, on all the possible inputs, which ultimately hits a combinatorial explosion for the first, and the impossibility to gather all the possible inputs for the second.\n",
        "submission_date": "2017-07-25T00:00:00",
        "last_modified_date": "2017-08-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.08250",
        "title": "Proceedings Sixteenth Conference on Theoretical Aspects of Rationality and Knowledge",
        "authors": [
            "J\u00e9r\u00f4me Lang"
        ],
        "abstract": "This volume consists of papers presented at the Sixteenth Conference on Theoretical Aspects of Rationality and Knowledge (TARK) held at the University of Liverpool, UK, from July 24 to 26, 2017.\n",
        "submission_date": "2017-07-25T00:00:00",
        "last_modified_date": "2017-07-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.08309",
        "title": "Probabilistic Graphical Models for Credibility Analysis in Evolving Online Communities",
        "authors": [
            "Subhabrata Mukherjee"
        ],
        "abstract": "One of the major hurdles preventing the full exploitation of information from online communities is the widespread concern regarding the quality and credibility of user-contributed content. Prior works in this domain operate on a static snapshot of the community, making strong assumptions about the structure of the data (e.g., relational tables), or consider only shallow features for text classification.\n",
        "submission_date": "2017-07-26T00:00:00",
        "last_modified_date": "2017-07-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.08454",
        "title": "Making the best of data derived from a daily practice in clinical legal medicine for research and practice - the example of Spe3dLab",
        "authors": [
            "Vincent Laugier",
            "Eric Stindel",
            "Alcibiade Lichterowicz",
            "S\u00e9verine Ansart",
            "Thomas Lef\u00e8vre"
        ],
        "abstract": "Forensic science suffers from a lack of studies with high-quality design, such as randomized controlled trials (RCT). Evidence in forensic science may be of insufficient quality, which is a major concern. Results from RCT are criticized for providing artificial results that are not useful in real life and unfit for individualized prescription. Various sources of collected data (e.g. data collected in routine practice) could be exploited for distinct goals. Obstacles remain before such data can be practically accessed and used, including technical issues. We present an easy-to-use software dedicated to innovative data analyses for practitioners and researchers. We provide 2 examples in forensics. Spe3dLab has been developed by 3 French teams: a bioinformatics laboratory (LaTIM), a private partner (Tekliko) and a department of forensic medicine (Jean Verdier Hospital). It was designed to be open source, relying on documented and maintained libraries, query-oriented and capable of handling the entire data process from capture to export of best predictive models for their integration in information systems. Spe3dLab was used for 2 specific forensics applications: i) the search for multiple causal factors and ii) the best predictive model of the functional impairment (total incapacity to work, TIW) of assault survivors. 2,892 patients were included over a 6-month period. Time to evaluation was the only direct cause identified for TIW, and victim category was an indirect cause. The specificity and sensitivity of the predictive model were 99.9% and 90%, respectively. Spe3dLab is a quick and efficient tool for accessing observational, routinely collected data and performing innovative analyses. Analyses can be exported for validation and routine use by practitioners, e.g., for computer-aided evaluation of complex problems. It can provide a fully integrated solution for individualized medicine.\n    ",
        "submission_date": "2017-07-26T00:00:00",
        "last_modified_date": "2017-07-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.08470",
        "title": "Implicit Entity Linking in Tweets",
        "authors": [
            "Sujan Perera",
            "Pablo N. Mendes",
            "Adarsh Alex",
            "Amit Sheth",
            "Krishnaprasad Thirunarayan"
        ],
        "abstract": "Over the years, Twitter has become one of the largest communication platforms providing key data to various applications such as brand monitoring, trend detection, among others. Entity linking is one of the major tasks in natural language understanding from tweets and it associates entity mentions in text to corresponding entries in knowledge bases in order to provide unambiguous interpretation and additional con- text. State-of-the-art techniques have focused on linking explicitly mentioned entities in tweets with reasonable success. However, we argue that in addition to explicit mentions i.e. The movie Gravity was more ex- pensive than the mars orbiter mission entities (movie Gravity) can also be mentioned implicitly i.e. This new space movie is crazy. you must watch it!. This paper introduces the problem of implicit entity linking in tweets. We propose an approach that models the entities by exploiting their factual and contextual knowledge. We demonstrate how to use these models to perform implicit entity linking on a ground truth dataset with 397 tweets from two domains, namely, Movie and Book. Specifically, we show: 1) the importance of linking implicit entities and its value addition to the standard entity linking task, and 2) the importance of exploiting contextual knowledge associated with an entity for linking their implicit mentions. We also make the ground truth dataset publicly available to foster the research in this new research area.\n    ",
        "submission_date": "2017-07-26T00:00:00",
        "last_modified_date": "2017-07-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.08475",
        "title": "DARLA: Improving Zero-Shot Transfer in Reinforcement Learning",
        "authors": [
            "Irina Higgins",
            "Arka Pal",
            "Andrei A. Rusu",
            "Loic Matthey",
            "Christopher P Burgess",
            "Alexander Pritzel",
            "Matthew Botvinick",
            "Charles Blundell",
            "Alexander Lerchner"
        ],
        "abstract": "Domain adaptation is an important open problem in deep reinforcement learning (RL). In many scenarios of interest data is hard to obtain, so agents may learn a source policy in a setting where data is readily available, with the hope that it generalises well to the target domain. We propose a new multi-stage RL agent, DARLA (DisentAngled Representation Learning Agent), which learns to see before learning to act. DARLA's vision is based on learning a disentangled representation of the observed environment. Once DARLA can see, it is able to acquire source policies that are robust to many domain shifts - even with no access to the target domain. DARLA significantly outperforms conventional baselines in zero-shot domain adaptation scenarios, an effect that holds across a variety of RL environments (Jaco arm, DeepMind Lab) and base RL algorithms (DQN, A3C and EC).\n    ",
        "submission_date": "2017-07-26T00:00:00",
        "last_modified_date": "2018-06-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.08559",
        "title": "Video Highlight Prediction Using Audience Chat Reactions",
        "authors": [
            "Cheng-Yang Fu",
            "Joon Lee",
            "Mohit Bansal",
            "Alexander C. Berg"
        ],
        "abstract": "Sports channel video portals offer an exciting domain for research on multimodal, multilingual analysis. We present methods addressing the problem of automatic video highlight prediction based on joint visual features and textual analysis of the real-world audience discourse with complex slang, in both English and traditional Chinese. We present a novel dataset based on League of Legends championships recorded from North American and Taiwanese ",
        "submission_date": "2017-07-26T00:00:00",
        "last_modified_date": "2017-07-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.08626",
        "title": "Robust Rigid Point Registration based on Convolution of Adaptive Gaussian Mixture Models",
        "authors": [
            "Can Pu",
            "Nanbo Li",
            "Robert B Fisher"
        ],
        "abstract": "Matching 3D rigid point clouds in complex environments robustly and accurately is still a core technique used in many applications. This paper proposes a new architecture combining error estimation from sample covariances and dual global probability alignment based on the convolution of adaptive Gaussian Mixture Models (GMM) from point clouds. Firstly, a novel adaptive GMM is defined using probability distributions from the corresponding points. Then rigid point cloud alignment is performed by maximizing the global probability from the convolution of dual adaptive GMMs in the whole 2D or 3D space, which can be efficiently optimized and has a large zone of accurate convergence. Thousands of trials have been conducted on 200 models from public 2D and 3D datasets to demonstrate superior robustness and accuracy in complex environments with unpredictable noise, outliers, occlusion, initial rotation, shape and missing points.\n    ",
        "submission_date": "2017-07-26T00:00:00",
        "last_modified_date": "2017-07-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.08734",
        "title": "Common Knowledge in a Logic of Gossips",
        "authors": [
            "Krzysztof R. Apt",
            "Dominik Wojtczak"
        ],
        "abstract": "Gossip protocols aim at arriving, by means of point-to-point or group communications, at a situation in which all the agents know each other secrets. Recently a number of authors studied distributed epistemic gossip protocols. These protocols use as guards formulas from a simple epistemic logic, which makes their analysis and verification substantially easier. \n",
        "submission_date": "2017-07-27T00:00:00",
        "last_modified_date": "2017-07-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.08735",
        "title": "A Logic for Global and Local Announcements",
        "authors": [
            "Francesco Belardinelli",
            "Hans van Ditmarsch",
            "Wiebe van der Hoek"
        ],
        "abstract": "In this paper we introduce {\\em global and local announcement logic} (GLAL), a dynamic epistemic logic with two distinct announcement operators -- $[\\phi]^+_A$ and $[\\phi]^-_A$ indexed to a subset $A$ of the set $Ag$ of all agents -- for global and local announcements respectively. The boundary case $[\\phi]^+_{Ag}$ corresponds to the public announcement of $\\phi$, as known from the literature. Unlike standard public announcements, which are {\\em model transformers}, the global and local announcements are {\\em pointed model transformers}. In particular, the update induced by the announcement may be different in different states of the model. Therefore, the resulting computations are trees of models, rather than the typical sequences. A consequence of our semantics is that modally bisimilar states may be distinguished in our logic. Then, we provide a stronger notion of bisimilarity and we show that it preserves modal equivalence in GLAL.  Additionally, we show that GLAL is strictly more expressive than public announcement logic with common knowledge. We prove a wide range of validities for GLAL involving the interaction between dynamics and knowledge, and show that the satisfiability problem for GLAL is decidable. We illustrate the formal machinery by means of detailed epistemic scenarios.\n    ",
        "submission_date": "2017-07-27T00:00:00",
        "last_modified_date": "2017-07-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.08741",
        "title": "Binary Voting with Delegable Proxy: An Analysis of Liquid Democracy",
        "authors": [
            "Zo\u00e9 Christoff",
            "Davide Grossi"
        ],
        "abstract": "The paper provides an analysis of the voting method known as delegable proxy voting, or liquid democracy. The analysis first positions liquid democracy within the theory of binary aggregation. It then focuses on two issues of the system: the occurrence of delegation cycles; and the effect of delegations on individual rationality when voting on logically interdependent propositions. It finally points to proposals on how the system may be modified in order to address the above issues.\n    ",
        "submission_date": "2017-07-27T00:00:00",
        "last_modified_date": "2017-07-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.08750",
        "title": "An Epistemic Foundation for Authentication Logics (Extended Abstract)",
        "authors": [
            "Joseph Y. Halpern",
            "Ron van der Meyden",
            "Riccardo Pucella"
        ],
        "abstract": "While there have been many attempts, going back to BAN logic, to base reasoning about security protocols on epistemic notions, they have not been all that successful. Arguably, this has been due to the particular logics chosen. We present a simple logic based on the well-understood modal operators of knowledge, time, and probability, and show that it is able to handle issues that have often been swept under the rug by other approaches, while being flexible enough to capture all the higher- level security notions that appear in BAN logic. Moreover, while still assuming that the knowledge operator allows for unbounded computation, it can handle the fact that a computationally bounded agent cannot decrypt messages in a natural way, by distinguishing strings and message terms. We demonstrate that our logic can capture BAN logic notions by providing a translation of the BAN operators into our logic, capturing belief by a form of probabilistic knowledge.\n    ",
        "submission_date": "2017-07-27T00:00:00",
        "last_modified_date": "2017-07-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.08755",
        "title": "Group Recommendations: Axioms, Impossibilities, and Random Walks",
        "authors": [
            "Omer Lev",
            "Moshe Tennenholtz"
        ],
        "abstract": "We introduce an axiomatic approach to group recommendations, in line of previous work on the axiomatic treatment of trust-based recommendation systems, ranking systems, and other foundational work on the axiomatic approach to internet mechanisms in social choice settings. In group recommendations we wish to recommend to a group of agents, consisting of both opinionated and undecided members, a joint choice that would be acceptable to them. Such a system has many applications, such as choosing a movie or a restaurant to go to with a group of friends, recommending games for online game players, & other communal activities.\n",
        "submission_date": "2017-07-27T00:00:00",
        "last_modified_date": "2017-07-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.08783",
        "title": "Analysis of Italian Word Embeddings",
        "authors": [
            "Rocco Tripodi",
            "Stefano Li Pira"
        ],
        "abstract": "In this work we analyze the performances of two of the most used word embeddings algorithms, skip-gram and continuous bag of words on Italian language. These algorithms have many hyper-parameter that have to be carefully tuned in order to obtain accurate word representation in vectorial space. We provide an accurate analysis and an evaluation, showing what are the best configuration of parameters for specific tasks.\n    ",
        "submission_date": "2017-07-27T00:00:00",
        "last_modified_date": "2017-11-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.08852",
        "title": "Detecting and Explaining Causes From Text For a Time Series Event",
        "authors": [
            "Dongyeop Kang",
            "Varun Gangal",
            "Ang Lu",
            "Zheng Chen",
            "Eduard Hovy"
        ],
        "abstract": "Explaining underlying causes or effects about events is a challenging but valuable task. We define a novel problem of generating explanations of a time series event by (1) searching cause and effect relationships of the time series with textual data and (2) constructing a connecting chain between them to generate an explanation. To detect causal features from text, we propose a novel method based on the Granger causality of time series between features extracted from text such as N-grams, topics, sentiments, and their composition. The generation of the sequence of causal entities requires a commonsense causative knowledge base with efficient reasoning. To ensure good interpretability and appropriate lexical usage we combine symbolic and neural representations, using a neural reasoning algorithm trained on commonsense causal tuples to predict the next cause step. Our quantitative and human analysis show empirical evidence that our method successfully extracts meaningful causality relationships between time series with textual features and generates appropriate explanation between them.\n    ",
        "submission_date": "2017-07-27T00:00:00",
        "last_modified_date": "2017-07-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.08866",
        "title": "Deep Residual Learning for Weakly-Supervised Relation Extraction",
        "authors": [
            "Yi Yao Huang",
            "William Yang Wang"
        ],
        "abstract": "Deep residual learning (ResNet) is a new method for training very deep neural networks using identity map-ping for shortcut connections. ResNet has won the ImageNet ILSVRC 2015 classification task, and achieved state-of-the-art performances in many computer vision tasks. However, the effect of residual learning on noisy natural language processing tasks is still not well understood. In this paper, we design a novel convolutional neural network (CNN) with residual learning, and investigate its impacts on the task of distantly supervised noisy relation extraction. In contradictory to popular beliefs that ResNet only works well for very deep networks, we found that even with 9 layers of CNNs, using identity mapping could significantly improve the performance for distantly-supervised relation extraction.\n    ",
        "submission_date": "2017-07-27T00:00:00",
        "last_modified_date": "2017-07-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.08912",
        "title": "A Family of Metrics for Clustering Algorithms",
        "authors": [
            "Clark Alexander",
            "Sofya Akhmametyeva"
        ],
        "abstract": "We give the motivation for scoring clustering algorithms and a metric $M : A \\rightarrow \\mathbb{N}$ from the set of clustering algorithms to the natural numbers which we realize as \\begin{equation} M(A) = \\sum_i \\alpha_i |f_i - \\beta_i|^{w_i} \\end{equation} where $\\alpha_i,\\beta_i,w_i$ are parameters used for scoring the feature $f_i$, which is computed empirically.. We give a method by which one can score features such as stability, noise sensitivity, etc and derive the necessary parameters. We conclude by giving a sample set of scores.\n    ",
        "submission_date": "2017-07-27T00:00:00",
        "last_modified_date": "2017-07-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.09198",
        "title": "Data-Driven Stochastic Robust Optimization: A General Computational Framework and Algorithm for Optimization under Uncertainty in the Big Data Era",
        "authors": [
            "Chao Ning",
            "Fengqi You"
        ],
        "abstract": "A novel data-driven stochastic robust optimization (DDSRO) framework is proposed for optimization under uncertainty leveraging labeled multi-class uncertainty data. Uncertainty data in large datasets are often collected from various conditions, which are encoded by class labels. Machine learning methods including Dirichlet process mixture model and maximum likelihood estimation are employed for uncertainty modeling. A DDSRO framework is further proposed based on the data-driven uncertainty model through a bi-level optimization structure. The outer optimization problem follows a two-stage stochastic programming approach to optimize the expected objective across different data classes; adaptive robust optimization is nested as the inner problem to ensure the robustness of the solution while maintaining computational tractability. A decomposition-based algorithm is further developed to solve the resulting multi-level optimization problem efficiently. Case studies on process network design and planning are presented to demonstrate the applicability of the proposed framework and algorithm.\n    ",
        "submission_date": "2017-07-28T00:00:00",
        "last_modified_date": "2017-12-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.09219",
        "title": "Recurrent Ladder Networks",
        "authors": [
            "Isabeau Pr\u00e9mont-Schwarz",
            "Alexander Ilin",
            "Tele Hotloo Hao",
            "Antti Rasmus",
            "Rinu Boney",
            "Harri Valpola"
        ],
        "abstract": "We propose a recurrent extension of the Ladder networks whose structure is motivated by the inference required in hierarchical latent variable models. We demonstrate that the recurrent Ladder is able to handle a wide variety of complex learning tasks that benefit from iterative inference and temporal modeling. The architecture shows close-to-optimal results on temporal modeling of video data, competitive results on music modeling, and improved perceptual grouping based on higher order abstractions, such as stochastic textures and motion cues. We present results for fully supervised, semi-supervised, and unsupervised tasks. The results suggest that the proposed architecture and principles are powerful tools for learning a hierarchy of abstractions, learning iterative inference and handling temporal information.\n    ",
        "submission_date": "2017-07-28T00:00:00",
        "last_modified_date": "2017-12-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.09376",
        "title": "Face Deidentification with Generative Deep Neural Networks",
        "authors": [
            "Bla\u017e Meden",
            "Refik Can Mall\u0131",
            "Sebastjan Fabijan",
            "Haz\u0131m Kemal Ekenel",
            "Vitomir \u0160truc",
            "Peter Peer"
        ],
        "abstract": "Face deidentification is an active topic amongst privacy and security researchers. Early deidentification methods relying on image blurring or pixelization were replaced in recent years with techniques based on formal anonymity models that provide privacy guaranties and at the same time aim at retaining certain characteristics of the data even after deidentification. The latter aspect is particularly important, as it allows to exploit the deidentified data in applications for which identity information is irrelevant. In this work we present a novel face deidentification pipeline, which ensures anonymity by synthesizing artificial surrogate faces using generative neural networks (GNNs). The generated faces are used to deidentify subjects in images or video, while preserving non-identity-related aspects of the data and consequently enabling data utilization. Since generative networks are very adaptive and can utilize a diverse set of parameters (pertaining to the appearance of the generated output in terms of facial expressions, gender, race, etc.), they represent a natural choice for the problem of face deidentification. To demonstrate the feasibility of our approach, we perform experiments using automated recognition tools and human annotators. Our results show that the recognition performance on deidentified images is close to chance, suggesting that the deidentification process based on GNNs is highly effective.\n    ",
        "submission_date": "2017-07-28T00:00:00",
        "last_modified_date": "2017-07-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.09378",
        "title": "The Topology of Statistical Verifiability",
        "authors": [
            "Konstantin Genin",
            "Kevin T. Kelly"
        ],
        "abstract": "Topological models of empirical and formal inquiry are increasingly prevalent. They have emerged in such diverse fields as domain theory [1, 16], formal learning theory [18], epistemology and philosophy of science [10, 15, 8, 9, 2], statistics [6, 7] and modal logic [17, 4]. In those applications, open sets are typically interpreted as hypotheses deductively verifiable by true propositional information that rules out relevant possibilities. However, in statistical data analysis, one routinely receives random samples logically compatible with every statistical hypothesis. We bridge the gap between propositional and statistical data by solving for the unique topology on probability measures in which the open sets are exactly the statistically verifiable hypotheses. Furthermore, we extend that result to a topological characterization of learnability in the limit from statistical data.\n    ",
        "submission_date": "2017-07-27T00:00:00",
        "last_modified_date": "2017-07-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.09405",
        "title": "Photographic Image Synthesis with Cascaded Refinement Networks",
        "authors": [
            "Qifeng Chen",
            "Vladlen Koltun"
        ],
        "abstract": "We present an approach to synthesizing photographic images conditioned on semantic layouts. Given a semantic label map, our approach produces an image with photographic appearance that conforms to the input layout. The approach thus functions as a rendering engine that takes a two-dimensional semantic specification of the scene and produces a corresponding photographic image. Unlike recent and contemporaneous work, our approach does not rely on adversarial training. We show that photographic images can be synthesized from semantic layouts by a single feedforward network with appropriate structure, trained end-to-end with a direct regression objective. The presented approach scales seamlessly to high resolutions; we demonstrate this by synthesizing photographic images at 2-megapixel resolution, the full resolution of our training data. Extensive perceptual experiments on datasets of outdoor and indoor scenes demonstrate that images synthesized by the presented approach are considerably more realistic than alternative approaches. The results are shown in the supplementary video at ",
        "submission_date": "2017-07-28T00:00:00",
        "last_modified_date": "2017-07-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.09422",
        "title": "Hyperprofile-based Computation Offloading for Mobile Edge Networks",
        "authors": [
            "Andrew Crutcher",
            "Caleb Koch",
            "Kyle Coleman",
            "Jon Patman",
            "Flavio Esposito",
            "Prasad Calyam"
        ],
        "abstract": "In recent studies, researchers have developed various computation offloading frameworks for bringing cloud services closer to the user via edge networks. Specifically, an edge device needs to offload computationally intensive tasks because of energy and processing constraints. These constraints present the challenge of identifying which edge nodes should receive tasks to reduce overall resource consumption. We propose a unique solution to this problem which incorporates elements from Knowledge-Defined Networking (KDN) to make intelligent predictions about offloading costs based on historical data. Each server instance can be represented in a multidimensional feature space where each dimension corresponds to a predicted metric. We compute features for a \"hyperprofile\" and position nodes based on the predicted costs of offloading a particular task. We then perform a k-Nearest Neighbor (kNN) query within the hyperprofile to select nodes for offloading computation. This paper formalizes our hyperprofile-based solution and explores the viability of using machine learning (ML) techniques to predict metrics useful for computation offloading. We also investigate the effects of using different distance metrics for the queries. Our results show various network metrics can be modeled accurately with regression, and there are circumstances where kNN queries using Euclidean distance as opposed to rectilinear distance is more favorable.\n    ",
        "submission_date": "2017-07-28T00:00:00",
        "last_modified_date": "2017-07-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.09487",
        "title": "Method and apparatus for automatic text input insertion in digital devices with a restricted number of keys",
        "authors": [
            "Nikolaos Tselios",
            "Manolis Maragoudakis"
        ],
        "abstract": "A device which contains number of symbol input keys, where the number of available keys is less than the number of symbols of an alphabet of any given language, screen, and dynamic reordering table of the symbols which are mapped onto those keys, according to a disambiguation method based on the previously entered symbols. The device incorporates a previously entered keystrokes tracking mechanism, and the key selected by the user detector, as well as a mechanism to select the dynamic symbol reordering mapped onto this key according to the information contained to the reordering table. The reordering table occurs from a disambiguation method which reorders the symbol appearance. The reordering information occurs from Bayesian Belief network construction and training from text corpora of the specific language.\n    ",
        "submission_date": "2017-07-29T00:00:00",
        "last_modified_date": "2017-07-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.09585",
        "title": "Virtual PET Images from CT Data Using Deep Convolutional Networks: Initial Results",
        "authors": [
            "Avi Ben-Cohen",
            "Eyal Klang",
            "Stephen P. Raskin",
            "Michal Marianne Amitai",
            "Hayit Greenspan"
        ],
        "abstract": "In this work we present a novel system for PET estimation using CT scans. We explore the use of fully convolutional networks (FCN) and conditional generative adversarial networks (GAN) to export PET data from CT data. Our dataset includes 25 pairs of PET and CT scans where 17 were used for training and 8 for testing. The system was tested for detection of malignant tumors in the liver region. Initial results look promising showing high detection performance with a TPR of 92.3% and FPR of 0.25 per case. Future work entails expansion of the current system to the entire body using a much larger dataset. Such a system can be used for tumor detection and drug treatment evaluation in a CT-only environment instead of the expansive and radioactive PET-CT scan.\n    ",
        "submission_date": "2017-07-30T00:00:00",
        "last_modified_date": "2017-07-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.09899",
        "title": "Fashioning with Networks: Neural Style Transfer to Design Clothes",
        "authors": [
            "Prutha Date",
            "Ashwinkumar Ganesan",
            "Tim Oates"
        ],
        "abstract": "Convolutional Neural Networks have been highly successful in performing a host of computer vision tasks such as object recognition, object detection, image segmentation and texture synthesis. In 2015, Gatys et. al [7] show how the style of a painter can be extracted from an image of the painting and applied to another normal photograph, thus recreating the photo in the style of the painter. The method has been successfully applied to a wide range of images and has since spawned multiple applications and mobile apps. In this paper, the neural style transfer algorithm is applied to fashion so as to synthesize new custom clothes. We construct an approach to personalize and generate new custom clothes based on a users preference and by learning the users fashion choices from a limited set of clothes from their closet. The approach is evaluated by analyzing the generated images of clothes and how well they align with the users fashion style.\n    ",
        "submission_date": "2017-07-31T00:00:00",
        "last_modified_date": "2017-07-31T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.09933",
        "title": "Learning Neural Network Classifiers with Low Model Complexity",
        "authors": [
            "Jayadeva",
            "Himanshu Pant",
            "Mayank Sharma",
            "Abhimanyu Dubey",
            "Sumit Soman",
            "Suraj Tripathi",
            "Sai Guruju",
            "Nihal Goalla"
        ],
        "abstract": "Modern neural network architectures for large-scale learning tasks have substantially higher model complexities, which makes understanding, visualizing and training these architectures difficult. Recent contributions to deep learning techniques have focused on architectural modifications to improve parameter efficiency and performance. In this paper, we derive a continuous and differentiable error functional for a neural network that minimizes its empirical error as well as a measure of the model complexity. The latter measure is obtained by deriving a differentiable upper bound on the Vapnik-Chervonenkis (VC) dimension of the classifier layer of a class of deep networks. Using standard backpropagation, we realize a training rule that tries to minimize the error on training samples, while improving generalization by keeping the model complexity low. We demonstrate the effectiveness of our formulation (the Low Complexity Neural Network - LCNN) across several deep learning algorithms, and a variety of large benchmark datasets. We show that hidden layer neurons in the resultant networks learn features that are crisp, and in the case of image datasets, quantitatively sharper. Our proposed approach yields benefits across a wide range of architectures, in comparison to and in conjunction with methods such as Dropout and Batch Normalization, and our results strongly suggest that deep learning techniques can benefit from model complexity control methods such as the LCNN learning rule.\n    ",
        "submission_date": "2017-07-31T00:00:00",
        "last_modified_date": "2021-03-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1707.09938",
        "title": "Deep Convolutional Framelet Denosing for Low-Dose CT via Wavelet Residual Network",
        "authors": [
            "Eunhee Kang",
            "Jaejun Yoo",
            "Jong Chul Ye"
        ],
        "abstract": "Model based iterative reconstruction (MBIR) algorithms for low-dose X-ray CT are computationally expensive. To address this problem, we recently proposed a deep convolutional neural network (CNN) for low-dose X-ray CT and won the second place in 2016 AAPM Low-Dose CT Grand Challenge. However, some of the texture were not fully recovered. To address this problem, here we propose a novel framelet-based denoising algorithm using wavelet residual network which synergistically combines the expressive power of deep learning and the performance guarantee from the framelet-based denoising algorithms. The new algorithms were inspired by the recent interpretation of the deep convolutional neural network (CNN) as a cascaded convolution framelet signal representation. Extensive experimental results confirm that the proposed networks have significantly improved performance and preserves the detail texture of the original images.\n    ",
        "submission_date": "2017-07-31T00:00:00",
        "last_modified_date": "2018-03-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.00107",
        "title": "Learned in Translation: Contextualized Word Vectors",
        "authors": [
            "Bryan McCann",
            "James Bradbury",
            "Caiming Xiong",
            "Richard Socher"
        ],
        "abstract": "Computer vision has benefited from initializing multiple deep layers with weights pretrained on large supervised training sets like ImageNet. Natural language processing (NLP) typically sees initialization of only the lowest layer of deep models with pretrained word vectors. In this paper, we use a deep LSTM encoder from an attentional sequence-to-sequence model trained for machine translation (MT) to contextualize word vectors. We show that adding these context vectors (CoVe) improves performance over using only unsupervised word and character vectors on a wide variety of common NLP tasks: sentiment analysis (SST, IMDb), question classification (TREC), entailment (SNLI), and question answering (SQuAD). For fine-grained sentiment analysis and entailment, CoVe improves performance of our baseline models to the state of the art.\n    ",
        "submission_date": "2017-08-01T00:00:00",
        "last_modified_date": "2018-06-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.00133",
        "title": "Grounding Language for Transfer in Deep Reinforcement Learning",
        "authors": [
            "Karthik Narasimhan",
            "Regina Barzilay",
            "Tommi Jaakkola"
        ],
        "abstract": "In this paper, we explore the utilization of natural language to drive transfer for reinforcement learning (RL). Despite the wide-spread application of deep RL techniques, learning generalized policy representations that work across domains remains a challenging problem. We demonstrate that textual descriptions of environments provide a compact intermediate channel to facilitate effective policy transfer. Specifically, by learning to ground the meaning of text to the dynamics of the environment such as transitions and rewards, an autonomous agent can effectively bootstrap policy learning on a new domain given its description. We employ a model-based RL approach consisting of a differentiable planning module, a model-free component and a factorized state representation to effectively use entity descriptions. Our model outperforms prior work on both transfer and multi-task scenarios in a variety of different environments. For instance, we achieve up to 14% and 11.5% absolute improvement over previously existing models in terms of average and initial rewards, respectively.\n    ",
        "submission_date": "2017-08-01T00:00:00",
        "last_modified_date": "2018-12-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.00146",
        "title": "Large-Scale Low-Rank Matrix Learning with Nonconvex Regularizers",
        "authors": [
            "Quanming Yao",
            "James T.Kwok",
            "Taifeng Wang",
            "Tie-Yan Liu"
        ],
        "abstract": "Low-rank modeling has many important applications in computer vision and machine learning. While the matrix rank is often approximated by the convex nuclear norm, the use of nonconvex low-rank regularizers has demonstrated better empirical performance. However, the resulting optimization problem is much more challenging. Recent state-of-the-art requires an expensive full SVD in each iteration. In this paper, we show that for many commonly-used nonconvex low-rank regularizers, a cutoff can be derived to automatically threshold the singular values obtained from the proximal operator. This allows such operator being efficiently approximated by power method. Based on it, we develop a proximal gradient algorithm (and its accelerated variant) with inexact proximal splitting and prove that a convergence rate of O(1/T) where T is the number of iterations is guaranteed. Furthermore, we show the proposed algorithm can be well parallelized, which achieves nearly linear speedup w.r.t the number of threads. Extensive experiments are performed on matrix completion and robust principal component analysis, which shows a significant speedup over the state-of-the-art. Moreover, the matrix solution obtained is more accurate and has a lower rank than that of the nuclear norm regularizer.\n    ",
        "submission_date": "2017-08-01T00:00:00",
        "last_modified_date": "2018-07-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.00154",
        "title": "Neural Rating Regression with Abstractive Tips Generation for Recommendation",
        "authors": [
            "Piji Li",
            "Zihao Wang",
            "Zhaochun Ren",
            "Lidong Bing",
            "Wai Lam"
        ],
        "abstract": "Recently, some E-commerce sites launch a new interaction box called Tips on their mobile apps. Users can express their experience and feelings or provide suggestions using short texts typically several words or one sentence. In essence, writing some tips and giving a numerical rating are two facets of a user's product assessment action, expressing the user experience and feelings. Jointly modeling these two facets is helpful for designing a better recommendation system. While some existing models integrate text information such as item specifications or user reviews into user and item latent factors for improving the rating prediction, no existing works consider tips for improving recommendation quality. We propose a deep learning based framework named NRT which can simultaneously predict precise ratings and generate abstractive tips with good linguistic quality simulating user experience and feelings. For abstractive tips generation, gated recurrent neural networks are employed to \"translate\" user and item latent representations into a concise sentence. Extensive experiments on benchmark datasets from different domains show that NRT achieves significant improvements over the state-of-the-art methods. Moreover, the generated tips can vividly predict the user experience and feelings.\n    ",
        "submission_date": "2017-08-01T00:00:00",
        "last_modified_date": "2017-08-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.00224",
        "title": "Fast Preprocessing for Robust Face Sketch Synthesis",
        "authors": [
            "Yibing Song",
            "Jiawei Zhang",
            "Linchao Bao",
            "Qingxiong Yang"
        ],
        "abstract": "Exemplar-based face sketch synthesis methods usually meet the challenging problem that input photos are captured in different lighting conditions from training photos. The critical step causing the failure is the search of similar patch candidates for an input photo patch. Conventional illumination invariant patch distances are adopted rather than directly relying on pixel intensity difference, but they will fail when local contrast within a patch changes. In this paper, we propose a fast preprocessing method named Bidirectional Luminance Remapping (BLR), which interactively adjust the lighting of training and input photos. Our method can be directly integrated into state-of-the-art exemplar-based methods to improve their robustness with ignorable computational cost.\n    ",
        "submission_date": "2017-08-01T00:00:00",
        "last_modified_date": "2017-08-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.00225",
        "title": "CREST: Convolutional Residual Learning for Visual Tracking",
        "authors": [
            "Yibing Song",
            "Chao Ma",
            "Lijun Gong",
            "Jiawei Zhang",
            "Rynson Lau",
            "Ming-Hsuan Yang"
        ],
        "abstract": "Discriminative correlation filters (DCFs) have been shown to perform superiorly in visual tracking. They only need a small set of training samples from the initial frame to generate an appearance model. However, existing DCFs learn the filters separately from feature extraction, and update these filters using a moving average operation with an empirical weight. These DCF trackers hardly benefit from the end-to-end training. In this paper, we propose the CREST algorithm to reformulate DCFs as a one-layer convolutional neural network. Our method integrates feature extraction, response map generation as well as model update into the neural networks for an end-to-end training. To reduce model degradation during online update, we apply residual learning to take appearance changes into account. Extensive experiments on the benchmark datasets demonstrate that our CREST tracker performs favorably against state-of-the-art trackers.\n    ",
        "submission_date": "2017-08-01T00:00:00",
        "last_modified_date": "2017-08-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.00339",
        "title": "Attend and Predict: Understanding Gene Regulation by Selective Attention on Chromatin",
        "authors": [
            "Ritambhara Singh",
            "Jack Lanchantin",
            "Arshdeep Sekhon",
            "Yanjun Qi"
        ],
        "abstract": "The past decade has seen a revolution in genomic technologies that enable a flood of genome-wide profiling of chromatin marks. Recent literature tried to understand gene regulation by predicting gene expression from large-scale chromatin measurements. Two fundamental challenges exist for such learning tasks: (1) genome-wide chromatin signals are spatially structured, high-dimensional and highly modular; and (2) the core aim is to understand what are the relevant factors and how they work together? Previous studies either failed to model complex dependencies among input signals or relied on separate feature analysis to explain the decisions. This paper presents an attention-based deep learning approach; we call AttentiveChrome, that uses a unified architecture to model and to interpret dependencies among chromatin factors for controlling gene regulation. AttentiveChrome uses a hierarchy of multiple Long short-term memory (LSTM) modules to encode the input signals and to model how various chromatin marks cooperate automatically. AttentiveChrome trains two levels of attention jointly with the target prediction, enabling it to attend differentially to relevant marks and to locate important positions per mark. We evaluate the model across 56 different cell types (tasks) in human. Not only is the proposed architecture more accurate, but its attention scores also provide a better interpretation than state-of-the-art feature visualization methods such as saliency map.\n",
        "submission_date": "2017-08-01T00:00:00",
        "last_modified_date": "2017-11-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.00495",
        "title": "\"I can assure you [$\\ldots$] that it's going to be all right\" -- A definition, case for, and survey of algorithmic assurances in human-autonomy trust relationships",
        "authors": [
            "Brett W Israelsen"
        ],
        "abstract": "As technology become more advanced, those who design, use and are otherwise affected by it want to know that it will perform correctly, and understand why it does what it does, and how to use it appropriately. In essence they want to be able to trust the systems that are being designed. In this survey we present assurances that are the method by which users can understand how to trust this technology. Trust between humans and autonomy is reviewed, and the implications for the design of assurances are highlighted. A survey of research that has been performed with respect to assurances is presented, and several key ideas are extracted in order to refine the definition of assurances. Several directions for future research are identified and discussed.\n    ",
        "submission_date": "2017-08-01T00:00:00",
        "last_modified_date": "2017-09-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.00625",
        "title": "Deep Recurrent Generative Decoder for Abstractive Text Summarization",
        "authors": [
            "Piji Li",
            "Wai Lam",
            "Lidong Bing",
            "Zihao Wang"
        ],
        "abstract": "We propose a new framework for abstractive text summarization based on a sequence-to-sequence oriented encoder-decoder model equipped with a deep recurrent generative decoder (DRGN).\n",
        "submission_date": "2017-08-02T00:00:00",
        "last_modified_date": "2017-08-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.00630",
        "title": "ProjectionNet: Learning Efficient On-Device Deep Networks Using Neural Projections",
        "authors": [
            "Sujith Ravi"
        ],
        "abstract": "Deep neural networks have become ubiquitous for applications related to visual recognition and language understanding tasks. However, it is often prohibitive to use typical neural networks on devices like mobile phones or smart watches since the model sizes are huge and cannot fit in the limited memory available on such devices. While these devices could make use of machine learning models running on high-performance data centers with CPUs or GPUs, this is not feasible for many applications because data can be privacy sensitive and inference needs to be performed directly \"on\" device.\n",
        "submission_date": "2017-08-02T00:00:00",
        "last_modified_date": "2017-08-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.00631",
        "title": "On the Importance of Consistency in Training Deep Neural Networks",
        "authors": [
            "Chengxi Ye",
            "Yezhou Yang",
            "Cornelia Fermuller",
            "Yiannis Aloimonos"
        ],
        "abstract": "We explain that the difficulties of training deep neural networks come from a syndrome of three consistency issues. This paper describes our efforts in their analysis and treatment. The first issue is the training speed inconsistency in different layers. We propose to address it with an intuitive, simple-to-implement, low footprint second-order method. The second issue is the scale inconsistency between the layer inputs and the layer residuals. We explain how second-order information provides favorable convenience in removing this roadblock. The third and most challenging issue is the inconsistency in residual propagation. Based on the fundamental theorem of linear algebra, we provide a mathematical characterization of the famous vanishing gradient problem. Thus, an important design principle for future optimization and neural network design is derived. We conclude this paper with the construction of a novel contractive neural network.\n    ",
        "submission_date": "2017-08-02T00:00:00",
        "last_modified_date": "2017-08-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.00807",
        "title": "Adversarial-Playground: A Visualization Suite Showing How Adversarial Examples Fool Deep Learning",
        "authors": [
            "Andrew P. Norton",
            "Yanjun Qi"
        ],
        "abstract": "Recent studies have shown that attackers can force deep learning models to misclassify so-called \"adversarial examples\": maliciously generated images formed by making imperceptible modifications to pixel values. With growing interest in deep learning for security applications, it is important for security experts and users of machine learning to recognize how learning systems may be attacked. Due to the complex nature of deep learning, it is challenging to understand how deep models can be fooled by adversarial examples. Thus, we present a web-based visualization tool, Adversarial-Playground, to demonstrate the efficacy of common adversarial methods against a convolutional neural network (CNN) system. Adversarial-Playground is educational, modular and interactive. (1) It enables non-experts to compare examples visually and to understand why an adversarial example can fool a CNN-based image classifier. (2) It can help security experts explore more vulnerability of deep learning as a software module. (3) Building an interactive visualization is challenging in this domain due to the large feature space of image classification (generating adversarial examples is slow in general and visualizing images are costly). Through multiple novel design choices, our tool can provide fast and accurate responses to user requests. Empirically, we find that our client-server division strategy reduced the response time by an average of 1.5 seconds per sample. Our other innovation, a faster variant of JSMA evasion algorithm, empirically performed twice as fast as JSMA and yet maintains a comparable evasion rate.\n",
        "submission_date": "2017-08-01T00:00:00",
        "last_modified_date": "2017-08-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.01065",
        "title": "Reader-Aware Multi-Document Summarization: An Enhanced Model and The First Dataset",
        "authors": [
            "Piji Li",
            "Lidong Bing",
            "Wai Lam"
        ],
        "abstract": "We investigate the problem of reader-aware multi-document summarization (RA-MDS) and introduce a new dataset for this problem. To tackle RA-MDS, we extend a variational auto-encodes (VAEs) based MDS framework by jointly considering news documents and reader comments. To conduct evaluation for summarization performance, we prepare a new dataset. We describe the methods for data collection, aspect annotation, and summary writing as well as scrutinizing by experts. Experimental results show that reader comments can improve the summarization performance, which also demonstrates the usefulness of the proposed dataset. The annotated dataset for RA-MDS is available online.\n    ",
        "submission_date": "2017-08-03T00:00:00",
        "last_modified_date": "2017-08-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.01289",
        "title": "Independently Controllable Factors",
        "authors": [
            "Valentin Thomas",
            "Jules Pondard",
            "Emmanuel Bengio",
            "Marc Sarfati",
            "Philippe Beaudoin",
            "Marie-Jean Meurs",
            "Joelle Pineau",
            "Doina Precup",
            "Yoshua Bengio"
        ],
        "abstract": "It has been postulated that a good representation is one that disentangles the underlying explanatory factors of variation. However, it remains an open question what kind of training framework could potentially achieve that. Whereas most previous work focuses on the static setting (e.g., with images), we postulate that some of the causal factors could be discovered if the learner is allowed to interact with its environment. The agent can experiment with different actions and observe their effects. More specifically, we hypothesize that some of these factors correspond to aspects of the environment which are independently controllable, i.e., that there exists a policy and a learnable feature for each such aspect of the environment, such that this policy can yield changes in that feature with minimal changes to other features that explain the statistical variations in the observed data. We propose a specific objective function to find such factors and verify experimentally that it can indeed disentangle independently controllable aspects of the environment without any extrinsic reward signal.\n    ",
        "submission_date": "2017-08-03T00:00:00",
        "last_modified_date": "2017-08-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.01318",
        "title": "The UMD Neural Machine Translation Systems at WMT17 Bandit Learning Task",
        "authors": [
            "Amr Sharaf",
            "Shi Feng",
            "Khanh Nguyen",
            "Kiant\u00e9 Brantley",
            "Hal Daum\u00e9 III"
        ],
        "abstract": "We describe the University of Maryland machine translation systems submitted to the WMT17 German-English Bandit Learning Task. The task is to adapt a translation system to a new domain, using only bandit feedback: the system receives a German sentence to translate, produces an English sentence, and only gets a scalar score as feedback. Targeting these two challenges (adaptation and bandit learning), we built a standard neural machine translation system and extended it in two ways: (1) robust reinforcement learning techniques to learn effectively from the bandit feedback, and (2) domain adaptation using data selection from a large corpus of parallel data.\n    ",
        "submission_date": "2017-08-03T00:00:00",
        "last_modified_date": "2017-08-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.01425",
        "title": "The Argument Reasoning Comprehension Task: Identification and Reconstruction of Implicit Warrants",
        "authors": [
            "Ivan Habernal",
            "Henning Wachsmuth",
            "Iryna Gurevych",
            "Benno Stein"
        ],
        "abstract": "Reasoning is a crucial part of natural language argumentation. To comprehend an argument, one must analyze its warrant, which explains why its claim follows from its premises. As arguments are highly contextualized, warrants are usually presupposed and left implicit. Thus, the comprehension does not only require language understanding and logic skills, but also depends on common sense. In this paper we develop a methodology for reconstructing warrants systematically. We operationalize it in a scalable crowdsourcing process, resulting in a freely licensed dataset with warrants for 2k authentic arguments from news comments. On this basis, we present a new challenging task, the argument reasoning comprehension task. Given an argument with a claim and a premise, the goal is to choose the correct implicit warrant from two options. Both warrants are plausible and lexically close, but lead to contradicting claims. A solution to this task will define a substantial step towards automatic warrant reconstruction. However, experiments with several neural attention and language models reveal that current approaches do not suffice.\n    ",
        "submission_date": "2017-08-04T00:00:00",
        "last_modified_date": "2018-02-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.01599",
        "title": "Agent based Tools for Modeling and Simulation of Self-Organization in Peer-to-Peer, Ad-Hoc and other Complex Networks",
        "authors": [
            "Muaz A. Niazi",
            "Amir Hussain"
        ],
        "abstract": "Agent-based modeling and simulation tools provide a mature platform for development of complex simulations. They however, have not been applied much in the domain of mainstream modeling and simulation of computer networks. In this article, we evaluate how and if these tools can offer any value-addition in the modeling & simulation of complex networks such as pervasive computing, large-scale peer-to-peer systems, and networks involving considerable environment and human/animal/habitat interaction. Specifically, we demonstrate the effectiveness of NetLogo - a tool that has been widely used in the area of agent-based social simulation.\n    ",
        "submission_date": "2017-08-04T00:00:00",
        "last_modified_date": "2017-08-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.01611",
        "title": "Identification of Probabilities",
        "authors": [
            "Paul M.B. Vitanyi",
            "Nick Chater"
        ],
        "abstract": "Within psychology, neuroscience and artificial intelligence, there has been increasing interest in the proposal that the brain builds probabilistic models of sensory and linguistic input: that is, to infer a probabilistic model from a sample. The practical problems of such inference are substantial: the brain has limited data and restricted computational resources. But there is a more fundamental question: is the problem of inferring a probabilistic model from a sample possible even in principle? We explore this question and find some surprisingly positive and general results. First, for a broad class of probability distributions characterised by computability restrictions, we specify a learning algorithm that will almost surely identify a probability distribution in the limit given a finite i.i.d. sample of sufficient but unknown length. This is similarly shown to hold for sequences generated by a broad class of Markov chains, subject to computability assumptions. The technical tool is the strong law of large numbers. Second, for a large class of dependent sequences, we specify an algorithm which identifies in the limit a computable measure for which the sequence is typical, in the sense of Martin-Lof (there may be more than one such measure). The technical tool is the theory of Kolmogorov complexity. We analyse the associated predictions in both cases. We also briefly consider special cases, including language learning, and wider theoretical implications for psychology.\n    ",
        "submission_date": "2017-08-04T00:00:00",
        "last_modified_date": "2017-08-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.01628",
        "title": "Validation of Enhanced Emotion Enabled Cognitive Agent Using Virtual Overlay Multi-Agent System Approach",
        "authors": [
            "Faisal Riaz",
            "Muaz A. Niazi"
        ],
        "abstract": "Making roads safer by avoiding road collisions is one of the main reasons for inventing Autonomous vehicles (AVs). In this context, designing agent-based collision avoidance components of AVs which truly represent human cognition and emotions look is a more feasible approach as agents can replace human drivers. However, to the best of our knowledge, very few human emotion and cognition-inspired agent-based studies have previously been conducted in this domain. Furthermore, these agent-based solutions have not been validated using any key validation technique. Keeping in view this lack of validation practices, we have selected state-of-the-art Emotion Enabled Cognitive Agent (EEC_Agent), which was proposed to avoid lateral collisions between semi-AVs. The architecture of EEC_Agent has been revised using Exploratory Agent Based Modeling (EABM) level of the Cognitive Agent Based Computing (CABC) framework and real-time fear emotion generation mechanism using the Ortony, Clore & Collins (OCC) model has also been introduced. Then the proposed fear generation mechanism has been validated using the Validated Agent Based Modeling level of CABC framework using a Virtual Overlay MultiAgent System (VOMAS). Extensive simulation and practical experiments demonstrate that the Enhanced EEC_Agent exhibits the capability to feel different levels of fear, according to different traffic situations and also needs a smaller Stopping Sight Distance (SSD) and Overtaking Sight Distance (OSD) as compared to human drivers.\n    ",
        "submission_date": "2017-08-04T00:00:00",
        "last_modified_date": "2017-08-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.01636",
        "title": "Game theory models for communication between agents: a review",
        "authors": [
            "Aisha D. Farooqui",
            "Muaz A. Niazi"
        ],
        "abstract": "In the real world, agents or entities are in a continuous state of interactions. These inter- actions lead to various types of complexity dynamics. One key difficulty in the study of complex agent interactions is the difficulty of modeling agent communication on the basis of rewards. Game theory offers a perspective of analysis and modeling these interactions. Previously, while a large amount of literature is available on game theory, most of it is from specific domains and does not cater for the concepts from an agent- based perspective. Here in this paper, we present a comprehensive multidisciplinary state-of-the-art review and taxonomy of game theory models of complex interactions between agents.\n    ",
        "submission_date": "2017-08-04T00:00:00",
        "last_modified_date": "2017-08-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.01648",
        "title": "3D-PRNN: Generating Shape Primitives with Recurrent Neural Networks",
        "authors": [
            "Chuhang Zou",
            "Ersin Yumer",
            "Jimei Yang",
            "Duygu Ceylan",
            "Derek Hoiem"
        ],
        "abstract": "The success of various applications including robotics, digital content creation, and visualization demand a structured and abstract representation of the 3D world from limited sensor data. Inspired by the nature of human perception of 3D shapes as a collection of simple parts, we explore such an abstract shape representation based on primitives. Given a single depth image of an object, we present 3D-PRNN, a generative recurrent neural network that synthesizes multiple plausible shapes composed of a set of primitives. Our generative model encodes symmetry characteristics of common man-made objects, preserves long-range structural coherence, and describes objects of varying complexity with a compact representation. We also propose a method based on Gaussian Fields to generate a large scale dataset of primitive-based shape representations to train our network. We evaluate our approach on a wide range of examples and show that it outperforms nearest-neighbor based shape retrieval methods and is on-par with voxel-based generative models while using a significantly reduced parameter space.\n    ",
        "submission_date": "2017-08-04T00:00:00",
        "last_modified_date": "2017-08-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.01666",
        "title": "An Effective Training Method For Deep Convolutional Neural Network",
        "authors": [
            "Yang Jiang",
            "Zeyang Dou",
            "Qun Hao",
            "Jie Cao",
            "Kun Gao",
            "Xi Chen"
        ],
        "abstract": "In this paper, we propose the nonlinearity generation method to speed up and stabilize the training of deep convolutional neural networks. The proposed method modifies a family of activation functions as nonlinearity generators (NGs). NGs make the activation functions linear symmetric for their inputs to lower model capacity, and automatically introduce nonlinearity to enhance the capacity of the model during training. The proposed method can be considered an unusual form of regularization: the model parameters are obtained by training a relatively low-capacity model, that is relatively easy to optimize at the beginning, with only a few iterations, and these parameters are reused for the initialization of a higher-capacity model. We derive the upper and lower bounds of variance of the weight variation, and show that the initial symmetric structure of NGs helps stabilize training. We evaluate the proposed method on different frameworks of convolutional neural networks over two object recognition benchmark tasks (CIFAR-10 and CIFAR-100). Experimental results showed that the proposed method allows us to (1) speed up the convergence of training, (2) allow for less careful weight initialization, (3) improve or at least maintain the performance of the model at negligible extra computational cost, and (4) easily train a very deep model.\n    ",
        "submission_date": "2017-07-31T00:00:00",
        "last_modified_date": "2017-10-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.01729",
        "title": "Inception Score, Label Smoothing, Gradient Vanishing and -log(D(x)) Alternative",
        "authors": [
            "Zhiming Zhou",
            "Weinan Zhang",
            "Jun Wang"
        ],
        "abstract": "In this article, we mathematically study several GAN related topics, including Inception score, label smoothing, gradient vanishing and the -log(D(x)) alternative. \n--- \nAn advanced version is included in ",
        "submission_date": "2017-08-05T00:00:00",
        "last_modified_date": "2018-06-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.01733",
        "title": "Boosting Variational Inference: an Optimization Perspective",
        "authors": [
            "Francesco Locatello",
            "Rajiv Khanna",
            "Joydeep Ghosh",
            "Gunnar R\u00e4tsch"
        ],
        "abstract": "Variational inference is a popular technique to approximate a possibly intractable Bayesian posterior with a more tractable one. Recently, boosting variational inference has been proposed as a new paradigm to approximate the posterior by a mixture of densities by greedily adding components to the mixture. However, as is the case with many other variational inference algorithms, its theoretical properties have not been studied. In the present work, we study the convergence properties of this approach from a modern optimization viewpoint by establishing connections to the classic Frank-Wolfe algorithm. Our analyses yields novel theoretical insights regarding the sufficient conditions for convergence, explicit rates, and algorithmic simplifications. Since a lot of focus in previous works for variational inference has been on tractability, our work is especially important as a much needed attempt to bridge the gap between probabilistic models and their corresponding theoretical properties.\n    ",
        "submission_date": "2017-08-05T00:00:00",
        "last_modified_date": "2018-03-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.01776",
        "title": "e-QRAQ: A Multi-turn Reasoning Dataset and Simulator with Explanations",
        "authors": [
            "Clemens Rosenbaum",
            "Tian Gao",
            "Tim Klinger"
        ],
        "abstract": "In this paper we present a new dataset and user simulator e-QRAQ (explainable Query, Reason, and Answer Question) which tests an Agent's ability to read an ambiguous text; ask questions until it can answer a challenge question; and explain the reasoning behind its questions and answer. The User simulator provides the Agent with a short, ambiguous story and a challenge question about the story. The story is ambiguous because some of the entities have been replaced by variables. At each turn the Agent may ask for the value of a variable or try to answer the challenge question. In response the User simulator provides a natural language explanation of why the Agent's query or answer was useful in narrowing down the set of possible answers, or not. To demonstrate one potential application of the e-QRAQ dataset, we train a new neural architecture based on End-to-End Memory Networks to successfully generate both predictions and partial explanations of its current understanding of the problem. We observe a strong correlation between the quality of the prediction and explanation.\n    ",
        "submission_date": "2017-08-05T00:00:00",
        "last_modified_date": "2017-08-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.01911",
        "title": "Training of Deep Neural Networks based on Distance Measures using RMSProp",
        "authors": [
            "Thomas Kurbiel",
            "Shahrzad Khaleghian"
        ],
        "abstract": "The vanishing gradient problem was a major obstacle for the success of deep learning. In recent years it was gradually alleviated through multiple different techniques. However the problem was not really overcome in a fundamental way, since it is inherent to neural networks with activation functions based on dot products. In a series of papers, we are going to analyze alternative neural network structures which are not based on dot products. In this first paper, we revisit neural networks built up of layers based on distance measures and Gaussian activation functions. These kinds of networks were only sparsely used in the past since they are hard to train when using plain stochastic gradient descent methods. We show that by using Root Mean Square Propagation (RMSProp) it is possible to efficiently learn multi-layer neural networks. Furthermore we show that when appropriately initialized these kinds of neural networks suffer much less from the vanishing and exploding gradient problem than traditional neural networks even for deep networks.\n    ",
        "submission_date": "2017-08-06T00:00:00",
        "last_modified_date": "2017-08-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.01925",
        "title": "Designing Autonomous Vehicles: Evaluating the Role of Human Emotions and Social Norms",
        "authors": [
            "Faisal Riaz",
            "Muaz A. Niazi"
        ],
        "abstract": "Humans are going to delegate the rights of driving to the autonomous vehicles in near future. However, to fulfill this complicated task, there is a need for a mechanism, which enforces the autonomous vehicles to obey the road and social rules that have been practiced by well-behaved drivers. This task can be achieved by introducing social norms compliance mechanism in the autonomous vehicles. This research paper is proposing an artificial society of autonomous vehicles as an analogy of human social society. Each AV has been assigned a social personality having different social influence. Social norms have been introduced which help the AVs in making the decisions, influenced by emotions, regarding road collision avoidance. Furthermore, social norms compliance mechanism, by artificial social AVs, has been proposed using prospect based emotion i.e. fear, which is conceived from OCC model. Fuzzy logic has been employed to compute the emotions quantitatively. Then, using SimConnect approach, fuzzy values of fear has been provided to the Netlogo simulation environment to simulate artificial society of AVs. Extensive testing has been performed using the behavior space tool to find out the performance of the proposed approach in terms of the number of collisions. For comparison, the random-walk model based artificial society of AVs has been proposed as well. A comparative study with a random walk, prove that proposed approach provides a better option to tailor the autopilots of future AVS, Which will be more socially acceptable and trustworthy by their riders in terms of safe road travel.\n    ",
        "submission_date": "2017-08-06T00:00:00",
        "last_modified_date": "2017-08-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.01927",
        "title": "Emotion Controlled Spectrum Mobility Scheme for Efficient Syntactic Interoperability In Cognitive Radio Based Internet of Vehicles",
        "authors": [
            "Faisal Riaz",
            "Muaz A. Niazi"
        ],
        "abstract": "Blind spots are one of the causes of road accidents in the hilly and flat areas. These blind spot accidents can be decreased by establishing an Internet of Vehicles (IoV) using Vehicle-2-Vehicle (V2V) and Vehicle-2-Infrastrtructure (V2I) communication systems. But the problem with these IoV is that most of them are using DSRC or single Radio Access Technology (RAT) as a wireless technology, which has been proven to be failed for efficient communication between vehicles. Recently, Cognitive Radio (CR) based IoV have to be proven best wireless communication systems for vehicular networks. However, the spectrum mobility is a challenging task to keep CR based vehicular networks interoperable and has not been addressed sufficiently in existing research. In our previous research work, the Cognitive Radio Site (CR-Site) has been proposed as in-vehicle CR-device, which can be utilized to establish efficient IoV systems. H In this paper, we have introduced the Emotions Inspired Cognitive Agent (EIC_Agent) based spectrum mobility mechanism in CR-Site and proposed a novel emotions controlled spectrum mobility scheme for efficient syntactic interoperability between vehicles. For this purpose, a probabilistic deterministic finite automaton using fear factor is proposed to perform efficient spectrum mobility using fuzzy logic. In addition, the quantitative computation of different fear intensity levels has been performed with the help of fuzzy logic. The system has been tested using active data from different GSM service providers on Mangla-Mirpur road. This is supplemented by extensive simulation experiments which validate the proposed scheme for CR based high-speed vehicular networks. The qualitative comparison with the existing-state-of the-art has proven the superiority of the proposed emotions controlled syntactic interoperable spectrum mobility scheme within cognitive radio based IoV systems.\n    ",
        "submission_date": "2017-08-06T00:00:00",
        "last_modified_date": "2017-08-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.01967",
        "title": "Fake News Detection on Social Media: A Data Mining Perspective",
        "authors": [
            "Kai Shu",
            "Amy Sliva",
            "Suhang Wang",
            "Jiliang Tang",
            "Huan Liu"
        ],
        "abstract": "Social media for news consumption is a double-edged sword. On the one hand, its low cost, easy access, and rapid dissemination of information lead people to seek out and consume news from social media. On the other hand, it enables the wide spread of \"fake news\", i.e., low quality news with intentionally false information. The extensive spread of fake news has the potential for extremely negative impacts on individuals and society. Therefore, fake news detection on social media has recently become an emerging research that is attracting tremendous attention. Fake news detection on social media presents unique characteristics and challenges that make existing detection algorithms from traditional news media ineffective or not applicable. First, fake news is intentionally written to mislead readers to believe false information, which makes it difficult and nontrivial to detect based on news content; therefore, we need to include auxiliary information, such as user social engagements on social media, to help make a determination. Second, exploiting this auxiliary information is challenging in and of itself as users' social engagements with fake news produce data that is big, incomplete, unstructured, and noisy. Because the issue of fake news detection on social media is both challenging and relevant, we conducted this survey to further facilitate research on the problem. In this survey, we present a comprehensive review of detecting fake news on social media, including fake news characterizations on psychology and social theories, existing algorithms from a data mining perspective, evaluation metrics and representative datasets. We also discuss related research areas, open problems, and future research directions for fake news detection on social media.\n    ",
        "submission_date": "2017-08-07T00:00:00",
        "last_modified_date": "2017-09-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.02188",
        "title": "PowerAI DDL",
        "authors": [
            "Minsik Cho",
            "Ulrich Finkler",
            "Sameer Kumar",
            "David Kung",
            "Vaibhav Saxena",
            "Dheeraj Sreedhar"
        ],
        "abstract": "As deep neural networks become more complex and input datasets grow larger, it can take days or even weeks to train a deep neural network to the desired accuracy. Therefore, distributed Deep Learning at a massive scale is a critical capability, since it offers the potential to reduce the training time from weeks to hours. In this paper, we present a software-hardware co-optimized distributed Deep Learning system that can achieve near-linear scaling up to hundreds of GPUs. The core algorithm is a multi-ring communication pattern that provides a good tradeoff between latency and bandwidth and adapts to a variety of system configurations. The communication algorithm is implemented as a library for easy use. This library has been integrated into Tensorflow, Caffe, and Torch. We train Resnet-101 on Imagenet 22K with 64 IBM Power8 S822LC servers (256 GPUs) in about 7 hours to an accuracy of 33.8 % validation accuracy. Microsoft's ADAM and Google's DistBelief results did not reach 30 % validation accuracy for Imagenet 22K. Compared to Facebook AI Research's recent paper on 256 GPU training, we use a different communication algorithm, and our combined software and hardware system offers better communication overhead for Resnet-50. A PowerAI DDL enabled version of Torch completed 90 epochs of training on Resnet 50 for 1K classes in 50 minutes using 64 IBM Power8 S822LC servers (256 GPUs).\n    ",
        "submission_date": "2017-08-07T00:00:00",
        "last_modified_date": "2017-08-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.02191",
        "title": "Unsupervised Domain Adaptation for Face Recognition in Unlabeled Videos",
        "authors": [
            "Kihyuk Sohn",
            "Sifei Liu",
            "Guangyu Zhong",
            "Xiang Yu",
            "Ming-Hsuan Yang",
            "Manmohan Chandraker"
        ],
        "abstract": "Despite rapid advances in face recognition, there remains a clear gap between the performance of still image-based face recognition and video-based face recognition, due to the vast difference in visual quality between the domains and the difficulty of curating diverse large-scale video datasets. This paper addresses both of those challenges, through an image to video feature-level domain adaptation approach, to learn discriminative video frame representations. The framework utilizes large-scale unlabeled video data to reduce the gap between different domains while transferring discriminative knowledge from large-scale labeled still images. Given a face recognition network that is pretrained in the image domain, the adaptation is achieved by (i) distilling knowledge from the network to a video adaptation network through feature matching, (ii) performing feature restoration through synthetic data augmentation and (iii) learning a domain-invariant feature through a domain adversarial discriminator. We further improve performance through a discriminator-guided feature fusion that boosts high-quality frames while eliminating those degraded by video domain-specific factors. Experiments on the YouTube Faces and IJB-A datasets demonstrate that each module contributes to our feature-level domain adaptation framework and substantially improves video face recognition performance to achieve state-of-the-art accuracy. We demonstrate qualitatively that the network learns to suppress diverse artifacts in videos such as pose, illumination or occlusion without being explicitly trained for them.\n    ",
        "submission_date": "2017-08-07T00:00:00",
        "last_modified_date": "2017-08-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.02254",
        "title": "Asking Too Much? The Rhetorical Role of Questions in Political Discourse",
        "authors": [
            "Justine Zhang",
            "Arthur Spirling",
            "Cristian Danescu-Niculescu-Mizil"
        ],
        "abstract": "Questions play a prominent role in social interactions, performing rhetorical functions that go beyond that of simple informational exchange. The surface form of a question can signal the intention and background of the person asking it, as well as the nature of their relation with the interlocutor. While the informational nature of questions has been extensively examined in the context of question-answering applications, their rhetorical aspects have been largely understudied.\n",
        "submission_date": "2017-08-07T00:00:00",
        "last_modified_date": "2017-08-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.02300",
        "title": "Reinforced Video Captioning with Entailment Rewards",
        "authors": [
            "Ramakanth Pasunuru",
            "Mohit Bansal"
        ],
        "abstract": "Sequence-to-sequence models have shown promising improvements on the temporal task of video captioning, but they optimize word-level cross-entropy loss during training. First, using policy gradient and mixed-loss methods for reinforcement learning, we directly optimize sentence-level task-based metrics (as rewards), achieving significant improvements over the baseline, based on both automatic metrics and human evaluation on multiple datasets. Next, we propose a novel entailment-enhanced reward (CIDEnt) that corrects phrase-matching based metrics (such as CIDEr) to only allow for logically-implied partial matches and avoid contradictions, achieving further significant improvements over the CIDEr-reward model. Overall, our CIDEnt-reward model achieves the new state-of-the-art on the MSR-VTT dataset.\n    ",
        "submission_date": "2017-08-07T00:00:00",
        "last_modified_date": "2017-08-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.02312",
        "title": "Shortcut-Stacked Sentence Encoders for Multi-Domain Inference",
        "authors": [
            "Yixin Nie",
            "Mohit Bansal"
        ],
        "abstract": "We present a simple sequential sentence encoder for multi-domain natural language inference. Our encoder is based on stacked bidirectional LSTM-RNNs with shortcut connections and fine-tuning of word embeddings. The overall supervised model uses the above encoder to encode two input sentences into two vectors, and then uses a classifier over the vector combination to label the relationship between these two sentences as that of entailment, contradiction, or neural. Our Shortcut-Stacked sentence encoders achieve strong improvements over existing encoders on matched and mismatched multi-domain natural language inference (top non-ensemble single-model result in the EMNLP RepEval 2017 Shared Task (Nangia et al., 2017)). Moreover, they achieve the new state-of-the-art encoding result on the original SNLI dataset (Bowman et al., 2015).\n    ",
        "submission_date": "2017-08-07T00:00:00",
        "last_modified_date": "2017-11-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.02357",
        "title": "Towards A Novel Unified Framework for Developing Formal, Network and Validated Agent-Based Simulation Models of Complex Adaptive Systems",
        "authors": [
            "Muaz A. Niazi"
        ],
        "abstract": "Literature on the modeling and simulation of complex adaptive systems (cas) has primarily advanced vertically in different scientific domains with scientists developing a variety of domain-specific approaches and applications. However, while cas researchers are inher-ently interested in an interdisciplinary comparison of models, to the best of our knowledge, there is currently no single unified framework for facilitating the development, comparison, communication and validation of models across different scientific domains. In this thesis, we propose first steps towards such a unified framework using a combination of agent-based and complex network-based modeling approaches and guidelines formulated in the form of a set of four levels of usage, which allow multidisciplinary researchers to adopt a suitable framework level on the basis of available data types, their research study objectives and expected outcomes, thus allowing them to better plan and conduct their respective re-search case studies.\n    ",
        "submission_date": "2017-08-08T00:00:00",
        "last_modified_date": "2017-08-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.02361",
        "title": "Verification & Validation of Agent Based Simulations using the VOMAS (Virtual Overlay Multi-agent System) approach",
        "authors": [
            "Muaz A. Niazi",
            "Amir Hussain",
            "Mario Kolberg"
        ],
        "abstract": "Agent Based Models are very popular in a number of different areas. For example, they have been used in a range of domains ranging from modeling of tumor growth, immune systems, molecules to models of social networks, crowds and computer and mobile self-organizing networks. One reason for their success is their intuitiveness and similarity to human cognition. However, with this power of abstraction, in spite of being easily applicable to such a wide number of domains, it is hard to validate agent-based models. In addition, building valid and credible simulations is not just a challenging task but also a crucial exercise to ensure that what we are modeling is, at some level of abstraction, a model of our conceptual system; the system that we have in mind. In this paper, we address this important area of validation of agent based models by presenting a novel technique which has broad applicability and can be applied to all kinds of agent-based models. We present a framework, where a virtual overlay multi-agent system can be used to validate simulation models. In addition, since agent-based models have been typically growing, in parallel, in multiple domains, to cater for all of these, we present a new single validation technique applicable to all agent based models. Our technique, which allows for the validation of agent based simulations uses VOMAS: a Virtual Overlay Multi-agent System. This overlay multi-agent system can comprise various types of agents, which form an overlay on top of the agent based simulation model that needs to be validated. Other than being able to watch and log, each of these agents contains clearly defined constraints, which, if violated, can be logged in real time. To demonstrate its effectiveness, we show its broad applicability in a wide variety of simulation models ranging from social sciences to computer networks in spatial and non-spatial conceptual models.\n    ",
        "submission_date": "2017-08-08T00:00:00",
        "last_modified_date": "2017-08-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.02363",
        "title": "Beyond the technical challenges for deploying Machine Learning solutions in a software company",
        "authors": [
            "Ilias Flaounas"
        ],
        "abstract": "Recently software development companies started to embrace Machine Learning (ML) techniques for introducing a series of advanced functionality in their products such as personalisation of the user experience, improved search, content recommendation and automation. The technical challenges for tackling these problems are heavily researched in literature. A less studied area is a pragmatic approach to the role of humans in a complex modern industrial environment where ML based systems are developed. Key stakeholders affect the system from inception and up to operation and maintenance. Product managers want to embed \"smart\" experiences for their users and drive the decisions on what should be built next; software engineers are challenged to build or utilise ML software tools that require skills that are well outside of their comfort zone; legal and risk departments may influence design choices and data access; operations teams are requested to maintain ML systems which are non-stationary in their nature and change behaviour over time; and finally ML practitioners should communicate with all these stakeholders to successfully build a reliable system. This paper discusses some of the challenges we faced in Atlassian as we started investing more in the ML space.\n    ",
        "submission_date": "2017-08-08T00:00:00",
        "last_modified_date": "2017-08-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.02383",
        "title": "Learning how to Active Learn: A Deep Reinforcement Learning Approach",
        "authors": [
            "Meng Fang",
            "Yuan Li",
            "Trevor Cohn"
        ],
        "abstract": "Active learning aims to select a small subset of data for annotation such that a classifier learned on the data is highly accurate. This is usually done using heuristic selection methods, however the effectiveness of such methods is limited and moreover, the performance of heuristics varies between datasets. To address these shortcomings, we introduce a novel formulation by reframing the active learning as a reinforcement learning problem and explicitly learning a data selection policy, where the policy takes the role of the active learning heuristic. Importantly, our method allows the selection policy learned using simulation on one language to be transferred to other languages. We demonstrate our method using cross-lingual named entity recognition, observing uniform improvements over traditional active learning.\n    ",
        "submission_date": "2017-08-08T00:00:00",
        "last_modified_date": "2017-08-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.02531",
        "title": "Deep Binaries: Encoding Semantic-Rich Cues for Efficient Textual-Visual Cross Retrieval",
        "authors": [
            "Yuming Shen",
            "Li Liu",
            "Ling Shao",
            "Jingkuan Song"
        ],
        "abstract": "Cross-modal hashing is usually regarded as an effective technique for large-scale textual-visual cross retrieval, where data from different modalities are mapped into a shared Hamming space for matching. Most of the traditional textual-visual binary encoding methods only consider holistic image representations and fail to model descriptive sentences. This renders existing methods inappropriate to handle the rich semantics of informative cross-modal data for quality textual-visual search tasks. To address the problem of hashing cross-modal data with semantic-rich cues, in this paper, a novel integrated deep architecture is developed to effectively encode the detailed semantics of informative images and long descriptive sentences, named as Textual-Visual Deep Binaries (TVDB). In particular, region-based convolutional networks with long short-term memory units are introduced to fully explore image regional details while semantic cues of sentences are modeled by a text convolutional network. Additionally, we propose a stochastic batch-wise training routine, where high-quality binary codes and deep encoding functions are efficiently optimized in an alternating manner. Experiments are conducted on three multimedia datasets, i.e. Microsoft COCO, IAPR TC-12, and INRIA Web Queries, where the proposed TVDB model significantly outperforms state-of-the-art binary coding methods in the task of cross-modal retrieval.\n    ",
        "submission_date": "2017-08-08T00:00:00",
        "last_modified_date": "2017-08-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.02536",
        "title": "A Framework for Inferring Causality from Multi-Relational Observational Data using Conditional Independence",
        "authors": [
            "Sudeepa Roy",
            "Babak Salimi"
        ],
        "abstract": "The study of causality or causal inference - how much a given treatment causally affects a given outcome in a population - goes way beyond correlation or association analysis of variables, and is critical in making sound data driven decisions and policies in a multitude of applications. The gold standard in causal inference is performing \"controlled experiments\", which often is not possible due to logistical or ethical reasons. As an alternative, inferring causality on \"observational data\" based on the \"Neyman-Rubin potential outcome model\" has been extensively used in statistics, economics, and social sciences over several decades. In this paper, we present a formal framework for sound causal analysis on observational datasets that are given as multiple relations and where the population under study is obtained by joining these base relations. We study a crucial condition for inferring causality from observational data, called the \"strong ignorability assumption\" (the treatment and outcome variables should be independent in the joined relation given the observed covariates), using known conditional independences that hold in the base relations. We also discuss how the structure of the conditional independences in base relations given as graphical models help infer new conditional independences in the joined relation. The proposed framework combines concepts from databases, statistics, and graphical models, and aims to initiate new research directions spanning these fields to facilitate powerful data-driven decisions in today's big data world.\n    ",
        "submission_date": "2017-08-08T00:00:00",
        "last_modified_date": "2017-08-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.02544",
        "title": "Stochastic Optimization with Bandit Sampling",
        "authors": [
            "Farnood Salehi",
            "L. Elisa Celis",
            "Patrick Thiran"
        ],
        "abstract": "Many stochastic optimization algorithms work by estimating the gradient of the cost function on the fly by sampling datapoints uniformly at random from a training set. However, the estimator might have a large variance, which inadvertently slows down the convergence rate of the algorithms. One way to reduce this variance is to sample the datapoints from a carefully selected non-uniform distribution. In this work, we propose a novel non-uniform sampling approach that uses the multi-armed bandit framework. Theoretically, we show that our algorithm asymptotically approximates the optimal variance within a factor of 3. Empirically, we show that using this datapoint-selection technique results in a significant reduction in the convergence time and variance of several stochastic optimization algorithms such as SGD, SVRG and SAGA. This approach for sampling datapoints is general, and can be used in conjunction with any algorithm that uses an unbiased gradient estimation -- we expect it to have broad applicability beyond the specific examples explored in this work.\n    ",
        "submission_date": "2017-08-08T00:00:00",
        "last_modified_date": "2017-08-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.02556",
        "title": "Multi-Generator Generative Adversarial Nets",
        "authors": [
            "Quan Hoang",
            "Tu Dinh Nguyen",
            "Trung Le",
            "Dinh Phung"
        ],
        "abstract": "We propose a new approach to train the Generative Adversarial Nets (GANs) with a mixture of generators to overcome the mode collapsing problem. The main intuition is to employ multiple generators, instead of using a single one as in the original GAN. The idea is simple, yet proven to be extremely effective at covering diverse data modes, easily overcoming the mode collapse and delivering state-of-the-art results. A minimax formulation is able to establish among a classifier, a discriminator, and a set of generators in a similar spirit with GAN. Generators create samples that are intended to come from the same distribution as the training data, whilst the discriminator determines whether samples are true data or generated by generators, and the classifier specifies which generator a sample comes from. The distinguishing feature is that internal samples are created from multiple generators, and then one of them will be randomly selected as final output similar to the mechanism of a probabilistic mixture model. We term our method Mixture GAN (MGAN). We develop theoretical analysis to prove that, at the equilibrium, the Jensen-Shannon divergence (JSD) between the mixture of generators' distributions and the empirical data distribution is minimal, whilst the JSD among generators' distributions is maximal, hence effectively avoiding the mode collapse. By utilizing parameter sharing, our proposed model adds minimal computational cost to the standard GAN, and thus can also efficiently scale to large-scale datasets. We conduct extensive experiments on synthetic 2D data and natural image databases (CIFAR-10, STL-10 and ImageNet) to demonstrate the superior performance of our MGAN in achieving state-of-the-art Inception scores over latest baselines, generating diverse and appealing recognizable objects at different resolutions, and specializing in capturing different types of objects by generators.\n    ",
        "submission_date": "2017-08-08T00:00:00",
        "last_modified_date": "2017-10-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.02596",
        "title": "Neural Network Dynamics for Model-Based Deep Reinforcement Learning with Model-Free Fine-Tuning",
        "authors": [
            "Anusha Nagabandi",
            "Gregory Kahn",
            "Ronald S. Fearing",
            "Sergey Levine"
        ],
        "abstract": "Model-free deep reinforcement learning algorithms have been shown to be capable of learning a wide range of robotic skills, but typically require a very large number of samples to achieve good performance. Model-based algorithms, in principle, can provide for much more efficient learning, but have proven difficult to extend to expressive, high-capacity models such as deep neural networks. In this work, we demonstrate that medium-sized neural network models can in fact be combined with model predictive control (MPC) to achieve excellent sample complexity in a model-based reinforcement learning algorithm, producing stable and plausible gaits to accomplish various complex locomotion tasks. We also propose using deep neural network dynamics models to initialize a model-free learner, in order to combine the sample efficiency of model-based approaches with the high task-specific performance of model-free methods. We empirically demonstrate on MuJoCo locomotion tasks that our pure model-based approach trained on just random action data can follow arbitrary trajectories with excellent sample efficiency, and that our hybrid algorithm can accelerate model-free learning on high-speed benchmark tasks, achieving sample efficiency gains of 3-5x on swimmer, cheetah, hopper, and ant agents. Videos can be found at ",
        "submission_date": "2017-08-08T00:00:00",
        "last_modified_date": "2017-12-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.02940",
        "title": "Role of Secondary Attributes to Boost the Prediction Accuracy of Students Employability Via Data Mining",
        "authors": [
            "Pooja Thakar",
            "Anil Mehta",
            "Manisha"
        ],
        "abstract": "Data Mining is best-known for its analytical and prediction capabilities. It is used in several areas such as fraud detection, predicting client behavior, money market behavior, bankruptcy prediction. It can also help in establishing an educational ecosystem, which discovers useful knowledge, and assist educators to take proactive decisions to boost student performance and employability. This paper presents an empirical study that compares varied classification algorithms on two datasets of MCA (Masters in Computer Applications) students collected from various affiliated colleges of a reputed state university in India. One dataset includes only primary attributes, whereas other dataset is feeded with secondary psychometric attributes in it. The results showcase that solely primary academic attributes do not lead to smart prediction accuracy of students employability, once they square measure within the initial year of their education. The study analyzes and stresses the role of secondary psychometric attributes for better prediction accuracy and analysis of students performance. Timely prediction and analysis of students performance can help Management, Teachers and Students to work on their gray areas for better results and employment opportunities.\n    ",
        "submission_date": "2017-08-09T00:00:00",
        "last_modified_date": "2017-08-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.02977",
        "title": "Hierarchically-Attentive RNN for Album Summarization and Storytelling",
        "authors": [
            "Licheng Yu",
            "Mohit Bansal",
            "Tamara L. Berg"
        ],
        "abstract": "We address the problem of end-to-end visual storytelling. Given a photo album, our model first selects the most representative (summary) photos, and then composes a natural language story for the album. For this task, we make use of the Visual Storytelling dataset and a model composed of three hierarchically-attentive Recurrent Neural Nets (RNNs) to: encode the album photos, select representative (summary) photos, and compose the story. Automatic and human evaluations show our model achieves better performance on selection, generation, and retrieval than baselines.\n    ",
        "submission_date": "2017-08-09T00:00:00",
        "last_modified_date": "2017-08-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.03044",
        "title": "\"Is there anything else I can help you with?\": Challenges in Deploying an On-Demand Crowd-Powered Conversational Agent",
        "authors": [
            "Ting-Hao Kenneth Huang",
            "Walter S. Lasecki",
            "Amos Azaria",
            "Jeffrey P. Bigham"
        ],
        "abstract": "Intelligent conversational assistants, such as Apple's Siri, Microsoft's Cortana, and Amazon's Echo, have quickly become a part of our digital life. However, these assistants have major limitations, which prevents users from conversing with them as they would with human dialog partners. This limits our ability to observe how users really want to interact with the underlying system. To address this problem, we developed a crowd-powered conversational assistant, Chorus, and deployed it to see how users and workers would interact together when mediated by the system. Chorus sophisticatedly converses with end users over time by recruiting workers on demand, which in turn decide what might be the best response for each user sentence. Up to the first month of our deployment, 59 users have held conversations with Chorus during 320 conversational sessions. In this paper, we present an account of Chorus' deployment, with a focus on four challenges: (i) identifying when conversations are over, (ii) malicious users and workers, (iii) on-demand recruiting, and (iv) settings in which consensus is not enough. Our observations could assist the deployment of crowd-powered conversation systems and crowd-powered systems in general.\n    ",
        "submission_date": "2017-08-10T00:00:00",
        "last_modified_date": "2017-08-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.03080",
        "title": "A Simple and Realistic Pedestrian Model for Crowd Simulation and Application",
        "authors": [
            "Wonho Kang",
            "Youngnam Han"
        ],
        "abstract": "The simulation of pedestrian crowd that reflects reality is a major challenge for researches. Several crowd simulation models have been proposed such as cellular automata model, agent-based model, fluid dynamic model, etc. It is important to note that agent-based model is able, over others approaches, to provide a natural description of the system and then to capture complex human behaviors. In this paper, we propose a multi-agent simulation model in which pedestrian positions are updated at discrete time intervals. It takes into account the major normal conditions of a simple pedestrian situated in a crowd such as preferences, realistic perception of environment, etc. Our objective is to simulate the pedestrian crowd realistically towards a simulation of believable pedestrian behaviors. Typical pedestrian phenomena, including the unidirectional and bidirectional movement in a corridor as well as the flow through bottleneck, are simulated. The conducted simulations show that our model is able to produce realistic pedestrian behaviors. The obtained fundamental diagram and flow rate at bottleneck agree very well with classic conclusions and empirical study results. It is hoped that the idea of this study may be helpful in promoting the modeling and simulation of pedestrian crowd in a simple way.\n    ",
        "submission_date": "2017-08-10T00:00:00",
        "last_modified_date": "2017-08-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.03246",
        "title": "SESA: Supervised Explicit Semantic Analysis",
        "authors": [
            "Dasha Bogdanova",
            "Majid Yazdani"
        ],
        "abstract": "In recent years supervised representation learning has provided state of the art or close to the state of the art results in semantic analysis tasks including ranking and information retrieval. The core idea is to learn how to embed items into a latent space such that they optimize a supervised objective in that latent space. The dimensions of the latent space have no clear semantics, and this reduces the interpretability of the system. For example, in personalization models, it is hard to explain why a particular item is ranked high for a given user profile. We propose a novel model of representation learning called Supervised Explicit Semantic Analysis (SESA) that is trained in a supervised fashion to embed items to a set of dimensions with explicit semantics. The model learns to compare two objects by representing them in this explicit space, where each dimension corresponds to a concept from a knowledge base. This work extends Explicit Semantic Analysis (ESA) with a supervised model for ranking problems. We apply this model to the task of Job-Profile relevance in LinkedIn in which a set of skills defines our explicit dimensions of the space. Every profile and job are encoded to this set of skills their similarity is calculated in this space. We use RNNs to embed text input into this space. In addition to interpretability, our model makes use of the web-scale collaborative skills data that is provided by users for each LinkedIn profile. Our model provides state of the art result while it remains interpretable.\n    ",
        "submission_date": "2017-08-10T00:00:00",
        "last_modified_date": "2017-08-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.03309",
        "title": "Systematic Testing of Convolutional Neural Networks for Autonomous Driving",
        "authors": [
            "Tommaso Dreossi",
            "Shromona Ghosh",
            "Alberto Sangiovanni-Vincentelli",
            "Sanjit A. Seshia"
        ],
        "abstract": "We present a framework to systematically analyze convolutional neural networks (CNNs) used in classification of cars in autonomous vehicles. Our analysis procedure comprises an image generator that produces synthetic pictures by sampling in a lower dimension image modification subspace and a suite of visualization tools. The image generator produces images which can be used to test the CNN and hence expose its vulnerabilities. The presented framework can be used to extract insights of the CNN classifier, compare across classification models, or generate training and validation datasets.\n    ",
        "submission_date": "2017-08-10T00:00:00",
        "last_modified_date": "2017-08-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.03366",
        "title": "Resilient Linear Classification: An Approach to Deal with Attacks on Training Data",
        "authors": [
            "Sangdon Park",
            "James Weimer",
            "Insup Lee"
        ],
        "abstract": "Data-driven techniques are used in cyber-physical systems (CPS) for controlling autonomous vehicles, handling demand responses for energy management, and modeling human physiology for medical devices. These data-driven techniques extract models from training data, where their performance is often analyzed with respect to random errors in the training data. However, if the training data is maliciously altered by attackers, the effect of these attacks on the learning algorithms underpinning data-driven CPS have yet to be considered. In this paper, we analyze the resilience of classification algorithms to training data attacks. Specifically, a generic metric is proposed that is tailored to measure resilience of classification algorithms with respect to worst-case tampering of the training data. Using the metric, we show that traditional linear classification algorithms are resilient under restricted conditions. To overcome these limitations, we propose a linear classification algorithm with a majority constraint and prove that it is strictly more resilient than the traditional algorithms. Evaluations on both synthetic data and a real-world retrospective arrhythmia medical case-study show that the traditional algorithms are vulnerable to tampered training data, whereas the proposed algorithm is more resilient (as measured by worst-case tampering).\n    ",
        "submission_date": "2017-08-10T00:00:00",
        "last_modified_date": "2017-08-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.03395",
        "title": "Optimal Errors and Phase Transitions in High-Dimensional Generalized Linear Models",
        "authors": [
            "Jean Barbier",
            "Florent Krzakala",
            "Nicolas Macris",
            "L\u00e9o Miolane",
            "Lenka Zdeborov\u00e1"
        ],
        "abstract": "Generalized linear models (GLMs) arise in high-dimensional machine learning, statistics, communications and signal processing. In this paper we analyze GLMs when the data matrix is random, as relevant in problems such as compressed sensing, error-correcting codes or benchmark models in neural networks. We evaluate the mutual information (or \"free entropy\") from which we deduce the Bayes-optimal estimation and generalization errors. Our analysis applies to the high-dimensional limit where both the number of samples and the dimension are large and their ratio is fixed. Non-rigorous predictions for the optimal errors existed for special cases of GLMs, e.g. for the perceptron, in the field of statistical physics based on the so-called replica method. Our present paper rigorously establishes those decades old conjectures and brings forward their algorithmic interpretation in terms of performance of the generalized approximate message-passing algorithm. Furthermore, we tightly characterize, for many learning problems, regions of parameters for which this algorithm achieves the optimal performance, and locate the associated sharp phase transitions separating learnable and non-learnable regions. We believe that this random version of GLMs can serve as a challenging benchmark for multi-purpose algorithms. This paper is divided in two parts that can be read independently: The first part (main part) presents the model and main results, discusses some applications and sketches the main ideas of the proof. The second part (supplementary informations) is much more detailed and provides more examples as well as all the proofs.\n    ",
        "submission_date": "2017-08-10T00:00:00",
        "last_modified_date": "2018-11-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.03417",
        "title": "GlobeNet: Convolutional Neural Networks for Typhoon Eye Tracking from Remote Sensing Imagery",
        "authors": [
            "Seungkyun Hong",
            "Seongchan Kim",
            "Minsu Joh",
            "Sa-kwang Song"
        ],
        "abstract": "Advances in remote sensing technologies have made it possible to use high-resolution visual data for weather observation and forecasting tasks. We propose the use of multi-layer neural networks for understanding complex atmospheric dynamics based on multichannel satellite images. The capability of our model was evaluated by using a linear regression task for single typhoon coordinates prediction. A specific combination of models and different activation policies enabled us to obtain an interesting prediction result in the northeastern hemisphere (ENH).\n    ",
        "submission_date": "2017-08-11T00:00:00",
        "last_modified_date": "2017-08-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.03418",
        "title": "Learning to Attend, Copy, and Generate for Session-Based Query Suggestion",
        "authors": [
            "Mostafa Dehghani",
            "Sascha Rothe",
            "Enrique Alfonseca",
            "Pascal Fleury"
        ],
        "abstract": "Users try to articulate their complex information needs during search sessions by reformulating their queries. To make this process more effective, search engines provide related queries to help users in specifying the information need in their search process. In this paper, we propose a customized sequence-to-sequence model for session-based query suggestion. In our model, we employ a query-aware attention mechanism to capture the structure of the session context. is enables us to control the scope of the session from which we infer the suggested next query, which helps not only handle the noisy data but also automatically detect session boundaries. Furthermore, we observe that, based on the user query reformulation behavior, within a single session a large portion of query terms is retained from the previously submitted queries and consists of mostly infrequent or unseen terms that are usually not included in the vocabulary. We therefore empower the decoder of our model to access the source words from the session context during decoding by incorporating a copy mechanism. Moreover, we propose evaluation metrics to assess the quality of the generative models for query suggestion. We conduct an extensive set of experiments and analysis. e results suggest that our model outperforms the baselines both in terms of the generating queries and scoring candidate queries for the task of query suggestion.\n    ",
        "submission_date": "2017-08-11T00:00:00",
        "last_modified_date": "2017-11-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.03800",
        "title": "Energy saving for building heating via a simple and efficient model-free control design: First steps with computer simulations",
        "authors": [
            "Hassane Aboua\u00efssa",
            "Ola Alhaj Hasan",
            "C\u00e9dric Join",
            "Michel Fliess",
            "Didier Defer"
        ],
        "abstract": "The model-based control of building heating systems for energy saving encounters severe physical, mathematical and calibration difficulties in the numerous attempts that has been published until now. This topic is addressed here via a new model-free control setting, where the need of any mathematical description disappears. Several convincing computer simulations are presented. Comparisons with classic PI controllers and flatness-based predictive control are provided.\n    ",
        "submission_date": "2017-08-12T00:00:00",
        "last_modified_date": "2017-09-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.03910",
        "title": "Semi-supervised emotion lexicon expansion with label propagation and specialized word embeddings",
        "authors": [
            "Mario Giulianelli"
        ],
        "abstract": "There exist two main approaches to automatically extract affective orientation: lexicon-based and corpus-based. In this work, we argue that these two methods are compatible and show that combining them can improve the accuracy of emotion classifiers. In particular, we introduce a novel variant of the Label Propagation algorithm that is tailored to distributed word representations, we apply batch gradient descent to accelerate the optimization of label propagation and to make the optimization feasible for large graphs, and we propose a reproducible method for emotion lexicon expansion. We conclude that label propagation can expand an emotion lexicon in a meaningful way and that the expanded emotion lexicon can be leveraged to improve the accuracy of an emotion classifier.\n    ",
        "submission_date": "2017-08-13T00:00:00",
        "last_modified_date": "2017-08-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.03951",
        "title": "Optimization of Ensemble Supervised Learning Algorithms for Increased Sensitivity, Specificity, and AUC of Population-Based Colorectal Cancer Screenings",
        "authors": [
            "Anirudh Kamath",
            "Aditya Singh",
            "Raj Ramnani",
            "Ayush Vyas",
            "Jay Shenoy"
        ],
        "abstract": "Over 150,000 new people in the United States are diagnosed with colorectal cancer each year. Nearly a third die from it (American Cancer Society). The only approved noninvasive diagnosis tools currently involve fecal blood count tests (FOBTs) or stool DNA tests. Fecal blood count tests take only five minutes and are available over the counter for as low as \\$15. They are highly specific, yet not nearly as sensitive, yielding a high percentage (25%) of false negatives (Colon Cancer Alliance). Moreover, FOBT results are far too generalized, meaning that a positive result could mean much more than just colorectal cancer, and could just as easily mean hemorrhoids, anal fissure, proctitis, Crohn's disease, diverticulosis, ulcerative colitis, rectal ulcer, rectal prolapse, ischemic colitis, angiodysplasia, rectal trauma, proctitis from radiation therapy, and others. Stool DNA tests, the modern benchmark for CRC screening, have a much higher sensitivity and specificity, but also cost \\$600, take two weeks to process, and are not for high-risk individuals or people with a history of polyps. To yield a cheap and effective CRC screening alternative, a unique ensemble-based classification algorithm is put in place that considers the FIT result, BMI, smoking history, and diabetic status of patients. This method is tested under ten-fold cross validation to have a .95 AUC, 92% specificity, 89% sensitivity, .88 F1, and 90% precision. Once clinically validated, this test promises to be cheaper, faster, and potentially more accurate when compared to a stool DNA test.\n    ",
        "submission_date": "2017-08-13T00:00:00",
        "last_modified_date": "2017-08-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.03995",
        "title": "Sentiment Analysis by Joint Learning of Word Embeddings and Classifier",
        "authors": [
            "Prathusha Kameswara Sarma",
            "Bill Sethares"
        ],
        "abstract": "Word embeddings are representations of individual words of a text document in a vector space and they are often use- ful for performing natural language pro- cessing tasks. Current state of the art al- gorithms for learning word embeddings learn vector representations from large corpora of text documents in an unsu- pervised fashion. This paper introduces SWESA (Supervised Word Embeddings for Sentiment Analysis), an algorithm for sentiment analysis via word embeddings. SWESA leverages document label infor- mation to learn vector representations of words from a modest corpus of text doc- uments by solving an optimization prob- lem that minimizes a cost function with respect to both word embeddings as well as classification accuracy. Analysis re- veals that SWESA provides an efficient way of estimating the dimension of the word embeddings that are to be learned. Experiments on several real world data sets show that SWESA has superior per- formance when compared to previously suggested approaches to word embeddings and sentiment analysis tasks.\n    ",
        "submission_date": "2017-08-14T00:00:00",
        "last_modified_date": "2017-08-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.04028",
        "title": "Counterexample Guided Inductive Optimization Applied to Mobile Robots Path Planning (Extended Version)",
        "authors": [
            "Rodrigo F. Ara\u00fajo",
            "Alexandre Ribeiro",
            "Iury V. Bessa",
            "Lucas C. Cordeiro",
            "Jo\u00e3o E. C. Filho"
        ],
        "abstract": "We describe and evaluate a novel optimization-based off-line path planning algorithm for mobile robots based on the Counterexample-Guided Inductive Optimization (CEGIO) technique. CEGIO iteratively employs counterexamples generated from Boolean Satisfiability (SAT) and Satisfiability Modulo Theories (SMT) solvers, in order to guide the optimization process and to ensure global optimization. This paper marks the first application of CEGIO for planning mobile robot path. In particular, CEGIO has been successfully applied to obtain optimal two-dimensional paths for autonomous mobile robots using off-the-shelf SAT and SMT solvers.\n    ",
        "submission_date": "2017-08-14T00:00:00",
        "last_modified_date": "2017-08-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.04033",
        "title": "Deep Reinforcement Learning for High Precision Assembly Tasks",
        "authors": [
            "Tadanobu Inoue",
            "Giovanni De Magistris",
            "Asim Munawar",
            "Tsuyoshi Yokoya",
            "Ryuki Tachibana"
        ],
        "abstract": "High precision assembly of mechanical parts requires accuracy exceeding the robot precision. Conventional part mating methods used in the current manufacturing requires tedious tuning of numerous parameters before deployment. We show how the robot can successfully perform a tight clearance peg-in-hole task through training a recurrent neural network with reinforcement learning. In addition to saving the manual effort, the proposed technique also shows robustness against position and angle errors for the peg-in-hole task. The neural network learns to take the optimal action by observing the robot sensors to estimate the system state. The advantages of our proposed method is validated experimentally on a 7-axis articulated robot arm.\n    ",
        "submission_date": "2017-08-14T00:00:00",
        "last_modified_date": "2017-09-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.04134",
        "title": "A Measure for Dialog Complexity and its Application in Streamlining Service Operations",
        "authors": [
            "Q Vera Liao",
            "Biplav Srivastava",
            "Pavan Kapanipathi"
        ],
        "abstract": "Dialog is a natural modality for interaction between customers and businesses in the service industry. As customers call up the service provider, their interactions may be routine or extraordinary. We believe that these interactions, when seen as dialogs, can be analyzed to obtain a better understanding of customer needs and how to efficiently address them. We introduce the idea of a dialog complexity measure to characterize multi-party interactions, propose a general data-driven method to calculate it, use it to discover insights in public and enterprise dialog datasets, and demonstrate its beneficial usage in facilitating better handling of customer requests and evaluating service agents.\n    ",
        "submission_date": "2017-08-04T00:00:00",
        "last_modified_date": "2017-08-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.04198",
        "title": "A scalable multi-core architecture with heterogeneous memory structures for Dynamic Neuromorphic Asynchronous Processors (DYNAPs)",
        "authors": [
            "Saber Moradi",
            "Ning Qiao",
            "Fabio Stefanini",
            "Giacomo Indiveri"
        ],
        "abstract": "Neuromorphic computing systems comprise networks of neurons that use asynchronous events for both computation and communication. This type of representation offers several advantages in terms of bandwidth and power consumption in neuromorphic electronic systems. However, managing the traffic of asynchronous events in large scale systems is a daunting task, both in terms of circuit complexity and memory requirements. Here we present a novel routing methodology that employs both hierarchical and mesh routing strategies and combines heterogeneous memory structures for minimizing both memory requirements and latency, while maximizing programming flexibility to support a wide range of event-based neural network architectures, through parameter configuration. We validated the proposed scheme in a prototype multi-core neuromorphic processor chip that employs hybrid analog/digital circuits for emulating synapse and neuron dynamics together with asynchronous digital circuits for managing the address-event traffic. We present a theoretical analysis of the proposed connectivity scheme, describe the methods and circuits used to implement such scheme, and characterize the prototype chip. Finally, we demonstrate the use of the neuromorphic processor with a convolutional neural network for the real-time classification of visual symbols being flashed to a dynamic vision sensor (DVS) at high speed.\n    ",
        "submission_date": "2017-08-14T00:00:00",
        "last_modified_date": "2017-08-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.04225",
        "title": "Deep Object-Centric Representations for Generalizable Robot Learning",
        "authors": [
            "Coline Devin",
            "Pieter Abbeel",
            "Trevor Darrell",
            "Sergey Levine"
        ],
        "abstract": "Robotic manipulation in complex open-world scenarios requires both reliable physical manipulation skills and effective and generalizable perception. In this paper, we propose a method where general purpose pretrained visual models serve as an object-centric prior for the perception system of a learned policy. We devise an object-level attentional mechanism that can be used to determine relevant objects from a few trajectories or demonstrations, and then immediately incorporate those objects into a learned policy. A task-independent meta-attention locates possible objects in the scene, and a task-specific attention identifies which objects are predictive of the trajectories. The scope of the task-specific attention is easily adjusted by showing demonstrations with distractor objects or with diverse relevant objects. Our results indicate that this approach exhibits good generalization across object instances using very few samples, and can be used to learn a variety of manipulation tasks using reinforcement learning.\n    ",
        "submission_date": "2017-08-14T00:00:00",
        "last_modified_date": "2017-09-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.04236",
        "title": "Strategy Synthesis in POMDPs via Game-Based Abstractions",
        "authors": [
            "Leonore Winterer",
            "Sebastian Junges",
            "Ralf Wimmer",
            "Nils Jansen",
            "Ufuk Topcu",
            "Joost-Pieter Katoen",
            "Bernd Becker"
        ],
        "abstract": "We study synthesis problems with constraints in partially observable Markov decision processes (POMDPs), where the objective is to compute a strategy for an agent that is guaranteed to satisfy certain safety and performance specifications. Verification and strategy synthesis for POMDPs are, however, computationally intractable in general. We alleviate this difficulty by focusing on planning applications and exploiting typical structural properties of such scenarios; for instance, we assume that the agent has the ability to observe its own position inside an environment. We propose an abstraction refinement framework which turns such a POMDP model into a (fully observable) probabilistic two-player game (PG). For the obtained PGs, efficient verification and synthesis tools allow to determine strategies with optimal safety and performance measures, which approximate optimal schedulers on the POMDP. If the approximation is too coarse to satisfy the given specifications, an refinement scheme improves the computed strategies. As a running example, we use planning problems where an agent moves inside an environment with randomly moving obstacles and restricted observability. We demonstrate that the proposed method advances the state of the art by solving problems several orders-of-magnitude larger than those that can be handled by existing POMDP solvers. Furthermore, this method gives guarantees on safety constraints, which is not supported by the majority of the existing solvers.\n    ",
        "submission_date": "2017-08-14T00:00:00",
        "last_modified_date": "2019-05-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.04321",
        "title": "Distance and Similarity Measures Effect on the Performance of K-Nearest Neighbor Classifier -- A Review",
        "authors": [
            "V. B. Surya Prasath",
            "Haneen Arafat Abu Alfeilat",
            "Ahmad B. A. Hassanat",
            "Omar Lasassmeh",
            "Ahmad S. Tarawneh",
            "Mahmoud Bashir Alhasanat",
            "Hamzeh S. Eyal Salman"
        ],
        "abstract": "The K-nearest neighbor (KNN) classifier is one of the simplest and most common classifiers, yet its performance competes with the most complex classifiers in the literature. The core of this classifier depends mainly on measuring the distance or similarity between the tested examples and the training examples. This raises a major question about which distance measures to be used for the KNN classifier among a large number of distance and similarity measures available? This review attempts to answer this question through evaluating the performance (measured by accuracy, precision and recall) of the KNN using a large number of distance measures, tested on a number of real-world datasets, with and without adding different levels of noise. The experimental results show that the performance of KNN classifier depends significantly on the distance used, and the results showed large gaps between the performances of different distances. We found that a recently proposed non-convex distance performed the best when applied on most datasets comparing to the other tested distances. In addition, the performance of the KNN with this top performing distance degraded only about $20\\%$ while the noise level reaches $90\\%$, this is true for most of the distances used as well. This means that the KNN classifier using any of the top $10$ distances tolerate noise to a certain degree. Moreover, the results show that some distances are less affected by the added noise comparing to other distances.\n    ",
        "submission_date": "2017-08-14T00:00:00",
        "last_modified_date": "2019-09-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.04357",
        "title": "Graph Classification via Deep Learning with Virtual Nodes",
        "authors": [
            "Trang Pham",
            "Truyen Tran",
            "Hoa Dam",
            "Svetha Venkatesh"
        ],
        "abstract": "Learning representation for graph classification turns a variable-size graph into a fixed-size vector (or matrix). Such a representation works nicely with algebraic manipulations. Here we introduce a simple method to augment an attributed graph with a virtual node that is bidirectionally connected to all existing nodes. The virtual node represents the latent aspects of the graph, which are not immediately available from the attributes and local connectivity structures. The expanded graph is then put through any node representation method. The representation of the virtual node is then the representation of the entire graph. In this paper, we use the recently introduced Column Network for the expanded graph, resulting in a new end-to-end graph classification model dubbed Virtual Column Network (VCN). The model is validated on two tasks: (i) predicting bio-activity of chemical compounds, and (ii) finding software vulnerability from source code. Results demonstrate that VCN is competitive against well-established rivals.\n    ",
        "submission_date": "2017-08-14T00:00:00",
        "last_modified_date": "2017-08-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.04403",
        "title": "Theoretical Foundation of Co-Training and Disagreement-Based Algorithms",
        "authors": [
            "Wei Wang",
            "Zhi-Hua Zhou"
        ],
        "abstract": "Disagreement-based approaches generate multiple classifiers and exploit the disagreement among them with unlabeled data to improve learning performance. Co-training is a representative paradigm of them, which trains two classifiers separately on two sufficient and redundant views; while for the applications where there is only one view, several successful variants of co-training with two different classifiers on single-view data instead of two views have been proposed. For these disagreement-based approaches, there are several important issues which still are unsolved, in this article we present theoretical analyses to address these issues, which provides a theoretical foundation of co-training and disagreement-based approaches.\n    ",
        "submission_date": "2017-08-15T00:00:00",
        "last_modified_date": "2017-08-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.04529",
        "title": "Learning from Noisy Label Distributions",
        "authors": [
            "Yuya Yoshikawa"
        ],
        "abstract": "In this paper, we consider a novel machine learning problem, that is, learning a classifier from noisy label distributions. In this problem, each instance with a feature vector belongs to at least one group. Then, instead of the true label of each instance, we observe the label distribution of the instances associated with a group, where the label distribution is distorted by an unknown noise. Our goals are to (1) estimate the true label of each instance, and (2) learn a classifier that predicts the true label of a new instance. We propose a probabilistic model that considers true label distributions of groups and parameters that represent the noise as hidden variables. The model can be learned based on a variational Bayesian method. In numerical experiments, we show that the proposed model outperforms existing methods in terms of the estimation of the true labels of instances.\n    ",
        "submission_date": "2017-08-11T00:00:00",
        "last_modified_date": "2017-08-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.04571",
        "title": "A Machine Learning Based Intrusion Detection System for Software Defined 5G Network",
        "authors": [
            "Jiaqi Li",
            "Zhifeng Zhao",
            "Rongpeng Li"
        ],
        "abstract": "As an inevitable trend of future 5G networks, Software Defined architecture has many advantages in providing central- ized control and flexible resource management. But it is also confronted with various security challenges and potential threats with emerging services and technologies. As the focus of network security, Intrusion Detection Systems (IDS) are usually deployed separately without collaboration. They are also unable to detect novel attacks with limited intelligent abilities, which are hard to meet the needs of software defined 5G. In this paper, we propose an intelligent intrusion system taking the advances of software defined technology and artificial intelligence based on Software Defined 5G architecture. It flexibly combines security function mod- ules which are adaptively invoked under centralized management and control with a globle view. It can also deal with unknown intrusions by using machine learning algorithms. Evaluation results prove that the intelligent intrusion detection system achieves a better performance.\n    ",
        "submission_date": "2017-07-10T00:00:00",
        "last_modified_date": "2017-07-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.04587",
        "title": "Automatic Summarization of Online Debates",
        "authors": [
            "Nattapong Sanchan",
            "Ahmet Aker",
            "Kalina Bontcheva"
        ],
        "abstract": "Debate summarization is one of the novel and challenging research areas in automatic text summarization which has been largely unexplored. In this paper, we develop a debate summarization pipeline to summarize key topics which are discussed or argued in the two opposing sides of online debates. We view that the generation of debate summaries can be achieved by clustering, cluster labeling, and visualization. In our work, we investigate two different clustering approaches for the generation of the summaries. In the first approach, we generate the summaries by applying purely term-based clustering and cluster labeling. The second approach makes use of X-means for clustering and Mutual Information for labeling the clusters. Both approaches are driven by ontologies. We visualize the results using bar charts. We think that our results are a smooth entry for users aiming to receive the first impression about what is discussed within a debate topic containing waste number of argumentations.\n    ",
        "submission_date": "2017-08-15T00:00:00",
        "last_modified_date": "2017-08-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.04592",
        "title": "Gold Standard Online Debates Summaries and First Experiments Towards Automatic Summarization of Online Debate Data",
        "authors": [
            "Nattapong Sanchan",
            "Ahmet Aker",
            "Kalina Bontcheva"
        ],
        "abstract": "Usage of online textual media is steadily increasing. Daily, more and more news stories, blog posts and scientific articles are added to the online volumes. These are all freely accessible and have been employed extensively in multiple research areas, e.g. automatic text summarization, information retrieval, information extraction, etc. Meanwhile, online debate forums have recently become popular, but have remained largely unexplored. For this reason, there are no sufficient resources of annotated debate data available for conducting research in this genre. In this paper, we collected and annotated debate data for an automatic summarization task. Similar to extractive gold standard summary generation our data contains sentences worthy to include into a summary. Five human annotators performed this task. Inter-annotator agreement, based on semantic similarity, is 36% for Cohen's kappa and 48% for Krippendorff's alpha. Moreover, we also implement an extractive summarization system for online debates and discuss prominent features for the task of summarizing online debate data automatically.\n    ",
        "submission_date": "2017-08-15T00:00:00",
        "last_modified_date": "2017-08-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.04670",
        "title": "DeepFaceLIFT: Interpretable Personalized Models for Automatic Estimation of Self-Reported Pain",
        "authors": [
            "Dianbo Liu",
            "Fengjiao Peng",
            "Andrew Shea",
            "Ognjen",
            "Rudovic",
            "Rosalind Picard"
        ],
        "abstract": "Previous research on automatic pain estimation from facial expressions has focused primarily on \"one-size-fits-all\" metrics (such as PSPI). In this work, we focus on directly estimating each individual's self-reported visual-analog scale (VAS) pain metric, as this is considered the gold standard for pain measurement. The VAS pain score is highly subjective and context-dependent, and its range can vary significantly among different persons. To tackle these issues, we propose a novel two-stage personalized model, named DeepFaceLIFT, for automatic estimation of VAS. This model is based on (1) Neural Network and (2) Gaussian process regression models, and is used to personalize the estimation of self-reported pain via a set of hand-crafted personal features and multi-task learning. We show on the benchmark dataset for pain analysis (The UNBC-McMaster Shoulder Pain Expression Archive) that the proposed personalized model largely outperforms the traditional, unpersonalized models: the intra-class correlation improves from a baseline performance of 19\\% to a personalized performance of 35\\% while also providing confidence in the model\\textquotesingle s estimates -- in contrast to existing models for the target task. Additionally, DeepFaceLIFT automatically discovers the pain-relevant facial regions for each person, allowing for an easy interpretation of the pain-related facial cues.\n    ",
        "submission_date": "2017-08-09T00:00:00",
        "last_modified_date": "2017-08-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.04733",
        "title": "Geometric Enclosing Networks",
        "authors": [
            "Trung Le",
            "Hung Vu",
            "Tu Dinh Nguyen",
            "Dinh Phung"
        ],
        "abstract": "Training model to generate data has increasingly attracted research attention and become important in modern world applications. We propose in this paper a new geometry-based optimization approach to address this problem. Orthogonal to current state-of-the-art density-based approaches, most notably VAE and GAN, we present a fresh new idea that borrows the principle of minimal enclosing ball to train a generator G\\left(\\bz\\right) in such a way that both training and generated data, after being mapped to the feature space, are enclosed in the same sphere. We develop theory to guarantee that the mapping is bijective so that its inverse from feature space to data space results in expressive nonlinear contours to describe the data manifold, hence ensuring data generated are also lying on the data manifold learned from training data. Our model enjoys a nice geometric interpretation, hence termed Geometric Enclosing Networks (GEN), and possesses some key advantages over its rivals, namely simple and easy-to-control optimization formulation, avoidance of mode collapsing and efficiently learn data manifold representation in a completely unsupervised manner. We conducted extensive experiments on synthesis and real-world datasets to illustrate the behaviors, strength and weakness of our proposed GEN, in particular its ability to handle multi-modal data and quality of generated data.\n    ",
        "submission_date": "2017-08-16T00:00:00",
        "last_modified_date": "2017-08-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.04757",
        "title": "Scalable Joint Models for Reliable Uncertainty-Aware Event Prediction",
        "authors": [
            "Hossein Soleimani",
            "James Hensman",
            "Suchi Saria"
        ],
        "abstract": "Missing data and noisy observations pose significant challenges for reliably predicting events from irregularly sampled multivariate time series (longitudinal) data. Imputation methods, which are typically used for completing the data prior to event prediction, lack a principled mechanism to account for the uncertainty due to missingness. Alternatively, state-of-the-art joint modeling techniques can be used for jointly modeling the longitudinal and event data and compute event probabilities conditioned on the longitudinal observations. These approaches, however, make strong parametric assumptions and do not easily scale to multivariate signals with many observations. Our proposed approach consists of several key innovations. First, we develop a flexible and scalable joint model based upon sparse multiple-output Gaussian processes. Unlike state-of-the-art joint models, the proposed model can explain highly challenging structure including non-Gaussian noise while scaling to large data. Second, we derive an optimal policy for predicting events using the distribution of the event occurrence estimated by the joint model. The derived policy trades-off the cost of a delayed detection versus incorrect assessments and abstains from making decisions when the estimated event probability does not satisfy the derived confidence criteria. Experiments on a large dataset show that the proposed framework significantly outperforms state-of-the-art techniques in event prediction.\n    ",
        "submission_date": "2017-08-16T00:00:00",
        "last_modified_date": "2017-08-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.04782",
        "title": "StarCraft II: A New Challenge for Reinforcement Learning",
        "authors": [
            "Oriol Vinyals",
            "Timo Ewalds",
            "Sergey Bartunov",
            "Petko Georgiev",
            "Alexander Sasha Vezhnevets",
            "Michelle Yeo",
            "Alireza Makhzani",
            "Heinrich K\u00fcttler",
            "John Agapiou",
            "Julian Schrittwieser",
            "John Quan",
            "Stephen Gaffney",
            "Stig Petersen",
            "Karen Simonyan",
            "Tom Schaul",
            "Hado van Hasselt",
            "David Silver",
            "Timothy Lillicrap",
            "Kevin Calderone",
            "Paul Keet",
            "Anthony Brunasso",
            "David Lawrence",
            "Anders Ekermo",
            "Jacob Repp",
            "Rodney Tsing"
        ],
        "abstract": "This paper introduces SC2LE (StarCraft II Learning Environment), a reinforcement learning environment based on the StarCraft II game. This domain poses a new grand challenge for reinforcement learning, representing a more difficult class of problems than considered in most prior work. It is a multi-agent problem with multiple players interacting; there is imperfect information due to a partially observed map; it has a large action space involving the selection and control of hundreds of units; it has a large state space that must be observed solely from raw input feature planes; and it has delayed credit assignment requiring long-term strategies over thousands of steps. We describe the observation, action, and reward specification for the StarCraft II domain and provide an open source Python-based interface for communicating with the game engine. In addition to the main game maps, we provide a suite of mini-games focusing on different elements of StarCraft II gameplay. For the main game maps, we also provide an accompanying dataset of game replay data from human expert players. We give initial baseline results for neural networks trained from this data to predict game outcomes and player actions. Finally, we present initial baseline results for canonical deep reinforcement learning agents applied to the StarCraft II domain. On the mini-games, these agents learn to achieve a level of play that is comparable to a novice player. However, when trained on the main game, these agents are unable to make significant progress. Thus, SC2LE offers a new and challenging environment for exploring deep reinforcement learning algorithms and architectures.\n    ",
        "submission_date": "2017-08-16T00:00:00",
        "last_modified_date": "2017-08-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.04801",
        "title": "Weighted parallel SGD for distributed unbalanced-workload training system",
        "authors": [
            "Cheng Daning",
            "Li Shigang",
            "Zhang Yunquan"
        ],
        "abstract": "Stochastic gradient descent (SGD) is a popular stochastic optimization method in machine learning. Traditional parallel SGD algorithms, e.g., SimuParallel SGD, often require all nodes to have the same performance or to consume equal quantities of data. However, these requirements are difficult to satisfy when the parallel SGD algorithms run in a heterogeneous computing environment; low-performance nodes will exert a negative influence on the final result. In this paper, we propose an algorithm called weighted parallel SGD (WP-SGD). WP-SGD combines weighted model parameters from different nodes in the system to produce the final output. WP-SGD makes use of the reduction in standard deviation to compensate for the loss from the inconsistency in performance of nodes in the cluster, which means that WP-SGD does not require that all nodes consume equal quantities of data. We also analyze the theoretical feasibility of running two other parallel SGD algorithms combined with WP-SGD in a heterogeneous environment. The experimental results show that WP-SGD significantly outperforms the traditional parallel SGD algorithms on distributed training systems with an unbalanced workload.\n    ",
        "submission_date": "2017-08-16T00:00:00",
        "last_modified_date": "2017-08-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.04988",
        "title": "Warp: a method for neural network interpretability applied to gene expression profiles",
        "authors": [
            "Trofimov Assya",
            "Lemieux Sebastien",
            "Perreault Claude"
        ],
        "abstract": "We show a proof of principle for warping, a method to interpret the inner working of neural networks in the context of gene expression analysis. Warping is an efficient way to gain insight to the inner workings of neural nets and make them more interpretable. We demonstrate the ability of warping to recover meaningful information for a given class on a samplespecific individual basis. We found warping works well in both linearly and nonlinearly separable datasets. These encouraging results show that warping has a potential to be the answer to neural networks interpretability in computational biology.\n    ",
        "submission_date": "2017-08-16T00:00:00",
        "last_modified_date": "2017-08-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.05045",
        "title": "Cross-lingual Entity Alignment via Joint Attribute-Preserving Embedding",
        "authors": [
            "Zequn Sun",
            "Wei Hu",
            "Chengkai Li"
        ],
        "abstract": "Entity alignment is the task of finding entities in two knowledge bases (KBs) that represent the same real-world object. When facing KBs in different natural languages, conventional cross-lingual entity alignment methods rely on machine translation to eliminate the language barriers. These approaches often suffer from the uneven quality of translations between languages. While recent embedding-based techniques encode entities and relationships in KBs and do not need machine translation for cross-lingual entity alignment, a significant number of attributes remain largely unexplored. In this paper, we propose a joint attribute-preserving embedding model for cross-lingual entity alignment. It jointly embeds the structures of two KBs into a unified vector space and further refines it by leveraging attribute correlations in the KBs. Our experimental results on real-world datasets show that this approach significantly outperforms the state-of-the-art embedding approaches for cross-lingual entity alignment and could be complemented with methods based on machine translation.\n    ",
        "submission_date": "2017-08-16T00:00:00",
        "last_modified_date": "2017-09-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.05069",
        "title": "A causation coefficient and taxonomy of correlation/causation relationships",
        "authors": [
            "Joshua Brul\u00e9"
        ],
        "abstract": "This paper introduces a causation coefficient which is defined in terms of probabilistic causal models. This coefficient is suggested as the natural causal analogue of the Pearson correlation coefficient and permits comparing causation and correlation to each other in a simple, yet rigorous manner. Together, these coefficients provide a natural way to classify the possible correlation/causation relationships that can occur in practice and examples of each relationship are provided. In addition, the typical relationship between correlation and causation is analyzed to provide insight into why correlation and causation are often conflated. Finally, example calculations of the causation coefficient are shown on a real data set.\n    ",
        "submission_date": "2017-08-05T00:00:00",
        "last_modified_date": "2017-08-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.05106",
        "title": "The Mean and Median Criterion for Automatic Kernel Bandwidth Selection for Support Vector Data Description",
        "authors": [
            "Arin Chaudhuri",
            "Deovrat Kakde",
            "Carol Sadek",
            "Laura Gonzalez",
            "Seunghyun Kong"
        ],
        "abstract": "Support vector data description (SVDD) is a popular technique for detecting anomalies. The SVDD classifier partitions the whole space into an inlier region, which consists of the region near the training data, and an outlier region, which consists of points away from the training data. The computation of the SVDD classifier requires a kernel function, and the Gaussian kernel is a common choice for the kernel function. The Gaussian kernel has a bandwidth parameter, whose value is important for good results. A small bandwidth leads to overfitting, and the resulting SVDD classifier overestimates the number of anomalies. A large bandwidth leads to underfitting, and the classifier fails to detect many anomalies. In this paper we present a new automatic, unsupervised method for selecting the Gaussian kernel bandwidth. The selected value can be computed quickly, and it is competitive with existing bandwidth selection methods.\n    ",
        "submission_date": "2017-08-16T00:00:00",
        "last_modified_date": "2017-08-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.05122",
        "title": "Evaluating Visual Conversational Agents via Cooperative Human-AI Games",
        "authors": [
            "Prithvijit Chattopadhyay",
            "Deshraj Yadav",
            "Viraj Prabhu",
            "Arjun Chandrasekaran",
            "Abhishek Das",
            "Stefan Lee",
            "Dhruv Batra",
            "Devi Parikh"
        ],
        "abstract": "As AI continues to advance, human-AI teams are inevitable. However, progress in AI is routinely measured in isolation, without a human in the loop. It is crucial to benchmark progress in AI, not just in isolation, but also in terms of how it translates to helping humans perform certain tasks, i.e., the performance of human-AI teams.\n",
        "submission_date": "2017-08-17T00:00:00",
        "last_modified_date": "2017-08-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.05325",
        "title": "Learning Musical Relations using Gated Autoencoders",
        "authors": [
            "Stefan Lattner",
            "Maarten Grachten",
            "Gerhard Widmer"
        ],
        "abstract": "Music is usually highly structured and it is still an open question how to design models which can successfully learn to recognize and represent musical structure. A fundamental problem is that structurally related patterns can have very distinct appearances, because the structural relationships are often based on transformations of musical material, like chromatic or diatonic transposition, inversion, retrograde, or rhythm change. In this preliminary work, we study the potential of two unsupervised learning techniques - Restricted Boltzmann Machines (RBMs) and Gated Autoencoders (GAEs) - to capture pre-defined transformations from constructed data pairs. We evaluate the models by using the learned representations as inputs in a discriminative task where for a given type of transformation (e.g. diatonic transposition), the specific relation between two musical patterns must be recognized (e.g. an upward transposition of diatonic steps). Furthermore, we measure the reconstruction error of models when reconstructing musical transformed patterns. Lastly, we test the models in an analogy-making task. We find that it is difficult to learn musical transformations with the RBM and that the GAE is much more adequate for this task, since it is able to learn representations of specific transformations that are largely content-invariant. We believe these results show that models such as GAEs may provide the basis for more encompassing music analysis systems, by endowing them with a better understanding of the structures underlying music.\n    ",
        "submission_date": "2017-08-17T00:00:00",
        "last_modified_date": "2017-08-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.05563",
        "title": "Induction of Decision Trees based on Generalized Graph Queries",
        "authors": [
            "Pedro Almagro-Blanco",
            "Fernando Sancho-Caparrini"
        ],
        "abstract": "Usually, decision tree induction algorithms are limited to work with non relational data. Given a record, they do not take into account other objects attributes even though they can provide valuable information for the learning task. In this paper we present GGQ-ID3, a multi-relational decision tree learning algorithm that uses Generalized Graph Queries (GGQ) as predicates in the decision nodes. GGQs allow to express complex patterns (including cycles) and they can be refined step-by-step. Also, they can evaluate structures (not only single records) and perform Regular Pattern Matching. GGQ are built dynamically (pattern mining) during the GGQ-ID3 tree construction process. We will show how to use GGQ-ID3 to perform multi-relational machine learning keeping complexity under control. Finally, some real examples of automatically obtained classification trees and semantic patterns are shown.\n",
        "submission_date": "2017-08-18T00:00:00",
        "last_modified_date": "2017-08-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.05565",
        "title": "LADDER: A Human-Level Bidding Agent for Large-Scale Real-Time Online Auctions",
        "authors": [
            "Yu Wang",
            "Jiayi Liu",
            "Yuxiang Liu",
            "Jun Hao",
            "Yang He",
            "Jinghe Hu",
            "Weipeng P. Yan",
            "Mantian Li"
        ],
        "abstract": "We present LADDER, the first deep reinforcement learning agent that can successfully learn control policies for large-scale real-world problems directly from raw inputs composed of high-level semantic information. The agent is based on an asynchronous stochastic variant of DQN (Deep Q Network) named DASQN. The inputs of the agent are plain-text descriptions of states of a game of incomplete information, i.e. real-time large scale online auctions, and the rewards are auction profits of very large scale. We apply the agent to an essential portion of JD's online RTB (real-time bidding) advertising business and find that it easily beats the former state-of-the-art bidding policy that had been carefully engineered and calibrated by human experts: during ",
        "submission_date": "2017-08-18T00:00:00",
        "last_modified_date": "2017-09-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.05682",
        "title": "An Improved Residual LSTM Architecture for Acoustic Modeling",
        "authors": [
            "Lu Huang",
            "Jiasong Sun",
            "Ji Xu",
            "Yi Yang"
        ],
        "abstract": "Long Short-Term Memory (LSTM) is the primary recurrent neural networks architecture for acoustic modeling in automatic speech recognition systems. Residual learning is an efficient method to help neural networks converge easier and faster. In this paper, we propose several types of residual LSTM methods for our acoustic modeling. Our experiments indicate that, compared with classic LSTM, our architecture shows more than 8% relative reduction in Phone Error Rate (PER) on TIMIT tasks. At the same time, our residual fast LSTM approach shows 4% relative reduction in PER on the same task. Besides, we find that all this architecture could have good results on THCHS-30, Librispeech and Switchboard corpora.\n    ",
        "submission_date": "2017-08-17T00:00:00",
        "last_modified_date": "2017-08-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.05688",
        "title": "Human Uncertainty and Ranking Error -- The Secret of Successful Evaluation in Predictive Data Mining",
        "authors": [
            "Kevin Jasberg",
            "Sergej Sizov"
        ],
        "abstract": "One of the most crucial issues in data mining is to model human behaviour in order to provide personalisation, adaptation and recommendation. This usually involves implicit or explicit knowledge, either by observing user interactions, or by asking users directly. But these sources of information are always subject to the volatility of human decisions, making utilised data uncertain to a particular extent. In this contribution, we elaborate on the impact of this human uncertainty when it comes to comparative assessments of different data mining approaches. In particular, we reveal two problems: (1) biasing effects on various metrics of model-based prediction and (2) the propagation of uncertainty and its thus induced error probabilities for algorithm rankings. For this purpose, we introduce a probabilistic view and prove the existence of those problems mathematically, as well as provide possible solution strategies. We exemplify our theory mainly in the context of recommender systems along with the metric RMSE as a prominent example of precision quality measures.\n    ",
        "submission_date": "2017-08-17T00:00:00",
        "last_modified_date": "2017-08-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.05714",
        "title": "A Stronger Foundation for Computer Science and P=NP",
        "authors": [
            "Mark Inman"
        ],
        "abstract": "This article describes a Turing machine which can solve for $\\beta^{'}$ which is RE-complete. RE-complete problems are proven to be undecidable by Turing's accepted proof on the Entscheidungsproblem. Thus, constructing a machine which decides over $\\beta^{'}$ implies inconsistency in ZFC. We then discover that unrestricted use of the axiom of substitution can lead to hidden assumptions in a certain class of proofs by contradiction. These hidden assumptions create an implied axiom of incompleteness for ZFC. Later, we offer a restriction on the axiom of substitution by introducing a new axiom which prevents impredicative tautologies from producing theorems. Our discovery in regards to these foundational arguments, disproves the SPACE hierarchy theorem which allows us to solve the P vs NP problem using a TIME-SPACE equivalence oracle.\n    ",
        "submission_date": "2017-08-18T00:00:00",
        "last_modified_date": "2018-04-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.05732",
        "title": "Security, Privacy and Safety Evaluation of Dynamic and Static Fleets of Drones",
        "authors": [
            "Raja Naeem Akram",
            "Konstantinos Markantonakis",
            "Keith Mayes",
            "Oussama Habachi",
            "Damien Sauveron",
            "Andreas Steyven",
            "Serge Chaumette"
        ],
        "abstract": "Inter-connected objects, either via public or private networks are the near future of modern societies. Such inter-connected objects are referred to as Internet-of-Things (IoT) and/or Cyber-Physical Systems (CPS). One example of such a system is based on Unmanned Aerial Vehicles (UAVs). The fleet of such vehicles are prophesied to take on multiple roles involving mundane to high-sensitive, such as, prompt pizza or shopping deliveries to your homes to battlefield deployment for reconnaissance and combat missions. Drones, as we refer to UAVs in this paper, either can operate individually (solo missions) or part of a fleet (group missions), with and without constant connection with the base station. The base station acts as the command centre to manage the activities of the drones. However, an independent, localised and effective fleet control is required, potentially based on swarm intelligence, for the reasons: 1) increase in the number of drone fleets, 2) number of drones in a fleet might be multiple of tens, 3) time-criticality in making decisions by such fleets in the wild, 4) potential communication congestions/lag, and 5) in some cases working in challenging terrains that hinders or mandates-limited communication with control centre (i.e., operations spanning long period of times or military usage of such fleets in enemy territory). This self-ware, mission-focused and independent fleet of drones that potential utilises swarm intelligence for a) air-traffic and/or flight control management, b) obstacle avoidance, c) self-preservation while maintaining the mission criteria, d) collaboration with other fleets in the wild (autonomously) and e) assuring the security, privacy and safety of physical (drones itself) and virtual (data, software) assets. In this paper, we investigate the challenges faced by fleet of drones and propose a potential course of action on how to overcome them.\n    ",
        "submission_date": "2017-08-18T00:00:00",
        "last_modified_date": "2017-08-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.05840",
        "title": "A Data and Model-Parallel, Distributed and Scalable Framework for Training of Deep Networks in Apache Spark",
        "authors": [
            "Disha Shrivastava",
            "Santanu Chaudhury",
            "Dr. Jayadeva"
        ],
        "abstract": "Training deep networks is expensive and time-consuming with the training period increasing with data size and growth in model parameters. In this paper, we provide a framework for distributed training of deep networks over a cluster of CPUs in Apache Spark. The framework implements both Data Parallelism and Model Parallelism making it suitable to use for deep networks which require huge training data and model parameters which are too big to fit into the memory of a single machine. It can be scaled easily over a cluster of cheap commodity hardware to attain significant speedup and obtain better results making it quite economical as compared to farm of GPUs and supercomputers. We have proposed a new algorithm for training of deep networks for the case when the network is partitioned across the machines (Model Parallelism) along with detailed cost analysis and proof of convergence of the same. We have developed implementations for Fully-Connected Feedforward Networks, Convolutional Neural Networks, Recurrent Neural Networks and Long Short-Term Memory architectures. We present the results of extensive simulations demonstrating the speedup and accuracy obtained by our framework for different sizes of the data and model parameters with variation in the number of worker cores/partitions; thereby showing that our proposed framework can achieve significant speedup (upto 11X for CNN) and is also quite scalable.\n    ",
        "submission_date": "2017-08-19T00:00:00",
        "last_modified_date": "2017-08-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.05866",
        "title": "A Brief Survey of Deep Reinforcement Learning",
        "authors": [
            "Kai Arulkumaran",
            "Marc Peter Deisenroth",
            "Miles Brundage",
            "Anil Anthony Bharath"
        ],
        "abstract": "Deep reinforcement learning is poised to revolutionise the field of AI and represents a step towards building autonomous systems with a higher level understanding of the visual world. Currently, deep learning is enabling reinforcement learning to scale to problems that were previously intractable, such as learning to play video games directly from pixels. Deep reinforcement learning algorithms are also applied to robotics, allowing control policies for robots to be learned directly from camera inputs in the real world. In this survey, we begin with an introduction to the general field of reinforcement learning, then progress to the main streams of value-based and policy-based methods. Our survey will cover central algorithms in deep reinforcement learning, including the deep $Q$-network, trust region policy optimisation, and asynchronous advantage actor-critic. In parallel, we highlight the unique advantages of deep neural networks, focusing on visual understanding via reinforcement learning. To conclude, we describe several current areas of research within the field.\n    ",
        "submission_date": "2017-08-19T00:00:00",
        "last_modified_date": "2017-09-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.05872",
        "title": "Agent-based computing from multi-agent systems to agent-based Models: a visual survey",
        "authors": [
            "Muaz A. Niazi",
            "Amir Hussain"
        ],
        "abstract": "Agent-Based Computing is a diverse research domain concerned with the building of intelligent software based on the concept of \"agents\". In this paper, we use Scientometric analysis to analyze all sub-domains of agent-based computing. Our data consists of 1,064 journal articles indexed in the ISI web of knowledge published during a twenty year period: 1990-2010. These were retrieved using a topic search with various keywords commonly used in sub-domains of agent-based computing. In our proposed approach, we have employed a combination of two applications for analysis, namely Network Workbench and CiteSpace - wherein Network Workbench allowed for the analysis of complex network aspects of the domain, detailed visualization-based analysis of the bibliographic data was performed using CiteSpace. Our results include the identification of the largest cluster based on keywords, the timeline of publication of index terms, the core journals and key subject categories. We also identify the core authors, top countries of origin of the manuscripts along with core research institutes. Finally, our results have interestingly revealed the strong presence of agent-based computing in a number of non-computing related scientific domains including Life Sciences, Ecological Sciences and Social Sciences.\n    ",
        "submission_date": "2017-08-19T00:00:00",
        "last_modified_date": "2017-08-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.05875",
        "title": "A novel agent-based simulation framework for sensing in complex adaptive environments",
        "authors": [
            "Muaz A. Niazi",
            "Amir Hussain"
        ],
        "abstract": "In this paper we present a novel Formal Agent-Based Simulation framework (FABS). FABS uses formal specification as a means of clear description of wireless sensor networks (WSN) sensing a Complex Adaptive Environment. This specification model is then used to develop an agent-based model of both the wireless sensor network as well as the environment. As proof of concept, we demonstrate the application of FABS to a boids model of self-organized flocking of animals monitored by a random deployment of proximity sensors.\n    ",
        "submission_date": "2017-08-19T00:00:00",
        "last_modified_date": "2017-08-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.05878",
        "title": "Event-Radar: Real-time Local Event Detection System for Geo-Tagged Tweet Streams",
        "authors": [
            "Sibo Zhang",
            "Yuan Cheng",
            "Deyuan Ke"
        ],
        "abstract": "The local event detection is to use posting messages with geotags on social networks to reveal the related ongoing events and their locations. Recent studies have demonstrated that the geo-tagged tweet stream serves as an unprecedentedly valuable source for local event detection. Nevertheless, how to effectively extract local events from large geo-tagged tweet streams in real time remains challenging. A robust and efficient cloud-based real-time local event detection software system would benefit various aspects in the real-life society, from shopping recommendation for customer service providers to disaster alarming for emergency departments. We use the preliminary research GeoBurst as a starting point, which proposed a novel method to detect local events. GeoBurst+ leverages a novel cross-modal authority measure to identify several pivots in the query window. Such pivots reveal different geo-topical activities and naturally attract related tweets to form candidate events. It further summarises the continuous stream and compares the candidates against the historical summaries to pinpoint truly interesting local events. We mainly implement a website demonstration system Event-Radar with an improved algorithm to show the real-time local events online for public interests. Better still, as the query window shifts, our method can update the event list with little time cost, thus achieving continuous monitoring of the stream.\n    ",
        "submission_date": "2017-08-19T00:00:00",
        "last_modified_date": "2017-10-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.05935",
        "title": "Software-Defined Robotics -- Idea & Approach",
        "authors": [
            "Ali Al-Bayaty"
        ],
        "abstract": "The methodology of Software-Defined Robotics hierarchical-based and stand-alone framework can be designed and implemented to program and control different sets of robots, regardless of their manufacturers' parameters and specifications, with unified commands and communications. This framework approach will increase the capability of (re)programming a specific group of robots during the runtime without affecting the others as desired in the critical missions and industrial operations, expand the shared bandwidth, enhance the reusability of code, leverage the computational processing power, decrease the unnecessary analyses of vast supplemental electrical components for each robot, as well as get advantages of the most state-of-the-art industrial trends in the cloud-based computing, Virtual Machines (VM), and Robot-as-a-Service (RaaS) technologies.\n    ",
        "submission_date": "2017-08-20T00:00:00",
        "last_modified_date": "2017-08-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.05997",
        "title": "A Batch Noise Contrastive Estimation Approach for Training Large Vocabulary Language Models",
        "authors": [
            "Youssef Oualil",
            "Dietrich Klakow"
        ],
        "abstract": "Training large vocabulary Neural Network Language Models (NNLMs) is a difficult task due to the explicit requirement of the output layer normalization, which typically involves the evaluation of the full softmax function over the complete vocabulary. This paper proposes a Batch Noise Contrastive Estimation (B-NCE) approach to alleviate this problem. This is achieved by reducing the vocabulary, at each time step, to the target words in the batch and then replacing the softmax by the noise contrastive estimation approach, where these words play the role of targets and noise samples at the same time. In doing so, the proposed approach can be fully formulated and implemented using optimal dense matrix operations. Applying B-NCE to train different NNLMs on the Large Text Compression Benchmark (LTCB) and the One Billion Word Benchmark (OBWB) shows a significant reduction of the training time with no noticeable degradation of the models performance. This paper also presents a new baseline comparative study of different standard NNLMs on the large OBWB on a single Titan-X GPU.\n    ",
        "submission_date": "2017-08-20T00:00:00",
        "last_modified_date": "2017-08-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.06039",
        "title": "More cat than cute? Interpretable Prediction of Adjective-Noun Pairs",
        "authors": [
            "Delia Fernandez",
            "Alejandro Woodward",
            "Victor Campos",
            "Xavier Giro-i-Nieto",
            "Brendan Jou",
            "Shih-Fu Chang"
        ],
        "abstract": "The increasing availability of affect-rich multimedia resources has bolstered interest in understanding sentiment and emotions in and from visual content. Adjective-noun pairs (ANP) are a popular mid-level semantic construct for capturing affect via visually detectable concepts such as \"cute dog\" or \"beautiful landscape\". Current state-of-the-art methods approach ANP prediction by considering each of these compound concepts as individual tokens, ignoring the underlying relationships in ANPs. This work aims at disentangling the contributions of the `adjectives' and `nouns' in the visual prediction of ANPs. Two specialised classifiers, one trained for detecting adjectives and another for nouns, are fused to predict 553 different ANPs. The resulting ANP prediction model is more interpretable as it allows us to study contributions of the adjective and noun components. Source code and models are available at ",
        "submission_date": "2017-08-21T00:00:00",
        "last_modified_date": "2017-08-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.06068",
        "title": "Vector Space Model as Cognitive Space for Text Classification",
        "authors": [
            "Barathi Ganesh HB",
            "Anand Kumar M",
            "Soman KP"
        ],
        "abstract": "In this era of digitization, knowing the user's sociolect aspects have become essential features to build the user specific recommendation systems. These sociolect aspects could be found by mining the user's language sharing in the form of text in social media and reviews. This paper describes about the experiment that was performed in PAN Author Profiling 2017 shared task. The objective of the task is to find the sociolect aspects of the users from their tweets. The sociolect aspects considered in this experiment are user's gender and native language information. Here user's tweets written in a different language from their native language are represented as Document - Term Matrix with document frequency as the constraint. Further classification is done using the Support Vector Machine by taking gender and native language as target classes. This experiment attains the average accuracy of 73.42% in gender prediction and 76.26% in the native language identification task.\n    ",
        "submission_date": "2017-08-21T00:00:00",
        "last_modified_date": "2017-08-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.06257",
        "title": "A Flow Model of Neural Networks",
        "authors": [
            "Zhen Li",
            "Zuoqiang Shi"
        ],
        "abstract": "Based on a natural connection between ResNet and transport equation or its characteristic equation, we propose a continuous flow model for both ResNet and plain net. Through this continuous model, a ResNet can be explicitly constructed as a refinement of a plain net. The flow model provides an alternative perspective to understand phenomena in deep neural networks, such as why it is necessary and sufficient to use 2-layer blocks in ResNets, why deeper is better, and why ResNets are even deeper, and so on. It also opens a gate to bring in more tools from the huge area of differential equations.\n    ",
        "submission_date": "2017-08-21T00:00:00",
        "last_modified_date": "2017-12-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.06276",
        "title": "The CARESSES EU-Japan project: making assistive robots culturally competent",
        "authors": [
            "Barbara Bruno",
            "Nak Young Chong",
            "Hiroko Kamide",
            "Sanjeev Kanoria",
            "Jaeryoung Lee",
            "Yuto Lim",
            "Amit Kumar Pandey",
            "Chris Papadopoulos",
            "Irena Papadopoulos",
            "Federico Pecora",
            "Alessandro Saffiotti",
            "Antonio Sgorbissa"
        ],
        "abstract": "The nursing literature shows that cultural competence is an important requirement for effective healthcare. We claim that personal assistive robots should likewise be culturally competent, that is, they should be aware of general cultural characteristics and of the different forms they take in different individuals, and take these into account while perceiving, reasoning, and acting. The CARESSES project is an Europe-Japan collaborative effort that aims at designing, developing and evaluating culturally competent assistive robots. These robots will be able to adapt the way they behave, speak and interact to the cultural identity of the person they assist. This paper describes the approach taken in the CARESSES project, its initial steps, and its future plans.\n    ",
        "submission_date": "2017-08-21T00:00:00",
        "last_modified_date": "2017-08-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.06303",
        "title": "Network Model Selection for Task-Focused Attributed Network Inference",
        "authors": [
            "Ivan Brugere",
            "Chris Kanich",
            "Tanya Y. Berger-Wolf"
        ],
        "abstract": "Networks are models representing relationships between entities. Often these relationships are explicitly given, or we must learn a representation which generalizes and predicts observed behavior in underlying individual data (e.g. attributes or labels). Whether given or inferred, choosing the best representation affects subsequent tasks and questions on the network. This work focuses on model selection to evaluate network representations from data, focusing on fundamental predictive tasks on networks. We present a modular methodology using general, interpretable network models, task neighborhood functions found across domains, and several criteria for robust model selection. We demonstrate our methodology on three online user activity datasets and show that network model selection for the appropriate network task vs. an alternate task increases performance by an order of magnitude in our experiments.\n    ",
        "submission_date": "2017-08-21T00:00:00",
        "last_modified_date": "2017-09-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.06374",
        "title": "On a Formal Model of Safe and Scalable Self-driving Cars",
        "authors": [
            "Shai Shalev-Shwartz",
            "Shaked Shammah",
            "Amnon Shashua"
        ],
        "abstract": "In recent years, car makers and tech companies have been racing towards self driving cars. It seems that the main parameter in this race is who will have the first car on the road. The goal of this paper is to add to the equation two additional crucial parameters. The first is standardization of safety assurance --- what are the minimal requirements that every self-driving car must satisfy, and how can we verify these requirements. The second parameter is scalability --- engineering solutions that lead to unleashed costs will not scale to millions of cars, which will push interest in this field into a niche academic corner, and drive the entire field into a \"winter of autonomous driving\". In the first part of the paper we propose a white-box, interpretable, mathematical model for safety assurance, which we call Responsibility-Sensitive Safety (RSS). In the second part we describe a design of a system that adheres to our safety assurance requirements and is scalable to millions of cars.\n    ",
        "submission_date": "2017-08-21T00:00:00",
        "last_modified_date": "2018-10-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.06425",
        "title": "SafePredict: A Meta-Algorithm for Machine Learning That Uses Refusals to Guarantee Correctness",
        "authors": [
            "Mustafa A. Kocak",
            "David Ramirez",
            "Elza Erkip",
            "Dennis E. Shasha"
        ],
        "abstract": "SafePredict is a novel meta-algorithm that works with any base prediction algorithm for online data to guarantee an arbitrarily chosen correctness rate, $1-\\epsilon$, by allowing refusals. Allowing refusals means that the meta-algorithm may refuse to emit a prediction produced by the base algorithm on occasion so that the error rate on non-refused predictions does not exceed $\\epsilon$. The SafePredict error bound does not rely on any assumptions on the data distribution or the base predictor. When the base predictor happens not to exceed the target error rate $\\epsilon$, SafePredict refuses only a finite number of times. When the error rate of the base predictor changes through time SafePredict makes use of a weight-shifting heuristic that adapts to these changes without knowing when the changes occur yet still maintains the correctness guarantee. Empirical results show that (i) SafePredict compares favorably with state-of-the art confidence based refusal mechanisms which fail to offer robust error guarantees; and (ii) combining SafePredict with such refusal mechanisms can in many cases further reduce the number of refusals. Our software (currently in Python) is included in the supplementary material.\n    ",
        "submission_date": "2017-08-21T00:00:00",
        "last_modified_date": "2017-11-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.06519",
        "title": "Learning Efficient Convolutional Networks through Network Slimming",
        "authors": [
            "Zhuang Liu",
            "Jianguo Li",
            "Zhiqiang Shen",
            "Gao Huang",
            "Shoumeng Yan",
            "Changshui Zhang"
        ],
        "abstract": "The deployment of deep convolutional neural networks (CNNs) in many real world applications is largely hindered by their high computational cost. In this paper, we propose a novel learning scheme for CNNs to simultaneously 1) reduce the model size; 2) decrease the run-time memory footprint; and 3) lower the number of computing operations, without compromising accuracy. This is achieved by enforcing channel-level sparsity in the network in a simple but effective way. Different from many existing approaches, the proposed method directly applies to modern CNN architectures, introduces minimum overhead to the training process, and requires no special software/hardware accelerators for the resulting models. We call our approach network slimming, which takes wide and large networks as input models, but during training insignificant channels are automatically identified and pruned afterwards, yielding thin and compact models with comparable accuracy. We empirically demonstrate the effectiveness of our approach with several state-of-the-art CNN models, including VGGNet, ResNet and DenseNet, on various image classification datasets. For VGGNet, a multi-pass version of network slimming gives a 20x reduction in model size and a 5x reduction in computing operations.\n    ",
        "submission_date": "2017-08-22T00:00:00",
        "last_modified_date": "2017-08-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.06665",
        "title": "Software engineering and the SP Theory of Intelligence",
        "authors": [
            "J Gerard Wolff"
        ],
        "abstract": "This paper describes a novel approach to software engineering derived from the \"SP Theory of Intelligence\" and its realisation in the \"SP Computer Model\". Despite superficial appearances, it is shown that many of the key ideas in software engineering have counterparts in the structure and workings of the SP system. Potential benefits of this new approach to software engineering include: the automation or semi-automation of software development, with support for programming of the SP system where necessary; allowing programmers to concentrate on 'world-oriented' parallelism, without worries about parallelism to speed up processing; support for the long-term goal of programming the SP system via written or spoken natural language; reducing or eliminating the distinction between 'design' and 'implementation'; reducing or eliminating operations like compiling or interpretation; reducing or eliminating the need for verification of software; reducing the need for validation of software; no formal distinction between program and database; the potential for substantial reductions in the number of types of data file and the number of computer languages; benefits for version control; and reducing technical debt.\n    ",
        "submission_date": "2017-08-18T00:00:00",
        "last_modified_date": "2018-08-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.06794",
        "title": "Human Action Recognition System using Good Features and Multilayer Perceptron Network",
        "authors": [
            "Jonti Talukdar",
            "Bhavana Mehta"
        ],
        "abstract": "Human action recognition involves the characterization of human actions through the automated analysis of video data and is integral in the development of smart computer vision systems. However, several challenges like dynamic backgrounds, camera stabilization, complex actions, occlusions etc. make action recognition in a real time and robust fashion difficult. Several complex approaches exist but are computationally intensive. This paper presents a novel approach of using a combination of good features along with iterative optical flow algorithm to compute feature vectors which are classified using a multilayer perceptron (MLP) network. The use of multiple features for motion descriptors enhances the quality of tracking. Resilient backpropagation algorithm is used for training the feedforward neural network reducing the learning time. The overall system accuracy is improved by optimizing the various parameters of the multilayer perceptron network.\n    ",
        "submission_date": "2017-08-22T00:00:00",
        "last_modified_date": "2017-08-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.06828",
        "title": "Classification of Radiology Reports Using Neural Attention Models",
        "authors": [
            "Bonggun Shin",
            "Falgun H. Chokshi",
            "Timothy Lee",
            "Jinho D. Choi"
        ],
        "abstract": "The electronic health record (EHR) contains a large amount of multi-dimensional and unstructured clinical data of significant operational and research value. Distinguished from previous studies, our approach embraces a double-annotated dataset and strays away from obscure \"black-box\" models to comprehensive deep learning models. In this paper, we present a novel neural attention mechanism that not only classifies clinically important findings. Specifically, convolutional neural networks (CNN) with attention analysis are used to classify radiology head computed tomography reports based on five categories that radiologists would account for in assessing acute and communicable findings in daily practice. The experiments show that our CNN attention models outperform non-neural models, especially when trained on a larger dataset. Our attention analysis demonstrates the intuition behind the classifier's decision by generating a heatmap that highlights attended terms used by the CNN model; this is valuable when potential downstream medical decisions are to be performed by human experts or the classifier information is to be used in cohort construction such as for epidemiological studies.\n    ",
        "submission_date": "2017-08-22T00:00:00",
        "last_modified_date": "2017-08-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.06832",
        "title": "Learning Anytime Predictions in Neural Networks via Adaptive Loss Balancing",
        "authors": [
            "Hanzhang Hu",
            "Debadeepta Dey",
            "Martial Hebert",
            "J. Andrew Bagnell"
        ],
        "abstract": "This work considers the trade-off between accuracy and test-time computational cost of deep neural networks (DNNs) via \\emph{anytime} predictions from auxiliary predictions. Specifically, we optimize auxiliary losses jointly in an \\emph{adaptive} weighted sum, where the weights are inversely proportional to average of each loss. Intuitively, this balances the losses to have the same scale. We demonstrate theoretical considerations that motivate this approach from multiple viewpoints, including connecting it to optimizing the geometric mean of the expectation of each loss, an objective that ignores the scale of losses. Experimentally, the adaptive weights induce more competitive anytime predictions on multiple recognition data-sets and models than non-adaptive approaches including weighing all losses equally. In particular, anytime neural networks (ANNs) can achieve the same accuracy faster using adaptive weights on a small network than using static constant weights on a large one. For problems with high performance saturation, we also show a sequence of exponentially deepening ANNscan achieve near-optimal anytime results at any budget, at the cost of a const fraction of extra computation.\n    ",
        "submission_date": "2017-08-22T00:00:00",
        "last_modified_date": "2018-05-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.06850",
        "title": "Learning Deep Neural Network Representations for Koopman Operators of Nonlinear Dynamical Systems",
        "authors": [
            "Enoch Yeung",
            "Soumya Kundu",
            "Nathan Hodas"
        ],
        "abstract": "The Koopman operator has recently garnered much attention for its value in dynamical systems analysis and data-driven model discovery. However, its application has been hindered by the computational complexity of extended dynamic mode decomposition; this requires a combinatorially large basis set to adequately describe many nonlinear systems of interest, e.g. cyber-physical infrastructure systems, biological networks, social systems, and fluid dynamics. Often the dictionaries generated for these problems are manually curated, requiring domain-specific knowledge and painstaking tuning. In this paper we introduce a deep learning framework for learning Koopman operators of nonlinear dynamical systems. We show that this novel method automatically selects efficient deep dictionaries, outperforming state-of-the-art methods. We benchmark this method on partially observed nonlinear systems, including the glycolytic oscillator and show it is able to predict quantitatively 100 steps into the future, using only a single timepoint, and qualitative oscillatory behavior 400 steps into the future.\n    ",
        "submission_date": "2017-08-22T00:00:00",
        "last_modified_date": "2017-11-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.06877",
        "title": "The Reachability of Computer Programs",
        "authors": [
            "Reginaldo I. Silva Filho",
            "Ricardo L. Azevedo da Rocha",
            "Camila Leite Silva",
            "Ricardo H. Gracini Guiraldelli"
        ],
        "abstract": "Would it be possible to explain the emergence of new computational ideas using the computation itself? Would it be feasible to describe the discovery process of new algorithmic solutions using only mathematics? This study is the first effort to analyze the nature of such inquiry from the viewpoint of effort to find a new algorithmic solution to a given problem. We define program reachability as a probability function whose argument is a form of the energetic cost (algorithmic entropy) of the problem.\n    ",
        "submission_date": "2017-08-23T00:00:00",
        "last_modified_date": "2017-08-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.06975",
        "title": "Generating Visual Representations for Zero-Shot Classification",
        "authors": [
            "Maxime Bucher",
            "St\u00e9phane Herbin",
            "Fr\u00e9d\u00e9ric Jurie"
        ],
        "abstract": "This paper addresses the task of learning an image clas-sifier when some categories are defined by semantic descriptions only (e.g. visual attributes) while the others are defined by exemplar images as well. This task is often referred to as the Zero-Shot classification task (ZSC). Most of the previous methods rely on learning a common embedding space allowing to compare visual features of unknown categories with semantic descriptions. This paper argues that these approaches are limited as i) efficient discrimi-native classifiers can't be used ii) classification tasks with seen and unseen categories (Generalized Zero-Shot Classification or GZSC) can't be addressed efficiently. In contrast , this paper suggests to address ZSC and GZSC by i) learning a conditional generator using seen classes ii) generate artificial training examples for the categories without exemplars. ZSC is then turned into a standard supervised learning problem. Experiments with 4 generative models and 5 datasets experimentally validate the approach, giving state-of-the-art results on both ZSC and GZSC.\n    ",
        "submission_date": "2017-08-23T00:00:00",
        "last_modified_date": "2017-12-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.06988",
        "title": "Paving the Roadway for Safety of Automated Vehicles: An Empirical Study on Testing Challenges",
        "authors": [
            "Alessia Knauss",
            "Jan Schr\u00f6der",
            "Christian Berger",
            "Henrik Eriksson"
        ],
        "abstract": "The technology in the area of automated vehicles is gaining speed and promises many advantages. However, with the recent introduction of conditionally automated driving, we have also seen accidents. Test protocols for both, conditionally automated (e.g., on highways) and automated vehicles do not exist yet and leave researchers and practitioners with different challenges. For instance, current test procedures do not suffice for fully automated vehicles, which are supposed to be completely in charge for the driving task and have no driver as a back up. This paper presents current challenges of testing the functionality and safety of automated vehicles derived from conducting focus groups and interviews with 26 participants from five countries having a background related to testing automotive safety-related ",
        "submission_date": "2017-05-09T00:00:00",
        "last_modified_date": "2017-05-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.06989",
        "title": "A Neural Network Approach for Mixing Language Models",
        "authors": [
            "Youssef Oualil",
            "Dietrich Klakow"
        ],
        "abstract": "The performance of Neural Network (NN)-based language models is steadily improving due to the emergence of new architectures, which are able to learn different natural language characteristics. This paper presents a novel framework, which shows that a significant improvement can be achieved by combining different existing heterogeneous models in a single architecture. This is done through 1) a feature layer, which separately learns different NN-based models and 2) a mixture layer, which merges the resulting model features. In doing so, this architecture benefits from the learning capabilities of each model with no noticeable increase in the number of model parameters or the training time. Extensive experiments conducted on the Penn Treebank (PTB) and the Large Text Compression Benchmark (LTCB) corpus showed a significant reduction of the perplexity when compared to state-of-the-art feedforward as well as recurrent neural network architectures.\n    ",
        "submission_date": "2017-08-23T00:00:00",
        "last_modified_date": "2017-08-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.07038",
        "title": "Non-linear Convolution Filters for CNN-based Learning",
        "authors": [
            "Georgios Zoumpourlis",
            "Alexandros Doumanoglou",
            "Nicholas Vretos",
            "Petros Daras"
        ],
        "abstract": "During the last years, Convolutional Neural Networks (CNNs) have achieved state-of-the-art performance in image classification. Their architectures have largely drawn inspiration by models of the primate visual system. However, while recent research results of neuroscience prove the existence of non-linear operations in the response of complex visual cells, little effort has been devoted to extend the convolution technique to non-linear forms. Typical convolutional layers are linear systems, hence their expressiveness is limited. To overcome this, various non-linearities have been used as activation functions inside CNNs, while also many pooling strategies have been applied. We address the issue of developing a convolution method in the context of a computational model of the visual cortex, exploring quadratic forms through the Volterra kernels. Such forms, constituting a more rich function space, are used as approximations of the response profile of visual cells. Our proposed second-order convolution is tested on CIFAR-10 and CIFAR-100. We show that a network which combines linear and non-linear filters in its convolutional layers, can outperform networks that use standard linear filters with the same architecture, yielding results competitive with the state-of-the-art on these datasets.\n    ",
        "submission_date": "2017-08-23T00:00:00",
        "last_modified_date": "2017-08-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.07050",
        "title": "Capturing Long-term Temporal Dependencies with Convolutional Networks for Continuous Emotion Recognition",
        "authors": [
            "Soheil Khorram",
            "Zakaria Aldeneh",
            "Dimitrios Dimitriadis",
            "Melvin McInnis",
            "Emily Mower Provost"
        ],
        "abstract": "The goal of continuous emotion recognition is to assign an emotion value to every frame in a sequence of acoustic features. We show that incorporating long-term temporal dependencies is critical for continuous emotion recognition tasks. To this end, we first investigate architectures that use dilated convolutions. We show that even though such architectures outperform previously reported systems, the output signals produced from such architectures undergo erratic changes between consecutive time steps. This is inconsistent with the slow moving ground-truth emotion labels that are obtained from human annotators. To deal with this problem, we model a downsampled version of the input signal and then generate the output signal through upsampling. Not only does the resulting downsampling/upsampling network achieve good performance, it also generates smooth output trajectories. Our method yields the best known audio-only performance on the RECOLA dataset.\n    ",
        "submission_date": "2017-08-23T00:00:00",
        "last_modified_date": "2017-08-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.07149",
        "title": "Towards an Automatic Turing Test: Learning to Evaluate Dialogue Responses",
        "authors": [
            "Ryan Lowe",
            "Michael Noseworthy",
            "Iulian V. Serban",
            "Nicolas Angelard-Gontier",
            "Yoshua Bengio",
            "Joelle Pineau"
        ],
        "abstract": "Automatically evaluating the quality of dialogue responses for unstructured domains is a challenging problem. Unfortunately, existing automatic evaluation metrics are biased and correlate very poorly with human judgements of response quality. Yet having an accurate automatic evaluation procedure is crucial for dialogue research, as it allows rapid prototyping and testing of new models with fewer expensive human evaluations. In response to this challenge, we formulate automatic dialogue evaluation as a learning problem. We present an evaluation model (ADEM) that learns to predict human-like scores to input responses, using a new dataset of human response scores. We show that the ADEM model's predictions correlate significantly, and at a level much higher than word-overlap metrics such as BLEU, with human judgements at both the utterance and system-level. We also show that ADEM can generalize to evaluating dialogue models unseen during training, an important step for automatic dialogue evaluation.\n    ",
        "submission_date": "2017-08-23T00:00:00",
        "last_modified_date": "2018-01-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.07244",
        "title": "On the Compressive Power of Deep Rectifier Networks for High Resolution Representation of Class Boundaries",
        "authors": [
            "Senjian An",
            "Mohammed Bennamoun",
            "Farid Boussaid"
        ],
        "abstract": "This paper provides a theoretical justification of the superior classification performance of deep rectifier networks over shallow rectifier networks from the geometrical perspective of piecewise linear (PWL) classifier boundaries. We show that, for a given threshold on the approximation error, the required number of boundary facets to approximate a general smooth boundary grows exponentially with the dimension of the data, and thus the number of boundary facets, referred to as boundary resolution, of a PWL classifier is an important quality measure that can be used to estimate a lower bound on the classification errors. However, learning naively an exponentially large number of boundary facets requires the determination of an exponentially large number of parameters and also requires an exponentially large number of training patterns. To overcome this issue of \"curse of dimensionality\", compressive representations of high resolution classifier boundaries are required. To show the superior compressive power of deep rectifier networks over shallow rectifier networks, we prove that the maximum boundary resolution of a single hidden layer rectifier network classifier grows exponentially with the number of units when this number is smaller than the dimension of the patterns. When the number of units is larger than the dimension of the patterns, the growth rate is reduced to a polynomial order. Consequently, the capacity of generating a high resolution boundary will increase if the same large number of units are arranged in multiple layers instead of a single hidden layer. Taking high dimensional spherical boundaries as examples, we show how deep rectifier networks can utilize geometric symmetries to approximate a boundary with the same accuracy but with a significantly fewer number of parameters than single hidden layer nets.\n    ",
        "submission_date": "2017-08-24T00:00:00",
        "last_modified_date": "2017-08-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.07252",
        "title": "A Study on Neural Network Language Modeling",
        "authors": [
            "Dengliang Shi"
        ],
        "abstract": "An exhaustive study on neural network language modeling (NNLM) is performed in this paper. Different architectures of basic neural network language models are described and examined. A number of different improvements over basic neural network language models, including importance sampling, word classes, caching and bidirectional recurrent neural network (BiRNN), are studied separately, and the advantages and disadvantages of every technique are evaluated. Then, the limits of neural network language modeling are explored from the aspects of model architecture and knowledge representation. Part of the statistical information from a word sequence will loss when it is processed word by word in a certain order, and the mechanism of training neural network by updating weight matrixes and vectors imposes severe restrictions on any significant enhancement of NNLM. For knowledge representation, the knowledge represented by neural network language models is the approximate probabilistic distribution of word sequences from a certain training data set rather than the knowledge of a language itself or the information conveyed by word sequences in a natural language. Finally, some directions for improving neural network language modeling further is discussed.\n    ",
        "submission_date": "2017-08-24T00:00:00",
        "last_modified_date": "2017-08-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.07303",
        "title": "Learning 6-DOF Grasping Interaction via Deep Geometry-aware 3D Representations",
        "authors": [
            "Xinchen Yan",
            "Jasmine Hsu",
            "Mohi Khansari",
            "Yunfei Bai",
            "Arkanath Pathak",
            "Abhinav Gupta",
            "James Davidson",
            "Honglak Lee"
        ],
        "abstract": "This paper focuses on the problem of learning 6-DOF grasping with a parallel jaw gripper in simulation. We propose the notion of a geometry-aware representation in grasping based on the assumption that knowledge of 3D geometry is at the heart of interaction. Our key idea is constraining and regularizing grasping interaction learning through 3D geometry prediction. Specifically, we formulate the learning of deep geometry-aware grasping model in two steps: First, we learn to build mental geometry-aware representation by reconstructing the scene (i.e., 3D occupancy grid) from RGBD input via generative 3D shape modeling. Second, we learn to predict grasping outcome with its internal geometry-aware representation. The learned outcome prediction model is used to sequentially propose grasping solutions via analysis-by-synthesis optimization. Our contributions are fourfold: (1) To best of our knowledge, we are presenting for the first time a method to learn a 6-DOF grasping net from RGBD input; (2) We build a grasping dataset from demonstrations in virtual reality with rich sensory and interaction annotations. This dataset includes 101 everyday objects spread across 7 categories, additionally, we propose a data augmentation strategy for effective learning; (3) We demonstrate that the learned geometry-aware representation leads to about 10 percent relative performance improvement over the baseline CNN on grasping objects from our dataset. (4) We further demonstrate that the model generalizes to novel viewpoints and object instances.\n    ",
        "submission_date": "2017-08-24T00:00:00",
        "last_modified_date": "2018-06-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.07579",
        "title": "Hamiltonian Maker-Breaker games on small graphs",
        "authors": [
            "Milo\u0161 Stojakovi\u0107",
            "Nikola Trkulja"
        ],
        "abstract": "We look at the unbiased Maker-Breaker Hamiltonicity game played on the edge set of a complete graph $K_n$, where Maker's goal is to claim a Hamiltonian cycle. First, we prove that, independent of who starts, Maker can win the game for $n = 8$ and $n = 9$. Then we use an inductive argument to show that, independent of who starts, Maker can win the game if and only if $n \\geq 8$. This, in particular, resolves in the affirmative the long-standing conjecture of Papaioannou.\n",
        "submission_date": "2017-08-25T00:00:00",
        "last_modified_date": "2018-08-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.07580",
        "title": "The Expanding Approvals Rule: Improving Proportional Representation and Monotonicity",
        "authors": [
            "Haris Aziz",
            "Barton Lee"
        ],
        "abstract": "Proportional representation (PR) is often discussed in voting settings as a major desideratum. For the past century or so, it is common both in practice and in the academic literature to jump to single transferable vote (STV) as the solution for achieving PR. Some of the most prominent electoral reform movements around the globe are pushing for the adoption of STV. It has been termed a major open problem to design a voting rule that satisfies the same PR properties as STV and better monotonicity properties. In this paper, we first present a taxonomy of proportional representation axioms for general weak order preferences, some of which generalise and strengthen previously introduced concepts. We then present a rule called Expanding Approvals Rule (EAR) that satisfies properties stronger than the central PR axiom satisfied by STV, can handle indifferences in a convenient and computationally efficient manner, and also satisfies better candidate monotonicity properties. In view of this, our proposed rule seems to be a compelling solution for achieving proportional representation in voting settings.\n    ",
        "submission_date": "2017-08-25T00:00:00",
        "last_modified_date": "2018-06-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.07607",
        "title": "Reinforcement Mechanism Design for e-commerce",
        "authors": [
            "Qingpeng Cai",
            "Aris Filos-Ratsikas",
            "Pingzhong Tang",
            "Yiwei Zhang"
        ],
        "abstract": "We study the problem of allocating impressions to sellers in e-commerce websites, such as Amazon, eBay or Taobao, aiming to maximize the total revenue generated by the platform. We employ a general framework of reinforcement mechanism design, which uses deep reinforcement learning to design efficient algorithms, taking the strategic behaviour of the sellers into account. Specifically, we model the impression allocation problem as a Markov decision process, where the states encode the history of impressions, prices, transactions and generated revenue and the actions are the possible impression allocations in each round. To tackle the problem of continuity and high-dimensionality of states and actions, we adopt the ideas of the DDPG algorithm to design an actor-critic policy gradient algorithm which takes advantage of the problem domain in order to achieve convergence and stability. We evaluate our proposed algorithm, coined IA(GRU), by comparing it against DDPG, as well as several natural heuristics, under different rationality models for the sellers - we assume that sellers follow well-known no-regret type strategies which may vary in their degree of sophistication. We find that IA(GRU) outperforms all algorithms in terms of the total revenue.\n    ",
        "submission_date": "2017-08-25T00:00:00",
        "last_modified_date": "2018-02-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.07689",
        "title": "Understanding and Comparing Deep Neural Networks for Age and Gender Classification",
        "authors": [
            "Sebastian Lapuschkin",
            "Alexander Binder",
            "Klaus-Robert M\u00fcller",
            "Wojciech Samek"
        ],
        "abstract": "Recently, deep neural networks have demonstrated excellent performances in recognizing the age and gender on human face images. However, these models were applied in a black-box manner with no information provided about which facial features are actually used for prediction and how these features depend on image preprocessing, model initialization and architecture choice. We present a study investigating these different effects.\n",
        "submission_date": "2017-08-25T00:00:00",
        "last_modified_date": "2017-08-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.07732",
        "title": "Multi-Agent Q-Learning for Minimizing Demand-Supply Power Deficit in Microgrids",
        "authors": [
            "Raghuram Bharadwaj Diddigi",
            "D. Sai Koti Reddy",
            "Shalabh Bhatnagar"
        ],
        "abstract": "We consider the problem of minimizing the difference in the demand and the supply of power using microgrids. We setup multiple microgrids, that provide electricity to a village. They have access to the batteries that can store renewable power and also the electrical lines from the main grid. During each time period, these microgrids need to take decision on the amount of renewable power to be used from the batteries as well as the amount of power needed from the main grid. We formulate this problem in the framework of Markov Decision Process (MDP), similar to the one discussed in [1]. The power allotment to the village from the main grid is fixed and bounded, whereas the renewable energy generation is uncertain in nature. Therefore we adapt a distributed version of the popular Reinforcement learning technique, Multi-Agent Q-Learning to the problem. Finally, we also consider a variant of this problem where the cost of power production at the main site is taken into consideration. In this scenario the microgrids need to minimize the demand-supply deficit, while maintaining the desired average cost of the power production.\n    ",
        "submission_date": "2017-08-25T00:00:00",
        "last_modified_date": "2017-08-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.07863",
        "title": "$k$-Nearest Neighbor Augmented Neural Networks for Text Classification",
        "authors": [
            "Zhiguo Wang",
            "Wael Hamza",
            "Linfeng Song"
        ],
        "abstract": "In recent years, many deep-learning based models are proposed for text classification. This kind of models well fits the training set from the statistical point of view. However, it lacks the capacity of utilizing instance-level information from individual instances in the training set. In this work, we propose to enhance neural network models by allowing them to leverage information from $k$-nearest neighbor (kNN) of the input text. Our model employs a neural network that encodes texts into text embeddings. Moreover, we also utilize $k$-nearest neighbor of the input text as an external memory, and utilize it to capture instance-level information from the training set. The final prediction is made based on features from both the neural network encoder and the kNN memory. Experimental results on several standard benchmark datasets show that our model outperforms the baseline model on all the datasets, and it even beats a very deep neural network model (with 29 layers) in several datasets. Our model also shows superior performance when training instances are scarce, and when the training set is severely unbalanced. Our model also leverages techniques such as semi-supervised training and transfer learning quite well.\n    ",
        "submission_date": "2017-08-25T00:00:00",
        "last_modified_date": "2017-08-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.07918",
        "title": "Robust Task Clustering for Deep Many-Task Learning",
        "authors": [
            "Mo Yu",
            "Xiaoxiao Guo",
            "Jinfeng Yi",
            "Shiyu Chang",
            "Saloni Potdar",
            "Gerald Tesauro",
            "Haoyu Wang",
            "Bowen Zhou"
        ],
        "abstract": "We investigate task clustering for deep-learning based multi-task and few-shot learning in a many-task setting. We propose a new method to measure task similarities with cross-task transfer performance matrix for the deep learning scenario. Although this matrix provides us critical information regarding similarity between tasks, its asymmetric property and unreliable performance scores can affect conventional clustering methods adversely. Additionally, the uncertain task-pairs, i.e., the ones with extremely asymmetric transfer scores, may collectively mislead clustering algorithms to output an inaccurate task-partition. To overcome these limitations, we propose a novel task-clustering algorithm by using the matrix completion technique. The proposed algorithm constructs a partially-observed similarity matrix based on the certainty of cluster membership of the task-pairs. We then use a matrix completion algorithm to complete the similarity matrix. Our theoretical analysis shows that under mild constraints, the proposed algorithm will perfectly recover the underlying \"true\" similarity matrix with a high probability. Our results show that the new task clustering method can discover task clusters for training flexible and superior neural network models in a multi-task learning setup for sentiment classification and dialog intent classification tasks. Our task clustering approach also extends metric-based few-shot learning methods to adapt multiple metrics, which demonstrates empirical advantages when the tasks are diverse.\n    ",
        "submission_date": "2017-08-26T00:00:00",
        "last_modified_date": "2018-05-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.07969",
        "title": "3D Object Reconstruction from a Single Depth View with Adversarial Learning",
        "authors": [
            "Bo Yang",
            "Hongkai Wen",
            "Sen Wang",
            "Ronald Clark",
            "Andrew Markham",
            "Niki Trigoni"
        ],
        "abstract": "In this paper, we propose a novel 3D-RecGAN approach, which reconstructs the complete 3D structure of a given object from a single arbitrary depth view using generative adversarial networks. Unlike the existing work which typically requires multiple views of the same object or class labels to recover the full 3D geometry, the proposed 3D-RecGAN only takes the voxel grid representation of a depth view of the object as input, and is able to generate the complete 3D occupancy grid by filling in the occluded/missing regions. The key idea is to combine the generative capabilities of autoencoders and the conditional Generative Adversarial Networks (GAN) framework, to infer accurate and fine-grained 3D structures of objects in high-dimensional voxel space. Extensive experiments on large synthetic datasets show that the proposed 3D-RecGAN significantly outperforms the state of the art in single view 3D object reconstruction, and is able to reconstruct unseen types of objects. Our code and data are available at: ",
        "submission_date": "2017-08-26T00:00:00",
        "last_modified_date": "2017-08-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.08035",
        "title": "A Conservation Law Method in Optimization",
        "authors": [
            "Bin Shi"
        ],
        "abstract": "We propose some algorithms to find local minima in nonconvex optimization and to obtain global minima in some degree from the Newton Second Law without friction. With the key observation of the velocity observable and controllable in the motion, the algorithms simulate the Newton Second Law without friction based on symplectic Euler scheme. From the intuitive analysis of analytical solution, we give a theoretical analysis for the high-speed convergence in the algorithm proposed. Finally, we propose the experiments for strongly convex function, non-strongly convex function and nonconvex function in high-dimension.\n    ",
        "submission_date": "2017-08-27T00:00:00",
        "last_modified_date": "2017-10-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.08127",
        "title": "RIOT: a Stochastic-based Method for Workflow Scheduling in the Cloud",
        "authors": [
            "Jianfeng Chen",
            "Tim Menzies"
        ],
        "abstract": "Cloud computing provides engineers or scientists a place to run complex computing tasks. Finding a workflow's deployment configuration in a cloud environment is not easy. Traditional workflow scheduling algorithms were based on some heuristics, e.g. reliability greedy, cost greedy, cost-time balancing, etc., or more recently, the meta-heuristic methods, such as genetic algorithms. These methods are very slow and not suitable for rescheduling in the dynamic cloud environment. This paper introduces RIOT (Randomized Instance Order Types), a stochastic based method for workflow scheduling. RIOT groups the tasks in the workflow into virtual machines via a probability model and then uses an effective surrogate-based method to assess a large amount of potential scheduling. Experiments in dozens of study cases showed that RIOT executes tens of times faster than traditional methods while generating comparable results to other methods.\n    ",
        "submission_date": "2017-08-27T00:00:00",
        "last_modified_date": "2018-04-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.08133",
        "title": "Methods for applying the Neural Engineering Framework to neuromorphic hardware",
        "authors": [
            "Aaron R. Voelker",
            "Chris Eliasmith"
        ],
        "abstract": "We review our current software tools and theoretical methods for applying the Neural Engineering Framework to state-of-the-art neuromorphic hardware. These methods can be used to implement linear and nonlinear dynamical systems that exploit axonal transmission time-delays, and to fully account for nonideal mixed-analog-digital synapses that exhibit higher-order dynamics with heterogeneous time-constants. This summarizes earlier versions of these methods that have been discussed in a more biological context (Voelker & Eliasmith, 2017) or regarding a specific neuromorphic architecture (Voelker et al., 2017).\n    ",
        "submission_date": "2017-08-27T00:00:00",
        "last_modified_date": "2017-08-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.08227",
        "title": "ChemGAN challenge for drug discovery: can AI reproduce natural chemical diversity?",
        "authors": [
            "Mostapha Benhenda"
        ],
        "abstract": "Generating molecules with desired chemical properties is important for drug discovery. The use of generative neural networks is promising for this task. However, from visual inspection, it often appears that generated samples lack diversity. In this paper, we quantify this internal chemical diversity, and we raise the following challenge: can a nontrivial AI model reproduce natural chemical diversity for desired molecules? To illustrate this question, we consider two generative models: a Reinforcement Learning model and the recently introduced ORGAN. Both fail at this challenge. We hope this challenge will stimulate research in this direction.\n    ",
        "submission_date": "2017-08-28T00:00:00",
        "last_modified_date": "2017-08-31T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.08289",
        "title": "Generating Query Suggestions to Support Task-Based Search",
        "authors": [
            "Dar\u00edo Garigliotti",
            "Krisztian Balog"
        ],
        "abstract": "We address the problem of generating query suggestions to support users in completing their underlying tasks (which motivated them to search in the first place). Given an initial query, these query suggestions should provide a coverage of possible subtasks the user might be looking for. We propose a probabilistic modeling framework that obtains keyphrases from multiple sources and generates query suggestions from these keyphrases. Using the test suites of the TREC Tasks track, we evaluate and analyze each component of our model.\n    ",
        "submission_date": "2017-08-28T00:00:00",
        "last_modified_date": "2017-08-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.08291",
        "title": "On Type-Aware Entity Retrieval",
        "authors": [
            "Dar\u00edo Garigliotti",
            "Krisztian Balog"
        ],
        "abstract": "Today, the practice of returning entities from a knowledge base in response to search queries has become widespread. One of the distinctive characteristics of entities is that they are typed, i.e., assigned to some hierarchically organized type system (type taxonomy). The primary objective of this paper is to gain a better understanding of how entity type information can be utilized in entity retrieval. We perform this investigation in an idealized \"oracle\" setting, assuming that we know the distribution of target types of the relevant entities for a given query. We perform a thorough analysis of three main aspects: (i) the choice of type taxonomy, (ii) the representation of hierarchical type information, and (iii) the combination of type-based and term-based similarity in the retrieval model. Using a standard entity search test collection based on DBpedia, we find that type information proves most useful when using large type taxonomies that provide very specific types. We provide further insights on the extensional coverage of entities and on the utility of target types.\n    ",
        "submission_date": "2017-08-28T00:00:00",
        "last_modified_date": "2017-08-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.08299",
        "title": "The Convergence of Machine Learning and Communications",
        "authors": [
            "Wojciech Samek",
            "Slawomir Stanczak",
            "Thomas Wiegand"
        ],
        "abstract": "The areas of machine learning and communication technology are converging. Today's communications systems generate a huge amount of traffic data, which can help to significantly enhance the design and management of networks and communication components when combined with advanced machine learning methods. Furthermore, recently developed end-to-end training procedures offer new ways to jointly optimize the components of a communication system. Also in many emerging application fields of communication technology, e.g., smart cities or internet of things, machine learning methods are of central importance. This paper gives an overview over the use of machine learning in different areas of communications and discusses two exemplar applications in wireless networking. Furthermore, it identifies promising future research topics and discusses their potential impact.\n    ",
        "submission_date": "2017-08-28T00:00:00",
        "last_modified_date": "2017-08-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.08377",
        "title": "Two-Dimensional Indirect Binary Search for the Positive One-in-Three Satisfiability Problem",
        "authors": [
            "Shunichi Matsubara"
        ],
        "abstract": "In this paper, we propose an algorithm for the positive one-in-three satisfiability problem (Pos1in3SAT). The proposed algorithm can efficiently decide the existence of a satisfying assignment in all assignments for a given formula by using a 2-dimensional binary search method without constructing an exponential number of assignments.\n    ",
        "submission_date": "2017-08-28T00:00:00",
        "last_modified_date": "2017-09-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.08430",
        "title": "Deep Belief Networks used on High Resolution Multichannel Electroencephalography Data for Seizure Detection",
        "authors": [
            "JT Turner",
            "Adam Page",
            "Tinoosh Mohsenin",
            "Tim Oates"
        ],
        "abstract": "Ubiquitous bio-sensing for personalized health monitoring is slowly becoming a reality with the increasing availability of small, diverse, robust, high fidelity sensors. This oncoming flood of data begs the question of how we will extract useful information from it. In this paper we explore the use of a variety of representations and machine learning algorithms applied to the task of seizure detection in high resolution, multichannel EEG data. We explore classification accuracy, computational complexity and memory requirements with a view toward understanding which approaches are most suitable for such tasks as the number of people involved and the amount of data they produce grows to be quite large. In particular, we show that layered learning approaches such as Deep Belief Networks excel along these dimensions.\n    ",
        "submission_date": "2017-08-28T00:00:00",
        "last_modified_date": "2017-08-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.08508",
        "title": "Subspace Selection to Suppress Confounding Source Domain Information in AAM Transfer Learning",
        "authors": [
            "Azin Asgarian",
            "Ahmed Bilal Ashraf",
            "David Fleet",
            "Babak Taati"
        ],
        "abstract": "Active appearance models (AAMs) are a class of generative models that have seen tremendous success in face analysis. However, model learning depends on the availability of detailed annotation of canonical landmark points. As a result, when accurate AAM fitting is required on a different set of variations (expression, pose, identity), a new dataset is collected and annotated. To overcome the need for time consuming data collection and annotation, transfer learning approaches have received recent attention. The goal is to transfer knowledge from previously available datasets (source) to a new dataset (target). We propose a subspace transfer learning method, in which we select a subspace from the source that best describes the target space. We propose a metric to compute the directional similarity between the source eigenvectors and the target subspace. We show an equivalence between this metric and the variance of target data when projected onto source eigenvectors. Using this equivalence, we select a subset of source principal directions that capture the variance in target data. To define our model, we augment the selected source subspace with the target subspace learned from a handful of target examples. In experiments done on six publicly available datasets, we show that our approach outperforms the state of the art in terms of the RMS fitting error as well as the percentage of test examples for which AAM fitting converges to the ground truth.\n    ",
        "submission_date": "2017-08-28T00:00:00",
        "last_modified_date": "2017-10-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.08551",
        "title": "Deep Learning for Accelerated Reliability Analysis of Infrastructure Networks",
        "authors": [
            "Mohammad Amin Nabian",
            "Hadi Meidani"
        ],
        "abstract": "Natural disasters can have catastrophic impacts on the functionality of infrastructure systems and cause severe physical and socio-economic losses. Given budget constraints, it is crucial to optimize decisions regarding mitigation, preparedness, response, and recovery practices for these systems. This requires accurate and efficient means to evaluate the infrastructure system reliability. While numerous research efforts have addressed and quantified the impact of natural disasters on infrastructure systems, typically using the Monte Carlo approach, they still suffer from high computational cost and, thus, are of limited applicability to large systems. This paper presents a deep learning framework for accelerating infrastructure system reliability analysis. In particular, two distinct deep neural network surrogates are constructed and studied: (1) A classifier surrogate which speeds up the connectivity determination of networks, and (2) An end-to-end surrogate that replaces a number of components such as roadway status realization, connectivity determination, and connectivity averaging. The proposed approach is applied to a simulation-based study of the two-terminal connectivity of a California transportation network subject to extreme probabilistic earthquake events. Numerical results highlight the effectiveness of the proposed approach in accelerating the transportation system two-terminal reliability analysis with extremely high prediction accuracy.\n    ",
        "submission_date": "2017-08-28T00:00:00",
        "last_modified_date": "2017-08-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.08559",
        "title": "DeepTest: Automated Testing of Deep-Neural-Network-driven Autonomous Cars",
        "authors": [
            "Yuchi Tian",
            "Kexin Pei",
            "Suman Jana",
            "Baishakhi Ray"
        ],
        "abstract": "Recent advances in Deep Neural Networks (DNNs) have led to the development of DNN-driven autonomous cars that, using sensors like camera, LiDAR, etc., can drive without any human intervention. Most major manufacturers including Tesla, GM, Ford, BMW, and Waymo/Google are working on building and testing different types of autonomous vehicles. The lawmakers of several US states including California, Texas, and New York have passed new legislation to fast-track the process of testing and deployment of autonomous vehicles on their roads.\n",
        "submission_date": "2017-08-28T00:00:00",
        "last_modified_date": "2018-03-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.08611",
        "title": "Safe Reinforcement Learning via Shielding",
        "authors": [
            "Mohammed Alshiekh",
            "Roderick Bloem",
            "Ruediger Ehlers",
            "Bettina K\u00f6nighofer",
            "Scott Niekum",
            "Ufuk Topcu"
        ],
        "abstract": "Reinforcement learning algorithms discover policies that maximize reward, but do not necessarily guarantee safety during learning or execution phases. We introduce a new approach to learn optimal policies while enforcing properties expressed in temporal logic. To this end, given the temporal logic specification that is to be obeyed by the learning system, we propose to synthesize a reactive system called a shield. The shield is introduced in the traditional learning process in two alternative ways, depending on the location at which the shield is implemented. In the first one, the shield acts each time the learning agent is about to make a decision and provides a list of safe actions. In the second way, the shield is introduced after the learning agent. The shield monitors the actions from the learner and corrects them only if the chosen action causes a violation of the specification. We discuss which requirements a shield must meet to preserve the convergence guarantees of the learner. Finally, we demonstrate the versatility of our approach on several challenging reinforcement learning scenarios.\n    ",
        "submission_date": "2017-08-29T00:00:00",
        "last_modified_date": "2017-09-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.08722",
        "title": "Unifying DAGs and UGs",
        "authors": [
            "Jose M. Pe\u00f1a"
        ],
        "abstract": "We introduce a new class of graphical models that generalizes Lauritzen-Wermuth-Frydenberg chain graphs by relaxing the semi-directed acyclity constraint so that only directed cycles are forbidden. Moreover, up to two edges are allowed between any pair of nodes. Specifically, we present local, pairwise and global Markov properties for the new graphical models and prove their equivalence. We also present an equivalent factorization property. Finally, we present a causal interpretation of the new models.\n    ",
        "submission_date": "2017-08-29T00:00:00",
        "last_modified_date": "2018-03-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.08917",
        "title": "CirCNN: Accelerating and Compressing Deep Neural Networks Using Block-CirculantWeight Matrices",
        "authors": [
            "Caiwen Ding",
            "Siyu Liao",
            "Yanzhi Wang",
            "Zhe Li",
            "Ning Liu",
            "Youwei Zhuo",
            "Chao Wang",
            "Xuehai Qian",
            "Yu Bai",
            "Geng Yuan",
            "Xiaolong Ma",
            "Yipeng Zhang",
            "Jian Tang",
            "Qinru Qiu",
            "Xue Lin",
            "Bo Yuan"
        ],
        "abstract": "Large-scale deep neural networks (DNNs) are both compute and memory intensive. As the size of DNNs continues to grow, it is critical to improve the energy efficiency and performance while maintaining accuracy. For DNNs, the model size is an important factor affecting performance, scalability and energy efficiency. Weight pruning achieves good compression ratios but suffers from three drawbacks: 1) the irregular network structure after pruning; 2) the increased training complexity; and 3) the lack of rigorous guarantee of compression ratio and inference accuracy. To overcome these limitations, this paper proposes CirCNN, a principled approach to represent weights and process neural networks using block-circulant matrices. CirCNN utilizes the Fast Fourier Transform (FFT)-based fast multiplication, simultaneously reducing the computational complexity (both in inference and training) from O(n2) to O(nlogn) and the storage complexity from O(n2) to O(n), with negligible accuracy loss. Compared to other approaches, CirCNN is distinct due to its mathematical rigor: it can converge to the same effectiveness as DNNs without compression. The CirCNN architecture, a universal DNN inference engine that can be implemented on various hardware/software platforms with configurable network architecture. To demonstrate the performance and energy efficiency, we test CirCNN in FPGA, ASIC and embedded processors. Our results show that CirCNN architecture achieves very high energy efficiency and performance with a small hardware footprint. Based on the FPGA implementation and ASIC synthesis results, CirCNN achieves 6-102X energy efficiency improvements compared with the best state-of-the-art results.\n    ",
        "submission_date": "2017-08-29T00:00:00",
        "last_modified_date": "2017-08-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.08985",
        "title": "Limiting the Reconstruction Capability of Generative Neural Network using Negative Learning",
        "authors": [
            "Asim Munawar",
            "Phongtharin Vinayavekhin",
            "Giovanni De Magistris"
        ],
        "abstract": "Generative models are widely used for unsupervised learning with various applications, including data compression and signal restoration. Training methods for such systems focus on the generality of the network given limited amount of training data. A less researched type of techniques concerns generation of only a single type of input. This is useful for applications such as constraint handling, noise reduction and anomaly detection. In this paper we present a technique to limit the generative capability of the network using negative learning. The proposed method searches the solution in the gradient direction for the desired input and in the opposite direction for the undesired input. One of the application can be anomaly detection where the undesired inputs are the anomalous data. In the results section we demonstrate the features of the algorithm using MNIST handwritten digit dataset and latter apply the technique to a real-world obstacle detection problem. The results clearly show that the proposed learning technique can significantly improve the performance for anomaly detection.\n    ",
        "submission_date": "2017-08-16T00:00:00",
        "last_modified_date": "2017-08-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.09020",
        "title": "Learning to Price with Reference Effects",
        "authors": [
            "Abbas Kazerouni",
            "Benjamin Van Roy"
        ],
        "abstract": "As a firm varies the price of a product, consumers exhibit reference effects, making purchase decisions based not only on the prevailing price but also the product's price history. We consider the problem of learning such behavioral patterns as a monopolist releases, markets, and prices products. This context calls for pricing decisions that intelligently trade off between maximizing revenue generated by a current product and probing to gain information for future benefit. Due to dependence on price history, realized demand can reflect delayed consequences of earlier pricing decisions. As such, inference entails attribution of outcomes to prior decisions and effective exploration requires planning price sequences that yield informative future outcomes. Despite the considerable complexity of this problem, we offer a tractable systematic approach. In particular, we frame the problem as one of reinforcement learning and leverage Thompson sampling. We also establish a regret bound that provides graceful guarantees on how performance improves as data is gathered and how this depends on the complexity of the demand model. We illustrate merits of the approach through simulations.\n    ",
        "submission_date": "2017-08-29T00:00:00",
        "last_modified_date": "2017-08-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.09251",
        "title": "Quality and Diversity Optimization: A Unifying Modular Framework",
        "authors": [
            "Antoine Cully",
            "Yiannis Demiris"
        ],
        "abstract": "The optimization of functions to find the best solution according to one or several objectives has a central role in many engineering and research fields. Recently, a new family of optimization algorithms, named Quality-Diversity optimization, has been introduced, and contrasts with classic algorithms. Instead of searching for a single solution, Quality-Diversity algorithms are searching for a large collection of both diverse and high-performing solutions. The role of this collection is to cover the range of possible solution types as much as possible, and to contain the best solution for each type. The contribution of this paper is threefold. Firstly, we present a unifying framework of Quality-Diversity optimization algorithms that covers the two main algorithms of this family (Multi-dimensional Archive of Phenotypic Elites and the Novelty Search with Local Competition), and that highlights the large variety of variants that can be investigated within this family. Secondly, we propose algorithms with a new selection mechanism for Quality-Diversity algorithms that outperforms all the algorithms tested in this paper. Lastly, we present a new collection management that overcomes the erosion issues observed when using unstructured collections. These three contributions are supported by extensive experimental comparisons of Quality-Diversity algorithms on three different experimental scenarios.\n    ",
        "submission_date": "2017-05-12T00:00:00",
        "last_modified_date": "2017-05-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.09401",
        "title": "Machine Learning Topological Invariants with Neural Networks",
        "authors": [
            "Pengfei Zhang",
            "Huitao Shen",
            "Hui Zhai"
        ],
        "abstract": "In this Letter we supervisedly train neural networks to distinguish different topological phases in the context of topological band insulators. After training with Hamiltonians of one-dimensional insulators with chiral symmetry, the neural network can predict their topological winding numbers with nearly 100% accuracy, even for Hamiltonians with larger winding numbers that are not included in the training data. These results show a remarkable success that the neural network can capture the global and nonlinear topological features of quantum phases from local inputs. By opening up the neural network, we confirm that the network does learn the discrete version of the winding number formula. We also make a couple of remarks regarding the role of the symmetry and the opposite effect of regularization techniques when applying machine learning to physical systems.\n    ",
        "submission_date": "2017-08-30T00:00:00",
        "last_modified_date": "2018-01-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.09427",
        "title": "Deep Learning to Improve Breast Cancer Early Detection on Screening Mammography",
        "authors": [
            "Li Shen",
            "Laurie R. Margolies",
            "Joseph H. Rothstein",
            "Eugene Fluder",
            "Russell B. McBride",
            "Weiva Sieh"
        ],
        "abstract": "The rapid development of deep learning, a family of machine learning techniques, has spurred much interest in its application to medical imaging problems. Here, we develop a deep learning algorithm that can accurately detect breast cancer on screening mammograms using an \"end-to-end\" training approach that efficiently leverages training datasets with either complete clinical annotation or only the cancer status (label) of the whole image. In this approach, lesion annotations are required only in the initial training stage, and subsequent stages require only image-level labels, eliminating the reliance on rarely available lesion annotations. Our all convolutional network method for classifying screening mammograms attained excellent performance in comparison with previous methods. On an independent test set of digitized film mammograms from Digital Database for Screening Mammography (DDSM), the best single model achieved a per-image AUC of 0.88, and four-model averaging improved the AUC to 0.91 (sensitivity: 86.1%, specificity: 80.1%). On a validation set of full-field digital mammography (FFDM) images from the INbreast database, the best single model achieved a per-image AUC of 0.95, and four-model averaging improved the AUC to 0.98 (sensitivity: 86.7%, specificity: 96.1%). We also demonstrate that a whole image classifier trained using our end-to-end approach on the DDSM digitized film mammograms can be transferred to INbreast FFDM images using only a subset of the INbreast data for fine-tuning and without further reliance on the availability of lesion annotations. These findings show that automatic deep learning methods can be readily trained to attain high accuracy on heterogeneous mammography platforms, and hold tremendous promise for improving clinical tools to reduce false positive and false negative screening mammography results.\n    ",
        "submission_date": "2017-08-30T00:00:00",
        "last_modified_date": "2018-12-31T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.09441",
        "title": "Incorporating Feedback into Tree-based Anomaly Detection",
        "authors": [
            "Shubhomoy Das",
            "Weng-Keen Wong",
            "Alan Fern",
            "Thomas G. Dietterich",
            "Md Amran Siddiqui"
        ],
        "abstract": "Anomaly detectors are often used to produce a ranked list of statistical anomalies, which are examined by human analysts in order to extract the actual anomalies of interest. Unfortunately, in realworld applications, this process can be exceedingly difficult for the analyst since a large fraction of high-ranking anomalies are false positives and not interesting from the application perspective. In this paper, we aim to make the analyst's job easier by allowing for analyst feedback during the investigation process. Ideally, the feedback influences the ranking of the anomaly detector in a way that reduces the number of false positives that must be examined before discovering the anomalies of interest. In particular, we introduce a novel technique for incorporating simple binary feedback into tree-based anomaly detectors. We focus on the Isolation Forest algorithm as a representative tree-based anomaly detector, and show that we can significantly improve its performance by incorporating feedback, when compared with the baseline algorithm that does not incorporate feedback. Our technique is simple and scales well as the size of the data increases, which makes it suitable for interactive discovery of anomalies in large datasets.\n    ",
        "submission_date": "2017-08-30T00:00:00",
        "last_modified_date": "2017-08-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.09450",
        "title": "Learning Fine-Grained Knowledge about Contingent Relations between Everyday Events",
        "authors": [
            "Elahe Rahimtoroghi",
            "Ernesto Hernandez",
            "Marilyn A Walker"
        ],
        "abstract": "Much of the user-generated content on social media is provided by ordinary people telling stories about their daily lives. We develop and test a novel method for learning fine-grained common-sense knowledge from these stories about contingent (causal and conditional) relationships between everyday events. This type of knowledge is useful for text and story understanding, information extraction, question answering, and text summarization. We test and compare different methods for learning contingency relation, and compare what is learned from topic-sorted story collections vs. general-domain stories. Our experiments show that using topic-specific datasets enables learning finer-grained knowledge about events and results in significant improvement over the baselines. An evaluation on Amazon Mechanical Turk shows 82% of the relations between events that we learn from topic-sorted stories are judged as contingent.\n    ",
        "submission_date": "2017-08-30T00:00:00",
        "last_modified_date": "2017-08-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1708.09453",
        "title": "Inference of Fine-Grained Event Causality from Blogs and Films",
        "authors": [
            "Zhichao Hu",
            "Elahe Rahimtoroghi",
            "Marilyn A Walker"
        ],
        "abstract": "Human understanding of narrative is mainly driven by reasoning about causal relations between events and thus recognizing them is a key capability for computational models of language understanding. Computational work in this area has approached this via two different routes: by focusing on acquiring a knowledge base of common causal relations between events, or by attempting to understand a particular story or macro-event, along with its storyline. In this position paper, we focus on knowledge acquisition approach and claim that newswire is a relatively poor source for learning fine-grained causal relations between everyday events. We describe experiments using an unsupervised method to learn causal relations between events in the narrative genres of first-person narratives and film scene descriptions. We show that our method learns fine-grained causal relations, judged by humans as likely to be causal over 80% of the time. We also demonstrate that the learned event pairs do not exist in publicly available event-pair datasets extracted from newswire.\n    ",
        "submission_date": "2017-08-30T00:00:00",
        "last_modified_date": "2017-08-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.00023",
        "title": "R$^3$: Reinforced Reader-Ranker for Open-Domain Question Answering",
        "authors": [
            "Shuohang Wang",
            "Mo Yu",
            "Xiaoxiao Guo",
            "Zhiguo Wang",
            "Tim Klinger",
            "Wei Zhang",
            "Shiyu Chang",
            "Gerald Tesauro",
            "Bowen Zhou",
            "Jing Jiang"
        ],
        "abstract": "In recent years researchers have achieved considerable success applying neural network methods to question answering (QA). These approaches have achieved state of the art results in simplified closed-domain settings such as the SQuAD (Rajpurkar et al., 2016) dataset, which provides a pre-selected passage, from which the answer to a given question may be extracted. More recently, researchers have begun to tackle open-domain QA, in which the model is given a question and access to a large corpus (e.g., wikipedia) instead of a pre-selected passage (Chen et al., 2017a). This setting is more complex as it requires large-scale search for relevant passages by an information retrieval component, combined with a reading comprehension model that \"reads\" the passages to generate an answer to the question. Performance in this setting lags considerably behind closed-domain performance. In this paper, we present a novel open-domain QA system called Reinforced Ranker-Reader $(R^3)$, based on two algorithmic innovations. First, we propose a new pipeline for open-domain QA with a Ranker component, which learns to rank retrieved passages in terms of likelihood of generating the ground-truth answer to a given question. Second, we propose a novel method that jointly trains the Ranker along with an answer-generation Reader model, based on reinforcement learning. We report extensive experimental results showing that our method significantly improves on the state of the art for multiple open-domain QA datasets.\n    ",
        "submission_date": "2017-08-31T00:00:00",
        "last_modified_date": "2017-11-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.00084",
        "title": "Behavior Trees in Robotics and AI: An Introduction",
        "authors": [
            "Michele Colledanchise",
            "Petter \u00d6gren"
        ],
        "abstract": "A Behavior Tree (BT) is a way to structure the switching between different tasks in an autonomous agent, such as a robot or a virtual entity in a computer game. BTs are a very efficient way of creating complex systems that are both modular and reactive. These properties are crucial in many applications, which has led to the spread of BT from computer game programming to many branches of AI and Robotics. In this book, we will first give an introduction to BTs, then we describe how BTs relate to, and in many cases generalize, earlier switching structures. These ideas are then used as a foundation for a set of efficient and easy to use design principles. Properties such as safety, robustness, and efficiency are important for an autonomous system, and we describe a set of tools for formally analyzing these using a state space description of BTs. With the new analysis tools, we can formalize the descriptions of how BTs generalize earlier approaches. We also show the use of BTs in automated planning and machine learning. Finally, we describe an extended set of tools to capture the behavior of Stochastic BTs, where the outcomes of actions are described by probabilities. These tools enable the computation of both success probabilities and time to completion.\n    ",
        "submission_date": "2017-08-31T00:00:00",
        "last_modified_date": "2022-10-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.00103",
        "title": "Seq2SQL: Generating Structured Queries from Natural Language using Reinforcement Learning",
        "authors": [
            "Victor Zhong",
            "Caiming Xiong",
            "Richard Socher"
        ],
        "abstract": "A significant amount of the world's knowledge is stored in relational databases. However, the ability for users to retrieve facts from a database is limited due to a lack of understanding of query languages such as SQL. We propose Seq2SQL, a deep neural network for translating natural language questions to corresponding SQL queries. Our model leverages the structure of SQL queries to significantly reduce the output space of generated queries. Moreover, we use rewards from in-the-loop query execution over the database to learn a policy to generate unordered parts of the query, which we show are less suitable for optimization via cross entropy loss. In addition, we will publish WikiSQL, a dataset of 80654 hand-annotated examples of questions and SQL queries distributed across 24241 tables from Wikipedia. This dataset is required to train our model and is an order of magnitude larger than comparable datasets. By applying policy-based reinforcement learning with a query execution environment to WikiSQL, our model Seq2SQL outperforms attentional sequence to sequence models, improving execution accuracy from 35.9% to 59.4% and logical form accuracy from 23.4% to 48.3%.\n    ",
        "submission_date": "2017-08-31T00:00:00",
        "last_modified_date": "2017-11-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.00155",
        "title": "Order-Planning Neural Text Generation From Structured Data",
        "authors": [
            "Lei Sha",
            "Lili Mou",
            "Tianyu Liu",
            "Pascal Poupart",
            "Sujian Li",
            "Baobao Chang",
            "Zhifang Sui"
        ],
        "abstract": "Generating texts from structured data (e.g., a table) is important for various natural language processing tasks such as question answering and dialog systems. In recent studies, researchers use neural language models and encoder-decoder frameworks for table-to-text generation. However, these neural network-based approaches do not model the order of contents during text generation. When a human writes a summary based on a given table, he or she would probably consider the content order before wording. In a biography, for example, the nationality of a person is typically mentioned before occupation in a biography. In this paper, we propose an order-planning text generation model to capture the relationship between different fields and use such relationship to make the generated text more fluent and smooth. We conducted experiments on the WikiBio dataset and achieve significantly higher performance than previous methods in terms of BLEU, ROUGE, and NIST scores.\n    ",
        "submission_date": "2017-09-01T00:00:00",
        "last_modified_date": "2017-09-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.00348",
        "title": "Inferring Networked Device Categories from Low-Level Activity Indicators",
        "authors": [
            "Kyumars Sheykh Esmaili",
            "Jaideep Chandrashekar",
            "Pascal Le Guyadec"
        ],
        "abstract": "We study the problem of inferring the type of a networked device in a home network by leveraging low level traffic activity indicators seen at commodity home gateways. We analyze a dataset of detailed device network activity obtained from 240 subscriber homes of a large European ISP and extract a number of traffic and spatial fingerprints for individual devices. We develop a two level taxonomy to describe devices onto which we map individual devices using a number of heuristics. We leverage the heuristically derived labels to train classifiers that distinguish device classes based on the traffic and spatial fingerprints of a device. Our results show an accuracy level up to 91% for the coarse level category and up to 84% for the fine grained category. By incorporating information from other sources (e.g., MAC OUI), we are able to further improve accuracy to above 97% and 92%, respectively. Finally, we also extract a set of simple and human-readable rules that concisely capture the behaviour of these distinct device categories.\n    ",
        "submission_date": "2017-09-01T00:00:00",
        "last_modified_date": "2017-09-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.00359",
        "title": "Convergence, Continuity and Recurrence in Dynamic Epistemic Logic",
        "authors": [
            "Dominik Klein",
            "Rasmus K. Rendsvig"
        ],
        "abstract": "The paper analyzes dynamic epistemic logic from a topological perspective. The main contribution consists of a framework in which dynamic epistemic logic satisfies the requirements for being a topological dynamical system thus interfacing discrete dynamic logics with continuous mappings of dynamical systems. The setting is based on a notion of logical convergence, demonstratively equivalent with convergence in Stone topology. Presented is a flexible, parametrized family of metrics inducing the latter, used as an analytical aid. We show maps induced by action model transformations continuous with respect to the Stone topology and present results on the recurrent behavior of said maps.\n    ",
        "submission_date": "2017-09-01T00:00:00",
        "last_modified_date": "2017-09-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.00410",
        "title": "Visual art inspired by the collective feeding behavior of sand-bubbler crabs",
        "authors": [
            "Hendrik Richter"
        ],
        "abstract": "Sand--bubblers are crabs of the genera Dotilla and Scopimera which are known to produce remarkable patterns and structures at tropical beaches. From these pattern-making abilities, we may draw inspiration for digital visual art. A simple mathematical model is proposed and an algorithm is designed that may create such sand-bubbler patterns artificially. In addition, design parameters to modify the patterns are identified and analyzed by computational aesthetic measures. Finally, an extension of the algorithm is discussed that may enable controlling and guiding generative evolution of the art-making process.\n    ",
        "submission_date": "2017-09-01T00:00:00",
        "last_modified_date": "2018-01-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.00503",
        "title": "Mean Actor Critic",
        "authors": [
            "Cameron Allen",
            "Kavosh Asadi",
            "Melrose Roderick",
            "Abdel-rahman Mohamed",
            "George Konidaris",
            "Michael Littman"
        ],
        "abstract": "We propose a new algorithm, Mean Actor-Critic (MAC), for discrete-action continuous-state reinforcement learning. MAC is a policy gradient algorithm that uses the agent's explicit representation of all action values to estimate the gradient of the policy, rather than using only the actions that were actually executed. We prove that this approach reduces variance in the policy gradient estimate relative to traditional actor-critic methods. We show empirical results on two control domains and on six Atari games, where MAC is competitive with state-of-the-art policy search algorithms.\n    ",
        "submission_date": "2017-09-01T00:00:00",
        "last_modified_date": "2018-05-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.00513",
        "title": "Training Shallow and Thin Networks for Acceleration via Knowledge Distillation with Conditional Adversarial Networks",
        "authors": [
            "Zheng Xu",
            "Yen-Chang Hsu",
            "Jiawei Huang"
        ],
        "abstract": "There is an increasing interest on accelerating neural networks for real-time applications. We study the student-teacher strategy, in which a small and fast student network is trained with the auxiliary information learned from a large and accurate teacher network. We propose to use conditional adversarial networks to learn the loss function to transfer knowledge from teacher to student. The proposed method is particularly effective for relatively small student networks. Moreover, experimental results show the effect of network size when the modern networks are used as student. We empirically study the trade-off between inference time and classification accuracy, and provide suggestions on choosing a proper student network.\n    ",
        "submission_date": "2017-09-02T00:00:00",
        "last_modified_date": "2018-04-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.00572",
        "title": "XFlow: Cross-modal Deep Neural Networks for Audiovisual Classification",
        "authors": [
            "C\u0103t\u0103lina Cangea",
            "Petar Veli\u010dkovi\u0107",
            "Pietro Li\u00f2"
        ],
        "abstract": "In recent years, there have been numerous developments towards solving multimodal tasks, aiming to learn a stronger representation than through a single modality. Certain aspects of the data can be particularly useful in this case - for example, correlations in the space or time domain across modalities - but should be wisely exploited in order to benefit from their full predictive potential. We propose two deep learning architectures with multimodal cross-connections that allow for dataflow between several feature extractors (XFlow). Our models derive more interpretable features and achieve better performances than models which do not exchange representations, usefully exploiting correlations between audio and visual data, which have a different dimensionality and are nontrivially exchangeable. Our work improves on existing multimodal deep learning algorithms in two essential ways: (1) it presents a novel method for performing cross-modality (before features are learned from individual modalities) and (2) extends the previously proposed cross-connections which only transfer information between streams that process compatible data. Illustrating some of the representations learned by the connections, we analyse their contribution to the increase in discrimination ability and reveal their compatibility with a lip-reading network intermediate representation. We provide the research community with Digits, a new dataset consisting of three data types extracted from videos of people saying the digits 0-9. Results show that both cross-modal architectures outperform their baselines (by up to 11.5%) when evaluated on the AVletters, CUAVE and Digits datasets, achieving state-of-the-art results.\n    ",
        "submission_date": "2017-09-02T00:00:00",
        "last_modified_date": "2019-04-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.00653",
        "title": "From Query-By-Keyword to Query-By-Example: LinkedIn Talent Search Approach",
        "authors": [
            "Viet Ha-Thuc",
            "Yan Yan",
            "Xianren Wu",
            "Vijay Dialani",
            "Abhishek Gupta",
            "Shakti Sinha"
        ],
        "abstract": "One key challenge in talent search is to translate complex criteria of a hiring position into a search query, while it is relatively easy for a searcher to list examples of suitable candidates for a given position. To improve search efficiency, we propose the next generation of talent search at LinkedIn, also referred to as Search By Ideal Candidates. In this system, a searcher provides one or several ideal candidates as the input to hire for a given position. The system then generates a query based on the ideal candidates and uses it to retrieve and rank results. Shifting from the traditional Query-By-Keyword to this new Query-By-Example system poses a number of challenges: How to generate a query that best describes the candidates? When moving to a completely different paradigm, how does one leverage previous product logs to learn ranking models and/or evaluate the new system with no existing usage logs? Finally, given the different nature between the two search paradigms, the ranking features typically used for Query-By-Keyword systems might not be optimal for Query-By-Example. This paper describes our approach to solving these challenges. We present experimental results confirming the effectiveness of the proposed solution, particularly on query building and search ranking tasks. As of writing this paper, the new system has been available to all LinkedIn members.\n    ",
        "submission_date": "2017-09-03T00:00:00",
        "last_modified_date": "2017-09-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.00668",
        "title": "SamBaTen: Sampling-based Batch Incremental Tensor Decomposition",
        "authors": [
            "Ekta Gujral",
            "Ravdeep Pasricha",
            "Evangelos E. Papalexakis"
        ],
        "abstract": "Tensor decompositions are invaluable tools in analyzing multimodal datasets. In many real-world scenarios, such datasets are far from being static, to the contrary they tend to grow over time. For instance, in an online social network setting, as we observe new interactions over time, our dataset gets updated in its \"time\" mode. How can we maintain a valid and accurate tensor decomposition of such a dynamically evolving multimodal dataset, without having to re-compute the entire decomposition after every single update? In this paper we introduce SaMbaTen, a Sampling-based Batch Incremental Tensor Decomposition algorithm, which incrementally maintains the decomposition given new updates to the tensor dataset. SaMbaTen is able to scale to datasets that the state-of-the-art in incremental tensor decomposition is unable to operate on, due to its ability to effectively summarize the existing tensor and the incoming updates, and perform all computations in the reduced summary space. We extensively evaluate SaMbaTen using synthetic and real datasets. Indicatively, SaMbaTen achieves comparable accuracy to state-of-the-art incremental and non-incremental techniques, while being 25-30 times faster. Furthermore, SaMbaTen scales to very large sparse and dense dynamically evolving tensors of dimensions up to 100K x 100K x 100K where state-of-the-art incremental approaches were not able to operate.\n    ",
        "submission_date": "2017-09-03T00:00:00",
        "last_modified_date": "2017-09-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.00744",
        "title": "An Improved Algorithm for E-Generalization",
        "authors": [
            "Jochen Burghardt"
        ],
        "abstract": "E-generalization computes common generalizations of given ground terms w.r.t. a given equational background theory E. In 2005 [",
        "submission_date": "2017-09-03T00:00:00",
        "last_modified_date": "2017-09-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.00928",
        "title": "Automation of Android Applications Testing Using Machine Learning Activities Classification",
        "authors": [
            "Ariel Rosenfeld",
            "Odaya Kardashov",
            "Orel Zang"
        ],
        "abstract": "Mobile applications are being used every day by more than half of the world's population to perform a great variety of tasks. With the increasingly widespread usage of these applications, the need arises for efficient techniques to test them. Many frameworks allow automating the process of application testing, however existing frameworks mainly rely on the application developer for providing testing scripts for each developed application, thus preventing reuse of these tests for similar applications. In this paper, we present a novel approach for the automation of testing Android applications by leveraging machine learning techniques and reusing popular test scenarios. We discuss and demonstrate the potential benefits of our approach in an empirical study where we show that our developed testing tool, based on the proposed approach, outperforms standard methods in realistic settings.\n    ",
        "submission_date": "2017-09-04T00:00:00",
        "last_modified_date": "2017-09-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.01070",
        "title": "Maintaining Ad-Hoc Communication Network in Area Protection Scenarios with Adversarial Agents",
        "authors": [
            "Marika Ivanov\u00e1",
            "Pavel Surynek",
            "Diep Thi Ngoc Nguyen"
        ],
        "abstract": "We address a problem of area protection in graph-based scenarios with multiple mobile agents where connectivity is maintained among agents to ensure they can communicate. The problem consists of two adversarial teams of agents that move in an undirected graph shared by both teams. Agents are placed in vertices of the graph; at most one agent can occupy a vertex; and they can move into adjacent vertices in a conflict free way. Teams have asymmetric goals: the aim of one team - attackers - is to invade into given area while the aim of the opponent team - defenders - is to protect the area from being entered by attackers by occupying selected vertices. The team of defenders need to maintain connectivity of vertices occupied by its own agents in a visibility graph. The visibility graph models possibility of communication between pairs of vertices.\n",
        "submission_date": "2017-09-04T00:00:00",
        "last_modified_date": "2017-09-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.01215",
        "title": "ALICE: Towards Understanding Adversarial Learning for Joint Distribution Matching",
        "authors": [
            "Chunyuan Li",
            "Hao Liu",
            "Changyou Chen",
            "Yunchen Pu",
            "Liqun Chen",
            "Ricardo Henao",
            "Lawrence Carin"
        ],
        "abstract": "We investigate the non-identifiability issues associated with bidirectional adversarial training for joint distribution matching. Within a framework of conditional entropy, we propose both adversarial and non-adversarial approaches to learn desirable matched joint distributions for unsupervised and supervised tasks. We unify a broad family of adversarial models as joint distribution matching problems. Our approach stabilizes learning of unsupervised bidirectional adversarial learning methods. Further, we introduce an extension for semi-supervised learning tasks. Theoretical results are validated in synthetic data and real-world applications.\n    ",
        "submission_date": "2017-09-05T00:00:00",
        "last_modified_date": "2017-11-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.01366",
        "title": "Speeding-up the decision making of a learning agent using an ion trap quantum processor",
        "authors": [
            "Theeraphot Sriarunothai",
            "Sabine W\u00f6lk",
            "Gouri Shankar Giri",
            "Nicolai Friis",
            "Vedran Dunjko",
            "Hans J. Briegel",
            "Christof Wunderlich"
        ],
        "abstract": "We report a proof-of-principle experimental demonstration of the quantum speed-up for learning agents utilizing a small-scale quantum information processor based on radiofrequency-driven trapped ions. The decision-making process of a quantum learning agent within the projective simulation paradigm for machine learning is implemented in a system of two qubits. The latter are realized using hyperfine states of two frequency-addressed atomic ions exposed to a static magnetic field gradient. We show that the deliberation time of this quantum learning agent is quadratically improved with respect to comparable classical learning agents. The performance of this quantum-enhanced learning agent highlights the potential of scalable quantum processors taking advantage of machine learning.\n    ",
        "submission_date": "2017-09-05T00:00:00",
        "last_modified_date": "2018-12-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.01434",
        "title": "A Generic Approach for Escaping Saddle points",
        "authors": [
            "Sashank J Reddi",
            "Manzil Zaheer",
            "Suvrit Sra",
            "Barnabas Poczos",
            "Francis Bach",
            "Ruslan Salakhutdinov",
            "Alexander J Smola"
        ],
        "abstract": "A central challenge to using first-order methods for optimizing nonconvex problems is the presence of saddle points. First-order methods often get stuck at saddle points, greatly deteriorating their performance. Typically, to escape from saddles one has to use second-order methods. However, most works on second-order methods rely extensively on expensive Hessian-based computations, making them impractical in large-scale settings. To tackle this challenge, we introduce a generic framework that minimizes Hessian based computations while at the same time provably converging to second-order critical points. Our framework carefully alternates between a first-order and a second-order subroutine, using the latter only close to saddle points, and yields convergence results competitive to the state-of-the-art. Empirical results suggest that our strategy also enjoys a good practical performance.\n    ",
        "submission_date": "2017-09-05T00:00:00",
        "last_modified_date": "2017-09-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.01476",
        "title": "Fine-tuning deep CNN models on specific MS COCO categories",
        "authors": [
            "Daniel Sonntag",
            "Michael Barz",
            "Jan Zacharias",
            "Sven Stauden",
            "Vahid Rahmani",
            "\u00c1ron F\u00f3thi",
            "Andr\u00e1s L\u0151rincz"
        ],
        "abstract": "Fine-tuning of a deep convolutional neural network (CNN) is often desired. This paper provides an overview of our publicly available py-faster-rcnn-ft software library that can be used to fine-tune the VGG_CNN_M_1024 model on custom subsets of the Microsoft Common Objects in Context (MS COCO) dataset. For example, we improved the procedure so that the user does not have to look for suitable image files in the dataset by hand which can then be used in the demo program. Our implementation randomly selects images that contain at least one object of the categories on which the model is fine-tuned.\n    ",
        "submission_date": "2017-09-05T00:00:00",
        "last_modified_date": "2017-09-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.01509",
        "title": "Linking Generative Adversarial Learning and Binary Classification",
        "authors": [
            "Akshay Balsubramani"
        ],
        "abstract": "In this note, we point out a basic link between generative adversarial (GA) training and binary classification -- any powerful discriminator essentially computes an (f-)divergence between real and generated samples. The result, repeatedly re-derived in decision theory, has implications for GA Networks (GANs), providing an alternative perspective on training f-GANs by designing the discriminator loss function.\n    ",
        "submission_date": "2017-09-05T00:00:00",
        "last_modified_date": "2017-09-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.01532",
        "title": "Interacting Attention-gated Recurrent Networks for Recommendation",
        "authors": [
            "Wenjie Pei",
            "Jie Yang",
            "Zhu Sun",
            "Jie Zhang",
            "Alessandro Bozzon",
            "David M.J. Tax"
        ],
        "abstract": "Capturing the temporal dynamics of user preferences over items is important for recommendation. Existing methods mainly assume that all time steps in user-item interaction history are equally relevant to recommendation, which however does not apply in real-world scenarios where user-item interactions can often happen accidentally. More importantly, they learn user and item dynamics separately, thus failing to capture their joint effects on user-item interactions. To better model user and item dynamics, we present the Interacting Attention-gated Recurrent Network (IARN) which adopts the attention model to measure the relevance of each time step. In particular, we propose a novel attention scheme to learn the attention scores of user and item history in an interacting way, thus to account for the dependencies between user and item dynamics in shaping user-item interactions. By doing so, IARN can selectively memorize different time steps of a user's history when predicting her preferences over different items. Our model can therefore provide meaningful interpretations for recommendation results, which could be further enhanced by auxiliary features. Extensive validation on real-world datasets shows that IARN consistently outperforms state-of-the-art methods.\n    ",
        "submission_date": "2017-09-05T00:00:00",
        "last_modified_date": "2017-09-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.01610",
        "title": "A second order primal-dual method for nonsmooth convex composite optimization",
        "authors": [
            "Neil K. Dhingra",
            "Sei Zhen Khong",
            "Mihailo R. Jovanovi\u0107"
        ],
        "abstract": "We develop a second order primal-dual method for optimization problems in which the objective function is given by the sum of a strongly convex twice differentiable term and a possibly nondifferentiable convex regularizer. After introducing an auxiliary variable, we utilize the proximal operator of the nonsmooth regularizer to transform the associated augmented Lagrangian into a function that is once, but not twice, continuously differentiable. The saddle point of this function corresponds to the solution of the original optimization problem. We employ a generalization of the Hessian to define second order updates on this function and prove global exponential stability of the corresponding differential inclusion. Furthermore, we develop a globally convergent customized algorithm that utilizes the primal-dual augmented Lagrangian as a merit function. We show that the search direction can be computed efficiently and prove quadratic/superlinear asymptotic convergence. We use the $\\ell_1$-regularized model predictive control problem and the problem of designing a distributed controller for a spatially-invariant system to demonstrate the merits and the effectiveness of our method.\n    ",
        "submission_date": "2017-09-05T00:00:00",
        "last_modified_date": "2020-08-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.01613",
        "title": "Machine Learning and Social Robotics for Detecting Early Signs of Dementia",
        "authors": [
            "Patrik Jonell",
            "Joseph Mendelson",
            "Thomas Storskog",
            "Goran Hagman",
            "Per Ostberg",
            "Iolanda Leite",
            "Taras Kucherenko",
            "Olga Mikheeva",
            "Ulrika Akenine",
            "Vesna Jelic",
            "Alina Solomon",
            "Jonas Beskow",
            "Joakim Gustafson",
            "Miia Kivipelto",
            "Hedvig Kjellstrom"
        ],
        "abstract": "This paper presents the EACare project, an ambitious multi-disciplinary collaboration with the aim to develop an embodied system, capable of carrying out neuropsychological tests to detect early signs of dementia, e.g., due to Alzheimer's disease. The system will use methods from Machine Learning and Social Robotics, and be trained with examples of recorded clinician-patient interactions. The interaction will be developed using a participatory design approach. We describe the scope and method of the project, and report on a first Wizard of Oz prototype.\n    ",
        "submission_date": "2017-09-05T00:00:00",
        "last_modified_date": "2017-09-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.01887",
        "title": "Measuring the Similarity of Sentential Arguments in Dialog",
        "authors": [
            "Amita Misra",
            "Brian Ecker",
            "Marilyn A. Walker"
        ],
        "abstract": "When people converse about social or political topics, similar arguments are often paraphrased by different speakers, across many different conversations. Debate websites produce curated summaries of arguments on such topics; these summaries typically consist of lists of sentences that represent frequently paraphrased propositions, or labels capturing the essence of one particular aspect of an argument, e.g. Morality or Second Amendment. We call these frequently paraphrased propositions ARGUMENT FACETS. Like these curated sites, our goal is to induce and identify argument facets across multiple conversations, and produce summaries. However, we aim to do this automatically. We frame the problem as consisting of two steps: we first extract sentences that express an argument from raw social media dialogs, and then rank the extracted arguments in terms of their similarity to one another. Sets of similar arguments are used to represent argument facets. We show here that we can predict ARGUMENT FACET SIMILARITY with a correlation averaging 0.63 compared to a human topline averaging 0.68 over three debate topics, easily beating several reasonable baselines.\n    ",
        "submission_date": "2017-09-06T00:00:00",
        "last_modified_date": "2017-09-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.01915",
        "title": "Towards Neural Machine Translation with Latent Tree Attention",
        "authors": [
            "James Bradbury",
            "Richard Socher"
        ],
        "abstract": "Building models that take advantage of the hierarchical structure of language without a priori annotation is a longstanding goal in natural language processing. We introduce such a model for the task of machine translation, pairing a recurrent neural network grammar encoder with a novel attentional RNNG decoder and applying policy gradient reinforcement learning to induce unsupervised tree structures on both the source and target. When trained on character-level datasets with no explicit segmentation or parse annotation, the model learns a plausible segmentation and shallow parse, obtaining performance close to an attentional baseline.\n    ",
        "submission_date": "2017-09-06T00:00:00",
        "last_modified_date": "2017-09-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.02023",
        "title": "CausalGAN: Learning Causal Implicit Generative Models with Adversarial Training",
        "authors": [
            "Murat Kocaoglu",
            "Christopher Snyder",
            "Alexandros G. Dimakis",
            "Sriram Vishwanath"
        ],
        "abstract": "We propose an adversarial training procedure for learning a causal implicit generative model for a given causal graph. We show that adversarial training can be used to learn a generative model with true observational and interventional distributions if the generator architecture is consistent with the given causal graph. We consider the application of generating faces based on given binary labels where the dependency structure between the labels is preserved with a causal graph. This problem can be seen as learning a causal implicit generative model for the image and labels. We devise a two-stage procedure for this problem. First we train a causal implicit generative model over binary labels using a neural network consistent with a causal graph as the generator. We empirically show that WassersteinGAN can be used to output discrete labels. Later, we propose two new conditional GAN architectures, which we call CausalGAN and CausalBEGAN. We show that the optimal generator of the CausalGAN, given the labels, samples from the image distributions conditioned on these labels. The conditional GAN combined with a trained causal implicit generative model for the labels is then a causal implicit generative model over the labels and the generated image. We show that the proposed architectures can be used to sample from observational and interventional image distributions, even for interventions which do not naturally occur in the dataset.\n    ",
        "submission_date": "2017-09-06T00:00:00",
        "last_modified_date": "2017-09-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.02066",
        "title": "Formulation of Deep Reinforcement Learning Architecture Toward Autonomous Driving for On-Ramp Merge",
        "authors": [
            "Pin Wang",
            "Ching-Yao Chan"
        ],
        "abstract": "Multiple automakers have in development or in production automated driving systems (ADS) that offer freeway-pilot functions. This type of ADS is typically limited to restricted-access freeways only, that is, the transition from manual to automated modes takes place only after the ramp merging process is completed manually. One major challenge to extend the automation to ramp merging is that the automated vehicle needs to incorporate and optimize long-term objectives (e.g. successful and smooth merge) when near-term actions must be safely executed. Moreover, the merging process involves interactions with other vehicles whose behaviors are sometimes hard to predict but may influence the merging vehicle optimal actions. To tackle such a complicated control problem, we propose to apply Deep Reinforcement Learning (DRL) techniques for finding an optimal driving policy by maximizing the long-term reward in an interactive environment. Specifically, we apply a Long Short-Term Memory (LSTM) architecture to model the interactive environment, from which an internal state containing historical driving information is conveyed to a Deep Q-Network (DQN). The DQN is used to approximate the Q-function, which takes the internal state as input and generates Q-values as output for action selection. With this DRL architecture, the historical impact of interactive environment on the long-term reward can be captured and taken into account for deciding the optimal control policy. The proposed architecture has the potential to be extended and applied to other autonomous driving scenarios such as driving through a complex intersection or changing lanes under varying traffic flow conditions.\n    ",
        "submission_date": "2017-09-07T00:00:00",
        "last_modified_date": "2019-02-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.02126",
        "title": "Proceedings First Workshop on Formal Verification of Autonomous Vehicles",
        "authors": [
            "Lukas Bulwahn",
            "Maryam Kamali",
            "Sven Linker"
        ],
        "abstract": "These are the proceedings of the workshop on Formal Verification of Autonomous Vehicles, held on September 19th, 2017 in Turin, Italy, as an affiliated workshop of the International Conference on integrated Formal Methods (iFM 2017). The workshop aim is to bring together researchers from the formal verification community that are developing formal methods for autonomous vehicles as well as researchers working, e.g., in the area of control theory or robotics, interested in applying verification techniques for designing and developing of autonomous vehicles.\n    ",
        "submission_date": "2017-09-07T00:00:00",
        "last_modified_date": "2017-09-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.02169",
        "title": "Bayesian Optimisation for Safe Navigation under Localisation Uncertainty",
        "authors": [
            "Rafael Oliveira",
            "Lionel Ott",
            "Vitor Guizilini",
            "Fabio Ramos"
        ],
        "abstract": "In outdoor environments, mobile robots are required to navigate through terrain with varying characteristics, some of which might significantly affect the integrity of the platform. Ideally, the robot should be able to identify areas that are safe for navigation based on its own percepts about the environment while avoiding damage to itself. Bayesian optimisation (BO) has been successfully applied to the task of learning a model of terrain traversability while guiding the robot through more traversable areas. An issue, however, is that localisation uncertainty can end up guiding the robot to unsafe areas and distort the model being learnt. In this paper, we address this problem and present a novel method that allows BO to consider localisation uncertainty by applying a Gaussian process model for uncertain inputs as a prior. We evaluate the proposed method in simulation and in experiments with a real robot navigating over rough terrain and compare it against standard BO methods.\n    ",
        "submission_date": "2017-09-07T00:00:00",
        "last_modified_date": "2018-02-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.02249",
        "title": "Uncertainty-Aware Learning from Demonstration using Mixture Density Networks with Sampling-Free Variance Modeling",
        "authors": [
            "Sungjoon Choi",
            "Kyungjae Lee",
            "Sungbin Lim",
            "Songhwai Oh"
        ],
        "abstract": "In this paper, we propose an uncertainty-aware learning from demonstration method by presenting a novel uncertainty estimation method utilizing a mixture density network appropriate for modeling complex and noisy human behaviors. The proposed uncertainty acquisition can be done with a single forward path without Monte Carlo sampling and is suitable for real-time robotics applications. The properties of the proposed uncertainty measure are analyzed through three different synthetic examples, absence of data, heavy measurement noise, and composition of functions scenarios. We show that each case can be distinguished using the proposed uncertainty measure and presented an uncertainty-aware learn- ing from demonstration method of an autonomous driving using this property. The proposed uncertainty-aware learning from demonstration method outperforms other compared methods in terms of safety using a complex real-world driving dataset.\n    ",
        "submission_date": "2017-09-03T00:00:00",
        "last_modified_date": "2017-09-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.02314",
        "title": "Answering Visual-Relational Queries in Web-Extracted Knowledge Graphs",
        "authors": [
            "Daniel O\u00f1oro-Rubio",
            "Mathias Niepert",
            "Alberto Garc\u00eda-Dur\u00e1n",
            "Roberto Gonz\u00e1lez",
            "Roberto J. L\u00f3pez-Sastre"
        ],
        "abstract": "A visual-relational knowledge graph (KG) is a multi-relational graph whose entities are associated with images. We explore novel machine learning approaches for answering visual-relational queries in web-extracted knowledge graphs. To this end, we have created ImageGraph, a KG with 1,330 relation types, 14,870 entities, and 829,931 images crawled from the web. With visual-relational KGs such as ImageGraph one can introduce novel probabilistic query types in which images are treated as first-class citizens. Both the prediction of relations between unseen images as well as multi-relational image retrieval can be expressed with specific families of visual-relational queries. We introduce novel combinations of convolutional networks and knowledge graph embedding methods to answer such queries. We also explore a zero-shot learning scenario where an image of an entirely new entity is linked with multiple relations to entities of an existing KG. The resulting multi-relational grounding of unseen entity images into a knowledge graph serves as a semantic entity representation. We conduct experiments to demonstrate that the proposed methods can answer these visual-relational queries efficiently and accurately.\n    ",
        "submission_date": "2017-09-07T00:00:00",
        "last_modified_date": "2019-05-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.02349",
        "title": "A Deep Reinforcement Learning Chatbot",
        "authors": [
            "Iulian V. Serban",
            "Chinnadhurai Sankar",
            "Mathieu Germain",
            "Saizheng Zhang",
            "Zhouhan Lin",
            "Sandeep Subramanian",
            "Taesup Kim",
            "Michael Pieper",
            "Sarath Chandar",
            "Nan Rosemary Ke",
            "Sai Rajeshwar",
            "Alexandre de Brebisson",
            "Jose M. R. Sotelo",
            "Dendi Suhubdy",
            "Vincent Michalski",
            "Alexandre Nguyen",
            "Joelle Pineau",
            "Yoshua Bengio"
        ],
        "abstract": "We present MILABOT: a deep reinforcement learning chatbot developed by the Montreal Institute for Learning Algorithms (MILA) for the Amazon Alexa Prize competition. MILABOT is capable of conversing with humans on popular small talk topics through both speech and text. The system consists of an ensemble of natural language generation and retrieval models, including template-based models, bag-of-words models, sequence-to-sequence neural network and latent variable neural network models. By applying reinforcement learning to crowdsourced data and real-world user interactions, the system has been trained to select an appropriate response from the models in its ensemble. The system has been evaluated through A/B testing with real-world users, where it performed significantly better than many competing systems. Due to its machine learning architecture, the system is likely to improve with additional data.\n    ",
        "submission_date": "2017-09-07T00:00:00",
        "last_modified_date": "2017-11-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.02477",
        "title": "Inferring Generative Model Structure with Static Analysis",
        "authors": [
            "Paroma Varma",
            "Bryan He",
            "Payal Bajaj",
            "Imon Banerjee",
            "Nishith Khandwala",
            "Daniel L. Rubin",
            "Christopher R\u00e9"
        ],
        "abstract": "Obtaining enough labeled data to robustly train complex discriminative models is a major bottleneck in the machine learning pipeline. A popular solution is combining multiple sources of weak supervision using generative models. The structure of these models affects training label quality, but is difficult to learn without any ground truth labels. We instead rely on these weak supervision sources having some structure by virtue of being encoded programmatically. We present Coral, a paradigm that infers generative model structure by statically analyzing the code for these heuristics, thus reducing the data required to learn structure significantly. We prove that Coral's sample complexity scales quasilinearly with the number of heuristics and number of relations found, improving over the standard sample complexity, which is exponential in $n$ for identifying $n^{\\textrm{th}}$ degree relations. Experimentally, Coral matches or outperforms traditional structure learning approaches by up to 3.81 F1 points. Using Coral to model dependencies instead of assuming independence results in better performance than a fully supervised model by 3.07 accuracy points when heuristics are used to label radiology data without ground truth labels.\n    ",
        "submission_date": "2017-09-07T00:00:00",
        "last_modified_date": "2017-09-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.02513",
        "title": "Intelligent Subset Selection of Power Generators for Economic Dispatch",
        "authors": [
            "Biswarup Bhattacharya",
            "Abhishek Sinha"
        ],
        "abstract": "Sustainable and economical generation of electrical power is an essential and mandatory component of infrastructure in today's world. Optimal generation (generator subset selection) of power requires a careful evaluation of various factors like type of source, generation, transmission & storage capacities, congestion among others which makes this a difficult task. We created a grid to simulate various conditions including stimuli like generator supply, weather and load demand using Siemens PSS/E software and this data is trained using deep learning methods and subsequently tested. The results are highly encouraging. As per our knowledge, this is the first paper to propose a working and scalable deep learning model for this problem.\n    ",
        "submission_date": "2017-09-08T00:00:00",
        "last_modified_date": "2017-09-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.02555",
        "title": "Causality-Aided Falsification",
        "authors": [
            "Takumi Akazaki",
            "Yoshihiro Kumazawa",
            "Ichiro Hasuo"
        ],
        "abstract": "Falsification is drawing attention in quality assurance of heterogeneous systems whose complexities are beyond most verification techniques' scalability. In this paper we introduce the idea of causality aid in falsification: by providing a falsification solver -- that relies on stochastic optimization of a certain cost function -- with suitable causal information expressed by a Bayesian network, search for a falsifying input value can be efficient. Our experiment results show the idea's viability.\n    ",
        "submission_date": "2017-09-08T00:00:00",
        "last_modified_date": "2017-09-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.02779",
        "title": "Machine learning \\& artificial intelligence in the quantum domain",
        "authors": [
            "Vedran Dunjko",
            "Hans J. Briegel"
        ],
        "abstract": "Quantum information technologies, and intelligent learning systems, are both emergent technologies that will likely have a transforming impact on our society. The respective underlying fields of research -- quantum information (QI) versus machine learning (ML) and artificial intelligence (AI) -- have their own specific challenges, which have hitherto been investigated largely independently. However, in a growing body of recent work, researchers have been probing the question to what extent these fields can learn and benefit from each other. QML explores the interaction between quantum computing and ML, investigating how results and techniques from one field can be used to solve the problems of the other. Recently, we have witnessed breakthroughs in both directions of influence. For instance, quantum computing is finding a vital application in providing speed-ups in ML, critical in our \"big data\" world. Conversely, ML already permeates cutting-edge technologies, and may become instrumental in advanced quantum technologies. Aside from quantum speed-up in data analysis, or classical ML optimization used in quantum experiments, quantum enhancements have also been demonstrated for interactive learning, highlighting the potential of quantum-enhanced learning agents. Finally, works exploring the use of AI for the very design of quantum experiments, and for performing parts of genuine research autonomously, have reported their first successes. Beyond the topics of mutual enhancement, researchers have also broached the fundamental issue of quantum generalizations of ML/AI concepts. This deals with questions of the very meaning of learning and intelligence in a world that is described by quantum mechanics. In this review, we describe the main ideas, recent developments, and progress in a broad spectrum of research investigating machine learning and artificial intelligence in the quantum domain.\n    ",
        "submission_date": "2017-09-08T00:00:00",
        "last_modified_date": "2017-09-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.02877",
        "title": "Variable Annealing Length and Parallelism in Simulated Annealing",
        "authors": [
            "Vincent A. Cicirello"
        ],
        "abstract": "In this paper, we propose: (a) a restart schedule for an adaptive simulated annealer, and (b) parallel simulated annealing, with an adaptive and parameter-free annealing schedule. The foundation of our approach is the Modified Lam annealing schedule, which adaptively controls the temperature parameter to track a theoretically ideal rate of acceptance of neighboring states. A sequential implementation of Modified Lam simulated annealing is almost parameter-free. However, it requires prior knowledge of the annealing length. We eliminate this parameter using restarts, with an exponentially increasing schedule of annealing lengths. We then extend this restart schedule to parallel implementation, executing several Modified Lam simulated annealers in parallel, with varying initial annealing lengths, and our proposed parallel annealing length schedule. To validate our approach, we conduct experiments on an NP-Hard scheduling problem with sequence-dependent setup constraints. We compare our approach to fixed length restarts, both sequentially and in parallel. Our results show that our approach can achieve substantial performance gains, throughout the course of the run, demonstrating our approach to be an effective anytime algorithm.\n    ",
        "submission_date": "2017-09-08T00:00:00",
        "last_modified_date": "2017-09-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.02878",
        "title": "TensorFlow Agents: Efficient Batched Reinforcement Learning in TensorFlow",
        "authors": [
            "Danijar Hafner",
            "James Davidson",
            "Vincent Vanhoucke"
        ],
        "abstract": "We introduce TensorFlow Agents, an efficient infrastructure paradigm for building parallel reinforcement learning algorithms in TensorFlow. We simulate multiple environments in parallel, and group them to perform the neural network computation on a batch rather than individual observations. This allows the TensorFlow execution engine to parallelize computation, without the need for manual synchronization. Environments are stepped in separate Python processes to progress them in parallel without interference of the global interpreter lock. As part of this project, we introduce BatchPPO, an efficient implementation of the proximal policy optimization algorithm. By open sourcing TensorFlow Agents, we hope to provide a flexible starting point for future projects that accelerates future research in the field.\n    ",
        "submission_date": "2017-09-08T00:00:00",
        "last_modified_date": "2018-10-31T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.03008",
        "title": "Identifying Irregular Power Usage by Turning Predictions into Holographic Spatial Visualizations",
        "authors": [
            "Patrick Glauner",
            "Niklas Dahringer",
            "Oleksandr Puhachov",
            "Jorge Augusto Meira",
            "Petko Valtchev",
            "Radu State",
            "Diogo Duarte"
        ],
        "abstract": "Power grids are critical infrastructure assets that face non-technical losses (NTL) such as electricity theft or faulty meters. NTL may range up to 40% of the total electricity distributed in emerging countries. Industrial NTL detection systems are still largely based on expert knowledge when deciding whether to carry out costly on-site inspections of customers. Electricity providers are reluctant to move to large-scale deployments of automated systems that learn NTL profiles from data due to the latter's propensity to suggest a large number of unnecessary inspections. In this paper, we propose a novel system that combines automated statistical decision making with expert knowledge. First, we propose a machine learning framework that classifies customers into NTL or non-NTL using a variety of features derived from the customers' consumption data. The methodology used is specifically tailored to the level of noise in the data. Second, in order to allow human experts to feed their knowledge in the decision loop, we propose a method for visualizing prediction results at various granularity levels in a spatial hologram. Our approach allows domain experts to put the classification results into the context of the data and to incorporate their knowledge for making the final decisions of which customers to inspect. This work has resulted in appreciable results on a real-world data set of 3.6M customers. Our system is being deployed in a commercial NTL detection software.\n    ",
        "submission_date": "2017-09-09T00:00:00",
        "last_modified_date": "2017-09-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.03126",
        "title": "Robust Emotion Recognition from Low Quality and Low Bit Rate Video: A Deep Learning Approach",
        "authors": [
            "Bowen Cheng",
            "Zhangyang Wang",
            "Zhaobin Zhang",
            "Zhu Li",
            "Ding Liu",
            "Jianchao Yang",
            "Shuai Huang",
            "Thomas S. Huang"
        ],
        "abstract": "Emotion recognition from facial expressions is tremendously useful, especially when coupled with smart devices and wireless multimedia applications. However, the inadequate network bandwidth often limits the spatial resolution of the transmitted video, which will heavily degrade the recognition reliability. We develop a novel framework to achieve robust emotion recognition from low bit rate video. While video frames are downsampled at the encoder side, the decoder is embedded with a deep network model for joint super-resolution (SR) and recognition. Notably, we propose a novel max-mix training strategy, leading to a single \"One-for-All\" model that is remarkably robust to a vast range of downsampling factors. That makes our framework well adapted for the varied bandwidths in real transmission scenarios, without hampering scalability or efficiency. The proposed framework is evaluated on the AVEC 2016 benchmark, and demonstrates significantly improved stand-alone recognition performance, as well as rate-distortion (R-D) performance, than either directly recognizing from LR frames, or separating SR and recognition.\n    ",
        "submission_date": "2017-09-10T00:00:00",
        "last_modified_date": "2017-09-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.03153",
        "title": "MBMF: Model-Based Priors for Model-Free Reinforcement Learning",
        "authors": [
            "Somil Bansal",
            "Roberto Calandra",
            "Kurtland Chua",
            "Sergey Levine",
            "Claire Tomlin"
        ],
        "abstract": "Reinforcement Learning is divided in two main paradigms: model-free and model-based. Each of these two paradigms has strengths and limitations, and has been successfully applied to real world domains that are appropriate to its corresponding strengths. In this paper, we present a new approach aimed at bridging the gap between these two paradigms. We aim to take the best of the two paradigms and combine them in an approach that is at the same time data-efficient and cost-savvy. We do so by learning a probabilistic dynamics model and leveraging it as a prior for the intertwined model-free optimization. As a result, our approach can exploit the generality and structure of the dynamics model, but is also capable of ignoring its inevitable inaccuracies, by directly incorporating the evidence provided by the direct observation of the cost. Preliminary results demonstrate that our approach outperforms purely model-based and model-free approaches, as well as the approach of simply switching from a model-based to a model-free setting.\n    ",
        "submission_date": "2017-09-10T00:00:00",
        "last_modified_date": "2017-10-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.03221",
        "title": "Fairness Testing: Testing Software for Discrimination",
        "authors": [
            "Sainyam Galhotra",
            "Yuriy Brun",
            "Alexandra Meliou"
        ],
        "abstract": "This paper defines software fairness and discrimination and develops a testing-based method for measuring if and how much software discriminates, focusing on causality in discriminatory behavior. Evidence of software discrimination has been found in modern software systems that recommend criminal sentences, grant access to financial products, and determine who is allowed to participate in promotions. Our approach, Themis, generates efficient test suites to measure discrimination. Given a schema describing valid system inputs, Themis generates discrimination tests automatically and does not require an oracle. We evaluate Themis on 20 software systems, 12 of which come from prior work with explicit focus on avoiding discrimination. We find that (1) Themis is effective at discovering software discrimination, (2) state-of-the-art techniques for removing discrimination from algorithms fail in many situations, at times discriminating against as much as 98% of an input subdomain, (3) Themis optimizations are effective at producing efficient test suites for measuring discrimination, and (4) Themis is more efficient on systems that exhibit more discrimination. We thus demonstrate that fairness testing is a critical aspect of the software development cycle in domains with possible discrimination and provide initial tools for measuring software discrimination.\n    ",
        "submission_date": "2017-09-11T00:00:00",
        "last_modified_date": "2017-09-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.03239",
        "title": "On better training the infinite restricted Boltzmann machines",
        "authors": [
            "Xuan Peng",
            "Xunzhang Gao",
            "Xiang Li"
        ],
        "abstract": "The infinite restricted Boltzmann machine (iRBM) is an extension of the classic RBM. It enjoys a good property of automatically deciding the size of the hidden layer according to specific training data. With sufficient training, the iRBM can achieve a competitive performance with that of the classic RBM. However, the convergence of learning the iRBM is slow, due to the fact that the iRBM is sensitive to the ordering of its hidden units, the learned filters change slowly from the left-most hidden unit to right. To break this dependency between neighboring hidden units and speed up the convergence of training, a novel training strategy is proposed. The key idea of the proposed training strategy is randomly regrouping the hidden units before each gradient descent step. Potentially, a mixing of infinite many iRBMs with different permutations of the hidden units can be achieved by this learning method, which has a similar effect of preventing the model from over-fitting as the dropout. The original iRBM is also modified to be capable of carrying out discriminative training. To evaluate the impact of our method on convergence speed of learning and the model's generalization ability, several experiments have been performed on the binarized MNIST and CalTech101 Silhouettes datasets. Experimental results indicate that the proposed training strategy can greatly accelerate learning and enhance generalization ability of iRBMs.\n    ",
        "submission_date": "2017-09-11T00:00:00",
        "last_modified_date": "2017-10-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.03297",
        "title": "Cellular Automaton Based Simulation of Large Pedestrian Facilities - A Case Study on the Staten Island Ferry Terminals",
        "authors": [
            "Luca Crociani",
            "Gregor L\u00e4mmel",
            "H. Joon Park",
            "Giuseppe Vizzari"
        ],
        "abstract": "Current metropolises largely depend on a functioning transport infrastructure and the increasing demand can only be satisfied by a well organized mass transit. One example for a crucial mass transit system is New York City's Staten Island Ferry, connecting the two boroughs of Staten Island and Manhattan with a regular passenger service. Today's demand already exceeds 2500 passengers for a single cycle during peek hours, and future projections suggest that it will further increase. One way to appraise how the system will cope with future demand is by simulation. This contribution proposes an integrated simulation approach to evaluate the system performance with respect to future demand. The simulation relies on a multiscale modeling approach where the terminal buildings are simulated by a microscopic and quantitatively valid cellular automata (CA) and the journeys of the ferries themselves are modeled by a mesoscopic queue simulation approach. Based on the simulation results recommendations with respect to the future demand are given.\n    ",
        "submission_date": "2017-09-11T00:00:00",
        "last_modified_date": "2017-09-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.03450",
        "title": "UI-Net: Interactive Artificial Neural Networks for Iterative Image Segmentation Based on a User Model",
        "authors": [
            "Mario Amrehn",
            "Sven Gaube",
            "Mathias Unberath",
            "Frank Schebesch",
            "Tim Horz",
            "Maddalena Strumia",
            "Stefan Steidl",
            "Markus Kowarschik",
            "Andreas Maier"
        ],
        "abstract": "For complex segmentation tasks, fully automatic systems are inherently limited in their achievable accuracy for extracting relevant objects. Especially in cases where only few data sets need to be processed for a highly accurate result, semi-automatic segmentation techniques exhibit a clear benefit for the user. One area of application is medical image processing during an intervention for a single patient. We propose a learning-based cooperative segmentation approach which includes the computing entity as well as the user into the task. Our system builds upon a state-of-the-art fully convolutional artificial neural network (FCN) as well as an active user model for training. During the segmentation process, a user of the trained system can iteratively add additional hints in form of pictorial scribbles as seed points into the FCN system to achieve an interactive and precise segmentation result. The segmentation quality of interactive FCNs is evaluated. Iterative FCN approaches can yield superior results compared to networks without the user input channel component, due to a consistent improvement in segmentation quality after each interaction.\n    ",
        "submission_date": "2017-09-11T00:00:00",
        "last_modified_date": "2017-09-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.03456",
        "title": "CLAD: A Complex and Long Activities Dataset with Rich Crowdsourced Annotations",
        "authors": [
            "Jawad Tayyub",
            "Majd Hawasly",
            "David C. Hogg",
            "Anthony G. Cohn"
        ],
        "abstract": "This paper introduces a novel activity dataset which exhibits real-life and diverse scenarios of complex, temporally-extended human activities and actions. The dataset presents a set of videos of actors performing everyday activities in a natural and unscripted manner. The dataset was recorded using a static Kinect 2 sensor which is commonly used on many robotic platforms. The dataset comprises of RGB-D images, point cloud data, automatically generated skeleton tracks in addition to crowdsourced annotations. Furthermore, we also describe the methodology used to acquire annotations through crowdsourcing. Finally some activity recognition benchmarks are presented using current state-of-the-art techniques. We believe that this dataset is particularly suitable as a testbed for activity recognition research but it can also be applicable for other common tasks in robotics/computer vision research such as object detection and human skeleton tracking.\n    ",
        "submission_date": "2017-09-11T00:00:00",
        "last_modified_date": "2017-09-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.03582",
        "title": "Art of singular vectors and universal adversarial perturbations",
        "authors": [
            "Valentin Khrulkov",
            "Ivan Oseledets"
        ],
        "abstract": "Vulnerability of Deep Neural Networks (DNNs) to adversarial attacks has been attracting a lot of attention in recent studies. It has been shown that for many state of the art DNNs performing image classification there exist universal adversarial perturbations --- image-agnostic perturbations mere addition of which to natural images with high probability leads to their misclassification. In this work we propose a new algorithm for constructing such universal perturbations. Our approach is based on computing the so-called $(p, q)$-singular vectors of the Jacobian matrices of hidden layers of a network. Resulting perturbations present interesting visual patterns, and by using only 64 images we were able to construct universal perturbations with more than 60 \\% fooling rate on the dataset consisting of 50000 images. We also investigate a correlation between the maximal singular value of the Jacobian matrix and the fooling rate of the corresponding singular vector, and show that the constructed perturbations generalize across networks.\n    ",
        "submission_date": "2017-09-11T00:00:00",
        "last_modified_date": "2017-11-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.03625",
        "title": "Budgeted Experiment Design for Causal Structure Learning",
        "authors": [
            "AmirEmad Ghassami",
            "Saber Salehkaleybar",
            "Negar Kiyavash",
            "Elias Bareinboim"
        ],
        "abstract": "We study the problem of causal structure learning when the experimenter is limited to perform at most $k$ non-adaptive experiments of size $1$. We formulate the problem of finding the best intervention target set as an optimization problem, which aims to maximize the average number of edges whose directions are resolved. We prove that the corresponding objective function is submodular and a greedy algorithm suffices to achieve $(1-\\frac{1}{e})$-approximation of the optimal value. We further present an accelerated variant of the greedy algorithm, which can lead to orders of magnitude performance speedup. We validate our proposed approach on synthetic and real graphs. The results show that compared to the purely observational setting, our algorithm orients the majority of the edges through a considerably small number of interventions.\n    ",
        "submission_date": "2017-09-11T00:00:00",
        "last_modified_date": "2018-07-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.03683",
        "title": "A Practically Competitive and Provably Consistent Algorithm for Uplift Modeling",
        "authors": [
            "Yan Zhao",
            "Xiao Fang",
            "David Simchi-Levi"
        ],
        "abstract": "Randomized experiments have been critical tools of decision making for decades. However, subjects can show significant heterogeneity in response to treatments in many important applications. Therefore it is not enough to simply know which treatment is optimal for the entire population. What we need is a model that correctly customize treatment assignment base on subject characteristics. The problem of constructing such models from randomized experiments data is known as Uplift Modeling in the literature. Many algorithms have been proposed for uplift modeling and some have generated promising results on various data sets. Yet little is known about the theoretical properties of these algorithms. In this paper, we propose a new tree-based ensemble algorithm for uplift modeling. Experiments show that our algorithm can achieve competitive results on both synthetic and industry-provided data. In addition, by properly tuning the \"node size\" parameter, our algorithm is proved to be consistent under mild regularity conditions. This is the first consistent algorithm for uplift modeling that we are aware of.\n    ",
        "submission_date": "2017-09-12T00:00:00",
        "last_modified_date": "2017-09-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.03714",
        "title": "RRA: Recurrent Residual Attention for Sequence Learning",
        "authors": [
            "Cheng Wang"
        ],
        "abstract": "In this paper, we propose a recurrent neural network (RNN) with residual attention (RRA) to learn long-range dependencies from sequential data. We propose to add residual connections across timesteps to RNN, which explicitly enhances the interaction between current state and hidden states that are several timesteps apart. This also allows training errors to be directly back-propagated through residual connections and effectively alleviates gradient vanishing problem. We further reformulate an attention mechanism over residual connections. An attention gate is defined to summarize the individual contribution from multiple previous hidden states in computing the current state. We evaluate RRA on three tasks: the adding problem, pixel-by-pixel MNIST classification and sentiment analysis on the IMDB dataset. Our experiments demonstrate that RRA yields better performance, faster convergence and more stable training compared to a standard LSTM network. Furthermore, RRA shows highly competitive performance to the state-of-the-art methods.\n    ",
        "submission_date": "2017-09-12T00:00:00",
        "last_modified_date": "2017-09-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.03919",
        "title": "End-to-End United Video Dehazing and Detection",
        "authors": [
            "Boyi Li",
            "Xiulian Peng",
            "Zhangyang Wang",
            "Jizheng Xu",
            "Dan Feng"
        ],
        "abstract": "The recent development of CNN-based image dehazing has revealed the effectiveness of end-to-end modeling. However, extending the idea to end-to-end video dehazing has not been explored yet. In this paper, we propose an End-to-End Video Dehazing Network (EVD-Net), to exploit the temporal consistency between consecutive video frames. A thorough study has been conducted over a number of structure options, to identify the best temporal fusion strategy. Furthermore, we build an End-to-End United Video Dehazing and Detection Network(EVDD-Net), which concatenates and jointly trains EVD-Net with a video object detection model. The resulting augmented end-to-end pipeline has demonstrated much more stable and accurate detection results in hazy video.\n    ",
        "submission_date": "2017-09-12T00:00:00",
        "last_modified_date": "2017-09-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.03968",
        "title": "Affective Neural Response Generation",
        "authors": [
            "Nabiha Asghar",
            "Pascal Poupart",
            "Jesse Hoey",
            "Xin Jiang",
            "Lili Mou"
        ],
        "abstract": "Existing neural conversational models process natural language primarily on a lexico-syntactic level, thereby ignoring one of the most crucial components of human-to-human dialogue: its affective content. We take a step in this direction by proposing three novel ways to incorporate affective/emotional aspects into long short term memory (LSTM) encoder-decoder neural conversation models: (1) affective word embeddings, which are cognitively engineered, (2) affect-based objective functions that augment the standard cross-entropy loss, and (3) affectively diverse beam search for decoding. Experiments show that these techniques improve the open-domain conversational prowess of encoder-decoder networks by enabling them to produce emotionally rich responses that are more interesting and natural.\n    ",
        "submission_date": "2017-09-12T00:00:00",
        "last_modified_date": "2017-09-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.03980",
        "title": "Refining Source Representations with Relation Networks for Neural Machine Translation",
        "authors": [
            "Wen Zhang",
            "Jiawei Hu",
            "Yang Feng",
            "Qun Liu"
        ],
        "abstract": "Although neural machine translation (NMT) with the encoder-decoder framework has achieved great success in recent times, it still suffers from some drawbacks: RNNs tend to forget old information which is often useful and the encoder only operates through words without considering word relationship. To solve these problems, we introduce a relation networks (RN) into NMT to refine the encoding representations of the source. In our method, the RN first augments the representation of each source word with its neighbors and reasons all the possible pairwise relations between them. Then the source representations and all the relations are fed to the attention module and the decoder together, keeping the main encoder-decoder architecture unchanged. Experiments on two Chinese-to-English data sets in different scales both show that our method can outperform the competitive baselines significantly.\n    ",
        "submission_date": "2017-09-12T00:00:00",
        "last_modified_date": "2018-05-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.03981",
        "title": "Aggregating incoherent agents who disagree",
        "authors": [
            "Richard Pettigrew"
        ],
        "abstract": "In this paper, we explore how we should aggregate the degrees of belief of of a group of agents to give a single coherent set of degrees of belief, when at least some of those agents might be probabilistically incoherent. There are a number of way of aggregating degrees of belief, and there are a number of ways of fixing incoherent degrees of belief. When we have picked one of each, should we aggregate first and then fix, or fix first and then aggregate? Or should we try to do both at once? And when do these different procedures agree with one another? In this paper, we focus particularly on the final question.\n    ",
        "submission_date": "2017-09-12T00:00:00",
        "last_modified_date": "2017-09-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.04057",
        "title": "Parallelizing Linear Recurrent Neural Nets Over Sequence Length",
        "authors": [
            "Eric Martin",
            "Chris Cundy"
        ],
        "abstract": "Recurrent neural networks (RNNs) are widely used to model sequential data but their non-linear dependencies between sequence elements prevent parallelizing training over sequence length. We show the training of RNNs with only linear sequential dependencies can be parallelized over the sequence length using the parallel scan algorithm, leading to rapid training on long sequences even with small minibatch size. We develop a parallel linear recurrence CUDA kernel and show that it can be applied to immediately speed up training and inference of several state of the art RNN architectures by up to 9x. We abstract recent work on linear RNNs into a new framework of linear surrogate RNNs and develop a linear surrogate model for the long short-term memory unit, the GILR-LSTM, that utilizes parallel linear recurrence. We extend sequence learning to new extremely long sequence regimes that were previously out of reach by successfully training a GILR-LSTM on a synthetic sequence classification task with a one million timestep dependency.\n    ",
        "submission_date": "2017-09-12T00:00:00",
        "last_modified_date": "2018-02-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.04071",
        "title": "Variational Reasoning for Question Answering with Knowledge Graph",
        "authors": [
            "Yuyu Zhang",
            "Hanjun Dai",
            "Zornitsa Kozareva",
            "Alexander J. Smola",
            "Le Song"
        ],
        "abstract": "Knowledge graph (KG) is known to be helpful for the task of question answering (QA), since it provides well-structured relational information between entities, and allows one to further infer indirect facts. However, it is challenging to build QA systems which can learn to reason over knowledge graphs based on question-answer pairs alone. First, when people ask questions, their expressions are noisy (for example, typos in texts, or variations in pronunciations), which is non-trivial for the QA system to match those mentioned entities to the knowledge graph. Second, many questions require multi-hop logic reasoning over the knowledge graph to retrieve the answers. To address these challenges, we propose a novel and unified deep learning architecture, and an end-to-end variational learning algorithm which can handle noise in questions, and learn multi-hop reasoning simultaneously. Our method achieves state-of-the-art performance on a recent benchmark dataset in the literature. We also derive a series of new benchmark datasets, including questions for multi-hop reasoning, questions paraphrased by neural translation model, and questions in human voice. Our method yields very promising results on all these challenging datasets.\n    ",
        "submission_date": "2017-09-12T00:00:00",
        "last_modified_date": "2017-11-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.04083",
        "title": "Pre-training Neural Networks with Human Demonstrations for Deep Reinforcement Learning",
        "authors": [
            "Gabriel V. de la Cruz Jr",
            "Yunshu Du",
            "Matthew E. Taylor"
        ],
        "abstract": "Deep reinforcement learning (deep RL) has achieved superior performance in complex sequential tasks by using a deep neural network as its function approximator and by learning directly from raw images. A drawback of using raw images is that deep RL must learn the state feature representation from the raw images in addition to learning a policy. As a result, deep RL can require a prohibitively large amount of training time and data to reach reasonable performance, making it difficult to use deep RL in real-world applications, especially when data is expensive. In this work, we speed up training by addressing half of what deep RL is trying to solve --- learning features. Our approach is to learn some of the important features by pre-training deep RL network's hidden layers via supervised learning using a small set of human demonstrations. We empirically evaluate our approach using deep Q-network (DQN) and asynchronous advantage actor-critic (A3C) algorithms on the Atari 2600 games of Pong, Freeway, and Beamrider. Our results show that: 1) pre-training with human demonstrations in a supervised learning manner is better at discovering features relative to pre-training naively in DQN, and 2) initializing a deep RL network with a pre-trained model provides a significant improvement in training time even when pre-training from a small number of human demonstrations.\n    ",
        "submission_date": "2017-09-12T00:00:00",
        "last_modified_date": "2019-04-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.04176",
        "title": "Computing the Shapley Value in Allocation Problems: Approximations and Bounds, with an Application to the Italian VQR Research Assessment Program",
        "authors": [
            "Francesco Lupia",
            "Angelo Mendicelli",
            "Andrea Ribichini",
            "Francesco Scarcello",
            "Marco Schaerf"
        ],
        "abstract": "In allocation problems, a given set of goods are assigned to agents in such a way that the social welfare is maximised, that is, the largest possible global worth is achieved. When goods are indivisible, it is possible to use money compensation to perform a fair allocation taking into account the actual contribution of all agents to the social welfare. Coalitional games provide a formal mathematical framework to model such problems, in particular the Shapley value is a solution concept widely used for assigning worths to agents in a fair way. Unfortunately, computing this value is a $\\#{\\rm P}$-hard problem, so that applying this good theoretical notion is often quite difficult in real-world problems.\n",
        "submission_date": "2017-09-13T00:00:00",
        "last_modified_date": "2017-09-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.04186",
        "title": "On labeling Android malware signatures using minhashing and further classification with Structural Equation Models",
        "authors": [
            "Ignacio Mart\u00edn",
            "Jos\u00e9 Alberto Hern\u00e1ndez",
            "Sergio de los Santos"
        ],
        "abstract": "Multi-scanner Antivirus systems provide insightful information on the nature of a suspect application; however there is often a lack of consensus and consistency between different Anti-Virus engines. In this article, we analyze more than 250 thousand malware signatures generated by 61 different Anti-Virus engines after analyzing 82 thousand different Android malware applications. We identify 41 different malware classes grouped into three major categories, namely Adware, Harmful Threats and Unknown or Generic signatures. We further investigate the relationships between such 41 classes using community detection algorithms from graph theory to identify similarities between them; and we finally propose a Structure Equation Model to identify which Anti-Virus engines are more powerful at detecting each macro-category. As an application, we show how such models can help in identifying whether Unknown malware applications are more likely to be of Harmful or Adware type.\n    ",
        "submission_date": "2017-09-13T00:00:00",
        "last_modified_date": "2017-09-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.04219",
        "title": "Assessing State-of-the-Art Sentiment Models on State-of-the-Art Sentiment Datasets",
        "authors": [
            "Jeremy Barnes",
            "Roman Klinger",
            "Sabine Schulte im Walde"
        ],
        "abstract": "There has been a good amount of progress in sentiment analysis over the past 10 years, including the proposal of new methods and the creation of benchmark datasets. In some papers, however, there is a tendency to compare models only on one or two datasets, either because of time restraints or because the model is tailored to a specific task. Accordingly, it is hard to understand how well a certain model generalizes across different tasks and datasets. In this paper, we contribute to this situation by comparing several models on six different benchmarks, which belong to different domains and additionally have different levels of granularity (binary, 3-class, 4-class and 5-class). We show that Bi-LSTMs perform well across datasets and that both LSTMs and Bi-LSTMs are particularly good at fine-grained sentiment tasks (i. e., with more than two classes). Incorporating sentiment information into word embeddings during training gives good results for datasets that are lexically similar to the training data. With our experiments, we contribute to a better understanding of the performance of different model architectures on different data sets. Consequently, we detect novel state-of-the-art results on the SenTube datasets.\n    ",
        "submission_date": "2017-09-13T00:00:00",
        "last_modified_date": "2017-09-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.04305",
        "title": "Automated Cloud Provisioning on AWS using Deep Reinforcement Learning",
        "authors": [
            "Zhiguang Wang",
            "Chul Gwon",
            "Tim Oates",
            "Adam Iezzi"
        ],
        "abstract": "As the use of cloud computing continues to rise, controlling cost becomes increasingly important. Yet there is evidence that 30\\% - 45\\% of cloud spend is wasted. Existing tools for cloud provisioning typically rely on highly trained human experts to specify what to monitor, thresholds for triggering action, and actions. In this paper we explore the use of reinforcement learning (RL) to acquire policies to balance performance and spend, allowing humans to specify what they want as opposed to how to do it, minimizing the need for cloud expertise. Empirical results with tabular, deep, and dueling double deep Q-learning with the CloudSim simulator show the utility of RL and the relative merits of the approaches. We also demonstrate effective policy transfer learning from an extremely simple simulator to CloudSim, with the next step being transfer from CloudSim to an Amazon Web Services physical environment.\n    ",
        "submission_date": "2017-09-13T00:00:00",
        "last_modified_date": "2017-09-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.04318",
        "title": "Predictive modeling of die filling of the pharmaceutical granules using the flexible neural tree",
        "authors": [
            "Varun Kumar Ojha",
            "Serena Schiano",
            "Chuan-Yu Wu",
            "V\u00e1clav Sn\u00e1\u0161el",
            "Ajith Abraham"
        ],
        "abstract": "In this work, a computational intelligence (CI) technique named flexible neural tree (FNT) was developed to predict die filling performance of pharmaceutical granules and to identify significant die filling process variables. FNT resembles feedforward neural network, which creates a tree-like structure by using genetic programming. To improve accuracy, FNT parameters were optimized by using differential evolution algorithm. The performance of the FNT-based CI model was evaluated and compared with other CI techniques: multilayer perceptron, Gaussian process regression, and reduced error pruning tree. The accuracy of the CI model was evaluated experimentally using die filling as a case study. The die filling experiments were performed using a model shoe system and three different grades of microcrystalline cellulose (MCC) powders (MCC PH 101, MCC PH 102, and MCC DG). The feed powders were roll-compacted and milled into granules. The granules were then sieved into samples of various size classes. The mass of granules deposited into the die at different shoe speeds was measured. From these experiments, a dataset consisting true density, mean diameter (d50), granule size, and shoe speed as the inputs and the deposited mass as the output was generated. Cross-validation (CV) methods such as 10FCV and 5x2FCV were applied to develop and to validate the predictive models. It was found that the FNT-based CI model (for both CV methods) performed much better than other CI models. Additionally, it was observed that process variables such as the granule size and the shoe speed had a higher impact on the predictability than that of the powder property such as d50. Furthermore, validation of model prediction with experimental data showed that the die filling behavior of coarse granules could be better predicted than that of fine granules.\n    ",
        "submission_date": "2017-05-16T00:00:00",
        "last_modified_date": "2017-05-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.04380",
        "title": "Neural Network Based Nonlinear Weighted Finite Automata",
        "authors": [
            "Tianyu Li",
            "Guillaume Rabusseau",
            "Doina Precup"
        ],
        "abstract": "Weighted finite automata (WFA) can expressively model functions defined over strings but are inherently linear models. Given the recent successes of nonlinear models in machine learning, it is natural to wonder whether ex-tending WFA to the nonlinear setting would be beneficial. In this paper, we propose a novel model of neural network based nonlinearWFA model (NL-WFA) along with a learning algorithm. Our learning algorithm is inspired by the spectral learning algorithm for WFAand relies on a nonlinear decomposition of the so-called Hankel matrix, by means of an auto-encoder network. The expressive power of NL-WFA and the proposed learning algorithm are assessed on both synthetic and real-world data, showing that NL-WFA can lead to smaller model sizes and infer complex grammatical structures from data.\n    ",
        "submission_date": "2017-09-13T00:00:00",
        "last_modified_date": "2017-12-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.04555",
        "title": "Predicting Organic Reaction Outcomes with Weisfeiler-Lehman Network",
        "authors": [
            "Wengong Jin",
            "Connor W. Coley",
            "Regina Barzilay",
            "Tommi Jaakkola"
        ],
        "abstract": "The prediction of organic reaction outcomes is a fundamental problem in computational chemistry. Since a reaction may involve hundreds of atoms, fully exploring the space of possible transformations is intractable. The current solution utilizes reaction templates to limit the space, but it suffers from coverage and efficiency issues. In this paper, we propose a template-free approach to efficiently explore the space of product molecules by first pinpointing the reaction center -- the set of nodes and edges where graph edits occur. Since only a small number of atoms contribute to reaction center, we can directly enumerate candidate products. The generated candidates are scored by a Weisfeiler-Lehman Difference Network that models high-order interactions between changes occurring at nodes across the molecule. Our framework outperforms the top-performing template-based approach with a 10\\% margin, while running orders of magnitude faster. Finally, we demonstrate that the model accuracy rivals the performance of domain experts.\n    ",
        "submission_date": "2017-09-13T00:00:00",
        "last_modified_date": "2017-12-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.04558",
        "title": "Using NLU in Context for Question Answering: Improving on Facebook's bAbI Tasks",
        "authors": [
            "John S. Ball"
        ],
        "abstract": "For the next step in human to machine interaction, Artificial Intelligence (AI) should interact predominantly using natural language because, if it worked, it would be the fastest way to communicate. Facebook's toy tasks (bAbI) provide a useful benchmark to compare implementations for conversational AI. While the published experiments so far have been based on exploiting the distributional hypothesis with machine learning, our model exploits natural language understanding (NLU) with the decomposition of language based on Role and Reference Grammar (RRG) and the brain-based Patom theory. Our combinatorial system for conversational AI based on linguistics has many advantages: passing bAbI task tests without parsing or statistics while increasing scalability. Our model validates both the training and test data to find 'garbage' input and output (GIGO). It is not rules-based, nor does it use parts of speech, but instead relies on meaning. While Deep Learning is difficult to debug and fix, every step in our model can be understood and changed like any non-statistical computer program. Deep Learning's lack of explicable reasoning has raised opposition to AI, partly due to fear of the unknown. To support the goals of AI, we propose extended tasks to use human-level statements with tense, aspect and voice, and embedded clauses with junctures: and answers to be natural language generation (NLG) instead of keywords. While machine learning permits invalid training data to produce incorrect test responses, our system cannot because the context tracking would need to be intentionally broken. We believe no existing learning systems can currently solve these extended natural language tests. There appears to be a knowledge gap between NLP researchers and linguists, but ongoing competitive results such as these promise to narrow that gap.\n    ",
        "submission_date": "2017-09-13T00:00:00",
        "last_modified_date": "2017-09-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.04574",
        "title": "Towards personalized human AI interaction - adapting the behavior of AI agents using neural signatures of subjective interest",
        "authors": [
            "Victor Shih",
            "David C Jangraw",
            "Paul Sajda",
            "Sameer Saproo"
        ],
        "abstract": "Reinforcement Learning AI commonly uses reward/penalty signals that are objective and explicit in an environment -- e.g. game score, completion time, etc. -- in order to learn the optimal strategy for task performance. However, Human-AI interaction for such AI agents should include additional reinforcement that is implicit and subjective -- e.g. human preferences for certain AI behavior -- in order to adapt the AI behavior to idiosyncratic human preferences. Such adaptations would mirror naturally occurring processes that increase trust and comfort during social interactions. Here, we show how a hybrid brain-computer-interface (hBCI), which detects an individual's level of interest in objects/events in a virtual environment, can be used to adapt the behavior of a Deep Reinforcement Learning AI agent that is controlling a virtual autonomous vehicle. Specifically, we show that the AI learns a driving strategy that maintains a safe distance from a lead vehicle, and most novelly, preferentially slows the vehicle when the human passengers of the vehicle encounter objects of interest. This adaptation affords an additional 20\\% viewing time for subjectively interesting objects. This is the first demonstration of how an hBCI can be used to provide implicit reinforcement to an AI agent in a way that incorporates user preferences into the control system.\n    ",
        "submission_date": "2017-09-14T00:00:00",
        "last_modified_date": "2017-09-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.04596",
        "title": "A Framework for Generalizing Graph-based Representation Learning Methods",
        "authors": [
            "Nesreen K. Ahmed",
            "Ryan A. Rossi",
            "Rong Zhou",
            "John Boaz Lee",
            "Xiangnan Kong",
            "Theodore L. Willke",
            "Hoda Eldardiry"
        ],
        "abstract": "Random walks are at the heart of many existing deep learning algorithms for graph data. However, such algorithms have many limitations that arise from the use of random walks, e.g., the features resulting from these methods are unable to transfer to new nodes and graphs as they are tied to node identity. In this work, we introduce the notion of attributed random walks which serves as a basis for generalizing existing methods such as DeepWalk, node2vec, and many others that leverage random walks. Our proposed framework enables these methods to be more widely applicable for both transductive and inductive learning as well as for use on graphs with attributes (if available). This is achieved by learning functions that generalize to new nodes and graphs. We show that our proposed framework is effective with an average AUC improvement of 16.1% while requiring on average 853 times less space than existing methods on a variety of graphs from several domains.\n    ",
        "submission_date": "2017-09-14T00:00:00",
        "last_modified_date": "2017-09-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.04695",
        "title": "The Conditional Analogy GAN: Swapping Fashion Articles on People Images",
        "authors": [
            "Nikolay Jetchev",
            "Urs Bergmann"
        ],
        "abstract": "We present a novel method to solve image analogy problems : it allows to learn the relation between paired images present in training data, and then generalize and generate images that correspond to the relation, but were never seen in the training set. Therefore, we call the method Conditional Analogy Generative Adversarial Network (CAGAN), as it is based on adversarial training and employs deep convolutional neural networks. An especially interesting application of that technique is automatic swapping of clothing on fashion model photos. Our work has the following contributions. First, the definition of the end-to-end trainable CAGAN architecture, which implicitly learns segmentation masks without expensive supervised labeling data. Second, experimental results show plausible segmentation masks and often convincing swapped images, given the target article. Finally, we discuss the next steps for that technique: neural network architecture improvements and more advanced applications.\n    ",
        "submission_date": "2017-09-14T00:00:00",
        "last_modified_date": "2017-09-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.04696",
        "title": "DiSAN: Directional Self-Attention Network for RNN/CNN-Free Language Understanding",
        "authors": [
            "Tao Shen",
            "Tianyi Zhou",
            "Guodong Long",
            "Jing Jiang",
            "Shirui Pan",
            "Chengqi Zhang"
        ],
        "abstract": "Recurrent neural nets (RNN) and convolutional neural nets (CNN) are widely used on NLP tasks to capture the long-term and local dependencies, respectively. Attention mechanisms have recently attracted enormous interest due to their highly parallelizable computation, significantly less training time, and flexibility in modeling dependencies. We propose a novel attention mechanism in which the attention between elements from input sequence(s) is directional and multi-dimensional (i.e., feature-wise). A light-weight neural net, \"Directional Self-Attention Network (DiSAN)\", is then proposed to learn sentence embedding, based solely on the proposed attention without any RNN/CNN structure. DiSAN is only composed of a directional self-attention with temporal order encoded, followed by a multi-dimensional attention that compresses the sequence into a vector representation. Despite its simple form, DiSAN outperforms complicated RNN models on both prediction quality and time efficiency. It achieves the best test accuracy among all sentence encoding methods and improves the most recent best result by 1.02% on the Stanford Natural Language Inference (SNLI) dataset, and shows state-of-the-art test accuracy on the Stanford Sentiment Treebank (SST), Multi-Genre natural language inference (MultiNLI), Sentences Involving Compositional Knowledge (SICK), Customer Review, MPQA, TREC question-type classification and Subjectivity (SUBJ) datasets.\n    ",
        "submission_date": "2017-09-14T00:00:00",
        "last_modified_date": "2017-11-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.04905",
        "title": "One-Shot Visual Imitation Learning via Meta-Learning",
        "authors": [
            "Chelsea Finn",
            "Tianhe Yu",
            "Tianhao Zhang",
            "Pieter Abbeel",
            "Sergey Levine"
        ],
        "abstract": "In order for a robot to be a generalist that can perform a wide range of jobs, it must be able to acquire a wide variety of skills quickly and efficiently in complex unstructured environments. High-capacity models such as deep neural networks can enable a robot to represent complex skills, but learning each skill from scratch then becomes infeasible. In this work, we present a meta-imitation learning method that enables a robot to learn how to learn more efficiently, allowing it to acquire new skills from just a single demonstration. Unlike prior methods for one-shot imitation, our method can scale to raw pixel inputs and requires data from significantly fewer prior tasks for effective learning of new skills. Our experiments on both simulated and real robot platforms demonstrate the ability to learn new tasks, end-to-end, from a single visual demonstration.\n    ",
        "submission_date": "2017-09-14T00:00:00",
        "last_modified_date": "2017-09-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.04909",
        "title": "Shared Learning : Enhancing Reinforcement in $Q$-Ensembles",
        "authors": [
            "Rakesh R Menon",
            "Balaraman Ravindran"
        ],
        "abstract": "Deep Reinforcement Learning has been able to achieve amazing successes in a variety of domains from video games to continuous control by trying to maximize the cumulative reward. However, most of these successes rely on algorithms that require a large amount of data to train in order to obtain results on par with human-level performance. This is not feasible if we are to deploy these systems on real world tasks and hence there has been an increased thrust in exploring data efficient algorithms. To this end, we propose the Shared Learning framework aimed at making $Q$-ensemble algorithms data-efficient. For achieving this, we look into some principles of transfer learning which aim to study the benefits of information exchange across tasks in reinforcement learning and adapt transfer to learning our value function estimates in a novel manner. In this paper, we consider the special case of transfer between the value function estimates in the $Q$-ensemble architecture of BootstrappedDQN. We further empirically demonstrate how our proposed framework can help in speeding up the learning process in $Q$-ensembles with minimum computational overhead on a suite of Atari 2600 Games.\n    ",
        "submission_date": "2017-09-14T00:00:00",
        "last_modified_date": "2017-09-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.04991",
        "title": "Abstractions for AI-Based User Interfaces and Systems",
        "authors": [
            "Alex Renda",
            "Harrison Goldstein",
            "Sarah Bird",
            "Chris Quirk",
            "Adrian Sampson"
        ],
        "abstract": "Novel user interfaces based on artificial intelligence, such as natural-language agents, present new categories of engineering challenges. These systems need to cope with uncertainty and ambiguity, interface with machine learning algorithms, and compose information from multiple users to make decisions. We propose to treat these challenges as language-design problems. We describe three programming language abstractions for three core problems in intelligent system design. First, hypothetical worlds support nondeterministic search over spaces of alternative actions. Second, a feature type system abstracts the interaction between applications and learning algorithms. Finally, constructs for collaborative execution extend hypothetical worlds across multiple machines while controlling access to private data. We envision these features as first steps toward a complete language for implementing AI-based interfaces and applications.\n    ",
        "submission_date": "2017-09-14T00:00:00",
        "last_modified_date": "2017-09-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.05014",
        "title": "WOAH: Preliminaries to Zero-shot Ontology Learning for Conversational Agents",
        "authors": [
            "Gonzalo Estr\u00e1n Buyo"
        ],
        "abstract": "The present paper presents the Weighted Ontology Approximation Heuristic (WOAH), a novel zero-shot approach to ontology estimation for conversational agents development environments. This methodology extracts verbs and nouns separately from data by distilling the dependencies obtained and applying similarity and sparsity metrics to generate an ontology estimation configurable in terms of the level of generalization.\n    ",
        "submission_date": "2017-09-15T00:00:00",
        "last_modified_date": "2017-09-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.05021",
        "title": "ClickBAIT: Click-based Accelerated Incremental Training of Convolutional Neural Networks",
        "authors": [
            "Ervin Teng",
            "Jo\u00e3o Diogo Falc\u00e3o",
            "Bob Iannucci"
        ],
        "abstract": "Today's general-purpose deep convolutional neural networks (CNN) for image classification and object detection are trained offline on large static datasets. Some applications, however, will require training in real-time on live video streams with a human-in-the-loop. We refer to this class of problem as Time-ordered Online Training (ToOT) - these problems will require a consideration of not only the quantity of incoming training data, but the human effort required to tag and use it. In this paper, we define training benefit as a metric to measure the effectiveness of a sequence in using each user interaction. We demonstrate and evaluate a system tailored to performing ToOT in the field, capable of training an image classifier on a live video stream through minimal input from a human operator. We show that by exploiting the time-ordered nature of the video stream through optical flow-based object tracking, we can increase the effectiveness of human actions by about 8 times.\n    ",
        "submission_date": "2017-09-15T00:00:00",
        "last_modified_date": "2017-09-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.05027",
        "title": "Learning Intrinsic Sparse Structures within Long Short-Term Memory",
        "authors": [
            "Wei Wen",
            "Yuxiong He",
            "Samyam Rajbhandari",
            "Minjia Zhang",
            "Wenhan Wang",
            "Fang Liu",
            "Bin Hu",
            "Yiran Chen",
            "Hai Li"
        ],
        "abstract": "Model compression is significant for the wide adoption of Recurrent Neural Networks (RNNs) in both user devices possessing limited resources and business clusters requiring quick responses to large-scale service requests. This work aims to learn structurally-sparse Long Short-Term Memory (LSTM) by reducing the sizes of basic structures within LSTM units, including input updates, gates, hidden states, cell states and outputs. Independently reducing the sizes of basic structures can result in inconsistent dimensions among them, and consequently, end up with invalid LSTM units. To overcome the problem, we propose Intrinsic Sparse Structures (ISS) in LSTMs. Removing a component of ISS will simultaneously decrease the sizes of all basic structures by one and thereby always maintain the dimension consistency. By learning ISS within LSTM units, the obtained LSTMs remain regular while having much smaller basic structures. Based on group Lasso regularization, our method achieves 10.59x speedup without losing any perplexity of a language modeling of Penn TreeBank dataset. It is also successfully evaluated through a compact model with only 2.69M weights for machine Question Answering of SQuAD dataset. Our approach is successfully extended to non- LSTM RNNs, like Recurrent Highway Networks (RHNs). Our source code is publicly available at ",
        "submission_date": "2017-09-15T00:00:00",
        "last_modified_date": "2018-02-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.05047",
        "title": "Disentangled Variational Auto-Encoder for Semi-supervised Learning",
        "authors": [
            "Yang Li",
            "Quan Pan",
            "Suhang Wang",
            "Haiyun Peng",
            "Tao Yang",
            "Erik Cambria"
        ],
        "abstract": "Semi-supervised learning is attracting increasing attention due to the fact that datasets of many domains lack enough labeled data. Variational Auto-Encoder (VAE), in particular, has demonstrated the benefits of semi-supervised learning. The majority of existing semi-supervised VAEs utilize a classifier to exploit label information, where the parameters of the classifier are introduced to the VAE. Given the limited labeled data, learning the parameters for the classifiers may not be an optimal solution for exploiting label information. Therefore, in this paper, we develop a novel approach for semi-supervised VAE without classifier. Specifically, we propose a new model called Semi-supervised Disentangled VAE (SDVAE), which encodes the input data into disentangled representation and non-interpretable representation, then the category information is directly utilized to regularize the disentangled representation via the equality constraint. To further enhance the feature learning ability of the proposed VAE, we incorporate reinforcement learning to relieve the lack of data. The dynamic framework is capable of dealing with both image and text data with its corresponding encoder and decoder networks. Extensive experiments on image and text datasets demonstrate the effectiveness of the proposed framework.\n    ",
        "submission_date": "2017-09-15T00:00:00",
        "last_modified_date": "2018-12-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.05107",
        "title": "Multi-Label Zero-Shot Human Action Recognition via Joint Latent Ranking Embedding",
        "authors": [
            "Qian Wang",
            "Ke Chen"
        ],
        "abstract": "Human action recognition refers to automatic recognizing human actions from a video clip. In reality, there often exist multiple human actions in a video stream. Such a video stream is often weakly-annotated with a set of relevant human action labels at a global level rather than assigning each label to a specific video episode corresponding to a single action, which leads to a multi-label learning problem. Furthermore, there are many meaningful human actions in reality but it would be extremely difficult to collect/annotate video clips regarding all of various human actions, which leads to a zero-shot learning scenario. To the best of our knowledge, there is no work that has addressed all the above issues together in human action recognition. In this paper, we formulate a real-world human action recognition task as a multi-label zero-shot learning problem and propose a framework to tackle this problem in a holistic way. Our framework holistically tackles the issue of unknown temporal boundaries between different actions for multi-label learning and exploits the side information regarding the semantic relationship between different human actions for knowledge transfer. Consequently, our framework leads to a joint latent ranking embedding for multi-label zero-shot human action recognition. A novel neural architecture of two component models and an alternate learning algorithm are proposed to carry out the joint latent ranking embedding learning. Thus, multi-label zero-shot recognition is done by measuring relatedness scores of action labels to a test video clip in the joint latent visual and semantic embedding spaces. We evaluate our framework with different settings, including a novel data split scheme designed especially for evaluating multi-label zero-shot learning, on two datasets: Breakfast and Charades. The experimental results demonstrate the effectiveness of our framework.\n    ",
        "submission_date": "2017-09-15T00:00:00",
        "last_modified_date": "2019-02-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.05116",
        "title": "A Streaming Accelerator for Deep Convolutional Neural Networks with Image and Feature Decomposition for Resource-limited System Applications",
        "authors": [
            "Yuan Du",
            "Li Du",
            "Yilei Li",
            "Junjie Su",
            "Mau-Chung Frank Chang"
        ],
        "abstract": "Deep convolutional neural networks (CNN) are widely used in modern artificial intelligence (AI) and smart vision systems but also limited by computation latency, throughput, and energy efficiency on a resource-limited scenario, such as mobile devices, internet of things (IoT), unmanned aerial vehicles (UAV), and so on. A hardware streaming architecture is proposed to accelerate convolution and pooling computations for state-of-the-art deep CNNs. It is optimized for energy efficiency by maximizing local data reuse to reduce off-chip DRAM data access. In addition, image and feature decomposition techniques are introduced to optimize memory access pattern for an arbitrary size of image and number of features within limited on-chip SRAM capacity. A prototype accelerator was implemented in TSMC 65 nm CMOS technology with 2.3 mm x 0.8 mm core area, which achieves 144 GOPS peak throughput and 0.8 TOPS/W peak energy efficiency.\n    ",
        "submission_date": "2017-09-15T00:00:00",
        "last_modified_date": "2017-09-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.05231",
        "title": "A Spectral Method for Activity Shaping in Continuous-Time Information Cascades",
        "authors": [
            "Kevin Scaman",
            "Argyris Kalogeratos",
            "Luca Corinzia",
            "Nicolas Vayatis"
        ],
        "abstract": "Information Cascades Model captures dynamical properties of user activity in a social network. In this work, we develop a novel framework for activity shaping under the Continuous-Time Information Cascades Model which allows the administrator for local control actions by allocating targeted resources that can alter the spread of the process. Our framework employs the optimization of the spectral radius of the Hazard matrix, a quantity that has been shown to drive the maximum influence in a network, while enjoying a simple convex relaxation when used to minimize the influence of the cascade. In addition, use-cases such as quarantine and node immunization are discussed to highlight the generality of the proposed activity shaping framework. Finally, we present the NetShape influence minimization method which is compared favorably to baseline and state-of-the-art approaches through simulations on real social networks.\n    ",
        "submission_date": "2017-09-15T00:00:00",
        "last_modified_date": "2017-09-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.05246",
        "title": "A Generic Framework for Interesting Subspace Cluster Detection in Multi-attributed Networks",
        "authors": [
            "Feng Chen",
            "Baojian Zhou",
            "Adil Alim",
            "Liang Zhao"
        ],
        "abstract": "Detection of interesting (e.g., coherent or anomalous) clusters has been studied extensively on plain or univariate networks, with various applications. Recently, algorithms have been extended to networks with multiple attributes for each node in the real-world. In a multi-attributed network, often, a cluster of nodes is only interesting for a subset (subspace) of attributes, and this type of clusters is called subspace clusters. However, in the current literature, few methods are capable of detecting subspace clusters, which involves concurrent feature selection and network cluster detection. These relevant methods are mostly heuristic-driven and customized for specific application scenarios.\n",
        "submission_date": "2017-09-15T00:00:00",
        "last_modified_date": "2018-09-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.05278",
        "title": "Algorithms and Architecture for Real-time Recommendations at News UK",
        "authors": [
            "Dion Bailey",
            "Tom Pajak",
            "Daoud Clarke",
            "Carlos Rodriguez"
        ],
        "abstract": "Recommendation systems are recognised as being hugely important in industry, and the area is now well understood. At News UK, there is a requirement to be able to quickly generate recommendations for users on news items as they are published. However, little has been published about systems that can generate recommendations in response to changes in recommendable items and user behaviour in a very short space of time. In this paper we describe a new algorithm for updating collaborative filtering models incrementally, and demonstrate its effectiveness on clickstream data from The Times. We also describe the architecture that allows recommendations to be generated on the fly, and how we have made each component scalable. The system is currently being used in production at News UK.\n    ",
        "submission_date": "2017-09-15T00:00:00",
        "last_modified_date": "2017-09-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.05293",
        "title": "Commonsense Scene Semantics for Cognitive Robotics: Towards Grounding Embodied Visuo-Locomotive Interactions",
        "authors": [
            "Jakob Suchan",
            "Mehul Bhatt"
        ],
        "abstract": "We present a commonsense, qualitative model for the semantic grounding of embodied visuo-spatial and locomotive interactions. The key contribution is an integrative methodology combining low-level visual processing with high-level, human-centred representations of space and motion rooted in artificial intelligence. We demonstrate practical applicability with examples involving object interactions, and indoor movement.\n    ",
        "submission_date": "2017-09-15T00:00:00",
        "last_modified_date": "2017-09-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.05341",
        "title": "LoIDE: a web-based IDE for Logic Programming - Preliminary Technical Report",
        "authors": [
            "Stefano Germano",
            "Francesco Calimeri",
            "Eliana Palermiti"
        ],
        "abstract": "Logic-based paradigms are nowadays widely used in many different fields, also thank to the availability of robust tools and systems that allow the development of real-world and industrial applications.\n",
        "submission_date": "2017-09-15T00:00:00",
        "last_modified_date": "2017-09-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.05360",
        "title": "Embedding Deep Networks into Visual Explanations",
        "authors": [
            "Zhongang Qi",
            "Saeed Khorram",
            "Fuxin Li"
        ],
        "abstract": "In this paper, we propose a novel Explanation Neural Network (XNN) to explain the predictions made by a deep network. The XNN works by learning a nonlinear embedding of a high-dimensional activation vector of a deep network layer into a low-dimensional explanation space while retaining faithfulness i.e., the original deep learning predictions can be constructed from the few concepts extracted by our explanation network. We then visualize such concepts for human to learn about the high-level concepts that the deep network is using to make decisions. We propose an algorithm called Sparse Reconstruction Autoencoder (SRAE) for learning the embedding to the explanation space. SRAE aims to reconstruct part of the original feature space while retaining faithfulness. A pull-away term is applied to SRAE to make the bases of the explanation space more orthogonal to each other. A visualization system is then introduced for human understanding of the features in the explanation space. The proposed method is applied to explain CNN models in image classification tasks. We conducted a human study, which shows that the proposed approach outperforms single saliency map baselines, and improves human performance on a difficult classification tasks. Also, several novel metrics are introduced to evaluate the performance of explanations quantitatively without human involvement.\n    ",
        "submission_date": "2017-09-15T00:00:00",
        "last_modified_date": "2020-12-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.05436",
        "title": "Scene-centric Joint Parsing of Cross-view Videos",
        "authors": [
            "Hang Qi",
            "Yuanlu Xu",
            "Tao Yuan",
            "Tianfu Wu",
            "Song-Chun Zhu"
        ],
        "abstract": "Cross-view video understanding is an important yet under-explored area in computer vision. In this paper, we introduce a joint parsing framework that integrates view-centric proposals into scene-centric parse graphs that represent a coherent scene-centric understanding of cross-view scenes. Our key observations are that overlapping fields of views embed rich appearance and geometry correlations and that knowledge fragments corresponding to individual vision tasks are governed by consistency constraints available in commonsense knowledge. The proposed joint parsing framework represents such correlations and constraints explicitly and generates semantic scene-centric parse graphs. Quantitative experiments show that scene-centric predictions in the parse graph outperform view-centric predictions.\n    ",
        "submission_date": "2017-09-16T00:00:00",
        "last_modified_date": "2018-02-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.05437",
        "title": "A Causal And-Or Graph Model for Visibility Fluent Reasoning in Tracking Interacting Objects",
        "authors": [
            "Yuanlu Xu",
            "Lei Qin",
            "Xiaobai Liu",
            "Jianwen Xie",
            "Song-Chun Zhu"
        ],
        "abstract": "Tracking humans that are interacting with the other subjects or environment remains unsolved in visual tracking, because the visibility of the human of interests in videos is unknown and might vary over time. In particular, it is still difficult for state-of-the-art human trackers to recover complete human trajectories in crowded scenes with frequent human interactions. In this work, we consider the visibility status of a subject as a fluent variable, whose change is mostly attributed to the subject's interaction with the surrounding, e.g., crossing behind another object, entering a building, or getting into a vehicle, etc. We introduce a Causal And-Or Graph (C-AOG) to represent the causal-effect relations between an object's visibility fluent and its activities, and develop a probabilistic graph model to jointly reason the visibility fluent change (e.g., from visible to invisible) and track humans in videos. We formulate this joint task as an iterative search of a feasible causal graph structure that enables fast search algorithm, e.g., dynamic programming method. We apply the proposed method on challenging video sequences to evaluate its capabilities of estimating visibility fluent changes of subjects and tracking subjects of interests over time. Results with comparisons demonstrate that our method outperforms the alternative trackers and can recover complete trajectories of humans in complicated scenarios with frequent human interactions.\n    ",
        "submission_date": "2017-09-16T00:00:00",
        "last_modified_date": "2018-03-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.05440",
        "title": "Process-oriented Iterative Multiple Alignment for Medical Process Mining",
        "authors": [
            "Shuhong Chen",
            "Sen Yang",
            "Moliang Zhou",
            "Randall S. Burd",
            "Ivan Marsic"
        ],
        "abstract": "Adapted from biological sequence alignment, trace alignment is a process mining technique used to visualize and analyze workflow data. Any analysis done with this method, however, is affected by the alignment quality. The best existing trace alignment techniques use progressive guide-trees to heuristically approximate the optimal alignment in O(N2L2) time. These algorithms are heavily dependent on the selected guide-tree metric, often return sum-of-pairs-score-reducing errors that interfere with interpretation, and are computationally intensive for large datasets. To alleviate these issues, we propose process-oriented iterative multiple alignment (PIMA), which contains specialized optimizations to better handle workflow data. We demonstrate that PIMA is a flexible framework capable of achieving better sum-of-pairs score than existing trace alignment algorithms in only O(NL2) time. We applied PIMA to analyzing medical workflow data, showing how iterative alignment can better represent the data and facilitate the extraction of insights from data visualization.\n    ",
        "submission_date": "2017-09-16T00:00:00",
        "last_modified_date": "2017-09-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.05576",
        "title": "SKOS Concepts and Natural Language Concepts: an Analysis of Latent Relationships in KOSs",
        "authors": [
            "Anna Mastora",
            "Manolis Peponakis",
            "Sarantos Kapidakis"
        ],
        "abstract": "The vehicle to represent Knowledge Organization Systems (KOSs) in the environment of the Semantic Web and linked data is the Simple Knowledge Organization System (SKOS). SKOS provides a way to assign a URI to each concept, and this URI functions as a surrogate for the concept. This fact makes of main concern the need to clarify the URIs' ontological meaning. The aim of this study is to investigate the relation between the ontological substance of KOS concepts and concepts revealed through the grammatical and syntactic formalisms of natural language. For this purpose, we examined the dividableness of concepts in specific KOSs (i.e. a thesaurus, a subject headings system and a classification scheme) by applying Natural Language Processing (NLP) techniques (i.e. morphosyntactic analysis) to the lexical representations (i.e. RDF literals) of SKOS concepts. The results of the comparative analysis reveal that, despite the use of multi-word units, thesauri tend to represent concepts in a way that can hardly be further divided conceptually, while Subject Headings and Classification Schemes - to a certain extent - comprise terms that can be decomposed into more conceptual constituents. Consequently, SKOS concepts deriving from thesauri are more likely to represent atomic conceptual units and thus be more appropriate tools for inference and reasoning. Since identifiers represent the meaning of a concept, complex concepts are neither the most appropriate nor the most efficient way of modelling a KOS for the Semantic Web.\n    ",
        "submission_date": "2017-09-16T00:00:00",
        "last_modified_date": "2017-09-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.05666",
        "title": "On Inductive Abilities of Latent Factor Models for Relational Learning",
        "authors": [
            "Th\u00e9o Trouillon",
            "\u00c9ric Gaussier",
            "Christopher R. Dance",
            "Guillaume Bouchard"
        ],
        "abstract": "Latent factor models are increasingly popular for modeling multi-relational knowledge graphs. By their vectorial nature, it is not only hard to interpret why this class of models works so well, but also to understand where they fail and how they might be improved. We conduct an experimental survey of state-of-the-art models, not towards a purely comparative end, but as a means to get insight about their inductive abilities. To assess the strengths and weaknesses of each model, we create simple tasks that exhibit first, atomic properties of binary relations, and then, common inter-relational inference through synthetic genealogies. Based on these experimental results, we propose new research directions to improve on existing models.\n    ",
        "submission_date": "2017-09-17T00:00:00",
        "last_modified_date": "2017-09-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.05746",
        "title": "Adversarial Discriminative Sim-to-real Transfer of Visuo-motor Policies",
        "authors": [
            "Fangyi Zhang",
            "J\u00fcrgen Leitner",
            "Zongyuan Ge",
            "Michael Milford",
            "Peter Corke"
        ],
        "abstract": "Various approaches have been proposed to learn visuo-motor policies for real-world robotic applications. One solution is first learning in simulation then transferring to the real world. In the transfer, most existing approaches need real-world images with labels. However, the labelling process is often expensive or even impractical in many robotic applications. In this paper, we propose an adversarial discriminative sim-to-real transfer approach to reduce the cost of labelling real data. The effectiveness of the approach is demonstrated with modular networks in a table-top object reaching task where a 7 DoF arm is controlled in velocity mode to reach a blue cuboid in clutter through visual observations. The adversarial transfer approach reduced the labelled real data requirement by 50%. Policies can be transferred to real environments with only 93 labelled and 186 unlabelled real images. The transferred visuo-motor policies are robust to novel (not seen in training) objects in clutter and even a moving target, achieving a 97.8% success rate and 1.8 cm control accuracy.\n    ",
        "submission_date": "2017-09-18T00:00:00",
        "last_modified_date": "2018-05-31T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.05774",
        "title": "Direction-Aware Semi-Dense SLAM",
        "authors": [
            "Julian Straub",
            "Randi Cabezas",
            "John Leonard",
            "John W. Fisher III"
        ],
        "abstract": "To aide simultaneous localization and mapping (SLAM), future perception systems will incorporate forms of scene understanding. In a step towards fully integrated probabilistic geometric scene understanding, localization and mapping we propose the first direction-aware semi-dense SLAM system. It jointly infers the directional Stata Center World (SCW) segmentation and a surfel-based semi-dense map while performing real-time camera tracking. The joint SCW map model connects a scene-wide Bayesian nonparametric Dirichlet Process von-Mises-Fisher mixture model (DP-vMF) prior on surfel orientations with the local surfel locations via a conditional random field (CRF). Camera tracking leverages the SCW segmentation to improve efficiency via guided observation selection. Results demonstrate improved SLAM accuracy and tracking efficiency at state of the art performance.\n    ",
        "submission_date": "2017-09-18T00:00:00",
        "last_modified_date": "2017-09-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.05870",
        "title": "ZhuSuan: A Library for Bayesian Deep Learning",
        "authors": [
            "Jiaxin Shi",
            "Jianfei Chen",
            "Jun Zhu",
            "Shengyang Sun",
            "Yucen Luo",
            "Yihong Gu",
            "Yuhao Zhou"
        ],
        "abstract": "In this paper we introduce ZhuSuan, a python probabilistic programming library for Bayesian deep learning, which conjoins the complimentary advantages of Bayesian methods and deep learning. ZhuSuan is built upon Tensorflow. Unlike existing deep learning libraries, which are mainly designed for deterministic neural networks and supervised tasks, ZhuSuan is featured for its deep root into Bayesian inference, thus supporting various kinds of probabilistic models, including both the traditional hierarchical Bayesian models and recent deep generative models. We use running examples to illustrate the probabilistic programming on ZhuSuan, including Bayesian logistic regression, variational auto-encoders, deep sigmoid belief networks and Bayesian recurrent neural networks.\n    ",
        "submission_date": "2017-09-18T00:00:00",
        "last_modified_date": "2017-09-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.05915",
        "title": "Push and Pull Search for Solving Constrained Multi-objective Optimization Problems",
        "authors": [
            "Zhun Fan",
            "Wenji Li",
            "Xinye Cai",
            "Hui Li",
            "Caimin Wei",
            "Qingfu Zhang",
            "Kalyanmoy Deb",
            "Erik D. Goodman"
        ],
        "abstract": "This paper proposes a push and pull search (PPS) framework for solving constrained multi-objective optimization problems (CMOPs). To be more specific, the proposed PPS divides the search process into two different stages, including the push and pull search stages. In the push stage, a multi-objective evolutionary algorithm (MOEA) is adopted to explore the search space without considering any constraints, which can help to get across infeasible regions very fast and approach the unconstrained Pareto front. Furthermore, the landscape of CMOPs with constraints can be probed and estimated in the push stage, which can be utilized to conduct the parameters setting for constraint-handling approaches applied in the pull stage. Then, a constrained multi-objective evolutionary algorithm (CMOEA) equipped with an improved epsilon constraint-handling is applied to pull the infeasible individuals achieved in the push stage to the feasible and non-dominated regions. Compared with other CMOEAs, the proposed PPS method can more efficiently get across infeasible regions and converge to the feasible and non-dominated regions by applying push and pull search strategies at different stages. To evaluate the performance regarding convergence and diversity, a set of benchmark CMOPs is used to test the proposed PPS and compare with other five CMOEAs, including MOEA/D-CDP, MOEA/D-SR, C-MOEA/D, MOEA/D-Epsilon and MOEA/D-IEpsilon. The comprehensive experimental results demonstrate that the proposed PPS achieves significantly better or competitive performance than the other five CMOEAs on most of the benchmark set.\n    ",
        "submission_date": "2017-09-15T00:00:00",
        "last_modified_date": "2017-09-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.05943",
        "title": "Fast YOLO: A Fast You Only Look Once System for Real-time Embedded Object Detection in Video",
        "authors": [
            "Mohammad Javad Shafiee",
            "Brendan Chywl",
            "Francis Li",
            "Alexander Wong"
        ],
        "abstract": "Object detection is considered one of the most challenging problems in this field of computer vision, as it involves the combination of object classification and object localization within a scene. Recently, deep neural networks (DNNs) have been demonstrated to achieve superior object detection performance compared to other approaches, with YOLOv2 (an improved You Only Look Once model) being one of the state-of-the-art in DNN-based object detection methods in terms of both speed and accuracy. Although YOLOv2 can achieve real-time performance on a powerful GPU, it still remains very challenging for leveraging this approach for real-time object detection in video on embedded computing devices with limited computational power and limited memory. In this paper, we propose a new framework called Fast YOLO, a fast You Only Look Once framework which accelerates YOLOv2 to be able to perform object detection in video on embedded devices in a real-time manner. First, we leverage the evolutionary deep intelligence framework to evolve the YOLOv2 network architecture and produce an optimized architecture (referred to as O-YOLOv2 here) that has 2.8X fewer parameters with just a ~2% IOU drop. To further reduce power consumption on embedded devices while maintaining performance, a motion-adaptive inference method is introduced into the proposed Fast YOLO framework to reduce the frequency of deep inference with O-YOLOv2 based on temporal motion characteristics. Experimental results show that the proposed Fast YOLO framework can reduce the number of deep inferences by an average of 38.13%, and an average speedup of ~3.3X for objection detection in video compared to the original YOLOv2, leading Fast YOLO to run an average of ~18FPS on a Nvidia Jetson TX1 embedded system.\n    ",
        "submission_date": "2017-09-18T00:00:00",
        "last_modified_date": "2017-09-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.05976",
        "title": "Leveraging Distributional Semantics for Multi-Label Learning",
        "authors": [
            "Rahul Wadbude",
            "Vivek Gupta",
            "Piyush Rai",
            "Nagarajan Natarajan",
            "Harish Karnick",
            "Prateek Jain"
        ],
        "abstract": "We present a novel and scalable label embedding framework for large-scale multi-label learning a.k.a ExMLDS (Extreme Multi-Label Learning using Distributional Semantics). Our approach draws inspiration from ideas rooted in distributional semantics, specifically the Skip Gram Negative Sampling (SGNS) approach, widely used to learn word embeddings for natural language processing tasks. Learning such embeddings can be reduced to a certain matrix factorization. Our approach is novel in that it highlights interesting connections between label embedding methods used for multi-label learning and paragraph/document embedding methods commonly used for learning representations of text data. The framework can also be easily extended to incorporate auxiliary information such as label-label correlations; this is crucial especially when there are a lot of missing labels in the training data. We demonstrate the effectiveness of our approach through an extensive set of experiments on a variety of benchmark datasets, and show that the proposed learning methods perform favorably compared to several baselines and state-of-the-art methods for large-scale multi-label learning. To facilitate end-to-end learning, we develop a joint learning algorithm that can learn the embeddings as well as a regression model that predicts these embeddings given input features, via efficient gradient-based methods.\n    ",
        "submission_date": "2017-09-18T00:00:00",
        "last_modified_date": "2017-11-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.06011",
        "title": "Guided Deep Reinforcement Learning for Swarm Systems",
        "authors": [
            "Maximilian H\u00fcttenrauch",
            "Adrian \u0160o\u0161i\u0107",
            "Gerhard Neumann"
        ],
        "abstract": "In this paper, we investigate how to learn to control a group of cooperative agents with limited sensing capabilities such as robot swarms. The agents have only very basic sensor capabilities, yet in a group they can accomplish sophisticated tasks, such as distributed assembly or search and rescue tasks. Learning a policy for a group of agents is difficult due to distributed partial observability of the state. Here, we follow a guided approach where a critic has central access to the global state during learning, which simplifies the policy evaluation problem from a reinforcement learning point of view. For example, we can get the positions of all robots of the swarm using a camera image of a scene. This camera image is only available to the critic and not to the control policies of the robots. We follow an actor-critic approach, where the actors base their decisions only on locally sensed information. In contrast, the critic is learned based on the true global state. Our algorithm uses deep reinforcement learning to approximate both the Q-function and the policy. The performance of the algorithm is evaluated on two tasks with simple simulated 2D agents: 1) finding and maintaining a certain distance to each others and 2) locating a target.\n    ",
        "submission_date": "2017-09-18T00:00:00",
        "last_modified_date": "2017-09-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.06075",
        "title": "Deep Graph Attention Model",
        "authors": [
            "John Boaz Lee",
            "Ryan Rossi",
            "Xiangnan Kong"
        ],
        "abstract": "Graph classification is a problem with practical applications in many different domains. Most of the existing methods take the entire graph into account when calculating graph features. In a graphlet-based approach, for instance, the entire graph is processed to get the total count of different graphlets or sub-graphs. In the real-world, however, graphs can be both large and noisy with discriminative patterns confined to certain regions in the graph only. In this work, we study the problem of attentional processing for graph classification. The use of attention allows us to focus on small but informative parts of the graph, avoiding noise in the rest of the graph. We present a novel RNN model, called the Graph Attention Model (GAM), that processes only a portion of the graph by adaptively selecting a sequence of \"interesting\" nodes. The model is equipped with an external memory component which allows it to integrate information gathered from different parts of the graph. We demonstrate the effectiveness of the model through various experiments.\n    ",
        "submission_date": "2017-09-15T00:00:00",
        "last_modified_date": "2017-09-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.06080",
        "title": "Feedforward and Recurrent Neural Networks Backward Propagation and Hessian in Matrix Form",
        "authors": [
            "Maxim Naumov"
        ],
        "abstract": "In this paper we focus on the linear algebra theory behind feedforward (FNN) and recurrent (RNN) neural networks. We review backward propagation, including backward propagation through time (BPTT). Also, we obtain a new exact expression for Hessian, which represents second order effects. We show that for $t$ time steps the weight gradient can be expressed as a rank-$t$ matrix, while the weight Hessian is as a sum of $t^{2}$ Kronecker products of rank-$1$ and $W^{T}AW$ matrices, for some matrix $A$ and weight matrix $W$. Also, we show that for a mini-batch of size $r$, the weight update can be expressed as a rank-$rt$ matrix. Finally, we briefly comment on the eigenvalues of the Hessian matrix.\n    ",
        "submission_date": "2017-09-16T00:00:00",
        "last_modified_date": "2017-09-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.06129",
        "title": "When is a Convolutional Filter Easy To Learn?",
        "authors": [
            "Simon S. Du",
            "Jason D. Lee",
            "Yuandong Tian"
        ],
        "abstract": "We analyze the convergence of (stochastic) gradient descent algorithm for learning a convolutional filter with Rectified Linear Unit (ReLU) activation function. Our analysis does not rely on any specific form of the input distribution and our proofs only use the definition of ReLU, in contrast with previous works that are restricted to standard Gaussian input. We show that (stochastic) gradient descent with random initialization can learn the convolutional filter in polynomial time and the convergence rate depends on the smoothness of the input distribution and the closeness of patches. To the best of our knowledge, this is the first recovery guarantee of gradient-based algorithms for convolutional filter on non-Gaussian input distributions. Our theory also justifies the two-stage learning rate strategy in deep neural networks. While our focus is theoretical, we also present experiments that illustrate our theoretical findings.\n    ",
        "submission_date": "2017-09-18T00:00:00",
        "last_modified_date": "2018-02-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.06138",
        "title": "Model-Powered Conditional Independence Test",
        "authors": [
            "Rajat Sen",
            "Ananda Theertha Suresh",
            "Karthikeyan Shanmugam",
            "Alexandros G. Dimakis",
            "Sanjay Shakkottai"
        ],
        "abstract": "We consider the problem of non-parametric Conditional Independence testing (CI testing) for continuous random variables. Given i.i.d samples from the joint distribution $f(x,y,z)$ of continuous random vectors $X,Y$ and $Z,$ we determine whether $X \\perp Y | Z$. We approach this by converting the conditional independence test into a classification problem. This allows us to harness very powerful classifiers like gradient-boosted trees and deep neural networks. These models can handle complex probability distributions and allow us to perform significantly better compared to the prior state of the art, for high-dimensional CI testing. The main technical challenge in the classification problem is the need for samples from the conditional product distribution $f^{CI}(x,y,z) = f(x|z)f(y|z)f(z)$ -- the joint distribution if and only if $X \\perp Y | Z.$ -- when given access only to i.i.d. samples from the true joint distribution $f(x,y,z)$. To tackle this problem we propose a novel nearest neighbor bootstrap procedure and theoretically show that our generated samples are indeed close to $f^{CI}$ in terms of total variational distance. We then develop theoretical results regarding the generalization bounds for classification for our problem, which translate into error bounds for CI testing. We provide a novel analysis of Rademacher type classification bounds in the presence of non-i.i.d near-independent samples. We empirically validate the performance of our algorithm on simulated and real datasets and show performance gains over previous methods.\n    ",
        "submission_date": "2017-09-18T00:00:00",
        "last_modified_date": "2017-09-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.06172",
        "title": "On the Complexity of Robust Stable Marriage",
        "authors": [
            "Begum Genc",
            "Mohamed Siala",
            "Gilles Simonin",
            "Barry O'Sullivan"
        ],
        "abstract": "Robust Stable Marriage (RSM) is a variant of the classical Stable Marriage problem, where the robustness of a given stable matching is measured by the number of modifications required for repairing it in case an unforeseen event occurs. We focus on the complexity of finding an (a,b)-supermatch. An (a,b)-supermatch is defined as a stable matching in which if any 'a' (non-fixed) men/women break up it is possible to find another stable matching by changing the partners of those 'a' men/women and also the partners of at most 'b' other couples. In order to show deciding if there exists an (a,b)-supermatch is NP-Complete, we first introduce a SAT formulation that is NP-Complete by using Schaefer's Dichotomy Theorem. Then, we show the equivalence between the SAT formulation and finding a (1,1)-supermatch on a specific family of instances.\n    ",
        "submission_date": "2017-09-18T00:00:00",
        "last_modified_date": "2022-04-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.06202",
        "title": "A Comparative Quantitative Analysis of Contemporary Big Data Clustering Algorithms for Market Segmentation in Hospitality Industry",
        "authors": [
            "Avishek Bose",
            "Arslan Munir",
            "Neda Shabani"
        ],
        "abstract": "The hospitality industry is one of the data-rich industries that receives huge Volumes of data streaming at high Velocity with considerably Variety, Veracity, and Variability. These properties make the data analysis in the hospitality industry a big data problem. Meeting the customers' expectations is a key factor in the hospitality industry to grasp the customers' loyalty. To achieve this goal, marketing professionals in this industry actively look for ways to utilize their data in the best possible manner and advance their data analytic solutions, such as identifying a unique market segmentation clustering and developing a recommendation system. In this paper, we present a comprehensive literature review of existing big data clustering algorithms and their advantages and disadvantages for various use cases. We implement the existing big data clustering algorithms and provide a quantitative comparison of the performance of different clustering algorithms for different scenarios. We also present our insights and recommendations regarding the suitability of different big data clustering algorithms for different use cases. These recommendations will be helpful for hoteliers in selecting the appropriate market segmentation clustering algorithm for different clustering datasets to improve the customer experience and maximize the hotel revenue.\n    ",
        "submission_date": "2017-09-18T00:00:00",
        "last_modified_date": "2017-09-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.06293",
        "title": "Sparse Markov Decision Processes with Causal Sparse Tsallis Entropy Regularization for Reinforcement Learning",
        "authors": [
            "Kyungjae Lee",
            "Sungjoon Choi",
            "Songhwai Oh"
        ],
        "abstract": "In this paper, a sparse Markov decision process (MDP) with novel causal sparse Tsallis entropy regularization is ",
        "submission_date": "2017-09-19T00:00:00",
        "last_modified_date": "2017-10-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.06298",
        "title": "MuseGAN: Multi-track Sequential Generative Adversarial Networks for Symbolic Music Generation and Accompaniment",
        "authors": [
            "Hao-Wen Dong",
            "Wen-Yi Hsiao",
            "Li-Chia Yang",
            "Yi-Hsuan Yang"
        ],
        "abstract": "Generating music has a few notable differences from generating images and videos. First, music is an art of time, necessitating a temporal model. Second, music is usually composed of multiple instruments/tracks with their own temporal dynamics, but collectively they unfold over time interdependently. Lastly, musical notes are often grouped into chords, arpeggios or melodies in polyphonic music, and thereby introducing a chronological ordering of notes is not naturally suitable. In this paper, we propose three models for symbolic multi-track music generation under the framework of generative adversarial networks (GANs). The three models, which differ in the underlying assumptions and accordingly the network architectures, are referred to as the jamming model, the composer model and the hybrid model. We trained the proposed models on a dataset of over one hundred thousand bars of rock music and applied them to generate piano-rolls of five tracks: bass, drums, guitar, piano and strings. A few intra-track and inter-track objective metrics are also proposed to evaluate the generative results, in addition to a subjective user study. We show that our models can generate coherent music of four bars right from scratch (i.e. without human inputs). We also extend our models to human-AI cooperative music generation: given a specific track composed by human, we can generate four additional tracks to accompany it. All code, the dataset and the rendered audio samples are available at ",
        "submission_date": "2017-09-19T00:00:00",
        "last_modified_date": "2017-11-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.06533",
        "title": "Summable Reparameterizations of Wasserstein Critics in the One-Dimensional Setting",
        "authors": [
            "Christopher Grimm",
            "Yuhang Song",
            "Michael L. Littman"
        ],
        "abstract": "Generative adversarial networks (GANs) are an exciting alternative to algorithms for solving density estimation problems---using data to assess how likely samples are to be drawn from the same distribution. Instead of explicitly computing these probabilities, GANs learn a generator that can match the given probabilistic source. This paper looks particularly at this matching capability in the context of problems with one-dimensional outputs. We identify a class of function decompositions with properties that make them well suited to the critic role in a leading approach to GANs known as Wasserstein GANs. We show that Taylor and Fourier series decompositions belong to our class, provide examples of these critics outperforming standard GAN approaches, and suggest how they can be scaled to higher dimensional problems in the future.\n    ",
        "submission_date": "2017-09-19T00:00:00",
        "last_modified_date": "2017-09-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.06620",
        "title": "Learning of Coordination Policies for Robotic Swarms",
        "authors": [
            "Qiyang Li",
            "Xintong Du",
            "Yizhou Huang",
            "Quinlan Sykora",
            "Angela P. Schoellig"
        ],
        "abstract": "Inspired by biological swarms, robotic swarms are envisioned to solve real-world problems that are difficult for individual agents. Biological swarms can achieve collective intelligence based on local interactions and simple rules; however, designing effective distributed policies for large-scale robotic swarms to achieve a global objective can be challenging. Although it is often possible to design an optimal centralized strategy for smaller numbers of agents, those methods can fail as the number of agents increases. Motivated by the growing success of machine learning, we develop a deep learning approach that learns distributed coordination policies from centralized policies. In contrast to traditional distributed control approaches, which are usually based on human-designed policies for relatively simple tasks, this learning-based approach can be adapted to more difficult tasks. We demonstrate the efficacy of our proposed approach on two different tasks, the well-known rendezvous problem and a more difficult particle assignment problem. For the latter, no known distributed policy exists. From extensive simulations, it is shown that the performance of the learned coordination policies is comparable to the centralized policies, surpassing state-of-the-art distributed policies. Thereby, our proposed approach provides a promising alternative for real-world coordination problems that would be otherwise computationally expensive to solve or intangible to explore.\n    ",
        "submission_date": "2017-09-19T00:00:00",
        "last_modified_date": "2017-09-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.06662",
        "title": "Verifying Properties of Binarized Deep Neural Networks",
        "authors": [
            "Nina Narodytska",
            "Shiva Prasad Kasiviswanathan",
            "Leonid Ryzhyk",
            "Mooly Sagiv",
            "Toby Walsh"
        ],
        "abstract": "Understanding properties of deep neural networks is an important challenge in deep learning. In this paper, we take a step in this direction by proposing a rigorous way of verifying properties of a popular class of neural networks, Binarized Neural Networks, using the well-developed means of Boolean satisfiability. Our main contribution is a construction that creates a representation of a binarized neural network as a Boolean formula. Our encoding is the first exact Boolean representation of a deep neural network. Using this encoding, we leverage the power of modern SAT solvers along with a proposed counterexample-guided search procedure to verify various properties of these networks. A particular focus will be on the critical property of robustness to adversarial perturbations. For this property, our experimental results demonstrate that our approach scales to medium-size deep neural networks used in image classification tasks. To the best of our knowledge, this is the first work on verifying properties of deep neural networks using an exact Boolean encoding of the network.\n    ",
        "submission_date": "2017-09-19T00:00:00",
        "last_modified_date": "2018-05-31T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.06673",
        "title": "Why PairDiff works? -- A Mathematical Analysis of Bilinear Relational Compositional Operators for Analogy Detection",
        "authors": [
            "Huda Hakami",
            "Danushka Bollegala",
            "Hayashi Kohei"
        ],
        "abstract": "Representing the semantic relations that exist between two given words (or entities) is an important first step in a wide-range of NLP applications such as analogical reasoning, knowledge base completion and relational information retrieval. A simple, yet surprisingly accurate method for representing a relation between two words is to compute the vector offset (\\PairDiff) between their corresponding word embeddings. Despite the empirical success, it remains unclear as to whether \\PairDiff is the best operator for obtaining a relational representation from word embeddings. We conduct a theoretical analysis of generalised bilinear operators that can be used to measure the $\\ell_{2}$ relational distance between two word-pairs. We show that, if the word embeddings are standardised and uncorrelated, such an operator will be independent of bilinear terms, and can be simplified to a linear form, where \\PairDiff is a special case. For numerous word embedding types, we empirically verify the uncorrelation assumption, demonstrating the general applicability of our theoretical result. Moreover, we experimentally discover \\PairDiff from the bilinear relation composition operator on several benchmark analogy datasets.\n    ",
        "submission_date": "2017-09-19T00:00:00",
        "last_modified_date": "2017-12-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.06871",
        "title": "Open Source Dataset and Deep Learning Models for Online Digit Gesture Recognition on Touchscreens",
        "authors": [
            "Philip J. Corr",
            "Guenole C. Silvestre",
            "Chris J. Bleakley"
        ],
        "abstract": "This paper presents an evaluation of deep neural networks for recognition of digits entered by users on a smartphone touchscreen. A new large dataset of Arabic numerals was collected for training and evaluation of the network. The dataset consists of spatial and temporal touch data recorded for 80 digits entered by 260 users. Two neural network models were investigated. The first model was a 2D convolutional neural (ConvNet) network applied to bitmaps of the glpyhs created by interpolation of the sensed screen touches and its topology is similar to that of previously published models for offline handwriting recognition from scanned images. The second model used a 1D ConvNet architecture but was applied to the sequence of polar vectors connecting the touch points. The models were found to provide accuracies of 98.50% and 95.86%, respectively. The second model was much simpler, providing a reduction in the number of parameters from 1,663,370 to 287,690. The dataset has been made available to the community as an open source resource.\n    ",
        "submission_date": "2017-09-20T00:00:00",
        "last_modified_date": "2017-09-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.06907",
        "title": "Doctoral Advisor or Medical Condition: Towards Entity-specific Rankings of Knowledge Base Properties [Extended Version]",
        "authors": [
            "Simon Razniewski",
            "Vevake Balaraman",
            "Werner Nutt"
        ],
        "abstract": "In knowledge bases such as Wikidata, it is possible to assert a large set of properties for entities, ranging from generic ones such as name and place of birth to highly profession-specific or background-specific ones such as doctoral advisor or medical condition. Determining a preference or ranking in this large set is a challenge in tasks such as prioritisation of edits or natural-language generation. Most previous approaches to ranking knowledge base properties are purely data-driven, that is, as we show, mistake frequency for interestingness.\n",
        "submission_date": "2017-09-20T00:00:00",
        "last_modified_date": "2017-09-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.06917",
        "title": "Using Parameterized Black-Box Priors to Scale Up Model-Based Policy Search for Robotics",
        "authors": [
            "Konstantinos Chatzilygeroudis",
            "Jean-Baptiste Mouret"
        ],
        "abstract": "The most data-efficient algorithms for reinforcement learning in robotics are model-based policy search algorithms, which alternate between learning a dynamical model of the robot and optimizing a policy to maximize the expected return given the model and its uncertainties. Among the few proposed approaches, the recently introduced Black-DROPS algorithm exploits a black-box optimization algorithm to achieve both high data-efficiency and good computation times when several cores are used; nevertheless, like all model-based policy search approaches, Black-DROPS does not scale to high dimensional state/action spaces. In this paper, we introduce a new model learning procedure in Black-DROPS that leverages parameterized black-box priors to (1) scale up to high-dimensional systems, and (2) be robust to large inaccuracies of the prior information. We demonstrate the effectiveness of our approach with the \"pendubot\" swing-up task in simulation and with a physical hexapod robot (48D state space, 18D action space) that has to walk forward as fast as possible. The results show that our new algorithm is more data-efficient than previous model-based policy search algorithms (with and without priors) and that it can allow a physical 6-legged robot to learn new gaits in only 16 to 30 seconds of interaction time.\n    ",
        "submission_date": "2017-09-20T00:00:00",
        "last_modified_date": "2018-03-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.06919",
        "title": "Bayesian Optimization with Automatic Prior Selection for Data-Efficient Direct Policy Search",
        "authors": [
            "R\u00e9mi Pautrat",
            "Konstantinos Chatzilygeroudis",
            "Jean-Baptiste Mouret"
        ],
        "abstract": "One of the most interesting features of Bayesian optimization for direct policy search is that it can leverage priors (e.g., from simulation or from previous tasks) to accelerate learning on a robot. In this paper, we are interested in situations for which several priors exist but we do not know in advance which one fits best the current situation. We tackle this problem by introducing a novel acquisition function, called Most Likely Expected Improvement (MLEI), that combines the likelihood of the priors and the expected improvement. We evaluate this new acquisition function on a transfer learning task for a 5-DOF planar arm and on a possibly damaged, 6-legged robot that has to learn to walk on flat ground and on stairs, with priors corresponding to different stairs and different kinds of damages. Our results show that MLEI effectively identifies and exploits the priors, even when there is no obvious match between the current situations and the priors.\n    ",
        "submission_date": "2017-09-20T00:00:00",
        "last_modified_date": "2018-03-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.06990",
        "title": "Text Compression for Sentiment Analysis via Evolutionary Algorithms",
        "authors": [
            "Emmanuel Dufourq",
            "Bruce A. Bassett"
        ],
        "abstract": "Can textual data be compressed intelligently without losing accuracy in evaluating sentiment? In this study, we propose a novel evolutionary compression algorithm, PARSEC (PARts-of-Speech for sEntiment Compression), which makes use of Parts-of-Speech tags to compress text in a way that sacrifices minimal classification accuracy when used in conjunction with sentiment analysis algorithms. An analysis of PARSEC with eight commercial and non-commercial sentiment analysis algorithms on twelve English sentiment data sets reveals that accurate compression is possible with (0%, 1.3%, 3.3%) loss in sentiment classification accuracy for (20%, 50%, 75%) data compression with PARSEC using LingPipe, the most accurate of the sentiment algorithms. Other sentiment analysis algorithms are more severely affected by compression. We conclude that significant compression of text data is possible for sentiment analysis depending on the accuracy demands of the specific application and the specific sentiment analysis algorithm used.\n    ",
        "submission_date": "2017-09-20T00:00:00",
        "last_modified_date": "2017-09-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.07080",
        "title": "A Deep-Reinforcement Learning Approach for Software-Defined Networking Routing Optimization",
        "authors": [
            "Giorgio Stampa",
            "Marta Arias",
            "David Sanchez-Charles",
            "Victor Muntes-Mulero",
            "Albert Cabellos"
        ],
        "abstract": "In this paper we design and evaluate a Deep-Reinforcement Learning agent that optimizes routing. Our agent adapts automatically to current traffic conditions and proposes tailored configurations that attempt to minimize the network delay. Experiments show very promising performance. Moreover, this approach provides important operational advantages with respect to traditional optimization algorithms.\n    ",
        "submission_date": "2017-09-20T00:00:00",
        "last_modified_date": "2017-09-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.07095",
        "title": "Practical Machine Learning for Cloud Intrusion Detection: Challenges and the Way Forward",
        "authors": [
            "Ram Shankar Siva Kumar",
            "Andrew Wicker",
            "Matt Swann"
        ],
        "abstract": "Operationalizing machine learning based security detections is extremely challenging, especially in a continuously evolving cloud environment. Conventional anomaly detection does not produce satisfactory results for analysts that are investigating security incidents in the cloud. Model evaluation alone presents its own set of problems due to a lack of benchmark datasets. When deploying these detections, we must deal with model compliance, localization, and data silo issues, among many others. We pose the problem of \"attack disruption\" as a way forward in the security data science space. In this paper, we describe the framework, challenges, and open questions surrounding the successful operationalization of machine learning based security detections in a cloud environment and provide some insights on how we have addressed them.\n    ",
        "submission_date": "2017-09-20T00:00:00",
        "last_modified_date": "2017-09-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.07223",
        "title": "Convolutional neural networks that teach microscopes how to image",
        "authors": [
            "Roarke Horstmeyer",
            "Richard Y. Chen",
            "Barbara Kappes",
            "Benjamin Judkewitz"
        ],
        "abstract": "Deep learning algorithms offer a powerful means to automatically analyze the content of medical images. However, many biological samples of interest are primarily transparent to visible light and contain features that are difficult to resolve with a standard optical microscope. Here, we use a convolutional neural network (CNN) not only to classify images, but also to optimize the physical layout of the imaging device itself. We increase the classification accuracy of a microscope's recorded images by merging an optical model of image formation into the pipeline of a CNN. The resulting network simultaneously determines an ideal illumination arrangement to highlight important sample features during image acquisition, along with a set of convolutional weights to classify the detected images post-capture. We demonstrate our joint optimization technique with an experimental microscope configuration that automatically identifies malaria-infected cells with 5-10% higher accuracy than standard and alternative microscope lighting designs.\n    ",
        "submission_date": "2017-09-21T00:00:00",
        "last_modified_date": "2017-09-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.07224",
        "title": "Local Communication Protocols for Learning Complex Swarm Behaviors with Deep Reinforcement Learning",
        "authors": [
            "Maximilian H\u00fcttenrauch",
            "Adrian \u0160o\u0161i\u0107",
            "Gerhard Neumann"
        ],
        "abstract": "Swarm systems constitute a challenging problem for reinforcement learning (RL) as the algorithm needs to learn decentralized control policies that can cope with limited local sensing and communication abilities of the agents. While it is often difficult to directly define the behavior of the agents, simple communication protocols can be defined more easily using prior knowledge about the given task. In this paper, we propose a number of simple communication protocols that can be exploited by deep reinforcement learning to find decentralized control policies in a multi-robot swarm environment. The protocols are based on histograms that encode the local neighborhood relations of the agents and can also transmit task-specific information, such as the shortest distance and direction to a desired target. In our framework, we use an adaptation of Trust Region Policy Optimization to learn complex collaborative tasks, such as formation building and building a communication link. We evaluate our findings in a simulated 2D-physics environment, and compare the implications of different communication protocols.\n    ",
        "submission_date": "2017-09-21T00:00:00",
        "last_modified_date": "2018-07-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.07314",
        "title": "Exact Learning of Lightweight Description Logic Ontologies",
        "authors": [
            "Boris Konev",
            "Carsten Lutz",
            "Ana Ozaki",
            "Frank Wolter"
        ],
        "abstract": "We study the problem of learning description logic (DL) ontologies in Angluin et al.'s framework of exact learning via queries. We admit membership queries (\"is a given subsumption entailed by the target ontology?\") and equivalence queries (\"is a given ontology equivalent to the target ontology?\"). We present three main results: (1) ontologies formulated in (two relevant versions of) the description logic DL-Lite can be learned with polynomially many queries of polynomial size; (2) this is not the case for ontologies formulated in the description logic EL, even when only acyclic ontologies are admitted; and (3) ontologies formulated in a fragment of EL related to the web ontology language OWL 2 RL can be learned in polynomial time. We also show that neither membership nor equivalence queries alone are sufficient in cases (1) and (3).\n    ",
        "submission_date": "2017-09-20T00:00:00",
        "last_modified_date": "2017-09-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.07358",
        "title": "Non-Depth-First Search against Independent Distributions on an AND-OR Tree",
        "authors": [
            "Toshio Suzuki"
        ],
        "abstract": "Suzuki and Niida (Ann. Pure. Appl. Logic, 2015) showed the following results on independent distributions (IDs) on an AND-OR tree, where they took only depth-first algorithms into consideration. (1) Among IDs such that probability of the root having value 0 is fixed as a given r such that 0 < r < 1, if d is a maximizer of cost of the best algorithm then d is an independent and identical distribution (IID). (2) Among all IDs, if d is a maximizer of cost of the best algorithm then d is an IID. In the case where non-depth-first algorithms are taken into consideration, the counter parts of (1) and (2) are left open in the above work. Peng et al. (Inform. Process. Lett., 2017) extended (1) and (2) to multi-branching trees, where in (2) they put an additional hypothesis on IDs that probability of the root having value 0 is neither 0 nor 1. We give positive answers for the two questions of Suzuki-Niida. A key to the proof is that if ID d achieves the equilibrium among IDs then we can chose an algorithm of the best cost against d from depth-first algorithms. In addition, we extend the result of Peng et al. to the case where non-depth-first algorithms are taken into consideration.\n    ",
        "submission_date": "2017-09-21T00:00:00",
        "last_modified_date": "2017-09-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.07401",
        "title": "Influence of Personal Preferences on Link Dynamics in Social Networks",
        "authors": [
            "Ashwin Bahulkar",
            "Boleslaw K. Szymanski",
            "Nitesh Chawla",
            "Omar Lizardo",
            "Kevin Chan"
        ],
        "abstract": "We study a unique network dataset including periodic surveys and electronic logs of dyadic contacts via smartphones. The participants were a sample of freshmen entering university in the Fall 2011. Their opinions on a variety of political and social issues and lists of activities on campus were regularly recorded at the beginning and end of each semester for the first three years of study. We identify a behavioral network defined by call and text data, and a cognitive network based on friendship nominations in ego-network surveys. Both networks are limited to study participants. Since a wide range of attributes on each node were collected in self-reports, we refer to these networks as attribute-rich networks. We study whether student preferences for certain attributes of friends can predict formation and dissolution of edges in both networks. We introduce a method for computing student preferences for different attributes which we use to predict link formation and dissolution. We then rank these attributes according to their importance for making predictions. We find that personal preferences, in particular political views, and preferences for common activities help predict link formation and dissolution in both the behavioral and cognitive networks.\n    ",
        "submission_date": "2017-09-21T00:00:00",
        "last_modified_date": "2017-09-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.07480",
        "title": "Complexity of Scheduling Charging in the Smart Grid",
        "authors": [
            "Mathijs de Weerdt",
            "Michael Albert",
            "Vincent Conitzer"
        ],
        "abstract": "In the smart grid, the intent is to use flexibility in demand, both to balance demand and supply as well as to resolve potential congestion. A first prominent example of such flexible demand is the charging of electric vehicles, which do not necessarily need to be charged as soon as they are plugged in. The problem of optimally scheduling the charging demand of electric vehicles within the constraints of the electricity infrastructure is called the charge scheduling problem. The models of the charging speed, horizon, and charging demand determine the computational complexity of the charge scheduling problem. For about 20 variants, we show, using a dynamic programming approach, that the problem is either in P or weakly NP-hard. We also show that about 10 variants of the problem are strongly NP-hard, presenting a potentially significant obstacle to their use in practical situations of scale.\n    ",
        "submission_date": "2017-09-21T00:00:00",
        "last_modified_date": "2017-09-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.07492",
        "title": "Sparse-to-Dense: Depth Prediction from Sparse Depth Samples and a Single Image",
        "authors": [
            "Fangchang Ma",
            "Sertac Karaman"
        ],
        "abstract": "We consider the problem of dense depth prediction from a sparse set of depth measurements and a single RGB image. Since depth estimation from monocular images alone is inherently ambiguous and unreliable, to attain a higher level of robustness and accuracy, we introduce additional sparse depth samples, which are either acquired with a low-resolution depth sensor or computed via visual Simultaneous Localization and Mapping (SLAM) algorithms. We propose the use of a single deep regression network to learn directly from the RGB-D raw data, and explore the impact of number of depth samples on prediction accuracy. Our experiments show that, compared to using only RGB images, the addition of 100 spatially random depth samples reduces the prediction root-mean-square error by 50% on the NYU-Depth-v2 indoor dataset. It also boosts the percentage of reliable prediction from 59% to 92% on the KITTI dataset. We demonstrate two applications of the proposed algorithm: a plug-in module in SLAM to convert sparse maps to dense maps, and super-resolution for LiDARs. Software and video demonstration are publicly available.\n    ",
        "submission_date": "2017-09-21T00:00:00",
        "last_modified_date": "2018-02-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.07528",
        "title": "Defining a Lingua Franca to Open the Black Box of a Na\u00efve Bayes Recommender",
        "authors": [
            "Kenneth L. Hess",
            "Hugo D. Paz"
        ],
        "abstract": "Many AI systems have a black box nature that makes it difficult to understand how they make their recommendations. This can be unsettling, as the designer cannot be certain how the system will respond to novelty. To penetrate our Na\u00efve Bayes recommender's black box, we first asked, what do we want to know from our system, and how can it be obtained? The answers led us to recursively define a common lexicon with the AI, a lingua franca, using the very items that the system ranks to create meta-symbols recognized by the system, and enabling us to understand the system's knowledge in plain terms and at different levels of abstraction. As one bonus, using its existing knowledge, the lingua franca can enable the system to extend recommendations to related, but entirely new areas, ameliorating the cold start problem. We also supplement the lingua franca with techniques for visualizing the system's knowledge state, develop metrics for evaluating the meaningfulness of terms in the lingua franca, and generalize the requirements for developing a similar lingua franca in other applications.\n    ",
        "submission_date": "2017-09-21T00:00:00",
        "last_modified_date": "2017-09-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.07581",
        "title": "Hierarchical Detail Enhancing Mesh-Based Shape Generation with 3D Generative Adversarial Network",
        "authors": [
            "Chiyu \"Max\" Jiang",
            "Philip Marcus"
        ],
        "abstract": "Automatic mesh-based shape generation is of great interest across a wide range of disciplines, from industrial design to gaming, computer graphics and various other forms of digital art. While most traditional methods focus on primitive based model generation, advances in deep learning made it possible to learn 3-dimensional geometric shape representations in an end-to-end manner. However, most current deep learning based frameworks focus on the representation and generation of voxel and point-cloud based shapes, making it not directly applicable to design and graphics communities. This study addresses the needs for automatic generation of mesh-based geometries, and propose a novel framework that utilizes signed distance function representation that generates detail preserving three-dimensional surface mesh by a deep learning based approach.\n    ",
        "submission_date": "2017-09-22T00:00:00",
        "last_modified_date": "2017-09-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.07643",
        "title": "OptLayer - Practical Constrained Optimization for Deep Reinforcement Learning in the Real World",
        "authors": [
            "Tu-Hoa Pham",
            "Giovanni De Magistris",
            "Ryuki Tachibana"
        ],
        "abstract": "While deep reinforcement learning techniques have recently produced considerable achievements on many decision-making problems, their use in robotics has largely been limited to simulated worlds or restricted motions, since unconstrained trial-and-error interactions in the real world can have undesirable consequences for the robot or its environment. To overcome such limitations, we propose a novel reinforcement learning architecture, OptLayer, that takes as inputs possibly unsafe actions predicted by a neural network and outputs the closest actions that satisfy chosen constraints. While learning control policies often requires carefully crafted rewards and penalties while exploring the range of possible actions, OptLayer ensures that only safe actions are actually executed and unsafe predictions are penalized during training. We demonstrate the effectiveness of our approach on robot reaching tasks, both simulated and in the real world.\n    ",
        "submission_date": "2017-09-22T00:00:00",
        "last_modified_date": "2018-02-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.07796",
        "title": "On overfitting and asymptotic bias in batch reinforcement learning with partial observability",
        "authors": [
            "Vincent Francois-Lavet",
            "Guillaume Rabusseau",
            "Joelle Pineau",
            "Damien Ernst",
            "Raphael Fonteneau"
        ],
        "abstract": "This paper provides an analysis of the tradeoff between asymptotic bias (suboptimality with unlimited data) and overfitting (additional suboptimality due to limited data) in the context of reinforcement learning with partial observability. Our theoretical analysis formally characterizes that while potentially increasing the asymptotic bias, a smaller state representation decreases the risk of overfitting. This analysis relies on expressing the quality of a state representation by bounding L1 error terms of the associated belief states. Theoretical results are empirically illustrated when the state representation is a truncated history of observations, both on synthetic POMDPs and on a large-scale POMDP in the context of smartgrids, with real-world data. Finally, similarly to known results in the fully observable setting, we also briefly discuss and empirically illustrate how using function approximators and adapting the discount factor may enhance the tradeoff between asymptotic bias and overfitting in the partially observable context.\n    ",
        "submission_date": "2017-09-22T00:00:00",
        "last_modified_date": "2019-02-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.07808",
        "title": "Quantum Memristors in Quantum Photonics",
        "authors": [
            "M. Sanz",
            "L. Lamata",
            "E. Solano"
        ],
        "abstract": "We propose a method to build quantum memristors in quantum photonic platforms. We firstly design an effective beam splitter, which is tunable in real-time, by means of a Mach-Zehnder-type array with two equal 50:50 beam splitters and a tunable retarder, which allows us to control its reflectivity. Then, we show that this tunable beam splitter, when equipped with weak measurements and classical feedback, behaves as a quantum memristor. Indeed, in order to prove its quantumness, we show how to codify quantum information in the coherent beams. Moreover, we estimate the memory capability of the quantum memristor. Finally, we show the feasibility of the proposed setup in integrated quantum photonics.\n    ",
        "submission_date": "2017-09-22T00:00:00",
        "last_modified_date": "2018-12-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.07842",
        "title": "Bayesian Optimization for Parameter Tuning of the XOR Neural Network",
        "authors": [
            "Lawrence Stewart",
            "Mark Stalzer"
        ],
        "abstract": "When applying Machine Learning techniques to problems, one must select model parameters to ensure that the system converges but also does not become stuck at the objective function's local minimum. Tuning these parameters becomes a non-trivial task for large models and it is not always apparent if the user has found the optimal parameters. We aim to automate the process of tuning a Neural Network, (where only a limited number of parameter search attempts are available) by implementing Bayesian Optimization. In particular, by assigning Gaussian Process Priors to the parameter space, we utilize Bayesian Optimization to tune an Artificial Neural Network used to learn the XOR function, with the result of achieving higher prediction accuracy.\n    ",
        "submission_date": "2017-09-22T00:00:00",
        "last_modified_date": "2017-11-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.07848",
        "title": "Multiqubit and multilevel quantum reinforcement learning with quantum technologies",
        "authors": [
            "F. A. C\u00e1rdenas-L\u00f3pez",
            "L. Lamata",
            "J. C. Retamal",
            "E. Solano"
        ],
        "abstract": "We propose a protocol to perform quantum reinforcement learning with quantum technologies. At variance with recent results on quantum reinforcement learning with superconducting circuits, in our current protocol coherent feedback during the learning process is not required, enabling its implementation in a wide variety of quantum systems. We consider diverse possible scenarios for an agent, an environment, and a register that connects them, involving multiqubit and multilevel systems, as well as open-system dynamics. We finally propose possible implementations of this protocol in trapped ions and superconducting circuits. The field of quantum reinforcement learning with quantum technologies will enable enhanced quantum control, as well as more efficient machine learning calculations.\n    ",
        "submission_date": "2017-09-22T00:00:00",
        "last_modified_date": "2018-07-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.07857",
        "title": "Using Simulation and Domain Adaptation to Improve Efficiency of Deep Robotic Grasping",
        "authors": [
            "Konstantinos Bousmalis",
            "Alex Irpan",
            "Paul Wohlhart",
            "Yunfei Bai",
            "Matthew Kelcey",
            "Mrinal Kalakrishnan",
            "Laura Downs",
            "Julian Ibarz",
            "Peter Pastor",
            "Kurt Konolige",
            "Sergey Levine",
            "Vincent Vanhoucke"
        ],
        "abstract": "Instrumenting and collecting annotated visual grasping datasets to train modern machine learning algorithms can be extremely time-consuming and expensive. An appealing alternative is to use off-the-shelf simulators to render synthetic data for which ground-truth annotations are generated automatically. Unfortunately, models trained purely on simulated data often fail to generalize to the real world. We study how randomized simulated environments and domain adaptation methods can be extended to train a grasping system to grasp novel objects from raw monocular RGB images. We extensively evaluate our approaches with a total of more than 25,000 physical test grasps, studying a range of simulation conditions and domain adaptation methods, including a novel extension of pixel-level domain adaptation that we term the GraspGAN. We show that, by using synthetic data and domain adaptation, we are able to reduce the number of real-world samples needed to achieve a given level of performance by up to 50 times, using only randomly generated simulated objects. We also show that by using only unlabeled real-world data and our GraspGAN methodology, we obtain real-world grasping performance without any real-world labels that is similar to that achieved with 939,777 labeled real-world samples.\n    ",
        "submission_date": "2017-09-22T00:00:00",
        "last_modified_date": "2017-09-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.07871",
        "title": "FiLM: Visual Reasoning with a General Conditioning Layer",
        "authors": [
            "Ethan Perez",
            "Florian Strub",
            "Harm de Vries",
            "Vincent Dumoulin",
            "Aaron Courville"
        ],
        "abstract": "We introduce a general-purpose conditioning method for neural networks called FiLM: Feature-wise Linear Modulation. FiLM layers influence neural network computation via a simple, feature-wise affine transformation based on conditioning information. We show that FiLM layers are highly effective for visual reasoning - answering image-related questions which require a multi-step, high-level process - a task which has proven difficult for standard deep learning methods that do not explicitly model reasoning. Specifically, we show on visual reasoning tasks that FiLM layers 1) halve state-of-the-art error for the CLEVR benchmark, 2) modulate features in a coherent manner, 3) are robust to ablations and architectural modifications, and 4) generalize well to challenging, new data from few examples or even zero-shot.\n    ",
        "submission_date": "2017-09-22T00:00:00",
        "last_modified_date": "2017-12-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.07876",
        "title": "Fast, Robust, and Versatile Event Detection through HMM Belief State Gradient Measures",
        "authors": [
            "Shuangqi Luo",
            "Hongmin Wu",
            "Hongbin Lin",
            "Shuangda Duan",
            "Yisheng Guan",
            "Juan Rojas"
        ],
        "abstract": "Event detection is a critical feature in data-driven systems as it assists with the identification of nominal and anomalous behavior. Event detection is increasingly relevant in robotics as robots operate with greater autonomy in increasingly unstructured environments. In this work, we present an accurate, robust, fast, and versatile measure for skill and anomaly identification. A theoretical proof establishes the link between the derivative of the log-likelihood of the HMM filtered belief state and the latest emission probabilities. The key insight is the inverse relationship in which gradient analysis is used for skill and anomaly identification. Our measure showed better performance across all metrics than related state-of-the art works. The result is broadly applicable to domains that use HMMs for event detection.\n    ",
        "submission_date": "2017-09-24T00:00:00",
        "last_modified_date": "2018-06-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.07941",
        "title": "Efficiently Discovering Locally Exceptional yet Globally Representative Subgroups",
        "authors": [
            "Janis Kalofolias",
            "Mario Boley",
            "Jilles Vreeken"
        ],
        "abstract": "Subgroup discovery is a local pattern mining technique to find interpretable descriptions of sub-populations that stand out on a given target variable. That is, these sub-populations are exceptional with regard to the global distribution. In this paper we argue that in many applications, such as scientific discovery, subgroups are only useful if they are additionally representative of the global distribution with regard to a control variable. That is, when the distribution of this control variable is the same, or almost the same, as over the whole data.\n",
        "submission_date": "2017-09-22T00:00:00",
        "last_modified_date": "2017-09-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.07979",
        "title": "Multi-task Learning with Gradient Guided Policy Specialization",
        "authors": [
            "Wenhao Yu",
            "C. Karen Liu",
            "Greg Turk"
        ],
        "abstract": "We present a method for efficient learning of control policies for multiple related robotic motor skills. Our approach consists of two stages, joint training and specialization training. During the joint training stage, a neural network policy is trained with minimal information to disambiguate the motor skills. This forces the policy to learn a common representation of the different tasks. Then, during the specialization training stage we selectively split the weights of the policy based on a per-weight metric that measures the disagreement among the multiple tasks. By splitting part of the control policy, it can be further trained to specialize to each task. To update the control policy during learning, we use Trust Region Policy Optimization with Generalized Advantage Function (TRPOGAE). We propose a modification to the gradient update stage of TRPO to better accommodate multi-task learning scenarios. We evaluate our approach on three continuous motor skill learning problems in simulation: 1) a locomotion task where three single legged robots with considerable difference in shape and size are trained to hop forward, 2) a manipulation task where three robot manipulators with different sizes and joint types are trained to reach different locations in 3D space, and 3) locomotion of a two-legged robot, whose range of motion of one leg is constrained in different ways. We compare our training method to three baselines. The first baseline uses only joint training for the policy, the second trains independent policies for each task, and the last randomly selects weights to split. We show that our approach learns more efficiently than each of the baseline methods.\n    ",
        "submission_date": "2017-09-23T00:00:00",
        "last_modified_date": "2018-03-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.08073",
        "title": "Cross-modal Recurrent Models for Weight Objective Prediction from Multimodal Time-series Data",
        "authors": [
            "Petar Veli\u010dkovi\u0107",
            "Laurynas Karazija",
            "Nicholas D. Lane",
            "Sourav Bhattacharya",
            "Edgar Liberis",
            "Pietro Li\u00f2",
            "Angela Chieh",
            "Otmane Bellahsen",
            "Matthieu Vegreville"
        ],
        "abstract": "We analyse multimodal time-series data corresponding to weight, sleep and steps measurements. We focus on predicting whether a user will successfully achieve his/her weight objective. For this, we design several deep long short-term memory (LSTM) architectures, including a novel cross-modal LSTM (X-LSTM), and demonstrate their superiority over baseline approaches. The X-LSTM improves parameter efficiency by processing each modality separately and allowing for information flow between them by way of recurrent cross-connections. We present a general hyperparameter optimisation technique for X-LSTMs, which allows us to significantly improve on the LSTM and a prior state-of-the-art cross-modal approach, using a comparable number of parameters. Finally, we visualise the model's predictions, revealing implications about latent variables in this task.\n    ",
        "submission_date": "2017-09-23T00:00:00",
        "last_modified_date": "2017-11-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.08126",
        "title": "Self-supervised learning: When is fusion of the primary and secondary sensor cue useful?",
        "authors": [
            "G.C.H.E. de Croon"
        ],
        "abstract": "Self-supervised learning (SSL) is a reliable learning mechanism in which a robot enhances its perceptual capabilities. Typically, in SSL a trusted, primary sensor cue provides supervised training data to a secondary sensor cue. In this article, a theoretical analysis is performed on the fusion of the primary and secondary cue in a minimal model of SSL. A proof is provided that determines the specific conditions under which it is favorable to perform fusion. In short, it is favorable when (i) the prior on the target value is strong or (ii) the secondary cue is sufficiently accurate. The theoretical findings are validated with computational experiments. Subsequently, a real-world case study is performed to investigate if fusion in SSL is also beneficial when assumptions of the minimal model are not met. In particular, a flying robot learns to map pressure measurements to sonar height measurements and then fuses the two, resulting in better height estimation. Fusion is also beneficial in the opposite case, when pressure is the primary cue. The analysis and results are encouraging to study SSL fusion also for other robots and sensors.\n    ",
        "submission_date": "2017-09-23T00:00:00",
        "last_modified_date": "2017-09-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.08267",
        "title": "HDLTex: Hierarchical Deep Learning for Text Classification",
        "authors": [
            "Kamran Kowsari",
            "Donald E. Brown",
            "Mojtaba Heidarysafa",
            "Kiana Jafari Meimandi",
            "Matthew S. Gerber",
            "Laura E. Barnes"
        ],
        "abstract": "The continually increasing number of documents produced each year necessitates ever improving information processing methods for searching, retrieving, and organizing text. Central to these information processing methods is document classification, which has become an important application for supervised learning. Recently the performance of these traditional classifiers has degraded as the number of documents has increased. This is because along with this growth in the number of documents has come an increase in the number of categories. This paper approaches this problem differently from current document classification methods that view the problem as multi-class classification. Instead we perform hierarchical classification using an approach we call Hierarchical Deep Learning for Text classification (HDLTex). HDLTex employs stacks of deep learning architectures to provide specialized understanding at each level of the document hierarchy.\n    ",
        "submission_date": "2017-09-24T00:00:00",
        "last_modified_date": "2017-10-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.08292",
        "title": "Underwater Multi-Robot Convoying using Visual Tracking by Detection",
        "authors": [
            "Florian Shkurti",
            "Wei-Di Chang",
            "Peter Henderson",
            "Md Jahidul Islam",
            "Juan Camilo Gamboa Higuera",
            "Jimmy Li",
            "Travis Manderson",
            "Anqi Xu",
            "Gregory Dudek",
            "Junaed Sattar"
        ],
        "abstract": "We present a robust multi-robot convoying approach that relies on visual detection of the leading agent, thus enabling target following in unstructured 3-D environments. Our method is based on the idea of tracking-by-detection, which interleaves efficient model-based object detection with temporal filtering of image-based bounding box estimation. This approach has the important advantage of mitigating tracking drift (i.e. drifting away from the target object), which is a common symptom of model-free trackers and is detrimental to sustained convoying in practice. To illustrate our solution, we collected extensive footage of an underwater robot in ocean settings, and hand-annotated its location in each frame. Based on this dataset, we present an empirical comparison of multiple tracker variants, including the use of several convolutional neural networks, both with and without recurrent connections, as well as frequency-based model-free trackers. We also demonstrate the practicality of this tracking-by-detection strategy in real-world scenarios by successfully controlling a legged underwater robot in five degrees of freedom to follow another robot's independent motion.\n    ",
        "submission_date": "2017-09-25T00:00:00",
        "last_modified_date": "2017-09-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.08385",
        "title": "Deep Learning Based Cryptographic Primitive Classification",
        "authors": [
            "Gregory D. Hill",
            "Xavier J. A. Bellekens"
        ],
        "abstract": "Cryptovirological augmentations present an immediate, incomparable threat. Over the last decade, the substantial proliferation of crypto-ransomware has had widespread consequences for consumers and organisations alike. Established preventive measures perform well, however, the problem has not ceased. Reverse engineering potentially malicious software is a cumbersome task due to platform eccentricities and obfuscated transmutation mechanisms, hence requiring smarter, more efficient detection strategies. The following manuscript presents a novel approach for the classification of cryptographic primitives in compiled binary executables using deep learning. The model blueprint, a DCNN, is fittingly configured to learn from variable-length control flow diagnostics output from a dynamic trace. To rival the size and variability of contemporary data compendiums, hence feeding the model cognition, a methodology for the procedural generation of synthetic cryptographic binaries is defined, utilising core primitives from OpenSSL with multivariate obfuscation, to draw a vastly scalable distribution. The library, CryptoKnight, rendered an algorithmic pool of AES, RC4, Blowfish, MD5 and RSA to synthesis combinable variants which are automatically fed in its core model. Converging at 91% accuracy, CryptoKnight is successfully able to classify the sample algorithms with minimal loss.\n    ",
        "submission_date": "2017-09-25T00:00:00",
        "last_modified_date": "2017-09-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.08426",
        "title": "Non-iterative Label Propagation in Optimal Leading Forest",
        "authors": [
            "Ji Xu",
            "Guoyin Wang"
        ],
        "abstract": "Graph based semi-supervised learning (GSSL) has intuitive representation and can be improved by exploiting the matrix calculation. However, it has to perform iterative optimization to achieve a preset objective, which usually leads to low efficiency. Another inconvenience lying in GSSL is that when new data come, the graph construction and the optimization have to be conducted all over again. We propose a sound assumption, arguing that: the neighboring data points are not in peer-to-peer relation, but in a partial-ordered relation induced by the local density and distance between the data; and the label of a center can be regarded as the contribution of its followers. Starting from the assumption, we develop a highly efficient non-iterative label propagation algorithm based on a novel data structure named as optimal leading forest (LaPOLeaF). The major weaknesses of the traditional GSSL are addressed by this study. We further scale LaPOLeaF to accommodate big data by utilizing block distance matrix technique, parallel computing, and Locality-Sensitive Hashing (LSH). Experiments on large datasets have shown the promising results of the proposed methods.\n    ",
        "submission_date": "2017-09-25T00:00:00",
        "last_modified_date": "2019-02-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.08430",
        "title": "Towards continuous control of flippers for a multi-terrain robot using deep reinforcement learning",
        "authors": [
            "Giuseppe Paolo",
            "Lei Tai",
            "Ming Liu"
        ],
        "abstract": "In this paper we focus on developing a control algorithm for multi-terrain tracked robots with flippers using a reinforcement learning (RL) approach. The work is based on the deep deterministic policy gradient (DDPG) algorithm, proven to be very successful in simple simulation environments. The algorithm works in an end-to-end fashion in order to control the continuous position of the flippers. This end-to-end approach makes it easy to apply the controller to a wide array of circumstances, but the huge flexibility comes to the cost of an increased difficulty of solution. The complexity of the task is enlarged even more by the fact that real multi-terrain robots move in partially observable environments. Notwithstanding these complications, being able to smoothly control a multi-terrain robot can produce huge benefits in impaired people daily lives or in search and rescue situations.\n    ",
        "submission_date": "2017-09-25T00:00:00",
        "last_modified_date": "2017-09-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.08461",
        "title": "Mining a Sub-Matrix of Maximal Sum",
        "authors": [
            "Vincent Branders",
            "Pierre Schaus",
            "Pierre Dupont"
        ],
        "abstract": "Biclustering techniques have been widely used to identify homogeneous subgroups within large data matrices, such as subsets of genes similarly expressed across subsets of patients. Mining a max-sum sub-matrix is a related but distinct problem for which one looks for a (non-necessarily contiguous) rectangular sub-matrix with a maximal sum of its entries. Le Van et al. (Ranked Tiling, 2014) already illustrated its applicability to gene expression analysis and addressed it with a constraint programming (CP) approach combined with large neighborhood search (CP-LNS). In this work, we exhibit some key properties of this NP-hard problem and define a bounding function such that larger problems can be solved in reasonable time. Two different algorithms are proposed in order to exploit the highlighted characteristics of the problem: a CP approach with a global constraint (CPGC) and mixed integer linear programming (MILP). Practical experiments conducted both on synthetic and real gene expression data exhibit the characteristics of these approaches and their relative benefits over the original CP-LNS method. Overall, the CPGC approach tends to be the fastest to produce a good solution. Yet, the MILP formulation is arguably the easiest to formulate and can also be competitive.\n    ",
        "submission_date": "2017-09-25T00:00:00",
        "last_modified_date": "2017-09-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.08471",
        "title": "Bayesian Filtering for ODEs with Bounded Derivatives",
        "authors": [
            "Emilia Magnani",
            "Hans Kersting",
            "Michael Schober",
            "Philipp Hennig"
        ],
        "abstract": "Recently there has been increasing interest in probabilistic solvers for ordinary differential equations (ODEs) that return full probability measures, instead of point estimates, over the solution and can incorporate uncertainty over the ODE at hand, e.g. if the vector field or the initial value is only approximately known or evaluable. The ODE filter proposed in recent work models the solution of the ODE by a Gauss-Markov process which serves as a prior in the sense of Bayesian statistics. While previous work employed a Wiener process prior on the (possibly multiple times) differentiated solution of the ODE and established equivalence of the corresponding solver with classical numerical methods, this paper raises the question whether other priors also yield practically useful solvers. To this end, we discuss a range of possible priors which enable fast filtering and propose a new prior--the Integrated Ornstein Uhlenbeck Process (IOUP)--that complements the existing Integrated Wiener process (IWP) filter by encoding the property that a derivative in time of the solution is bounded in the sense that it tends to drift back to zero. We provide experiments comparing IWP and IOUP filters which support the belief that IWP approximates better divergent ODE's solutions whereas IOUP is a better prior for trajectories with bounded derivatives.\n    ",
        "submission_date": "2017-09-25T00:00:00",
        "last_modified_date": "2017-09-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.08519",
        "title": "Enhanced Quantum Synchronization via Quantum Machine Learning",
        "authors": [
            "F. A. C\u00e1rdenas-L\u00f3pez",
            "M. Sanz",
            "J. C. Retamal",
            "E. Solano"
        ],
        "abstract": "We study the quantum synchronization between a pair of two-level systems inside two coupled cavities. By using a digital-analog decomposition of the master equation that rules the system dynamics, we show that this approach leads to quantum synchronization between both two-level systems. Moreover, we can identify in this digital-analog block decomposition the fundamental elements of a quantum machine learning protocol, in which the agent and the environment (learning units) interact through a mediating system, namely, the register. If we can additionally equip this algorithm with a classical feedback mechanism, which consists of projective measurements in the register, reinitialization of the register state and local conditional operations on the agent and environment subspace, a powerful and flexible quantum machine learning protocol emerges. Indeed, numerical simulations show that this protocol enhances the synchronization process, even when every subsystem experience different loss/decoherence mechanisms, and give us the flexibility to choose the synchronization state. Finally, we propose an implementation based on current technologies in superconducting circuits.\n    ",
        "submission_date": "2017-09-25T00:00:00",
        "last_modified_date": "2019-01-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.08568",
        "title": "The Consciousness Prior",
        "authors": [
            "Yoshua Bengio"
        ],
        "abstract": "A new prior is proposed for learning representations of high-level concepts of the kind we manipulate with language. This prior can be combined with other priors in order to help disentangling abstract factors from each other. It is inspired by cognitive neuroscience theories of consciousness, seen as a bottleneck through which just a few elements, after having been selected by attention from a broader pool, are then broadcast and condition further processing, both in perception and decision-making. The set of recently selected elements one becomes aware of is seen as forming a low-dimensional conscious state. This conscious state is combining the few concepts constituting a conscious thought, i.e., what one is immediately conscious of at a particular moment. We claim that this architectural and information-processing constraint corresponds to assumptions about the joint distribution between high-level concepts. To the extent that these assumptions are generally true (and the form of natural language seems consistent with them), they can form a useful prior for representation learning. A low-dimensional thought or conscious state is analogous to a sentence: it involves only a few variables and yet can make a statement with very high probability of being true. This is consistent with a joint distribution (over high-level concepts) which has the form of a sparse factor graph, i.e., where the dependencies captured by each factor of the factor graph involve only very few variables while creating a strong dip in the overall energy function. The consciousness prior also makes it natural to map conscious states to natural language utterances or to express classical AI knowledge in a form similar to facts and rules, albeit capturing uncertainty as well as efficient search mechanisms implemented by attention mechanisms.\n    ",
        "submission_date": "2017-09-25T00:00:00",
        "last_modified_date": "2019-12-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.08607",
        "title": "Towards automation of data quality system for CERN CMS experiment",
        "authors": [
            "Maxim Borisyak",
            "Fedor Ratnikov",
            "Denis Derkach",
            "Andrey Ustyuzhanin"
        ],
        "abstract": "Daily operation of a large-scale experiment is a challenging task, particularly from perspectives of routine monitoring of quality for data being taken. We describe an approach that uses Machine Learning for the automated system to monitor data quality, which is based on partial use of data qualified manually by detector experts. The system automatically classifies marginal cases: both of good an bad data, and use human expert decision to classify remaining \"grey area\" cases.\n",
        "submission_date": "2017-09-25T00:00:00",
        "last_modified_date": "2017-09-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.08624",
        "title": "Long Text Generation via Adversarial Training with Leaked Information",
        "authors": [
            "Jiaxian Guo",
            "Sidi Lu",
            "Han Cai",
            "Weinan Zhang",
            "Yong Yu",
            "Jun Wang"
        ],
        "abstract": "Automatically generating coherent and semantically meaningful text has many applications in machine translation, dialogue systems, image captioning, etc. Recently, by combining with policy gradient, Generative Adversarial Nets (GAN) that use a discriminative model to guide the training of the generative model as a reinforcement learning policy has shown promising results in text generation. However, the scalar guiding signal is only available after the entire text has been generated and lacks intermediate information about text structure during the generative process. As such, it limits its success when the length of the generated text samples is long (more than 20 words). In this paper, we propose a new framework, called LeakGAN, to address the problem for long text generation. We allow the discriminative net to leak its own high-level extracted features to the generative net to further help the guidance. The generator incorporates such informative signals into all generation steps through an additional Manager module, which takes the extracted features of current generated words and outputs a latent vector to guide the Worker module for next-word generation. Our extensive experiments on synthetic data and various real-world tasks with Turing test demonstrate that LeakGAN is highly effective in long text generation and also improves the performance in short text generation scenarios. More importantly, without any supervision, LeakGAN would be able to implicitly learn sentence structures only through the interaction between Manager and Worker.\n    ",
        "submission_date": "2017-09-24T00:00:00",
        "last_modified_date": "2017-12-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.08669",
        "title": "Glass-Box Program Synthesis: A Machine Learning Approach",
        "authors": [
            "Konstantina Christakopoulou",
            "Adam Tauman Kalai"
        ],
        "abstract": "Recently proposed models which learn to write computer programs from data use either input/output examples or rich execution traces. Instead, we argue that a novel alternative is to use a glass-box loss function, given as a program itself that can be directly inspected. Glass-box optimization covers a wide range of problems, from computing the greatest common divisor of two integers, to learning-to-learn problems.\n",
        "submission_date": "2017-09-25T00:00:00",
        "last_modified_date": "2017-09-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.08853",
        "title": "Object-oriented Neural Programming (OONP) for Document Understanding",
        "authors": [
            "Zhengdong Lu",
            "Xianggen Liu",
            "Haotian Cui",
            "Yukun Yan",
            "Daqi Zheng"
        ],
        "abstract": "We propose Object-oriented Neural Programming (OONP), a framework for semantically parsing documents in specific domains. Basically, OONP reads a document and parses it into a predesigned object-oriented data structure (referred to as ontology in this paper) that reflects the domain-specific semantics of the document. An OONP parser models semantic parsing as a decision process: a neural net-based Reader sequentially goes through the document, and during the process it builds and updates an intermediate ontology to summarize its partial understanding of the text it covers. OONP supports a rich family of operations (both symbolic and differentiable) for composing the ontology, and a big variety of forms (both symbolic and differentiable) for representing the state and the document. An OONP parser can be trained with supervision of different forms and strength, including supervised learning (SL) , reinforcement learning (RL) and hybrid of the two. Our experiments on both synthetic and real-world document parsing tasks have shown that OONP can learn to handle fairly complicated ontology with training data of modest sizes.\n    ",
        "submission_date": "2017-09-26T00:00:00",
        "last_modified_date": "2018-07-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.08878",
        "title": "Generating Sentences by Editing Prototypes",
        "authors": [
            "Kelvin Guu",
            "Tatsunori B. Hashimoto",
            "Yonatan Oren",
            "Percy Liang"
        ],
        "abstract": "We propose a new generative model of sentences that first samples a prototype sentence from the training corpus and then edits it into a new sentence. Compared to traditional models that generate from scratch either left-to-right or by first sampling a latent sentence vector, our prototype-then-edit model improves perplexity on language modeling and generates higher quality outputs according to human evaluation. Furthermore, the model gives rise to a latent edit vector that captures interpretable semantics such as sentence similarity and sentence-level analogies.\n    ",
        "submission_date": "2017-09-26T00:00:00",
        "last_modified_date": "2018-09-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.08880",
        "title": "An enhanced method to compute the similarity between concepts of ontology",
        "authors": [
            "Noreddine Gherabi",
            "Abdelhadi Daoui",
            "Abderrahim Marzouk"
        ],
        "abstract": "With the use of ontologies in several domains such as semantic web, information retrieval, artificial intelligence, the concept of similarity measuring has become a very important domain of research. Therefore, in the current paper, we propose our method of similarity measuring which uses the Dijkstra algorithm to define and compute the shortest path. Then, we use this one to compute the semantic distance between two concepts defined in the same hierarchy of ontology. Afterward, we base on this result to compute the semantic similarity. Finally, we present an experimental comparison between our method and other methods of similarity measuring.\n    ",
        "submission_date": "2017-09-26T00:00:00",
        "last_modified_date": "2017-09-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.08992",
        "title": "Embodied Evolution in Collective Robotics: A Review",
        "authors": [
            "Nicolas Bredeche",
            "Evert Haasdijk",
            "Abraham Prieto"
        ],
        "abstract": "This paper provides an overview of evolutionary robotics techniques applied to on-line distributed evolution for robot collectives -- namely, embodied evolution. It provides a definition of embodied evolution as well as a thorough description of the underlying concepts and mechanisms. The paper also presents a comprehensive summary of research published in the field since its inception (1999-2017), providing various perspectives to identify the major trends. In particular, we identify a shift from considering embodied evolution as a parallel search method within small robot collectives (fewer than 10 robots) to embodied evolution as an on-line distributed learning method for designing collective behaviours in swarm-like collectives. The paper concludes with a discussion of applications and open questions, providing a milestone for past and an inspiration for future research.\n    ",
        "submission_date": "2017-09-26T00:00:00",
        "last_modified_date": "2018-02-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.09051",
        "title": "Exact MAP inference in general higher-order graphical models using linear programming",
        "authors": [
            "Ikhlef Bechar"
        ],
        "abstract": "This paper is concerned with the problem of exact MAP inference in general higher-order graphical models by means of a traditional linear programming relaxation approach. In fact, the proof that we have developed in this paper is a rather simple algebraic proof being made straightforward, above all, by the introduction of two novel algebraic tools. Indeed, on the one hand, we introduce the notion of delta-distribution which merely stands for the difference of two arbitrary probability distributions, and which mainly serves to alleviate the sign constraint inherent to a traditional probability distribution. On the other hand, we develop an approximation framework of general discrete functions by means of an orthogonal projection expressing in terms of linear combinations of function margins with respect to a given collection of point subsets, though, we rather exploit the latter approach for the purpose of modeling locally consistent sets of discrete functions from a global perspective. After that, as a first step, we develop from scratch the expectation optimization framework which is nothing else than a reformulation, on stochastic grounds, of the convex-hull approach, as a second step, we develop the traditional LP relaxation of such an expectation optimization approach, and we show that it enables to solve the MAP inference problem in graphical models under rather general assumptions. Last but not least, we describe an algorithm which allows to compute an exact MAP solution from a perhaps fractional optimal (probability) solution of the proposed LP relaxation.\n    ",
        "submission_date": "2017-09-25T00:00:00",
        "last_modified_date": "2017-09-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.09093",
        "title": "Beyond opening up the black box: Investigating the role of algorithmic systems in Wikipedian organizational culture",
        "authors": [
            "R. Stuart Geiger"
        ],
        "abstract": "Scholars and practitioners across domains are increasingly concerned with algorithmic transparency and opacity, interrogating the values and assumptions embedded in automated, black-boxed systems, particularly in user-generated content platforms. I report from an ethnography of infrastructure in Wikipedia to discuss an often understudied aspect of this topic: the local, contextual, learned expertise involved in participating in a highly automated social-technical environment. Today, the organizational culture of Wikipedia is deeply intertwined with various data-driven algorithmic systems, which Wikipedians rely on to help manage and govern the \"anyone can edit\" encyclopedia at a massive scale. These bots, scripts, tools, plugins, and dashboards make Wikipedia more efficient for those who know how to work with them, but like all organizational culture, newcomers must learn them if they want to fully participate. I illustrate how cultural and organizational expertise is enacted around algorithmic agents by discussing two autoethnographic vignettes, which relate my personal experience as a veteran in Wikipedia. I present thick descriptions of how governance and gatekeeping practices are articulated through and in alignment with these automated infrastructures. Over the past 15 years, Wikipedian veterans and administrators have made specific decisions to support administrative and editorial workflows with automation in particular ways and not others. I use these cases of Wikipedia's bot-supported bureaucracy to discuss several issues in the fields of critical algorithms studies, critical data studies, and fairness, accountability, and transparency in machine learning -- most principally arguing that scholarship and practice must go beyond trying to \"open up the black box\" of such systems and also examine sociocultural processes like newcomer socialization.\n    ",
        "submission_date": "2017-09-26T00:00:00",
        "last_modified_date": "2017-10-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.09233",
        "title": "A feasibility study for predicting optimal radiation therapy dose distributions of prostate cancer patients from patient anatomy using deep learning",
        "authors": [
            "Dan Nguyen",
            "Troy Long",
            "Xun Jia",
            "Weiguo Lu",
            "Xuejun Gu",
            "Zohaib Iqbal",
            "Steve Jiang"
        ],
        "abstract": "With the advancement of treatment modalities in radiation therapy for cancer patients, outcomes have improved, but at the cost of increased treatment plan complexity and planning time. The accurate prediction of dose distributions would alleviate this issue by guiding clinical plan optimization to save time and maintain high quality plans. We have modified a convolutional deep network model, U-net (originally designed for segmentation purposes), for predicting dose from patient image contours of the planning target volume (PTV) and organs at risk (OAR). We show that, as an example, we are able to accurately predict the dose of intensity-modulated radiation therapy (IMRT) for prostate cancer patients, where the average Dice similarity coefficient is 0.91 when comparing the predicted vs. true isodose volumes between 0% and 100% of the prescription dose. The average value of the absolute differences in [max, mean] dose is found to be under 5% of the prescription dose, specifically for each structure is [1.80%, 1.03%](PTV), [1.94%, 4.22%](Bladder), [1.80%, 0.48%](Body), [3.87%, 1.79%](L Femoral Head), [5.07%, 2.55%](R Femoral Head), and [1.26%, 1.62%](Rectum) of the prescription dose. We thus managed to map a desired radiation dose distribution from a patient's PTV and OAR contours. As an additional advantage, relatively little data was used in the techniques and models described in this paper.\n    ",
        "submission_date": "2017-09-26T00:00:00",
        "last_modified_date": "2018-11-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.09250",
        "title": "Lexical Disambiguation in Natural Language Questions (NLQs)",
        "authors": [
            "Omar Al-Harbi",
            "Shaidah Jusoh",
            "Norita Md Norwawi"
        ],
        "abstract": "Question processing is a fundamental step in a question answering (QA) application, and its quality impacts the performance of QA application. The major challenging issue in processing question is how to extract semantic of natural language questions (NLQs). A human language is ambiguous. Ambiguity may occur at two levels; lexical and syntactic. In this paper, we propose a new approach for resolving lexical ambiguity problem by integrating context knowledge and concepts knowledge of a domain, into shallow natural language processing (SNLP) techniques. Concepts knowledge is modeled using ontology, while context knowledge is obtained from WordNet, and it is determined based on neighborhood words in a question. The approach will be applied to a university QA system.\n    ",
        "submission_date": "2017-09-26T00:00:00",
        "last_modified_date": "2017-09-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.09268",
        "title": "FSL-BM: Fuzzy Supervised Learning with Binary Meta-Feature for Classification",
        "authors": [
            "Kamran Kowsari",
            "Nima Bari",
            "Roman Vichr",
            "Farhad A. Goodarzi"
        ],
        "abstract": "This paper introduces a novel real-time Fuzzy Supervised Learning with Binary Meta-Feature (FSL-BM) for big data classification task. The study of real-time algorithms addresses several major concerns, which are namely: accuracy, memory consumption, and ability to stretch assumptions and time complexity. Attaining a fast computational model providing fuzzy logic and supervised learning is one of the main challenges in the machine learning. In this research paper, we present FSL-BM algorithm as an efficient solution of supervised learning with fuzzy logic processing using binary meta-feature representation using Hamming Distance and Hash function to relax assumptions. While many studies focused on reducing time complexity and increasing accuracy during the last decade, the novel contribution of this proposed solution comes through integration of Hamming Distance, Hash function, binary meta-features, binary classification to provide real time supervised method. Hash Tables (HT) component gives a fast access to existing indices; and therefore, the generation of new indices in a constant time complexity, which supersedes existing fuzzy supervised algorithms with better or comparable results. To summarize, the main contribution of this technique for real-time Fuzzy Supervised Learning is to represent hypothesis through binary input as meta-feature space and creating the Fuzzy Supervised Hash table to train and validate model.\n    ",
        "submission_date": "2017-09-26T00:00:00",
        "last_modified_date": "2017-11-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.09364",
        "title": "Research on several key technologies in practical speech emotion recognition",
        "authors": [
            "Chengwei Huang"
        ],
        "abstract": "In this dissertation the practical speech emotion recognition technology is studied, including several cognitive related emotion types, namely fidgetiness, confidence and tiredness. The high quality of naturalistic emotional speech data is the basis of this research. The following techniques are used for inducing practical emotional speech: cognitive task, computer game, noise stimulation, sleep deprivation and movie clips.\n",
        "submission_date": "2017-09-27T00:00:00",
        "last_modified_date": "2017-09-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.09450",
        "title": "A Literature Based Approach to Define the Scope of Biomedical Ontologies: A Case Study on a Rehabilitation Therapy Ontology",
        "authors": [
            "Mohammad K. Halawani",
            "Rob Forsyth",
            "Phillip Lord"
        ],
        "abstract": "In this article, we investigate our early attempts at building an ontology describing rehabilitation therapies following brain injury. These therapies are wide-ranging, involving interventions of many different kinds. As a result, these therapies are hard to describe. As well as restricting actual practice, this is also a major impediment to evidence-based medicine as it is hard to meaningfully compare two treatment plans.\n",
        "submission_date": "2017-09-27T00:00:00",
        "last_modified_date": "2017-09-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.09527",
        "title": "Introducing machine learning for power system operation support",
        "authors": [
            "Benjamin Donnot",
            "Isabelle Guyon",
            "Marc Schoenauer",
            "Patrick Panciatici",
            "Antoine Marot"
        ],
        "abstract": "We address the problem of assisting human dispatchers in operating power grids in today's changing  context  using machine learning,  with  theaim of increasing security and reducing costs. Power networks  are  highly  regulated  systems,  which  at  all times must meet varying demands of electricity with a complex production system, including conventional power   plants,   less   predictable   renewable   energies (such as wind or solar power), and the possibility of buying/selling electricity on the international market with  more  and  more  actors  involved  at  a  Europeanscale. This problem is becoming ever more challenging  in  an  aging  network  infrastructure.  One  of  the primary goals of dispatchers is to protect equipment (e.g.   avoid   that   transmission   lines   overheat)   with few  degrees  of  freedom:  we  are  considering  in  this paper  solely  modifications  in  network  topology,  i.e. re-configuring  the  way  in  which  lines,  transformers,  productions  and  loads  are  connected  in  sub-stations.  Using  years  of  historical  data  collected  by the  French  Transmission  Service  Operator  (TSO) \"R\u00e9seau  de  Transport  d'Electricit\u00e9\"  (RTE),  we  develop novel machine learning techniques (drawing on \"deep learning\") to mimic human decisions to devise \"remedial  actions\"  to  prevent  any  line  to  violate power  flow  limits  (so-called  \"thermal  limits\").  The proposed technique is hybrid. It does not rely purely on   machine   learning:   every   action   will   be   tested with  actual  simulators  before  being  proposed  to  the dispatchers  or  implemented  on  the  grid.\n    ",
        "submission_date": "2017-09-27T00:00:00",
        "last_modified_date": "2017-09-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.09569",
        "title": "Traffic Optimization For a Mixture of Self-interested and Compliant Agents",
        "authors": [
            "Guni Sharon",
            "Michael Albert",
            "Tarun Rambha",
            "Stephen Boyles",
            "Peter Stone"
        ],
        "abstract": "This paper focuses on two commonly used path assignment policies for agents traversing a congested network: self-interested routing, and system-optimum routing. In the self-interested routing policy each agent selects a path that optimizes its own utility, while the system-optimum routing agents are assigned paths with the goal of maximizing system performance. This paper considers a scenario where a centralized network manager wishes to optimize utilities over all agents, i.e., implement a system-optimum routing policy. In many real-life scenarios, however, the system manager is unable to influence the route assignment of all agents due to limited influence on route choice decisions. Motivated by such scenarios, a computationally tractable method is presented that computes the minimal amount of agents that the system manager needs to influence (compliant agents) in order to achieve system optimal performance. Moreover, this methodology can also determine whether a given set of compliant agents is sufficient to achieve system optimum and compute the optimal route assignment for the compliant agents to do so. Experimental results are presented showing that in several large-scale, realistic traffic networks optimal flow can be achieved with as low as 13% of the agent being compliant and up to 54%.\n    ",
        "submission_date": "2017-09-27T00:00:00",
        "last_modified_date": "2017-09-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.09587",
        "title": "Multi-Label Classification of Patient Notes a Case Study on ICD Code Assignment",
        "authors": [
            "Tal Baumel",
            "Jumana Nassour-Kassis",
            "Raphael Cohen",
            "Michael Elhadad",
            "No`emie Elhadad"
        ],
        "abstract": "In the context of the Electronic Health Record, automated diagnosis coding of patient notes is a useful task, but a challenging one due to the large number of codes and the length of patient notes. We investigate four models for assigning multiple ICD codes to discharge summaries taken from both MIMIC II and III. We present Hierarchical Attention-GRU (HA-GRU), a hierarchical approach to tag a document by identifying the sentences relevant for each label. HA-GRU achieves state-of-the art results. Furthermore, the learned sentence-level attention layer highlights the model decision process, allows easier error analysis, and suggests future directions for improvement.\n    ",
        "submission_date": "2017-09-27T00:00:00",
        "last_modified_date": "2017-11-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.09735",
        "title": "Deep Haptic Model Predictive Control for Robot-Assisted Dressing",
        "authors": [
            "Zackory Erickson",
            "Henry M. Clever",
            "Greg Turk",
            "C. Karen Liu",
            "Charles C. Kemp"
        ],
        "abstract": "Robot-assisted dressing offers an opportunity to benefit the lives of many people with disabilities, such as some older adults. However, robots currently lack common sense about the physical implications of their actions on people. The physical implications of dressing are complicated by non-rigid garments, which can result in a robot indirectly applying high forces to a person's body. We present a deep recurrent model that, when given a proposed action by the robot, predicts the forces a garment will apply to a person's body. We also show that a robot can provide better dressing assistance by using this model with model predictive control. The predictions made by our model only use haptic and kinematic observations from the robot's end effector, which are readily attainable. Collecting training data from real world physical human-robot interaction can be time consuming, costly, and put people at risk. Instead, we train our predictive model using data collected in an entirely self-supervised fashion from a physics-based simulation. We evaluated our approach with a PR2 robot that attempted to pull a hospital gown onto the arms of 10 human participants. With a 0.2s prediction horizon, our controller succeeded at high rates and lowered applied force while navigating the garment around a persons fist and elbow without getting caught. Shorter prediction horizons resulted in significantly reduced performance with the sleeve catching on the participants' fists and elbows, demonstrating the value of our model's predictions. These behaviors of mitigating catches emerged from our deep predictive model and the controller objective function, which primarily penalizes high forces.\n    ",
        "submission_date": "2017-09-27T00:00:00",
        "last_modified_date": "2019-05-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.09816",
        "title": "Edina: Building an Open Domain Socialbot with Self-dialogues",
        "authors": [
            "Ben Krause",
            "Marco Damonte",
            "Mihai Dobre",
            "Daniel Duma",
            "Joachim Fainberg",
            "Federico Fancellu",
            "Emmanuel Kahembwe",
            "Jianpeng Cheng",
            "Bonnie Webber"
        ],
        "abstract": "We present Edina, the University of Edinburgh's social bot for the Amazon Alexa Prize competition. Edina is a conversational agent whose responses utilize data harvested from Amazon Mechanical Turk (AMT) through an innovative new technique we call self-dialogues. These are conversations in which a single AMT Worker plays both participants in a dialogue. Such dialogues are surprisingly natural, efficient to collect and reflective of relevant and/or trending topics. These self-dialogues provide training data for a generative neural network as well as a basis for soft rules used by a matching score component. Each match of a soft rule against a user utterance is associated with a confidence score which we show is strongly indicative of reply quality, allowing this component to self-censor and be effectively integrated with other components. Edina's full architecture features a rule-based system backing off to a matching score, backing off to a generative neural network. Our hybrid data-driven methodology thus addresses both coverage limitations of a strictly rule-based approach and the lack of guarantees of a strictly machine-learning approach.\n    ",
        "submission_date": "2017-09-28T00:00:00",
        "last_modified_date": "2017-09-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.09882",
        "title": "Are we done with object recognition? The iCub robot's perspective",
        "authors": [
            "Giulia Pasquale",
            "Carlo Ciliberto",
            "Francesca Odone",
            "Lorenzo Rosasco",
            "Lorenzo Natale"
        ],
        "abstract": "We report on an extensive study of the benefits and limitations of current deep learning approaches to object recognition in robot vision scenarios, introducing a novel dataset used for our investigation. To avoid the biases in currently available datasets, we consider a natural human-robot interaction setting to design a data-acquisition protocol for visual object recognition on the iCub humanoid robot. Analyzing the performance of off-the-shelf models trained off-line on large-scale image retrieval datasets, we show the necessity for knowledge transfer. We evaluate different ways in which this last step can be done, and identify the major bottlenecks affecting robotic scenarios. By studying both object categorization and identification problems, we highlight key differences between object recognition in robotics applications and in image retrieval tasks, for which the considered deep learning approaches have been originally designed. In a nutshell, our results confirm the remarkable improvements yield by deep learning in this setting, while pointing to specific open challenges that need be addressed for seamless deployment in robotics.\n    ",
        "submission_date": "2017-09-28T00:00:00",
        "last_modified_date": "2019-01-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.09902",
        "title": "Improving Efficiency in Convolutional Neural Network with Multilinear Filters",
        "authors": [
            "Dat Thanh Tran",
            "Alexandros Iosifidis",
            "Moncef Gabbouj"
        ],
        "abstract": "The excellent performance of deep neural networks has enabled us to solve several automatization problems, opening an era of autonomous devices. However, current deep net architectures are heavy with millions of parameters and require billions of floating point operations. Several works have been developed to compress a pre-trained deep network to reduce memory footprint and, possibly, computation. Instead of compressing a pre-trained network, in this work, we propose a generic neural network layer structure employing multilinear projection as the primary feature extractor. The proposed architecture requires several times less memory as compared to the traditional Convolutional Neural Networks (CNN), while inherits the similar design principles of a CNN. In addition, the proposed architecture is equipped with two computation schemes that enable computation reduction or scalability. Experimental results show the effectiveness of our compact projection that outperforms traditional CNN, while requiring far fewer parameters.\n    ",
        "submission_date": "2017-09-28T00:00:00",
        "last_modified_date": "2017-10-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.10082",
        "title": "Towards Optimally Decentralized Multi-Robot Collision Avoidance via Deep Reinforcement Learning",
        "authors": [
            "Pinxin Long",
            "Tingxiang Fan",
            "Xinyi Liao",
            "Wenxi Liu",
            "Hao Zhang",
            "Jia Pan"
        ],
        "abstract": "Developing a safe and efficient collision avoidance policy for multiple robots is challenging in the decentralized scenarios where each robot generate its paths without observing other robots' states and intents. While other distributed multi-robot collision avoidance systems exist, they often require extracting agent-level features to plan a local collision-free action, which can be computationally prohibitive and not robust. More importantly, in practice the performance of these methods are much lower than their centralized counterparts.\n",
        "submission_date": "2017-09-28T00:00:00",
        "last_modified_date": "2018-05-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.10087",
        "title": "Learning Complex Dexterous Manipulation with Deep Reinforcement Learning and Demonstrations",
        "authors": [
            "Aravind Rajeswaran",
            "Vikash Kumar",
            "Abhishek Gupta",
            "Giulia Vezzani",
            "John Schulman",
            "Emanuel Todorov",
            "Sergey Levine"
        ],
        "abstract": "Dexterous multi-fingered hands are extremely versatile and provide a generic way to perform a multitude of tasks in human-centric environments. However, effectively controlling them remains challenging due to their high dimensionality and large number of potential contacts. Deep reinforcement learning (DRL) provides a model-agnostic approach to control complex dynamical systems, but has not been shown to scale to high-dimensional dexterous manipulation. Furthermore, deployment of DRL on physical systems remains challenging due to sample inefficiency. Consequently, the success of DRL in robotics has thus far been limited to simpler manipulators and tasks. In this work, we show that model-free DRL can effectively scale up to complex manipulation tasks with a high-dimensional 24-DoF hand, and solve them from scratch in simulated experiments. Furthermore, with the use of a small number of human demonstrations, the sample complexity can be significantly reduced, which enables learning with sample sizes equivalent to a few hours of robot experience. The use of demonstrations result in policies that exhibit very natural movements and, surprisingly, are also substantially more robust.\n    ",
        "submission_date": "2017-09-28T00:00:00",
        "last_modified_date": "2018-06-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.10089",
        "title": "Overcoming Exploration in Reinforcement Learning with Demonstrations",
        "authors": [
            "Ashvin Nair",
            "Bob McGrew",
            "Marcin Andrychowicz",
            "Wojciech Zaremba",
            "Pieter Abbeel"
        ],
        "abstract": "Exploration in environments with sparse rewards has been a persistent problem in reinforcement learning (RL). Many tasks are natural to specify with a sparse reward, and manually shaping a reward function can result in suboptimal performance. However, finding a non-zero reward is exponentially more difficult with increasing task horizon or action dimensionality. This puts many real-world tasks out of practical reach of RL methods. In this work, we use demonstrations to overcome the exploration problem and successfully learn to perform long-horizon, multi-step robotics tasks with continuous control such as stacking blocks with a robot arm. Our method, which builds on top of Deep Deterministic Policy Gradients and Hindsight Experience Replay, provides an order of magnitude of speedup over RL on simulated robotics tasks. It is simple to implement and makes only the additional assumption that we can collect a small set of demonstrations. Furthermore, our method is able to solve tasks not solvable by either RL or behavior cloning alone, and often ends up outperforming the demonstrator policy.\n    ",
        "submission_date": "2017-09-28T00:00:00",
        "last_modified_date": "2018-02-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.10204",
        "title": "A Neural Comprehensive Ranker (NCR) for Open-Domain Question Answering",
        "authors": [
            "Bin Bi",
            "Hao Ma"
        ],
        "abstract": "This paper proposes a novel neural machine reading model for open-domain question answering at scale. Existing machine comprehension models typically assume that a short piece of relevant text containing answers is already identified and given to the models, from which the models are designed to extract answers. This assumption, however, is not realistic for building a large-scale open-domain question answering system which requires both deep text understanding and identifying relevant text from corpus simultaneously.\n",
        "submission_date": "2017-09-29T00:00:00",
        "last_modified_date": "2017-10-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.10205",
        "title": "Neural and Synaptic Array Transceiver: A Brain-Inspired Computing Framework for Embedded Learning",
        "authors": [
            "Georgios Detorakis",
            "Sadique Sheik",
            "Charles Augustine",
            "Somnath Paul",
            "Bruno U. Pedroni",
            "Nikil Dutt",
            "Jeffrey Krichmar",
            "Gert Cauwenberghs",
            "Emre Neftci"
        ],
        "abstract": "Embedded, continual learning for autonomous and adaptive behavior is a key application of neuromorphic hardware. However, neuromorphic implementations of embedded learning at large scales that are both flexible and efficient have been hindered by a lack of a suitable algorithmic framework. As a result, the most neuromorphic hardware is trained off-line on large clusters of dedicated processors or GPUs and transferred post hoc to the device. We address this by introducing the neural and synaptic array transceiver (NSAT), a neuromorphic computational framework facilitating flexible and efficient embedded learning by matching algorithmic requirements and neural and synaptic dynamics. NSAT supports event-driven supervised, unsupervised and reinforcement learning algorithms including deep learning. We demonstrate the NSAT in a wide range of tasks, including the simulation of Mihalas-Niebur neuron, dynamic neural fields, event-driven random back-propagation for event-based deep learning, event-based contrastive divergence for unsupervised learning, and voltage-based learning rules for sequence learning. We anticipate that this contribution will establish the foundation for a new generation of devices enabling adaptive mobile systems, wearable devices, and robots with data-driven autonomy.\n    ",
        "submission_date": "2017-09-29T00:00:00",
        "last_modified_date": "2018-08-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.10207",
        "title": "Provably Minimally-Distorted Adversarial Examples",
        "authors": [
            "Nicholas Carlini",
            "Guy Katz",
            "Clark Barrett",
            "David L. Dill"
        ],
        "abstract": "The ability to deploy neural networks in real-world, safety-critical systems is severely limited by the presence of adversarial examples: slightly perturbed inputs that are misclassified by the network. In recent years, several techniques have been proposed for increasing robustness to adversarial examples --- and yet most of these have been quickly shown to be vulnerable to future attacks. For example, over half of the defenses proposed by papers accepted at ICLR 2018 have already been broken. We propose to address this difficulty through formal verification techniques. We show how to construct provably minimally distorted adversarial examples: given an arbitrary neural network and input sample, we can construct adversarial examples which we prove are of minimal distortion. Using this approach, we demonstrate that one of the recent ICLR defense proposals, adversarial retraining, provably succeeds at increasing the distortion required to construct adversarial examples by a factor of 4.2.\n    ",
        "submission_date": "2017-09-29T00:00:00",
        "last_modified_date": "2018-02-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.10423",
        "title": "Learning how to learn: an adaptive dialogue agent for incrementally learning visually grounded word meanings",
        "authors": [
            "Yanchao Yu",
            "Arash Eshghi",
            "Oliver Lemon"
        ],
        "abstract": "We present an optimised multi-modal dialogue agent for interactive learning of visually grounded word meanings from a human tutor, trained on real human-human tutoring data. Within a life-long interactive learning period, the agent, trained using Reinforcement Learning (RL), must be able to handle natural conversations with human users and achieve good learning performance (accuracy) while minimising human effort in the learning process. We train and evaluate this system in interaction with a simulated human tutor, which is built on the BURCHAK corpus -- a Human-Human Dialogue dataset for the visual learning task. The results show that: 1) The learned policy can coherently interact with the simulated user to achieve the goal of the task (i.e. learning visual attributes of objects, e.g. colour and shape); and 2) it finds a better trade-off between classifier accuracy and tutoring costs than hand-crafted rule-based policies, including ones with dynamic policies.\n    ",
        "submission_date": "2017-09-29T00:00:00",
        "last_modified_date": "2017-09-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.10426",
        "title": "Training an adaptive dialogue policy for interactive learning of visually grounded word meanings",
        "authors": [
            "Yanchao Yu",
            "Arash Eshghi",
            "Oliver Lemon"
        ],
        "abstract": "We present a multi-modal dialogue system for interactive learning of perceptually grounded word meanings from a human tutor. The system integrates an incremental, semantic parsing/generation framework - Dynamic Syntax and Type Theory with Records (DS-TTR) - with a set of visual classifiers that are learned throughout the interaction and which ground the meaning representations that it produces. We use this system in interaction with a simulated human tutor to study the effects of different dialogue policies and capabilities on the accuracy of learned meanings, learning rates, and efforts/costs to the tutor. We show that the overall performance of the learning agent is affected by (1) who takes initiative in the dialogues; (2) the ability to express/use their confidence level about visual attributes; and (3) the ability to process elliptical and incrementally constructed dialogue turns. Ultimately, we train an adaptive dialogue policy which optimises the trade-off between classifier accuracy and tutoring costs.\n    ",
        "submission_date": "2017-09-29T00:00:00",
        "last_modified_date": "2017-09-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.10431",
        "title": "The BURCHAK corpus: a Challenge Data Set for Interactive Learning of Visually Grounded Word Meanings",
        "authors": [
            "Yanchao Yu",
            "Arash Eshghi",
            "Gregory Mills",
            "Oliver Joseph Lemon"
        ],
        "abstract": "We motivate and describe a new freely available human-human dialogue dataset for interactive learning of visually grounded word meanings through ostensive definition by a tutor to a learner. The data has been collected using a novel, character-by-character variant of the DiET chat tool (Healey et al., 2003; Mills and Healey, submitted) with a novel task, where a Learner needs to learn invented visual attribute words (such as \" burchak \" for square) from a tutor. As such, the text-based interactions closely resemble face-to-face conversation and thus contain many of the linguistic phenomena encountered in natural, spontaneous dialogue. These include self-and other-correction, mid-sentence continuations, interruptions, overlaps, fillers, and hedges. We also present a generic n-gram framework for building user (i.e. tutor) simulations from this type of incremental data, which is freely available to researchers. We show that the simulations produce outputs that are similar to the original data (e.g. 78% turn match similarity). Finally, we train and evaluate a Reinforcement Learning dialogue control agent for learning visually grounded word meanings, trained from the BURCHAK corpus. The learned policy shows comparable performance to a rule-based system built previously.\n    ",
        "submission_date": "2017-09-29T00:00:00",
        "last_modified_date": "2017-09-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.10445",
        "title": "Synonym Discovery with Etymology-based Word Embeddings",
        "authors": [
            "Seunghyun Yoon",
            "Pablo Estrada",
            "Kyomin Jung"
        ],
        "abstract": "We propose a novel approach to learn word embeddings based on an extended version of the distributional hypothesis. Our model derives word embedding vectors using the etymological composition of words, rather than the context in which they appear. It has the strength of not requiring a large text corpus, but instead it requires reliable access to etymological roots of words, making it specially fit for languages with logographic writing systems. The model consists on three steps: (1) building an etymological graph, which is a bipartite network of words and etymological roots, (2) obtaining the biadjacency matrix of the etymological graph and reducing its dimensionality, (3) using columns/rows of the resulting matrices as embedding vectors. We test our model in the Chinese and Sino-Korean vocabularies. Our graphs are formed by a set of 117,000 Chinese words, and a set of 135,000 Sino-Korean words. In both cases we show that our model performs well in the task of synonym discovery.\n    ",
        "submission_date": "2017-09-29T00:00:00",
        "last_modified_date": "2017-12-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.10489",
        "title": "Self-supervised Deep Reinforcement Learning with Generalized Computation Graphs for Robot Navigation",
        "authors": [
            "Gregory Kahn",
            "Adam Villaflor",
            "Bosen Ding",
            "Pieter Abbeel",
            "Sergey Levine"
        ],
        "abstract": "Enabling robots to autonomously navigate complex environments is essential for real-world deployment. Prior methods approach this problem by having the robot maintain an internal map of the world, and then use a localization and planning method to navigate through the internal map. However, these approaches often include a variety of assumptions, are computationally intensive, and do not learn from failures. In contrast, learning-based methods improve as the robot acts in the environment, but are difficult to deploy in the real-world due to their high sample complexity. To address the need to learn complex policies with few samples, we propose a generalized computation graph that subsumes value-based model-free methods and model-based methods, with specific instantiations interpolating between model-free and model-based. We then instantiate this graph to form a navigation model that learns from raw images and is sample efficient. Our simulated car experiments explore the design decisions of our navigation model, and show our approach outperforms single-step and $N$-step double Q-learning. We also evaluate our approach on a real-world RC car and show it can learn to navigate through a complex indoor environment with a few hours of fully autonomous, self-supervised training. Videos of the experiments and code can be found at ",
        "submission_date": "2017-09-29T00:00:00",
        "last_modified_date": "2018-05-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1709.10494",
        "title": "Discovery and recognition of motion primitives in human activities",
        "authors": [
            "Marta Sanzari",
            "Valsamis Ntouskos",
            "Fiora Pirri"
        ],
        "abstract": "We present a novel framework for the automatic discovery and recognition of motion primitives in videos of human activities. Given the 3D pose of a human in a video, human motion primitives are discovered by optimizing the `motion flux', a quantity which captures the motion variation of a group of skeletal joints. A normalization of the primitives is proposed in order to make them invariant with respect to a subject anatomical variations and data sampling rate. The discovered primitives are unknown and unlabeled and are unsupervisedly collected into classes via a hierarchical non-parametric Bayes mixture model. Once classes are determined and labeled they are further analyzed for establishing models for recognizing discovered primitives. Each primitive model is defined by a set of learned parameters.\n",
        "submission_date": "2017-09-29T00:00:00",
        "last_modified_date": "2019-02-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.00262",
        "title": "Fine-grained Event Learning of Human-Object Interaction with LSTM-CRF",
        "authors": [
            "Tuan Do",
            "James Pustejovsky"
        ],
        "abstract": "Event learning is one of the most important problems in AI. However, notwithstanding significant research efforts, it is still a very complex task, especially when the events involve the interaction of humans or agents with other objects, as it requires modeling human kinematics and object movements. This study proposes a methodology for learning complex human-object interaction (HOI) events, involving the recording, annotation and classification of event interactions. For annotation, we allow multiple interpretations of a motion capture by slicing over its temporal span, for classification, we use Long-Short Term Memory (LSTM) sequential models with Conditional Randon Field (CRF) for constraints of outputs. Using a setup involving captures of human-object interaction as three dimensional inputs, we argue that this approach could be used for event types involving complex spatio-temporal dynamics.\n    ",
        "submission_date": "2017-09-30T00:00:00",
        "last_modified_date": "2017-09-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.00310",
        "title": "Personalized Recommender System for Children's Book Recommendation with A Realtime Interactive Robot",
        "authors": [
            "Yun Liu",
            "Tianmeng Gao",
            "Baolin Song",
            "Chengwei Huang"
        ],
        "abstract": "In this paper we study the personalized book recommender system in a child-robot interactive environment. Firstly, we propose a novel text search algorithm using an inverse filtering mechanism that improves the efficiency. Secondly, we propose a user interest prediction method based on the Bayesian network and a novel feedback mechanism. According to children's fuzzy language input, the proposed method gives the predicted interests. Thirdly, the domain specific synonym association is proposed based on word vectorization, in order to improve the understanding of user intention. Experimental results show that the proposed recommender system has an improved performance and it can operate on embedded consumer devices with limited computational resources.\n    ",
        "submission_date": "2017-10-01T00:00:00",
        "last_modified_date": "2023-05-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.00448",
        "title": "Learning event representation: As sparse as possible, but not sparser",
        "authors": [
            "Tuan Do",
            "James Pustejovsky"
        ],
        "abstract": "Selecting an optimal event representation is essential for event classification in real world contexts. In this paper, we investigate the application of qualitative spatial reasoning (QSR) frameworks for classification of human-object interaction in three dimensional space, in comparison with the use of quantitative feature extraction approaches for the same purpose. In particular, we modify QSRLib, a library that allows computation of Qualitative Spatial Relations and Calculi, and employ it for feature extraction, before inputting features into our neural network models. Using an experimental setup involving motion captures of human-object interaction as three dimensional inputs, we observe that the use of qualitative spatial features significantly improves the performance of our machine learning algorithm against our baseline, while quantitative features of similar kinds fail to deliver similar improvement. We also observe that sequential representations of QSR features yield the best classification performance. A result of our learning method is a simple approach to the qualitative representation of 3D activities as compositions of 2D actions that can be visualized and learned using 2-dimensional QSR.\n    ",
        "submission_date": "2017-10-02T00:00:00",
        "last_modified_date": "2017-10-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.00459",
        "title": "Deep Abstract Q-Networks",
        "authors": [
            "Melrose Roderick",
            "Christopher Grimm",
            "Stefanie Tellex"
        ],
        "abstract": "We examine the problem of learning and planning on high-dimensional domains with long horizons and sparse rewards. Recent approaches have shown great successes in many Atari 2600 domains. However, domains with long horizons and sparse rewards, such as Montezuma's Revenge and Venture, remain challenging for existing methods. Methods using abstraction (Dietterich 2000; Sutton, Precup, and Singh 1999) have shown to be useful in tackling long-horizon problems. We combine recent techniques of deep reinforcement learning with existing model-based approaches using an expert-provided state abstraction. We construct toy domains that elucidate the problem of long horizons, sparse rewards and high-dimensional inputs, and show that our algorithm significantly outperforms previous methods on these domains. Our abstraction-based approach outperforms Deep Q-Networks (Mnih et al. 2015) on Montezuma's Revenge and Venture, and exhibits backtracking behavior that is absent from previous methods.\n    ",
        "submission_date": "2017-10-02T00:00:00",
        "last_modified_date": "2018-08-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.00489",
        "title": "SE3-Pose-Nets: Structured Deep Dynamics Models for Visuomotor Planning and Control",
        "authors": [
            "Arunkumar Byravan",
            "Felix Leeb",
            "Franziska Meier",
            "Dieter Fox"
        ],
        "abstract": "In this work, we present an approach to deep visuomotor control using structured deep dynamics models. Our deep dynamics model, a variant of SE3-Nets, learns a low-dimensional pose embedding for visuomotor control via an encoder-decoder structure. Unlike prior work, our dynamics model is structured: given an input scene, our network explicitly learns to segment salient parts and predict their pose-embedding along with their motion modeled as a change in the pose space due to the applied actions. We train our model using a pair of point clouds separated by an action and show that given supervision only in the form of point-wise data associations between the frames our network is able to learn a meaningful segmentation of the scene along with consistent poses. We further show that our model can be used for closed-loop control directly in the learned low-dimensional pose space, where the actions are computed by minimizing error in the pose space using gradient-based methods, similar to traditional model-based control. We present results on controlling a Baxter robot from raw depth data in simulation and in the real world and compare against two baseline deep networks. Our method runs in real-time, achieves good prediction of scene dynamics and outperforms the baseline methods on multiple control runs. Video results can be found at: ",
        "submission_date": "2017-10-02T00:00:00",
        "last_modified_date": "2017-10-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.00641",
        "title": "Improving speech recognition by revising gated recurrent units",
        "authors": [
            "Mirco Ravanelli",
            "Philemon Brakel",
            "Maurizio Omologo",
            "Yoshua Bengio"
        ],
        "abstract": "Speech recognition is largely taking advantage of deep learning, showing that substantial benefits can be obtained by modern Recurrent Neural Networks (RNNs). The most popular RNNs are Long Short-Term Memory (LSTMs), which typically reach state-of-the-art performance in many tasks thanks to their ability to learn long-term dependencies and robustness to vanishing gradients. Nevertheless, LSTMs have a rather complex design with three multiplicative gates, that might impair their efficient implementation. An attempt to simplify LSTMs has recently led to Gated Recurrent Units (GRUs), which are based on just two multiplicative gates.\n",
        "submission_date": "2017-09-29T00:00:00",
        "last_modified_date": "2017-09-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.00892",
        "title": "R\u00e9nyi Differential Privacy Mechanisms for Posterior Sampling",
        "authors": [
            "Joseph Geumlek",
            "Shuang Song",
            "Kamalika Chaudhuri"
        ],
        "abstract": "Using a recently proposed privacy definition of R\u00e9nyi Differential Privacy (RDP), we re-examine the inherent privacy of releasing a single sample from a posterior distribution. We exploit the impact of the prior distribution in mitigating the influence of individual data points. In particular, we focus on sampling from an exponential family and specific generalized linear models, such as logistic regression. We propose novel RDP mechanisms as well as offering a new RDP analysis for an existing method in order to add value to the RDP framework. Each method is capable of achieving arbitrary RDP privacy guarantees, and we offer experimental results of their efficacy.\n    ",
        "submission_date": "2017-10-02T00:00:00",
        "last_modified_date": "2017-10-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.00978",
        "title": "Supervised Q-walk for Learning Vector Representation of Nodes in Networks",
        "authors": [
            "Naimish Agarwal",
            "G.C. Nandi"
        ],
        "abstract": "Automatic feature learning algorithms are at the forefront of modern day machine learning research. We present a novel algorithm, supervised Q-walk, which applies Q-learning to generate random walks on graphs such that the walks prove to be useful for learning node features suitable for tackling with the node classification problem. We present another novel algorithm, k-hops neighborhood based confidence values learner, which learns confidence values of labels for unlabelled nodes in the network without first learning the node embedding. These confidence values aid in learning an apt reward function for Q-learning.\n",
        "submission_date": "2017-10-03T00:00:00",
        "last_modified_date": "2017-10-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.01079",
        "title": "Optimal DNN Primitive Selection with Partitioned Boolean Quadratic Programming",
        "authors": [
            "Andrew Anderson",
            "David Gregg"
        ],
        "abstract": "Deep Neural Networks (DNNs) require very large amounts of computation both for training and for inference when deployed in the field. Many different algorithms have been proposed to implement the most computationally expensive layers of DNNs. Further, each of these algorithms has a large number of variants, which offer different trade-offs of parallelism, data locality, memory footprint, and execution time. In addition, specific algorithms operate much more efficiently on specialized data layouts and formats.\n",
        "submission_date": "2017-10-03T00:00:00",
        "last_modified_date": "2018-11-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.01437",
        "title": "Duality of Graphical Models and Tensor Networks",
        "authors": [
            "Elina Robeva",
            "Anna Seigal"
        ],
        "abstract": "In this article we show the duality between tensor networks and undirected graphical models with discrete variables. We study tensor networks on hypergraphs, which we call tensor hypernetworks. We show that the tensor hypernetwork on a hypergraph exactly corresponds to the graphical model given by the dual hypergraph. We translate various notions under duality. For example, marginalization in a graphical model is dual to contraction in the tensor network. Algorithms also translate under duality. We show that belief propagation corresponds to a known algorithm for tensor network contraction. This article is a reminder that the research areas of graphical models and tensor networks can benefit from interaction.\n    ",
        "submission_date": "2017-10-04T00:00:00",
        "last_modified_date": "2017-10-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.01691",
        "title": "Context Embedding Networks",
        "authors": [
            "Kun Ho Kim",
            "Oisin Mac Aodha",
            "Pietro Perona"
        ],
        "abstract": "Low dimensional embeddings that capture the main variations of interest in collections of data are important for many applications. One way to construct these embeddings is to acquire estimates of similarity from the crowd. However, similarity is a multi-dimensional concept that varies from individual to individual. Existing models for learning embeddings from the crowd typically make simplifying assumptions such as all individuals estimate similarity using the same criteria, the list of criteria is known in advance, or that the crowd workers are not influenced by the data that they see. To overcome these limitations we introduce Context Embedding Networks (CENs). In addition to learning interpretable embeddings from images, CENs also model worker biases for different attributes along with the visual context i.e. the visual attributes highlighted by a set of images. Experiments on two noisy crowd annotated datasets show that modeling both worker bias and visual context results in more interpretable embeddings compared to existing approaches.\n    ",
        "submission_date": "2017-09-22T00:00:00",
        "last_modified_date": "2018-03-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.01692",
        "title": "IQ of Neural Networks",
        "authors": [
            "Dokhyam Hoshen",
            "Michael Werman"
        ],
        "abstract": "IQ tests are an accepted method for assessing human intelligence. The tests consist of several parts that must be solved under a time constraint. Of all the tested abilities, pattern recognition has been found to have the highest correlation with general intelligence. This is primarily because pattern recognition is the ability to find order in a noisy environment, a necessary skill for intelligent agents. In this paper, we propose a convolutional neural network (CNN) model for solving geometric pattern recognition problems. The CNN receives as input multiple ordered input images and outputs the next image according to the pattern. Our CNN is able to solve problems involving rotation, reflection, color, size and shape patterns and score within the top 5% of human performance.\n    ",
        "submission_date": "2017-09-29T00:00:00",
        "last_modified_date": "2017-09-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.01727",
        "title": "Privacy-Preserving Deep Inference for Rich User Data on The Cloud",
        "authors": [
            "Seyed Ali Osia",
            "Ali Shahin Shamsabadi",
            "Ali Taheri",
            "Kleomenis Katevas",
            "Hamid R. Rabiee",
            "Nicholas D. Lane",
            "Hamed Haddadi"
        ],
        "abstract": "Deep neural networks are increasingly being used in a variety of machine learning applications applied to rich user data on the cloud. However, this approach introduces a number of privacy and efficiency challenges, as the cloud operator can perform secondary inferences on the available data. Recently, advances in edge processing have paved the way for more efficient, and private, data processing at the source for simple tasks and lighter models, though they remain a challenge for larger, and more complicated models. In this paper, we present a hybrid approach for breaking down large, complex deep models for cooperative, privacy-preserving analytics. We do this by breaking down the popular deep architectures and fine-tune them in a particular way. We then evaluate the privacy benefits of this approach based on the information exposed to the cloud service. We also asses the local inference cost of different layers on a modern handset for mobile applications. Our evaluations show that by using certain kind of fine-tuning and embedding techniques and at a small processing costs, we can greatly reduce the level of information available to unintended tasks applied to the data feature on the cloud, and hence achieving the desired tradeoff between privacy and performance.\n    ",
        "submission_date": "2017-10-04T00:00:00",
        "last_modified_date": "2017-10-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.02035",
        "title": "HANDY: A Hybrid Association Rules Mining Approach for Network Layer Discovery of Services for Mobile Ad hoc Network",
        "authors": [
            "Noman Islam",
            "Zubair A. Shaikh",
            "Aqeel-ur-Rehman",
            "Muhammad Shahab Siddiqui"
        ],
        "abstract": "Mobile Ad hoc Network (MANET) is an infrastructure-less network formed between a set of mobile nodes. The discovery of services in MANET is a challenging job due to the unique properties of network. In this paper, a novel service discovery framework called Hybrid Association Rules Based Network Layer Discovery of Services for Ad hoc Networks (HANDY) has been proposed. HANDY provides three major research contributions. At first, it adopts a cross-layer optimized design for discovery of services that is based on simultaneous discovery of services and corresponding routes. Secondly, it provides a multi-level ontology-based approach to describe the services. This resolves the issue of semantic interoperability among the service consumers in a scalable fashion. Finally, to further optimize the performance of the discovery process, HANDY recommends exploiting the inherent associations present among the services. These associations are used in two ways. First, periodic service advertisements are performed based on these associations. In addition, when a response of a service discovery request is generated, correlated services are also attached with the response. The proposed service discovery scheme has been implemented in JIST/SWANS simulator. The results demonstrate that the proposed modifications give rise to improvement in hit ratio of the service consumers and latency of discovery process.\n    ",
        "submission_date": "2017-10-03T00:00:00",
        "last_modified_date": "2017-10-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.02221",
        "title": "Stacked Structure Learning for Lifted Relational Neural Networks",
        "authors": [
            "Gustav Sourek",
            "Martin Svatos",
            "Filip Zelezny",
            "Steven Schockaert",
            "Ondrej Kuzelka"
        ],
        "abstract": "Lifted Relational Neural Networks (LRNNs) describe relational domains using weighted first-order rules which act as templates for constructing feed-forward neural networks. While previous work has shown that using LRNNs can lead to state-of-the-art results in various ILP tasks, these results depended on hand-crafted rules. In this paper, we extend the framework of LRNNs with structure learning, thus enabling a fully automated learning process. Similarly to many ILP methods, our structure learning algorithm proceeds in an iterative fashion by top-down searching through the hypothesis space of all possible Horn clauses, considering the predicates that occur in the training examples as well as invented soft concepts entailed by the best weighted rules found so far. In the experiments, we demonstrate the ability to automatically induce useful hierarchical soft concepts leading to deep LRNNs with a competitive predictive power.\n    ",
        "submission_date": "2017-10-05T00:00:00",
        "last_modified_date": "2017-10-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.02238",
        "title": "How Much Chemistry Does a Deep Neural Network Need to Know to Make Accurate Predictions?",
        "authors": [
            "Garrett B. Goh",
            "Charles Siegel",
            "Abhinav Vishnu",
            "Nathan O. Hodas",
            "Nathan Baker"
        ],
        "abstract": "The meteoric rise of deep learning models in computer vision research, having achieved human-level accuracy in image recognition tasks is firm evidence of the impact of representation learning of deep neural networks. In the chemistry domain, recent advances have also led to the development of similar CNN models, such as Chemception, that is trained to predict chemical properties using images of molecular drawings. In this work, we investigate the effects of systematically removing and adding localized domain-specific information to the image channels of the training data. By augmenting images with only 3 additional basic information, and without introducing any architectural changes, we demonstrate that an augmented Chemception (AugChemception) outperforms the original model in the prediction of toxicity, activity, and solvation free energy. Then, by altering the information content in the images, and examining the resulting model's performance, we also identify two distinct learning patterns in predicting toxicity/activity as compared to solvation free energy. These patterns suggest that Chemception is learning about its tasks in the manner that is consistent with established knowledge. Thus, our work demonstrates that advanced chemical knowledge is not a pre-requisite for deep learning models to accurately predict complex chemical properties.\n    ",
        "submission_date": "2017-10-05T00:00:00",
        "last_modified_date": "2018-03-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.02248",
        "title": "Learnable Explicit Density for Continuous Latent Space and Variational Inference",
        "authors": [
            "Chin-Wei Huang",
            "Ahmed Touati",
            "Laurent Dinh",
            "Michal Drozdzal",
            "Mohammad Havaei",
            "Laurent Charlin",
            "Aaron Courville"
        ],
        "abstract": "In this paper, we study two aspects of the variational autoencoder (VAE): the prior distribution over the latent variables and its corresponding posterior. First, we decompose the learning of VAEs into layerwise density estimation, and argue that having a flexible prior is beneficial to both sample generation and inference. Second, we analyze the family of inverse autoregressive flows (inverse AF) and show that with further improvement, inverse AF could be used as universal approximation to any complicated posterior. Our analysis results in a unified approach to parameterizing a VAE, without the need to restrict ourselves to use factorial Gaussians in the latent real space.\n    ",
        "submission_date": "2017-10-06T00:00:00",
        "last_modified_date": "2017-10-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.02254",
        "title": "Lattice Recurrent Unit: Improving Convergence and Statistical Efficiency for Sequence Modeling",
        "authors": [
            "Chaitanya Ahuja",
            "Louis-Philippe Morency"
        ],
        "abstract": "Recurrent neural networks have shown remarkable success in modeling sequences. However low resource situations still adversely affect the generalizability of these models. We introduce a new family of models, called Lattice Recurrent Units (LRU), to address the challenge of learning deep multi-layer recurrent models with limited resources. LRU models achieve this goal by creating distinct (but coupled) flow of information inside the units: a first flow along time dimension and a second flow along depth dimension. It also offers a symmetry in how information can flow horizontally and vertically. We analyze the effects of decoupling three different components of our LRU model: Reset Gate, Update Gate and Projected State. We evaluate this family on new LRU models on computational convergence rates and statistical efficiency. Our experiments are performed on four publicly-available datasets, comparing with Grid-LSTM and Recurrent Highway networks. Our results show that LRU has better empirical computational convergence rates and statistical efficiency values, along with learning more accurate language models.\n    ",
        "submission_date": "2017-10-06T00:00:00",
        "last_modified_date": "2017-11-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.02280",
        "title": "Generating Nontrivial Melodies for Music as a Service",
        "authors": [
            "Yifei Teng",
            "An Zhao",
            "Camille Goudeseune"
        ],
        "abstract": "We present a hybrid neural network and rule-based system that generates pop music. Music produced by pure rule-based systems often sounds mechanical. Music produced by machine learning sounds better, but still lacks hierarchical temporal structure. We restore temporal hierarchy by augmenting machine learning with a temporal production grammar, which generates the music's overall structure and chord progressions. A compatible melody is then generated by a conditional variational recurrent autoencoder. The autoencoder is trained with eight-measure segments from a corpus of 10,000 MIDI files, each of which has had its melody track and chord progressions identified heuristically. The autoencoder maps melody into a multi-dimensional feature space, conditioned by the underlying chord progression. A melody is then generated by feeding a random sample from that space to the autoencoder's decoder, along with the chord progression generated by the grammar. The autoencoder can make musically plausible variations on an existing melody, suitable for recurring motifs. It can also reharmonize a melody to a new chord progression, keeping the rhythm and contour. The generated music compares favorably with that generated by other academic and commercial software designed for the music-as-a-service industry.\n    ",
        "submission_date": "2017-10-06T00:00:00",
        "last_modified_date": "2017-10-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.02338",
        "title": "Projection Based Weight Normalization for Deep Neural Networks",
        "authors": [
            "Lei Huang",
            "Xianglong Liu",
            "Bo Lang",
            "Bo Li"
        ],
        "abstract": "Optimizing deep neural networks (DNNs) often suffers from the ill-conditioned problem. We observe that the scaling-based weight space symmetry property in rectified nonlinear network will cause this negative effect. Therefore, we propose to constrain the incoming weights of each neuron to be unit-norm, which is formulated as an optimization problem over Oblique manifold. A simple yet efficient method referred to as projection based weight normalization (PBWN) is also developed to solve this problem. PBWN executes standard gradient updates, followed by projecting the updated weight back to Oblique manifold. This proposed method has the property of regularization and collaborates well with the commonly used batch normalization technique. We conduct comprehensive experiments on several widely-used image datasets including CIFAR-10, CIFAR-100, SVHN and ImageNet for supervised learning over the state-of-the-art convolutional neural networks, such as Inception, VGG and residual networks. The results show that our method is able to improve the performance of DNNs with different architectures consistently. We also apply our method to Ladder network for semi-supervised learning on permutation invariant MNIST dataset, and our method outperforms the state-of-the-art methods: we obtain test errors as 2.52%, 1.06%, and 0.91% with only 20, 50, and 100 labeled samples, respectively.\n    ",
        "submission_date": "2017-10-06T00:00:00",
        "last_modified_date": "2017-10-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.02543",
        "title": "Socially Compliant Navigation through Raw Depth Inputs with Generative Adversarial Imitation Learning",
        "authors": [
            "Lei Tai",
            "Jingwei Zhang",
            "Ming Liu",
            "Wolfram Burgard"
        ],
        "abstract": "We present an approach for mobile robots to learn to navigate in dynamic environments with pedestrians via raw depth inputs, in a socially compliant manner. To achieve this, we adopt a generative adversarial imitation learning (GAIL) strategy, which improves upon a pre-trained behavior cloning policy. Our approach overcomes the disadvantages of previous methods, as they heavily depend on the full knowledge of the location and velocity information of nearby pedestrians, which not only requires specific sensors, but also the extraction of such state information from raw sensory input could consume much computation time. In this paper, our proposed GAIL-based model performs directly on raw depth inputs and plans in real-time. Experiments show that our GAIL-based approach greatly improves the safety and efficiency of the behavior of mobile robots from pure behavior cloning. The real-world deployment also shows that our method is capable of guiding autonomous vehicles to navigate in a socially compliant manner directly through raw depth inputs. In addition, we release a simulation plugin for modeling pedestrian behaviors based on the social force model.\n    ",
        "submission_date": "2017-10-06T00:00:00",
        "last_modified_date": "2018-02-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.02754",
        "title": "Texture Fuzzy Segmentation using Skew Divergence Adaptive Affinity Functions",
        "authors": [
            "Jos\u00e9 F. S. Neto",
            "Waldson P. N. Leandro",
            "Matheus A. Gadelha",
            "Tiago S. Santos",
            "Bruno M. Carvalho",
            "Edgar Gardu\u00f1o"
        ],
        "abstract": "Digital image segmentation is the process of assigning distinct labels to different objects in a digital image, and the fuzzy segmentation algorithm has been successfully used in the segmentation of images from a wide variety of sources. However, the traditional fuzzy segmentation algorithm fails to segment objects that are characterized by textures whose patterns cannot be successfully described by simple statistics computed over a very restricted area. In this paper, we propose an extension of the fuzzy segmentation algorithm that uses adaptive textural affinity functions to perform the segmentation of such objects on bidimensional images. The adaptive affinity functions compute their appropriate neighborhood size as they compute the texture descriptors surrounding the seed spels (spatial elements), according to the characteristics of the texture being processed. The algorithm then segments the image with an appropriate neighborhood for each object. We performed experiments on mosaic images that were composed using images from the Brodatz database, and compared our results with the ones produced by a recently published texture segmentation algorithm, showing the applicability of our method.\n    ",
        "submission_date": "2017-10-07T00:00:00",
        "last_modified_date": "2017-10-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.02913",
        "title": "Artificial Neural Networks-Based Machine Learning for Wireless Networks: A Tutorial",
        "authors": [
            "Mingzhe Chen",
            "Ursula Challita",
            "Walid Saad",
            "Changchuan Yin",
            "M\u00e9rouane Debbah"
        ],
        "abstract": "Next-generation wireless networks must support ultra-reliable, low-latency communication and intelligently manage a massive number of Internet of Things (IoT) devices in real-time, within a highly dynamic environment. This need for stringent communication quality-of-service (QoS) requirements as well as mobile edge and core intelligence can only be realized by integrating fundamental notions of artificial intelligence (AI) and machine learning across the wireless infrastructure and end-user devices. In this context, this paper provides a comprehensive tutorial that introduces the main concepts of machine learning, in general, and artificial neural networks (ANNs), in particular, and their potential applications in wireless communications. For this purpose, we present a comprehensive overview on a number of key types of neural networks that include feed-forward, recurrent, spiking, and deep neural networks. For each type of neural network, we present the basic architecture and training procedure, as well as the associated challenges and opportunities. Then, we provide an in-depth overview on the variety of wireless communication problems that can be addressed using ANNs, ranging from communication using unmanned aerial vehicles to virtual reality and edge ",
        "submission_date": "2017-10-09T00:00:00",
        "last_modified_date": "2019-06-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.03163",
        "title": "Random Projection and Its Applications",
        "authors": [
            "Mahmoud Nabil"
        ],
        "abstract": "Random Projection is a foundational research topic that connects a bunch of machine learning algorithms under a similar mathematical basis. It is used to reduce the dimensionality of the dataset by projecting the data points efficiently to a smaller dimensions while preserving the original relative distance between the data points. In this paper, we are intended to explain random projection method, by explaining its mathematical background and foundation, the applications that are currently adopting it, and an overview on its current research perspective.\n    ",
        "submission_date": "2017-10-09T00:00:00",
        "last_modified_date": "2017-10-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.03184",
        "title": "On Formalizing Fairness in Prediction with Machine Learning",
        "authors": [
            "Pratik Gajane",
            "Mykola Pechenizkiy"
        ],
        "abstract": "Machine learning algorithms for prediction are increasingly being used in critical decisions affecting human lives. Various fairness formalizations, with no firm consensus yet, are employed to prevent such algorithms from systematically discriminating against people based on certain attributes protected by law. The aim of this article is to survey how fairness is formalized in the machine learning literature for the task of prediction and present these formalizations with their corresponding notions of distributive justice from the social sciences literature. We provide theoretical as well as empirical critiques of these notions from the social sciences literature and explain how these critiques limit the suitability of the corresponding fairness formalizations to certain domains. We also suggest two notions of distributive justice which address some of these critiques and discuss avenues for prospective fairness formalizations.\n    ",
        "submission_date": "2017-10-09T00:00:00",
        "last_modified_date": "2018-05-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.03189",
        "title": "Towards Agent-Based Model Specification in Smart Grid: A Cognitive Agent-based Computing Approach",
        "authors": [
            "Waseem Akram",
            "Muaz A. Niazi",
            "Laszlo Barna Iantovics"
        ],
        "abstract": "A smart grid can be considered as a complex network where each node represents a generation unit or a consumer. Whereas links can be used to represent transmission lines. One way to study complex systems is by using the agent-based modeling (ABM) paradigm. An ABM is a way of representing a complex system of autonomous agents interacting with each other. Previously, a number of studies have been presented in the smart grid domain making use of the ABM paradigm. However, to the best of our knowledge, none of these studies have focused on the specification aspect of ABM. An ABM specification is important not only for understanding but also for replication of the model. In this study, we focus on development as well as specification of ABM for smart grid. We propose an ABM by using a combination of agent-based and complex network-based approaches. For ABM specification, we use ODD and DREAM specification approaches. We analyze these two specification approaches qualitatively as well as quantitatively. Extensive experiments demonstrate that DREAM is a most useful approach as compared with ODD for modeling as well as for replication of models for smart grid.\n    ",
        "submission_date": "2017-10-01T00:00:00",
        "last_modified_date": "2017-11-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.03337",
        "title": "Standard detectors aren't (currently) fooled by physical adversarial stop signs",
        "authors": [
            "Jiajun Lu",
            "Hussein Sibai",
            "Evan Fabry",
            "David Forsyth"
        ],
        "abstract": "An adversarial example is an example that has been adjusted to produce the wrong label when presented to a system at test time. If adversarial examples existed that could fool a detector, they could be used to (for example) wreak havoc on roads populated with smart vehicles. Recently, we described our difficulties creating physical adversarial stop signs that fool a detector. More recently, Evtimov et al. produced a physical adversarial stop sign that fools a proxy model of a detector. In this paper, we show that these physical adversarial stop signs do not fool two standard detectors (YOLO and Faster RCNN) in standard configuration. Evtimov et al.'s construction relies on a crop of the image to the stop sign; this crop is then resized and presented to a classifier. We argue that the cropping and resizing procedure largely eliminates the effects of rescaling and of view angle. Whether an adversarial attack is robust under rescaling and change of view direction remains moot. We argue that attacking a classifier is very different from attacking a detector, and that the structure of detectors - which must search for their own bounding box, and which cannot estimate that box very accurately - likely makes it difficult to make adversarial patterns. Finally, an adversarial pattern on a physical object that could fool a detector would have to be adversarial in the face of a wide family of parametric distortions (scale; view angle; box shift inside the detector; illumination; and so on). Such a pattern would be of great theoretical and practical interest. There is currently no evidence that such patterns exist.\n    ",
        "submission_date": "2017-10-09T00:00:00",
        "last_modified_date": "2017-10-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.03393",
        "title": "Counterfactual Causality from First Principles?",
        "authors": [
            "Gregor G\u00f6ssler",
            "Oleg Sokolsky",
            "Jean-Bernard Stefani"
        ],
        "abstract": "In this position paper we discuss three main shortcomings of existing approaches to counterfactual causality from the computer science perspective, and sketch lines of work to try and overcome these issues: (1) causality definitions should be driven by a set of precisely specified requirements rather than specific examples; (2) causality frameworks should support system dynamics; (3) causality analysis should have a well-understood behavior in presence of abstraction.\n    ",
        "submission_date": "2017-10-10T00:00:00",
        "last_modified_date": "2017-10-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.03399",
        "title": "Prior Knowledge based mutation prioritization towards causal variant finding in rare disease",
        "authors": [
            "Vasundhara Dehiya",
            "Jaya Thomas",
            "Lee Sael"
        ],
        "abstract": "How do we determine the mutational effects in exome sequencing data with little or no statistical evidence? Can protein structural information fill in the gap of not having enough statistical evidence? In this work, we answer the two questions with the goal towards determining pathogenic effects of rare variants in rare disease. We take the approach of determining the importance of point mutation loci focusing on protein structure features. The proposed structure-based features contain information about geometric, physicochemical, and functional information of mutation loci and those of structural neighbors of the loci. The performance of the structure-based features trained on 80\\% of HumDiv and tested on 20\\% of HumDiv and on ClinVar datasets showed high levels of discernibility in the mutation's pathogenic or benign effects: F score of 0.71 and 0.68 respectively using multi-layer perceptron. Combining structure- and sequence-based feature further improve the accuracy: F score of 0.86 (HumDiv) and 0.75 (ClinVar). Also, careful examination of the rare variants in rare diseases cases showed that structure-based features are important in discerning importance of variant loci.\n    ",
        "submission_date": "2017-10-10T00:00:00",
        "last_modified_date": "2017-10-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.03414",
        "title": "Network of Recurrent Neural Networks",
        "authors": [
            "Chao-Ming Wang"
        ],
        "abstract": "We describe a class of systems theory based neural networks called \"Network Of Recurrent neural networks\" (NOR), which introduces a new structure level to RNN related models. In NOR, RNNs are viewed as the high-level neurons and are used to build the high-level layers. More specifically, we propose several methodologies to design different NOR topologies according to the theory of system evolution. Then we carry experiments on three different tasks to evaluate our implementations. Experimental results show our models outperform simple RNN remarkably under the same number of parameters, and sometimes achieve even better results than GRU and LSTM.\n    ",
        "submission_date": "2017-10-10T00:00:00",
        "last_modified_date": "2017-10-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.03430",
        "title": "Learning to Rank Question-Answer Pairs using Hierarchical Recurrent Encoder with Latent Topic Clustering",
        "authors": [
            "Seunghyun Yoon",
            "Joongbo Shin",
            "Kyomin Jung"
        ],
        "abstract": "In this paper, we propose a novel end-to-end neural architecture for ranking candidate answers, that adapts a hierarchical recurrent neural network and a latent topic clustering module. With our proposed model, a text is encoded to a vector representation from an word-level to a chunk-level to effectively capture the entire meaning. In particular, by adapting the hierarchical structure, our model shows very small performance degradations in longer text comprehension while other state-of-the-art recurrent neural network models suffer from it. Additionally, the latent topic clustering module extracts semantic information from target samples. This clustering module is useful for any text related tasks by allowing each data sample to find its nearest topic cluster, thus helping the neural network model analyze the entire data. We evaluate our models on the Ubuntu Dialogue Corpus and consumer electronic domain question answering dataset, which is related to Samsung products. The proposed model shows state-of-the-art results for ranking question-answer pairs.\n    ",
        "submission_date": "2017-10-10T00:00:00",
        "last_modified_date": "2018-04-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.03641",
        "title": "Continuous Adaptation via Meta-Learning in Nonstationary and Competitive Environments",
        "authors": [
            "Maruan Al-Shedivat",
            "Trapit Bansal",
            "Yuri Burda",
            "Ilya Sutskever",
            "Igor Mordatch",
            "Pieter Abbeel"
        ],
        "abstract": "Ability to continuously learn and adapt from limited experience in nonstationary environments is an important milestone on the path towards general intelligence. In this paper, we cast the problem of continuous adaptation into the learning-to-learn framework. We develop a simple gradient-based meta-learning algorithm suitable for adaptation in dynamically changing and adversarial scenarios. Additionally, we design a new multi-agent competitive environment, RoboSumo, and define iterated adaptation games for testing various aspects of continuous adaptation strategies. We demonstrate that meta-learning enables significantly more efficient adaptation than reactive baselines in the few-shot regime. Our experiments with a population of agents that learn and compete suggest that meta-learners are the fittest.\n    ",
        "submission_date": "2017-10-10T00:00:00",
        "last_modified_date": "2018-02-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.03753",
        "title": "Optimizing Long Short-Term Memory Recurrent Neural Networks Using Ant Colony Optimization to Predict Turbine Engine Vibration",
        "authors": [
            "AbdElRahman ElSaid",
            "Travis Desell",
            "Fatima El Jamiy",
            "James Higgins",
            "Brandon Wild"
        ],
        "abstract": "This article expands on research that has been done to develop a recurrent neural network (RNN) capable of predicting aircraft engine vibrations using long short-term memory (LSTM) neurons. LSTM RNNs can provide a more generalizable and robust method for prediction over analytical calculations of engine vibration, as analytical calculations must be solved iteratively based on specific empirical engine parameters, making this approach ungeneralizable across multiple engines. In initial work, multiple LSTM RNN architectures were proposed, evaluated and compared. This research improves the performance of the most effective LSTM network design proposed in the previous work by using a promising neuroevolution method based on ant colony optimization (ACO) to develop and enhance the LSTM cell structure of the network. A parallelized version of the ACO neuroevolution algorithm has been developed and the evolved LSTM RNNs were compared to the previously used fixed topology. The evolved networks were trained on a large database of flight data records obtained from an airline containing flights that suffered from excessive vibration. Results were obtained using MPI (Message Passing Interface) on a high performance computing (HPC) cluster, evolving 1000 different LSTM cell structures using 168 cores over 4 days. The new evolved LSTM cells showed an improvement of 1.35%, reducing prediction error from 5.51% to 4.17% when predicting excessive engine vibrations 10 seconds in the future, while at the same time dramatically reducing the number of weights from 21,170 to 11,810.\n    ",
        "submission_date": "2017-10-10T00:00:00",
        "last_modified_date": "2017-10-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.03803",
        "title": "Day-Ahead Solar Forecasting Based on Multi-level Solar Measurements",
        "authors": [
            "Mohana Alanazi",
            "Mohsen Mahoor",
            "Amin Khodaei"
        ],
        "abstract": "The growing proliferation in solar deployment, especially at distribution level, has made the case for power system operators to develop more accurate solar forecasting models. This paper proposes a solar photovoltaic (PV) generation forecasting model based on multi-level solar measurements and utilizing a nonlinear autoregressive with exogenous input (NARX) model to improve the training and achieve better forecasts. The proposed model consists of four stages of data preparation, establishment of fitting model, model training, and forecasting. The model is tested under different weather conditions. Numerical simulations exhibit the acceptable performance of the model when compared to forecasting results obtained from two-level and single-level studies.\n    ",
        "submission_date": "2017-10-10T00:00:00",
        "last_modified_date": "2017-10-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.03875",
        "title": "Learning Task Specifications from Demonstrations",
        "authors": [
            "Marcell Vazquez-Chanlatte",
            "Susmit Jha",
            "Ashish Tiwari",
            "Mark K. Ho",
            "Sanjit A. Seshia"
        ],
        "abstract": "Real world applications often naturally decompose into several sub-tasks. In many settings (e.g., robotics) demonstrations provide a natural way to specify the sub-tasks. However, most methods for learning from demonstrations either do not provide guarantees that the artifacts learned for the sub-tasks can be safely recombined or limit the types of composition available. Motivated by this deficit, we consider the problem of inferring Boolean non-Markovian rewards (also known as logical trace properties or specifications) from demonstrations provided by an agent operating in an uncertain, stochastic environment. Crucially, specifications admit well-defined composition rules that are typically easy to interpret. In this paper, we formulate the specification inference task as a maximum a posteriori (MAP) probability inference problem, apply the principle of maximum entropy to derive an analytic demonstration likelihood model and give an efficient approach to search for the most likely specification in a large candidate pool of specifications. In our experiments, we demonstrate how learning specifications can help avoid common problems that often arise due to ad-hoc reward composition.\n    ",
        "submission_date": "2017-10-11T00:00:00",
        "last_modified_date": "2018-10-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.03978",
        "title": "Exploring Cross-Domain Data Dependencies for Smart Homes to Improve Energy Efficiency",
        "authors": [
            "Shamaila Iram",
            "Terrence Fernando",
            "May Bassanino"
        ],
        "abstract": "Over the past decade, the idea of smart homes has been conceived as a potential solution to counter energy crises or to at least mitigate its intensive destructive consequences in the residential building sector.\n    ",
        "submission_date": "2017-10-11T00:00:00",
        "last_modified_date": "2017-10-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.04076",
        "title": "Deep Semantic Abstractions of Everyday Human Activities: On Commonsense Representations of Human Interactions",
        "authors": [
            "Jakob Suchan",
            "Mehul Bhatt"
        ],
        "abstract": "We propose a deep semantic characterization of space and motion categorically from the viewpoint of grounding embodied human-object interactions. Our key focus is on an ontological model that would be adept to formalisation from the viewpoint of commonsense knowledge representation, relational learning, and qualitative reasoning about space and motion in cognitive robotics settings. We demonstrate key aspects of the space & motion ontology and its formalization as a representational framework in the backdrop of select examples from a dataset of everyday activities. Furthermore, focussing on human-object interaction data obtained from RGBD sensors, we also illustrate how declarative (spatio-temporal) reasoning in the (constraint) logic programming family may be performed with the developed deep semantic abstractions.\n    ",
        "submission_date": "2017-10-10T00:00:00",
        "last_modified_date": "2017-10-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.04162",
        "title": "Synkhronos: a Multi-GPU Theano Extension for Data Parallelism",
        "authors": [
            "Adam Stooke",
            "Pieter Abbeel"
        ],
        "abstract": "We present Synkhronos, an extension to Theano for multi-GPU computations leveraging data parallelism. Our framework provides automated execution and synchronization across devices, allowing users to continue to write serial programs without risk of race conditions. The NVIDIA Collective Communication Library is used for high-bandwidth inter-GPU communication. Further enhancements to the Theano function interface include input slicing (with aggregation) and input indexing, which perform common data-parallel computation patterns efficiently. One example use case is synchronous SGD, which has recently been shown to scale well for a growing set of deep learning problems. When training ResNet-50, we achieve a near-linear speedup of 7.5x on an NVIDIA DGX-1 using 8 GPUs, relative to Theano-only code running a single GPU in isolation. Yet Synkhronos remains general to any data-parallel computation programmable in Theano. By implementing parallelism at the level of individual Theano functions, our framework uniquely addresses a niche between manual multi-device programming and prescribed multi-GPU training routines.\n    ",
        "submission_date": "2017-10-11T00:00:00",
        "last_modified_date": "2017-10-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.04312",
        "title": "Measurement Context Extraction from Text: Discovering Opportunities and Gaps in Earth Science",
        "authors": [
            "Kyle Hundman",
            "Chris A. Mattmann"
        ],
        "abstract": "We propose Marve, a system for extracting measurement values, units, and related words from natural language text. Marve uses conditional random fields (CRF) to identify measurement values and units, followed by a rule-based system to find related entities, descriptors and modifiers within a sentence. Sentence tokens are represented by an undirected graphical model, and rules are based on part-of-speech and word dependency patterns connecting values and units to contextual words. Marve is unique in its focus on measurement context and early experimentation demonstrates Marve's ability to generate high-precision extractions with strong recall. We also discuss Marve's role in refining measurement requirements for NASA's proposed HyspIRI mission, a hyperspectral infrared imaging satellite that will study the world's ecosystems. In general, our work with HyspIRI demonstrates the value of semantic measurement extractions in characterizing quantitative discussion contained in large corpuses of natural language text. These extractions accelerate broad, cross-cutting research and expose scientists new algorithmic approaches and experimental nuances. They also facilitate identification of scientific opportunities enabled by HyspIRI leading to more efficient scientific investment and research.\n    ",
        "submission_date": "2017-10-11T00:00:00",
        "last_modified_date": "2017-10-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.04334",
        "title": "DisSent: Sentence Representation Learning from Explicit Discourse Relations",
        "authors": [
            "Allen Nie",
            "Erin D. Bennett",
            "Noah D. Goodman"
        ],
        "abstract": "Learning effective representations of sentences is one of the core missions of natural language understanding. Existing models either train on a vast amount of text, or require costly, manually curated sentence relation datasets. We show that with dependency parsing and rule-based rubrics, we can curate a high quality sentence relation task by leveraging explicit discourse relations. We show that our curated dataset provides an excellent signal for learning vector representations of sentence meaning, representing relations that can only be determined when the meanings of two sentences are combined. We demonstrate that the automatically curated corpus allows a bidirectional LSTM sentence encoder to yield high quality sentence embeddings and can serve as a supervised fine-tuning dataset for larger models such as BERT. Our fixed sentence embeddings achieve high performance on a variety of transfer tasks, including SentEval, and we achieve state-of-the-art results on Penn Discourse Treebank's implicit relation prediction task.\n    ",
        "submission_date": "2017-10-12T00:00:00",
        "last_modified_date": "2019-06-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.04380",
        "title": "Sign-Constrained Regularized Loss Minimization",
        "authors": [
            "Tsuyoshi Kato",
            "Misato Kobayashi",
            "Daisuke Sano"
        ],
        "abstract": "In practical analysis, domain knowledge about analysis target has often been accumulated, although, typically, such knowledge has been discarded in the statistical analysis stage, and the statistical tool has been applied as a black box. In this paper, we introduce sign constraints that are a handy and simple representation for non-experts in generic learning problems. We have developed two new optimization algorithms for the sign-constrained regularized loss minimization, called the sign-constrained Pegasos (SC-Pega) and the sign-constrained SDCA (SC-SDCA), by simply inserting the sign correction step into the original Pegasos and SDCA, respectively. We present theoretical analyses that guarantee that insertion of the sign correction step does not degrade the convergence rate for both algorithms. Two applications, where the sign-constrained learning is effective, are presented. The one is exploitation of prior information about correlation between explanatory variables and a target variable. The other is introduction of the sign-constrained to SVM-Pairwise method. Experimental results demonstrate significant improvement of generalization performance by introducing sign constraints in both applications.\n    ",
        "submission_date": "2017-10-12T00:00:00",
        "last_modified_date": "2017-10-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.04382",
        "title": "Marginal sequential Monte Carlo for doubly intractable models",
        "authors": [
            "Richard G. Everitt",
            "Dennis Prangle",
            "Philip Maybank",
            "Mark Bell"
        ],
        "abstract": "Bayesian inference for models that have an intractable partition function is known as a doubly intractable problem, where standard Monte Carlo methods are not applicable. The past decade has seen the development of auxiliary variable Monte Carlo techniques (M\u00f8ller et al., 2006; Murray et al., 2006) for tackling this problem; these approaches being members of the more general class of pseudo-marginal, or exact-approximate, Monte Carlo algorithms (Andrieu and Roberts, 2009), which make use of unbiased estimates of intractable posteriors. Everitt et al. (2017) investigated the use of exact-approximate importance sampling (IS) and sequential Monte Carlo (SMC) in doubly intractable problems, but focussed only on SMC algorithms that used data-point tempering. This paper describes SMC samplers that may use alternative sequences of distributions, and describes ways in which likelihood estimates may be improved adaptively as the algorithm progresses, building on ideas from Moores et al. (2015). This approach is compared with a number of alternative algorithms for doubly intractable problems, including approximate Bayesian computation (ABC), which we show is closely related to the method of M\u00f8ller et al. (2006).\n    ",
        "submission_date": "2017-10-12T00:00:00",
        "last_modified_date": "2017-10-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.04582",
        "title": "Is Epicurus the father of Reinforcement Learning?",
        "authors": [
            "Eleni Vasilaki"
        ],
        "abstract": "The Epicurean Philosophy is commonly thought as simplistic and hedonistic. Here I discuss how this is a misconception and explore its link to Reinforcement Learning. Based on the letters of Epicurus, I construct an objective function for hedonism which turns out to be equivalent of the Reinforcement Learning objective function when omitting the discount factor. I then discuss how Plato and Aristotle 's views that can be also loosely linked to Reinforcement Learning, as well as their weaknesses in relationship to it. Finally, I emphasise the close affinity of the Epicurean views and the Bellman equation.\n    ",
        "submission_date": "2017-10-12T00:00:00",
        "last_modified_date": "2017-10-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.04584",
        "title": "Towards Scalable Spectral Clustering via Spectrum-Preserving Sparsification",
        "authors": [
            "Yongyu Wang",
            "Zhuo Feng"
        ],
        "abstract": "The eigendeomposition of nearest-neighbor (NN) graph Laplacian matrices is the main computational bottleneck in spectral clustering. In this work, we introduce a highly-scalable, spectrum-preserving graph sparsification algorithm that enables to build ultra-sparse NN (u-NN) graphs with guaranteed preservation of the original graph spectrums, such as the first few eigenvectors of the original graph Laplacian. Our approach can immediately lead to scalable spectral clustering of large data networks without sacrificing solution quality. The proposed method starts from constructing low-stretch spanning trees (LSSTs) from the original graphs, which is followed by iteratively recovering small portions of \"spectrally critical\" off-tree edges to the LSSTs by leveraging a spectral off-tree embedding scheme. To determine the suitable amount of off-tree edges to be recovered to the LSSTs, an eigenvalue stability checking scheme is proposed, which enables to robustly preserve the first few Laplacian eigenvectors within the sparsified graph. Additionally, an incremental graph densification scheme is proposed for identifying extra edges that have been missing in the original NN graphs but can still play important roles in spectral clustering tasks. Our experimental results for a variety of well-known data sets show that the proposed method can dramatically reduce the complexity of NN graphs, leading to significant speedups in spectral clustering.\n    ",
        "submission_date": "2017-10-12T00:00:00",
        "last_modified_date": "2018-10-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.04743",
        "title": "Identifying On-time Reward Delivery Projects with Estimating Delivery Duration on Kickstarter",
        "authors": [
            "Thanh Tran",
            "Kyumin Lee",
            "Nguyen Vo",
            "Hongkyu Choi"
        ],
        "abstract": "In Crowdfunding platforms, people turn their prototype ideas into real products by raising money from the crowd, or invest in someone else's projects. In reward-based crowdfunding platforms such as Kickstarter and Indiegogo, selecting accurate reward delivery duration becomes crucial for creators, backers, and platform providers to keep the trust between the creators and the backers, and the trust between the platform providers and users. According to Kickstarter, 35% backers did not receive rewards on time. Unfortunately, little is known about on-time and late reward delivery projects, and there is no prior work to estimate reward delivery duration. To fill the gap, in this paper, we (i) extract novel features that reveal latent difficulty levels of project rewards; (ii) build predictive models to identify whether a creator will deliver all rewards in a project on time or not; and (iii) build a regression model to estimate accurate reward delivery duration (i.e., how long it will take to produce and deliver all the rewards). Experimental results show that our models achieve good performance -- 82.5% accuracy, 78.1 RMSE, and 0.108 NRMSE at the first 5% of the longest reward delivery duration.\n    ",
        "submission_date": "2017-10-12T00:00:00",
        "last_modified_date": "2017-10-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.04749",
        "title": "Explaining Aviation Safety Incidents Using Deep Temporal Multiple Instance Learning",
        "authors": [
            "Vijay Manikandan Janakiraman"
        ],
        "abstract": "Although aviation accidents are rare, safety incidents occur more frequently and require a careful analysis to detect and mitigate risks in a timely manner. Analyzing safety incidents using operational data and producing event-based explanations is invaluable to airline companies as well as to governing organizations such as the Federal Aviation Administration (FAA) in the United States. However, this task is challenging because of the complexity involved in mining multi-dimensional heterogeneous time series data, the lack of time-step-wise annotation of events in a flight, and the lack of scalable tools to perform analysis over a large number of events. In this work, we propose a precursor mining algorithm that identifies events in the multidimensional time series that are correlated with the safety incident. Precursors are valuable to systems health and safety monitoring and in explaining and forecasting safety incidents. Current methods suffer from poor scalability to high dimensional time series data and are inefficient in capturing temporal behavior. We propose an approach by combining multiple-instance learning (MIL) and deep recurrent neural networks (DRNN) to take advantage of MIL's ability to learn using weakly supervised data and DRNN's ability to model temporal behavior. We describe the algorithm, the data, the intuition behind taking a MIL approach, and a comparative analysis of the proposed algorithm with baseline models. We also discuss the application to a real-world aviation safety problem using data from a commercial airline company and discuss the model's abilities and shortcomings, with some final remarks about possible deployment directions.\n    ",
        "submission_date": "2017-10-12T00:00:00",
        "last_modified_date": "2018-02-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.04759",
        "title": "Bayesian Hypernetworks",
        "authors": [
            "David Krueger",
            "Chin-Wei Huang",
            "Riashat Islam",
            "Ryan Turner",
            "Alexandre Lacoste",
            "Aaron Courville"
        ],
        "abstract": "We study Bayesian hypernetworks: a framework for approximate Bayesian inference in neural networks. A Bayesian hypernetwork $\\h$ is a neural network which learns to transform a simple noise distribution, $p(\\vec\\epsilon) = \\N(\\vec 0,\\mat I)$, to a distribution $q(\\pp) := q(h(\\vec\\epsilon))$ over the parameters $\\pp$ of another neural network (the \"primary network\")\\@. We train $q$ with variational inference, using an invertible $\\h$ to enable efficient estimation of the variational lower bound on the posterior $p(\\pp | \\D)$ via sampling. In contrast to most methods for Bayesian deep learning, Bayesian hypernets can represent a complex multimodal approximate posterior with correlations between parameters, while enabling cheap iid sampling of~$q(\\pp)$. In practice, Bayesian hypernets can provide a better defense against adversarial examples than dropout, and also exhibit competitive performance on a suite of tasks which evaluate model uncertainty, including regularization, active learning, and anomaly detection.\n    ",
        "submission_date": "2017-10-13T00:00:00",
        "last_modified_date": "2018-04-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.04837",
        "title": "Recent Advances in Zero-shot Recognition",
        "authors": [
            "Yanwei Fu",
            "Tao Xiang",
            "Yu-Gang Jiang",
            "Xiangyang Xue",
            "Leonid Sigal",
            "Shaogang Gong"
        ],
        "abstract": "With the recent renaissance of deep convolution neural networks, encouraging breakthroughs have been achieved on the supervised recognition tasks, where each class has sufficient training data and fully annotated training data. However, to scale the recognition to a large number of classes with few or now training samples for each class remains an unsolved problem. One approach to scaling up the recognition is to develop models capable of recognizing unseen categories without any training instances, or zero-shot recognition/ learning. This article provides a comprehensive review of existing zero-shot recognition techniques covering various aspects ranging from representations of models, and from datasets and evaluation settings. We also overview related recognition tasks including one-shot and open set recognition which can be used as natural extensions of zero-shot recognition when limited number of class samples become available or when zero-shot recognition is implemented in a real-world setting. Importantly, we highlight the limitations of existing approaches and point out future research directions in this existing new research area.\n    ",
        "submission_date": "2017-10-13T00:00:00",
        "last_modified_date": "2017-10-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.04924",
        "title": "Two-stage Algorithm for Fairness-aware Machine Learning",
        "authors": [
            "Junpei Komiyama",
            "Hajime Shimao"
        ],
        "abstract": "Algorithmic decision making process now affects many aspects of our lives. Standard tools for machine learning, such as classification and regression, are subject to the bias in data, and thus direct application of such off-the-shelf tools could lead to a specific group being unfairly discriminated. Removing sensitive attributes of data does not solve this problem because a \\textit{disparate impact} can arise when non-sensitive attributes and sensitive attributes are correlated. Here, we study a fair machine learning algorithm that avoids such a disparate impact when making a decision. Inspired by the two-stage least squares method that is widely used in the field of economics, we propose a two-stage algorithm that removes bias in the training data. The proposed algorithm is conceptually simple. Unlike most of existing fair algorithms that are designed for classification tasks, the proposed method is able to (i) deal with regression tasks, (ii) combine explanatory attributes to remove reverse discrimination, and (iii) deal with numerical sensitive attributes. The performance and fairness of the proposed algorithm are evaluated in simulations with synthetic and real-world datasets.\n    ",
        "submission_date": "2017-10-13T00:00:00",
        "last_modified_date": "2017-10-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.05199",
        "title": "Community Aware Random Walk for Network Embedding",
        "authors": [
            "Mohammad Mehdi Keikha",
            "Maseud Rahgozar",
            "Masoud Asadpour"
        ],
        "abstract": "Social network analysis provides meaningful information about behavior of network members that can be used for diverse applications such as classification, link prediction. However, network analysis is computationally expensive because of feature learning for different applications. In recent years, many researches have focused on feature learning methods in social networks. Network embedding represents the network in a lower dimensional representation space with the same properties which presents a compressed representation of the network. In this paper, we introduce a novel algorithm named \"CARE\" for network embedding that can be used for different types of networks including weighted, directed and complex. Current methods try to preserve local neighborhood information of nodes, whereas the proposed method utilizes local neighborhood and community information of network nodes to cover both local and global structure of social networks. CARE builds customized paths, which are consisted of local and global structure of network nodes, as a basis for network embedding and uses the Skip-gram model to learn representation vector of nodes. Subsequently, stochastic gradient descent is applied to optimize our objective function and learn the final representation of nodes. Our method can be scalable when new nodes are appended to network without information loss. Parallelize generation of customized random walks is also used for speeding up CARE. We evaluate the performance of CARE on multi label classification and link prediction tasks. Experimental results on various networks indicate that the proposed method outperforms others in both Micro and Macro-f1 measures for different size of training data.\n    ",
        "submission_date": "2017-10-14T00:00:00",
        "last_modified_date": "2018-02-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.05219",
        "title": "Mental Sampling in Multimodal Representations",
        "authors": [
            "Jian-Qiao Zhu",
            "Adam N. Sanborn",
            "Nick Chater"
        ],
        "abstract": "Both resources in the natural environment and concepts in a semantic space are distributed \"patchily\", with large gaps in between the patches. To describe people's internal and external foraging behavior, various random walk models have been proposed. In particular, internal foraging has been modeled as sampling: in order to gather relevant information for making a decision, people draw samples from a mental representation using random-walk algorithms such as Markov chain Monte Carlo (MCMC). However, two common empirical observations argue against simple sampling algorithms such as MCMC. First, the spatial structure is often best described by a L\u00e9vy flight distribution: the probability of the distance between two successive locations follows a power-law on the distances. Second, the temporal structure of the sampling that humans and other animals produce have long-range, slowly decaying serial correlations characterized as $1/f$-like fluctuations. We propose that mental sampling is not done by simple MCMC, but is instead adapted to multimodal representations and is implemented by Metropolis-coupled Markov chain Monte Carlo (MC$^3$), one of the first algorithms developed for sampling from multimodal distributions. MC$^3$ involves running multiple Markov chains in parallel but with target distributions of different temperatures, and it swaps the states of the chains whenever a better location is found. Heated chains more readily traverse valleys in the probability landscape to propose moves to far-away peaks, while the colder chains make the local steps that explore the current peak or patch. We show that MC$^3$ generates distances between successive samples that follow a L\u00e9vy flight distribution and $1/f$-like serial correlations, providing a single mechanistic account of these two puzzling empirical phenomena.\n    ",
        "submission_date": "2017-10-14T00:00:00",
        "last_modified_date": "2017-10-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.05233",
        "title": "Learners that Use Little Information",
        "authors": [
            "Raef Bassily",
            "Shay Moran",
            "Ido Nachum",
            "Jonathan Shafer",
            "Amir Yehudayoff"
        ],
        "abstract": "We study learning algorithms that are restricted to using a small amount of information from their input sample. We introduce a category of learning algorithms we term $d$-bit information learners, which are algorithms whose output conveys at most $d$ bits of information of their input. A central theme in this work is that such algorithms generalize.\n",
        "submission_date": "2017-10-14T00:00:00",
        "last_modified_date": "2018-02-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.05247",
        "title": "On Hashing-Based Approaches to Approximate DNF-Counting",
        "authors": [
            "Kuldeep S. Meel",
            "Aditya A. Shrotri",
            "Moshe Y. Vardi"
        ],
        "abstract": "Propositional model counting is a fundamental problem in artificial intelligence with a wide variety of applications, such as probabilistic inference, decision making under uncertainty, and probabilistic databases. Consequently, the problem is of theoretical as well as practical interest. When the constraints are expressed as DNF formulas, Monte Carlo-based techniques have been shown to provide a fully polynomial randomized approximation scheme (FPRAS). For CNF constraints, hashing-based approximation techniques have been demonstrated to be highly successful. Furthermore, it was shown that hashing-based techniques also yield an FPRAS for DNF counting without usage of Monte Carlo sampling. Our analysis, however, shows that the proposed hashing-based approach to DNF counting provides poor time complexity compared to the Monte Carlo-based DNF counting techniques. Given the success of hashing-based techniques for CNF constraints, it is natural to ask: Can hashing-based techniques provide an efficient FPRAS for DNF counting? In this paper, we provide a positive answer to this question. To this end, we introduce two novel algorithmic techniques: \\emph{Symbolic Hashing} and \\emph{Stochastic Cell Counting}, along with a new hash family of \\emph{Row-Echelon hash functions}. These innovations allow us to design a hashing-based FPRAS for DNF counting of similar complexity (up to polylog factors) as that of prior works. Furthermore, we expect these techniques to have potential applications beyond DNF counting.\n    ",
        "submission_date": "2017-10-14T00:00:00",
        "last_modified_date": "2017-10-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.05268",
        "title": "Self-Supervised Visual Planning with Temporal Skip Connections",
        "authors": [
            "Frederik Ebert",
            "Chelsea Finn",
            "Alex X. Lee",
            "Sergey Levine"
        ],
        "abstract": "In order to autonomously learn wide repertoires of complex skills, robots must be able to learn from their own autonomously collected data, without human supervision. One learning signal that is always available for autonomously collected data is prediction: if a robot can learn to predict the future, it can use this predictive model to take actions to produce desired outcomes, such as moving an object to a particular location. However, in complex open-world scenarios, designing a representation for prediction is difficult. In this work, we instead aim to enable self-supervised robotic learning through direct video prediction: instead of attempting to design a good representation, we directly predict what the robot will see next, and then use this model to achieve desired goals. A key challenge in video prediction for robotic manipulation is handling complex spatial arrangements such as occlusions. To that end, we introduce a video prediction model that can keep track of objects through occlusion by incorporating temporal skip-connections. Together with a novel planning criterion and action space formulation, we demonstrate that this model substantially outperforms prior work on video prediction-based control. Our results show manipulation of objects not seen during training, handling multiple objects, and pushing objects around obstructions. These results represent a significant advance in the range and complexity of skills that can be performed entirely with self-supervised robotic learning.\n    ",
        "submission_date": "2017-10-15T00:00:00",
        "last_modified_date": "2017-10-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.05270",
        "title": "Learning Infinite RBMs with Frank-Wolfe",
        "authors": [
            "Wei Ping",
            "Qiang Liu",
            "Alexander Ihler"
        ],
        "abstract": "In this work, we propose an infinite restricted Boltzmann machine~(RBM), whose maximum likelihood estimation~(MLE) corresponds to a constrained convex optimization. We consider the Frank-Wolfe algorithm to solve the program, which provides a sparse solution that can be interpreted as inserting a hidden unit at each iteration, so that the optimization process takes the form of a sequence of finite models of increasing complexity. As a side benefit, this can be used to easily and efficiently identify an appropriate number of hidden units during the optimization. The resulting model can also be used as an initialization for typical state-of-the-art RBM training algorithms such as contrastive divergence, leading to models with consistently higher test likelihood than random initialization.\n    ",
        "submission_date": "2017-10-15T00:00:00",
        "last_modified_date": "2017-10-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.05381",
        "title": "A systematic study of the class imbalance problem in convolutional neural networks",
        "authors": [
            "Mateusz Buda",
            "Atsuto Maki",
            "Maciej A. Mazurowski"
        ],
        "abstract": "In this study, we systematically investigate the impact of class imbalance on classification performance of convolutional neural networks (CNNs) and compare frequently used methods to address the issue. Class imbalance is a common problem that has been comprehensively studied in classical machine learning, yet very limited systematic research is available in the context of deep learning. In our study, we use three benchmark datasets of increasing complexity, MNIST, CIFAR-10 and ImageNet, to investigate the effects of imbalance on classification and perform an extensive comparison of several methods to address the issue: oversampling, undersampling, two-phase training, and thresholding that compensates for prior class probabilities. Our main evaluation metric is area under the receiver operating characteristic curve (ROC AUC) adjusted to multi-class tasks since overall accuracy metric is associated with notable difficulties in the context of imbalanced data. Based on results from our experiments we conclude that (i) the effect of class imbalance on classification performance is detrimental; (ii) the method of addressing class imbalance that emerged as dominant in almost all analyzed scenarios was oversampling; (iii) oversampling should be applied to the level that completely eliminates the imbalance, whereas the optimal undersampling ratio depends on the extent of imbalance; (iv) as opposed to some classical machine learning models, oversampling does not cause overfitting of CNNs; (v) thresholding should be applied to compensate for prior class probabilities when overall number of properly classified cases is of interest.\n    ",
        "submission_date": "2017-10-15T00:00:00",
        "last_modified_date": "2018-10-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.05387",
        "title": "Manifold Regularization for Kernelized LSTD",
        "authors": [
            "Xinyan Yan",
            "Krzysztof Choromanski",
            "Byron Boots",
            "Vikas Sindhwani"
        ],
        "abstract": "Policy evaluation or value function or Q-function approximation is a key procedure in reinforcement learning (RL). It is a necessary component of policy iteration and can be used for variance reduction in policy gradient methods. Therefore its quality has a significant impact on most RL algorithms. Motivated by manifold regularized learning, we propose a novel kernelized policy evaluation method that takes advantage of the intrinsic geometry of the state space learned from data, in order to achieve better sample efficiency and higher accuracy in Q-function approximation. Applying the proposed method in the Least-Squares Policy Iteration (LSPI) framework, we observe superior performance compared to widely used parametric basis functions on two standard benchmarks in terms of policy quality.\n    ",
        "submission_date": "2017-10-15T00:00:00",
        "last_modified_date": "2017-10-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.05468",
        "title": "Generalization in Deep Learning",
        "authors": [
            "Kenji Kawaguchi",
            "Leslie Pack Kaelbling",
            "Yoshua Bengio"
        ],
        "abstract": "This paper provides theoretical insights into why and how deep learning can generalize well, despite its large capacity, complexity, possible algorithmic instability, nonrobustness, and sharp minima, responding to an open question in the literature. We also discuss approaches to provide non-vacuous generalization guarantees for deep learning. Based on theoretical observations, we propose new open problems and discuss the limitations of our results.\n    ",
        "submission_date": "2017-10-16T00:00:00",
        "last_modified_date": "2023-08-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.05703",
        "title": "A Survey on Optical Character Recognition System",
        "authors": [
            "Noman Islam",
            "Zeeshan Islam",
            "Nazia Noor"
        ],
        "abstract": "Optical Character Recognition (OCR) has been a topic of interest for many years. It is defined as the process of digitizing a document image into its constituent characters. Despite decades of intense research, developing OCR with capabilities comparable to that of human still remains an open challenge. Due to this challenging nature, researchers from industry and academic circles have directed their attentions towards Optical Character Recognition. Over the last few years, the number of academic laboratories and companies involved in research on Character Recognition has increased dramatically. This research aims at summarizing the research so far done in the field of OCR. It provides an overview of different aspects of OCR and discusses corresponding proposals aimed at resolving issues of OCR.\n    ",
        "submission_date": "2017-10-03T00:00:00",
        "last_modified_date": "2017-10-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.05780",
        "title": "A retrieval-based dialogue system utilizing utterance and context embeddings",
        "authors": [
            "Alexander Bartl",
            "Gerasimos Spanakis"
        ],
        "abstract": "Finding semantically rich and computer-understandable representations for textual dialogues, utterances and words is crucial for dialogue systems (or conversational agents), as their performance mostly depends on understanding the context of conversations. Recent research aims at finding distributed vector representations (embeddings) for words, such that semantically similar words are relatively close within the vector-space. Encoding the \"meaning\" of text into vectors is a current trend, and text can range from words, phrases and documents to actual human-to-human conversations. In recent research approaches, responses have been generated utilizing a decoder architecture, given the vector representation of the current conversation. In this paper, the utilization of embeddings for answer retrieval is explored by using Locality-Sensitive Hashing Forest (LSH Forest), an Approximate Nearest Neighbor (ANN) model, to find similar conversations in a corpus and rank possible candidates. Experimental results on the well-known Ubuntu Corpus (in English) and a customer service chat dataset (in Dutch) show that, in combination with a candidate selection method, retrieval-based approaches outperform generative ones and reveal promising future research directions towards the usability of such a system.\n    ",
        "submission_date": "2017-10-16T00:00:00",
        "last_modified_date": "2017-10-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.05944",
        "title": "Neuro Fuzzy Modelling for Prediction of Consumer Price Index",
        "authors": [
            "Godwin Ambukege",
            "Godfrey Justo",
            "Joseph Mushi"
        ],
        "abstract": "Economic indicators such as Consumer Price Index (CPI) have frequently used in predicting future economic wealth for financial policy makers of respective country. Most central banks, on guidelines of research studies, have recently adopted an inflation targeting monetary policy regime, which accounts for high requirement for effective prediction model of consumer price index. However, prediction accuracy by numerous studies is still low, which raises a need for improvement. This manuscript presents findings of study that use neuro fuzzy technique to design a machine-learning model that train and test data to predict a univariate time series CPI. The study establishes a matrix of monthly CPI data from secondary data source of Tanzania National Bureau of Statistics from January 2000 to December 2015 as case study and thereafter conducted simulation experiments on MATLAB whereby ninety five percent (95%) of data used to train the model and five percent (5%) for testing. Furthermore, the study use root mean square error (RMSE) and mean absolute percentage error (MAPE) as error metrics for model evaluation. The results show that the neuro fuzzy model have an architecture of 5:74:1 with Gaussian membership functions (2, 2, 2, 2, 2), provides RMSE of 0.44886 and MAPE 0.23384, which is far better compared to existing research studies.\n    ",
        "submission_date": "2017-10-09T00:00:00",
        "last_modified_date": "2017-10-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.05958",
        "title": "Gradient-free Policy Architecture Search and Adaptation",
        "authors": [
            "Sayna Ebrahimi",
            "Anna Rohrbach",
            "Trevor Darrell"
        ],
        "abstract": "We develop a method for policy architecture search and adaptation via gradient-free optimization which can learn to perform autonomous driving tasks. By learning from both demonstration and environmental reward we develop a model that can learn with relatively few early catastrophic failures. We first learn an architecture of appropriate complexity to perceive aspects of world state relevant to the expert demonstration, and then mitigate the effect of domain-shift during deployment by adapting a policy demonstrated in a source domain to rewards obtained in a target environment. We show that our approach allows safer learning than baseline methods, offering a reduced cumulative crash metric over the agent's lifetime as it learns to drive in a realistic simulated environment.\n    ",
        "submission_date": "2017-10-16T00:00:00",
        "last_modified_date": "2017-10-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.05980",
        "title": "SMR: Medical Knowledge Graph Embedding for Safe Medicine Recommendation",
        "authors": [
            "Fang Gong",
            "Meng Wang",
            "Haofen Wang",
            "Sen Wang",
            "Mengyue Liu"
        ],
        "abstract": "Most of the existing medicine recommendation systems that are mainly based on electronic medical records (EMRs) are significantly assisting doctors to make better clinical decisions benefiting both patients and caregivers. Even though the growth of EMRs is at a lighting fast speed in the era of big data, content limitations in EMRs restrain the existed recommendation systems to reflect relevant medical facts, such as drug-drug interactions. Many medical knowledge graphs that contain drug-related information, such as DrugBank, may give hope for the recommendation systems. However, the direct use of these knowledge graphs in the systems suffers from robustness caused by the incompleteness of the graphs. To address these challenges, we stand on recent advances in graph embedding learning techniques and propose a novel framework, called Safe Medicine Recommendation (SMR), in this paper. Specifically, SMR first constructs a high-quality heterogeneous graph by bridging EMRs (MIMIC-III) and medical knowledge graphs (ICD-9 ontology and DrugBank). Then, SMR jointly embeds diseases, medicines, patients, and their corresponding relations into a shared lower dimensional space. Finally, SMR uses the embeddings to decompose the medicine recommendation into a link prediction process while considering the patient's diagnoses and adverse drug reactions. To our best knowledge, SMR is the first to learn embeddings of a patient-disease-medicine graph for medicine recommendation in the world. Extensive experiments on real datasets are conducted to evaluate the effectiveness of proposed framework.\n    ",
        "submission_date": "2017-10-16T00:00:00",
        "last_modified_date": "2020-11-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.06055",
        "title": "Evolution in Virtual Worlds",
        "authors": [
            "Tim Taylor"
        ],
        "abstract": "This chapter discusses the possibility of instilling a virtual world with mechanisms for evolution and natural selection in order to generate rich ecosystems of complex organisms in a process akin to biological evolution. Some previous work in the area is described, and successes and failures are discussed. The components of a more comprehensive framework for designing such worlds are mapped out, including the design of the individual organisms, the properties and dynamics of the environmental medium in which they are evolving, and the representational relationship between organism and environment. Some of the key issues discussed include how to allow organisms to evolve new structures and functions with few restrictions, and how to create an interconnectedness between organisms in order to generate drives for continuing evolutionary activity.\n    ",
        "submission_date": "2017-10-17T00:00:00",
        "last_modified_date": "2017-10-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.06061",
        "title": "Reply With: Proactive Recommendation of Email Attachments",
        "authors": [
            "Christophe Van Gysel",
            "Bhaskar Mitra",
            "Matteo Venanzi",
            "Roy Rosemarin",
            "Grzegorz Kukla",
            "Piotr Grudzien",
            "Nicola Cancedda"
        ],
        "abstract": "Email responses often contain items-such as a file or a hyperlink to an external document-that are attached to or included inline in the body of the message. Analysis of an enterprise email corpus reveals that 35% of the time when users include these items as part of their response, the attachable item is already present in their inbox or sent folder. A modern email client can proactively retrieve relevant attachable items from the user's past emails based on the context of the current conversation, and recommend them for inclusion, to reduce the time and effort involved in composing the response. In this paper, we propose a weakly supervised learning framework for recommending attachable items to the user. As email search systems are commonly available, we constrain the recommendation task to formulating effective search queries from the context of the conversations. The query is submitted to an existing IR system to retrieve relevant items for attachment. We also present a novel strategy for generating labels from an email corpus---without the need for manual annotations---that can be used to train and evaluate the query formulation model. In addition, we describe a deep convolutional neural network that demonstrates satisfactory performance on this query formulation task when evaluated on the publicly available Avocado dataset and a proprietary dataset of internal emails obtained through an employee participation program.\n    ",
        "submission_date": "2017-10-17T00:00:00",
        "last_modified_date": "2017-11-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.06071",
        "title": "PubMed 200k RCT: a Dataset for Sequential Sentence Classification in Medical Abstracts",
        "authors": [
            "Franck Dernoncourt",
            "Ji Young Lee"
        ],
        "abstract": "We present PubMed 200k RCT, a new dataset based on PubMed for sequential sentence classification. The dataset consists of approximately 200,000 abstracts of randomized controlled trials, totaling 2.3 million sentences. Each sentence of each abstract is labeled with their role in the abstract using one of the following classes: background, objective, method, result, or conclusion. The purpose of releasing this dataset is twofold. First, the majority of datasets for sequential short-text classification (i.e., classification of short texts that appear in sequences) are small: we hope that releasing a new large dataset will help develop more accurate algorithms for this task. Second, from an application perspective, researchers need better tools to efficiently skim through the literature. Automatically classifying each sentence in an abstract would help researchers read abstracts more efficiently, especially in fields where abstracts may be long, such as the medical field.\n    ",
        "submission_date": "2017-10-17T00:00:00",
        "last_modified_date": "2017-10-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.06096",
        "title": "Spontaneous Symmetry Breaking in Neural Networks",
        "authors": [
            "Ricky Fok",
            "Aijun An",
            "Xiaogang Wang"
        ],
        "abstract": "We propose a framework to understand the unprecedented performance and robustness of deep neural networks using field theory. Correlations between the weights within the same layer can be described by symmetries in that layer, and networks generalize better if such symmetries are broken to reduce the redundancies of the weights. Using a two parameter field theory, we find that the network can break such symmetries itself towards the end of training in a process commonly known in physics as spontaneous symmetry breaking. This corresponds to a network generalizing itself without any user input layers to break the symmetry, but by communication with adjacent layers. In the layer decoupling limit applicable to residual networks (He et al., 2015), we show that the remnant symmetries that survive the non-linear layers are spontaneously broken. The Lagrangian for the non-linear and weight layers together has striking similarities with the one in quantum field theory of a scalar. Using results from quantum field theory we show that our framework is able to explain many experimentally observed phenomena,such as training on random labels with zero error (Zhang et al., 2017), the information bottleneck, the phase transition out of it and gradient variance explosion (Shwartz-Ziv & Tishby, 2017), shattered gradients (Balduzzi et al., 2017), and many more.\n    ",
        "submission_date": "2017-10-17T00:00:00",
        "last_modified_date": "2017-10-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.06117",
        "title": "Map-based Multi-Policy Reinforcement Learning: Enhancing Adaptability of Robots by Deep Reinforcement Learning",
        "authors": [
            "Ayaka Kume",
            "Eiichi Matsumoto",
            "Kuniyuki Takahashi",
            "Wilson Ko",
            "Jethro Tan"
        ],
        "abstract": "In order for robots to perform mission-critical tasks, it is essential that they are able to quickly adapt to changes in their environment as well as to injuries and or other bodily changes. Deep reinforcement learning has been shown to be successful in training robot control policies for operation in complex environments. However, existing methods typically employ only a single policy. This can limit the adaptability since a large environmental modification might require a completely different behavior compared to the learning environment. To solve this problem, we propose Map-based Multi-Policy Reinforcement Learning (MMPRL), which aims to search and store multiple policies that encode different behavioral features while maximizing the expected reward in advance of the environment change. Thanks to these policies, which are stored into a multi-dimensional discrete map according to its behavioral feature, adaptation can be performed within reasonable time without retraining the robot. An appropriate pre-trained policy from the map can be recalled using Bayesian optimization. Our experiments show that MMPRL enables robots to quickly adapt to large changes without requiring any prior knowledge on the type of injuries that could occur. A highlight of the learned behaviors can be found here: ",
        "submission_date": "2017-10-17T00:00:00",
        "last_modified_date": "2017-10-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.06169",
        "title": "Distill-and-Compare: Auditing Black-Box Models Using Transparent Model Distillation",
        "authors": [
            "Sarah Tan",
            "Rich Caruana",
            "Giles Hooker",
            "Yin Lou"
        ],
        "abstract": "Black-box risk scoring models permeate our lives, yet are typically proprietary or opaque. We propose Distill-and-Compare, a model distillation and comparison approach to audit such models. To gain insight into black-box models, we treat them as teachers, training transparent student models to mimic the risk scores assigned by black-box models. We compare the student model trained with distillation to a second un-distilled transparent model trained on ground-truth outcomes, and use differences between the two models to gain insight into the black-box model. Our approach can be applied in a realistic setting, without probing the black-box model API. We demonstrate the approach on four public data sets: COMPAS, Stop-and-Frisk, Chicago Police, and Lending Club. We also propose a statistical test to determine if a data set is missing key features used to train the black-box model. Our test finds that the ProPublica data is likely missing key feature(s) used in COMPAS.\n    ",
        "submission_date": "2017-10-17T00:00:00",
        "last_modified_date": "2018-10-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.06331",
        "title": "Distributed algorithm for empty vehicles management in personal rapid transit (PRT) network",
        "authors": [
            "Wiktor B. Daszczuk",
            "Jerzy Mie\u015bcicki",
            "Waldemar Grabski"
        ],
        "abstract": "In this paper, an original heuristic algorithm of empty vehicles management in personal rapid transit network is presented. The algorithm is used for the delivery of empty vehicles for waiting passengers, for balancing the distribution of empty vehicles within the network, and for providing an empty space for vehicles approaching a station. Each of these tasks involves a decision on the trip that has to be done by a selected empty vehicle from its actual location to some determined destination. The decisions are based on a multi-parameter function involving a set of factors and thresholds. An important feature of the algorithm is that it does not use any central database of passenger input (demand) and locations of free vehicles. Instead, it is based on the local exchange of data between stations: on their states and on the vehicles they expect. Therefore, it seems well-tailored for a distributed implementation. The algorithm is uniform, meaning that the same basic procedure is used for multiple tasks using a task-specific set of parameters.\n    ",
        "submission_date": "2017-10-17T00:00:00",
        "last_modified_date": "2017-10-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.06406",
        "title": "Laying Down the Yellow Brick Road: Development of a Wizard-of-Oz Interface for Collecting Human-Robot Dialogue",
        "authors": [
            "Claire Bonial",
            "Matthew Marge",
            "Ron artstein",
            "Ashley Foots",
            "Felix Gervits",
            "Cory J. Hayes",
            "Cassidy Henry",
            "Susan G. Hill",
            "Anton Leuski",
            "Stephanie M. Lukin",
            "Pooja Moolchandani",
            "Kimberly A. Pollard",
            "David Traum",
            "Clare R. Voss"
        ],
        "abstract": "We describe the adaptation and refinement of a graphical user interface designed to facilitate a Wizard-of-Oz (WoZ) approach to collecting human-robot dialogue data. The data collected will be used to develop a dialogue system for robot navigation. Building on an interface previously used in the development of dialogue systems for virtual agents and video playback, we add templates with open parameters which allow the wizard to quickly produce a wide variety of utterances. Our research demonstrates that this approach to data collection is viable as an intermediate step in developing a dialogue system for physical robots in remote locations from their users - a domain in which the human and robot need to regularly verify and update a shared understanding of the physical environment. We show that our WoZ interface and the fixed set of utterances and templates therein provide for a natural pace of dialogue with good coverage of the navigation domain.\n    ",
        "submission_date": "2017-10-17T00:00:00",
        "last_modified_date": "2017-10-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.06422",
        "title": "Multi-Task Domain Adaptation for Deep Learning of Instance Grasping from Simulation",
        "authors": [
            "Kuan Fang",
            "Yunfei Bai",
            "Stefan Hinterstoisser",
            "Silvio Savarese",
            "Mrinal Kalakrishnan"
        ],
        "abstract": "Learning-based approaches to robotic manipulation are limited by the scalability of data collection and accessibility of labels. In this paper, we present a multi-task domain adaptation framework for instance grasping in cluttered scenes by utilizing simulated robot experiments. Our neural network takes monocular RGB images and the instance segmentation mask of a specified target object as inputs, and predicts the probability of successfully grasping the specified object for each candidate motor command. The proposed transfer learning framework trains a model for instance grasping in simulation and uses a domain-adversarial loss to transfer the trained model to real robots using indiscriminate grasping data, which is available both in simulation and the real world. We evaluate our model in real-world robot experiments, comparing it with alternative model architectures as well as an indiscriminate grasping baseline.\n    ",
        "submission_date": "2017-10-17T00:00:00",
        "last_modified_date": "2018-03-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.06451",
        "title": "A Bayesian Perspective on Generalization and Stochastic Gradient Descent",
        "authors": [
            "Samuel L. Smith",
            "Quoc V. Le"
        ],
        "abstract": "We consider two questions at the heart of machine learning; how can we predict if a minimum will generalize to the test set, and why does stochastic gradient descent find minima that generalize well? Our work responds to Zhang et al. (2016), who showed deep neural networks can easily memorize randomly labeled training data, despite generalizing well on real labels of the same inputs. We show that the same phenomenon occurs in small linear models. These observations are explained by the Bayesian evidence, which penalizes sharp minima but is invariant to model parameterization. We also demonstrate that, when one holds the learning rate fixed, there is an optimum batch size which maximizes the test set accuracy. We propose that the noise introduced by small mini-batches drives the parameters towards minima whose evidence is large. Interpreting stochastic gradient descent as a stochastic differential equation, we identify the \"noise scale\" $g = \\epsilon (\\frac{N}{B} - 1) \\approx \\epsilon N/B$, where $\\epsilon$ is the learning rate, $N$ the training set size and $B$ the batch size. Consequently the optimum batch size is proportional to both the learning rate and the size of the training set, $B_{opt} \\propto \\epsilon N$. We verify these predictions empirically.\n    ",
        "submission_date": "2017-10-17T00:00:00",
        "last_modified_date": "2018-02-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.06481",
        "title": "Constructing Datasets for Multi-hop Reading Comprehension Across Documents",
        "authors": [
            "Johannes Welbl",
            "Pontus Stenetorp",
            "Sebastian Riedel"
        ],
        "abstract": "Most Reading Comprehension methods limit themselves to queries which can be answered using a single sentence, paragraph, or document. Enabling models to combine disjoint pieces of textual evidence would extend the scope of machine comprehension methods, but currently there exist no resources to train and test this capability. We propose a novel task to encourage the development of models for text understanding across multiple documents and to investigate the limits of existing methods. In our task, a model learns to seek and combine evidence - effectively performing multi-hop (alias multi-step) inference. We devise a methodology to produce datasets for this task, given a collection of query-answer pairs and thematically linked documents. Two datasets from different domains are induced, and we identify potential pitfalls and devise circumvention strategies. We evaluate two previously proposed competitive models and find that one can integrate information across documents. However, both models struggle to select relevant information, as providing documents guaranteed to be relevant greatly improves their performance. While the models outperform several strong baselines, their best accuracy reaches 42.9% compared to human performance at 74.0% - leaving ample room for improvement.\n    ",
        "submission_date": "2017-10-17T00:00:00",
        "last_modified_date": "2018-06-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.06513",
        "title": "Learning Pose Grammar to Encode Human Body Configuration for 3D Pose Estimation",
        "authors": [
            "Haoshu Fang",
            "Yuanlu Xu",
            "Wenguan Wang",
            "Xiaobai Liu",
            "Song-Chun Zhu"
        ],
        "abstract": "In this paper, we propose a pose grammar to tackle the problem of 3D human pose estimation. Our model directly takes 2D pose as input and learns a generalized 2D-3D mapping function. The proposed model consists of a base network which efficiently captures pose-aligned features and a hierarchy of Bi-directional RNNs (BRNN) on the top to explicitly incorporate a set of knowledge regarding human body configuration (i.e., kinematics, symmetry, motor coordination). The proposed model thus enforces high-level constraints over human poses. In learning, we develop a pose sample simulator to augment training samples in virtual camera views, which further improves our model generalizability. We validate our method on public 3D human pose benchmarks and propose a new evaluation protocol working on cross-view setting to verify the generalization capability of different methods. We empirically observe that most state-of-the-art methods encounter difficulty under such setting while our method can well handle such challenges.\n    ",
        "submission_date": "2017-10-17T00:00:00",
        "last_modified_date": "2018-01-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.06542",
        "title": "Asymmetric Actor Critic for Image-Based Robot Learning",
        "authors": [
            "Lerrel Pinto",
            "Marcin Andrychowicz",
            "Peter Welinder",
            "Wojciech Zaremba",
            "Pieter Abbeel"
        ],
        "abstract": "Deep reinforcement learning (RL) has proven a powerful technique in many sequential decision making domains. However, Robotics poses many challenges for RL, most notably training on a physical system can be expensive and dangerous, which has sparked significant interest in learning control policies using a physics simulator. While several recent works have shown promising results in transferring policies trained in simulation to the real world, they often do not fully utilize the advantage of working with a simulator. In this work, we exploit the full state observability in the simulator to train better policies which take as input only partial observations (RGBD images). We do this by employing an actor-critic training algorithm in which the critic is trained on full states while the actor (or policy) gets rendered images as input. We show experimentally on a range of simulated tasks that using these asymmetric inputs significantly improves performance. Finally, we combine this method with domain randomization and show real robot experiments for several tasks like picking, pushing, and moving a block. We achieve this simulation to real world transfer without training on any real world data.\n    ",
        "submission_date": "2017-10-18T00:00:00",
        "last_modified_date": "2017-10-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.06636",
        "title": "Deceased Organ Matching in Australia",
        "authors": [
            "Toby Walsh"
        ],
        "abstract": "Despite efforts to increase the supply of organs from living donors, most kidney transplants performed in Australia still come from deceased donors. The age of these donated organs has increased substantially in recent decades as the rate of fatal accidents on roads has fallen. The Organ and Tissue Authority in Australia is therefore looking to design a new mechanism that better matches the age of the organ to the age of the patient. I discuss the design, axiomatics and performance of several candidate mechanisms that respect the special online nature of this fair division problem.\n    ",
        "submission_date": "2017-10-18T00:00:00",
        "last_modified_date": "2017-10-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.06922",
        "title": "Emergent Translation in Multi-Agent Communication",
        "authors": [
            "Jason Lee",
            "Kyunghyun Cho",
            "Jason Weston",
            "Douwe Kiela"
        ],
        "abstract": "While most machine translation systems to date are trained on large parallel corpora, humans learn language in a different way: by being grounded in an environment and interacting with other humans. In this work, we propose a communication game where two agents, native speakers of their own respective languages, jointly learn to solve a visual referential task. We find that the ability to understand and translate a foreign language emerges as a means to achieve shared goals. The emergent translation is interactive and multimodal, and crucially does not require parallel corpora, but only monolingual, independent text and corresponding images. Our proposed translation model achieves this by grounding the source and target languages into a shared visual modality, and outperforms several baselines on both word-level and sentence-level translation tasks. Furthermore, we show that agents in a multilingual community learn to translate better and faster than in a bilingual communication setting.\n    ",
        "submission_date": "2017-10-12T00:00:00",
        "last_modified_date": "2018-04-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.06923",
        "title": "Adapting general-purpose speech recognition engine output for domain-specific natural language question answering",
        "authors": [
            "C. Anantaram",
            "Sunil Kumar Kopparapu"
        ],
        "abstract": "Speech-based natural language question-answering interfaces to enterprise systems are gaining a lot of attention. General-purpose speech engines can be integrated with NLP systems to provide such interfaces. Usually, general-purpose speech engines are trained on large `general' corpus. However, when such engines are used for specific domains, they may not recognize domain-specific words well, and may produce erroneous output. Further, the accent and the environmental conditions in which the speaker speaks a sentence may induce the speech engine to inaccurately recognize certain words. The subsequent natural language question-answering does not produce the requisite results as the question does not accurately represent what the speaker intended. Thus, the speech engine's output may need to be adapted for a domain before further natural language processing is carried out. We present two mechanisms for such an adaptation, one based on evolutionary development and the other based on machine learning, and show how we can repair the speech-output to make the subsequent natural language question-answering better.\n    ",
        "submission_date": "2017-10-12T00:00:00",
        "last_modified_date": "2017-10-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.07558",
        "title": "Classification Driven Dynamic Image Enhancement",
        "authors": [
            "Vivek Sharma",
            "Ali Diba",
            "Davy Neven",
            "Michael S. Brown",
            "Luc Van Gool",
            "Rainer Stiefelhagen"
        ],
        "abstract": "Convolutional neural networks rely on image texture and structure to serve as discriminative features to classify the image content. Image enhancement techniques can be used as preprocessing steps to help improve the overall image quality and in turn improve the overall effectiveness of a CNN. Existing image enhancement methods, however, are designed to improve the perceptual quality of an image for a human observer. In this paper, we are interested in learning CNNs that can emulate image enhancement and restoration, but with the overall goal to improve image classification and not necessarily human perception. To this end, we present a unified CNN architecture that uses a range of enhancement filters that can enhance image-specific details via end-to-end dynamic filter learning. We demonstrate the effectiveness of this strategy on four challenging benchmark datasets for fine-grained, object, scene, and texture classification: CUB-200-2011, PASCAL-VOC2007, MIT-Indoor, and DTD. Experiments using our proposed enhancement show promising results on all the datasets. In addition, our approach is capable of improving the performance of all generic CNN architectures.\n    ",
        "submission_date": "2017-10-20T00:00:00",
        "last_modified_date": "2018-03-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.07654",
        "title": "Deep Voice 3: Scaling Text-to-Speech with Convolutional Sequence Learning",
        "authors": [
            "Wei Ping",
            "Kainan Peng",
            "Andrew Gibiansky",
            "Sercan O. Arik",
            "Ajay Kannan",
            "Sharan Narang",
            "Jonathan Raiman",
            "John Miller"
        ],
        "abstract": "We present Deep Voice 3, a fully-convolutional attention-based neural text-to-speech (TTS) system. Deep Voice 3 matches state-of-the-art neural speech synthesis systems in naturalness while training ten times faster. We scale Deep Voice 3 to data set sizes unprecedented for TTS, training on more than eight hundred hours of audio from over two thousand speakers. In addition, we identify common error modes of attention-based speech synthesis networks, demonstrate how to mitigate them, and compare several different waveform synthesis methods. We also describe how to scale inference to ten million queries per day on one single-GPU server.\n    ",
        "submission_date": "2017-10-20T00:00:00",
        "last_modified_date": "2018-02-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.07659",
        "title": "Point Neurons with Conductance-Based Synapses in the Neural Engineering Framework",
        "authors": [
            "Andreas St\u00f6ckel",
            "Aaron R. Voelker",
            "Chris Eliasmith"
        ],
        "abstract": "The mathematical model underlying the Neural Engineering Framework (NEF) expresses neuronal input as a linear combination of synaptic currents. However, in biology, synapses are not perfect current sources and are thus nonlinear. Detailed synapse models are based on channel conductances instead of currents, which require independent handling of excitatory and inhibitory synapses. This, in particular, significantly affects the influence of inhibitory signals on the neuronal dynamics. In this technical report we first summarize the relevant portions of the NEF and conductance-based synapse models. We then discuss a na\u00efve translation between populations of LIF neurons with current- and conductance-based synapses based on an estimation of an average membrane potential. Experiments show that this simple approach works relatively well for feed-forward communication channels, yet performance degrades for NEF networks describing more complex dynamics, such as integration.\n    ",
        "submission_date": "2017-10-20T00:00:00",
        "last_modified_date": "2017-10-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.07706",
        "title": "Low Precision RNNs: Quantizing RNNs Without Losing Accuracy",
        "authors": [
            "Supriya Kapur",
            "Asit Mishra",
            "Debbie Marr"
        ],
        "abstract": "Similar to convolution neural networks, recurrent neural networks (RNNs) typically suffer from over-parameterization. Quantizing bit-widths of weights and activations results in runtime efficiency on hardware, yet it often comes at the cost of reduced accuracy. This paper proposes a quantization approach that increases model size with bit-width reduction. This approach will allow networks to perform at their baseline accuracy while still maintaining the benefits of reduced precision and overall model size reduction.\n    ",
        "submission_date": "2017-10-20T00:00:00",
        "last_modified_date": "2017-10-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.07735",
        "title": "ADA: A Game-Theoretic Perspective on Data Augmentation for Object Detection",
        "authors": [
            "Sima Behpour",
            "Kris M. Kitani",
            "Brian D. Ziebart"
        ],
        "abstract": "The use of random perturbations of ground truth data, such as random translation or scaling of bounding boxes, is a common heuristic used for data augmentation that has been shown to prevent overfitting and improve generalization. Since the design of data augmentation is largely guided by reported best practices, it is difficult to understand if those design choices are optimal. To provide a more principled perspective, we develop a game-theoretic interpretation of data augmentation in the context of object detection. We aim to find an optimal adversarial perturbations of the ground truth data (i.e., the worst case perturbations) that forces the object bounding box predictor to learn from the hardest distribution of perturbed examples for better test-time performance. We establish that the game theoretic solution, the Nash equilibrium, provides both an optimal predictor and optimal data augmentation distribution. We show that our adversarial method of training a predictor can significantly improve test time performance for the task of object detection. On the ImageNet object detection task, our adversarial approach improves performance by over 16\\% compared to the best performing data augmentation method\n    ",
        "submission_date": "2017-10-21T00:00:00",
        "last_modified_date": "2017-12-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.07783",
        "title": "A Novel Stochastic Stratified Average Gradient Method: Convergence Rate and Its Complexity",
        "authors": [
            "Aixiang Chen",
            "Bingchuan Chen",
            "Xiaolong Chai",
            "Rui Bian",
            "Hengguang Li"
        ],
        "abstract": "SGD (Stochastic Gradient Descent) is a popular algorithm for large scale optimization problems due to its low iterative cost. However, SGD can not achieve linear convergence rate as FGD (Full Gradient Descent) because of the inherent gradient variance. To attack the problem, mini-batch SGD was proposed to get a trade-off in terms of convergence rate and iteration cost. In this paper, a general CVI (Convergence-Variance Inequality) equation is presented to state formally the interaction of convergence rate and gradient variance. Then a novel algorithm named SSAG (Stochastic Stratified Average Gradient) is introduced to reduce gradient variance based on two techniques, stratified sampling and averaging over iterations that is a key idea in SAG (Stochastic Average Gradient). Furthermore, SSAG can achieve linear convergence rate of $\\mathcal {O}((1-\\frac{\\mu}{8CL})^k)$ at smaller storage and iterative costs, where $C\\geq 2$ is the category number of training data. This convergence rate depends mainly on the variance between classes, but not on the variance within the classes. In the case of $C\\ll N$ ($N$ is the training data size), SSAG's convergence rate is much better than SAG's convergence rate of $\\mathcal {O}((1-\\frac{\\mu}{8NL})^k)$. Our experimental results show SSAG outperforms SAG and many other algorithms.\n    ",
        "submission_date": "2017-10-21T00:00:00",
        "last_modified_date": "2017-12-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.07818",
        "title": "A Learning-to-Infer Method for Real-Time Power Grid Multi-Line Outage Identification",
        "authors": [
            "Yue Zhao",
            "Jianshu Chen",
            "H. Vincent Poor"
        ],
        "abstract": "Identifying a potentially large number of simultaneous line outages in power transmission networks in real time is a computationally hard problem. This is because the number of hypotheses grows exponentially with the network size. A new \"Learning-to-Infer\" method is developed for efficient inference of every line status in the network. Optimizing the line outage detector is transformed to and solved as a discriminative learning problem based on Monte Carlo samples generated with power flow simulations. A major advantage of the developed Learning-to-Infer method is that the labeled data used for training can be generated in an arbitrarily large amount rapidly and at very little cost. As a result, the power of offline training is fully exploited to learn very complex classifiers for effective real-time multi-line outage identification. The proposed methods are evaluated in the IEEE 30, 118 and 300 bus systems. Excellent performance in identifying multi-line outages in real time is achieved with a reasonably small amount of data.\n    ",
        "submission_date": "2017-10-21T00:00:00",
        "last_modified_date": "2019-06-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.07850",
        "title": "Deep Neural Network Approximation using Tensor Sketching",
        "authors": [
            "Shiva Prasad Kasiviswanathan",
            "Nina Narodytska",
            "Hongxia Jin"
        ],
        "abstract": "Deep neural networks are powerful learning models that achieve state-of-the-art performance on many computer vision, speech, and language processing tasks. In this paper, we study a fundamental question that arises when designing deep network architectures: Given a target network architecture can we design a smaller network architecture that approximates the operation of the target network? The question is, in part, motivated by the challenge of parameter reduction (compression) in modern deep neural networks, as the ever increasing storage and memory requirements of these networks pose a problem in resource constrained environments.\n",
        "submission_date": "2017-10-21T00:00:00",
        "last_modified_date": "2017-10-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.07903",
        "title": "The Complexity of Graph-Based Reductions for Reachability in Markov Decision Processes",
        "authors": [
            "Stephane Le Roux",
            "Guillermo A. Perez"
        ],
        "abstract": "We study the never-worse relation (NWR) for Markov decision processes with an infinite-horizon reachability objective. A state q is never worse than a state p if the maximal probability of reaching the target set of states from p is at most the same value from q, regard- less of the probabilities labelling the transitions. Extremal-probability states, end components, and essential states are all special cases of the equivalence relation induced by the NWR. Using the NWR, states in the same equivalence class can be collapsed. Then, actions leading to sub- optimal states can be removed. We show the natural decision problem associated to computing the NWR is coNP-complete. Finally, we ex- tend a previously known incomplete polynomial-time iterative algorithm to under-approximate the NWR.\n    ",
        "submission_date": "2017-10-22T00:00:00",
        "last_modified_date": "2018-02-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.08012",
        "title": "Exploiting generalization in the subspaces for faster model-based learning",
        "authors": [
            "Maryam Hashemzadeh",
            "Reshad Hosseini",
            "Majid Nili Ahmadabadi"
        ],
        "abstract": "Due to the lack of enough generalization in the state-space, common methods in Reinforcement Learning (RL) suffer from slow learning speed especially in the early learning trials. This paper introduces a model-based method in discrete state-spaces for increasing learning speed in terms of required experience (but not required computational time) by exploiting generalization in the experiences of the subspaces. A subspace is formed by choosing a subset of features in the original state representation (full-space). Generalization and faster learning in a subspace are due to many-to-one mapping of experiences from the full-space to each state in the subspace. Nevertheless, due to inherent perceptual aliasing in the subspaces, the policy suggested by each subspace does not generally converge to the optimal policy. Our approach, called Model Based Learning with Subspaces (MoBLeS), calculates confidence intervals of the estimated Q-values in the full-space and in the subspaces. These confidence intervals are used in the decision making, such that the agent benefits the most from the possible generalization while avoiding from detriment of the perceptual aliasing in the subspaces. Convergence of MoBLeS to the optimal policy is theoretically investigated. Additionally, we show through several experiments that MoBLeS improves the learning speed in the early trials.\n    ",
        "submission_date": "2017-10-22T00:00:00",
        "last_modified_date": "2017-10-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.08107",
        "title": "Probabilistic Pursuits on Graphs",
        "authors": [
            "Michael Amir",
            "Alfred M. Bruckstein"
        ],
        "abstract": "We consider discrete dynamical systems of \"ant-like\" agents engaged in a sequence of pursuits on a graph environment. The agents emerge one by one at equal time intervals from a source vertex $s$ and pursue each other by greedily attempting to close the distance to their immediate predecessor, the agent that emerged just before them from $s$, until they arrive at the destination point $t$. Such pursuits have been investigated before in the continuous setting and in discrete time when the underlying environment is a regular grid. In both these settings the agents' walks provably converge to a shortest path from $s$ to $t$. Furthermore, assuming a certain natural probability distribution over the move choices of the agents on the grid (in case there are multiple shortest paths between an agent and its predecessor), the walks converge to the uniform distribution over all shortest paths from $s$ to $t$.\n",
        "submission_date": "2017-10-23T00:00:00",
        "last_modified_date": "2019-01-31T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.08192",
        "title": "Investigating the feature collection for semantic segmentation via single skip connection",
        "authors": [
            "Jonghwa Yim",
            "Kyung-Ah Sohn"
        ],
        "abstract": "Since the study of deep convolutional neural network became prevalent, one of the important discoveries is that a feature map from a convolutional network can be extracted before going into the fully connected layer and can be used as a saliency map for object detection. Furthermore, the model can use features from each different layer for accurate object detection: the features from different layers can have different properties. As the model goes deeper, it has many latent skip connections and feature maps to elaborate object detection. Although there are many intermediate layers that we can use for semantic segmentation through skip connection, still the characteristics of each skip connection and the best skip connection for this task are uncertain. Therefore, in this study, we exhaustively research skip connections of state-of-the-art deep convolutional networks and investigate the characteristics of the features from each intermediate layer. In addition, this study would suggest how to use a recent deep neural network model for semantic segmentation and it would therefore become a cornerstone for later studies with the state-of-the-art network models.\n    ",
        "submission_date": "2017-10-23T00:00:00",
        "last_modified_date": "2017-10-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.08315",
        "title": "BENCHIP: Benchmarking Intelligence Processors",
        "authors": [
            "Jinhua Tao",
            "Zidong Du",
            "Qi Guo",
            "Huiying Lan",
            "Lei Zhang",
            "Shengyuan Zhou",
            "Lingjie Xu",
            "Cong Liu",
            "Haifeng Liu",
            "Shan Tang",
            "Allen Rush",
            "Willian Chen",
            "Shaoli Liu",
            "Yunji Chen",
            "Tianshi Chen"
        ],
        "abstract": "The increasing attention on deep learning has tremendously spurred the design of intelligence processing hardware. The variety of emerging intelligence processors requires standard benchmarks for fair comparison and system optimization (in both software and hardware). However, existing benchmarks are unsuitable for benchmarking intelligence processors due to their non-diversity and nonrepresentativeness. Also, the lack of a standard benchmarking methodology further exacerbates this problem. In this paper, we propose BENCHIP, a benchmark suite and benchmarking methodology for intelligence processors. The benchmark suite in BENCHIP consists of two sets of benchmarks: microbenchmarks and macrobenchmarks. The microbenchmarks consist of single-layer networks. They are mainly designed for bottleneck analysis and system optimization. The macrobenchmarks contain state-of-the-art industrial networks, so as to offer a realistic comparison of different platforms. We also propose a standard benchmarking methodology built upon an industrial software stack and evaluation metrics that comprehensively reflect the various characteristics of the evaluated intelligence processors. BENCHIP is utilized for evaluating various hardware platforms, including CPUs, GPUs, and accelerators. BENCHIP will be open-sourced soon.\n    ",
        "submission_date": "2017-10-23T00:00:00",
        "last_modified_date": "2017-11-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.08377",
        "title": "Listening to the World Improves Speech Command Recognition",
        "authors": [
            "Brian McMahan",
            "Delip Rao"
        ],
        "abstract": "We study transfer learning in convolutional network architectures applied to the task of recognizing audio, such as environmental sound events and speech commands. Our key finding is that not only is it possible to transfer representations from an unrelated task like environmental sound classification to a voice-focused task like speech command recognition, but also that doing so improves accuracies significantly. We also investigate the effect of increased model capacity for transfer learning audio, by first validating known results from the field of Computer Vision of achieving better accuracies with increasingly deeper networks on two audio datasets: UrbanSound8k and the newly released Google Speech Commands dataset. Then we propose a simple multiscale input representation using dilated convolutions and show that it is able to aggregate larger contexts and increase classification performance. Further, the models trained using a combination of transfer learning and multiscale input representations need only 40% of the training data to achieve similar accuracies as a freshly trained model with 100% of the training data. Finally, we demonstrate a positive interaction effect for the multiscale input and transfer learning, making a case for the joint application of the two techniques.\n    ",
        "submission_date": "2017-10-23T00:00:00",
        "last_modified_date": "2017-10-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.08396",
        "title": "Deep Health Care Text Classification",
        "authors": [
            "Vinayakumar R",
            "Barathi Ganesh HB",
            "Anand Kumar M",
            "Soman KP"
        ],
        "abstract": "Health related social media mining is a valuable apparatus for the early recognition of the diverse antagonistic medicinal conditions. Mostly, the existing methods are based on machine learning with knowledge-based learning. This working note presents the Recurrent neural network (RNN) and Long short-term memory (LSTM) based embedding for automatic health text classification in the social media mining. For each task, two systems are built and that classify the tweet at the tweet level. RNN and LSTM are used for extracting features and non-linear activation function at the last layer facilitates to distinguish the tweets of different categories. The experiments are conducted on 2nd Social Media Mining for Health Applications Shared Task at AMIA 2017. The experiment results are considerable; however the proposed method is appropriate for the health text classification. This is primarily due to the reason that, it doesn't rely on any feature engineering mechanisms.\n    ",
        "submission_date": "2017-10-23T00:00:00",
        "last_modified_date": "2017-10-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.08543",
        "title": "Neural Stain-Style Transfer Learning using GAN for Histopathological Images",
        "authors": [
            "Hyungjoo Cho",
            "Sungbin Lim",
            "Gunho Choi",
            "Hyunseok Min"
        ],
        "abstract": "Performance of data-driven network for tumor classification varies with stain-style of histopathological images. This article proposes the stain-style transfer (SST) model based on conditional generative adversarial networks (GANs) which is to learn not only the certain color distribution but also the corresponding histopathological pattern. Our model considers feature-preserving loss in addition to well-known GAN loss. Consequently our model does not only transfers initial stain-styles to the desired one but also prevent the degradation of tumor classifier on transferred images. The model is examined using the CAMELYON16 dataset.\n    ",
        "submission_date": "2017-10-23T00:00:00",
        "last_modified_date": "2017-10-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.08585",
        "title": "Max-Margin Invariant Features from Transformed Unlabeled Data",
        "authors": [
            "Dipan K. Pal",
            "Ashwin A. Kannan",
            "Gautam Arakalgud",
            "Marios Savvides"
        ],
        "abstract": "The study of representations invariant to common transformations of the data is important to learning. Most techniques have focused on local approximate invariance implemented within expensive optimization frameworks lacking explicit theoretical guarantees. In this paper, we study kernels that are invariant to a unitary group while having theoretical guarantees in addressing the important practical issue of unavailability of transformed versions of labelled data. A problem we call the Unlabeled Transformation Problem which is a special form of semi-supervised learning and one-shot learning. We present a theoretically motivated alternate approach to the invariant kernel SVM based on which we propose Max-Margin Invariant Features (MMIF) to solve this problem. As an illustration, we design an framework for face recognition and demonstrate the efficacy of our approach on a large scale semi-synthetic dataset with 153,000 images and a new challenging protocol on Labelled Faces in the Wild (LFW) while out-performing strong baselines.\n    ",
        "submission_date": "2017-10-24T00:00:00",
        "last_modified_date": "2017-10-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.08893",
        "title": "Fast Model Identification via Physics Engines for Data-Efficient Policy Search",
        "authors": [
            "Shaojun Zhu",
            "Andrew Kimmel",
            "Kostas E. Bekris",
            "Abdeslam Boularias"
        ],
        "abstract": "This paper presents a method for identifying mechanical parameters of robots or objects, such as their mass and friction coefficients. Key features are the use of off-the-shelf physics engines and the adaptation of a Bayesian optimization technique towards minimizing the number of real-world experiments needed for model-based reinforcement learning. The proposed framework reproduces in a physics engine experiments performed on a real robot and optimizes the model's mechanical parameters so as to match real-world trajectories. The optimized model is then used for learning a policy in simulation, before real-world deployment. It is well understood, however, that it is hard to exactly reproduce real trajectories in simulation. Moreover, a near-optimal policy can be frequently found with an imperfect model. Therefore, this work proposes a strategy for identifying a model that is just good enough to approximate the value of a locally optimal policy with a certain confidence, instead of wasting effort on identifying the most accurate model. Evaluations, performed both in simulation and on a real robotic manipulation task, indicate that the proposed strategy results in an overall time-efficient, integrated model identification and learning solution, which significantly improves the data-efficiency of existing policy search algorithms.\n    ",
        "submission_date": "2017-10-24T00:00:00",
        "last_modified_date": "2018-06-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.08969",
        "title": "Efficiently Trainable Text-to-Speech System Based on Deep Convolutional Networks with Guided Attention",
        "authors": [
            "Hideyuki Tachibana",
            "Katsuya Uenoyama",
            "Shunsuke Aihara"
        ],
        "abstract": "This paper describes a novel text-to-speech (TTS) technique based on deep convolutional neural networks (CNN), without use of any recurrent units. Recurrent neural networks (RNN) have become a standard technique to model sequential data recently, and this technique has been used in some cutting-edge neural TTS techniques. However, training RNN components often requires a very powerful computer, or a very long time, typically several days or weeks. Recent other studies, on the other hand, have shown that CNN-based sequence synthesis can be much faster than RNN-based techniques, because of high parallelizability. The objective of this paper is to show that an alternative neural TTS based only on CNN alleviate these economic costs of training. In our experiment, the proposed Deep Convolutional TTS was sufficiently trained overnight (15 hours), using an ordinary gaming PC equipped with two GPUs, while the quality of the synthesized speech was almost acceptable.\n    ",
        "submission_date": "2017-10-24T00:00:00",
        "last_modified_date": "2020-09-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.09012",
        "title": "An Energy-Efficient Mixed-Signal Neuron for Inherently Error-Resilient Neuromorphic Systems",
        "authors": [
            "Baibhab Chatterjee",
            "Priyadarshini Panda",
            "Shovan Maity",
            "Kaushik Roy",
            "Shreyas Sen"
        ],
        "abstract": "This work presents the design and analysis of a mixed-signal neuron (MS-N) for convolutional neural networks (CNN) and compares its performance with a digital neuron (Dig-N) in terms of operating frequency, power and noise. The circuit-level implementation of the MS-N in 65 nm CMOS technology exhibits 2-3 orders of magnitude better energy-efficiency over Dig-N for neuromorphic computing applications - especially at low frequencies due to the high leakage currents from many transistors in Dig-N. The inherent error-resiliency of CNN is exploited to handle the thermal and flicker noise of MS-N. A system-level analysis using a cohesive circuit-algorithmic framework on MNIST and CIFAR-10 datasets demonstrate an increase of 3% in worst-case classification error for MNIST when the integrated noise power in the bandwidth is ~ 1 {\\mu}V2.\n    ",
        "submission_date": "2017-10-24T00:00:00",
        "last_modified_date": "2017-10-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.09471",
        "title": "Inductive Representation Learning in Large Attributed Graphs",
        "authors": [
            "Nesreen K. Ahmed",
            "Ryan A. Rossi",
            "Rong Zhou",
            "John Boaz Lee",
            "Xiangnan Kong",
            "Theodore L. Willke",
            "Hoda Eldardiry"
        ],
        "abstract": "Graphs (networks) are ubiquitous and allow us to model entities (nodes) and the dependencies (edges) between them. Learning a useful feature representation from graph data lies at the heart and success of many machine learning tasks such as classification, anomaly detection, link prediction, among many others. Many existing techniques use random walks as a basis for learning features or estimating the parameters of a graph model for a downstream prediction task. Examples include recent node embedding methods such as DeepWalk, node2vec, as well as graph-based deep learning algorithms. However, the simple random walk used by these methods is fundamentally tied to the identity of the node. This has three main disadvantages. First, these approaches are inherently transductive and do not generalize to unseen nodes and other graphs. Second, they are not space-efficient as a feature vector is learned for each node which is impractical for large graphs. Third, most of these approaches lack support for attributed graphs.\n",
        "submission_date": "2017-10-25T00:00:00",
        "last_modified_date": "2017-11-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.09549",
        "title": "Context-Aware Generative Adversarial Privacy",
        "authors": [
            "Chong Huang",
            "Peter Kairouz",
            "Xiao Chen",
            "Lalitha Sankar",
            "Ram Rajagopal"
        ],
        "abstract": "Preserving the utility of published datasets while simultaneously providing provable privacy guarantees is a well-known challenge. On the one hand, context-free privacy solutions, such as differential privacy, provide strong privacy guarantees, but often lead to a significant reduction in utility. On the other hand, context-aware privacy solutions, such as information theoretic privacy, achieve an improved privacy-utility tradeoff, but assume that the data holder has access to dataset statistics. We circumvent these limitations by introducing a novel context-aware privacy framework called generative adversarial privacy (GAP). GAP leverages recent advancements in generative adversarial networks (GANs) to allow the data holder to learn privatization schemes from the dataset itself. Under GAP, learning the privacy mechanism is formulated as a constrained minimax game between two players: a privatizer that sanitizes the dataset in a way that limits the risk of inference attacks on the individuals' private variables, and an adversary that tries to infer the private variables from the sanitized dataset. To evaluate GAP's performance, we investigate two simple (yet canonical) statistical dataset models: (a) the binary data model, and (b) the binary Gaussian mixture model. For both models, we derive game-theoretically optimal minimax privacy mechanisms, and show that the privacy mechanisms learned from data (in a generative adversarial fashion) match the theoretically optimal ones. This demonstrates that our framework can be easily applied in practice, even in the absence of dataset statistics.\n    ",
        "submission_date": "2017-10-26T00:00:00",
        "last_modified_date": "2017-12-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.09554",
        "title": "Duality-free Methods for Stochastic Composition Optimization",
        "authors": [
            "Liu Liu",
            "Ji Liu",
            "Dacheng Tao"
        ],
        "abstract": "We consider the composition optimization with two expected-value functions in the form of $\\frac{1}{n}\\sum\\nolimits_{i = 1}^n F_i(\\frac{1}{m}\\sum\\nolimits_{j = 1}^m G_j(x))+R(x)$, { which formulates many important problems in statistical learning and machine learning such as solving Bellman equations in reinforcement learning and nonlinear embedding}. Full Gradient or classical stochastic gradient descent based optimization algorithms are unsuitable or computationally expensive to solve this problem due to the inner expectation $\\frac{1}{m}\\sum\\nolimits_{j = 1}^m G_j(x)$. We propose a duality-free based stochastic composition method that combines variance reduction methods to address the stochastic composition problem. We apply SVRG and SAGA based methods to estimate the inner function, and duality-free method to estimate the outer function. We prove the linear convergence rate not only for the convex composition problem, but also for the case that the individual outer functions are non-convex while the objective function is strongly-convex. We also provide the results of experiments that show the effectiveness of our proposed methods.\n    ",
        "submission_date": "2017-10-26T00:00:00",
        "last_modified_date": "2017-10-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.09762",
        "title": "How to Fool Radiologists with Generative Adversarial Networks? A Visual Turing Test for Lung Cancer Diagnosis",
        "authors": [
            "Maria J. M. Chuquicusma",
            "Sarfaraz Hussein",
            "Jeremy Burt",
            "Ulas Bagci"
        ],
        "abstract": "Discriminating lung nodules as malignant or benign is still an underlying challenge. To address this challenge, radiologists need computer aided diagnosis (CAD) systems which can assist in learning discriminative imaging features corresponding to malignant and benign nodules. However, learning highly discriminative imaging features is an open problem. In this paper, our aim is to learn the most discriminative features pertaining to lung nodules by using an adversarial learning methodology. Specifically, we propose to use unsupervised learning with Deep Convolutional-Generative Adversarial Networks (DC-GANs) to generate lung nodule samples realistically. We hypothesize that imaging features of lung nodules will be discriminative if it is hard to differentiate them (fake) from real (true) nodules. To test this hypothesis, we present Visual Turing tests to two radiologists in order to evaluate the quality of the generated (fake) nodules. Extensive comparisons are performed in discerning real, generated, benign, and malignant nodules. This experimental set up allows us to validate the overall quality of the generated nodules, which can then be used to (1) improve diagnostic decisions by mining highly discriminative imaging features, (2) train radiologists for educational purposes, and (3) generate realistic samples to train deep networks with big data.\n    ",
        "submission_date": "2017-10-26T00:00:00",
        "last_modified_date": "2018-01-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.09779",
        "title": "Deep Multi-Modal Classification of Intraductal Papillary Mucinous Neoplasms (IPMN) with Canonical Correlation Analysis",
        "authors": [
            "Sarfaraz Hussein",
            "Pujan Kandel",
            "Juan E. Corral",
            "Candice W. Bolan",
            "Michael B. Wallace",
            "Ulas Bagci"
        ],
        "abstract": "Pancreatic cancer has the poorest prognosis among all cancer types. Intraductal Papillary Mucinous Neoplasms (IPMNs) are radiographically identifiable precursors to pancreatic cancer; hence, early detection and precise risk assessment of IPMN are vital. In this work, we propose a Convolutional Neural Network (CNN) based computer aided diagnosis (CAD) system to perform IPMN diagnosis and risk assessment by utilizing multi-modal MRI. In our proposed approach, we use minimum and maximum intensity projections to ease the annotation variations among different slices and type of MRIs. Then, we present a CNN to obtain deep feature representation corresponding to each MRI modality (T1-weighted and T2-weighted). At the final step, we employ canonical correlation analysis (CCA) to perform a fusion operation at the feature level, leading to discriminative canonical correlation features. Extracted features are used for classification. Our results indicate significant improvements over other potential approaches to solve this important problem. The proposed approach doesn't require explicit sample balancing in cases of imbalance between positive and negative examples. To the best of our knowledge, our study is the first to automatically diagnose IPMN using multi-modal MRI.\n    ",
        "submission_date": "2017-10-26T00:00:00",
        "last_modified_date": "2018-04-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.09824",
        "title": "Klout Topics for Modeling Interests and Expertise of Users Across Social Networks",
        "authors": [
            "Sarah Ellinger",
            "Prantik Bhattacharyya",
            "Preeti Bhargava",
            "Nemanja Spasojevic"
        ],
        "abstract": "This paper presents Klout Topics, a lightweight ontology to describe social media users' topics of interest and expertise. Klout Topics is designed to: be human-readable and consumer-friendly; cover multiple domains of knowledge in depth; and promote data extensibility via knowledge base entities. We discuss why this ontology is well-suited for text labeling and interest modeling applications, and how it compares to available alternatives. We show its coverage against common social media interest sets, and examples of how it is used to model the interests of over 780M social media users on ",
        "submission_date": "2017-10-26T00:00:00",
        "last_modified_date": "2017-10-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.09867",
        "title": "Understanding Early Word Learning in Situated Artificial Agents",
        "authors": [
            "Felix Hill",
            "Stephen Clark",
            "Karl Moritz Hermann",
            "Phil Blunsom"
        ],
        "abstract": "Neural network-based systems can now learn to locate the referents of words and phrases in images, answer questions about visual scenes, and execute symbolic instructions as first-person actors in partially-observable worlds. To achieve this so-called grounded language learning, models must overcome challenges that infants face when learning their first words. While it is notable that models with no meaningful prior knowledge overcome these obstacles, researchers currently lack a clear understanding of how they do so, a problem that we attempt to address in this paper. For maximum control and generality, we focus on a simple neural network-based language learning agent, trained via policy-gradient methods, which can interpret single-word instructions in a simulated 3D world. Whilst the goal is not to explicitly model infant word learning, we take inspiration from experimental paradigms in developmental psychology and apply some of these to the artificial agent, exploring the conditions under which established human biases and learning effects emerge. We further propose a novel method for visualising semantic representations in the agent.\n    ",
        "submission_date": "2017-10-26T00:00:00",
        "last_modified_date": "2019-10-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.09954",
        "title": "Audiovisual Analytics Vocabulary and Ontology (AAVO): initial core and example expansion",
        "authors": [
            "Renato Fabbri",
            "Maria Cristina Ferreira de Oliveira"
        ],
        "abstract": "Visual Analytics might be defined as data mining assisted by interactive visual interfaces. The field has been receiving prominent consideration by researchers, developers and the industry. The literature, however, is complex because it involves multiple fields of knowledge and is considerably recent. In this article we describe an initial tentative organization of the knowledge in the field as an OWL ontology and a SKOS vocabulary. This effort might be useful in many ways that include conceptual considerations and software implementations. Within the results and discussions, we expose a core and an example expansion of the conceptualization, and incorporate design issues that enhance the expressive power of the abstraction.\n    ",
        "submission_date": "2017-10-27T00:00:00",
        "last_modified_date": "2017-10-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.10035",
        "title": "Convolutional neural networks on irregular domains based on approximate vertex-domain translations",
        "authors": [
            "Bastien Pasdeloup",
            "Vincent Gripon",
            "Jean-Charles Vialatte",
            "Dominique Pastor",
            "Pascal Frossard"
        ],
        "abstract": "We propose a generalization of convolutional neural networks (CNNs) to irregular domains, through the use of a translation operator on a graph structure. In regular settings such as images, convolutional layers are designed by translating a convolutional kernel over all pixels, thus enforcing translation equivariance. In the case of general graphs however, translation is not a well-defined operation, which makes shifting a convolutional kernel not straightforward. In this article, we introduce a methodology to allow the design of convolutional layers that are adapted to signals evolving on irregular topologies, even in the absence of a natural translation. Using the designed layers, we build a CNN that we train using the initial set of signals. Contrary to other approaches that aim at extending CNNs to irregular domains, we incorporate the classical settings of CNNs for 2D signals as a particular case of our approach. Designing convolutional layers in the vertex domain directly implies weight sharing, which in other approaches is generally estimated a posteriori using heuristics.\n    ",
        "submission_date": "2017-10-27T00:00:00",
        "last_modified_date": "2018-11-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.10057",
        "title": "Multiwinner Voting with Fairness Constraints",
        "authors": [
            "L. Elisa Celis",
            "Lingxiao Huang",
            "Nisheeth K. Vishnoi"
        ],
        "abstract": "Multiwinner voting rules are used to select a small representative subset of candidates or items from a larger set given the preferences of voters. However, if candidates have sensitive attributes such as gender or ethnicity (when selecting a committee), or specified types such as political leaning (when selecting a subset of news items), an algorithm that chooses a subset by optimizing a multiwinner voting rule may be unbalanced in its selection -- it may under or over represent a particular gender or political orientation in the examples above. We introduce an algorithmic framework for multiwinner voting problems when there is an additional requirement that the selected subset should be \"fair\" with respect to a given set of attributes. Our framework provides the flexibility to (1) specify fairness with respect to multiple, non-disjoint attributes (e.g., ethnicity and gender) and (2) specify a score function. We study the computational complexity of this constrained multiwinner voting problem for monotone and submodular score functions and present several approximation algorithms and matching hardness of approximation results for various attribute group structure and types of score functions. We also present simulations that suggest that adding fairness constraints may not affect the scores significantly when compared to the unconstrained case.\n    ",
        "submission_date": "2017-10-27T00:00:00",
        "last_modified_date": "2018-06-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.10116",
        "title": "Inverse Reinforcement Learning Under Noisy Observations",
        "authors": [
            "Shervin Shahryari",
            "Prashant Doshi"
        ],
        "abstract": "We consider the problem of performing inverse reinforcement learning when the trajectory of the expert is not perfectly observed by the learner. Instead, a noisy continuous-time observation of the trajectory is provided to the learner. This problem exhibits wide-ranging applications and the specific application we consider here is the scenario in which the learner seeks to penetrate a perimeter patrolled by a robot. The learner's field of view is limited due to which it cannot observe the patroller's complete trajectory. Instead, we allow the learner to listen to the expert's movement sound, which it can also use to estimate the expert's state and action using an observation model. We treat the expert's state and action as hidden data and present an algorithm based on expectation maximization and maximum entropy principle to solve the non-linear, non-convex problem. Related work considers discrete-time observations and an observation model that does not include actions. In contrast, our technique takes expectations over both state and action of the expert, enabling learning even in the presence of extreme noise and broader applications.\n    ",
        "submission_date": "2017-10-27T00:00:00",
        "last_modified_date": "2017-10-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.10335",
        "title": "Similarity-based Multi-label Learning",
        "authors": [
            "Ryan A. Rossi",
            "Nesreen K. Ahmed",
            "Hoda Eldardiry",
            "Rong Zhou"
        ],
        "abstract": "Multi-label classification is an important learning problem with many applications. In this work, we propose a principled similarity-based approach for multi-label learning called SML. We also introduce a similarity-based approach for predicting the label set size. The experimental results demonstrate the effectiveness of SML for multi-label classification where it is shown to compare favorably with a wide variety of existing algorithms across a range of evaluation criterion.\n    ",
        "submission_date": "2017-10-27T00:00:00",
        "last_modified_date": "2017-10-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.10386",
        "title": "Dual Skipping Networks",
        "authors": [
            "Changmao Cheng",
            "Yanwei Fu",
            "Yu-Gang Jiang",
            "Wei Liu",
            "Wenlian Lu",
            "Jianfeng Feng",
            "Xiangyang Xue"
        ],
        "abstract": "Inspired by the recent neuroscience studies on the left-right asymmetry of the human brain in processing low and high spatial frequency information, this paper introduces a dual skipping network which carries out coarse-to-fine object categorization. Such a network has two branches to simultaneously deal with both coarse and fine-grained classification tasks. Specifically, we propose a layer-skipping mechanism that learns a gating network to predict which layers to skip in the testing stage. This layer-skipping mechanism endows the network with good flexibility and capability in practice. Evaluations are conducted on several widely used coarse-to-fine object categorization benchmarks, and promising results are achieved by our proposed network model.\n    ",
        "submission_date": "2017-10-28T00:00:00",
        "last_modified_date": "2018-05-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.10466",
        "title": "Scale-Robust Localization Using General Object Landmarks",
        "authors": [
            "Andrew Holliday",
            "Gregory Dudek"
        ],
        "abstract": "Visual localization under large changes in scale is an important capability in many robotic mapping applications, such as localizing at low altitudes in maps built at high altitudes, or performing loop closure over long distances. Existing approaches, however, are robust only up to about a 3x difference in scale between map and query images.\n",
        "submission_date": "2017-10-28T00:00:00",
        "last_modified_date": "2018-05-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.10519",
        "title": "Exploiting Points and Lines in Regression Forests for RGB-D Camera Relocalization",
        "authors": [
            "Lili Meng",
            "Frederick Tung",
            "James J. Little",
            "Julien Valentin",
            "Clarence de Silva"
        ],
        "abstract": "Camera relocalization plays a vital role in many robotics and computer vision tasks, such as global localization, recovery from tracking failure and loop closure detection. Recent random forests based methods exploit randomly sampled pixel comparison features to predict 3D world locations for 2D image locations to guide the camera pose optimization. However, these image features are only sampled randomly in the images, without considering the spatial structures or geometric information, leading to large errors or failure cases with the existence of poorly textured areas or in motion blur. Line segment features are more robust in these environments. In this work, we propose to jointly exploit points and lines within the framework of uncertainty driven regression forests. The proposed approach is thoroughly evaluated on three publicly available datasets against several strong state-of-the-art baselines in terms of several different error metrics. Experimental results prove the efficacy of our method, showing superior or on-par state-of-the-art performance.\n    ",
        "submission_date": "2017-10-28T00:00:00",
        "last_modified_date": "2018-07-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.10532",
        "title": "Interpretable Apprenticeship Learning with Temporal Logic Specifications",
        "authors": [
            "Daniel Kasenberg",
            "Matthias Scheutz"
        ],
        "abstract": "Recent work has addressed using formulas in linear temporal logic (LTL) as specifications for agents planning in Markov Decision Processes (MDPs). We consider the inverse problem: inferring an LTL specification from demonstrated behavior trajectories in MDPs. We formulate this as a multiobjective optimization problem, and describe state-based (\"what actually happened\") and action-based (\"what the agent expected to happen\") objective functions based on a notion of \"violation cost\". We demonstrate the efficacy of the approach by employing genetic programming to solve this problem in two simple domains.\n    ",
        "submission_date": "2017-10-28T00:00:00",
        "last_modified_date": "2017-10-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.10550",
        "title": "Vehicle Routing Problem with Vector Profits (VRPVP) with Max-Min Criterion",
        "authors": [
            "Dongoo Lee",
            "Jaemyung Ahn"
        ],
        "abstract": "This paper introduces a new routing problem referred to as the vehicle routing problem with vector profits. Given a network composed of nodes (depot/sites) and arcs connecting the nodes, the problem determines routes that depart from the depot, visit sites to collect profits, and return to the depot. There are multiple stakeholders interested in the mission and each site is associated with a vector whose k-th element represents the profit value for the k-th stakeholder. The objective of the problem is to maximize the profit sum for the least satisfied stakeholder, i.e., the stakeholder with the smallest total profit value. An approach based on the linear programming relaxation and column-generation to solve this max-min type routing problem was developed. Two cases studies - the planetary surface exploration and the Rome tour cases - were presented to demonstrate the effectiveness of the proposed problem formulation and solution methodology.\n    ",
        "submission_date": "2017-10-29T00:00:00",
        "last_modified_date": "2017-10-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.10600",
        "title": "Regularization approaches for support vector machines with applications to biomedical data",
        "authors": [
            "Daniel Lopez-Martinez"
        ],
        "abstract": "The support vector machine (SVM) is a widely used machine learning tool for classification based on statistical learning theory. Given a set of training data, the SVM finds a hyperplane that separates two different classes of data points by the largest distance. While the standard form of SVM uses L2-norm regularization, other regularization approaches are particularly attractive for biomedical datasets where, for example, sparsity and interpretability of the classifier's coefficient values are highly desired features. Therefore, in this paper we consider different types of regularization approaches for SVMs, and explore them in both synthetic and real biomedical datasets.\n    ",
        "submission_date": "2017-10-29T00:00:00",
        "last_modified_date": "2017-10-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.10686",
        "title": "Regularization for Deep Learning: A Taxonomy",
        "authors": [
            "Jan Kuka\u010dka",
            "Vladimir Golkov",
            "Daniel Cremers"
        ],
        "abstract": "Regularization is one of the crucial ingredients of deep learning, yet the term regularization has various definitions, and regularization methods are often studied separately from each other. In our work we present a systematic, unifying taxonomy to categorize existing methods. We distinguish methods that affect data, network architectures, error terms, regularization terms, and optimization procedures. We do not provide all details about the listed methods; instead, we present an overview of how the methods can be sorted into meaningful categories and sub-categories. This helps revealing links and fundamental similarities between them. Finally, we include practical recommendations both for users and for developers of new regularization methods.\n    ",
        "submission_date": "2017-10-29T00:00:00",
        "last_modified_date": "2017-10-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.10704",
        "title": "Training Probabilistic Spiking Neural Networks with First-to-spike Decoding",
        "authors": [
            "Alireza Bagheri",
            "Osvaldo Simeone",
            "Bipin Rajendran"
        ],
        "abstract": "Third-generation neural networks, or Spiking Neural Networks (SNNs), aim at harnessing the energy efficiency of spike-domain processing by building on computing elements that operate on, and exchange, spikes. In this paper, the problem of training a two-layer SNN is studied for the purpose of classification, under a Generalized Linear Model (GLM) probabilistic neural model that was previously considered within the computational neuroscience literature. Conventional classification rules for SNNs operate offline based on the number of output spikes at each output neuron. In contrast, a novel training method is proposed here for a first-to-spike decoding rule, whereby the SNN can perform an early classification decision once spike firing is detected at an output neuron. Numerical results bring insights into the optimal parameter selection for the GLM neuron and on the accuracy-complexity trade-off performance of conventional and first-to-spike decoding.\n    ",
        "submission_date": "2017-10-29T00:00:00",
        "last_modified_date": "2018-02-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.10753",
        "title": "Computational Social Choice and Computational Complexity: BFFs?",
        "authors": [
            "Lane A. Hemaspaandra"
        ],
        "abstract": "We discuss the connection between computational social choice (comsoc) and computational complexity. We stress the work so far on, and urge continued focus on, two less-recognized aspects of this connection. Firstly, this is very much a two-way street: Everyone knows complexity classification is used in comsoc, but we also highlight benefits to complexity that have arisen from its use in comsoc. Secondly, more subtle, less-known complexity tools often can be very productively used in comsoc.\n    ",
        "submission_date": "2017-10-30T00:00:00",
        "last_modified_date": "2017-11-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.10772",
        "title": "Tensorizing Generative Adversarial Nets",
        "authors": [
            "Xingwei Cao",
            "Xuyang Zhao",
            "Qibin Zhao"
        ],
        "abstract": "Generative Adversarial Network (GAN) and its variants exhibit state-of-the-art performance in the class of generative models. To capture higher-dimensional distributions, the common learning procedure requires high computational complexity and a large number of parameters. The problem of employing such massive framework arises when deploying it on a platform with limited computational power such as mobile phones. In this paper, we present a new generative adversarial framework by representing each layer as a tensor structure connected by multilinear operations, aiming to reduce the number of model parameters by a large factor while preserving the generative performance and sample quality. To learn the model, we employ an efficient algorithm which alternatively optimizes both discriminator and generator. Experimental outcomes demonstrate that our model can achieve high compression rate for model parameters up to $35$ times when compared to the original GAN for MNIST dataset.\n    ",
        "submission_date": "2017-10-30T00:00:00",
        "last_modified_date": "2018-03-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.10777",
        "title": "Understanding Hidden Memories of Recurrent Neural Networks",
        "authors": [
            "Yao Ming",
            "Shaozu Cao",
            "Ruixiang Zhang",
            "Zhen Li",
            "Yuanzhe Chen",
            "Yangqiu Song",
            "Huamin Qu"
        ],
        "abstract": "Recurrent neural networks (RNNs) have been successfully applied to various natural language processing (NLP) tasks and achieved better results than conventional methods. However, the lack of understanding of the mechanisms behind their effectiveness limits further improvements on their architectures. In this paper, we present a visual analytics method for understanding and comparing RNN models for NLP tasks. We propose a technique to explain the function of individual hidden state units based on their expected response to input texts. We then co-cluster hidden state units and words based on the expected response and visualize co-clustering results as memory chips and word clouds to provide more structured knowledge on RNNs' hidden states. We also propose a glyph-based sequence visualization based on aggregate information to analyze the behavior of an RNN's hidden state at the sentence-level. The usability and effectiveness of our method are demonstrated through case studies and reviews from domain experts.\n    ",
        "submission_date": "2017-10-30T00:00:00",
        "last_modified_date": "2017-10-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.10824",
        "title": "Rough extreme learning machine: a new classification method based on uncertainty measure",
        "authors": [
            "Lin Feng",
            "Shuliang Xu",
            "Feilong Wang",
            "Shenglan Liu"
        ],
        "abstract": "Extreme learning machine (ELM) is a new single hidden layer feedback neural network. The weights of the input layer and the biases of neurons in hidden layer are randomly generated, the weights of the output layer can be analytically determined. ELM has been achieved good results for a large number of classification tasks. In this paper, a new extreme learning machine called rough extreme learning machine (RELM) was proposed. RELM uses rough set to divide data into upper approximation set and lower approximation set, and the two approximation sets are utilized to train upper approximation neurons and lower approximation neurons. In addition, an attribute reduction is executed in this algorithm to remove redundant attributes. The experimental results showed, comparing with the comparison algorithms, RELM can get a better accuracy and repeatability in most cases, RELM can not only maintain the advantages of fast speed, but also effectively cope with the classification task for high-dimensional data.\n    ",
        "submission_date": "2017-10-30T00:00:00",
        "last_modified_date": "2018-03-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.10903",
        "title": "Graph Attention Networks",
        "authors": [
            "Petar Veli\u010dkovi\u0107",
            "Guillem Cucurull",
            "Arantxa Casanova",
            "Adriana Romero",
            "Pietro Li\u00f2",
            "Yoshua Bengio"
        ],
        "abstract": "We present graph attention networks (GATs), novel neural network architectures that operate on graph-structured data, leveraging masked self-attentional layers to address the shortcomings of prior methods based on graph convolutions or their approximations. By stacking layers in which nodes are able to attend over their neighborhoods' features, we enable (implicitly) specifying different weights to different nodes in a neighborhood, without requiring any kind of costly matrix operation (such as inversion) or depending on knowing the graph structure upfront. In this way, we address several key challenges of spectral-based graph neural networks simultaneously, and make our model readily applicable to inductive as well as transductive problems. Our GAT models have achieved or matched state-of-the-art results across four established transductive and inductive graph benchmarks: the Cora, Citeseer and Pubmed citation network datasets, as well as a protein-protein interaction dataset (wherein test graphs remain unseen during training).\n    ",
        "submission_date": "2017-10-30T00:00:00",
        "last_modified_date": "2018-02-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.10916",
        "title": "StackGAN++: Realistic Image Synthesis with Stacked Generative Adversarial Networks",
        "authors": [
            "Han Zhang",
            "Tao Xu",
            "Hongsheng Li",
            "Shaoting Zhang",
            "Xiaogang Wang",
            "Xiaolei Huang",
            "Dimitris Metaxas"
        ],
        "abstract": "Although Generative Adversarial Networks (GANs) have shown remarkable success in various tasks, they still face challenges in generating high quality images. In this paper, we propose Stacked Generative Adversarial Networks (StackGAN) aiming at generating high-resolution photo-realistic images. First, we propose a two-stage generative adversarial network architecture, StackGAN-v1, for text-to-image synthesis. The Stage-I GAN sketches the primitive shape and colors of the object based on given text description, yielding low-resolution images. The Stage-II GAN takes Stage-I results and text descriptions as inputs, and generates high-resolution images with photo-realistic details. Second, an advanced multi-stage generative adversarial network architecture, StackGAN-v2, is proposed for both conditional and unconditional generative tasks. Our StackGAN-v2 consists of multiple generators and discriminators in a tree-like structure; images at multiple scales corresponding to the same scene are generated from different branches of the tree. StackGAN-v2 shows more stable training behavior than StackGAN-v1 by jointly approximating multiple distributions. Extensive experiments demonstrate that the proposed stacked generative adversarial networks significantly outperform other state-of-the-art methods in generating photo-realistic images.\n    ",
        "submission_date": "2017-10-19T00:00:00",
        "last_modified_date": "2018-06-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.10928",
        "title": "Optimization Landscape and Expressivity of Deep CNNs",
        "authors": [
            "Quynh Nguyen",
            "Matthias Hein"
        ],
        "abstract": "We analyze the loss landscape and expressiveness of practical deep convolutional neural networks (CNNs) with shared weights and max pooling layers. We show that such CNNs produce linearly independent features at a \"wide\" layer which has more neurons than the number of training samples. This condition holds e.g. for the VGG network. Furthermore, we provide for such wide CNNs necessary and sufficient conditions for global minima with zero training error. For the case where the wide layer is followed by a fully connected layer we show that almost every critical point of the empirical loss is a global minimum with zero training error. Our analysis suggests that both depth and width are very important in deep learning. While depth brings more representational power and allows the network to learn high level features, width smoothes the optimization landscape of the loss function in the sense that a sufficiently wide network has a well-behaved loss surface with almost no bad local minima.\n    ",
        "submission_date": "2017-10-30T00:00:00",
        "last_modified_date": "2018-06-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.10967",
        "title": "Artificial Intelligence as Structural Estimation: Economic Interpretations of Deep Blue, Bonanza, and AlphaGo",
        "authors": [
            "Mitsuru Igami"
        ],
        "abstract": "Artificial intelligence (AI) has achieved superhuman performance in a growing number of tasks, but understanding and explaining AI remain challenging. This paper clarifies the connections between machine-learning algorithms to develop AIs and the econometrics of dynamic structural models through the case studies of three famous game AIs. Chess-playing Deep Blue is a calibrated value function, whereas shogi-playing Bonanza is an estimated value function via Rust's (1987) nested fixed-point method. AlphaGo's \"supervised-learning policy network\" is a deep neural network implementation of Hotz and Miller's (1993) conditional choice probability estimation; its \"reinforcement-learning value network\" is equivalent to Hotz, Miller, Sanders, and Smith's (1994) conditional choice simulation method. Relaxing these AIs' implicit econometric assumptions would improve their structural interpretability.\n    ",
        "submission_date": "2017-10-30T00:00:00",
        "last_modified_date": "2018-03-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.11040",
        "title": "How Should a Robot Assess Risk? Towards an Axiomatic Theory of Risk in Robotics",
        "authors": [
            "Anirudha Majumdar",
            "Marco Pavone"
        ],
        "abstract": "Endowing robots with the capability of assessing risk and making risk-aware decisions is widely considered a key step toward ensuring safety for robots operating under uncertainty. But, how should a robot quantify risk? A natural and common approach is to consider the framework whereby costs are assigned to stochastic outcomes - an assignment captured by a cost random variable. Quantifying risk then corresponds to evaluating a risk metric, i.e., a mapping from the cost random variable to a real number. Yet, the question of what constitutes a \"good\" risk metric has received little attention within the robotics community. The goal of this paper is to explore and partially address this question by advocating axioms that risk metrics in robotics applications should satisfy in order to be employed as rational assessments of risk. We discuss general representation theorems that precisely characterize the class of metrics that satisfy these axioms (referred to as distortion risk metrics), and provide instantiations that can be used in applications. We further discuss pitfalls of commonly used risk metrics in robotics, and discuss additional properties that one must consider in sequential decision making tasks. Our hope is that the ideas presented here will lead to a foundational framework for quantifying risk (and hence safety) in robotics applications.\n    ",
        "submission_date": "2017-10-30T00:00:00",
        "last_modified_date": "2017-11-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.11041",
        "title": "Unsupervised Neural Machine Translation",
        "authors": [
            "Mikel Artetxe",
            "Gorka Labaka",
            "Eneko Agirre",
            "Kyunghyun Cho"
        ],
        "abstract": "In spite of the recent success of neural machine translation (NMT) in standard benchmarks, the lack of large parallel corpora poses a major practical problem for many language pairs. There have been several proposals to alleviate this issue with, for instance, triangulation and semi-supervised learning techniques, but they still require a strong cross-lingual signal. In this work, we completely remove the need of parallel data and propose a novel method to train an NMT system in a completely unsupervised manner, relying on nothing but monolingual corpora. Our model builds upon the recent work on unsupervised embedding mappings, and consists of a slightly modified attentional encoder-decoder model that can be trained on monolingual corpora alone using a combination of denoising and backtranslation. Despite the simplicity of the approach, our system obtains 15.56 and 10.21 BLEU points in WMT 2014 French-to-English and German-to-English translation. The model can also profit from small parallel corpora, and attains 21.81 and 15.24 points when combined with 100,000 parallel sentences, respectively. Our implementation is released as an open source project.\n    ",
        "submission_date": "2017-10-30T00:00:00",
        "last_modified_date": "2018-02-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.11089",
        "title": "Eigenoption Discovery through the Deep Successor Representation",
        "authors": [
            "Marlos C. Machado",
            "Clemens Rosenbaum",
            "Xiaoxiao Guo",
            "Miao Liu",
            "Gerald Tesauro",
            "Murray Campbell"
        ],
        "abstract": "Options in reinforcement learning allow agents to hierarchically decompose a task into subtasks, having the potential to speed up learning and planning. However, autonomously learning effective sets of options is still a major challenge in the field. In this paper we focus on the recently introduced idea of using representation learning methods to guide the option discovery process. Specifically, we look at eigenoptions, options obtained from representations that encode diffusive information flow in the environment. We extend the existing algorithms for eigenoption discovery to settings with stochastic transitions and in which handcrafted features are not available. We propose an algorithm that discovers eigenoptions while learning non-linear state representations from raw pixels. It exploits recent successes in the deep reinforcement learning literature and the equivalence between proto-value functions and the successor representation. We use traditional tabular domains to provide intuition about our approach and Atari 2600 games to demonstrate its potential.\n    ",
        "submission_date": "2017-10-30T00:00:00",
        "last_modified_date": "2018-02-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.11160",
        "title": "Exponential improvements for quantum-accessible reinforcement learning",
        "authors": [
            "Vedran Dunjko",
            "Yi-Kai Liu",
            "Xingyao Wu",
            "Jacob M. Taylor"
        ],
        "abstract": "Quantum computers can offer dramatic improvements over classical devices for data analysis tasks such as prediction and classification. However, less is known about the advantages that quantum computers may bring in the setting of reinforcement learning, where learning is achieved via interaction with a task environment. Here, we consider a special case of reinforcement learning, where the task environment allows quantum access. In addition, we impose certain \"naturalness\" conditions on the task environment, which rule out the kinds of oracle problems that are studied in quantum query complexity (and for which quantum speedups are well-known). Within this framework of quantum-accessible reinforcement learning environments, we demonstrate that quantum agents can achieve exponential improvements in learning efficiency, surpassing previous results that showed only quadratic improvements. A key step in the proof is to construct task environments that encode well-known oracle problems, such as Simon's problem and Recursive Fourier Sampling, while satisfying the above \"naturalness\" conditions for reinforcement learning. Our results suggest that quantum agents may perform well in certain game-playing scenarios, where the game has recursive structure, and the agent can learn by playing against itself.\n    ",
        "submission_date": "2017-10-30T00:00:00",
        "last_modified_date": "2018-08-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.11169",
        "title": "Indirect Supervision for Relation Extraction using Question-Answer Pairs",
        "authors": [
            "Zeqiu Wu",
            "Xiang Ren",
            "Frank F. Xu",
            "Ji Li",
            "Jiawei Han"
        ],
        "abstract": "Automatic relation extraction (RE) for types of interest is of great importance for interpreting massive text corpora in an efficient manner. Traditional RE models have heavily relied on human-annotated corpus for training, which can be costly in generating labeled data and become obstacles when dealing with more relation types. Thus, more RE extraction systems have shifted to be built upon training data automatically acquired by linking to knowledge bases (distant supervision). However, due to the incompleteness of knowledge bases and the context-agnostic labeling, the training data collected via distant supervision (DS) can be very noisy. In recent years, as increasing attention has been brought to tackling question-answering (QA) tasks, user feedback or datasets of such tasks become more accessible. In this paper, we propose a novel framework, ReQuest, to leverage question-answer pairs as an indirect source of supervision for relation extraction, and study how to use such supervision to reduce noise induced from DS. Our model jointly embeds relation mentions, types, QA entity mention pairs and text features in two low-dimensional spaces (RE and QA), where objects with same relation types or semantically similar question-answer pairs have similar representations. Shared features connect these two spaces, carrying clearer semantic knowledge from both sources. ReQuest, then use these learned embeddings to estimate the types of test relation mentions. We formulate a global objective function and adopt a novel margin-based QA loss to reduce noise in DS by exploiting semantic evidence from the QA dataset. Our experimental results achieve an average of 11% improvement in F1 score on two public RE datasets combined with TREC QA dataset.\n    ",
        "submission_date": "2017-10-30T00:00:00",
        "last_modified_date": "2017-11-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.11223",
        "title": "Fast and Scalable Learning of Sparse Changes in High-Dimensional Gaussian Graphical Model Structure",
        "authors": [
            "Beilun Wang",
            "Arshdeep Sekhon",
            "Yanjun Qi"
        ],
        "abstract": "We focus on the problem of estimating the change in the dependency structures of two $p$-dimensional Gaussian Graphical models (GGMs). Previous studies for sparse change estimation in GGMs involve expensive and difficult non-smooth optimization. We propose a novel method, DIFFEE for estimating DIFFerential networks via an Elementary Estimator under a high-dimensional situation. DIFFEE is solved through a faster and closed form solution that enables it to work in large-scale settings. We conduct a rigorous statistical analysis showing that surprisingly DIFFEE achieves the same asymptotic convergence rates as the state-of-the-art estimators that are much more difficult to compute. Our experimental results on multiple synthetic datasets and one real-world data about brain connectivity show strong performance improvements over baselines, as well as significant computational benefits.\n    ",
        "submission_date": "2017-10-30T00:00:00",
        "last_modified_date": "2018-05-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.11238",
        "title": "Prototype Matching Networks for Large-Scale Multi-label Genomic Sequence Classification",
        "authors": [
            "Jack Lanchantin",
            "Arshdeep Sekhon",
            "Ritambhara Singh",
            "Yanjun Qi"
        ],
        "abstract": "One of the fundamental tasks in understanding genomics is the problem of predicting Transcription Factor Binding Sites (TFBSs). With more than hundreds of Transcription Factors (TFs) as labels, genomic-sequence based TFBS prediction is a challenging multi-label classification task. There are two major biological mechanisms for TF binding: (1) sequence-specific binding patterns on genomes known as \"motifs\" and (2) interactions among TFs known as co-binding effects. In this paper, we propose a novel deep architecture, the Prototype Matching Network (PMN) to mimic the TF binding mechanisms. Our PMN model automatically extracts prototypes (\"motif\"-like features) for each TF through a novel prototype-matching loss. Borrowing ideas from few-shot matching models, we use the notion of support set of prototypes and an LSTM to learn how TFs interact and bind to genomic sequences. On a reference TFBS dataset with $2.1$ $million$ genomic sequences, PMN significantly outperforms baselines and validates our design choices empirically. To our knowledge, this is the first deep learning architecture that introduces prototype learning and considers TF-TF interactions for large-scale TFBS prediction. Not only is the proposed architecture accurate, but it also models the underlying biology.\n    ",
        "submission_date": "2017-10-30T00:00:00",
        "last_modified_date": "2017-11-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.11277",
        "title": "Adversarial Advantage Actor-Critic Model for Task-Completion Dialogue Policy Learning",
        "authors": [
            "Baolin Peng",
            "Xiujun Li",
            "Jianfeng Gao",
            "Jingjing Liu",
            "Yun-Nung Chen",
            "Kam-Fai Wong"
        ],
        "abstract": "This paper presents a new method --- adversarial advantage actor-critic (Adversarial A2C), which significantly improves the efficiency of dialogue policy learning in task-completion dialogue systems. Inspired by generative adversarial networks (GAN), we train a discriminator to differentiate responses/actions generated by dialogue agents from responses/actions by experts. Then, we incorporate the discriminator as another critic into the advantage actor-critic (A2C) framework, to encourage the dialogue agent to explore state-action within the regions where the agent takes actions similar to those of the experts. Experimental results in a movie-ticket booking domain show that the proposed Adversarial A2C can accelerate policy exploration efficiently.\n    ",
        "submission_date": "2017-10-31T00:00:00",
        "last_modified_date": "2018-02-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.11311",
        "title": "Deep Forward and Inverse Perceptual Models for Tracking and Prediction",
        "authors": [
            "Alexander Lambert",
            "Amirreza Shaban",
            "Amit Raj",
            "Zhen Liu",
            "Byron Boots"
        ],
        "abstract": "We consider the problems of learning forward models that map state to high-dimensional images and inverse models that map high-dimensional images to state in robotics. Specifically, we present a perceptual model for generating video frames from state with deep networks, and provide a framework for its use in tracking and prediction tasks. We show that our proposed model greatly outperforms standard deconvolutional methods and GANs for image generation, producing clear, photo-realistic images. We also develop a convolutional neural network model for state estimation and compare the result to an Extended Kalman Filter to estimate robot trajectories. We validate all models on a real robotic system.\n    ",
        "submission_date": "2017-10-31T00:00:00",
        "last_modified_date": "2018-05-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.11342",
        "title": "Generating Natural Adversarial Examples",
        "authors": [
            "Zhengli Zhao",
            "Dheeru Dua",
            "Sameer Singh"
        ],
        "abstract": "Due to their complex nature, it is hard to characterize the ways in which machine learning models can misbehave or be exploited when deployed. Recent work on adversarial examples, i.e. inputs with minor perturbations that result in substantially different model predictions, is helpful in evaluating the robustness of these models by exposing the adversarial scenarios where they fail. However, these malicious perturbations are often unnatural, not semantically meaningful, and not applicable to complicated domains such as language. In this paper, we propose a framework to generate natural and legible adversarial examples that lie on the data manifold, by searching in semantic space of dense and continuous data representation, utilizing the recent advances in generative adversarial networks. We present generated adversaries to demonstrate the potential of the proposed approach for black-box classifiers for a wide range of applications such as image classification, textual entailment, and machine translation. We include experiments to show that the generated adversaries are natural, legible to humans, and useful in evaluating and analyzing black-box classifiers.\n    ",
        "submission_date": "2017-10-31T00:00:00",
        "last_modified_date": "2018-02-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.11386",
        "title": "Parametrizing filters of a CNN with a GAN",
        "authors": [
            "Yannic Kilcher",
            "Gary Becigneul",
            "Thomas Hofmann"
        ],
        "abstract": "It is commonly agreed that the use of relevant invariances as a good statistical bias is important in machine-learning. However, most approaches that explicitly incorporate invariances into a model architecture only make use of very simple transformations, such as translations and rotations. Hence, there is a need for methods to model and extract richer transformations that capture much higher-level invariances. To that end, we introduce a tool allowing to parametrize the set of filters of a trained convolutional neural network with the latent space of a generative adversarial network. We then show that the method can capture highly non-linear invariances of the data by visualizing their effect in the data space.\n    ",
        "submission_date": "2017-10-31T00:00:00",
        "last_modified_date": "2017-10-31T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.11424",
        "title": "Regret Minimization for Partially Observable Deep Reinforcement Learning",
        "authors": [
            "Peter Jin",
            "Kurt Keutzer",
            "Sergey Levine"
        ],
        "abstract": "Deep reinforcement learning algorithms that estimate state and state-action value functions have been shown to be effective in a variety of challenging domains, including learning control strategies from raw image pixels. However, algorithms that estimate state and state-action value functions typically assume a fully observed state and must compensate for partial observations by using finite length observation histories or recurrent networks. In this work, we propose a new deep reinforcement learning algorithm based on counterfactual regret minimization that iteratively updates an approximation to an advantage-like function and is robust to partially observed state. We demonstrate that this new algorithm can substantially outperform strong baseline methods on several partially observed reinforcement learning tasks: learning first-person 3D navigation in Doom and Minecraft, and acting in the presence of partially observed objects in Doom and Pong.\n    ",
        "submission_date": "2017-10-31T00:00:00",
        "last_modified_date": "2018-10-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.11431",
        "title": "Physics-guided Neural Networks (PGNN): An Application in Lake Temperature Modeling",
        "authors": [
            "Arka Daw",
            "Anuj Karpatne",
            "William Watkins",
            "Jordan Read",
            "Vipin Kumar"
        ],
        "abstract": "This paper introduces a framework for combining scientific knowledge of physics-based models with neural networks to advance scientific discovery. This framework, termed physics-guided neural networks (PGNN), leverages the output of physics-based model simulations along with observational features in a hybrid modeling setup to generate predictions using a neural network architecture. Further, this framework uses physics-based loss functions in the learning objective of neural networks to ensure that the model predictions not only show lower errors on the training set but are also scientifically consistent with the known physics on the unlabeled set. We illustrate the effectiveness of PGNN for the problem of lake temperature modeling, where physical relationships between the temperature, density, and depth of water are used to design a physics-based loss function. By using scientific knowledge to guide the construction and learning of neural networks, we are able to show that the proposed framework ensures better generalizability as well as scientific consistency of results. All the code and datasets used in this study have been made available on this link \\url{",
        "submission_date": "2017-10-31T00:00:00",
        "last_modified_date": "2021-09-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.11577",
        "title": "Learning Depthwise Separable Graph Convolution from Data Manifold",
        "authors": [
            "Guokun Lai",
            "Hanxiao Liu",
            "Yiming Yang"
        ],
        "abstract": "Convolution Neural Network (CNN) has gained tremendous success in computer vision tasks with its outstanding ability to capture the local latent features. Recently, there has been an increasing interest in extending convolution operations to the non-Euclidean geometry. Although various types of convolution operations have been proposed for graphs or manifolds, their connections with traditional convolution over grid-structured data are not well-understood. In this paper, we show that depthwise separable convolution can be successfully generalized for the unification of both graph-based and grid-based convolution methods. Based on this insight we propose a novel Depthwise Separable Graph Convolution (DSGC) approach which is compatible with the tradition convolution network and subsumes existing convolution methods as special cases. It is equipped with the combined strengths in model expressiveness, compatibility (relatively small number of parameters), modularity and computational efficiency in training. Extensive experiments show the outstanding performance of DSGC in comparison with strong baselines on multi-domain benchmark datasets.\n    ",
        "submission_date": "2017-10-31T00:00:00",
        "last_modified_date": "2018-11-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.11601",
        "title": "Whodunnit? Crime Drama as a Case for Natural Language Understanding",
        "authors": [
            "Lea Frermann",
            "Shay B. Cohen",
            "Mirella Lapata"
        ],
        "abstract": "In this paper we argue that crime drama exemplified in television programs such as CSI:Crime Scene Investigation is an ideal testbed for approximating real-world natural language understanding and the complex inferences associated with it. We propose to treat crime drama as a new inference task, capitalizing on the fact that each episode poses the same basic question (i.e., who committed the crime) and naturally provides the answer when the perpetrator is revealed. We develop a new dataset based on CSI episodes, formalize perpetrator identification as a sequence labeling problem, and develop an LSTM-based model which learns from multi-modal data. Experimental results show that an incremental inference strategy is key to making accurate guesses as well as learning from representations fusing textual, visual, and acoustic input.\n    ",
        "submission_date": "2017-10-31T00:00:00",
        "last_modified_date": "2017-10-31T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1710.11622",
        "title": "Meta-Learning and Universality: Deep Representations and Gradient Descent can Approximate any Learning Algorithm",
        "authors": [
            "Chelsea Finn",
            "Sergey Levine"
        ],
        "abstract": "Learning to learn is a powerful paradigm for enabling models to learn from data more effectively and efficiently. A popular approach to meta-learning is to train a recurrent model to read in a training dataset as input and output the parameters of a learned model, or output predictions for new test inputs. Alternatively, a more recent approach to meta-learning aims to acquire deep representations that can be effectively fine-tuned, via standard gradient descent, to new tasks. In this paper, we consider the meta-learning problem from the perspective of universality, formalizing the notion of learning algorithm approximation and comparing the expressive power of the aforementioned recurrent models to the more recent approaches that embed gradient descent into the meta-learner. In particular, we seek to answer the following question: does deep representation combined with standard gradient descent have sufficient capacity to approximate any learning algorithm? We find that this is indeed true, and further find, in our experiments, that gradient-based meta-learning consistently leads to learning strategies that generalize more widely compared to those represented by recurrent models.\n    ",
        "submission_date": "2017-10-31T00:00:00",
        "last_modified_date": "2018-02-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.00043",
        "title": "Unsupervised Machine Translation Using Monolingual Corpora Only",
        "authors": [
            "Guillaume Lample",
            "Alexis Conneau",
            "Ludovic Denoyer",
            "Marc'Aurelio Ranzato"
        ],
        "abstract": "Machine translation has recently achieved impressive performance thanks to recent advances in deep learning and the availability of large-scale parallel corpora. There have been numerous attempts to extend these successes to low-resource language pairs, yet requiring tens of thousands of parallel sentences. In this work, we take this research direction to the extreme and investigate whether it is possible to learn to translate even without any parallel data. We propose a model that takes sentences from monolingual corpora in two different languages and maps them into the same latent space. By learning to reconstruct in both languages from this shared feature space, the model effectively learns to translate without using any labeled data. We demonstrate our model on two widely used datasets and two language pairs, reporting BLEU scores of 32.8 and 15.1 on the Multi30k and WMT English-French datasets, without using even a single parallel sentence at training time.\n    ",
        "submission_date": "2017-10-31T00:00:00",
        "last_modified_date": "2018-04-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.00066",
        "title": "Fraternal Dropout",
        "authors": [
            "Konrad Zolna",
            "Devansh Arpit",
            "Dendi Suhubdy",
            "Yoshua Bengio"
        ],
        "abstract": "Recurrent neural networks (RNNs) are important class of architectures among neural networks useful for language modeling and sequential prediction. However, optimizing RNNs is known to be harder compared to feed-forward neural networks. A number of techniques have been proposed in literature to address this problem. In this paper we propose a simple technique called fraternal dropout that takes advantage of dropout to achieve this goal. Specifically, we propose to train two identical copies of an RNN (that share parameters) with different dropout masks while minimizing the difference between their (pre-softmax) predictions. In this way our regularization encourages the representations of RNNs to be invariant to dropout mask, thus being robust. We show that our regularization term is upper bounded by the expectation-linear dropout objective which has been shown to address the gap due to the difference between the train and inference phases of dropout. We evaluate our model and achieve state-of-the-art results in sequence modeling tasks on two benchmark datasets - Penn Treebank and Wikitext-2. We also show that our approach leads to performance improvement by a significant margin in image captioning (Microsoft COCO) and semi-supervised (CIFAR-10) tasks.\n    ",
        "submission_date": "2017-10-31T00:00:00",
        "last_modified_date": "2018-03-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.00106",
        "title": "DCN+: Mixed Objective and Deep Residual Coattention for Question Answering",
        "authors": [
            "Caiming Xiong",
            "Victor Zhong",
            "Richard Socher"
        ],
        "abstract": "Traditional models for question answering optimize using cross entropy loss, which encourages exact answers at the cost of penalizing nearby or overlapping answers that are sometimes equally accurate. We propose a mixed objective that combines cross entropy loss with self-critical policy learning. The objective uses rewards derived from word overlap to solve the misalignment between evaluation metric and optimization objective. In addition to the mixed objective, we improve dynamic coattention networks (DCN) with a deep residual coattention encoder that is inspired by recent work in deep self-attention and residual networks. Our proposals improve model performance across question types and input lengths, especially for long questions that requires the ability to capture long-term dependencies. On the Stanford Question Answering Dataset, our model achieves state-of-the-art results with 75.1% exact match accuracy and 83.1% F1, while the ensemble obtains 78.9% exact match accuracy and 86.0% F1.\n    ",
        "submission_date": "2017-10-31T00:00:00",
        "last_modified_date": "2017-11-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.00107",
        "title": "Separation of Water and Fat Magnetic Resonance Imaging Signals Using Deep Learning with Convolutional Neural Networks",
        "authors": [
            "James W Goldfarb"
        ],
        "abstract": "Purpose: A new method for magnetic resonance (MR) imaging water-fat separation using a convolutional neural network (ConvNet) and deep learning (DL) is presented. Feasibility of the method with complex and magnitude images is demonstrated with a series of patient studies and accuracy of predicted quantitative values is analyzed.\n",
        "submission_date": "2017-10-27T00:00:00",
        "last_modified_date": "2017-10-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.00108",
        "title": "Beyond Shared Hierarchies: Deep Multitask Learning through Soft Layer Ordering",
        "authors": [
            "Elliot Meyerson",
            "Risto Miikkulainen"
        ],
        "abstract": "Existing deep multitask learning (MTL) approaches align layers shared between tasks in a parallel ordering. Such an organization significantly constricts the types of shared structure that can be learned. The necessity of parallel ordering for deep MTL is first tested by comparing it with permuted ordering of shared layers. The results indicate that a flexible ordering can enable more effective sharing, thus motivating the development of a soft ordering approach, which learns how shared layers are applied in different ways for different tasks. Deep MTL with soft ordering outperforms parallel ordering methods across a series of domains. These results suggest that the power of deep MTL comes from learning highly general building blocks that can be assembled to meet the demands of each task.\n    ",
        "submission_date": "2017-10-31T00:00:00",
        "last_modified_date": "2018-02-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.00267",
        "title": "Acquiring Target Stacking Skills by Goal-Parameterized Deep Reinforcement Learning",
        "authors": [
            "Wenbin Li",
            "Jeannette Bohg",
            "Mario Fritz"
        ],
        "abstract": "Understanding physical phenomena is a key component of human intelligence and enables physical interaction with previously unseen environments. In this paper, we study how an artificial agent can autonomously acquire this intuition through interaction with the environment. We created a synthetic block stacking environment with physics simulation in which the agent can learn a policy end-to-end through trial and error. Thereby, we bypass to explicitly model physical knowledge within the policy. We are specifically interested in tasks that require the agent to reach a given goal state that may be different for every new trial. To this end, we propose a deep reinforcement learning framework that learns policies which are parametrized by a goal. We validated the model on a toy example navigating in a grid world with different target positions and in a block stacking task with different target structures of the final tower. In contrast to prior work, our policies show better generalization across different goals.\n    ",
        "submission_date": "2017-11-01T00:00:00",
        "last_modified_date": "2017-11-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.00350",
        "title": "Generalization without systematicity: On the compositional skills of sequence-to-sequence recurrent networks",
        "authors": [
            "Brenden M. Lake",
            "Marco Baroni"
        ],
        "abstract": "Humans can understand and produce new utterances effortlessly, thanks to their compositional skills. Once a person learns the meaning of a new verb \"dax,\" he or she can immediately understand the meaning of \"dax twice\" or \"sing and dax.\" In this paper, we introduce the SCAN domain, consisting of a set of simple compositional navigation commands paired with the corresponding action sequences. We then test the zero-shot generalization capabilities of a variety of recurrent neural networks (RNNs) trained on SCAN with sequence-to-sequence methods. We find that RNNs can make successful zero-shot generalizations when the differences between training and test commands are small, so that they can apply \"mix-and-match\" strategies to solve the task. However, when generalization requires systematic compositional skills (as in the \"dax\" example above), RNNs fail spectacularly. We conclude with a proof-of-concept experiment in neural machine translation, suggesting that lack of systematicity might be partially responsible for neural networks' notorious training data thirst.\n    ",
        "submission_date": "2017-10-31T00:00:00",
        "last_modified_date": "2018-06-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.00400",
        "title": "Minimal Exploration in Structured Stochastic Bandits",
        "authors": [
            "Richard Combes",
            "Stefan Magureanu",
            "Alexandre Proutiere"
        ],
        "abstract": "This paper introduces and addresses a wide class of stochastic bandit problems where the function mapping the arm to the corresponding reward exhibits some known structural properties. Most existing structures (e.g. linear, Lipschitz, unimodal, combinatorial, dueling, ...) are covered by our framework. We derive an asymptotic instance-specific regret lower bound for these problems, and develop OSSB, an algorithm whose regret matches this fundamental limit. OSSB is not based on the classical principle of \"optimism in the face of uncertainty\" or on Thompson sampling, and rather aims at matching the minimal exploration rates of sub-optimal arms as characterized in the derivation of the regret lower bound. We illustrate the efficiency of OSSB using numerical experiments in the case of the linear bandit problem and show that OSSB outperforms existing algorithms, including Thompson sampling.\n    ",
        "submission_date": "2017-11-01T00:00:00",
        "last_modified_date": "2017-11-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.00462",
        "title": "Early prediction of the duration of protests using probabilistic Latent Dirichlet Allocation and Decision Trees",
        "authors": [
            "Satyakama Paul",
            "Madhur Hasija",
            "Tshilidzi Marwala"
        ],
        "abstract": "Protests and agitations are an integral part of every democratic civil society. In recent years, South Africa has seen a large increase in its protests. The objective of this paper is to provide an early prediction of the duration of protests from its free flowing English text description. Free flowing descriptions of the protests help us in capturing its various nuances such as multiple causes, courses of actions etc. Next we use a combination of unsupervised learning (topic modeling) and supervised learning (decision trees) to predict the duration of the protests. Our results show a high degree (close to 90%) of accuracy in early prediction of the duration of ",
        "submission_date": "2017-09-18T00:00:00",
        "last_modified_date": "2017-09-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.00530",
        "title": "School bus routing by maximizing trip compatibility",
        "authors": [
            "Ali Shafahi",
            "Zhongxiang Wang",
            "Ali Haghani"
        ],
        "abstract": "School bus planning is usually divided into routing and scheduling due to the complexity of solving them concurrently. However, the separation between these two steps may lead to worse solutions with higher overall costs than that from solving them together. When finding the minimal number of trips in the routing problem, neglecting the importance of trip compatibility may increase the number of buses actually needed in the scheduling problem. This paper proposes a new formulation for the multi-school homogeneous fleet routing problem that maximizes trip compatibility while minimizing total travel time. This incorporates the trip compatibility for the scheduling problem in the routing problem. Since the problem is inherently just a routing problem, finding a good solution is not cumbersome. To compare the performance of the model with traditional routing problems, we generate eight mid-size data sets. Through importing the generated trips of the routing problems into the bus scheduling (blocking) problem, it is shown that the proposed model uses up to 13% fewer buses than the common traditional routing models.\n    ",
        "submission_date": "2017-11-01T00:00:00",
        "last_modified_date": "2017-11-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.00532",
        "title": "SCDA: School Compatibility Decomposition Algorithm for Solving the Multi-School Bus Routing and Scheduling Problem",
        "authors": [
            "Zhongxiang Wang",
            "Ali Shafahi",
            "Ali Haghani"
        ],
        "abstract": "Safely serving the school transportation demand with the minimum number of buses is one of the highest financial goals of school transportation directors. To achieve that objective, a good and efficient way to solve the routing and scheduling problem is required. Due to the growth of the computing power, the spotlight has been shed on solving the combined problem of the school bus routing and scheduling problem. We show that an integrated multi-school bus routing and scheduling can be formulated with the help of trip compatibility. A novel decomposition algorithm is proposed to solve the integrated model. The merit of this integrated model and the decomposition method is that with the consideration of the trip compatibility, the interrelationship between the routing and scheduling sub-problems will not be lost in the process of decomposition. Results show the proposed decomposed problem could provide the solutions using the same number of buses as the integrated model in much shorter time (as little as 0.6%) and that the proposed method can save up to 26% number of buses from existing research.\n    ",
        "submission_date": "2017-11-01T00:00:00",
        "last_modified_date": "2018-04-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.00536",
        "title": "Beautiful and damned. Combined effect of content quality and social ties on user engagement",
        "authors": [
            "Luca M. Aiello",
            "Rossano Schifanella",
            "Miriam Redi",
            "Stacey Svetlichnaya",
            "Frank Liu",
            "Simon Osindero"
        ],
        "abstract": "User participation in online communities is driven by the intertwinement of the social network structure with the crowd-generated content that flows along its links. These aspects are rarely explored jointly and at scale. By looking at how users generate and access pictures of varying beauty on Flickr, we investigate how the production of quality impacts the dynamics of online social systems. We develop a deep learning computer vision model to score images according to their aesthetic value and we validate its output through crowdsourcing. By applying it to over 15B Flickr photos, we study for the first time how image beauty is distributed over a large-scale social system. Beautiful images are evenly distributed in the network, although only a small core of people get social recognition for them. To study the impact of exposure to quality on user engagement, we set up matching experiments aimed at detecting causality from observational data. Exposure to beauty is double-edged: following people who produce high-quality content increases one's probability of uploading better photos; however, an excessive imbalance between the quality generated by a user and the user's neighbors leads to a decline in engagement. Our analysis has practical implications for improving link recommender systems.\n    ",
        "submission_date": "2017-11-01T00:00:00",
        "last_modified_date": "2017-11-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.00549",
        "title": "Just ASK: Building an Architecture for Extensible Self-Service Spoken Language Understanding",
        "authors": [
            "Anjishnu Kumar",
            "Arpit Gupta",
            "Julian Chan",
            "Sam Tucker",
            "Bjorn Hoffmeister",
            "Markus Dreyer",
            "Stanislav Peshterliev",
            "Ankur Gandhe",
            "Denis Filiminov",
            "Ariya Rastrow",
            "Christian Monson",
            "Agnika Kumar"
        ],
        "abstract": "This paper presents the design of the machine learning architecture that underlies the Alexa Skills Kit (ASK) a large scale Spoken Language Understanding (SLU) Software Development Kit (SDK) that enables developers to extend the capabilities of Amazon's virtual assistant, Alexa. At Amazon, the infrastructure powers over 25,000 skills deployed through the ASK, as well as AWS's Amazon Lex SLU Service. The ASK emphasizes flexibility, predictability and a rapid iteration cycle for third party developers. It imposes inductive biases that allow it to learn robust SLU models from extremely small and sparse datasets and, in doing so, removes significant barriers to entry for software developers and dialogue systems researchers.\n    ",
        "submission_date": "2017-11-01T00:00:00",
        "last_modified_date": "2018-03-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.00740",
        "title": "Learning to Represent Programs with Graphs",
        "authors": [
            "Miltiadis Allamanis",
            "Marc Brockschmidt",
            "Mahmoud Khademi"
        ],
        "abstract": "Learning tasks on source code (i.e., formal languages) have been considered recently, but most work has tried to transfer natural language methods and does not capitalize on the unique opportunities offered by code's known syntax. For example, long-range dependencies induced by using the same variable or function in distant locations are often not considered. We propose to use graphs to represent both the syntactic and semantic structure of code and use graph-based deep learning methods to learn to reason over program structures.\n",
        "submission_date": "2017-11-01T00:00:00",
        "last_modified_date": "2018-05-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.00804",
        "title": "Framework for evaluation of sound event detection in web videos",
        "authors": [
            "Rohan Badlani",
            "Ankit Shah",
            "Benjamin Elizalde",
            "Anurag Kumar",
            "Bhiksha Raj"
        ],
        "abstract": "The largest source of sound events is web videos. Most videos lack sound event labels at segment level, however, a significant number of them do respond to text queries, from a match found using metadata by search engines. In this paper we explore the extent to which a search query can be used as the true label for detection of sound events in videos. We present a framework for large-scale sound event recognition on web videos. The framework crawls videos using search queries corresponding to 78 sound event labels drawn from three datasets. The datasets are used to train three classifiers, and we obtain a prediction on 3.7 million web video segments. We evaluated performance using the search query as true label and compare it with human labeling. Both types of ground truth exhibited close performance, to within 10%, and similar performance trend with increasing number of evaluated segments. Hence, our experiments show potential for using search query as a preliminary true label for sound event recognition in web videos.\n    ",
        "submission_date": "2017-11-02T00:00:00",
        "last_modified_date": "2018-04-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.00848",
        "title": "Variational Inference of Disentangled Latent Concepts from Unlabeled Observations",
        "authors": [
            "Abhishek Kumar",
            "Prasanna Sattigeri",
            "Avinash Balakrishnan"
        ],
        "abstract": "Disentangled representations, where the higher level data generative factors are reflected in disjoint latent dimensions, offer several benefits such as ease of deriving invariant representations, transferability to other tasks, interpretability, etc. We consider the problem of unsupervised learning of disentangled representations from large pool of unlabeled observations, and propose a variational inference based approach to infer disentangled latent factors. We introduce a regularizer on the expectation of the approximate posterior over observed data that encourages the disentanglement. We also propose a new disentanglement metric which is better aligned with the qualitative disentanglement observed in the decoder's output. We empirically observe significant improvement over existing methods in terms of both disentanglement and data likelihood (reconstruction quality).\n    ",
        "submission_date": "2017-11-02T00:00:00",
        "last_modified_date": "2018-12-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.00851",
        "title": "Provable defenses against adversarial examples via the convex outer adversarial polytope",
        "authors": [
            "Eric Wong",
            "J. Zico Kolter"
        ],
        "abstract": "We propose a method to learn deep ReLU-based classifiers that are provably robust against norm-bounded adversarial perturbations on the training data. For previously unseen examples, the approach is guaranteed to detect all adversarial examples, though it may flag some non-adversarial examples as well. The basic idea is to consider a convex outer approximation of the set of activations reachable through a norm-bounded perturbation, and we develop a robust optimization procedure that minimizes the worst case loss over this outer region (via a linear program). Crucially, we show that the dual problem to this linear program can be represented itself as a deep network similar to the backpropagation network, leading to very efficient optimization approaches that produce guaranteed bounds on the robust loss. The end result is that by executing a few more forward and backward passes through a slightly modified version of the original network (though possibly with much larger batch sizes), we can learn a classifier that is provably robust to any norm-bounded adversarial attack. We illustrate the approach on a number of tasks to train classifiers with robust adversarial guarantees (e.g. for MNIST, we produce a convolutional classifier that provably has less than 5.8% test error for any adversarial attack with bounded $\\ell_\\infty$ norm less than $\\epsilon = 0.1$), and code for all experiments in the paper is available at ",
        "submission_date": "2017-11-02T00:00:00",
        "last_modified_date": "2018-06-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.00956",
        "title": "Running Time Analysis of the (1+1)-EA for OneMax and LeadingOnes under Bit-wise Noise",
        "authors": [
            "Chao Qian",
            "Chao Bian",
            "Wu Jiang",
            "Ke Tang"
        ],
        "abstract": "In many real-world optimization problems, the objective function evaluation is subject to noise, and we cannot obtain the exact objective value. Evolutionary algorithms (EAs), a type of general-purpose randomized optimization algorithm, have been shown to be able to solve noisy optimization problems well. However, previous theoretical analyses of EAs mainly focused on noise-free optimization, which makes the theoretical understanding largely insufficient for the noisy case. Meanwhile, the few existing theoretical studies under noise often considered the one-bit noise model, which flips a randomly chosen bit of a solution before evaluation; while in many realistic applications, several bits of a solution can be changed simultaneously. In this paper, we study a natural extension of one-bit noise, the bit-wise noise model, which independently flips each bit of a solution with some probability. We analyze the running time of the (1+1)-EA solving OneMax and LeadingOnes under bit-wise noise for the first time, and derive the ranges of the noise level for polynomial and super-polynomial running time bounds. The analysis on LeadingOnes under bit-wise noise can be easily transferred to one-bit noise, and improves the previously known results. Since our analysis discloses that the (1+1)-EA can be efficient only under low noise levels, we also study whether the sampling strategy can bring robustness to noise. We prove that using sampling can significantly increase the largest noise level allowing a polynomial running time, that is, sampling is robust to noise.\n    ",
        "submission_date": "2017-11-02T00:00:00",
        "last_modified_date": "2022-11-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.01024",
        "title": "SPARK: Static Program Analysis Reasoning and Retrieving Knowledge",
        "authors": [
            "Wasuwee Sodsong",
            "Bernhard Scholz",
            "Sanjay Chawla"
        ],
        "abstract": "Program analysis is a technique to reason about programs without executing them, and it has various applications in compilers, integrated development environments, and security. In this work, we present a machine learning pipeline that induces a security analyzer for programs by example. The security analyzer determines whether a program is either secure or insecure based on symbolic rules that were deduced by our machine learning pipeline. The machine pipeline is two-staged consisting of a Recurrent Neural Networks (RNN) and an Extractor that converts an RNN to symbolic rules.\n",
        "submission_date": "2017-11-03T00:00:00",
        "last_modified_date": "2017-11-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.01125",
        "title": "Spintronics based Stochastic Computing for Efficient Bayesian Inference System",
        "authors": [
            "Xiaotao Jia",
            "Jianlei Yang",
            "Zhaohao Wang",
            "Yiran Chen",
            "Weisheng Zhao"
        ],
        "abstract": "Bayesian inference is an effective approach for solving statistical learning problems especially with uncertainty and incompleteness. However, inference efficiencies are physically limited by the bottlenecks of conventional computing platforms. In this paper, an emerging Bayesian inference system is proposed by exploiting spintronics based stochastic computing. A stochastic bitstream generator is realized as the kernel components by leveraging the inherent randomness of spintronics devices. The proposed system is evaluated by typical applications of data fusion and Bayesian belief networks. Simulation results indicate that the proposed approach could achieve significant improvement on inference efficiencies in terms of power consumption and inference speed.\n    ",
        "submission_date": "2017-11-03T00:00:00",
        "last_modified_date": "2017-11-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.01244",
        "title": "Meta-Learning by Adjusting Priors Based on Extended PAC-Bayes Theory",
        "authors": [
            "Ron Amit",
            "Ron Meir"
        ],
        "abstract": "In meta-learning an agent extracts knowledge from observed tasks, aiming to facilitate learning of novel future tasks. Under the assumption that future tasks are 'related' to previous tasks, the accumulated knowledge should be learned in a way which captures the common structure across learned tasks, while allowing the learner sufficient flexibility to adapt to novel aspects of new tasks. We present a framework for meta-learning that is based on generalization error bounds, allowing us to extend various PAC-Bayes bounds to meta-learning. Learning takes place through the construction of a distribution over hypotheses based on the observed tasks, and its utilization for learning a new task. Thus, prior knowledge is incorporated through setting an experience-dependent prior for novel tasks. We develop a gradient-based algorithm which minimizes an objective function derived from the bounds and demonstrate its effectiveness numerically with deep neural networks. In addition to establishing the improved performance available through meta-learning, we demonstrate the intuitive way by which prior information is manifested at different levels of the network.\n    ",
        "submission_date": "2017-11-03T00:00:00",
        "last_modified_date": "2019-05-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.01283",
        "title": "Mandolin: A Knowledge Discovery Framework for the Web of Data",
        "authors": [
            "Tommaso Soru",
            "Diego Esteves",
            "Edgard Marx",
            "Axel-Cyrille Ngonga Ngomo"
        ],
        "abstract": "Markov Logic Networks join probabilistic modeling with first-order logic and have been shown to integrate well with the Semantic Web foundations. While several approaches have been devised to tackle the subproblems of rule mining, grounding, and inference, no comprehensive workflow has been proposed so far. In this paper, we fill this gap by introducing a framework called Mandolin, which implements a workflow for knowledge discovery specifically on RDF datasets. Our framework imports knowledge from referenced graphs, creates similarity relationships among similar literals, and relies on state-of-the-art techniques for rule mining, grounding, and inference computation. We show that our best configuration scales well and achieves at least comparable results with respect to other statistical-relational-learning algorithms on link prediction.\n    ",
        "submission_date": "2017-11-03T00:00:00",
        "last_modified_date": "2017-11-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.01287",
        "title": "Discovering More Precise Process Models from Event Logs by Filtering Out Chaotic Activities",
        "authors": [
            "Niek Tax",
            "Natalia Sidorova",
            "Wil M. P. van der Aalst"
        ],
        "abstract": "Process Discovery is concerned with the automatic generation of a process model that describes a business process from execution data of that business process. Real life event logs can contain chaotic activities. These activities are independent of the state of the process and can, therefore, happen at rather arbitrary points in time. We show that the presence of such chaotic activities in an event log heavily impacts the quality of the process models that can be discovered with process discovery techniques. The current modus operandi for filtering activities from event logs is to simply filter out infrequent activities. We show that frequency-based filtering of activities does not solve the problems that are caused by chaotic activities. Moreover, we propose a novel technique to filter out chaotic activities from event logs. We evaluate this technique on a collection of seventeen real-life event logs that originate from both the business process management domain and the smart home environment domain. As demonstrated, the developed activity filtering methods enable the discovery of process models that are more behaviorally specific compared to process models that are discovered using standard frequency-based filtering.\n    ",
        "submission_date": "2017-11-03T00:00:00",
        "last_modified_date": "2017-11-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.01353",
        "title": "Decentralised firewall for malware detection",
        "authors": [
            "Saurabh Raje",
            "Shyamal Vaderia",
            "Neil Wilson",
            "Rudrakh Panigrahi"
        ],
        "abstract": "This paper describes the design and development of a decentralized firewall system powered by a novel malware detection engine. The firewall is built using blockchain technology. The detection engine aims to classify Portable Executable (PE) files as malicious or benign. File classification is carried out using a deep belief neural network (DBN) as the detection engine. Our approach is to model the files as grayscale images and use the DBN to classify those images into the aforementioned two classes. An extensive data set of 10,000 files is used to train the DBN. Validation is carried out using 4,000 files previously unexposed to the network. The final result of whether to allow or block a file is obtained by arriving at a proof of work based consensus in the blockchain network.\n    ",
        "submission_date": "2017-11-03T00:00:00",
        "last_modified_date": "2017-11-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.01436",
        "title": "Searching for Biophysically Realistic Parameters for Dynamic Neuron Models by Genetic Algorithms from Calcium Imaging Recording",
        "authors": [
            "Magdalena Fuchs",
            "Manuel Zimmer",
            "Radu Grosu",
            "Ramin M. Hasani"
        ],
        "abstract": "Individual Neurons in the nervous systems exploit various dynamics. To capture these dynamics for single neurons, we tune the parameters of an electrophysiological model of nerve cells, to fit experimental data obtained by calcium imaging. A search for the biophysical parameters of this model is performed by means of a genetic algorithm, where the model neuron is exposed to a predefined input current representing overall inputs from other parts of the nervous system. The algorithm is then constrained for keeping the ion-channel currents within reasonable ranges, while producing the best fit to a calcium imaging time series of the AVA interneuron, from the brain of the soil-worm, C. elegans. Our settings enable us to project a set of biophysical parameters to the the neuron kinetics observed in neuronal imaging.\n    ",
        "submission_date": "2017-11-04T00:00:00",
        "last_modified_date": "2017-11-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.01468",
        "title": "Ensembles of Multiple Models and Architectures for Robust Brain Tumour Segmentation",
        "authors": [
            "Konstantinos Kamnitsas",
            "Wenjia Bai",
            "Enzo Ferrante",
            "Steven McDonagh",
            "Matthew Sinclair",
            "Nick Pawlowski",
            "Martin Rajchl",
            "Matthew Lee",
            "Bernhard Kainz",
            "Daniel Rueckert",
            "Ben Glocker"
        ],
        "abstract": "Deep learning approaches such as convolutional neural nets have consistently outperformed previous methods on challenging tasks such as dense, semantic segmentation. However, the various proposed networks perform differently, with behaviour largely influenced by architectural choices and training settings. This paper explores Ensembles of Multiple Models and Architectures (EMMA) for robust performance through aggregation of predictions from a wide range of methods. The approach reduces the influence of the meta-parameters of individual models and the risk of overfitting the configuration to a particular database. EMMA can be seen as an unbiased, generic deep learning model which is shown to yield excellent performance, winning the first position in the BRATS 2017 competition among 50+ participating teams.\n    ",
        "submission_date": "2017-11-04T00:00:00",
        "last_modified_date": "2017-11-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.01519",
        "title": "HPX Smart Executors",
        "authors": [
            "Zahra Khatami",
            "Lukas Troska",
            "Hartmut Kaiser",
            "J. Ramanujam",
            "Adrian Serio"
        ],
        "abstract": "The performance of many parallel applications depends on loop-level parallelism. However, manually parallelizing all loops may result in degrading parallel performance, as some of them cannot scale desirably to a large number of threads. In addition, the overheads of manually tuning loop parameters might prevent an application from reaching its maximum parallel performance. We illustrate how machine learning techniques can be applied to address these challenges. In this research, we develop a framework that is able to automatically capture the static and dynamic information of a loop. Moreover, we advocate a novel method by introducing HPX smart executors for determining the execution policy, chunk size, and prefetching distance of an HPX loop to achieve higher possible performance by feeding static information captured during compilation and runtime-based dynamic information to our learning model. Our evaluated execution results show that using these smart executors can speed up the HPX execution process by around 12%-35% for the Matrix Multiplication, Stream and $2D$ Stencil benchmarks compared to setting their HPX loop's execution policy/parameters manually or using HPX auto-parallelization techniques.\n    ",
        "submission_date": "2017-11-05T00:00:00",
        "last_modified_date": "2017-11-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.01530",
        "title": "Fisher-Rao Metric, Geometry, and Complexity of Neural Networks",
        "authors": [
            "Tengyuan Liang",
            "Tomaso Poggio",
            "Alexander Rakhlin",
            "James Stokes"
        ],
        "abstract": "We study the relationship between geometry and capacity measures for deep neural networks from an invariance viewpoint. We introduce a new notion of capacity --- the Fisher-Rao norm --- that possesses desirable invariance properties and is motivated by Information Geometry. We discover an analytical characterization of the new capacity measure, through which we establish norm-comparison inequalities and further show that the new measure serves as an umbrella for several existing norm-based complexity measures. We discuss upper bounds on the generalization error induced by the proposed measure. Extensive numerical experiments on CIFAR-10 support our theoretical findings. Our theoretical analysis rests on a key structural lemma about partial derivatives of multi-layer rectifier networks.\n    ",
        "submission_date": "2017-11-05T00:00:00",
        "last_modified_date": "2019-02-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.01577",
        "title": "Wider and Deeper, Cheaper and Faster: Tensorized LSTMs for Sequence Learning",
        "authors": [
            "Zhen He",
            "Shaobing Gao",
            "Liang Xiao",
            "Daxue Liu",
            "Hangen He",
            "David Barber"
        ],
        "abstract": "Long Short-Term Memory (LSTM) is a popular approach to boosting the ability of Recurrent Neural Networks to store longer term temporal information. The capacity of an LSTM network can be increased by widening and adding layers. However, usually the former introduces additional parameters, while the latter increases the runtime. As an alternative we propose the Tensorized LSTM in which the hidden states are represented by tensors and updated via a cross-layer convolution. By increasing the tensor size, the network can be widened efficiently without additional parameters since the parameters are shared across different locations in the tensor; by delaying the output, the network can be deepened implicitly with little additional runtime since deep computations for each timestep are merged into temporal computations of the sequence. Experiments conducted on five challenging sequence learning tasks show the potential of the proposed model.\n    ",
        "submission_date": "2017-11-05T00:00:00",
        "last_modified_date": "2017-12-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.01634",
        "title": "Strategies for Conceptual Change in Convolutional Neural Networks",
        "authors": [
            "Maarten Grachten",
            "Carlos Eduardo Cancino Chac\u00f3n"
        ],
        "abstract": "A remarkable feature of human beings is their capacity for creative behaviour, referring to their ability to react to problems in ways that are novel, surprising, and useful. Transformational creativity is a form of creativity where the creative behaviour is induced by a transformation of the actor's conceptual space, that is, the representational system with which the actor interprets its environment. In this report, we focus on ways of adapting systems of learned representations as they switch from performing one task to performing another. We describe an experimental comparison of multiple strategies for adaptation of learned features, and evaluate how effectively each of these strategies realizes the adaptation, in terms of the amount of training, and in terms of their ability to cope with restricted availability of training data. We show, among other things, that across handwritten digits, natural images, and classical music, adaptive strategies are systematically more effective than a baseline method that starts learning from scratch.\n    ",
        "submission_date": "2017-11-05T00:00:00",
        "last_modified_date": "2019-06-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.01694",
        "title": "Multilingual Speech Recognition With A Single End-To-End Model",
        "authors": [
            "Shubham Toshniwal",
            "Tara N. Sainath",
            "Ron J. Weiss",
            "Bo Li",
            "Pedro Moreno",
            "Eugene Weinstein",
            "Kanishka Rao"
        ],
        "abstract": "Training a conventional automatic speech recognition (ASR) system to support multiple languages is challenging because the sub-word unit, lexicon and word inventories are typically language specific. In contrast, sequence-to-sequence models are well suited for multilingual ASR because they encapsulate an acoustic, pronunciation and language model jointly in a single network. In this work we present a single sequence-to-sequence ASR model trained on 9 different Indian languages, which have very little overlap in their scripts. Specifically, we take a union of language-specific grapheme sets and train a grapheme-based sequence-to-sequence model jointly on data from all languages. We find that this model, which is not explicitly given any information about language identity, improves recognition performance by 21% relative compared to analogous sequence-to-sequence models trained on each language individually. By modifying the model to accept a language identifier as an additional input feature, we further improve performance by an additional 7% relative and eliminate confusion between different languages.\n    ",
        "submission_date": "2017-11-06T00:00:00",
        "last_modified_date": "2018-02-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.01711",
        "title": "Coding-theorem Like Behaviour and Emergence of the Universal Distribution from Resource-bounded Algorithmic Probability",
        "authors": [
            "Hector Zenil",
            "Liliana Badillo",
            "Santiago Hern\u00e1ndez-Orozco",
            "Francisco Hern\u00e1ndez-Quiroz"
        ],
        "abstract": "Previously referred to as `miraculous' in the scientific literature because of its powerful properties and its wide application as optimal solution to the problem of induction/inference, (approximations to) Algorithmic Probability (AP) and the associated Universal Distribution are (or should be) of the greatest importance in science. Here we investigate the emergence, the rates of emergence and convergence, and the Coding-theorem like behaviour of AP in Turing-subuniversal models of computation. We investigate empirical distributions of computing models in the Chomsky hierarchy. We introduce measures of algorithmic probability and algorithmic complexity based upon resource-bounded computation, in contrast to previously thoroughly investigated distributions produced from the output distribution of Turing machines. This approach allows for numerical approximations to algorithmic (Kolmogorov-Chaitin) complexity-based estimations at each of the levels of a computational hierarchy. We demonstrate that all these estimations are correlated in rank and that they converge both in rank and values as a function of computational power, despite fundamental differences between computational models. In the context of natural processes that operate below the Turing universal level because of finite resources and physical degradation, the investigation of natural biases stemming from algorithmic rules may shed light on the distribution of outcomes. We show that up to 60\\% of the simplicity/complexity bias in distributions produced even by the weakest of the computational models can be accounted for by Algorithmic Probability in its approximation to the Universal Distribution.\n    ",
        "submission_date": "2017-11-06T00:00:00",
        "last_modified_date": "2018-04-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.01744",
        "title": "KGAN: How to Break The Minimax Game in GAN",
        "authors": [
            "Trung Le",
            "Tu Dinh Nguyen",
            "Dinh Phung"
        ],
        "abstract": "Generative Adversarial Networks (GANs) were intuitively and attractively explained under the perspective of game theory, wherein two involving parties are a discriminator and a generator. In this game, the task of the discriminator is to discriminate the real and generated (i.e., fake) data, whilst the task of the generator is to generate the fake data that maximally confuses the discriminator. In this paper, we propose a new viewpoint for GANs, which is termed as the minimizing general loss viewpoint. This viewpoint shows a connection between the general loss of a classification problem regarding a convex loss function and a f-divergence between the true and fake data distributions. Mathematically, we proposed a setting for the classification problem of the true and fake data, wherein we can prove that the general loss of this classification problem is exactly the negative f-divergence for a certain convex function f. This allows us to interpret the problem of learning the generator for dismissing the f-divergence between the true and fake data distributions as that of maximizing the general loss which is equivalent to the min-max problem in GAN if the Logistic loss is used in the classification problem. However, this viewpoint strengthens GANs in two ways. First, it allows us to employ any convex loss function for the discriminator. Second, it suggests that rather than limiting ourselves in NN-based discriminators, we can alternatively utilize other powerful families. Bearing this viewpoint, we then propose using the kernel-based family for discriminators. This family has two appealing features: i) a powerful capacity in classifying non-linear nature data and ii) being convex in the feature space. Using the convexity of this family, we can further develop Fenchel duality to equivalently transform the max-min problem to the max-max dual problem.\n    ",
        "submission_date": "2017-11-06T00:00:00",
        "last_modified_date": "2017-11-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.01843",
        "title": "Online Tool Condition Monitoring Based on Parsimonious Ensemble+",
        "authors": [
            "Mahardhika Pratama",
            "Eric Dimla",
            "Edwin Lughofer",
            "Witold Pedrycz",
            "Tegoeh Tjahjowidowo"
        ],
        "abstract": "Accurate diagnosis of tool wear in metal turning process remains an open challenge for both scientists and industrial practitioners because of inhomogeneities in workpiece material, nonstationary machining settings to suit production requirements, and nonlinear relations between measured variables and tool wear. Common methodologies for tool condition monitoring still rely on batch approaches which cannot cope with a fast sampling rate of metal cutting process. Furthermore they require a retraining process to be completed from scratch when dealing with a new set of machining parameters. This paper presents an online tool condition monitoring approach based on Parsimonious Ensemble+, pENsemble+. The unique feature of pENsemble+ lies in its highly flexible principle where both ensemble structure and base-classifier structure can automatically grow and shrink on the fly based on the characteristics of data streams. Moreover, the online feature selection scenario is integrated to actively sample relevant input attributes. The paper presents advancement of a newly developed ensemble learning algorithm, pENsemble+, where online active learning scenario is incorporated to reduce operator labelling effort. The ensemble merging scenario is proposed which allows reduction of ensemble complexity while retaining its diversity. Experimental studies utilising real-world manufacturing data streams and comparisons with well known algorithms were carried out. Furthermore, the efficacy of pENsemble was examined using benchmark concept drift data streams. It has been found that pENsemble+ incurs low structural complexity and results in a significant reduction of operator labelling effort.\n    ",
        "submission_date": "2017-11-06T00:00:00",
        "last_modified_date": "2019-12-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.02012",
        "title": "Hi, how can I help you?: Automating enterprise IT support help desks",
        "authors": [
            "Senthil Mani",
            "Neelamadhav Gantayat",
            "Rahul Aralikatte",
            "Monika Gupta",
            "Sampath Dechu",
            "Anush Sankaran",
            "Shreya Khare",
            "Barry Mitchell",
            "Hemamalini Subramanian",
            "Hema Venkatarangan"
        ],
        "abstract": "Question answering is one of the primary challenges of natural language understanding. In realizing such a system, providing complex long answers to questions is a challenging task as opposed to factoid answering as the former needs context disambiguation. The different methods explored in the literature can be broadly classified into three categories namely: 1) classification based, 2) knowledge graph based and 3) retrieval based. Individually, none of them address the need of an enterprise wide assistance system for an IT support and maintenance domain. In this domain the variance of answers is large ranging from factoid to structured operating procedures; the knowledge is present across heterogeneous data sources like application specific documentation, ticket management systems and any single technique for a general purpose assistance is unable to scale for such a landscape. To address this, we have built a cognitive platform with capabilities adopted for this domain. Further, we have built a general purpose question answering system leveraging the platform that can be instantiated for multiple products, technologies in the support domain. The system uses a novel hybrid answering model that orchestrates across a deep learning classifier, a knowledge graph based context disambiguation module and a sophisticated bag-of-words search system. This orchestration performs context switching for a provided question and also does a smooth hand-off of the question to a human expert if none of the automated techniques can provide a confident answer. This system has been deployed across 675 internal enterprise IT support and maintenance projects.\n    ",
        "submission_date": "2017-11-02T00:00:00",
        "last_modified_date": "2017-11-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.02013",
        "title": "Neural Language Modeling by Jointly Learning Syntax and Lexicon",
        "authors": [
            "Yikang Shen",
            "Zhouhan Lin",
            "Chin-Wei Huang",
            "Aaron Courville"
        ],
        "abstract": "We propose a neural language model capable of unsupervised syntactic structure induction. The model leverages the structure information to form better semantic representations and better language modeling. Standard recurrent neural networks are limited by their structure and fail to efficiently use syntactic information. On the other hand, tree-structured recursive networks usually require additional structural supervision at the cost of human expert annotation. In this paper, We propose a novel neural language model, called the Parsing-Reading-Predict Networks (PRPN), that can simultaneously induce the syntactic structure from unannotated sentences and leverage the inferred structure to learn a better language model. In our model, the gradient can be directly back-propagated from the language model loss into the neural parsing network. Experiments show that the proposed model can discover the underlying syntactic structure and achieve state-of-the-art performance on word/character-level language model tasks.\n    ",
        "submission_date": "2017-11-02T00:00:00",
        "last_modified_date": "2018-02-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.02017",
        "title": "NeST: A Neural Network Synthesis Tool Based on a Grow-and-Prune Paradigm",
        "authors": [
            "Xiaoliang Dai",
            "Hongxu Yin",
            "Niraj K. Jha"
        ],
        "abstract": "Deep neural networks (DNNs) have begun to have a pervasive impact on various applications of machine learning. However, the problem of finding an optimal DNN architecture for large applications is challenging. Common approaches go for deeper and larger DNN architectures but may incur substantial redundancy. To address these problems, we introduce a network growth algorithm that complements network pruning to learn both weights and compact DNN architectures during training. We propose a DNN synthesis tool (NeST) that combines both methods to automate the generation of compact and accurate DNNs. NeST starts with a randomly initialized sparse network called the seed architecture. It iteratively tunes the architecture with gradient-based growth and magnitude-based pruning of neurons and connections. Our experimental results show that NeST yields accurate, yet very compact DNNs, with a wide range of seed architecture selection. For the LeNet-300-100 (LeNet-5) architecture, we reduce network parameters by 70.2x (74.3x) and floating-point operations (FLOPs) by 79.4x (43.7x). For the AlexNet and VGG-16 architectures, we reduce network parameters (FLOPs) by 15.7x (4.6x) and 30.2x (8.6x), respectively. NeST's grow-and-prune paradigm delivers significant additional parameter and FLOPs reduction relative to pruning-only methods.\n    ",
        "submission_date": "2017-11-06T00:00:00",
        "last_modified_date": "2018-06-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.02114",
        "title": "Bounding and Counting Linear Regions of Deep Neural Networks",
        "authors": [
            "Thiago Serra",
            "Christian Tjandraatmadja",
            "Srikumar Ramalingam"
        ],
        "abstract": "We investigate the complexity of deep neural networks (DNN) that represent piecewise linear (PWL) functions. In particular, we study the number of linear regions, i.e. pieces, that a PWL function represented by a DNN can attain, both theoretically and empirically. We present (i) tighter upper and lower bounds for the maximum number of linear regions on rectifier networks, which are exact for inputs of dimension one; (ii) a first upper bound for multi-layer maxout networks; and (iii) a first method to perform exact enumeration or counting of the number of regions by modeling the DNN with a mixed-integer linear formulation. These bounds come from leveraging the dimension of the space defining each linear region. The results also indicate that a deep rectifier network can only have more linear regions than every shallow counterpart with same number of neurons if that number exceeds the dimension of the input.\n    ",
        "submission_date": "2017-11-06T00:00:00",
        "last_modified_date": "2018-09-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.02159",
        "title": "Adaptive Bayesian Sampling with Monte Carlo EM",
        "authors": [
            "Anirban Roychowdhury",
            "Srinivasan Parthasarathy"
        ],
        "abstract": "We present a novel technique for learning the mass matrices in samplers obtained from discretized dynamics that preserve some energy function. Existing adaptive samplers use Riemannian preconditioning techniques, where the mass matrices are functions of the parameters being sampled. This leads to significant complexities in the energy reformulations and resultant dynamics, often leading to implicit systems of equations and requiring inversion of high-dimensional matrices in the leapfrog steps. Our approach provides a simpler alternative, by using existing dynamics in the sampling step of a Monte Carlo EM framework, and learning the mass matrices in the M step with a novel online technique. We also propose a way to adaptively set the number of samples gathered in the E step, using sampling error estimates from the leapfrog dynamics. Along with a novel stochastic sampler based on Nos\u00e9-Poincar\u00e9 dynamics, we use this framework with standard Hamiltonian Monte Carlo (HMC) as well as newer stochastic algorithms such as SGHMC and SGNHT, and show strong performance on synthetic and real high-dimensional sampling scenarios; we achieve sampling accuracies comparable to Riemannian samplers while being significantly faster.\n    ",
        "submission_date": "2017-11-06T00:00:00",
        "last_modified_date": "2017-11-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.02195",
        "title": "Optimality of Approximate Inference Algorithms on Stable Instances",
        "authors": [
            "Hunter Lang",
            "David Sontag",
            "Aravindan Vijayaraghavan"
        ],
        "abstract": "Approximate algorithms for structured prediction problems---such as LP relaxations and the popular alpha-expansion algorithm (Boykov et al. 2001)---typically far exceed their theoretical performance guarantees on real-world instances. These algorithms often find solutions that are very close to optimal. The goal of this paper is to partially explain the performance of alpha-expansion and an LP relaxation algorithm on MAP inference in Ferromagnetic Potts models (FPMs). Our main results give stability conditions under which these two algorithms provably recover the optimal MAP solution. These theoretical results complement numerous empirical observations of good performance.\n    ",
        "submission_date": "2017-11-06T00:00:00",
        "last_modified_date": "2018-04-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.02231",
        "title": "Visually-Aware Fashion Recommendation and Design with Generative Image Models",
        "authors": [
            "Wang-Cheng Kang",
            "Chen Fang",
            "Zhaowen Wang",
            "Julian McAuley"
        ],
        "abstract": "Building effective recommender systems for domains like fashion is challenging due to the high level of subjectivity and the semantic complexity of the features involved (i.e., fashion styles). Recent work has shown that approaches to `visual' recommendation (e.g.~clothing, art, etc.) can be made more accurate by incorporating visual signals directly into the recommendation objective, using `off-the-shelf' feature representations derived from deep networks. Here, we seek to extend this contribution by showing that recommendation performance can be significantly improved by learning `fashion aware' image representations directly, i.e., by training the image representation (from the pixel level) and the recommender system jointly; this contribution is related to recent work using Siamese CNNs, though we are able to show improvements over state-of-the-art recommendation techniques such as BPR and variants that make use of pre-trained visual features. Furthermore, we show that our model can be used \\emph{generatively}, i.e., given a user and a product category, we can generate new images (i.e., clothing items) that are most consistent with their personal taste. This represents a first step towards building systems that go beyond recommending existing items from a product corpus, but which can be used to suggest styles and aid the design of new products.\n    ",
        "submission_date": "2017-11-07T00:00:00",
        "last_modified_date": "2017-11-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.02309",
        "title": "Learning Overcomplete HMMs",
        "authors": [
            "Vatsal Sharan",
            "Sham Kakade",
            "Percy Liang",
            "Gregory Valiant"
        ],
        "abstract": "We study the problem of learning overcomplete HMMs---those that have many hidden states but a small output alphabet. Despite having significant practical importance, such HMMs are poorly understood with no known positive or negative results for efficient learning. In this paper, we present several new results---both positive and negative---which help define the boundaries between the tractable and intractable settings. Specifically, we show positive results for a large subclass of HMMs whose transition matrices are sparse, well-conditioned, and have small probability mass on short cycles. On the other hand, we show that learning is impossible given only a polynomial number of samples for HMMs with a small output alphabet and whose transition matrices are random regular graphs with large degree. We also discuss these results in the context of learning HMMs which can capture long-term dependencies.\n    ",
        "submission_date": "2017-11-07T00:00:00",
        "last_modified_date": "2018-06-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.02515",
        "title": "Continuous DR-submodular Maximization: Structure and Algorithms",
        "authors": [
            "An Bian",
            "Kfir Y. Levy",
            "Andreas Krause",
            "Joachim M. Buhmann"
        ],
        "abstract": "DR-submodular continuous functions are important objectives with wide real-world applications spanning MAP inference in determinantal point processes (DPPs), and mean-field inference for probabilistic submodular models, amongst others. DR-submodularity captures a subclass of non-convex functions that enables both exact minimization and approximate maximization in polynomial time.\n",
        "submission_date": "2017-11-04T00:00:00",
        "last_modified_date": "2019-05-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.02741",
        "title": "Recurrent Autoregressive Networks for Online Multi-Object Tracking",
        "authors": [
            "Kuan Fang",
            "Yu Xiang",
            "Xiaocheng Li",
            "Silvio Savarese"
        ],
        "abstract": "The main challenge of online multi-object tracking is to reliably associate object trajectories with detections in each video frame based on their tracking history. In this work, we propose the Recurrent Autoregressive Network (RAN), a temporal generative modeling framework to characterize the appearance and motion dynamics of multiple objects over time. The RAN couples an external memory and an internal memory. The external memory explicitly stores previous inputs of each trajectory in a time window, while the internal memory learns to summarize long-term tracking history and associate detections by processing the external memory. We conduct experiments on the MOT 2015 and 2016 datasets to demonstrate the robustness of our tracking method in highly crowded and occluded scenes. Our method achieves top-ranked results on the two benchmarks.\n    ",
        "submission_date": "2017-11-07T00:00:00",
        "last_modified_date": "2018-03-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.02782",
        "title": "Block-Sparse Recurrent Neural Networks",
        "authors": [
            "Sharan Narang",
            "Eric Undersander",
            "Gregory Diamos"
        ],
        "abstract": "Recurrent Neural Networks (RNNs) are used in state-of-the-art models in domains such as speech recognition, machine translation, and language modelling. Sparsity is a technique to reduce compute and memory requirements of deep learning models. Sparse RNNs are easier to deploy on devices and high-end server processors. Even though sparse operations need less compute and memory relative to their dense counterparts, the speed-up observed by using sparse operations is less than expected on different hardware platforms. In order to address this issue, we investigate two different approaches to induce block sparsity in RNNs: pruning blocks of weights in a layer and using group lasso regularization to create blocks of weights with zeros. Using these techniques, we demonstrate that we can create block-sparse RNNs with sparsity ranging from 80% to 90% with small loss in accuracy. This allows us to reduce the model size by roughly 10x. Additionally, we can prune a larger dense network to recover this loss in accuracy while maintaining high block sparsity and reducing the overall parameter count. Our technique works with a variety of block sizes up to 32x32. Block-sparse RNNs eliminate overheads related to data storage and irregular memory accesses while increasing hardware efficiency compared to unstructured sparsity.\n    ",
        "submission_date": "2017-11-08T00:00:00",
        "last_modified_date": "2017-11-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.02810",
        "title": "Deep Fault Analysis and Subset Selection in Solar Power Grids",
        "authors": [
            "Biswarup Bhattacharya",
            "Abhishek Sinha"
        ],
        "abstract": "Non-availability of reliable and sustainable electric power is a major problem in the developing world. Renewable energy sources like solar are not very lucrative in the current stage due to various uncertainties like weather, storage, land use among others. There also exists various other issues like mis-commitment of power, absence of intelligent fault analysis, congestion, etc. In this paper, we propose a novel deep learning-based system for predicting faults and selecting power generators optimally so as to reduce costs and ensure higher reliability in solar power systems. The results are highly encouraging and they suggest that the approaches proposed in this paper have the potential to be applied successfully in the developing world.\n    ",
        "submission_date": "2017-11-08T00:00:00",
        "last_modified_date": "2017-11-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.02831",
        "title": "SIMILARnet: Simultaneous Intelligent Localization and Recognition Network",
        "authors": [
            "Arna Ghosh",
            "Biswarup Bhattacharya",
            "Somnath Basu Roy Chowdhury"
        ],
        "abstract": "Global Average Pooling (GAP) [4] has been used previously to generate class activation for image classification tasks. The motivation behind SIMILARnet comes from the fact that the convolutional filters possess position information of the essential features and hence, combination of the feature maps could help us locate the class instances in an image. We propose a biologically inspired model that is free of differential connections and doesn't require separate training thereby reducing computation overhead. Our novel architecture generates promising results and unlike existing methods, the model is not sensitive to the input image size, thus promising wider application. Codes for the experiment and illustrations can be found at: ",
        "submission_date": "2017-11-08T00:00:00",
        "last_modified_date": "2017-11-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.02857",
        "title": "Learning Sparse Visual Representations with Leaky Capped Norm Regularizers",
        "authors": [
            "Jianqiao Wangni",
            "Dahua Lin"
        ],
        "abstract": "Sparsity inducing regularization is an important part for learning over-complete visual representations. Despite the popularity of $\\ell_1$ regularization, in this paper, we investigate the usage of non-convex regularizations in this problem. Our contribution consists of three parts. First, we propose the leaky capped norm regularization (LCNR), which allows model weights below a certain threshold to be regularized more strongly as opposed to those above, therefore imposes strong sparsity and only introduces controllable estimation bias. We propose a majorization-minimization algorithm to optimize the joint objective function. Second, our study over monocular 3D shape recovery and neural networks with LCNR outperforms $\\ell_1$ and other non-convex regularizations, achieving state-of-the-art performance and faster convergence. Third, we prove a theoretical global convergence speed on the 3D recovery problem. To the best of our knowledge, this is the first convergence analysis of the 3D recovery problem.\n    ",
        "submission_date": "2017-11-08T00:00:00",
        "last_modified_date": "2017-11-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.02877",
        "title": "Un r\u00e9sultat intrigant en commande sans mod\u00e8le",
        "authors": [
            "C\u00e9dric Join",
            "Emmanuel Delaleau",
            "Michel Fliess",
            "Claude H. Moog"
        ],
        "abstract": "An elementary mathematical example proves, thanks to the Routh-Hurwitz criterion, a result that is intriguing with respect to today's practical understanding of model-free control, i.e., an \"intelligent\" proportional controller (iP) may turn to be more difficult to tune than an intelligent proportional-derivative one (iPD). The vast superiority of iPDs when compared to classic PIDs is shown via computer simulations. The introduction as well as the conclusion analyse model-free control in the light of recent advances.\n    ",
        "submission_date": "2017-11-08T00:00:00",
        "last_modified_date": "2017-11-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.02974",
        "title": "Clustering with feature selection using alternating minimization, Application to computational biology",
        "authors": [
            "Cyprien Gilet",
            "Marie Deprez",
            "Jean-Baptiste Caillau",
            "Michel Barlaud"
        ],
        "abstract": "This paper deals with unsupervised clustering with feature selection. The problem is to estimate both labels and a sparse projection matrix of weights. To address this combinatorial non-convex problem maintaining a strict control on the sparsity of the matrix of weights, we propose an alternating minimization of the Frobenius norm criterion. We provide a new efficient algorithm named K-sparse which alternates k-means with projection-gradient minimization. The projection-gradient step is a method of splitting type, with exact projection on the $\\ell^1$ ball to promote sparsity. The convergence of the gradient-projection step is addressed, and a preliminary analysis of the alternating minimization is made. The Frobenius norm criterion converges as the number of iterates in Algorithm K-sparse goes to infinity. Experiments on Single Cell RNA sequencing datasets show that our method significantly improves the results of PCA k-means, spectral clustering, SIMLR, and Sparcl methods, and achieves a relevant selection of genes. The complexity of K-sparse is linear in the number of samples (cells), so that the method scales up to large datasets.\n    ",
        "submission_date": "2017-11-08T00:00:00",
        "last_modified_date": "2019-05-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.03026",
        "title": "Intelligent Fault Analysis in Electrical Power Grids",
        "authors": [
            "Biswarup Bhattacharya",
            "Abhishek Sinha"
        ],
        "abstract": "Power grids are one of the most important components of infrastructure in today's world. Every nation is dependent on the security and stability of its own power grid to provide electricity to the households and industries. A malfunction of even a small part of a power grid can cause loss of productivity, revenue and in some cases even life. Thus, it is imperative to design a system which can detect the health of the power grid and take protective measures accordingly even before a serious anomaly takes place. To achieve this objective, we have set out to create an artificially intelligent system which can analyze the grid information at any given time and determine the health of the grid through the usage of sophisticated formal models and novel machine learning techniques like recurrent neural networks. Our system simulates grid conditions including stimuli like faults, generator output fluctuations, load fluctuations using Siemens PSS/E software and this data is trained using various classifiers like SVM, LSTM and subsequently tested. The results are excellent with our methods giving very high accuracy for the data. This model can easily be scaled to handle larger and more complex grid architectures.\n    ",
        "submission_date": "2017-11-08T00:00:00",
        "last_modified_date": "2017-11-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.03067",
        "title": "Learning K-way D-dimensional Discrete Code For Compact Embedding Representations",
        "authors": [
            "Ting Chen",
            "Martin Renqiang Min",
            "Yizhou Sun"
        ],
        "abstract": "Embedding methods such as word embedding have become pillars for many applications containing discrete structures. Conventional embedding methods directly associate each symbol with a continuous embedding vector, which is equivalent to applying linear transformation based on \"one-hot\" encoding of the discrete symbols. Despite its simplicity, such approach yields number of parameters that grows linearly with the vocabulary size and can lead to overfitting. In this work we propose a much more compact K-way D-dimensional discrete encoding scheme to replace the \"one-hot\" encoding. In \"KD encoding\", each symbol is represented by a $D$-dimensional code, and each of its dimension has a cardinality of $K$. The final symbol embedding vector can be generated by composing the code embedding vectors. To learn the semantically meaningful code, we derive a relaxed discrete optimization technique based on stochastic gradient descent. By adopting the new coding system, the efficiency of parameterization can be significantly improved (from linear to logarithmic), and this can also mitigate the over-fitting problem. In our experiments with language modeling, the number of embedding parameters can be reduced by 97\\% while achieving similar or better performance.\n    ",
        "submission_date": "2017-11-08T00:00:00",
        "last_modified_date": "2017-12-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.03198",
        "title": "Information Directed Sampling for Stochastic Bandits with Graph Feedback",
        "authors": [
            "Fang Liu",
            "Swapna Buccapatnam",
            "Ness Shroff"
        ],
        "abstract": "We consider stochastic multi-armed bandit problems with graph feedback, where the decision maker is allowed to observe the neighboring actions of the chosen action. We allow the graph structure to vary with time and consider both deterministic and Erd\u0151s-R\u00e9nyi random graph models. For such a graph feedback model, we first present a novel analysis of Thompson sampling that leads to tighter performance bound than existing work. Next, we propose new Information Directed Sampling based policies that are graph-aware in their decision making. Under the deterministic graph case, we establish a Bayesian regret bound for the proposed policies that scales with the clique cover number of the graph instead of the number of actions. Under the random graph case, we provide a Bayesian regret bound for the proposed policies that scales with the ratio of the number of actions over the expected number of observations per iteration. To the best of our knowledge, this is the first analytical result for stochastic bandits with random graph feedback. Finally, using numerical evaluations, we demonstrate that our proposed IDS policies outperform existing approaches, including adaptions of upper confidence bound, $\\epsilon$-greedy and Exp3 algorithms.\n    ",
        "submission_date": "2017-11-08T00:00:00",
        "last_modified_date": "2017-11-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.03225",
        "title": "Large-scale Cloze Test Dataset Created by Teachers",
        "authors": [
            "Qizhe Xie",
            "Guokun Lai",
            "Zihang Dai",
            "Eduard Hovy"
        ],
        "abstract": "Cloze tests are widely adopted in language exams to evaluate students' language proficiency. In this paper, we propose the first large-scale human-created cloze test dataset CLOTH, containing questions used in middle-school and high-school language exams. With missing blanks carefully created by teachers and candidate choices purposely designed to be nuanced, CLOTH requires a deeper language understanding and a wider attention span than previously automatically-generated cloze datasets. We test the performance of dedicatedly designed baseline models including a language model trained on the One Billion Word Corpus and show humans outperform them by a significant margin. We investigate the source of the performance gap, trace model deficiencies to some distinct properties of CLOTH, and identify the limited ability of comprehending the long-term context to be the key bottleneck.\n    ",
        "submission_date": "2017-11-09T00:00:00",
        "last_modified_date": "2018-08-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.03331",
        "title": "Heuristic Optimization for Automated Distribution System Planning in Network Integration Studies",
        "authors": [
            "Alexander Scheidler",
            "Leon Thurner",
            "Martin Braun"
        ],
        "abstract": "Network integration studies try to assess the impact of future developments, such as the increase of Renewable Energy Sources or the introduction of Smart Grid Technologies, on large-scale network areas. Goals can be to support strategic alignment in the regulatory framework or to adapt the network planning principles of Distribution System Operators. This study outlines an approach for the automated distribution system planning that can calculate network reconfiguration, reinforcement and extension plans in a fully automated fashion. This allows the estimation of the expected cost in massive probabilistic simulations of large numbers of real networks and constitutes a core component of a framework for large-scale network integration studies. Exemplary case study results are presented that were performed in cooperation with different major distribution system operators. The case studies cover the estimation of expected network reinforcement costs, technical and economical assessment of smart grid technologies and structural network optimisation.\n    ",
        "submission_date": "2017-11-09T00:00:00",
        "last_modified_date": "2018-02-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.03467",
        "title": "Worm-level Control through Search-based Reinforcement Learning",
        "authors": [
            "Mathias Lechner",
            "Radu Grosu",
            "Ramin M. Hasani"
        ],
        "abstract": "Through natural evolution, nervous systems of organisms formed near-optimal structures to express behavior. Here, we propose an effective way to create control agents, by \\textit{re-purposing} the function of biological neural circuit models, to govern similar real world applications. We model the tap-withdrawal (TW) neural circuit of the nematode, \\textit{C. elegans}, a circuit responsible for the worm's reflexive response to external mechanical touch stimulations, and learn its synaptic and neural parameters as a policy for controlling the inverted pendulum problem. For reconfiguration of the purpose of the TW neural circuit, we manipulate a search-based reinforcement learning. We show that our neural policy performs as good as existing traditional control theory and machine learning approaches. A video demonstration of the performance of our method can be accessed at \\url{",
        "submission_date": "2017-11-09T00:00:00",
        "last_modified_date": "2017-11-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.03481",
        "title": "Scalable Log Determinants for Gaussian Process Kernel Learning",
        "authors": [
            "Kun Dong",
            "David Eriksson",
            "Hannes Nickisch",
            "David Bindel",
            "Andrew Gordon Wilson"
        ],
        "abstract": "For applications as varied as Bayesian neural networks, determinantal point processes, elliptical graphical models, and kernel learning for Gaussian processes (GPs), one must compute a log determinant of an $n \\times n$ positive definite matrix, and its derivatives - leading to prohibitive $\\mathcal{O}(n^3)$ computations. We propose novel $\\mathcal{O}(n)$ approaches to estimating these quantities from only fast matrix vector multiplications (MVMs). These stochastic approximations are based on Chebyshev, Lanczos, and surrogate models, and converge quickly even for kernel matrices that have challenging spectra. We leverage these approximations to develop a scalable Gaussian process approach to kernel learning. We find that Lanczos is generally superior to Chebyshev for kernel learning, and that a surrogate approach can be highly efficient and accurate with popular kernels.\n    ",
        "submission_date": "2017-11-09T00:00:00",
        "last_modified_date": "2017-11-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.03483",
        "title": "Learning Multi-Modal Word Representation Grounded in Visual Context",
        "authors": [
            "\u00c9loi Zablocki",
            "Benjamin Piwowarski",
            "Laure Soulier",
            "Patrick Gallinari"
        ],
        "abstract": "Representing the semantics of words is a long-standing problem for the natural language processing community. Most methods compute word semantics given their textual context in large corpora. More recently, researchers attempted to integrate perceptual and visual features. Most of these works consider the visual appearance of objects to enhance word representations but they ignore the visual environment and context in which objects appear. We propose to unify text-based techniques with vision-based techniques by simultaneously leveraging textual and visual context to learn multimodal word embeddings. We explore various choices for what can serve as a visual context and present an end-to-end method to integrate visual context elements in a multimodal skip-gram model. We provide experiments and extensive analysis of the obtained results.\n    ",
        "submission_date": "2017-11-09T00:00:00",
        "last_modified_date": "2017-11-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.03512",
        "title": "Fast Meta-Learning for Adaptive Hierarchical Classifier Design",
        "authors": [
            "Gerrit J. J. van den Burg",
            "Alfred O. Hero"
        ],
        "abstract": "We propose a new splitting criterion for a meta-learning approach to multiclass classifier design that adaptively merges the classes into a tree-structured hierarchy of increasingly difficult binary classification problems. The classification tree is constructed from empirical estimates of the Henze-Penrose bounds on the pairwise Bayes misclassification rates that rank the binary subproblems in terms of difficulty of classification. The proposed empirical estimates of the Bayes error rate are computed from the minimal spanning tree (MST) of the samples from each pair of classes. Moreover, a meta-learning technique is presented for quantifying the one-vs-rest Bayes error rate for each individual class from a single MST on the entire dataset. Extensive simulations on benchmark datasets show that the proposed hierarchical method can often be learned much faster than competing methods, while achieving competitive accuracy.\n    ",
        "submission_date": "2017-11-09T00:00:00",
        "last_modified_date": "2017-11-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.03536",
        "title": "Picasso, Matisse, or a Fake? Automated Analysis of Drawings at the Stroke Level for Attribution and Authentication",
        "authors": [
            "Ahmed Elgammal",
            "Yan Kang",
            "Milko Den Leeuw"
        ],
        "abstract": "This paper proposes a computational approach for analysis of strokes in line drawings by artists. We aim at developing an AI methodology that facilitates attribution of drawings of unknown authors in a way that is not easy to be deceived by forged art. The methodology used is based on quantifying the characteristics of individual strokes in drawings. We propose a novel algorithm for segmenting individual strokes. We designed and compared different hand-crafted and learned features for the task of quantifying stroke characteristics. We also propose and compare different classification methods at the drawing level. We experimented with a dataset of 300 digitized drawings with over 80 thousands strokes. The collection mainly consisted of drawings of Pablo Picasso, Henry Matisse, and Egon Schiele, besides a small number of representative works of other artists. The experiments shows that the proposed methodology can classify individual strokes with accuracy 70%-90%, and aggregate over drawings with accuracy above 80%, while being robust to be deceived by fakes (with accuracy 100% for detecting fakes in most settings).\n    ",
        "submission_date": "2017-11-08T00:00:00",
        "last_modified_date": "2017-11-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.03537",
        "title": "Discovery of potential collaboration networks from open knowledge sources",
        "authors": [
            "Nelson Piedra",
            "Janneth Chicaiza",
            "Jorge Lopez-Vargas",
            "Edmundo Tovar"
        ],
        "abstract": "Scientific publishing conveys the outputs of an academic or research activity, in this sense; it also reflects the efforts and issues in which people engage. To identify potential collaborative networks one of the simplest approaches is to leverage the co-authorship relations. In this approach, semantic and hierarchic relationships defined by a Knowledge Organization System are used in order to improve the system's ability to recommend potential networks beyond the lexical or syntactic analysis of the topics or concepts that are of interest to academics.\n    ",
        "submission_date": "2017-11-08T00:00:00",
        "last_modified_date": "2017-11-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.03539",
        "title": "A Change-Detection based Framework for Piecewise-stationary Multi-Armed Bandit Problem",
        "authors": [
            "Fang Liu",
            "Joohyun Lee",
            "Ness Shroff"
        ],
        "abstract": "The multi-armed bandit problem has been extensively studied under the stationary assumption. However in reality, this assumption often does not hold because the distributions of rewards themselves may change over time. In this paper, we propose a change-detection (CD) based framework for multi-armed bandit problems under the piecewise-stationary setting, and study a class of change-detection based UCB (Upper Confidence Bound) policies, CD-UCB, that actively detects change points and restarts the UCB indices. We then develop CUSUM-UCB and PHT-UCB, that belong to the CD-UCB class and use cumulative sum (CUSUM) and Page-Hinkley Test (PHT) to detect changes. We show that CUSUM-UCB obtains the best known regret upper bound under mild assumptions. We also demonstrate the regret reduction of the CD-UCB policies over arbitrary Bernoulli rewards and Yahoo! datasets of webpage click-through rates.\n    ",
        "submission_date": "2017-11-08T00:00:00",
        "last_modified_date": "2017-11-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.03543",
        "title": "DLPaper2Code: Auto-generation of Code from Deep Learning Research Papers",
        "authors": [
            "Akshay Sethi",
            "Anush Sankaran",
            "Naveen Panwar",
            "Shreya Khare",
            "Senthil Mani"
        ],
        "abstract": "With an abundance of research papers in deep learning, reproducibility or adoption of the existing works becomes a challenge. This is due to the lack of open source implementations provided by the authors. Further, re-implementing research papers in a different library is a daunting task. To address these challenges, we propose a novel extensible approach, DLPaper2Code, to extract and understand deep learning design flow diagrams and tables available in a research paper and convert them to an abstract computational graph. The extracted computational graph is then converted into execution ready source code in both Keras and Caffe, in real-time. An arXiv-like website is created where the automatically generated designs is made publicly available for 5,000 research papers. The generated designs could be rated and edited using an intuitive drag-and-drop UI framework in a crowdsourced manner. To evaluate our approach, we create a simulated dataset with over 216,000 valid design visualizations using a manually defined grammar. Experiments on the simulated dataset show that the proposed framework provide more than $93\\%$ accuracy in flow diagram content extraction.\n    ",
        "submission_date": "2017-11-09T00:00:00",
        "last_modified_date": "2017-11-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.03637",
        "title": "Learning and Real-time Classification of Hand-written Digits With Spiking Neural Networks",
        "authors": [
            "Shruti R. Kulkarni",
            "John M. Alexiades",
            "Bipin Rajendran"
        ],
        "abstract": "We describe a novel spiking neural network (SNN) for automated, real-time handwritten digit classification and its implementation on a GP-GPU platform. Information processing within the network, from feature extraction to classification is implemented by mimicking the basic aspects of neuronal spike initiation and propagation in the brain. The feature extraction layer of the SNN uses fixed synaptic weight maps to extract the key features of the image and the classifier layer uses the recently developed NormAD approximate gradient descent based supervised learning algorithm for spiking neural networks to adjust the synaptic weights. On the standard MNIST database images of handwritten digits, our network achieves an accuracy of 99.80% on the training set and 98.06% on the test set, with nearly 7x fewer parameters compared to the state-of-the-art spiking networks. We further use this network in a GPU based user-interface system demonstrating real-time SNN simulation to infer digits written by different users. On a test set of 500 such images, this real-time platform achieves an accuracy exceeding 97% while making a prediction within an SNN emulation time of less than 100ms.\n    ",
        "submission_date": "2017-11-09T00:00:00",
        "last_modified_date": "2017-11-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.03640",
        "title": "Stochastic Deep Learning in Memristive Networks",
        "authors": [
            "Anakha V Babu",
            "Bipin Rajendran"
        ],
        "abstract": "We study the performance of stochastically trained deep neural networks (DNNs) whose synaptic weights are implemented using emerging memristive devices that exhibit limited dynamic range, resolution, and variability in their programming characteristics. We show that a key device parameter to optimize the learning efficiency of DNNs is the variability in its programming characteristics. DNNs with such memristive synapses, even with dynamic range as low as $15$ and only $32$ discrete levels, when trained based on stochastic updates suffer less than $3\\%$ loss in accuracy compared to floating point software baseline. We also study the performance of stochastic memristive DNNs when used as inference engines with noise corrupted data and find that if the device variability can be minimized, the relative degradation in performance for the Stochastic DNN is better than that of the software baseline. Hence, our study presents a new optimization corner for memristive devices for building large noise-immune deep learning systems.\n    ",
        "submission_date": "2017-11-09T00:00:00",
        "last_modified_date": "2017-11-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.03678",
        "title": "Self-Supervised Intrinsic Image Decomposition",
        "authors": [
            "Michael Janner",
            "Jiajun Wu",
            "Tejas D. Kulkarni",
            "Ilker Yildirim",
            "Joshua B. Tenenbaum"
        ],
        "abstract": "Intrinsic decomposition from a single image is a highly challenging task, due to its inherent ambiguity and the scarcity of training data. In contrast to traditional fully supervised learning approaches, in this paper we propose learning intrinsic image decomposition by explaining the input image. Our model, the Rendered Intrinsics Network (RIN), joins together an image decomposition pipeline, which predicts reflectance, shape, and lighting conditions given a single image, with a recombination function, a learned shading model used to recompose the original input based off of intrinsic image predictions. Our network can then use unsupervised reconstruction error as an additional signal to improve its intermediate representations. This allows large-scale unlabeled data to be useful during training, and also enables transferring learned knowledge to images of unseen object categories, lighting conditions, and shapes. Extensive experiments demonstrate that our method performs well on both intrinsic image decomposition and knowledge transfer.\n    ",
        "submission_date": "2017-11-10T00:00:00",
        "last_modified_date": "2018-02-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.03726",
        "title": "Saliency Prediction for Mobile User Interfaces",
        "authors": [
            "Prakhar Gupta",
            "Shubh Gupta",
            "Ajaykrishnan Jayagopal",
            "Sourav Pal",
            "Ritwik Sinha"
        ],
        "abstract": "We introduce models for saliency prediction for mobile user interfaces. A mobile interface may include elements like buttons, text, etc. in addition to natural images which enable performing a variety of tasks. Saliency in natural images is a well studied area. However, given the difference in what constitutes a mobile interface, and the usage context of these devices, we postulate that saliency prediction for mobile interface images requires a fresh approach. Mobile interface design involves operating on elements, the building blocks of the interface. We first collected eye-gaze data from mobile devices for free viewing task. Using this data, we develop a novel autoencoder based multi-scale deep learning model that provides saliency prediction at the mobile interface element level. Compared to saliency prediction approaches developed for natural images, we show that our approach performs significantly better on a range of established metrics.\n    ",
        "submission_date": "2017-11-10T00:00:00",
        "last_modified_date": "2017-11-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.03846",
        "title": "\"Dave...I can assure you...that it's going to be all right...\" -- A definition, case for, and survey of algorithmic assurances in human-autonomy trust relationships",
        "authors": [
            "Brett W Israelsen",
            "Nisar R Ahmed"
        ],
        "abstract": "People who design, use, and are affected by autonomous artificially intelligent agents want to be able to \\emph{trust} such agents -- that is, to know that these agents will perform correctly, to understand the reasoning behind their actions, and to know how to use them appropriately. Many techniques have been devised to assess and influence human trust in artificially intelligent agents. However, these approaches are typically ad hoc, and have not been formally related to each other or to formal trust models. This paper presents a survey of \\emph{algorithmic assurances}, i.e. programmed components of agent operation that are expressly designed to calibrate user trust in artificially intelligent agents. Algorithmic assurances are first formally defined and classified from the perspective of formally modeled human-artificially intelligent agent trust relationships. Building on these definitions, a synthesis of research across communities such as machine learning, human-computer interaction, robotics, e-commerce, and others reveals that assurance algorithms naturally fall along a spectrum in terms of their impact on an agent's core functionality, with seven notable classes ranging from integral assurances (which impact an agent's core functionality) to supplemental assurances (which have no direct effect on agent performance). Common approaches within each of these classes are identified and discussed; benefits and drawbacks of different approaches are also investigated.\n    ",
        "submission_date": "2017-11-08T00:00:00",
        "last_modified_date": "2018-08-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.03938",
        "title": "CARLA: An Open Urban Driving Simulator",
        "authors": [
            "Alexey Dosovitskiy",
            "German Ros",
            "Felipe Codevilla",
            "Antonio Lopez",
            "Vladlen Koltun"
        ],
        "abstract": "We introduce CARLA, an open-source simulator for autonomous driving research. CARLA has been developed from the ground up to support development, training, and validation of autonomous urban driving systems. In addition to open-source code and protocols, CARLA provides open digital assets (urban layouts, buildings, vehicles) that were created for this purpose and can be used freely. The simulation platform supports flexible specification of sensor suites and environmental conditions. We use CARLA to study the performance of three approaches to autonomous driving: a classic modular pipeline, an end-to-end model trained via imitation learning, and an end-to-end model trained via reinforcement learning. The approaches are evaluated in controlled scenarios of increasing difficulty, and their performance is examined via metrics provided by CARLA, illustrating the platform's utility for autonomous driving research. The supplementary video can be viewed at ",
        "submission_date": "2017-11-10T00:00:00",
        "last_modified_date": "2017-11-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.03987",
        "title": "Optimised Maintenance of Datalog Materialisations",
        "authors": [
            "Pan Hu",
            "Boris Motik",
            "Ian Horrocks"
        ],
        "abstract": "To efficiently answer queries, datalog systems often materialise all consequences of a datalog program, so the materialisation must be updated whenever the input facts change. Several solutions to the materialisation update problem have been proposed. The Delete/Rederive (DRed) and the Backward/Forward (B/F) algorithms solve this problem for general datalog, but both contain steps that evaluate rules 'backwards' by matching their heads to a fact and evaluating the partially instantiated rule bodies as queries. We show that this can be a considerable source of overhead even on very small updates. In contrast, the Counting algorithm does not evaluate the rules 'backwards', but it can handle only nonrecursive rules. We present two hybrid approaches that combine DRed and B/F with Counting so as to reduce or even eliminate 'backward' rule evaluation while still handling arbitrary datalog programs. We show empirically that our hybrid algorithms are usually significantly faster than existing approaches, sometimes by orders of magnitude.\n    ",
        "submission_date": "2017-11-10T00:00:00",
        "last_modified_date": "2017-11-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.04022",
        "title": "Deep Within-Class Covariance Analysis for Robust Audio Representation Learning",
        "authors": [
            "Hamid Eghbal-zadeh",
            "Matthias Dorfer",
            "Gerhard Widmer"
        ],
        "abstract": "Convolutional Neural Networks (CNNs) can learn effective features, though have been shown to suffer from a performance drop when the distribution of the data changes from training to test data. In this paper we analyze the internal representations of CNNs and observe that the representations of unseen data in each class, spread more (with higher variance) in the embedding space of the CNN compared to representations of the training data. More importantly, this difference is more extreme if the unseen data comes from a shifted distribution. Based on this observation, we objectively evaluate the degree of representation's variance in each class via eigenvalue decomposition on the within-class covariance of the internal representations of CNNs and observe the same behaviour. This can be problematic as larger variances might lead to mis-classification if the sample crosses the decision boundary of its class. We apply nearest neighbor classification on the representations and empirically show that the embeddings with the high variance actually have significantly worse KNN classification performances, although this could not be foreseen from their end-to-end classification results. To tackle this problem, we propose Deep Within-Class Covariance Analysis (DWCCA), a deep neural network layer that significantly reduces the within-class covariance of a DNN's representation, improving performance on unseen test data from a shifted distribution. We empirically evaluate DWCCA on two datasets for Acoustic Scene Classification (DCASE2016 and DCASE2017). We demonstrate that not only does DWCCA significantly improve the network's internal representation, it also increases the end-to-end classification accuracy, especially when the test set exhibits a distribution shift. By adding DWCCA to a VGG network, we achieve around 6 percentage points improvement in the case of a distribution mismatch.\n    ",
        "submission_date": "2017-11-10T00:00:00",
        "last_modified_date": "2018-11-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.04071",
        "title": "KBGAN: Adversarial Learning for Knowledge Graph Embeddings",
        "authors": [
            "Liwei Cai",
            "William Yang Wang"
        ],
        "abstract": "We introduce KBGAN, an adversarial learning framework to improve the performances of a wide range of existing knowledge graph embedding models. Because knowledge graphs typically only contain positive facts, sampling useful negative training examples is a non-trivial task. Replacing the head or tail entity of a fact with a uniformly randomly selected entity is a conventional method for generating negative facts, but the majority of the generated negative facts can be easily discriminated from positive facts, and will contribute little towards the training. Inspired by generative adversarial networks (GANs), we use one knowledge graph embedding model as a negative sample generator to assist the training of our desired model, which acts as the discriminator in GANs. This framework is independent of the concrete form of generator and discriminator, and therefore can utilize a wide variety of knowledge graph embedding models as its building blocks. In experiments, we adversarially train two translation-based models, TransE and TransD, each with assistance from one of the two probability-based models, DistMult and ComplEx. We evaluate the performances of KBGAN on the link prediction task, using three knowledge base completion datasets: FB15k-237, WN18 and WN18RR. Experimental results show that adversarial training substantially improves the performances of target embedding models under various settings.\n    ",
        "submission_date": "2017-11-11T00:00:00",
        "last_modified_date": "2018-04-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.04078",
        "title": "Parkinson's Disease Digital Biomarker Discovery with Optimized Transitions and Inferred Markov Emissions",
        "authors": [
            "Avinash Bukkittu",
            "Baihan Lin",
            "Trung Vu",
            "Itsik Pe'er"
        ],
        "abstract": "We search for digital biomarkers from Parkinson's Disease by observing approximate repetitive patterns matching hypothesized step and stride periodic cycles. These observations were modeled as a cycle of hidden states with randomness allowing deviation from a canonical pattern of transitions and emissions, under the hypothesis that the averaged features of hidden states would serve to informatively characterize classes of patients/controls. We propose a Hidden Semi-Markov Model (HSMM), a latent-state model, emitting 3D-acceleration vectors. Transitions and emissions are inferred from data. We fit separate models per unique device and training label. Hidden Markov Models (HMM) force geometric distributions of the duration spent at each state before transition to a new state. Instead, our HSMM allows us to specify the distribution of state duration. This modified version is more effective because we are interested more in each state's duration than the sequence of distinct states, allowing inclusion of these durations the feature vector.\n    ",
        "submission_date": "2017-11-11T00:00:00",
        "last_modified_date": "2017-11-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.04079",
        "title": "Fine Grained Knowledge Transfer for Personalized Task-oriented Dialogue Systems",
        "authors": [
            "Kaixiang Mo",
            "Yu Zhang",
            "Qiang Yang",
            "Pascale Fung"
        ],
        "abstract": "Training a personalized dialogue system requires a lot of data, and the data collected for a single user is usually insufficient. One common practice for this problem is to share training dialogues between different users and train multiple sequence-to-sequence dialogue models together with transfer learning. However, current sequence-to-sequence transfer learning models operate on the entire sentence, which might cause negative transfer if different personal information from different users is mixed up. We propose a personalized decoder model to transfer finer granularity phrase-level knowledge between different users while keeping personal preferences of each user intact. A novel personal control gate is introduced, enabling the personalized decoder to switch between generating personalized phrases and shared phrases. The proposed personalized decoder model can be easily combined with various deep models and can be trained with reinforcement learning. Real-world experimental results demonstrate that the phrase-level personalized decoder improves the BLEU over multiple sentence-level transfer baseline models by as much as 7.5%.\n    ",
        "submission_date": "2017-11-11T00:00:00",
        "last_modified_date": "2017-11-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.04090",
        "title": "MojiTalk: Generating Emotional Responses at Scale",
        "authors": [
            "Xianda Zhou",
            "William Yang Wang"
        ],
        "abstract": "Generating emotional language is a key step towards building empathetic natural language processing agents. However, a major challenge for this line of research is the lack of large-scale labeled training data, and previous studies are limited to only small sets of human annotated sentiment labels. Additionally, explicitly controlling the emotion and sentiment of generated text is also difficult. In this paper, we take a more radical approach: we exploit the idea of leveraging Twitter data that are naturally labeled with emojis. More specifically, we collect a large corpus of Twitter conversations that include emojis in the response, and assume the emojis convey the underlying emotions of the sentence. We then introduce a reinforced conditional variational encoder approach to train a deep generative model on these conversations, which allows us to use emojis to control the emotion of the generated text. Experimentally, we show in our quantitative and qualitative analyses that the proposed models can successfully generate high-quality abstractive conversation responses in accordance with designated emotions.\n    ",
        "submission_date": "2017-11-11T00:00:00",
        "last_modified_date": "2018-05-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.04101",
        "title": "Recommender Systems with Random Walks: A Survey",
        "authors": [
            "Laknath Semage"
        ],
        "abstract": "Recommender engines have become an integral component in today's e-commerce systems. From recommending books in Amazon to finding friends in social networks such as Facebook, they have become omnipresent.\n",
        "submission_date": "2017-11-11T00:00:00",
        "last_modified_date": "2017-11-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.04204",
        "title": "Automatic Extraction of Commonsense LocatedNear Knowledge",
        "authors": [
            "Frank F. Xu",
            "Bill Yuchen Lin",
            "Kenny Q. Zhu"
        ],
        "abstract": "LocatedNear relation is a kind of commonsense knowledge describing two physical objects that are typically found near each other in real life. In this paper, we study how to automatically extract such relationship through a sentence-level relation classifier and aggregating the scores of entity pairs from a large corpus. Also, we release two benchmark datasets for evaluation and future research.\n    ",
        "submission_date": "2017-11-11T00:00:00",
        "last_modified_date": "2018-05-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.04258",
        "title": "Unified Spectral Clustering with Optimal Graph",
        "authors": [
            "Zhao Kang",
            "Chong Peng",
            "Qiang Cheng",
            "Zenglin Xu"
        ],
        "abstract": "Spectral clustering has found extensive use in many areas. Most traditional spectral clustering algorithms work in three separate steps: similarity graph construction; continuous labels learning; discretizing the learned labels by k-means clustering. Such common practice has two potential flaws, which may lead to severe information loss and performance degradation. First, predefined similarity graph might not be optimal for subsequent clustering. It is well-accepted that similarity graph highly affects the clustering results. To this end, we propose to automatically learn similarity information from data and simultaneously consider the constraint that the similarity matrix has exact c connected components if there are c clusters. Second, the discrete solution may deviate from the spectral solution since k-means method is well-known as sensitive to the initialization of cluster centers. In this work, we transform the candidate solution into a new one that better approximates the discrete one. Finally, those three subtasks are integrated into a unified framework, with each subtask iteratively boosted by using the results of the others towards an overall optimal solution. It is known that the performance of a kernel method is largely determined by the choice of kernels. To tackle this practical problem of how to select the most suitable kernel for a particular data set, we further extend our model to incorporate multiple kernel learning ability. Extensive experiments demonstrate the superiority of our proposed method as compared to existing clustering approaches.\n    ",
        "submission_date": "2017-11-12T00:00:00",
        "last_modified_date": "2017-11-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.04323",
        "title": "High-Order Attention Models for Visual Question Answering",
        "authors": [
            "Idan Schwartz",
            "Alexander G. Schwing",
            "Tamir Hazan"
        ],
        "abstract": "The quest for algorithms that enable cognitive abilities is an important part of machine learning. A common trait in many recently investigated cognitive-like tasks is that they take into account different data modalities, such as visual and textual input. In this paper we propose a novel and generally applicable form of attention mechanism that learns high-order correlations between various data modalities. We show that high-order correlations effectively direct the appropriate attention to the relevant elements in the different data modalities that are required to solve the joint task. We demonstrate the effectiveness of our high-order attention mechanism on the task of visual question answering (VQA), where we achieve state-of-the-art performance on the standard VQA dataset.\n    ",
        "submission_date": "2017-11-12T00:00:00",
        "last_modified_date": "2017-11-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.04436",
        "title": "SQLNet: Generating Structured Queries From Natural Language Without Reinforcement Learning",
        "authors": [
            "Xiaojun Xu",
            "Chang Liu",
            "Dawn Song"
        ],
        "abstract": "Synthesizing SQL queries from natural language is a long-standing open problem and has been attracting considerable interest recently. Toward solving the problem, the de facto approach is to employ a sequence-to-sequence-style model. Such an approach will necessarily require the SQL queries to be serialized. Since the same SQL query may have multiple equivalent serializations, training a sequence-to-sequence-style model is sensitive to the choice from one of them. This phenomenon is documented as the \"order-matters\" problem. Existing state-of-the-art approaches rely on reinforcement learning to reward the decoder when it generates any of the equivalent serializations. However, we observe that the improvement from reinforcement learning is limited.\n",
        "submission_date": "2017-11-13T00:00:00",
        "last_modified_date": "2017-11-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.04498",
        "title": "Targeted Advertising Based on Browsing History",
        "authors": [
            "Yong Zhang",
            "Hongming Zhou",
            "Nganmeng Tan",
            "Saeed Bagheri",
            "Meng Joo Er"
        ],
        "abstract": "Audience interest, demography, purchase behavior and other possible classifications are ex- tremely important factors to be carefully studied in a targeting campaign. This information can help advertisers and publishers deliver advertisements to the right audience group. How- ever, it is not easy to collect such information, especially for the online audience with whom we have limited interaction and minimum deterministic knowledge. In this paper, we pro- pose a predictive framework that can estimate online audience demographic attributes based on their browsing histories. Under the proposed framework, first, we retrieve the content of the websites visited by audience, and represent the content as website feature vectors; second, we aggregate the vectors of websites that audience have visited and arrive at feature vectors representing the users; finally, the support vector machine is exploited to predict the audience demographic attributes. The key to achieving good prediction performance is preparing representative features of the audience. Word Embedding, a widely used tech- nique in natural language processing tasks, together with term frequency-inverse document frequency weighting scheme is used in the proposed method. This new representation ap- proach is unsupervised and very easy to implement. The experimental results demonstrate that the new audience feature representation method is more powerful than existing baseline methods, leading to a great improvement in prediction accuracy.\n    ",
        "submission_date": "2017-11-13T00:00:00",
        "last_modified_date": "2017-11-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.04518",
        "title": "A Supervised Learning Concept for Reducing User Interaction in Passenger Cars",
        "authors": [
            "Marius St\u00e4rk",
            "Damian Backes",
            "Christian Kehl"
        ],
        "abstract": "In this article an automation system for human-machine-interfaces (HMI) for setpoint adjustment using supervised learning is presented. We use HMIs of multi-modal thermal conditioning systems in passenger cars as example for a complex setpoint selection system. The goal is the reduction of interaction complexity up to full automation. The approach is not limited to climate control applications but can be extended to other setpoint-based HMIs.\n    ",
        "submission_date": "2017-11-13T00:00:00",
        "last_modified_date": "2017-11-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.04528",
        "title": "Simple And Efficient Architecture Search for Convolutional Neural Networks",
        "authors": [
            "Thomas Elsken",
            "Jan-Hendrik Metzen",
            "Frank Hutter"
        ],
        "abstract": "Neural networks have recently had a lot of success for many tasks. However, neural network architectures that perform well are still typically designed manually by experts in a cumbersome trial-and-error process. We propose a new method to automatically search for well-performing CNN architectures based on a simple hill climbing procedure whose operators apply network morphisms, followed by short optimization runs by cosine annealing. Surprisingly, this simple method yields competitive results, despite only requiring resources in the same order of magnitude as training a single network. E.g., on CIFAR-10, our method designs and trains networks with an error rate below 6% in only 12 hours on a single GPU; training for one day reduces this error further, to almost 5%.\n    ",
        "submission_date": "2017-11-13T00:00:00",
        "last_modified_date": "2017-11-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.04556",
        "title": "Solving the Resource Constrained Project Scheduling Problem Using the Parallel Tabu Search Designed for the CUDA Platform",
        "authors": [
            "Libor Bukata",
            "Premysl Sucha",
            "Zdenek Hanzalek"
        ],
        "abstract": "In the paper, a parallel Tabu Search algorithm for the Resource Constrained Project Scheduling Problem is proposed. To deal with this NP-hard combinatorial problem many optimizations have been performed. For example, a resource evaluation algorithm is selected by a heuristic and an effective Tabu List was designed. In addition to that, a capacity-indexed resource evaluation algorithm was proposed and the GPU (Graphics Processing Unit) version uses a homogeneous model to reduce the required communication bandwidth. According to the experiments, the GPU version outperforms the optimized parallel CPU version with respect to the computational time and the quality of solutions. In comparison with other existing heuristics, the proposed solution often gives better quality solutions.\n    ",
        "submission_date": "2017-11-13T00:00:00",
        "last_modified_date": "2017-11-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.04564",
        "title": "Phonemic and Graphemic Multilingual CTC Based Speech Recognition",
        "authors": [
            "Markus M\u00fcller",
            "Sebastian St\u00fcker",
            "Alex Waibel"
        ],
        "abstract": "Training automatic speech recognition (ASR) systems requires large amounts of data in the target language in order to achieve good performance. Whereas large training corpora are readily available for languages like English, there exists a long tail of languages which do suffer from a lack of resources. One method to handle data sparsity is to use data from additional source languages and build a multilingual system. Recently, ASR systems based on recurrent neural networks (RNNs) trained with connectionist temporal classification (CTC) have gained substantial research interest. In this work, we extended our previous approach towards training CTC-based systems multilingually. Our systems feature a global phone set, based on the joint phone sets of each source language. We evaluated the use of different language combinations as well as the addition of Language Feature Vectors (LFVs). As contrastive experiment, we built systems based on graphemes as well. Systems having a multilingual phone set are known to suffer in performance compared to their monolingual counterparts. With our proposed approach, we could reduce the gap between these mono- and multilingual setups, using either graphemes or phonemes.\n    ",
        "submission_date": "2017-11-13T00:00:00",
        "last_modified_date": "2017-11-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.04569",
        "title": "Multilingual Adaptation of RNN Based ASR Systems",
        "authors": [
            "Markus M\u00fcller",
            "Sebastian St\u00fcker",
            "Alex Waibel"
        ],
        "abstract": "In this work, we focus on multilingual systems based on recurrent neural networks (RNNs), trained using the Connectionist Temporal Classification (CTC) loss function. Using a multilingual set of acoustic units poses difficulties. To address this issue, we proposed Language Feature Vectors (LFVs) to train language adaptive multilingual systems. Language adaptation, in contrast to speaker adaptation, needs to be applied not only on the feature level, but also to deeper layers of the network. In this work, we therefore extended our previous approach by introducing a novel technique which we call \"modulation\". Based on this method, we modulated the hidden layers of RNNs using LFVs. We evaluated this approach in both full and low resource conditions, as well as for grapheme and phone based systems. Lower error rates throughout the different conditions could be achieved by the use of the modulation.\n    ",
        "submission_date": "2017-11-13T00:00:00",
        "last_modified_date": "2018-02-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.04623",
        "title": "Three Factors Influencing Minima in SGD",
        "authors": [
            "Stanis\u0142aw Jastrz\u0119bski",
            "Zachary Kenton",
            "Devansh Arpit",
            "Nicolas Ballas",
            "Asja Fischer",
            "Yoshua Bengio",
            "Amos Storkey"
        ],
        "abstract": "We investigate the dynamical and convergent properties of stochastic gradient descent (SGD) applied to Deep Neural Networks (DNNs). Characterizing the relation between learning rate, batch size and the properties of the final minima, such as width or generalization, remains an open question. In order to tackle this problem we investigate the previously proposed approximation of SGD by a stochastic differential equation (SDE). We theoretically argue that three factors - learning rate, batch size and gradient covariance - influence the minima found by SGD. In particular we find that the ratio of learning rate to batch size is a key determinant of SGD dynamics and of the width of the final minima, and that higher values of the ratio lead to wider minima and often better generalization. We confirm these findings experimentally. Further, we include experiments which show that learning rate schedules can be replaced with batch size schedules and that the ratio of learning rate to batch size is an important factor influencing the memorization process.\n    ",
        "submission_date": "2017-11-13T00:00:00",
        "last_modified_date": "2018-09-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.04708",
        "title": "Machine Learning for the Geosciences: Challenges and Opportunities",
        "authors": [
            "Anuj Karpatne",
            "Imme Ebert-Uphoff",
            "Sai Ravela",
            "Hassan Ali Babaie",
            "Vipin Kumar"
        ],
        "abstract": "Geosciences is a field of great societal relevance that requires solutions to several urgent problems facing our humanity and the planet. As geosciences enters the era of big data, machine learning (ML) -- that has been widely successful in commercial domains -- offers immense potential to contribute to problems in geosciences. However, problems in geosciences have several unique challenges that are seldom found in traditional applications, requiring novel problem formulations and methodologies in machine learning. This article introduces researchers in the machine learning (ML) community to these challenges offered by geoscience problems and the opportunities that exist for advancing both machine learning and geosciences. We first highlight typical sources of geoscience data and describe their properties that make it challenging to use traditional machine learning techniques. We then describe some of the common categories of geoscience problems where machine learning can play a role, and discuss some of the existing efforts and promising directions for methodological development in machine learning. We conclude by discussing some of the emerging research themes in machine learning that are applicable across all problems in the geosciences, and the importance of a deep collaboration between machine learning and geosciences for synergistic advancements in both disciplines.\n    ",
        "submission_date": "2017-11-13T00:00:00",
        "last_modified_date": "2017-11-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.04710",
        "title": "Spatio-Temporal Data Mining: A Survey of Problems and Methods",
        "authors": [
            "Gowtham Atluri",
            "Anuj Karpatne",
            "Vipin Kumar"
        ],
        "abstract": "Large volumes of spatio-temporal data are increasingly collected and studied in diverse domains including, climate science, social sciences, neuroscience, epidemiology, transportation, mobile health, and Earth sciences. Spatio-temporal data differs from relational data for which computational approaches are developed in the data mining community for multiple decades, in that both spatial and temporal attributes are available in addition to the actual measurements/attributes. The presence of these attributes introduces additional challenges that needs to be dealt with. Approaches for mining spatio-temporal data have been studied for over a decade in the data mining community. In this article we present a broad survey of this relatively young field of spatio-temporal data mining. We discuss different types of spatio-temporal data and the relevant data mining questions that arise in the context of analyzing each of these datasets. Based on the nature of the data mining problem studied, we classify literature on spatio-temporal data mining into six major categories: clustering, predictive learning, change detection, frequent pattern mining, anomaly detection, and relationship mining. We discuss the various forms of spatio-temporal data mining problems in each of these categories.\n    ",
        "submission_date": "2017-11-13T00:00:00",
        "last_modified_date": "2017-11-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.04883",
        "title": "Accelerating HPC codes on Intel(R) Omni-Path Architecture networks: From particle physics to Machine Learning",
        "authors": [
            "Peter Boyle",
            "Michael Chuvelev",
            "Guido Cossu",
            "Christopher Kelly",
            "Christoph Lehner",
            "Lawrence Meadows"
        ],
        "abstract": "We discuss practical methods to ensure near wirespeed performance from clusters with either one or two Intel(R) Omni-Path host fabric interfaces (HFI) per node, and Intel(R) Xeon Phi(TM) 72xx (Knight's Landing) processors, and using the Linux operating system.\n",
        "submission_date": "2017-11-13T00:00:00",
        "last_modified_date": "2017-11-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.05078",
        "title": "A unified decision making framework for supply and demand management in microgrid networks",
        "authors": [
            "Diddigi Raghuram Bharadwaj",
            "Sai Koti Reddy Danda",
            "Krishnasuri Narayanam",
            "Shalabh Bhatnagar"
        ],
        "abstract": "This paper considers two important problems -- on the supply-side and demand-side respectively and studies both in a unified framework. On the supply side, we study the problem of energy sharing among microgrids with the goal of maximizing profit obtained from selling power while at the same time not deviating much from the customer demand. On the other hand, under shortage of power, this problem becomes one of deciding the amount of power to be bought with dynamically varying prices. On the demand side, we consider the problem of optimally scheduling the time-adjustable demand - i.e., of loads with flexible time windows in which they can be scheduled. While previous works have treated these two problems in isolation, we combine these problems together and provide a unified Markov decision process (MDP) framework for these problems. We then apply the Q-learning algorithm, a popular model-free reinforcement learning technique, to obtain the optimal policy. Through simulations, we show that the policy obtained by solving our MDP model provides more profit to the microgrids.\n    ",
        "submission_date": "2017-11-14T00:00:00",
        "last_modified_date": "2019-07-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.05116",
        "title": "Evidence Aggregation for Answer Re-Ranking in Open-Domain Question Answering",
        "authors": [
            "Shuohang Wang",
            "Mo Yu",
            "Jing Jiang",
            "Wei Zhang",
            "Xiaoxiao Guo",
            "Shiyu Chang",
            "Zhiguo Wang",
            "Tim Klinger",
            "Gerald Tesauro",
            "Murray Campbell"
        ],
        "abstract": "A popular recent approach to answering open-domain questions is to first search for question-related passages and then apply reading comprehension models to extract answers. Existing methods usually extract answers from single passages independently. But some questions require a combination of evidence from across different sources to answer correctly. In this paper, we propose two models which make use of multiple passages to generate their answers. Both use an answer-reranking approach which reorders the answer candidates generated by an existing state-of-the-art QA model. We propose two methods, namely, strength-based re-ranking and coverage-based re-ranking, to make use of the aggregated evidence from different passages to better determine the answer. Our models have achieved state-of-the-art results on three public open-domain QA datasets: Quasar-T, SearchQA and the open-domain version of TriviaQA, with about 8 percentage points of improvement over the former two datasets.\n    ",
        "submission_date": "2017-11-14T00:00:00",
        "last_modified_date": "2018-04-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.05136",
        "title": "Deep Rewiring: Training very sparse deep networks",
        "authors": [
            "Guillaume Bellec",
            "David Kappel",
            "Wolfgang Maass",
            "Robert Legenstein"
        ],
        "abstract": "Neuromorphic hardware tends to pose limits on the connectivity of deep networks that one can run on them. But also generic hardware and software implementations of deep learning run more efficiently for sparse networks. Several methods exist for pruning connections of a neural network after it was trained without connectivity constraints. We present an algorithm, DEEP R, that enables us to train directly a sparsely connected neural network. DEEP R automatically rewires the network during supervised training so that connections are there where they are most needed for the task, while its total number is all the time strictly bounded. We demonstrate that DEEP R can be used to train very sparse feedforward and recurrent neural networks on standard benchmark tasks with just a minor loss in performance. DEEP R is based on a rigorous theoretical foundation that views rewiring as stochastic sampling of network configurations from a posterior.\n    ",
        "submission_date": "2017-11-14T00:00:00",
        "last_modified_date": "2018-08-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.05165",
        "title": "Saliency-based Sequential Image Attention with Multiset Prediction",
        "authors": [
            "Sean Welleck",
            "Jialin Mao",
            "Kyunghyun Cho",
            "Zheng Zhang"
        ],
        "abstract": "Humans process visual scenes selectively and sequentially using attention. Central to models of human visual attention is the saliency map. We propose a hierarchical visual architecture that operates on a saliency map and uses a novel attention mechanism to sequentially focus on salient regions and take additional glimpses within those regions. The architecture is motivated by human visual attention, and is used for multi-label image classification on a novel multiset task, demonstrating that it achieves high precision and recall while localizing objects with its attention. Unlike conventional multi-label image classification models, the model supports multiset prediction due to a reinforcement-learning based training process that allows for arbitrary label permutation and multiple instances per label.\n    ",
        "submission_date": "2017-11-14T00:00:00",
        "last_modified_date": "2017-11-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.05240",
        "title": "Weakly-supervised Semantic Parsing with Abstract Examples",
        "authors": [
            "Omer Goldman",
            "Veronica Latcinnik",
            "Udi Naveh",
            "Amir Globerson",
            "Jonathan Berant"
        ],
        "abstract": "Training semantic parsers from weak supervision (denotations) rather than strong supervision (programs) complicates training in two ways. First, a large search space of potential programs needs to be explored at training time to find a correct program. Second, spurious programs that accidentally lead to a correct denotation add noise to training. In this work we propose that in closed worlds with clear semantic types, one can substantially alleviate these problems by utilizing an abstract representation, where tokens in both the language utterance and program are lifted to an abstract form. We show that these abstractions can be defined with a handful of lexical rules and that they result in sharing between different examples that alleviates the difficulties in training. To test our approach, we develop the first semantic parser for CNLVR, a challenging visual reasoning dataset, where the search space is large and overcoming spuriousness is critical, because denotations are either TRUE or FALSE, and thus random programs are likely to lead to a correct denotation. Our method substantially improves performance, and reaches 82.5% accuracy, a 14.7% absolute accuracy improvement compared to the best reported accuracy so far.\n    ",
        "submission_date": "2017-11-14T00:00:00",
        "last_modified_date": "2019-03-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.05246",
        "title": "Loss Functions for Multiset Prediction",
        "authors": [
            "Sean Welleck",
            "Zixin Yao",
            "Yu Gai",
            "Jialin Mao",
            "Zheng Zhang",
            "Kyunghyun Cho"
        ],
        "abstract": "We study the problem of multiset prediction. The goal of multiset prediction is to train a predictor that maps an input to a multiset consisting of multiple items. Unlike existing problems in supervised learning, such as classification, ranking and sequence generation, there is no known order among items in a target multiset, and each item in the multiset may appear more than once, making this problem extremely challenging. In this paper, we propose a novel multiset loss function by viewing this problem from the perspective of sequential decision making. The proposed multiset loss function is empirically evaluated on two families of datasets, one synthetic and the other real, with varying levels of difficulty, against various baseline loss functions including reinforcement learning, sequence, and aggregated distribution matching loss functions. The experiments reveal the effectiveness of the proposed loss function over the others.\n    ",
        "submission_date": "2017-11-14T00:00:00",
        "last_modified_date": "2018-10-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.05255",
        "title": "Deep-ESN: A Multiple Projection-encoding Hierarchical Reservoir Computing Framework",
        "authors": [
            "Qianli Ma",
            "Lifeng Shen",
            "Garrison W. Cottrell"
        ],
        "abstract": "As an efficient recurrent neural network (RNN) model, reservoir computing (RC) models, such as Echo State Networks, have attracted widespread attention in the last decade. However, while they have had great success with time series data [1], [2], many time series have a multiscale structure, which a single-hidden-layer RC model may have difficulty capturing. In this paper, we propose a novel hierarchical reservoir computing framework we call Deep Echo State Networks (Deep-ESNs). The most distinctive feature of a Deep-ESN is its ability to deal with time series through hierarchical projections. Specifically, when an input time series is projected into the high-dimensional echo-state space of a reservoir, a subsequent encoding layer (e.g., a PCA, autoencoder, or a random projection) can project the echo-state representations into a lower-dimensional space. These low-dimensional representations can then be processed by another ESN. By using projection layers and encoding layers alternately in the hierarchical framework, a Deep-ESN can not only attenuate the effects of the collinearity problem in ESNs, but also fully take advantage of the temporal kernel property of ESNs to explore multiscale dynamics of time series. To fuse the multiscale representations obtained by each reservoir, we add connections from each encoding layer to the last output layer. Theoretical analyses prove that stability of a Deep-ESN is guaranteed by the echo state property (ESP), and the time complexity is equivalent to a conventional ESN. Experimental results on some artificial and real world time series demonstrate that Deep-ESNs can capture multiscale dynamics, and outperform both standard ESNs and previous hierarchical ESN-based models.\n    ",
        "submission_date": "2017-11-13T00:00:00",
        "last_modified_date": "2017-11-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.05412",
        "title": "IKBT: solving closed-form Inverse Kinematics with Behavior Tree",
        "authors": [
            "Dianmu Zhang",
            "Blake Hannaford"
        ],
        "abstract": "Serial robot arms have complicated kinematic equations which must be solved to write effective arm planning and control software (the Inverse Kinematics Problem). Existing software packages for inverse kinematics often rely on numerical methods which have significant shortcomings. Here we report a new symbolic inverse kinematics solver which overcomes the limitations of numerical methods, and the shortcomings of previous symbolic software packages. We integrate Behavior Trees, an execution planning framework previously used for controlling intelligent robot behavior, to organize the equation solving process, and a modular architecture for each solution technique. The system successfully solved, generated a LaTex report, and generated a Python code template for 18 out of 19 example robots of 4-6 DOF. The system is readily extensible, maintainable, and multi-platform with few dependencies. The complete package is available with a Modified BSD license on Github.\n    ",
        "submission_date": "2017-11-15T00:00:00",
        "last_modified_date": "2017-12-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.05457",
        "title": "Hibikino-Musashi@Home 2017 Team Description Paper",
        "authors": [
            "Sansei Hori",
            "Yutaro Ishida",
            "Yuta Kiyama",
            "Yuichiro Tanaka",
            "Yuki Kuroda",
            "Masataka Hisano",
            "Yuto Imamura",
            "Tomotaka Himaki",
            "Yuma Yoshimoto",
            "Yoshiya Aratani",
            "Kouhei Hashimoto",
            "Gouki Iwamoto",
            "Hiroto Fujita",
            "Takashi Morie",
            "Hakaru Tamukoh"
        ],
        "abstract": "Our team Hibikino-Musashi@Home was founded in 2010. It is based in Kitakyushu Science and Research Park, Japan. Since 2010, we have participated in the RoboCup@Home Japan open competition open-platform league every year. Currently, the Hibikino-Musashi@Home team has 24 members from seven different laboratories based in the Kyushu Institute of Technology. Our home-service robots are used as platforms for both education and implementation of our research outcomes. In this paper, we introduce our team and the technologies that we have implemented in our robots.\n    ",
        "submission_date": "2017-11-15T00:00:00",
        "last_modified_date": "2017-11-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.05557",
        "title": "Phrase-based Image Captioning with Hierarchical LSTM Model",
        "authors": [
            "Ying Hua Tan",
            "Chee Seng Chan"
        ],
        "abstract": "Automatic generation of caption to describe the content of an image has been gaining a lot of research interests recently, where most of the existing works treat the image caption as pure sequential data. Natural language, however possess a temporal hierarchy structure, with complex dependencies between each subsequence. In this paper, we propose a phrase-based hierarchical Long Short-Term Memory (phi-LSTM) model to generate image description. In contrast to the conventional solutions that generate caption in a pure sequential manner, our proposed model decodes image caption from phrase to sentence. It consists of a phrase decoder at the bottom hierarchy to decode noun phrases of variable length, and an abbreviated sentence decoder at the upper hierarchy to decode an abbreviated form of the image description. A complete image caption is formed by combining the generated phrases with sentence during the inference stage. Empirically, our proposed model shows a better or competitive result on the Flickr8k, Flickr30k and MS-COCO datasets in comparison to the state-of-the art models. We also show that our proposed model is able to generate more novel captions (not seen in the training data) which are richer in word contents in all these three datasets.\n    ",
        "submission_date": "2017-11-11T00:00:00",
        "last_modified_date": "2017-11-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.05626",
        "title": "Deep Temporal-Recurrent-Replicated-Softmax for Topical Trends over Time",
        "authors": [
            "Pankaj Gupta",
            "Subburam Rajaram",
            "Hinrich Sch\u00fctze",
            "Bernt Andrassy"
        ],
        "abstract": "Dynamic topic modeling facilitates the identification of topical trends over time in temporal collections of unstructured documents. We introduce a novel unsupervised neural dynamic topic model named as Recurrent Neural Network-Replicated Softmax Model (RNNRSM), where the discovered topics at each time influence the topic discovery in the subsequent time steps. We account for the temporal ordering of documents by explicitly modeling a joint distribution of latent topical dependencies over time, using distributional estimators with temporal recurrent connections. Applying RNN-RSM to 19 years of articles on NLP research, we demonstrate that compared to state-of-the art topic models, RNNRSM shows better generalization, topic interpretation, evolution and trends. We also introduce a metric (named as SPAN) to quantify the capability of dynamic topic model to capture word evolution in topics over time.\n    ",
        "submission_date": "2017-11-15T00:00:00",
        "last_modified_date": "2018-05-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.05627",
        "title": "Exploiting Layerwise Convexity of Rectifier Networks with Sign Constrained Weights",
        "authors": [
            "Senjian An",
            "Farid Boussaid",
            "Mohammed Bennamoun",
            "Ferdous Sohel"
        ],
        "abstract": "By introducing sign constraints on the weights, this paper proposes sign constrained rectifier networks (SCRNs), whose training can be solved efficiently by the well known majorization-minimization (MM) algorithms. We prove that the proposed two-hidden-layer SCRNs, which exhibit negative weights in the second hidden layer and negative weights in the output layer, are capable of separating any two (or more) disjoint pattern sets. Furthermore, the proposed two-hidden-layer SCRNs can decompose the patterns of each class into several clusters so that each cluster is convexly separable from all the patterns from the other classes. This provides a means to learn the pattern structures and analyse the discriminant factors between different classes of patterns.\n    ",
        "submission_date": "2017-11-14T00:00:00",
        "last_modified_date": "2017-11-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.05726",
        "title": "Markov Decision Processes with Continuous Side Information",
        "authors": [
            "Aditya Modi",
            "Nan Jiang",
            "Satinder Singh",
            "Ambuj Tewari"
        ],
        "abstract": "We consider a reinforcement learning (RL) setting in which the agent interacts with a sequence of episodic MDPs. At the start of each episode the agent has access to some side-information or context that determines the dynamics of the MDP for that episode. Our setting is motivated by applications in healthcare where baseline measurements of a patient at the start of a treatment episode form the context that may provide information about how the patient might respond to treatment decisions. We propose algorithms for learning in such Contextual Markov Decision Processes (CMDPs) under an assumption that the unobserved MDP parameters vary smoothly with the observed context. We also give lower and upper PAC bounds under the smoothness assumption. Because our lower bound has an exponential dependence on the dimension, we consider a tractable linear setting where the context is used to create linear combinations of a finite set of MDPs. For the linear setting, we give a PAC learning algorithm based on KWIK learning techniques.\n    ",
        "submission_date": "2017-11-15T00:00:00",
        "last_modified_date": "2017-11-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.05766",
        "title": "Fast Predictive Simple Geodesic Regression",
        "authors": [
            "Zhipeng Ding",
            "Greg Fleishman",
            "Xiao Yang",
            "Paul Thompson",
            "Roland Kwitt",
            "Marc Niethammer"
        ],
        "abstract": "Deformable image registration and regression are important tasks in medical image analysis. However, they are computationally expensive, especially when analyzing large-scale datasets that contain thousands of images. Hence, cluster computing is typically used, making the approaches dependent on such computational infrastructure. Even larger computational resources are required as study sizes increase. This limits the use of deformable image registration and regression for clinical applications and as component algorithms for other image analysis approaches. We therefore propose using a fast predictive approach to perform image registrations. In particular, we employ these fast registration predictions to approximate a simplified geodesic regression model to capture longitudinal brain changes. The resulting method is orders of magnitude faster than the standard optimization-based regression model and hence facilitates large-scale analysis on a single graphics processing unit (GPU). We evaluate our results on 3D brain magnetic resonance images (MRI) from the ADNI datasets.\n    ",
        "submission_date": "2017-11-15T00:00:00",
        "last_modified_date": "2017-11-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.05825",
        "title": "Bootstrapped synthetic likelihood",
        "authors": [
            "Richard G. Everitt"
        ],
        "abstract": "Approximate Bayesian computation (ABC) and synthetic likelihood (SL) techniques have enabled the use of Bayesian inference for models that may be simulated, but for which the likelihood cannot be evaluated pointwise at values of an unknown parameter $\\theta$. The main idea in ABC and SL is to, for different values of $\\theta$ (usually chosen using a Monte Carlo algorithm), build estimates of the likelihood based on simulations from the model conditional on $\\theta$. The quality of these estimates determines the efficiency of an ABC/SL algorithm. In standard ABC/SL, the only means to improve an estimated likelihood at $\\theta$ is to simulate more times from the model conditional on $\\theta$, which is infeasible in cases where the simulator is computationally expensive. In this paper we describe how to use bootstrapping as a means for improving SL estimates whilst using fewer simulations from the model, and also investigate its use in ABC. Further, we investigate the use of the bag of little bootstraps as a means for applying this approach to large datasets, yielding Monte Carlo algorithms that accurately approximate posterior distributions whilst only simulating subsamples of the full data. Examples of the approach applied to i.i.d., temporal and spatial data are given.\n    ",
        "submission_date": "2017-11-15T00:00:00",
        "last_modified_date": "2018-01-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.05851",
        "title": "Go for a Walk and Arrive at the Answer: Reasoning Over Paths in Knowledge Bases using Reinforcement Learning",
        "authors": [
            "Rajarshi Das",
            "Shehzaad Dhuliawala",
            "Manzil Zaheer",
            "Luke Vilnis",
            "Ishan Durugkar",
            "Akshay Krishnamurthy",
            "Alex Smola",
            "Andrew McCallum"
        ],
        "abstract": "Knowledge bases (KB), both automatically and manually constructed, are often incomplete --- many valid facts can be inferred from the KB by synthesizing existing information. A popular approach to KB completion is to infer new relations by combinatory reasoning over the information found along other paths connecting a pair of entities. Given the enormous size of KBs and the exponential number of paths, previous path-based models have considered only the problem of predicting a missing relation given two entities or evaluating the truth of a proposed triple. Additionally, these methods have traditionally used random paths between fixed entity pairs or more recently learned to pick paths between them. We propose a new algorithm MINERVA, which addresses the much more difficult and practical task of answering questions where the relation is known, but only one entity. Since random walks are impractical in a setting with combinatorially many destinations from a start node, we present a neural reinforcement learning approach which learns how to navigate the graph conditioned on the input query to find predictive paths. Empirically, this approach obtains state-of-the-art results on several datasets, significantly outperforming prior methods.\n    ",
        "submission_date": "2017-11-15T00:00:00",
        "last_modified_date": "2018-12-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.05858",
        "title": "End-to-end 3D shape inverse rendering of different classes of objects from a single input image",
        "authors": [
            "Shima Kamyab",
            "S. Zohreh Azimifar"
        ],
        "abstract": "In this paper a semi-supervised deep framework is proposed for the problem of 3D shape inverse rendering from a single 2D input image. The main structure of proposed framework consists of unsupervised pre-trained components which significantly reduce the need to labeled data for training the whole framework. using labeled data has the advantage of achieving to accurate results without the need to predefined assumptions about image formation process. Three main components are used in the proposed network: an encoder which maps 2D input image to a representation space, a 3D decoder which decodes a representation to a 3D structure and a mapping component in order to map 2D to 3D representation. The only part that needs label for training is the mapping part with not too many parameters. The other components in the network can be pre-trained unsupervised using only 2D images or 3D data in each case. The way of reconstructing 3D shapes in the decoder component, inspired by the model based methods for 3D reconstruction, maps a low dimensional representation to 3D shape space with the advantage of extracting the basis vectors of shape space from training data itself and is not restricted to a small set of examples as used in predefined models. Therefore, the proposed framework deals directly with coordinate values of the point cloud representation which leads to achieve dense 3D shapes in the output. The experimental results on several benchmark datasets of objects and human faces and comparing with recent similar methods shows the power of proposed network in recovering more details from single 2D images.\n    ",
        "submission_date": "2017-11-11T00:00:00",
        "last_modified_date": "2017-11-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.05928",
        "title": "Budget-Constrained Multi-Armed Bandits with Multiple Plays",
        "authors": [
            "Datong P. Zhou",
            "Claire J. Tomlin"
        ],
        "abstract": "We study the multi-armed bandit problem with multiple plays and a budget constraint for both the stochastic and the adversarial setting. At each round, exactly $K$ out of $N$ possible arms have to be played (with $1\\leq K \\leq N$). In addition to observing the individual rewards for each arm played, the player also learns a vector of costs which has to be covered with an a-priori defined budget $B$. The game ends when the sum of current costs associated with the played arms exceeds the remaining budget.\n",
        "submission_date": "2017-11-16T00:00:00",
        "last_modified_date": "2017-11-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.06004",
        "title": "Remedies against the Vocabulary Gap in Information Retrieval",
        "authors": [
            "Christophe Van Gysel"
        ],
        "abstract": "Search engines rely heavily on term-based approaches that represent queries and documents as bags of words. Text---a document or a query---is represented by a bag of its words that ignores grammar and word order, but retains word frequency counts. When presented with a search query, the engine then ranks documents according to their relevance scores by computing, among other things, the matching degrees between query and document terms. While term-based approaches are intuitive and effective in practice, they are based on the hypothesis that documents that exactly contain the query terms are highly relevant regardless of query semantics. Inversely, term-based approaches assume documents that do not contain query terms as irrelevant. However, it is known that a high matching degree at the term level does not necessarily mean high relevance and, vice versa, documents that match null query terms may still be relevant. Consequently, there exists a vocabulary gap between queries and documents that occurs when both use different words to describe the same concepts. It is the alleviation of the effect brought forward by this vocabulary gap that is the topic of this dissertation. More specifically, we propose (1) methods to formulate an effective query from complex textual structures and (2) latent vector space models that circumvent the vocabulary gap in information retrieval.\n    ",
        "submission_date": "2017-11-16T00:00:00",
        "last_modified_date": "2017-11-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.06006",
        "title": "Hindsight policy gradients",
        "authors": [
            "Paulo Rauber",
            "Avinash Ummadisingu",
            "Filipe Mutz",
            "Juergen Schmidhuber"
        ],
        "abstract": "A reinforcement learning agent that needs to pursue different goals across episodes requires a goal-conditional policy. In addition to their potential to generalize desirable behavior to unseen goals, such policies may also enable higher-level planning based on subgoals. In sparse-reward environments, the capacity to exploit information about the degree to which an arbitrary goal has been achieved while another goal was intended appears crucial to enable sample efficient learning. However, reinforcement learning agents have only recently been endowed with such capacity for hindsight. In this paper, we demonstrate how hindsight can be introduced to policy gradient methods, generalizing this idea to a broad class of successful algorithms. Our experiments on a diverse selection of sparse-reward environments show that hindsight leads to a remarkable increase in sample efficiency.\n    ",
        "submission_date": "2017-11-16T00:00:00",
        "last_modified_date": "2019-02-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.06030",
        "title": "Sub-committee Approval Voting and Generalised Justified Representation Axioms",
        "authors": [
            "Haris Aziz",
            "Barton E. Lee"
        ],
        "abstract": "Social choice is replete with various settings including single-winner voting, multi-winner voting, probabilistic voting, multiple referenda, and public decision making. We study a general model of social choice called Sub-Committee Voting (SCV) that simultaneously generalizes these settings. We then focus on sub-committee voting with approvals and propose extensions of the justified representation axioms that have been considered for proportional representation in approval-based committee voting. We study the properties and relations of these axioms. For each of the axioms, we analyse whether a representative committee exists and also examine the complexity of computing and verifying such a committee.\n    ",
        "submission_date": "2017-11-16T00:00:00",
        "last_modified_date": "2017-11-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.06299",
        "title": "Bayesian Best-Arm Identification for Selecting Influenza Mitigation Strategies",
        "authors": [
            "Pieter Libin",
            "Timothy Verstraeten",
            "Diederik M. Roijers",
            "Jelena Grujic",
            "Kristof Theys",
            "Philippe Lemey",
            "Ann Now\u00e9"
        ],
        "abstract": "Pandemic influenza has the epidemic potential to kill millions of people. While various preventive measures exist (i.a., vaccination and school closures), deciding on strategies that lead to their most effective and efficient use remains challenging. To this end, individual-based epidemiological models are essential to assist decision makers in determining the best strategy to curb epidemic spread. However, individual-based models are computationally intensive and it is therefore pivotal to identify the optimal strategy using a minimal amount of model evaluations. Additionally, as epidemiological modeling experiments need to be planned, a computational budget needs to be specified a priori. Consequently, we present a new sampling technique to optimize the evaluation of preventive strategies using fixed budget best-arm identification algorithms. We use epidemiological modeling theory to derive knowledge about the reward distribution which we exploit using Bayesian best-arm identification algorithms (i.e., Top-two Thompson sampling and BayesGap). We evaluate these algorithms in a realistic experimental setting and demonstrate that it is possible to identify the optimal strategy using only a limited number of model evaluations, i.e., 2-to-3 times faster compared to the uniform sampling method, the predominant technique used for epidemiological decision making in the literature. Finally, we contribute and evaluate a statistic for Top-two Thompson sampling to inform the decision makers about the confidence of an arm recommendation.\n    ",
        "submission_date": "2017-11-16T00:00:00",
        "last_modified_date": "2018-06-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.06317",
        "title": "GA-PSO-Optimized Neural-Based Control Scheme for Adaptive Congestion Control to Improve Performance in Multimedia Applications",
        "authors": [
            "Mansour Sheikhan",
            "Ehsan Hemmati",
            "Reza Shahnazi"
        ],
        "abstract": "Active queue control aims to improve the overall communication network throughput while providing lower delay and small packet loss rate. The basic idea is to actively trigger packet dropping (or marking provided by explicit congestion notification (ECN)) before buffer overflow. In this paper, two artificial neural networks (ANN)-based control schemes are proposed for adaptive queue control in TCP communication networks. The structure of these controllers is optimized using genetic algorithm (GA) and the output weights of ANNs are optimized using particle swarm optimization (PSO) algorithm. The controllers are radial bias function (RBF)-based, but to improve the robustness of RBF controller, an error-integral term is added to RBF equation in the second scheme. Experimental results show that GA- PSO-optimized improved RBF (I-RBF) model controls network congestion effectively in terms of link utilization with a low packet loss rate and outperform Drop Tail, proportional-integral (PI), random exponential marking (REM), and adaptive random early detection (ARED) controllers.\n    ",
        "submission_date": "2017-11-16T00:00:00",
        "last_modified_date": "2017-11-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.06347",
        "title": "Conditional Markov Chain Search for the Simple Plant Location Problem improves upper bounds on twelve K\u00f6rkel-Ghosh instances",
        "authors": [
            "Daniel Karapetyan",
            "Boris Goldengorin"
        ],
        "abstract": "We address a family of hard benchmark instances for the Simple Plant Location Problem (also known as the Uncapacitated Facility Location Problem). The recent attempt by Fischetti et al. to tackle the K\u00f6rkel-Ghosh instances resulted in seven new optimal solutions and 22 improved upper bounds. We use automated generation of heuristics to obtain a new algorithm for the Simple Plant Location Problem. In our experiments, our new algorithm matched all the previous best known and optimal solutions, and further improved 12 upper bounds, all within shorter time budgets compared to the previous efforts.\n",
        "submission_date": "2017-11-16T00:00:00",
        "last_modified_date": "2017-11-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.06350",
        "title": "Towards Deep Learning Models for Psychological State Prediction using Smartphone Data: Challenges and Opportunities",
        "authors": [
            "Gatis Mikelsons",
            "Matthew Smith",
            "Abhinav Mehrotra",
            "Mirco Musolesi"
        ],
        "abstract": "There is an increasing interest in exploiting mobile sensing technologies and machine learning techniques for mental health monitoring and intervention. Researchers have effectively used contextual information, such as mobility, communication and mobile phone usage patterns for quantifying individuals' mood and wellbeing. In this paper, we investigate the effectiveness of neural network models for predicting users' level of stress by using the location information collected by smartphones. We characterize the mobility patterns of individuals using the GPS metrics presented in the literature and employ these metrics as input to the network. We evaluate our approach on the open-source StudentLife dataset. Moreover, we discuss the challenges and trade-offs involved in building machine learning models for digital mental health and highlight potential future work in this direction.\n    ",
        "submission_date": "2017-11-16T00:00:00",
        "last_modified_date": "2017-11-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.06351",
        "title": "Question Asking as Program Generation",
        "authors": [
            "Anselm Rothe",
            "Brenden M. Lake",
            "Todd M. Gureckis"
        ],
        "abstract": "A hallmark of human intelligence is the ability to ask rich, creative, and revealing questions. Here we introduce a cognitive model capable of constructing human-like questions. Our approach treats questions as formal programs that, when executed on the state of the world, output an answer. The model specifies a probability distribution over a complex, compositional space of programs, favoring concise programs that help the agent learn in the current context. We evaluate our approach by modeling the types of open-ended questions generated by humans who were attempting to learn about an ambiguous situation in a game. We find that our model predicts what questions people will ask, and can creatively produce novel questions that were not present in the training set. In addition, we compare a number of model variants, finding that both question informativeness and complexity are important for producing human-like questions.\n    ",
        "submission_date": "2017-11-16T00:00:00",
        "last_modified_date": "2017-11-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.06363",
        "title": "3D Reconstruction of Incomplete Archaeological Objects Using a Generative Adversarial Network",
        "authors": [
            "Renato Hermoza",
            "Ivan Sipiran"
        ],
        "abstract": "We introduce a data-driven approach to aid the repairing and conservation of archaeological objects: ORGAN, an object reconstruction generative adversarial network (GAN). By using an encoder-decoder 3D deep neural network on a GAN architecture, and combining two loss objectives: a completion loss and an Improved Wasserstein GAN loss, we can train a network to effectively predict the missing geometry of damaged objects. As archaeological objects can greatly differ between them, the network is conditioned on a variable, which can be a culture, a region or any metadata of the object. In our results, we show that our method can recover most of the information from damaged objects, even in cases where more than half of the voxels are missing, without producing many errors.\n    ",
        "submission_date": "2017-11-17T00:00:00",
        "last_modified_date": "2018-03-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.06550",
        "title": "Reconstruction of the External Stimuli from Brain Signals",
        "authors": [
            "Pouya Ghaemmaghami"
        ],
        "abstract": "Despite the rapid advances in Brain-computer Interfacing (BCI) and continuous effort to improve the accuracy of brain decoding systems, the urge for the systems to reconstruct the experiences of the users has been widely acknowledged. This urge has been investigated by some researchers during the past years in terms of reconstruction of the naturalistic images, abstract images, video and audio. In this study, we try to tackle this issue by regressing the stimuli spectrogram using the spectrogram analysis of the brain signals. The results of our regression-based method suggest the feasibility of such reconstructions using the neuroimaging techniques that are appropriate for out-of-lab scenarios.\n    ",
        "submission_date": "2017-11-14T00:00:00",
        "last_modified_date": "2017-11-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.06562",
        "title": "An Iterative Closest Points Approach to Neural Generative Models",
        "authors": [
            "Joose Rajam\u00e4ki",
            "Perttu H\u00e4m\u00e4l\u00e4inen"
        ],
        "abstract": "We present a simple way to learn a transformation that maps samples of one distribution to the samples of another distribution. Our algorithm comprises an iteration of 1) drawing samples from some simple distribution and transforming them using a neural network, 2) determining pairwise correspondences between the transformed samples and training data (or a minibatch), and 3) optimizing the weights of the neural network being trained to minimize the distances between the corresponding vectors. This can be considered as a variant of the Iterative Closest Points (ICP) algorithm, common in geometric computer vision, although ICP typically operates on sensor point clouds and linear transforms instead of random sample sets and neural nonlinear transforms. We demonstrate the algorithm on simple synthetic data and MNIST data. We furthermore demonstrate that the algorithm is capable of handling distributions with both continuous and discrete variables.\n    ",
        "submission_date": "2017-11-16T00:00:00",
        "last_modified_date": "2018-07-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.06623",
        "title": "Driven to Distraction: Self-Supervised Distractor Learning for Robust Monocular Visual Odometry in Urban Environments",
        "authors": [
            "Dan Barnes",
            "Will Maddern",
            "Geoffrey Pascoe",
            "Ingmar Posner"
        ],
        "abstract": "We present a self-supervised approach to ignoring \"distractors\" in camera images for the purposes of robustly estimating vehicle motion in cluttered urban environments. We leverage offline multi-session mapping approaches to automatically generate a per-pixel ephemerality mask and depth map for each input image, which we use to train a deep convolutional network. At run-time we use the predicted ephemerality and depth as an input to a monocular visual odometry (VO) pipeline, using either sparse features or dense photometric matching. Our approach yields metric-scale VO using only a single camera and can recover the correct egomotion even when 90% of the image is obscured by dynamic, independently moving objects. We evaluate our robust VO methods on more than 400km of driving from the Oxford RobotCar Dataset and demonstrate reduced odometry drift and significantly improved egomotion estimation in the presence of large moving vehicles in urban traffic.\n    ",
        "submission_date": "2017-11-17T00:00:00",
        "last_modified_date": "2018-03-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.06744",
        "title": "Learning to Organize Knowledge and Answer Questions with N-Gram Machines",
        "authors": [
            "Fan Yang",
            "Jiazhong Nie",
            "William W. Cohen",
            "Ni Lao"
        ],
        "abstract": "Though deep neural networks have great success in natural language processing, they are limited at more knowledge intensive AI tasks, such as open-domain Question Answering (QA). Existing end-to-end deep QA models need to process the entire text after observing the question, and therefore their complexity in responding a question is linear in the text size. This is prohibitive for practical tasks such as QA from Wikipedia, a novel, or the Web. We propose to solve this scalability issue by using symbolic meaning representations, which can be indexed and retrieved efficiently with complexity that is independent of the text size. We apply our approach, called the N-Gram Machine (NGM), to three representative tasks. First as proof-of-concept, we demonstrate that NGM successfully solves the bAbI tasks of synthetic text. Second, we show that NGM scales to large corpus by experimenting on \"life-long bAbI\", a special version of bAbI that contains millions of sentences. Lastly on the WikiMovies dataset, we use NGM to induce latent structure (i.e. schema) and answer questions from natural language Wikipedia text, with only QA pairs as weak supervision.\n    ",
        "submission_date": "2017-11-17T00:00:00",
        "last_modified_date": "2019-03-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.06761",
        "title": "Scalable Recollections for Continual Lifelong Learning",
        "authors": [
            "Matthew Riemer",
            "Tim Klinger",
            "Djallel Bouneffouf",
            "Michele Franceschini"
        ],
        "abstract": "Given the recent success of Deep Learning applied to a variety of single tasks, it is natural to consider more human-realistic settings. Perhaps the most difficult of these settings is that of continual lifelong learning, where the model must learn online over a continuous stream of non-stationary data. A successful continual lifelong learning system must have three key capabilities: it must learn and adapt over time, it must not forget what it has learned, and it must be efficient in both training time and memory. Recent techniques have focused their efforts primarily on the first two capabilities while questions of efficiency remain largely unexplored. In this paper, we consider the problem of efficient and effective storage of experiences over very large time-frames. In particular we consider the case where typical experiences are O(n) bits and memories are limited to O(k) bits for k << n. We present a novel scalable architecture and training algorithm in this challenging domain and provide an extensive evaluation of its performance. Our results show that we can achieve considerable gains on top of state-of-the-art methods such as GEM.\n    ",
        "submission_date": "2017-11-17T00:00:00",
        "last_modified_date": "2018-12-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.06794",
        "title": "Co-attending Free-form Regions and Detections with Multi-modal Multiplicative Feature Embedding for Visual Question Answering",
        "authors": [
            "Pan Lu",
            "Hongsheng Li",
            "Wei Zhang",
            "Jianyong Wang",
            "Xiaogang Wang"
        ],
        "abstract": "Recently, the Visual Question Answering (VQA) task has gained increasing attention in artificial intelligence. Existing VQA methods mainly adopt the visual attention mechanism to associate the input question with corresponding image regions for effective question answering. The free-form region based and the detection-based visual attention mechanisms are mostly investigated, with the former ones attending free-form image regions and the latter ones attending pre-specified detection-box regions. We argue that the two attention mechanisms are able to provide complementary information and should be effectively integrated to better solve the VQA problem. In this paper, we propose a novel deep neural network for VQA that integrates both attention mechanisms. Our proposed framework effectively fuses features from free-form image regions, detection boxes, and question representations via a multi-modal multiplicative feature embedding scheme to jointly attend question-related free-form image regions and detection boxes for more accurate question answering. The proposed method is extensively evaluated on two publicly available datasets, COCO-QA and VQA, and outperforms state-of-the-art approaches. Source code is available at ",
        "submission_date": "2017-11-18T00:00:00",
        "last_modified_date": "2017-12-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.06871",
        "title": "Anonymous Hedonic Game for Task Allocation in a Large-Scale Multiple Agent System",
        "authors": [
            "Inmo Jang",
            "Hyo-Sang Shin",
            "Antonios Tsourdos"
        ],
        "abstract": "This paper proposes a novel game-theoretical autonomous decision-making framework to address a task allocation problem for a swarm of multiple agents. We consider cooperation of self-interested agents, and show that our proposed decentralized algorithm guarantees convergence of agents with social inhibition to a Nash stable partition (i.e., social agreement) within polynomial time. The algorithm is simple and executable based on local interactions with neighbor agents under a strongly-connected communication network and even in asynchronous environments. We analytically present a mathematical formulation for computing the lower bound of suboptimality of the solution, and additionally show that 50% of suboptimality can be at least guaranteed if social utilities are non-decreasing functions with respect to the number of co-working agents. The results of numerical experiments confirm that the proposed framework is scalable, fast adaptable against dynamical environments, and robust even in a realistic situation.\n    ",
        "submission_date": "2017-11-18T00:00:00",
        "last_modified_date": "2018-07-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.07131",
        "title": "CleanNet: Transfer Learning for Scalable Image Classifier Training with Label Noise",
        "authors": [
            "Kuang-Huei Lee",
            "Xiaodong He",
            "Lei Zhang",
            "Linjun Yang"
        ],
        "abstract": "In this paper, we study the problem of learning image classification models with label noise. Existing approaches depending on human supervision are generally not scalable as manually identifying correct or incorrect labels is time-consuming, whereas approaches not relying on human supervision are scalable but less effective. To reduce the amount of human supervision for label noise cleaning, we introduce CleanNet, a joint neural embedding network, which only requires a fraction of the classes being manually verified to provide the knowledge of label noise that can be transferred to other classes. We further integrate CleanNet and conventional convolutional neural network classifier into one framework for image classification learning. We demonstrate the effectiveness of the proposed algorithm on both of the label noise detection task and the image classification on noisy data task on several large-scale datasets. Experimental results show that CleanNet can reduce label noise detection error rate on held-out classes where no human supervision available by 41.5% compared to current weakly supervised methods. It also achieves 47% of the performance gain of verifying all images with only 3.2% images verified on an image classification task. Source code and dataset will be available at ",
        "submission_date": "2017-11-20T00:00:00",
        "last_modified_date": "2018-03-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.07154",
        "title": "Interactive, Intelligent Tutoring for Auxiliary Constructions in Geometry Proofs",
        "authors": [
            "Ke Wang",
            "Zhendong Su"
        ],
        "abstract": "Geometry theorem proving forms a major and challenging component in the K-12 mathematics curriculum. A particular difficult task is to add auxiliary constructions (i.e, additional lines or points) to aid proof discovery. Although there exist many intelligent tutoring systems proposed for geometry proofs, few teach students how to find auxiliary constructions. And the few exceptions are all limited by their underlying reasoning processes for supporting auxiliary constructions. This paper tackles these weaknesses of prior systems by introducing an interactive geometry tutor, the Advanced Geometry Proof Tutor (AGPT). It leverages a recent automated geometry prover to provide combined benefits that any geometry theorem prover or intelligent tutoring system alone cannot accomplish. In particular, AGPT not only can automatically process images of geometry problems directly, but also can interactively train and guide students toward discovering auxiliary constructions on their own. We have evaluated AGPT via a pilot study with 78 high school students. The study results show that, on training students how to find auxiliary constructions, there is no significant perceived difference between AGPT and human tutors, and AGPT is significantly more effective than the state-of-the-art geometry solver that produces human-readable proofs.\n    ",
        "submission_date": "2017-11-20T00:00:00",
        "last_modified_date": "2017-11-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.07170",
        "title": "Parameter Reference Loss for Unsupervised Domain Adaptation",
        "authors": [
            "Jiren Jin",
            "Richard G. Calland",
            "Takeru Miyato",
            "Brian K. Vogel",
            "Hideki Nakayama"
        ],
        "abstract": "The success of deep learning in computer vision is mainly attributed to an abundance of data. However, collecting large-scale data is not always possible, especially for the supervised labels. Unsupervised domain adaptation (UDA) aims to utilize labeled data from a source domain to learn a model that generalizes to a target domain of unlabeled data. A large amount of existing work uses Siamese network-based models, where two streams of neural networks process the source and the target domain data respectively. Nevertheless, most of these approaches focus on minimizing the domain discrepancy, overlooking the importance of preserving the discriminative ability for target domain features. Another important problem in UDA research is how to evaluate the methods properly. Common evaluation procedures require target domain labels for hyper-parameter tuning and model selection, contradicting the definition of the UDA task. Hence we propose a more reasonable evaluation principle that avoids this contradiction by simply adopting the latest snapshot of a model for evaluation. This adds an extra requirement for UDA methods besides the main performance criteria: the stability during training. We design a novel method that connects the target domain stream to the source domain stream with a Parameter Reference Loss (PRL) to solve these problems simultaneously. Experiments on various datasets show that the proposed PRL not only improves the performance on the target domain, but also stabilizes the training procedure. As a result, PRL based models do not need the contradictory model selection, and thus are more suitable for practical applications.\n    ",
        "submission_date": "2017-11-20T00:00:00",
        "last_modified_date": "2017-12-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.07214",
        "title": "Maximizing Submodular or Monotone Approximately Submodular Functions by Multi-objective Evolutionary Algorithms",
        "authors": [
            "Chao Qian",
            "Yang Yu",
            "Ke Tang",
            "Xin Yao",
            "Zhi-Hua Zhou"
        ],
        "abstract": "Evolutionary algorithms (EAs) are a kind of nature-inspired general-purpose optimization algorithm, and have shown empirically good performance in solving various real-word optimization problems. During the past two decades, promising results on the running time analysis (one essential theoretical aspect) of EAs have been obtained, while most of them focused on isolated combinatorial optimization problems, which do not reflect the general-purpose nature of EAs. To provide a general theoretical explanation of the behavior of EAs, it is desirable to study their performance on general classes of combinatorial optimization problems. To the best of our knowledge, the only result towards this direction is the provably good approximation guarantees of EAs for the problem class of maximizing monotone submodular functions with matroid constraints. The aim of this work is to contribute to this line of research. Considering that many combinatorial optimization problems involve non-monotone or non-submodular objective functions, we study the general problem classes, maximizing submodular functions with/without a size constraint and maximizing monotone approximately submodular functions with a size constraint. We prove that a simple multi-objective EA called GSEMO-C can generally achieve good approximation guarantees in polynomial expected running time.\n    ",
        "submission_date": "2017-11-20T00:00:00",
        "last_modified_date": "2022-11-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.07280",
        "title": "Vision-and-Language Navigation: Interpreting visually-grounded navigation instructions in real environments",
        "authors": [
            "Peter Anderson",
            "Qi Wu",
            "Damien Teney",
            "Jake Bruce",
            "Mark Johnson",
            "Niko S\u00fcnderhauf",
            "Ian Reid",
            "Stephen Gould",
            "Anton van den Hengel"
        ],
        "abstract": "A robot that can carry out a natural-language instruction has been a dream since before the Jetsons cartoon series imagined a life of leisure mediated by a fleet of attentive robot helpers. It is a dream that remains stubbornly distant. However, recent advances in vision and language methods have made incredible progress in closely related areas. This is significant because a robot interpreting a natural-language navigation instruction on the basis of what it sees is carrying out a vision and language process that is similar to Visual Question Answering. Both tasks can be interpreted as visually grounded sequence-to-sequence translation problems, and many of the same methods are applicable. To enable and encourage the application of vision and language methods to the problem of interpreting visually-grounded navigation instructions, we present the Matterport3D Simulator -- a large-scale reinforcement learning environment based on real imagery. Using this simulator, which can in future support a range of embodied vision and language tasks, we provide the first benchmark dataset for visually-grounded natural language navigation in real buildings -- the Room-to-Room (R2R) dataset.\n    ",
        "submission_date": "2017-11-20T00:00:00",
        "last_modified_date": "2018-04-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.07329",
        "title": "Bayesian Active Edge Evaluation on Expensive Graphs",
        "authors": [
            "Sanjiban Choudhury",
            "Siddhartha Srinivasa",
            "Sebastian Scherer"
        ],
        "abstract": "Robots operate in environments with varying implicit structure. For instance, a helicopter flying over terrain encounters a very different arrangement of obstacles than a robotic arm manipulating objects on a cluttered table top. State-of-the-art motion planning systems do not exploit this structure, thereby expending valuable planning effort searching for implausible solutions. We are interested in planning algorithms that actively infer the underlying structure of the valid configuration space during planning in order to find solutions with minimal effort. Consider the problem of evaluating edges on a graph to quickly discover collision-free paths. Evaluating edges is expensive, both for robots with complex geometries like robot arms, and for robots with limited onboard computation like UAVs. Until now, this challenge has been addressed via laziness i.e. deferring edge evaluation until absolutely necessary, with the hope that edges turn out to be valid. However, all edges are not alike in value - some have a lot of potentially good paths flowing through them, and some others encode the likelihood of neighbouring edges being valid. This leads to our key insight - instead of passive laziness, we can actively choose edges that reduce the uncertainty about the validity of paths. We show that this is equivalent to the Bayesian active learning paradigm of decision region determination (DRD). However, the DRD problem is not only combinatorially hard, but also requires explicit enumeration of all possible worlds. We propose a novel framework that combines two DRD algorithms, DIRECT and BISECT, to overcome both issues. We show that our approach outperforms several state-of-the-art algorithms on a spectrum of planning problems for mobile robots, manipulators and autonomous helicopters.\n    ",
        "submission_date": "2017-11-20T00:00:00",
        "last_modified_date": "2017-11-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.07341",
        "title": "FusionNet: Fusing via Fully-Aware Attention with Application to Machine Comprehension",
        "authors": [
            "Hsin-Yuan Huang",
            "Chenguang Zhu",
            "Yelong Shen",
            "Weizhu Chen"
        ],
        "abstract": "This paper introduces a new neural structure called FusionNet, which extends existing attention approaches from three perspectives. First, it puts forward a novel concept of \"history of word\" to characterize attention information from the lowest word-level embedding up to the highest semantic-level representation. Second, it introduces an improved attention scoring function that better utilizes the \"history of word\" concept. Third, it proposes a fully-aware multi-level attention mechanism to capture the complete information in one text (such as a question) and exploit it in its counterpart (such as context or passage) layer by layer. We apply FusionNet to the Stanford Question Answering Dataset (SQuAD) and it achieves the first position for both single and ensemble model on the official SQuAD leaderboard at the time of writing (Oct. 4th, 2017). Meanwhile, we verify the generalization of FusionNet with two adversarial SQuAD datasets and it sets up the new state-of-the-art on both datasets: on AddSent, FusionNet increases the best F1 metric from 46.6% to 51.4%; on AddOneSent, FusionNet boosts the best F1 metric from 56.0% to 60.7%.\n    ",
        "submission_date": "2017-11-16T00:00:00",
        "last_modified_date": "2018-02-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.07387",
        "title": "How morphological development can guide evolution",
        "authors": [
            "Sam Kriegman",
            "Nick Cheney",
            "Josh Bongard"
        ],
        "abstract": "Organisms result from adaptive processes interacting across different time scales. One such interaction is that between development and evolution. Models have shown that development sweeps over several traits in a single agent, sometimes exposing promising static traits. Subsequent evolution can then canalize these rare traits. Thus, development can, under the right conditions, increase evolvability. Here, we report on a previously unknown phenomenon when embodied agents are allowed to develop and evolve: Evolution discovers body plans robust to control changes, these body plans become genetically assimilated, yet controllers for these agents are not assimilated. This allows evolution to continue climbing fitness gradients by tinkering with the developmental programs for controllers within these permissive body plans. This exposes a previously unknown detail about the Baldwin effect: instead of all useful traits becoming genetically assimilated, only traits that render the agent robust to changes in other traits become assimilated. We refer to this as differential canalization. This finding also has implications for the evolutionary design of artificial and embodied agents such as robots: robots robust to internal changes in their controllers may also be robust to external changes in their environment, such as transferal from simulation to reality or deployment in novel environments.\n    ",
        "submission_date": "2017-11-20T00:00:00",
        "last_modified_date": "2018-09-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.07425",
        "title": "Modular Continual Learning in a Unified Visual Environment",
        "authors": [
            "Kevin T. Feigelis",
            "Blue Sheffer",
            "Daniel L. K. Yamins"
        ],
        "abstract": "A core aspect of human intelligence is the ability to learn new tasks quickly and switch between them flexibly. Here, we describe a modular continual reinforcement learning paradigm inspired by these abilities. We first introduce a visual interaction environment that allows many types of tasks to be unified in a single framework. We then describe a reward map prediction scheme that learns new tasks robustly in the very large state and action spaces required by such an environment. We investigate how properties of module architecture influence efficiency of task learning, showing that a module motif incorporating specific design principles (e.g. early bottlenecks, low-order polynomial nonlinearities, and symmetry) significantly outperforms more standard neural network motifs, needing fewer training examples and fewer neurons to achieve high levels of performance. Finally, we present a meta-controller architecture for task switching based on a dynamic neural voting scheme, which allows new modules to use information learned from previously-seen tasks to substantially improve their own learning efficiency.\n    ",
        "submission_date": "2017-11-20T00:00:00",
        "last_modified_date": "2017-12-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.07446",
        "title": "A generalised framework for detailed classification of swimming paths inside the Morris Water Maze",
        "authors": [
            "Avgoustinos Vouros",
            "Tiago V. Gehring",
            "Kinga Szydlowska",
            "Artur Janusz",
            "Mike Croucher",
            "Katarzyna Lukasiuk",
            "Witold Konopka",
            "Carmen Sandi",
            "Zehai Tu",
            "Eleni Vasilaki"
        ],
        "abstract": "The Morris Water Maze is commonly used in behavioural neuroscience for the study of spatial learning with rodents. Over the years, various methods of analysing rodent data collected in this task have been proposed. These methods span from classical performance measurements (e.g. escape latency, rodent speed, quadrant preference) to more sophisticated methods of categorisation which classify the animal swimming path into behavioural classes known as strategies. Classification techniques provide additional insight in relation to the actual animal behaviours but still only a limited amount of studies utilise them mainly because they highly depend on machine learning knowledge. We have previously demonstrated that the animals implement various strategies and by classifying whole trajectories can lead to the loss of important information. In this work, we developed a generalised and robust classification methodology which implements majority voting to boost the classification performance and successfully nullify the need of manual tuning. Based on this framework, we built a complete software, capable of performing the full analysis described in this paper. The software provides an easy to use graphical user interface (GUI) through which users can enter their trajectory data, segment and label them and finally generate reports and figures of the results.\n    ",
        "submission_date": "2017-11-20T00:00:00",
        "last_modified_date": "2017-12-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.07459",
        "title": "SquishedNets: Squishing SqueezeNet further for edge device scenarios via deep evolutionary synthesis",
        "authors": [
            "Mohammad Javad Shafiee",
            "Francis Li",
            "Brendan Chwyl",
            "Alexander Wong"
        ],
        "abstract": "While deep neural networks have been shown in recent years to outperform other machine learning methods in a wide range of applications, one of the biggest challenges with enabling deep neural networks for widespread deployment on edge devices such as mobile and other consumer devices is high computational and memory requirements. Recently, there has been greater exploration into small deep neural network architectures that are more suitable for edge devices, with one of the most popular architectures being SqueezeNet, with an incredibly small model size of 4.8MB. Taking further advantage of the notion that many applications of machine learning on edge devices are often characterized by a low number of target classes, this study explores the utility of combining architectural modifications and an evolutionary synthesis strategy for synthesizing even smaller deep neural architectures based on the more recent SqueezeNet v1.1 macroarchitecture for applications with fewer target classes. In particular, architectural modifications are first made to SqueezeNet v1.1 to accommodate for a 10-class ImageNet-10 dataset, and then an evolutionary synthesis strategy is leveraged to synthesize more efficient deep neural networks based on this modified macroarchitecture. The resulting SquishedNets possess model sizes ranging from 2.4MB to 0.95MB (~5.17X smaller than SqueezeNet v1.1, or 253X smaller than AlexNet). Furthermore, the SquishedNets are still able to achieve accuracies ranging from 81.2% to 77%, and able to process at speeds of 156 images/sec to as much as 256 images/sec on a Nvidia Jetson TX1 embedded chip. These preliminary results show that a combination of architectural modifications and an evolutionary synthesis strategy can be a useful tool for producing very small deep neural network architectures that are well-suited for edge device scenarios.\n    ",
        "submission_date": "2017-11-20T00:00:00",
        "last_modified_date": "2017-11-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.07477",
        "title": "MaMaDroid: Detecting Android Malware by Building Markov Chains of Behavioral Models (Extended Version)",
        "authors": [
            "Lucky Onwuzurike",
            "Enrico Mariconti",
            "Panagiotis Andriotis",
            "Emiliano De Cristofaro",
            "Gordon Ross",
            "Gianluca Stringhini"
        ],
        "abstract": "As Android has become increasingly popular, so has malware targeting it, thus pushing the research community to propose different detection techniques. However, the constant evolution of the Android ecosystem, and of malware itself, makes it hard to design robust tools that can operate for long periods of time without the need for modifications or costly re-training. Aiming to address this issue, we set to detect malware from a behavioral point of view, modeled as the sequence of abstracted API calls. We introduce MaMaDroid, a static-analysis based system that abstracts the API calls performed by an app to their class, package, or family, and builds a model from their sequences obtained from the call graph of an app as Markov chains. This ensures that the model is more resilient to API changes and the features set is of manageable size. We evaluate MaMaDroid using a dataset of 8.5K benign and 35.5K malicious apps collected over a period of six years, showing that it effectively detects malware (with up to 0.99 F-measure) and keeps its detection capabilities for long periods of time (up to 0.87 F-measure two years after training). We also show that MaMaDroid remarkably outperforms DroidAPIMiner, a state-of-the-art detection system that relies on the frequency of (raw) API calls. Aiming to assess whether MaMaDroid's effectiveness mainly stems from the API abstraction or from the sequencing modeling, we also evaluate a variant of it that uses frequency (instead of sequences), of abstracted API calls. We find that it is not as accurate, failing to capture maliciousness when trained on malware samples that include API calls that are equally or more frequently used by benign apps.\n    ",
        "submission_date": "2017-11-20T00:00:00",
        "last_modified_date": "2019-03-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.07478",
        "title": "Implementing the Deep Q-Network",
        "authors": [
            "Melrose Roderick",
            "James MacGlashan",
            "Stefanie Tellex"
        ],
        "abstract": "The Deep Q-Network proposed by Mnih et al. [2015] has become a benchmark and building point for much deep reinforcement learning research. However, replicating results for complex systems is often challenging since original scientific publications are not always able to describe in detail every important parameter setting and software engineering solution. In this paper, we present results from our work reproducing the results of the DQN paper. We highlight key areas in the implementation that were not covered in great detail in the original paper to make it easier for researchers to replicate these results, including termination conditions and gradient descent algorithms. Finally, we discuss methods for improving the computational performance and provide our own implementation that is designed to work with a range of domains, and not just the original Arcade Learning Environment [Bellemare et al., 2013].\n    ",
        "submission_date": "2017-11-20T00:00:00",
        "last_modified_date": "2017-11-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.07479",
        "title": "Teaching a Machine to Read Maps with Deep Reinforcement Learning",
        "authors": [
            "Gino Brunner",
            "Oliver Richter",
            "Yuyi Wang",
            "Roger Wattenhofer"
        ],
        "abstract": "The ability to use a 2D map to navigate a complex 3D environment is quite remarkable, and even difficult for many humans. Localization and navigation is also an important problem in domains such as robotics, and has recently become a focus of the deep reinforcement learning community. In this paper we teach a reinforcement learning agent to read a map in order to find the shortest way out of a random maze it has never seen before. Our system combines several state-of-the-art methods such as A3C and incorporates novel elements such as a recurrent localization cell. Our agent learns to localize itself based on 3D first person images and an approximate orientation angle. The agent generalizes well to bigger mazes, showing that it learned useful localization and navigation capabilities.\n    ",
        "submission_date": "2017-11-20T00:00:00",
        "last_modified_date": "2017-11-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.07600",
        "title": "On the Distortion of Voting with Multiple Representative Candidates",
        "authors": [
            "Yu Cheng",
            "Shaddin Dughmi",
            "David Kempe"
        ],
        "abstract": "We study positional voting rules when candidates and voters are embedded in a common metric space, and cardinal preferences are naturally given by distances in the metric space. In a positional voting rule, each candidate receives a score from each ballot based on the ballot's rank order; the candidate with the highest total score wins the election. The cost of a candidate is his sum of distances to all voters, and the distortion of an election is the ratio between the cost of the elected candidate and the cost of the optimum candidate. We consider the case when candidates are representative of the population, in the sense that they are drawn i.i.d. from the population of the voters, and analyze the expected distortion of positional voting rules.\n",
        "submission_date": "2017-11-21T00:00:00",
        "last_modified_date": "2017-11-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.07613",
        "title": "Are You Talking to Me? Reasoned Visual Dialog Generation through Adversarial Learning",
        "authors": [
            "Qi Wu",
            "Peng Wang",
            "Chunhua Shen",
            "Ian Reid",
            "Anton van den Hengel"
        ],
        "abstract": "The Visual Dialogue task requires an agent to engage in a conversation about an image with a human. It represents an extension of the Visual Question Answering task in that the agent needs to answer a question about an image, but it needs to do so in light of the previous dialogue that has taken place. The key challenge in Visual Dialogue is thus maintaining a consistent, and natural dialogue while continuing to answer questions correctly. We present a novel approach that combines Reinforcement Learning and Generative Adversarial Networks (GANs) to generate more human-like responses to questions. The GAN helps overcome the relative paucity of training data, and the tendency of the typical MLE-based approach to generate overly terse answers. Critically, the GAN is tightly integrated into the attention mechanism that generates human-interpretable reasons for each answer. This means that the discriminative model of the GAN has the task of assessing whether a candidate answer is generated by a human or not, given the provided reason. This is significant because it drives the generative model to produce high quality answers that are well supported by the associated reasoning. The method also generates the state-of-the-art results on the primary benchmark.\n    ",
        "submission_date": "2017-11-21T00:00:00",
        "last_modified_date": "2017-11-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.07614",
        "title": "Asking the Difficult Questions: Goal-Oriented Visual Question Generation via Intermediate Rewards",
        "authors": [
            "Junjie Zhang",
            "Qi Wu",
            "Chunhua Shen",
            "Jian Zhang",
            "Jianfeng Lu",
            "Anton van den Hengel"
        ],
        "abstract": "Despite significant progress in a variety of vision-and-language problems, developing a method capable of asking intelligent, goal-oriented questions about images is proven to be an inscrutable challenge. Towards this end, we propose a Deep Reinforcement Learning framework based on three new intermediate rewards, namely goal-achieved, progressive and informativeness that encourage the generation of succinct questions, which in turn uncover valuable information towards the overall goal. By directly optimizing for questions that work quickly towards fulfilling the overall goal, we avoid the tendency of existing methods to generate long series of insane queries that add little value. We evaluate our model on the GuessWhat?! dataset and show that the resulting questions can help a standard Guesser identify a specific object in an image at a much higher success rate.\n    ",
        "submission_date": "2017-11-21T00:00:00",
        "last_modified_date": "2017-11-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.07621",
        "title": "Groupwise Maximin Fair Allocation of Indivisible Goods",
        "authors": [
            "Siddharth Barman",
            "Arpita Biswas",
            "Sanath Kumar Krishnamurthy",
            "Y. Narahari"
        ],
        "abstract": "We study the problem of allocating indivisible goods among n agents in a fair manner. For this problem, maximin share (MMS) is a well-studied solution concept which provides a fairness threshold. Specifically, maximin share is defined as the minimum utility that an agent can guarantee for herself when asked to partition the set of goods into n bundles such that the remaining (n-1) agents pick their bundles adversarially. An allocation is deemed to be fair if every agent gets a bundle whose valuation is at least her maximin share.\n",
        "submission_date": "2017-11-21T00:00:00",
        "last_modified_date": "2017-11-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.07632",
        "title": "Generating Thematic Chinese Poetry using Conditional Variational Autoencoders with Hybrid Decoders",
        "authors": [
            "Xiaopeng Yang",
            "Xiaowen Lin",
            "Shunda Suo",
            "Ming Li"
        ],
        "abstract": "Computer poetry generation is our first step towards computer writing. Writing must have a theme. The current approaches of using sequence-to-sequence models with attention often produce non-thematic poems. We present a novel conditional variational autoencoder with a hybrid decoder adding the deconvolutional neural networks to the general recurrent neural networks to fully learn topic information via latent variables. This approach significantly improves the relevance of the generated poems by representing each line of the poem not only in a context-sensitive manner but also in a holistic way that is highly related to the given keyword and the learned topic. A proposed augmented word2vec model further improves the rhythm and symmetry. Tests show that the generated poems by our approach are mostly satisfying with regulated rules and consistent themes, and 73.42% of them receive an Overall score no less than 3 (the highest score is 5).\n    ",
        "submission_date": "2017-11-21T00:00:00",
        "last_modified_date": "2020-03-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.07656",
        "title": "Cross Temporal Recurrent Networks for Ranking Question Answer Pairs",
        "authors": [
            "Yi Tay",
            "Luu Anh Tuan",
            "Siu Cheung Hui"
        ],
        "abstract": "Temporal gates play a significant role in modern recurrent-based neural encoders, enabling fine-grained control over recursive compositional operations over time. In recurrent models such as the long short-term memory (LSTM), temporal gates control the amount of information retained or discarded over time, not only playing an important role in influencing the learned representations but also serving as a protection against vanishing gradients. This paper explores the idea of learning temporal gates for sequence pairs (question and answer), jointly influencing the learned representations in a pairwise manner. In our approach, temporal gates are learned via 1D convolutional layers and then subsequently cross applied across question and answer for joint learning. Empirically, we show that this conceptually simple sharing of temporal gates can lead to competitive performance across multiple benchmarks. Intuitively, what our network achieves can be interpreted as learning representations of question and answer pairs that are aware of what each other is remembering or forgetting, i.e., pairwise temporal gating. Via extensive experiments, we show that our proposed model achieves state-of-the-art performance on two community-based QA datasets and competitive performance on one factoid-based QA dataset.\n    ",
        "submission_date": "2017-11-21T00:00:00",
        "last_modified_date": "2017-11-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.07661",
        "title": "Fullie and Wiselie: A Dual-Stream Recurrent Convolutional Attention Model for Activity Recognition",
        "authors": [
            "Kaixuan Chen",
            "Lina Yao",
            "Tao Gu",
            "Zhiwen Yu",
            "Xianzhi Wang",
            "Dalin Zhang"
        ],
        "abstract": "Multimodal features play a key role in wearable sensor based Human Activity Recognition (HAR). Selecting the most salient features adaptively is a promising way to maximize the effectiveness of multimodal sensor data. In this regard, we propose a \"collect fully and select wisely (Fullie and Wiselie)\" principle as well as a dual-stream recurrent convolutional attention model, Recurrent Attention and Activity Frame (RAAF), to improve the recognition performance. We first collect modality features and the relations between each pair of features to generate activity frames, and then introduce an attention mechanism to select the most prominent regions from activity frames precisely. The selected frames not only maximize the utilization of valid features but also reduce the number of features to be computed effectively. We further analyze the hyper-parameters, accuracy, interpretability, and annotation dependency of the proposed model based on extensive experiments. The results show that RAAF achieves competitive performance on two benchmarked datasets and works well in real life scenarios.\n    ",
        "submission_date": "2017-11-21T00:00:00",
        "last_modified_date": "2017-11-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.07676",
        "title": "Transferring Agent Behaviors from Videos via Motion GANs",
        "authors": [
            "Ashley D. Edwards",
            "Charles L. Isbell Jr"
        ],
        "abstract": "A major bottleneck for developing general reinforcement learning agents is determining rewards that will yield desirable behaviors under various circumstances. We introduce a general mechanism for automatically specifying meaningful behaviors from raw pixels. In particular, we train a generative adversarial network to produce short sub-goals represented through motion templates. We demonstrate that this approach generates visually meaningful behaviors in unknown environments with novel agents and describe how these motions can be used to train reinforcement learning agents.\n    ",
        "submission_date": "2017-11-21T00:00:00",
        "last_modified_date": "2017-11-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.07682",
        "title": "JamBot: Music Theory Aware Chord Based Generation of Polyphonic Music with LSTMs",
        "authors": [
            "Gino Brunner",
            "Yuyi Wang",
            "Roger Wattenhofer",
            "Jonas Wiesendanger"
        ],
        "abstract": "We propose a novel approach for the generation of polyphonic music based on LSTMs. We generate music in two steps. First, a chord LSTM predicts a chord progression based on a chord embedding. A second LSTM then generates polyphonic music from the predicted chord progression. The generated music sounds pleasing and harmonic, with only few dissonant notes. It has clear long-term structure that is similar to what a musician would play during a jam session. We show that our approach is sensible from a music theory perspective by evaluating the learned chord embeddings. Surprisingly, our simple model managed to extract the circle of fifths, an important tool in music theory, from the dataset.\n    ",
        "submission_date": "2017-11-21T00:00:00",
        "last_modified_date": "2017-11-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.07784",
        "title": "Hidden Tree Markov Networks: Deep and Wide Learning for Structured Data",
        "authors": [
            "Davide Bacciu"
        ],
        "abstract": "The paper introduces the Hidden Tree Markov Network (HTN), a neuro-probabilistic hybrid fusing the representation power of generative models for trees with the incremental and discriminative learning capabilities of neural networks. We put forward a modular architecture in which multiple generative models of limited complexity are trained to learn structural feature detectors whose outputs are then combined and integrated by neural layers at a later stage. In this respect, the model is both deep, thanks to the unfolding of the generative models on the input structures, as well as wide, given the potentially large number of generative modules that can be trained in parallel. Experimental results show that the proposed approach can outperform state-of-the-art syntactic kernels as well as generative kernels built on the same probabilistic model as the HTN.\n    ",
        "submission_date": "2017-11-21T00:00:00",
        "last_modified_date": "2017-11-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.07821",
        "title": "Evaluation of bioinspired algorithms for the solution of the job scheduling problem",
        "authors": [
            "Edson Florez",
            "Nelson Diaz",
            "Wilfredo Gomez",
            "Lola Bautista",
            "Dario Delgado"
        ],
        "abstract": "In this research we used bio-inspired metaheuristics, as artificial immune systems and ant colony algorithms that are based on a number of characteristics and behaviors of living things that are interesting in the computer science area. This paper presents an evaluation of bio-inspired solutions to combinatorial optimization problem, called the Job Shop Scheduling or planning work, in a simple way the objective is to find a configuration or job stream that has the least amount of time to be executed in machine settings. The performance of the algorithms was characterized and evaluated for reference instances of the job shop scheduling problem, comparing the quality of the solutions obtained with respect to the best known solution of the most effective methods. The solutions were evaluated in two aspects, first in relation of quality of solutions, taking as reference the makespan and secondly in relation of performance, taking the number evaluations performed by the algorithm to obtain the best solution.\n    ",
        "submission_date": "2017-11-21T00:00:00",
        "last_modified_date": "2017-11-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.07894",
        "title": "Quantifying Performance of Bipedal Standing with Multi-channel EMG",
        "authors": [
            "Yanan Sui",
            "Kun ho Kim",
            "Joel W. Burdick"
        ],
        "abstract": "Spinal cord stimulation has enabled humans with motor complete spinal cord injury (SCI) to independently stand and recover some lost autonomic function. Quantifying the quality of bipedal standing under spinal stimulation is important for spinal rehabilitation therapies and for new strategies that seek to combine spinal stimulation and rehabilitative robots (such as exoskeletons) in real time feedback. To study the potential for automated electromyography (EMG) analysis in SCI, we evaluated the standing quality of paralyzed patients undergoing electrical spinal cord stimulation using both video and multi-channel surface EMG recordings during spinal stimulation therapy sessions. The quality of standing under different stimulation settings was quantified manually by experienced clinicians. By correlating features of the recorded EMG activity with the expert evaluations, we show that multi-channel EMG recording can provide accurate, fast, and robust estimation for the quality of bipedal standing in spinally stimulated SCI patients. Moreover, our analysis shows that the total number of EMG channels needed to effectively predict standing quality can be reduced while maintaining high estimation accuracy, which provides more flexibility for rehabilitation robotic systems to incorporate EMG recordings.\n    ",
        "submission_date": "2017-11-21T00:00:00",
        "last_modified_date": "2017-11-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.07979",
        "title": "Posterior Sampling for Large Scale Reinforcement Learning",
        "authors": [
            "Georgios Theocharous",
            "Zheng Wen",
            "Yasin Abbasi-Yadkori",
            "Nikos Vlassis"
        ],
        "abstract": "We propose a practical non-episodic PSRL algorithm that unlike recent state-of-the-art PSRL algorithms uses a deterministic, model-independent episode switching schedule. Our algorithm termed deterministic schedule PSRL (DS-PSRL) is efficient in terms of time, sample, and space complexity. We prove a Bayesian regret bound under mild assumptions. Our result is more generally applicable to multiple parameters and continuous state action problems. We compare our algorithm with state-of-the-art PSRL algorithms on standard discrete and continuous problems from the literature. Finally, we show how the assumptions of our algorithm satisfy a sensible parametrization for a large class of problems in sequential recommendations.\n    ",
        "submission_date": "2017-11-21T00:00:00",
        "last_modified_date": "2018-10-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.08006",
        "title": "Relating Input Concepts to Convolutional Neural Network Decisions",
        "authors": [
            "Ning Xie",
            "Md Kamruzzaman Sarker",
            "Derek Doran",
            "Pascal Hitzler",
            "Michael Raymer"
        ],
        "abstract": "Many current methods to interpret convolutional neural networks (CNNs) use visualization techniques and words to highlight concepts of the input seemingly relevant to a CNN's decision. The methods hypothesize that the recognition of these concepts are instrumental in the decision a CNN reaches, but the nature of this relationship has not been well explored. To address this gap, this paper examines the quality of a concept's recognition by a CNN and the degree to which the recognitions are associated with CNN decisions. The study considers a CNN trained for scene recognition over the ADE20k dataset. It uses a novel approach to find and score the strength of minimally distributed representations of input concepts (defined by objects in scene images) across late stage feature maps. Subsequent analysis finds evidence that concept recognition impacts decision making. Strong recognition of concepts frequently-occurring in few scenes are indicative of correct decisions, but recognizing concepts common to many scenes may mislead the network.\n    ",
        "submission_date": "2017-11-21T00:00:00",
        "last_modified_date": "2017-11-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.08010",
        "title": "Unsupervised Adaptation with Domain Separation Networks for Robust Speech Recognition",
        "authors": [
            "Zhong Meng",
            "Zhuo Chen",
            "Vadim Mazalov",
            "Jinyu Li",
            "Yifan Gong"
        ],
        "abstract": "Unsupervised domain adaptation of speech signal aims at adapting a well-trained source-domain acoustic model to the unlabeled data from target domain. This can be achieved by adversarial training of deep neural network (DNN) acoustic models to learn an intermediate deep representation that is both senone-discriminative and domain-invariant. Specifically, the DNN is trained to jointly optimize the primary task of senone classification and the secondary task of domain classification with adversarial objective functions. In this work, instead of only focusing on learning a domain-invariant feature (i.e. the shared component between domains), we also characterize the difference between the source and target domain distributions by explicitly modeling the private component of each domain through a private component extractor DNN. The private component is trained to be orthogonal with the shared component and thus implicitly increases the degree of domain-invariance of the shared component. A reconstructor DNN is used to reconstruct the original speech feature from the private and shared components as a regularization. This domain separation framework is applied to the unsupervised environment adaptation task and achieved 11.08% relative WER reduction from the gradient reversal layer training, a representative adversarial training method, for automatic speech recognition on CHiME-3 dataset.\n    ",
        "submission_date": "2017-11-21T00:00:00",
        "last_modified_date": "2019-04-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.08080",
        "title": "Robust Stackelberg Equilibria in Extensive-Form Games and Extension to Limited Lookahead",
        "authors": [
            "Christian Kroer",
            "Gabriele Farina",
            "Tuomas Sandholm"
        ],
        "abstract": "Stackelberg equilibria have become increasingly important as a solution concept in computational game theory, largely inspired by practical problems such as security settings. In practice, however, there is typically uncertainty regarding the model about the opponent. This paper is, to our knowledge, the first to investigate Stackelberg equilibria under uncertainty in extensive-form games, one of the broadest classes of game. We introduce robust Stackelberg equilibria, where the uncertainty is about the opponent's payoffs, as well as ones where the opponent has limited lookahead and the uncertainty is about the opponent's node evaluation function. We develop a new mixed-integer program for the deterministic limited-lookahead setting. We then extend the program to the robust setting for Stackelberg equilibrium under unlimited and under limited lookahead by the opponent. We show that for the specific case of interval uncertainty about the opponent's payoffs (or about the opponent's node evaluations in the case of limited lookahead), robust Stackelberg equilibria can be computed with a mixed-integer program that is of the same asymptotic size as that for the deterministic setting.\n    ",
        "submission_date": "2017-11-21T00:00:00",
        "last_modified_date": "2017-11-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.08151",
        "title": "Multiagent Simple Temporal Problem: The Arc-Consistency Approach",
        "authors": [
            "Shufeng Kong",
            "Jae Hee Lee",
            "Sanjiang Li"
        ],
        "abstract": "The Simple Temporal Problem (STP) is a fundamental temporal reasoning problem and has recently been extended to the Multiagent Simple Temporal Problem (MaSTP). In this paper we present a novel approach that is based on enforcing arc-consistency (AC) on the input (multiagent) simple temporal network. We show that the AC-based approach is sufficient for solving both the STP and MaSTP and provide efficient algorithms for them. As our AC-based approach does not impose new constraints between agents, it does not violate the privacy of the agents and is superior to the state-of-the-art approach to MaSTP. Empirical evaluations on diverse benchmark datasets also show that our AC-based algorithms for STP and MaSTP are significantly more efficient than existing approaches.\n    ",
        "submission_date": "2017-11-22T00:00:00",
        "last_modified_date": "2017-11-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.08237",
        "title": "The Stochastic Firefighter Problem",
        "authors": [
            "Guy Tennenholtz",
            "Constantine Caramanis",
            "Shie Mannor"
        ],
        "abstract": "The dynamics of infectious diseases spread is crucial in determining their risk and offering ways to contain them. We study sequential vaccination of individuals in networks. In the original (deterministic) version of the Firefighter problem, a fire breaks out at some node of a given graph. At each time step, b nodes can be protected by a firefighter and then the fire spreads to all unprotected neighbors of the nodes on fire. The process ends when the fire can no longer spread. We extend the Firefighter problem to a probabilistic setting, where the infection is stochastic. We devise a simple policy that only vaccinates neighbors of infected nodes and is optimal on regular trees and on general graphs for a sufficiently large budget. We derive methods for calculating upper and lower bounds of the expected number of infected individuals, as well as provide estimates on the budget needed for containment in expectation. We calculate these explicitly on trees, d-dimensional grids, and Erd\u0151s R\u00e9nyi graphs. Finally, we construct a state-dependent budget allocation strategy and demonstrate its superiority over constant budget allocation on real networks following a first order acquaintance vaccination policy.\n    ",
        "submission_date": "2017-11-22T00:00:00",
        "last_modified_date": "2017-11-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.08275",
        "title": "Approximate Inference-based Motion Planning by Learning and Exploiting Low-Dimensional Latent Variable Models",
        "authors": [
            "Jung-Su Ha",
            "Hyeok-Joo Chae",
            "Han-Lim Choi"
        ],
        "abstract": "This work presents an efficient framework to generate a motion plan of a robot with high degrees of freedom (e.g., a humanoid robot). High-dimensionality of the robot configuration space often leads to difficulties in utilizing the widely-used motion planning algorithms, since the volume of the decision space increases exponentially with the number of dimensions. To handle complications arising from the large decision space, and to solve a corresponding motion planning problem efficiently, two key concepts are adopted in this work: First, the Gaussian process latent variable model (GP-LVM) is utilized for low-dimensional representation of the original configuration space. Second, an approximate inference algorithm is used, exploiting through the duality between control and estimation, to explore the decision space and to compute a high-quality motion trajectory of the robot. Utilizing the GP-LVM and the duality between control and estimation, we construct a fully probabilistic generative model with which a high-dimensional motion planning problem is transformed into a tractable inference problem. Finally, we compute the motion trajectory via an approximate inference algorithm based on a variant of the particle filter. The resulting motions can be viewed in the supplemental video. ( ",
        "submission_date": "2017-11-22T00:00:00",
        "last_modified_date": "2018-08-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.08319",
        "title": "Systems, Actors and Agents: Operation in a multicomponent environment",
        "authors": [
            "Mark Burgin"
        ],
        "abstract": "Multi-agent approach has become popular in computer science and technology. However, the conventional models of multi-agent and multicomponent systems implicitly or explicitly assume existence of absolute time or even do not include time in the set of defining parameters. At the same time, it is proved theoretically and validated experimentally that there are different times and time scales in a variety of real systems - physical, chemical, biological, social, informational, etc. Thus, the goal of this work is construction of a multi-agent multicomponent system models with concurrency of processes and diversity of actions. To achieve this goal, a mathematical system actor model is elaborated and its properties are studied.\n    ",
        "submission_date": "2017-11-16T00:00:00",
        "last_modified_date": "2017-11-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.08478",
        "title": "MagNet and \"Efficient Defenses Against Adversarial Attacks\" are Not Robust to Adversarial Examples",
        "authors": [
            "Nicholas Carlini",
            "David Wagner"
        ],
        "abstract": "MagNet and \"Efficient Defenses...\" were recently proposed as a defense to adversarial examples. We find that we can construct adversarial examples that defeat these defenses with only a slight increase in distortion.\n    ",
        "submission_date": "2017-11-22T00:00:00",
        "last_modified_date": "2017-11-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.08512",
        "title": "A Study on Modeling of Inputting Electrical Power of Ultra High Power Electric Furnace by using Fuzzy Rule and Regression Model",
        "authors": [
            "Choe Un-Chol",
            "Yun Kum-Il",
            "Kwak Son-Il"
        ],
        "abstract": ": In this paper a method to make inputting electrical model upon factors that affect melting process of high ultra power(UHP) electric furnace by using fuzzy rule and regression model is suggested and its effectiveness is verified with simulation experiment.\n    ",
        "submission_date": "2017-11-21T00:00:00",
        "last_modified_date": "2017-11-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.08534",
        "title": "Safer Classification by Synthesis",
        "authors": [
            "William Wang",
            "Angelina Wang",
            "Aviv Tamar",
            "Xi Chen",
            "Pieter Abbeel"
        ],
        "abstract": "The discriminative approach to classification using deep neural networks has become the de-facto standard in various fields. Complementing recent reservations about safety against adversarial examples, we show that conventional discriminative methods can easily be fooled to provide incorrect labels with very high confidence to out of distribution examples. We posit that a generative approach is the natural remedy for this problem, and propose a method for classification using generative models. At training time, we learn a generative model for each class, while at test time, given an example to classify, we query each generator for its most similar generation, and select the class corresponding to the most similar one. Our approach is general and can be used with expressive models such as GANs and VAEs. At test time, our method accurately \"knows when it does not know,\" and provides resilience to out of distribution examples while maintaining competitive performance for standard examples.\n    ",
        "submission_date": "2017-11-22T00:00:00",
        "last_modified_date": "2018-07-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.08859",
        "title": "Exploring Approximations for Floating-Point Arithmetic using UppSAT",
        "authors": [
            "Aleksandar Zeljic",
            "Peter Backeman",
            "Christoph M. Wintersteiger",
            "Philipp Ruemmer"
        ],
        "abstract": "We consider the problem of solving floating-point constraints obtained from software verification. We present UppSAT --- a new implementation of a systematic approximation refinement framework [ZWR17] as an abstract SMT solver. Provided with an approximation and a decision procedure (implemented in an off-the-shelf SMT solver), UppSAT yields an approximating SMT solver. Additionally, UppSAT includes a library of predefined approximation components which can be combined and extended to define new encodings, orderings and solving strategies. We propose that UppSAT can be used as a sandbox for easy and flexible exploration of new approximations. To substantiate this, we explore several approximations of floating-point arithmetic. Approximations can be viewed as a composition of an encoding into a target theory, a precision ordering, and a number of strategies for model reconstruction and precision (or approximation) refinement. We present encodings of floating-point arithmetic into reduced precision floating-point arithmetic, real-arithmetic, and fixed-point arithmetic (encoded in the theory of bit-vectors). In an experimental evaluation, we compare the advantages and disadvantages of approximating solvers obtained by combining various encodings and decision procedures (based on existing state-of-the-art SMT solvers for floating-point, real, and bit-vector arithmetic).\n    ",
        "submission_date": "2017-11-24T00:00:00",
        "last_modified_date": "2017-12-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.08921",
        "title": "Automated Algorithm Selection on Continuous Black-Box Problems By Combining Exploratory Landscape Analysis and Machine Learning",
        "authors": [
            "Pascal Kerschke",
            "Heike Trautmann"
        ],
        "abstract": "In this paper, we build upon previous work on designing informative and efficient Exploratory Landscape Analysis features for characterizing problems' landscapes and show their effectiveness in automatically constructing algorithm selection models in continuous black-box optimization problems. Focussing on algorithm performance results of the COCO platform of several years, we construct a representative set of high-performing complementary solvers and present an algorithm selection model that - compared to the portfolio's single best solver - on average requires less than half of the resources for solving a given problem. Therefore, there is a huge gain in efficiency compared to classical ensemble methods combined with an increased insight into problem characteristics and algorithm properties by using informative features. Acting on the assumption that the function set of the Black-Box Optimization Benchmark is representative enough for practical applications the model allows for selecting the best suited optimization algorithm within the considered set for unseen problems prior to the optimization itself based on a small sample of function evaluations. Note that such a sample can even be reused for the initial population of an evolutionary (optimization) algorithm so that even the feature costs become negligible.\n    ",
        "submission_date": "2017-11-24T00:00:00",
        "last_modified_date": "2018-11-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.08946",
        "title": "Action Branching Architectures for Deep Reinforcement Learning",
        "authors": [
            "Arash Tavakoli",
            "Fabio Pardo",
            "Petar Kormushev"
        ],
        "abstract": "Discrete-action algorithms have been central to numerous recent successes of deep reinforcement learning. However, applying these algorithms to high-dimensional action tasks requires tackling the combinatorial increase of the number of possible actions with the number of action dimensions. This problem is further exacerbated for continuous-action tasks that require fine control of actions via discretization. In this paper, we propose a novel neural architecture featuring a shared decision module followed by several network branches, one for each action dimension. This approach achieves a linear increase of the number of network outputs with the number of degrees of freedom by allowing a level of independence for each individual action dimension. To illustrate the approach, we present a novel agent, called Branching Dueling Q-Network (BDQ), as a branching variant of the Dueling Double Deep Q-Network (Dueling DDQN). We evaluate the performance of our agent on a set of challenging continuous control tasks. The empirical results show that the proposed agent scales gracefully to environments with increasing action dimensionality and indicate the significance of the shared decision module in coordination of the distributed action branches. Furthermore, we show that the proposed agent performs competitively against a state-of-the-art continuous control algorithm, Deep Deterministic Policy Gradient (DDPG).\n    ",
        "submission_date": "2017-11-24T00:00:00",
        "last_modified_date": "2019-01-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.09055",
        "title": "Interactive Robot Learning of Gestures, Language and Affordances",
        "authors": [
            "Giovanni Saponaro",
            "Lorenzo Jamone",
            "Alexandre Bernardino",
            "Giampiero Salvi"
        ],
        "abstract": "A growing field in robotics and Artificial Intelligence (AI) research is human-robot collaboration, whose target is to enable effective teamwork between humans and robots. However, in many situations human teams are still superior to human-robot teams, primarily because human teams can easily agree on a common goal with language, and the individual members observe each other effectively, leveraging their shared motor repertoire and sensorimotor resources. This paper shows that for cognitive robots it is possible, and indeed fruitful, to combine knowledge acquired from interacting with elements of the environment (affordance exploration) with the probabilistic observation of another agent's actions.\n",
        "submission_date": "2017-11-24T00:00:00",
        "last_modified_date": "2017-11-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.09268",
        "title": "Generalizing Hamiltonian Monte Carlo with Neural Networks",
        "authors": [
            "Daniel Levy",
            "Matthew D. Hoffman",
            "Jascha Sohl-Dickstein"
        ],
        "abstract": "We present a general-purpose method to train Markov chain Monte Carlo kernels, parameterized by deep neural networks, that converge and mix quickly to their target distribution. Our method generalizes Hamiltonian Monte Carlo and is trained to maximize expected squared jumped distance, a proxy for mixing speed. We demonstrate large empirical gains on a collection of simple but challenging distributions, for instance achieving a 106x improvement in effective sample size in one case, and mixing when standard HMC makes no measurable progress in a second. Finally, we show quantitative and qualitative gains on a real-world task: latent-variable generative modeling. We release an open source TensorFlow implementation of the algorithm.\n    ",
        "submission_date": "2017-11-25T00:00:00",
        "last_modified_date": "2018-03-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.09357",
        "title": "Generative Adversarial Network for Abstractive Text Summarization",
        "authors": [
            "Linqing Liu",
            "Yao Lu",
            "Min Yang",
            "Qiang Qu",
            "Jia Zhu",
            "Hongyan Li"
        ],
        "abstract": "In this paper, we propose an adversarial process for abstractive text summarization, in which we simultaneously train a generative model G and a discriminative model D. In particular, we build the generator G as an agent of reinforcement learning, which takes the raw text as input and predicts the abstractive summarization. We also build a discriminator which attempts to distinguish the generated summary from the ground truth summary. Extensive experiments demonstrate that our model achieves competitive ROUGE scores with the state-of-the-art methods on CNN/Daily Mail dataset. Qualitatively, we show that our model is able to generate more abstractive, readable and diverse summaries.\n    ",
        "submission_date": "2017-11-26T00:00:00",
        "last_modified_date": "2017-11-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.09395",
        "title": "Improved Neural Text Attribute Transfer with Non-parallel Data",
        "authors": [
            "Igor Melnyk",
            "Cicero Nogueira dos Santos",
            "Kahini Wadhawan",
            "Inkit Padhi",
            "Abhishek Kumar"
        ],
        "abstract": "Text attribute transfer using non-parallel data requires methods that can perform disentanglement of content and linguistic attributes. In this work, we propose multiple improvements over the existing approaches that enable the encoder-decoder framework to cope with the text attribute transfer from non-parallel data. We perform experiments on the sentiment transfer task using two datasets. For both datasets, our proposed method outperforms a strong baseline in two of the three employed evaluation metrics.\n    ",
        "submission_date": "2017-11-26T00:00:00",
        "last_modified_date": "2017-12-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.09414",
        "title": "MAVOT: Memory-Augmented Video Object Tracking",
        "authors": [
            "Boyu Liu",
            "Yanzhao Wang",
            "Yu-Wing Tai",
            "Chi-Keung Tang"
        ],
        "abstract": "We introduce a one-shot learning approach for video object tracking. The proposed algorithm requires seeing the object to be tracked only once, and employs an external memory to store and remember the evolving features of the foreground object as well as backgrounds over time during tracking. With the relevant memory retrieved and updated in each tracking, our tracking model is capable of maintaining long-term memory of the object, and thus can naturally deal with hard tracking scenarios including partial and total occlusion, motion changes and large scale and shape variations. In our experiments we use the ImageNet ILSVRC2015 video detection dataset to train and use the VOT-2016 benchmark to test and compare our Memory-Augmented Video Object Tracking (MAVOT) model. From the results, we conclude that given its oneshot property and simplicity in design, MAVOT is an attractive approach in visual tracking because it shows good performance on VOT-2016 benchmark and is among the top 5 performers in accuracy and robustness in occlusion, motion changes and empty target.\n    ",
        "submission_date": "2017-11-26T00:00:00",
        "last_modified_date": "2017-11-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.09442",
        "title": "Quantum Artificial Life in an IBM Quantum Computer",
        "authors": [
            "U. Alvarez-Rodriguez",
            "M. Sanz",
            "L. Lamata",
            "E. Solano"
        ],
        "abstract": "We present the first experimental realization of a quantum artificial life algorithm in a quantum computer. The quantum biomimetic protocol encodes tailored quantum behaviors belonging to living systems, namely, self-replication, mutation, interaction between individuals, and death, into the cloud quantum computer IBM ibmqx4. In this experiment, entanglement spreads throughout generations of individuals, where genuine quantum information features are inherited through genealogical networks. As a pioneering proof-of-principle, experimental data fits the ideal model with accuracy. Thereafter, these and other models of quantum artificial life, for which no classical device may predict its quantum supremacy evolution, can be further explored in novel generations of quantum computers. Quantum biomimetics, quantum machine learning, and quantum artificial intelligence will move forward hand in hand through more elaborate levels of quantum complexity.\n    ",
        "submission_date": "2017-11-26T00:00:00",
        "last_modified_date": "2018-10-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.09561",
        "title": "HP-GAN: Probabilistic 3D human motion prediction via GAN",
        "authors": [
            "Emad Barsoum",
            "John Kender",
            "Zicheng Liu"
        ],
        "abstract": "Predicting and understanding human motion dynamics has many applications, such as motion synthesis, augmented reality, security, and autonomous vehicles. Due to the recent success of generative adversarial networks (GAN), there has been much interest in probabilistic estimation and synthetic data generation using deep neural network architectures and learning algorithms.\n",
        "submission_date": "2017-11-27T00:00:00",
        "last_modified_date": "2017-11-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.09601",
        "title": "Memory Aware Synapses: Learning what (not) to forget",
        "authors": [
            "Rahaf Aljundi",
            "Francesca Babiloni",
            "Mohamed Elhoseiny",
            "Marcus Rohrbach",
            "Tinne Tuytelaars"
        ],
        "abstract": "Humans can learn in a continuous manner. Old rarely utilized knowledge can be overwritten by new incoming information while important, frequently used knowledge is prevented from being erased. In artificial learning systems, lifelong learning so far has focused mainly on accumulating knowledge over tasks and overcoming catastrophic forgetting. In this paper, we argue that, given the limited model capacity and the unlimited new information to be learned, knowledge has to be preserved or erased selectively. Inspired by neuroplasticity, we propose a novel approach for lifelong learning, coined Memory Aware Synapses (MAS). It computes the importance of the parameters of a neural network in an unsupervised and online manner. Given a new sample which is fed to the network, MAS accumulates an importance measure for each parameter of the network, based on how sensitive the predicted output function is to a change in this parameter. When learning a new task, changes to important parameters can then be penalized, effectively preventing important knowledge related to previous tasks from being overwritten. Further, we show an interesting connection between a local version of our method and Hebb's rule,which is a model for the learning process in the brain. We test our method on a sequence of object recognition tasks and on the challenging problem of learning an embedding for predicting $<$subject, predicate, object$>$ triplets. We show state-of-the-art performance and, for the first time, the ability to adapt the importance of the parameters based on unlabeled data towards what the network needs (not) to forget, which may vary depending on test conditions.\n    ",
        "submission_date": "2017-11-27T00:00:00",
        "last_modified_date": "2018-10-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.09681",
        "title": "Butterfly Effect: Bidirectional Control of Classification Performance by Small Additive Perturbation",
        "authors": [
            "YoungJoon Yoo",
            "Seonguk Park",
            "Junyoung Choi",
            "Sangdoo Yun",
            "Nojun Kwak"
        ],
        "abstract": "This paper proposes a new algorithm for controlling classification results by generating a small additive perturbation without changing the classifier network. Our work is inspired by existing works generating adversarial perturbation that worsens classification performance. In contrast to the existing methods, our work aims to generate perturbations that can enhance overall classification performance. To solve this performance enhancement problem, we newly propose a perturbation generation network (PGN) influenced by the adversarial learning strategy. In our problem, the information in a large external dataset is summarized by a small additive perturbation, which helps to improve the performance of the classifier trained with the target dataset. In addition to this performance enhancement problem, we show that the proposed PGN can be adopted to solve the classical adversarial problem without utilizing the information on the target classifier. The mentioned characteristics of our method are verified through extensive experiments on publicly available visual datasets.\n    ",
        "submission_date": "2017-11-27T00:00:00",
        "last_modified_date": "2017-12-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.09684",
        "title": "Production Ready Chatbots: Generate if not Retrieve",
        "authors": [
            "Aniruddha Tammewar",
            "Monik Pamecha",
            "Chirag Jain",
            "Apurva Nagvenkar",
            "Krupal Modi"
        ],
        "abstract": "In this paper, we present a hybrid model that combines a neural conversational model and a rule-based graph dialogue system that assists users in scheduling reminders through a chat conversation. The graph based system has high precision and provides a grammatically accurate response but has a low recall. The neural conversation model can cater to a variety of requests, as it generates the responses word by word as opposed to using canned responses. The hybrid system shows significant improvements over the existing baseline system of rule based approach and caters to complex queries with a domain-restricted neural model. Restricting the conversation topic and combination of graph based retrieval system with a neural generative model makes the final system robust enough for a real world application.\n    ",
        "submission_date": "2017-11-27T00:00:00",
        "last_modified_date": "2017-11-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.09724",
        "title": "Table-to-text Generation by Structure-aware Seq2seq Learning",
        "authors": [
            "Tianyu Liu",
            "Kexiang Wang",
            "Lei Sha",
            "Baobao Chang",
            "Zhifang Sui"
        ],
        "abstract": "Table-to-text generation aims to generate a description for a factual table which can be viewed as a set of field-value records. To encode both the content and the structure of a table, we propose a novel structure-aware seq2seq architecture which consists of field-gating encoder and description generator with dual attention. In the encoding phase, we update the cell memory of the LSTM unit by a field gate and its corresponding field value in order to incorporate field information into table representation. In the decoding phase, dual attention mechanism which contains word level attention and field level attention is proposed to model the semantic relevance between the generated description and the table. We conduct experiments on the \\texttt{WIKIBIO} dataset which contains over 700k biographies and corresponding infoboxes from Wikipedia. The attention visualizations and case studies show that our model is capable of generating coherent and informative descriptions based on the comprehensive understanding of both the content and the structure of a table. Automatic evaluations also show our model outperforms the baselines by a great margin. Code for this work is available on ",
        "submission_date": "2017-11-27T00:00:00",
        "last_modified_date": "2017-11-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.09767",
        "title": "GazeGAN - Unpaired Adversarial Image Generation for Gaze Estimation",
        "authors": [
            "Matan Sela",
            "Pingmei Xu",
            "Junfeng He",
            "Vidhya Navalpakkam",
            "Dmitry Lagun"
        ],
        "abstract": "Recent research has demonstrated the ability to estimate gaze on mobile devices by performing inference on the image from the phone's front-facing camera, and without requiring specialized hardware. While this offers wide potential applications such as in human-computer interaction, medical diagnosis and accessibility (e.g., hands free gaze as input for patients with motor disorders), current methods are limited as they rely on collecting data from real users, which is a tedious and expensive process that is hard to scale across devices. There have been some attempts to synthesize eye region data using 3D models that can simulate various head poses and camera settings, however these lack in realism.\n",
        "submission_date": "2017-11-27T00:00:00",
        "last_modified_date": "2017-11-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.09784",
        "title": "Distilling a Neural Network Into a Soft Decision Tree",
        "authors": [
            "Nicholas Frosst",
            "Geoffrey Hinton"
        ],
        "abstract": "Deep neural networks have proved to be a very effective way to perform classification tasks. They excel when the input data is high dimensional, the relationship between the input and the output is complicated, and the number of labeled training examples is large. But it is hard to explain why a learned network makes a particular classification decision on a particular test case. This is due to their reliance on distributed hierarchical representations. If we could take the knowledge acquired by the neural net and express the same knowledge in a model that relies on hierarchical decisions instead, explaining a particular decision would be much easier. We describe a way of using a trained neural net to create a type of soft decision tree that generalizes better than one learned directly from the training data.\n    ",
        "submission_date": "2017-11-27T00:00:00",
        "last_modified_date": "2017-11-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.09883",
        "title": "AI Safety Gridworlds",
        "authors": [
            "Jan Leike",
            "Miljan Martic",
            "Victoria Krakovna",
            "Pedro A. Ortega",
            "Tom Everitt",
            "Andrew Lefrancq",
            "Laurent Orseau",
            "Shane Legg"
        ],
        "abstract": "We present a suite of reinforcement learning environments illustrating various safety properties of intelligent agents. These problems include safe interruptibility, avoiding side effects, absent supervisor, reward gaming, safe exploration, as well as robustness to self-modification, distributional shift, and adversaries. To measure compliance with the intended safe behavior, we equip each environment with a performance function that is hidden from the agent. This allows us to categorize AI safety problems into robustness and specification problems, depending on whether the performance function corresponds to the observed reward function. We evaluate A2C and Rainbow, two recent deep reinforcement learning agents, on our environments and show that they are not able to solve them satisfactorily.\n    ",
        "submission_date": "2017-11-27T00:00:00",
        "last_modified_date": "2017-11-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.09990",
        "title": "Identification of Strong Edges in AMP Chain Graphs",
        "authors": [
            "Jose M. Pe\u00f1a"
        ],
        "abstract": "The essential graph is a distinguished member of a Markov equivalence class of AMP chain graphs. However, the directed edges in the essential graph are not necessarily strong or invariant, i.e. they may not be shared by every member of the equivalence class. Likewise for the undirected edges. In this paper, we develop a procedure for identifying which edges in an essential graph are strong. We also show how this makes it possible to bound some causal effects when the true chain graph is unknown.\n    ",
        "submission_date": "2017-11-23T00:00:00",
        "last_modified_date": "2018-06-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.10105",
        "title": "Tensor Completion Algorithms in Big Data Analytics",
        "authors": [
            "Qingquan Song",
            "Hancheng Ge",
            "James Caverlee",
            "Xia Hu"
        ],
        "abstract": "Tensor completion is a problem of filling the missing or unobserved entries of partially observed tensors. Due to the multidimensional character of tensors in describing complex datasets, tensor completion algorithms and their applications have received wide attention and achievement in areas like data mining, computer vision, signal processing, and neuroscience. In this survey, we provide a modern overview of recent advances in tensor completion algorithms from the perspective of big data analytics characterized by diverse variety, large volume, and high velocity. We characterize these advances from four perspectives: general tensor completion algorithms, tensor completion with auxiliary information (variety), scalable tensor completion algorithms (volume), and dynamic tensor completion algorithms (velocity). Further, we identify several tensor completion applications on real-world data-driven problems and present some common experimental frameworks popularized in the literature. Our goal is to summarize these popular methods and introduce them to researchers and practitioners for promoting future research and applications. We conclude with a discussion of key challenges and promising research directions in this community for future exploration.\n    ",
        "submission_date": "2017-11-28T00:00:00",
        "last_modified_date": "2018-05-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.10123",
        "title": "Homomorphic Parameter Compression for Distributed Deep Learning Training",
        "authors": [
            "Jaehee Jang",
            "Byungook Na",
            "Sungroh Yoon"
        ],
        "abstract": "Distributed training of deep neural networks has received significant research interest, and its major approaches include implementations on multiple GPUs and clusters. Parallelization can dramatically improve the efficiency of training deep and complicated models with large-scale data. A fundamental barrier against the speedup of DNN training, however, is the trade-off between computation and communication time. In other words, increasing the number of worker nodes decreases the time consumed in computation while simultaneously increasing communication overhead under constrained network bandwidth, especially in commodity hardware environments. To alleviate this trade-off, we suggest the idea of homomorphic parameter compression, which compresses parameters with the least expense and trains the DNN with the compressed representation. Although the specific method is yet to be discovered, we demonstrate that there is a high probability that the homomorphism can reduce the communication overhead, thanks to little compression and decompression times. We also provide theoretical speedup of homomorphic compression.\n    ",
        "submission_date": "2017-11-28T00:00:00",
        "last_modified_date": "2017-11-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.10125",
        "title": "Learning to cluster in order to transfer across domains and tasks",
        "authors": [
            "Yen-Chang Hsu",
            "Zhaoyang Lv",
            "Zsolt Kira"
        ],
        "abstract": "This paper introduces a novel method to perform transfer learning across domains and tasks, formulating it as a problem of learning to cluster. The key insight is that, in addition to features, we can transfer similarity information and this is sufficient to learn a similarity function and clustering network to perform both domain adaptation and cross-task transfer learning. We begin by reducing categorical information to pairwise constraints, which only considers whether two instances belong to the same class or not. This similarity is category-agnostic and can be learned from data in the source domain using a similarity network. We then present two novel approaches for performing transfer learning using this similarity function. First, for unsupervised domain adaptation, we design a new loss function to regularize classification with a constrained clustering loss, hence learning a clustering network with the transferred similarity metric generating the training inputs. Second, for cross-task learning (i.e., unsupervised clustering with unseen categories), we propose a framework to reconstruct and estimate the number of semantic clusters, again using the clustering network. Since the similarity network is noisy, the key is to use a robust clustering algorithm, and we show that our formulation is more robust than the alternative constrained and unconstrained clustering approaches. Using this method, we first show state of the art results for the challenging cross-task problem, applied on Omniglot and ImageNet. Our results show that we can reconstruct semantic clusters with high accuracy. We then evaluate the performance of cross-domain transfer using images from the Office-31 and SVHN-MNIST tasks and present top accuracy on both datasets. Our approach doesn't explicitly deal with domain discrepancy. If we combine with a domain adaptation loss, it shows further improvement.\n    ",
        "submission_date": "2017-11-28T00:00:00",
        "last_modified_date": "2018-03-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.10166",
        "title": "QCBA: Improving Rule Classifiers Learned from Quantitative Data by Recovering Information Lost by Discretisation",
        "authors": [
            "Tomas Kliegr",
            "Ebroul Izquierdo"
        ],
        "abstract": "A prediscretisation of numerical attributes which is required by some rule learning algorithms is a source of inefficiencies. This paper describes new rule tuning steps that aim to recover lost information in the discretisation and new pruning techniques that may further reduce the size of rule models and improve their accuracy. The proposed QCBA method was initially developed to postprocess quantitative attributes in models generated by the Classification based on associations (CBA) algorithm, but it can also be applied to the results of other rule learning approaches. We demonstrate the effectiveness on the postprocessing of models generated by five association rule classification algorithms (CBA, CMAR, CPAR, IDS, SBRL) and two first-order logic rule learners (FOIL2 and PRM). Benchmarks on 22 datasets from the UCI repository show smaller size and the overall best predictive performance for FOIL2+QCBA compared to all seven baselines. Postoptimised CBA models have a better predictive performance compared to the state-of-the-art rule learner CORELS in this benchmark. The article contains an ablation study for the individual postprocessing steps and a scalability analysis on the KDD'99 Anomaly detection dataset.\n    ",
        "submission_date": "2017-11-28T00:00:00",
        "last_modified_date": "2023-06-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.10207",
        "title": "Learning to Rank based on Analogical Reasoning",
        "authors": [
            "Mohsen Ahmadi Fahandar",
            "Eyke H\u00fcllermeier"
        ],
        "abstract": "Object ranking or \"learning to rank\" is an important problem in the realm of preference learning. On the basis of training data in the form of a set of rankings of objects represented as feature vectors, the goal is to learn a ranking function that predicts a linear order of any new set of objects. In this paper, we propose a new approach to object ranking based on principles of analogical reasoning. More specifically, our inference pattern is formalized in terms of so-called analogical proportions and can be summarized as follows: Given objects $A,B,C,D$, if object $A$ is known to be preferred to $B$, and $C$ relates to $D$ as $A$ relates to $B$, then $C$ is (supposedly) preferred to $D$. Our method applies this pattern as a main building block and combines it with ideas and techniques from instance-based learning and rank aggregation. Based on first experimental results for data sets from various domains (sports, education, tourism, etc.), we conclude that our approach is highly competitive. It appears to be specifically interesting in situations in which the objects are coming from different subdomains, and which hence require a kind of knowledge transfer.\n    ",
        "submission_date": "2017-11-28T00:00:00",
        "last_modified_date": "2017-11-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.10328",
        "title": "Meteorology-Aware Multi-Goal Path Planning for Large-Scale Inspection Missions with Long-Endurance Solar-Powered Aircraft",
        "authors": [
            "Philipp Oettershagen",
            "Julian F\u00f6rster",
            "Lukas Wirth",
            "Jacques Amb\u00fchl",
            "Roland Siegwart"
        ],
        "abstract": "Solar-powered aircraft promise significantly increased flight endurance over conventional aircraft. While this makes them promising candidates for large-scale aerial inspection missions, their structural fragility necessitates that adverse weather is avoided using appropriate path planning methods. This paper therefore presents MetPASS, the Meteorology-aware Path Planning and Analysis Software for Solar-powered UAVs. MetPASS is the first path planning framework in the literature that considers all aspects that influence the safety or performance of solar-powered flight: It avoids environmental risks (thunderstorms, rain, wind, wind gusts and humidity) and exploits advantageous regions (high sun radiation or tailwind). It also avoids system risks such as low battery state of charge and returns safe paths through cluttered terrain. MetPASS imports weather data from global meteorological models, propagates the aircraft state through an energetic system model, and then combines both into a cost function. A combination of dynamic programming techniques and an A*-search-algorithm with a custom heuristic is leveraged to plan globally optimal paths in station-keeping, point-to-point or multi-goal aerial inspection missions with coverage guarantees. A full software implementation including a GUI is provided. The planning methods are verified using three missions of ETH Zurich's AtlantikSolar UAV: An 81-hour continuous solar-powered station-keeping flight, a 4000km Atlantic crossing from Newfoundland to Portugal, and two multi-glacier aerial inspection missions above the Arctic Ocean performed near Greenland in summer 2017.\n    ",
        "submission_date": "2017-11-28T00:00:00",
        "last_modified_date": "2017-11-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.10331",
        "title": "Complex Structure Leads to Overfitting: A Structure Regularization Decoding Method for Natural Language Processing",
        "authors": [
            "Xu Sun",
            "Weiwei Sun",
            "Shuming Ma",
            "Xuancheng Ren",
            "Yi Zhang",
            "Wenjie Li",
            "Houfeng Wang"
        ],
        "abstract": "Recent systems on structured prediction focus on increasing the level of structural dependencies within the model. However, our study suggests that complex structures entail high overfitting risks. To control the structure-based overfitting, we propose to conduct structure regularization decoding (SR decoding). The decoding of the complex structure model is regularized by the additionally trained simple structure model. We theoretically analyze the quantitative relations between the structural complexity and the overfitting risk. The analysis shows that complex structure models are prone to the structure-based overfitting. Empirical evaluations show that the proposed method improves the performance of the complex structure models by reducing the structure-based overfitting. On the sequence labeling tasks, the proposed method substantially improves the performance of the complex neural network models. The maximum F1 error rate reduction is 36.4% for the third-order model. The proposed method also works for the parsing task. The maximum UAS improvement is 5.5% for the tri-sibling model. The results are competitive with or better than the state-of-the-art results.\n    ",
        "submission_date": "2017-11-25T00:00:00",
        "last_modified_date": "2017-11-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.10455",
        "title": "Backprop as Functor: A compositional perspective on supervised learning",
        "authors": [
            "Brendan Fong",
            "David I. Spivak",
            "R\u00e9my Tuy\u00e9ras"
        ],
        "abstract": "A supervised learning algorithm searches over a set of functions $A \\to B$ parametrised by a space $P$ to find the best approximation to some ideal function $f\\colon A \\to B$. It does this by taking examples $(a,f(a)) \\in A\\times B$, and updating the parameter according to some rule. We define a category where these update rules may be composed, and show that gradient descent---with respect to a fixed step size and an error function satisfying a certain property---defines a monoidal functor from a category of parametrised functions to this category of update rules. This provides a structural perspective on backpropagation, as well as a broad generalisation of neural networks.\n    ",
        "submission_date": "2017-11-28T00:00:00",
        "last_modified_date": "2019-05-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.10521",
        "title": "A Recursive Bayesian Approach To Describe Retinal Vasculature Geometry",
        "authors": [
            "Fatmatulzehra Uslu",
            "Anil Anthony Bharath"
        ],
        "abstract": "Demographic studies suggest that changes in the retinal vasculature geometry, especially in vessel width, are associated with the incidence or progression of eye-related or systemic diseases. To date, the main information source for width estimation from fundus images has been the intensity profile between vessel edges. However, there are many factors affecting the intensity profile: pathologies, the central light reflex and local illumination levels, to name a few. In this study, we introduce three information sources for width estimation. These are the probability profiles of vessel interior, centreline and edge locations generated by a deep network. The probability profiles provide direct access to vessel geometry and are used in the likelihood calculation for a Bayesian method, particle filtering. We also introduce a geometric model which can handle non-ideal conditions of the probability profiles. Our experiments conducted on the REVIEW dataset yielded consistent estimates of vessel width, even in cases when one of the vessel edges is difficult to identify. Moreover, our results suggest that the method is better than human observers at locating edges of low contrast vessels.\n    ",
        "submission_date": "2017-11-28T00:00:00",
        "last_modified_date": "2017-11-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.10558",
        "title": "Intent-Aware Contextual Recommendation System",
        "authors": [
            "Biswarup Bhattacharya",
            "Iftikhar Burhanuddin",
            "Abhilasha Sancheti",
            "Kushal Satya"
        ],
        "abstract": "Recommender systems take inputs from user history, use an internal ranking algorithm to generate results and possibly optimize this ranking based on feedback. However, often the recommender system is unaware of the actual intent of the user and simply provides recommendations dynamically without properly understanding the thought process of the user. An intelligent recommender system is not only useful for the user but also for businesses which want to learn the tendencies of their users. Finding out tendencies or intents of a user is a difficult problem to solve.\n",
        "submission_date": "2017-11-28T00:00:00",
        "last_modified_date": "2017-11-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.10563",
        "title": "FearNet: Brain-Inspired Model for Incremental Learning",
        "authors": [
            "Ronald Kemker",
            "Christopher Kanan"
        ],
        "abstract": "Incremental class learning involves sequentially learning classes in bursts of examples from the same class. This violates the assumptions that underlie methods for training standard deep neural networks, and will cause them to suffer from catastrophic forgetting. Arguably, the best method for incremental class learning is iCaRL, but it requires storing training examples for each class, making it challenging to scale. Here, we propose FearNet for incremental class learning. FearNet is a generative model that does not store previous examples, making it memory efficient. FearNet uses a brain-inspired dual-memory system in which new memories are consolidated from a network for recent memories inspired by the mammalian hippocampal complex to a network for long-term storage inspired by medial prefrontal cortex. Memory consolidation is inspired by mechanisms that occur during sleep. FearNet also uses a module inspired by the basolateral amygdala for determining which memory system to use for recall. FearNet achieves state-of-the-art performance at incremental class learning on image (CIFAR-100, CUB-200) and audio classification (AudioSet) benchmarks.\n    ",
        "submission_date": "2017-11-28T00:00:00",
        "last_modified_date": "2018-02-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.10604",
        "title": "TensorFlow Distributions",
        "authors": [
            "Joshua V. Dillon",
            "Ian Langmore",
            "Dustin Tran",
            "Eugene Brevdo",
            "Srinivas Vasudevan",
            "Dave Moore",
            "Brian Patton",
            "Alex Alemi",
            "Matt Hoffman",
            "Rif A. Saurous"
        ],
        "abstract": "The TensorFlow Distributions library implements a vision of probability theory adapted to the modern deep-learning paradigm of end-to-end differentiable computation. Building on two basic abstractions, it offers flexible building blocks for probabilistic computation. Distributions provide fast, numerically stable methods for generating samples and computing statistics, e.g., log density. Bijectors provide composable volume-tracking transformations with automatic caching. Together these enable modular construction of high dimensional distributions and transformations not possible with previous libraries (e.g., pixelCNNs, autoregressive flows, and reversible residual networks). They are the workhorse behind deep probabilistic programming systems like Edward and empower fast black-box inference in probabilistic models built on deep-network components. TensorFlow Distributions has proven an important part of the TensorFlow toolkit within Google and in the broader deep learning community.\n    ",
        "submission_date": "2017-11-28T00:00:00",
        "last_modified_date": "2017-11-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.10644",
        "title": "PSIque: Next Sequence Prediction of Satellite Images using a Convolutional Sequence-to-Sequence Network",
        "authors": [
            "Seungkyun Hong",
            "Seongchan Kim",
            "Minsu Joh",
            "Sa-kwang Song"
        ],
        "abstract": "Predicting unseen weather phenomena is an important issue for disaster management. In this paper, we suggest a model for a convolutional sequence-to-sequence autoencoder for predicting undiscovered weather situations from previous satellite images. We also propose a symmetric skip connection between encoder and decoder modules to produce more comprehensive image predictions. To examine our model performance, we conducted experiments for each suggested model to predict future satellite images from historical satellite images. A specific combination of skip connection and sequence-to-sequence autoencoder was able to generate closest prediction from the ground truth image.\n    ",
        "submission_date": "2017-11-29T00:00:00",
        "last_modified_date": "2017-11-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.10755",
        "title": "Representation Learning for Scale-free Networks",
        "authors": [
            "Rui Feng",
            "Yang Yang",
            "Wenjie Hu",
            "Fei Wu",
            "Yueting Zhuang"
        ],
        "abstract": "Network embedding aims to learn the low-dimensional representations of vertexes in a network, while structure and inherent properties of the network is preserved. Existing network embedding works primarily focus on preserving the microscopic structure, such as the first- and second-order proximity of vertexes, while the macroscopic scale-free property is largely ignored. Scale-free property depicts the fact that vertex degrees follow a heavy-tailed distribution (i.e., only a few vertexes have high degrees) and is a critical property of real-world networks, such as social networks. In this paper, we study the problem of learning representations for scale-free networks. We first theoretically analyze the difficulty of embedding and reconstructing a scale-free network in the Euclidean space, by converting our problem to the sphere packing problem. Then, we propose the \"degree penalty\" principle for designing scale-free property preserving network embedding algorithm: punishing the proximity between high-degree vertexes. We introduce two implementations of our principle by utilizing the spectral techniques and a skip-gram model respectively. Extensive experiments on six datasets show that our algorithms are able to not only reconstruct heavy-tailed distributed degree distribution, but also outperform state-of-the-art embedding models in various network mining tasks, such as vertex classification and link prediction.\n    ",
        "submission_date": "2017-11-29T00:00:00",
        "last_modified_date": "2017-11-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.10789",
        "title": "Efficient exploration with Double Uncertain Value Networks",
        "authors": [
            "Thomas M. Moerland",
            "Joost Broekens",
            "Catholijn M. Jonker"
        ],
        "abstract": "This paper studies directed exploration for reinforcement learning agents by tracking uncertainty about the value of each available action. We identify two sources of uncertainty that are relevant for exploration. The first originates from limited data (parametric uncertainty), while the second originates from the distribution of the returns (return uncertainty). We identify methods to learn these distributions with deep neural networks, where we estimate parametric uncertainty with Bayesian drop-out, while return uncertainty is propagated through the Bellman equation as a Gaussian distribution. Then, we identify that both can be jointly estimated in one network, which we call the Double Uncertain Value Network. The policy is directly derived from the learned distributions based on Thompson sampling. Experimental results show that both types of uncertainty may vastly improve learning in domains with a strong exploration challenge.\n    ",
        "submission_date": "2017-11-29T00:00:00",
        "last_modified_date": "2017-11-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.10795",
        "title": "Saliency Weighted Convolutional Features for Instance Search",
        "authors": [
            "Eva Mohedano",
            "Kevin McGuinness",
            "Xavier Giro-i-Nieto",
            "Noel E. O'Connor"
        ],
        "abstract": "This work explores attention models to weight the contribution of local convolutional representations for the instance search task. We present a retrieval framework based on bags of local convolutional features (BLCF) that benefits from saliency weighting to build an efficient image representation. The use of human visual attention models (saliency) allows significant improvements in retrieval performance without the need to conduct region analysis or spatial verification, and without requiring any feature fine tuning. We investigate the impact of different saliency models, finding that higher performance on saliency benchmarks does not necessarily equate to improved performance when used in instance search tasks. The proposed approach outperforms the state-of-the-art on the challenging INSTRE benchmark by a large margin, and provides similar performance on the Oxford and Paris benchmarks compared to more complex methods that use off-the-shelf representations. The source code used in this project is available at ",
        "submission_date": "2017-11-29T00:00:00",
        "last_modified_date": "2017-11-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.10868",
        "title": "La production de nitrites lors de la d\u00e9nitrification des eaux us\u00e9es par biofiltration - Strat\u00e9gie de contr\u00f4le et de r\u00e9duction des concentrations r\u00e9siduelles",
        "authors": [
            "Vincent Rocher",
            "C\u00e9dric Join",
            "St\u00e9phane Mottelet",
            "Jean Bernier",
            "Sabrina Rechdaoui-Gu\u00e9rin",
            "Sam Azimi",
            "Paul Lessard",
            "Andr\u00e9 Pauss",
            "Michel Fliess"
        ],
        "abstract": "The recent popularity of post-denitrification processes in the greater Paris area wastewater treatment plants has caused a resurgence of the presence of nitrite in the Seine river. Controlling the production of nitrite during the post-denitrification has thus become a major technical issue. Research studies have been led in the MOCOPEE program (",
        "submission_date": "2017-11-28T00:00:00",
        "last_modified_date": "2017-11-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.10938",
        "title": "Extreme Dimension Reduction for Handling Covariate Shift",
        "authors": [
            "Fulton Wang",
            "Cynthia Rudin"
        ],
        "abstract": "In the covariate shift learning scenario, the training and test covariate distributions differ, so that a predictor's average loss over the training and test distributions also differ. In this work, we explore the potential of extreme dimension reduction, i.e. to very low dimensions, in improving the performance of importance weighting methods for handling covariate shift, which fail in high dimensions due to potentially high train/test covariate divergence and the inability to accurately estimate the requisite density ratios. We first formulate and solve a problem optimizing over linear subspaces a combination of their predictive utility and train/test divergence within. Applying it to simulated and real data, we show extreme dimension reduction helps sometimes but not always, due to a bias introduced by dimension reduction.\n    ",
        "submission_date": "2017-11-29T00:00:00",
        "last_modified_date": "2018-03-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.10958",
        "title": "Now Playing: Continuous low-power music recognition",
        "authors": [
            "Blaise Ag\u00fcera y Arcas",
            "Beat Gfeller",
            "Ruiqi Guo",
            "Kevin Kilgour",
            "Sanjiv Kumar",
            "James Lyon",
            "Julian Odell",
            "Marvin Ritter",
            "Dominik Roblek",
            "Matthew Sharifi",
            "Mihajlo Velimirovi\u0107"
        ],
        "abstract": "Existing music recognition applications require a connection to a server that performs the actual recognition. In this paper we present a low-power music recognizer that runs entirely on a mobile device and automatically recognizes music without user interaction. To reduce battery consumption, a small music detector runs continuously on the mobile device's DSP chip and wakes up the main application processor only when it is confident that music is present. Once woken, the recognizer on the application processor is provided with a few seconds of audio which is fingerprinted and compared to the stored fingerprints in the on-device fingerprint database of tens of thousands of songs. Our presented system, Now Playing, has a daily battery usage of less than 1% on average, respects user privacy by running entirely on-device and can passively recognize a wide range of music.\n    ",
        "submission_date": "2017-11-29T00:00:00",
        "last_modified_date": "2017-11-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.11027",
        "title": "Embedding Words as Distributions with a Bayesian Skip-gram Model",
        "authors": [
            "Arthur Bra\u017einskas",
            "Serhii Havrylov",
            "Ivan Titov"
        ],
        "abstract": "We introduce a method for embedding words as probability densities in a low-dimensional space. Rather than assuming that a word embedding is fixed across the entire text collection, as in standard word embedding methods, in our Bayesian model we generate it from a word-specific prior density for each occurrence of a given word. Intuitively, for each word, the prior density encodes the distribution of its potential 'meanings'. These prior densities are conceptually similar to Gaussian embeddings. Interestingly, unlike the Gaussian embeddings, we can also obtain context-specific densities: they encode uncertainty about the sense of a word given its context and correspond to posterior distributions within our model. The context-dependent densities have many potential applications: for example, we show that they can be directly used in the lexical substitution task. We describe an effective estimation method based on the variational autoencoding framework. We also demonstrate that our embeddings achieve competitive results on standard benchmarks.\n    ",
        "submission_date": "2017-11-29T00:00:00",
        "last_modified_date": "2018-06-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.11068",
        "title": "Happiness Pursuit: Personality Learning in a Society of Agents",
        "authors": [
            "Rafa\u0142 Muszy\u0144ski",
            "Jun Wang"
        ],
        "abstract": "Modeling personality is a challenging problem with applications spanning computer games, virtual assistants, online shopping and education. Many techniques have been tried, ranging from neural networks to computational cognitive architectures. However, most approaches rely on examples with hand-crafted features and scenarios. Here, we approach learning a personality by training agents using a Deep Q-Network (DQN) model on rewards based on psychoanalysis, against hand-coded AI in the game of Pong. As a result, we obtain 4 agents, each with its own personality. Then, we define happiness of an agent, which can be seen as a measure of alignment with agent's objective function, and study it when agents play both against hand-coded AI, and against each other. We find that the agents that achieve higher happiness during testing against hand-coded AI, have lower happiness when competing against each other. This suggests that higher happiness in testing is a sign of overfitting in learning to interact with hand-coded AI, and leads to worse performance against agents with different personalities.\n    ",
        "submission_date": "2017-11-29T00:00:00",
        "last_modified_date": "2017-12-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.11124",
        "title": "Improving Latent User Models in Online Social Media",
        "authors": [
            "Adit Krishnan",
            "Ashish Sharma",
            "Hari Sundaram"
        ],
        "abstract": "Modern social platforms are characterized by the presence of rich user-behavior data associated with the publication, sharing and consumption of textual content. Users interact with content and with each other in a complex and dynamic social environment while simultaneously evolving over time. In order to effectively characterize users and predict their future behavior in such a setting, it is necessary to overcome several challenges. Content heterogeneity and temporal inconsistency of behavior data result in severe sparsity at the user level. In this paper, we propose a novel mutual-enhancement framework to simultaneously partition and learn latent activity profiles of users. We propose a flexible user partitioning approach to effectively discover rare behaviors and tackle user-level sparsity. We extensively evaluate the proposed framework on massive datasets from real-world platforms including Q&A networks and interactive online courses (MOOCs). Our results indicate significant gains over state-of-the-art behavior models ( 15% avg ) in a varied range of tasks and our gains are further magnified for users with limited interaction data. The proposed algorithms are amenable to parallelization, scale linearly in the size of datasets, and provide flexibility to model diverse facets of user behavior.\n    ",
        "submission_date": "2017-11-30T00:00:00",
        "last_modified_date": "2019-02-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.11135",
        "title": "Video Captioning via Hierarchical Reinforcement Learning",
        "authors": [
            "Xin Wang",
            "Wenhu Chen",
            "Jiawei Wu",
            "Yuan-Fang Wang",
            "William Yang Wang"
        ],
        "abstract": "Video captioning is the task of automatically generating a textual description of the actions in a video. Although previous work (e.g. sequence-to-sequence model) has shown promising results in abstracting a coarse description of a short video, it is still very challenging to caption a video containing multiple fine-grained actions with a detailed description. This paper aims to address the challenge by proposing a novel hierarchical reinforcement learning framework for video captioning, where a high-level Manager module learns to design sub-goals and a low-level Worker module recognizes the primitive actions to fulfill the sub-goal. With this compositional framework to reinforce video captioning at different levels, our approach significantly outperforms all the baseline methods on a newly introduced large-scale dataset for fine-grained video captioning. Furthermore, our non-ensemble model has already achieved the state-of-the-art results on the widely-used MSR-VTT dataset.\n    ",
        "submission_date": "2017-11-29T00:00:00",
        "last_modified_date": "2018-03-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.11200",
        "title": "Embedded Real-Time Fall Detection Using Deep Learning For Elderly Care",
        "authors": [
            "Hyunwoo Lee",
            "Jooyoung Kim",
            "Dojun Yang",
            "Joon-Ho Kim"
        ],
        "abstract": "This paper proposes a real-time embedded fall detection system using a DVS(Dynamic Vision Sensor) that has never been used for traditional fall detection, a dataset for fall detection using that, and a DVS-TN(DVS-Temporal Network). The first contribution is building a DVS Falls Dataset, which made our network to recognize a much greater variety of falls than the existing datasets that existed before and solved privacy issues using the DVS. Secondly, we introduce the DVS-TN : optimized deep learning network to detect falls using DVS. Finally, we implemented a fall detection system which can run on low-computing H/W with real-time, and tested on DVS Falls Dataset that takes into account various falls situations. Our approach achieved 95.5% on the F1-score and operates at 31.25 FPS on NVIDIA Jetson TX1 board.\n    ",
        "submission_date": "2017-11-30T00:00:00",
        "last_modified_date": "2017-11-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.11225",
        "title": "Variational Deep Q Network",
        "authors": [
            "Yunhao Tang",
            "Alp Kucukelbir"
        ],
        "abstract": "We propose a framework that directly tackles the probability distribution of the value function parameters in Deep Q Network (DQN), with powerful variational inference subroutines to approximate the posterior of the parameters. We will establish the equivalence between our proposed surrogate objective and variational inference loss. Our new algorithm achieves efficient exploration and performs well on large scale chain Markov Decision Process (MDP).\n    ",
        "submission_date": "2017-11-30T00:00:00",
        "last_modified_date": "2017-11-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.11383",
        "title": "Learning to Learn from Weak Supervision by Full Supervision",
        "authors": [
            "Mostafa Dehghani",
            "Aliaksei Severyn",
            "Sascha Rothe",
            "Jaap Kamps"
        ],
        "abstract": "In this paper, we propose a method for training neural networks when we have a large set of data with weak labels and a small amount of data with true labels. In our proposed model, we train two neural networks: a target network, the learner and a confidence network, the meta-learner. The target network is optimized to perform a given task and is trained using a large set of unlabeled data that are weakly annotated. We propose to control the magnitude of the gradient updates to the target network using the scores provided by the second confidence network, which is trained on a small amount of supervised data. Thus we avoid that the weight updates computed from noisy labels harm the quality of the target network model.\n    ",
        "submission_date": "2017-11-30T00:00:00",
        "last_modified_date": "2017-11-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.11443",
        "title": "ConvNets and ImageNet Beyond Accuracy: Understanding Mistakes and Uncovering Biases",
        "authors": [
            "Pierre Stock",
            "Moustapha Cisse"
        ],
        "abstract": "ConvNets and Imagenet have driven the recent success of deep learning for image classification. However, the marked slowdown in performance improvement combined with the lack of robustness of neural networks to adversarial examples and their tendency to exhibit undesirable biases question the reliability of these methods. This work investigates these questions from the perspective of the end-user by using human subject studies and explanations. The contribution of this study is threefold. We first experimentally demonstrate that the accuracy and robustness of ConvNets measured on Imagenet are vastly underestimated. Next, we show that explanations can mitigate the impact of misclassified adversarial examples from the perspective of the end-user. We finally introduce a novel tool for uncovering the undesirable biases learned by a model. These contributions also show that explanations are a valuable tool both for improving our understanding of ConvNets' predictions and for designing more reliable models.\n    ",
        "submission_date": "2017-11-30T00:00:00",
        "last_modified_date": "2018-07-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.11508",
        "title": "Calculating Semantic Similarity between Academic Articles using Topic Event and Ontology",
        "authors": [
            "Ming Liu",
            "Bo Lang",
            "Zepeng Gu"
        ],
        "abstract": "Determining semantic similarity between academic documents is crucial to many tasks such as plagiarism detection, automatic technical survey and semantic search. Current studies mostly focus on semantic similarity between concepts, sentences and short text fragments. However, document-level semantic matching is still based on statistical information in surface level, neglecting article structures and global semantic meanings, which may cause the deviation in document understanding. In this paper, we focus on the document-level semantic similarity issue for academic literatures with a novel method. We represent academic articles with topic events that utilize multiple information profiles, such as research purposes, methodologies and domains to integrally describe the research work, and calculate the similarity between topic events based on the domain ontology to acquire the semantic similarity between articles. Experiments show that our approach achieves significant performance compared to state-of-the-art methods.\n    ",
        "submission_date": "2017-11-30T00:00:00",
        "last_modified_date": "2017-11-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.11543",
        "title": "Embodied Question Answering",
        "authors": [
            "Abhishek Das",
            "Samyak Datta",
            "Georgia Gkioxari",
            "Stefan Lee",
            "Devi Parikh",
            "Dhruv Batra"
        ],
        "abstract": "We present a new AI task -- Embodied Question Answering (EmbodiedQA) -- where an agent is spawned at a random location in a 3D environment and asked a question (\"What color is the car?\"). In order to answer, the agent must first intelligently navigate to explore the environment, gather information through first-person (egocentric) vision, and then answer the question (\"orange\").\n",
        "submission_date": "2017-11-30T00:00:00",
        "last_modified_date": "2017-12-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1711.11565",
        "title": "Deep Neural Networks for Multiple Speaker Detection and Localization",
        "authors": [
            "Weipeng He",
            "Petr Motlicek",
            "Jean-Marc Odobez"
        ],
        "abstract": "We propose to use neural networks for simultaneous detection and localization of multiple sound sources in human-robot interaction. In contrast to conventional signal processing techniques, neural network-based sound source localization methods require fewer strong assumptions about the environment. Previous neural network-based methods have been focusing on localizing a single sound source, which do not extend to multiple sources in terms of detection and localization. In this paper, we thus propose a likelihood-based encoding of the network output, which naturally allows the detection of an arbitrary number of sources. In addition, we investigate the use of sub-band cross-correlation information as features for better localization in sound mixtures, as well as three different network architectures based on different motivations. Experiments on real data recorded from a robot show that our proposed methods significantly outperform the popular spatial spectrum-based approaches.\n    ",
        "submission_date": "2017-11-30T00:00:00",
        "last_modified_date": "2018-02-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.00004",
        "title": "Learnings Options End-to-End for Continuous Action Tasks",
        "authors": [
            "Martin Klissarov",
            "Pierre-Luc Bacon",
            "Jean Harb",
            "Doina Precup"
        ],
        "abstract": "We present new results on learning temporally extended actions for continuoustasks, using the options framework (Suttonet al.[1999b], Precup [2000]). In orderto achieve this goal we work with the option-critic architecture (Baconet al.[2017])using a deliberation cost and train it with proximal policy optimization (Schulmanet al.[2017]) instead of vanilla policy gradient. Results on Mujoco domains arepromising, but lead to interesting questions aboutwhena given option should beused, an issue directly connected to the use of initiation sets.\n    ",
        "submission_date": "2017-11-30T00:00:00",
        "last_modified_date": "2017-11-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.00006",
        "title": "Comparing Deep Reinforcement Learning and Evolutionary Methods in Continuous Control",
        "authors": [
            "Shangtong Zhang",
            "Osmar R. Zaiane"
        ],
        "abstract": "Reinforcement Learning and the Evolutionary Strategy are two major approaches in addressing complicated control problems. Both are strong contenders and have their own devotee communities. Both groups have been very active in developing new advances in their own domain and devising, in recent years, leading-edge techniques to address complex continuous control tasks. Here, in the context of Deep Reinforcement Learning, we formulate a parallelized version of the Proximal Policy Optimization method and a Deep Deterministic Policy Gradient method. Moreover, we conduct a thorough comparison between the state-of-the-art techniques in both camps fro continuous control; evolutionary methods and Deep Reinforcement Learning methods. The results show there is no consistent winner.\n    ",
        "submission_date": "2017-11-30T00:00:00",
        "last_modified_date": "2018-03-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.00166",
        "title": "Audio Cover Song Identification using Convolutional Neural Network",
        "authors": [
            "Sungkyun Chang",
            "Juheon Lee",
            "Sang Keun Choe",
            "Kyogu Lee"
        ],
        "abstract": "In this paper, we propose a new approach to cover song identification using a CNN (convolutional neural network). Most previous studies extract the feature vectors that characterize the cover song relation from a pair of songs and used it to compute the (dis)similarity between the two songs. Based on the observation that there is a meaningful pattern between cover songs and that this can be learned, we have reformulated the cover song identification problem in a machine learning framework. To do this, we first build the CNN using as an input a cross-similarity matrix generated from a pair of songs. We then construct the data set composed of cover song pairs and non-cover song pairs, which are used as positive and negative training samples, respectively. The trained CNN outputs the probability of being in the cover song relation given a cross-similarity matrix generated from any two pieces of music and identifies the cover song by ranking on the probability. Experimental results show that the proposed algorithm achieves performance better than or comparable to the state-of-the-art.\n    ",
        "submission_date": "2017-12-01T00:00:00",
        "last_modified_date": "2020-10-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.00193",
        "title": "InclusiveFaceNet: Improving Face Attribute Detection with Race and Gender Diversity",
        "authors": [
            "Hee Jung Ryu",
            "Hartwig Adam",
            "Margaret Mitchell"
        ],
        "abstract": "We demonstrate an approach to face attribute detection that retains or improves attribute detection accuracy across gender and race subgroups by learning demographic information prior to learning the attribute detection task. The system, which we call InclusiveFaceNet, detects face attributes by transferring race and gender representations learned from a held-out dataset of public race and gender identities. Leveraging learned demographic representations while withholding demographic inference from the downstream face attribute detection task preserves potential users' demographic privacy while resulting in some of the best reported numbers to date on attribute detection in the Faces of the World and CelebA datasets.\n    ",
        "submission_date": "2017-12-01T00:00:00",
        "last_modified_date": "2018-07-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.00377",
        "title": "Don't Just Assume; Look and Answer: Overcoming Priors for Visual Question Answering",
        "authors": [
            "Aishwarya Agrawal",
            "Dhruv Batra",
            "Devi Parikh",
            "Aniruddha Kembhavi"
        ],
        "abstract": "A number of studies have found that today's Visual Question Answering (VQA) models are heavily driven by superficial correlations in the training data and lack sufficient image grounding. To encourage development of models geared towards the latter, we propose a new setting for VQA where for every question type, train and test sets have different prior distributions of answers. Specifically, we present new splits of the VQA v1 and VQA v2 datasets, which we call Visual Question Answering under Changing Priors (VQA-CP v1 and VQA-CP v2 respectively). First, we evaluate several existing VQA models under this new setting and show that their performance degrades significantly compared to the original VQA setting. Second, we propose a novel Grounded Visual Question Answering model (GVQA) that contains inductive biases and restrictions in the architecture specifically designed to prevent the model from 'cheating' by primarily relying on priors in the training data. Specifically, GVQA explicitly disentangles the recognition of visual concepts present in the image from the identification of plausible answer space for a given question, enabling the model to more robustly generalize across different distributions of answers. GVQA is built off an existing VQA model -- Stacked Attention Networks (SAN). Our experiments demonstrate that GVQA significantly outperforms SAN on both VQA-CP v1 and VQA-CP v2 datasets. Interestingly, it also outperforms more powerful VQA models such as Multimodal Compact Bilinear Pooling (MCB) in several cases. GVQA offers strengths complementary to SAN when trained and evaluated on the original VQA v1 and VQA v2 datasets. Finally, GVQA is more transparent and interpretable than existing VQA models.\n    ",
        "submission_date": "2017-12-01T00:00:00",
        "last_modified_date": "2018-06-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.00489",
        "title": "Visual Features for Context-Aware Speech Recognition",
        "authors": [
            "Abhinav Gupta",
            "Yajie Miao",
            "Leonardo Neves",
            "Florian Metze"
        ],
        "abstract": "Automatic transcriptions of consumer-generated multi-media content such as \"Youtube\" videos still exhibit high word error rates. Such data typically occupies a very broad domain, has been recorded in challenging conditions, with cheap hardware and a focus on the visual modality, and may have been post-processed or edited. In this paper, we extend our earlier work on adapting the acoustic model of a DNN-based speech recognition system to an RNN language model and show how both can be adapted to the objects and scenes that can be automatically detected in the video. We are working on a corpus of \"how-to\" videos from the web, and the idea is that an object that can be seen (\"car\"), or a scene that is being detected (\"kitchen\") can be used to condition both models on the \"context\" of the recording, thereby reducing perplexity and improving transcription. We achieve good improvements in both cases and compare and analyze the respective reductions in word error rate. We expect that our results can be used for any type of speech processing in which \"context\" information is available, for example in robotics, man-machine interaction, or when indexing large audio-visual archives, and should ultimately help to bring together the \"video-to-text\" and \"speech-to-text\" communities.\n    ",
        "submission_date": "2017-12-01T00:00:00",
        "last_modified_date": "2017-12-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.00600",
        "title": "MAgent: A Many-Agent Reinforcement Learning Platform for Artificial Collective Intelligence",
        "authors": [
            "Lianmin Zheng",
            "Jiacheng Yang",
            "Han Cai",
            "Weinan Zhang",
            "Jun Wang",
            "Yong Yu"
        ],
        "abstract": "We introduce MAgent, a platform to support research and development of many-agent reinforcement learning. Unlike previous research platforms on single or multi-agent reinforcement learning, MAgent focuses on supporting the tasks and the applications that require hundreds to millions of agents. Within the interactions among a population of agents, it enables not only the study of learning algorithms for agents' optimal polices, but more importantly, the observation and understanding of individual agent's behaviors and social phenomena emerging from the AI society, including communication languages, leaderships, altruism. MAgent is highly scalable and can host up to one million agents on a single GPU server. MAgent also provides flexible configurations for AI researchers to design their customized environments and agents. In this demo, we present three environments designed on MAgent and show emerged collective intelligence by learning from scratch.\n    ",
        "submission_date": "2017-12-02T00:00:00",
        "last_modified_date": "2017-12-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.00634",
        "title": "PFAx: Predictable Feature Analysis to Perform Control",
        "authors": [
            "Stefan Richthofer",
            "Laurenz Wiskott"
        ],
        "abstract": "Predictable Feature Analysis (PFA) (Richthofer, Wiskott, ICMLA 2015) is an algorithm that performs dimensionality reduction on high dimensional input signal. It extracts those subsignals that are most predictable according to a certain prediction model. We refer to these extracted signals as predictable features.\n",
        "submission_date": "2017-12-02T00:00:00",
        "last_modified_date": "2017-12-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.00712",
        "title": "Evaluation of Alzheimer's Disease by Analysis of MR Images using Multilayer Perceptrons and Kohonen SOM Classifiers as an Alternative to the ADC Maps",
        "authors": [
            "Wellington Pinheiro dos Santos",
            "Ricardo Emmanuel de Souza",
            "Pl\u00ednio B. dos Santos Filho"
        ],
        "abstract": "Alzheimer's disease is the most common cause of dementia, yet hard to diagnose precisely without invasive techniques, particularly at the onset of the disease. This work approaches image analysis and classification of synthetic multispectral images composed by diffusion-weighted magnetic resonance (MR) cerebral images for the evaluation of cerebrospinal fluid area and measuring the advance of Alzheimer's disease. A clinical 1.5 T MR imaging system was used to acquire all images presented. The classification methods are based on multilayer perceptrons and Kohonen Self-Organized Map classifiers. We assume the classes of interest can be separated by hyperquadrics. Therefore, a 2-degree polynomial network is used to classify the original image, generating the ground truth image. The classification results are used to improve the usual analysis of the apparent diffusion coefficient map.\n    ",
        "submission_date": "2017-12-03T00:00:00",
        "last_modified_date": "2017-12-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.00725",
        "title": "Sentiment Classification using Images and Label Embeddings",
        "authors": [
            "Laura Graesser",
            "Abhinav Gupta",
            "Lakshay Sharma",
            "Evelina Bakhturina"
        ],
        "abstract": "In this project we analysed how much semantic information images carry, and how much value image data can add to sentiment analysis of the text associated with the images. To better understand the contribution from images, we compared models which only made use of image data, models which only made use of text data, and models which combined both data types. We also analysed if this approach could help sentiment classifiers generalize to unknown sentiments.\n    ",
        "submission_date": "2017-12-03T00:00:00",
        "last_modified_date": "2017-12-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.00779",
        "title": "Gradient Descent Learns One-hidden-layer CNN: Don't be Afraid of Spurious Local Minima",
        "authors": [
            "Simon S. Du",
            "Jason D. Lee",
            "Yuandong Tian",
            "Barnabas Poczos",
            "Aarti Singh"
        ],
        "abstract": "We consider the problem of learning a one-hidden-layer neural network with non-overlapping convolutional layer and ReLU activation, i.e., $f(\\mathbf{Z}, \\mathbf{w}, \\mathbf{a}) = \\sum_j a_j\\sigma(\\mathbf{w}^T\\mathbf{Z}_j)$, in which both the convolutional weights $\\mathbf{w}$ and the output weights $\\mathbf{a}$ are parameters to be learned. When the labels are the outputs from a teacher network of the same architecture with fixed weights $(\\mathbf{w}^*, \\mathbf{a}^*)$, we prove that with Gaussian input $\\mathbf{Z}$, there is a spurious local minimizer. Surprisingly, in the presence of the spurious local minimizer, gradient descent with weight normalization from randomly initialized weights can still be proven to recover the true parameters with constant probability, which can be boosted to probability $1$ with multiple restarts. We also show that with constant probability, the same procedure could also converge to the spurious local minimum, showing that the local minimum plays a non-trivial role in the dynamics of gradient descent. Furthermore, a quantitative analysis shows that the gradient descent dynamics has two phases: it starts off slow, but converges much faster after several iterations.\n    ",
        "submission_date": "2017-12-03T00:00:00",
        "last_modified_date": "2018-06-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.00898",
        "title": "Proceedings of the Fifth Workshop on Proof eXchange for Theorem Proving",
        "authors": [
            "Catherine Dubois",
            "Bruno Woltzenlogel Paleo"
        ],
        "abstract": "This volume of EPTCS contains the proceedings of the Fifth Workshop on Proof Exchange for Theorem Proving (PxTP 2017), held on September 23-24, 2017 as part of the Tableaux, FroCoS and ITP conferences in Brasilia, Brazil. The PxTP workshop series brings together researchers working on various aspects of communication, integration, and cooperation between reasoning systems and formalisms, with a special focus on proofs. The progress in computer-aided reasoning, both automated and interactive, during the past decades, made it possible to build deduction tools that are increasingly more applicable to a wider range of problems and are able to tackle larger problems progressively faster. In recent years, cooperation between such tools in larger systems has demonstrated the potential to reduce the amount of manual intervention. Cooperation between reasoning systems relies on availability of theoretical formalisms and practical tools to exchange problems, proofs, and models. The PxTP workshop series strives to encourage such cooperation by inviting contributions on all aspects of cooperation between reasoning tools, whether automatic or interactive.\n    ",
        "submission_date": "2017-12-04T00:00:00",
        "last_modified_date": "2017-12-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.00912",
        "title": "Deep Learning Diffuse Optical Tomography",
        "authors": [
            "Jaejun Yoo",
            "Sohail Sabir",
            "Duchang Heo",
            "Kee Hyun Kim",
            "Abdul Wahab",
            "Yoonseok Choi",
            "Seul-I Lee",
            "Eun Young Chae",
            "Hak Hee Kim",
            "Young Min Bae",
            "Young-wook Choi",
            "Seungryong Cho",
            "Jong Chul Ye"
        ],
        "abstract": "Diffuse optical tomography (DOT) has been investigated as an alternative imaging modality for breast cancer detection thanks to its excellent contrast to hemoglobin oxidization level. However, due to the complicated non-linear photon scattering physics and ill-posedness, the conventional reconstruction algorithms are sensitive to imaging parameters such as boundary conditions. To address this, here we propose a novel deep learning approach that learns non-linear photon scattering physics and obtains an accurate three dimensional (3D) distribution of optical anomalies. In contrast to the traditional black-box deep learning approaches, our deep network is designed to invert the Lippman-Schwinger integral equation using the recent mathematical theory of deep convolutional framelets. As an example of clinical relevance, we applied the method to our prototype DOT system. We show that our deep neural network, trained with only simulation data, can accurately recover the location of anomalies within biomimetic phantoms and live animals without the use of an exogenous contrast agent.\n    ",
        "submission_date": "2017-12-04T00:00:00",
        "last_modified_date": "2019-09-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.00991",
        "title": "Mining Supervisor Evaluation and Peer Feedback in Performance Appraisals",
        "authors": [
            "Girish Keshav Palshikar",
            "Sachin Pawar",
            "Saheb Chourasia",
            "Nitin Ramrakhiyani"
        ],
        "abstract": "Performance appraisal (PA) is an important HR process to periodically measure and evaluate every employee's performance vis-a-vis the goals established by the organization. A PA process involves purposeful multi-step multi-modal communication between employees, their supervisors and their peers, such as self-appraisal, supervisor assessment and peer feedback. Analysis of the structured data and text produced in PA is crucial for measuring the quality of appraisals and tracking actual improvements. In this paper, we apply text mining techniques to produce insights from PA text. First, we perform sentence classification to identify strengths, weaknesses and suggestions of improvements found in the supervisor assessments and then use clustering to discover broad categories among them. Next we use multi-class multi-label classification techniques to match supervisor assessments to predefined broad perspectives on performance. Finally, we propose a short-text summarization technique to produce a summary of peer feedback comments for a given employee and compare it with manual summaries. All techniques are illustrated using a real-life dataset of supervisor assessment and peer feedback text produced during the PA of 4528 employees in a large multi-national IT company.\n    ",
        "submission_date": "2017-12-04T00:00:00",
        "last_modified_date": "2017-12-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.01001",
        "title": "Specifying and Computing Causes for Query Answers in Databases via Database Repairs and Repair Programs",
        "authors": [
            "Leopoldo Bertossi"
        ],
        "abstract": "A correspondence between database tuples as causes for query answers in databases and tuple-based repairs of inconsistent databases with respect to denial constraints has already been established. In this work, answer-set programs that specify repairs of databases are used as a basis for solving computational and reasoning problems about causes. Here, causes are also introduced at the attribute level by appealing to a both null-based and attribute-based repair semantics. The corresponding repair programs are presented, and they are used as a basis for computation and reasoning about attribute-level causes. They are extended to deal with the case of causality under integrity constraints.\n    ",
        "submission_date": "2017-12-04T00:00:00",
        "last_modified_date": "2020-09-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.01106",
        "title": "Transferring Autonomous Driving Knowledge on Simulated and Real Intersections",
        "authors": [
            "David Isele",
            "Akansel Cosgun"
        ],
        "abstract": "We view intersection handling on autonomous vehicles as a reinforcement learning problem, and study its behavior in a transfer learning setting. We show that a network trained on one type of intersection generally is not able to generalize to other intersections. However, a network that is pre-trained on one intersection and fine-tuned on another performs better on the new task compared to training in isolation. This network also retains knowledge of the prior task, even though some forgetting occurs. Finally, we show that the benefits of fine-tuning hold when transferring simulated intersection handling knowledge to a real autonomous vehicle.\n    ",
        "submission_date": "2017-11-30T00:00:00",
        "last_modified_date": "2017-11-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.01252",
        "title": "An Equivalence of Fully Connected Layer and Convolutional Layer",
        "authors": [
            "Wei Ma",
            "Jun Lu"
        ],
        "abstract": "This article demonstrates that convolutional operation can be converted to matrix multiplication, which has the same calculation way with fully connected layer. The article is helpful for the beginners of the neural network to understand how fully connected layer and the convolutional layer work in the backend. To be concise and to make the article more readable, we only consider the linear case. It can be extended to the non-linear case easily through plugging in a non-linear encapsulation to the values like this $\\sigma(x)$ denoted as $x^{\\prime}$.\n    ",
        "submission_date": "2017-12-04T00:00:00",
        "last_modified_date": "2017-12-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.01262",
        "title": "Compatibility Family Learning for Item Recommendation and Generation",
        "authors": [
            "Yong-Siang Shih",
            "Kai-Yueh Chang",
            "Hsuan-Tien Lin",
            "Min Sun"
        ],
        "abstract": "Compatibility between items, such as clothes and shoes, is a major factor among customer's purchasing decisions. However, learning \"compatibility\" is challenging due to (1) broader notions of compatibility than those of similarity, (2) the asymmetric nature of compatibility, and (3) only a small set of compatible and incompatible items are observed. We propose an end-to-end trainable system to embed each item into a latent vector and project a query item into K compatible prototypes in the same space. These prototypes reflect the broad notions of compatibility. We refer to both the embedding and prototypes as \"Compatibility Family\". In our learned space, we introduce a novel Projected Compatibility Distance (PCD) function which is differentiable and ensures diversity by aiming for at least one prototype to be close to a compatible item, whereas none of the prototypes are close to an incompatible item. We evaluate our system on a toy dataset, two Amazon product datasets, and Polyvore outfit dataset. Our method consistently achieves state-of-the-art performance. Finally, we show that we can visualize the candidate compatible prototypes using a Metric-regularized Conditional Generative Adversarial Network (MrCGAN), where the input is a projected prototype and the output is a generated image of a compatible item. We ask human evaluators to judge the relative compatibility between our generated images and images generated by CGANs conditioned directly on query items. Our generated images are significantly preferred, with roughly twice the number of votes as others.\n    ",
        "submission_date": "2017-12-02T00:00:00",
        "last_modified_date": "2017-12-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.01275",
        "title": "A Deeper Look at Experience Replay",
        "authors": [
            "Shangtong Zhang",
            "Richard S. Sutton"
        ],
        "abstract": "Recently experience replay is widely used in various deep reinforcement learning (RL) algorithms, in this paper we rethink the utility of experience replay. It introduces a new hyper-parameter, the memory buffer size, which needs carefully tuning. However unfortunately the importance of this new hyper-parameter has been underestimated in the community for a long time. In this paper we did a systematic empirical study of experience replay under various function representations. We showcase that a large replay buffer can significantly hurt the performance. Moreover, we propose a simple O(1) method to remedy the negative influence of a large replay buffer. We showcase its utility in both simple grid world and challenging domains like Atari games.\n    ",
        "submission_date": "2017-12-04T00:00:00",
        "last_modified_date": "2018-04-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.01329",
        "title": "Examining Cooperation in Visual Dialog Models",
        "authors": [
            "Mircea Mironenco",
            "Dana Kianfar",
            "Ke Tran",
            "Evangelos Kanoulas",
            "Efstratios Gavves"
        ],
        "abstract": "In this work we propose a blackbox intervention method for visual dialog models, with the aim of assessing the contribution of individual linguistic or visual components. Concretely, we conduct structured or randomized interventions that aim to impair an individual component of the model, and observe changes in task performance. We reproduce a state-of-the-art visual dialog model and demonstrate that our methodology yields surprising insights, namely that both dialog and image information have minimal contributions to task performance. The intervention method presented here can be applied as a sanity check for the strength and robustness of each component in visual dialog systems.\n    ",
        "submission_date": "2017-12-04T00:00:00",
        "last_modified_date": "2017-12-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.01456",
        "title": "Learning to Fuse Music Genres with Generative Adversarial Dual Learning",
        "authors": [
            "Zhiqian Chen",
            "Chih-Wei Wu",
            "Yen-Cheng Lu",
            "Alexander Lerch",
            "Chang-Tien Lu"
        ],
        "abstract": "FusionGAN is a novel genre fusion framework for music generation that integrates the strengths of generative adversarial networks and dual learning. In particular, the proposed method offers a dual learning extension that can effectively integrate the styles of the given domains. To efficiently quantify the difference among diverse domains and avoid the vanishing gradient issue, FusionGAN provides a Wasserstein based metric to approximate the distance between the target domain and the existing domains. Adopting the Wasserstein distance, a new domain is created by combining the patterns of the existing domains using adversarial learning. Experimental results on public music datasets demonstrated that our approach could effectively merge two genres.\n    ",
        "submission_date": "2017-12-05T00:00:00",
        "last_modified_date": "2017-12-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.01488",
        "title": "Determinism in the Certification of UNSAT Proofs",
        "authors": [
            "Tomer Libal",
            "Xaviera Steele"
        ],
        "abstract": "The search for increased trustworthiness of SAT solvers is very active and uses various methods. Some of these methods obtain a proof from the provers then check it, normally by replicating the search based on the proof's information. Because the certification process involves another nontrivial proof search, the trust we can place in it is decreased. Some attempts to amend this use certifiers which have been verified by proofs assistants such as Isabelle/HOL and Coq. Our approach is different because it is based on an extremely simplified certifier. This certifier enjoys a very high level of trust but is very inefficient. In this paper, we experiment with this approach and conclude that by placing some restrictions on the formats, one can mostly eliminate the need for search and in principle, can certify proofs of arbitrary size.\n    ",
        "submission_date": "2017-12-05T00:00:00",
        "last_modified_date": "2017-12-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.01643",
        "title": "Discriminant Projection Representation-based Classification for Vision Recognition",
        "authors": [
            "Qingxiang Feng",
            "Yicong Zhou"
        ],
        "abstract": "Representation-based classification methods such as sparse representation-based classification (SRC) and linear regression classification (LRC) have attracted a lot of attentions. In order to obtain the better representation, a novel method called projection representation-based classification (PRC) is proposed for image recognition in this paper. PRC is based on a new mathematical model. This model denotes that the 'ideal projection' of a sample point $x$ on the hyper-space $H$ may be gained by iteratively computing the projection of $x$ on a line of hyper-space $H$ with the proper strategy. Therefore, PRC is able to iteratively approximate the 'ideal representation' of each subject for classification. Moreover, the discriminant PRC (DPRC) is further proposed, which obtains the discriminant information by maximizing the ratio of the between-class reconstruction error over the within-class reconstruction error. Experimental results on five typical databases show that the proposed PRC and DPRC are effective and outperform other state-of-the-art methods on several vision recognition tasks.\n    ",
        "submission_date": "2017-11-19T00:00:00",
        "last_modified_date": "2017-11-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.01651",
        "title": "Dilated FCN for Multi-Agent 2D/3D Medical Image Registration",
        "authors": [
            "Shun Miao",
            "Sebastien Piat",
            "Peter Fischer",
            "Ahmet Tuysuzoglu",
            "Philip Mewes",
            "Tommaso Mansi",
            "Rui Liao"
        ],
        "abstract": "2D/3D image registration to align a 3D volume and 2D X-ray images is a challenging problem due to its ill-posed nature and various artifacts presented in 2D X-ray images. In this paper, we propose a multi-agent system with an auto attention mechanism for robust and efficient 2D/3D image registration. Specifically, an individual agent is trained with dilated Fully Convolutional Network (FCN) to perform registration in a Markov Decision Process (MDP) by observing a local region, and the final action is then taken based on the proposals from multiple agents and weighted by their corresponding confidence levels. The contributions of this paper are threefold. First, we formulate 2D/3D registration as a MDP with observations, actions, and rewards properly defined with respect to X-ray imaging systems. Second, to handle various artifacts in 2D X-ray images, multiple local agents are employed efficiently via FCN-based structures, and an auto attention mechanism is proposed to favor the proposals from regions with more reliable visual cues. Third, a dilated FCN-based training mechanism is proposed to significantly reduce the Degree of Freedom in the simulation of registration environment, and drastically improve training efficiency by an order of magnitude compared to standard CNN-based training method. We demonstrate that the proposed method achieves high robustness on both spine cone beam Computed Tomography data with a low signal-to-noise ratio and data from minimally invasive spine surgery where severe image artifacts and occlusions are presented due to metal screws and guide wires, outperforming other state-of-the-art methods (single agent-based and optimization-based) by a large margin.\n    ",
        "submission_date": "2017-11-22T00:00:00",
        "last_modified_date": "2017-11-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.01668",
        "title": "A Novel Brain Decoding Method: a Correlation Network Framework for Revealing Brain Connections",
        "authors": [
            "Siyu Yu",
            "Nanning Zheng",
            "Yongqiang Ma",
            "Hao Wu",
            "Badong Chen"
        ],
        "abstract": "Brain decoding is a hot spot in cognitive science, which focuses on reconstructing perceptual images from brain activities. Analyzing the correlations of collected data from human brain activities and representing activity patterns are two problems in brain decoding based on functional magnetic resonance imaging (fMRI) signals. However, existing correlation analysis methods mainly focus on the strength information of voxel, which reveals functional connectivity in the cerebral cortex. They tend to neglect the structural information that implies the intracortical or intrinsic connections; that is, structural connectivity. Hence, the effective connectivity inferred by these methods is relatively unilateral. Therefore, we proposed a correlation network (CorrNet) framework that could be flexibly combined with diverse pattern representation models. In the CorrNet framework, the topological correlation was introduced to reveal structural information. Rich correlations were obtained, which contributed to specifying the underlying effective connectivity. We also combined the CorrNet framework with a linear support vector machine (SVM) and a dynamic evolving spike neuron network (SNN) for pattern representation separately, thus providing a novel method for decoding cognitive activity patterns. Experimental results verified the reliability and robustness of our CorrNet framework and demonstrated that the new method achieved significant improvement in brain decoding over comparable methods.\n    ",
        "submission_date": "2017-12-01T00:00:00",
        "last_modified_date": "2017-12-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.01694",
        "title": "Fuzzy-Based Dialectical Non-Supervised Image Classification and Clustering",
        "authors": [
            "Wellington Pinheiro dos Santos",
            "Francisco Marcos de Assis",
            "Ricardo Emmanuel de Souza",
            "Priscilla B. Mendes",
            "Henrique S. S. Monteiro",
            "Havana Diogo Alves"
        ],
        "abstract": "The materialist dialectical method is a philosophical investigative method to analyze aspects of reality. These aspects are viewed as complex processes composed by basic units named poles, which interact with each other. Dialectics has experienced considerable progress in the 19th century, with Hegel's dialectics and, in the 20th century, with the works of Marx, Engels, and Gramsci, in Philosophy and Economics. The movement of poles through their contradictions is viewed as a dynamic process with intertwined phases of evolution and revolutionary crisis. In order to build a computational process based on dialectics, the interaction between poles can be modeled using fuzzy membership functions. Based on this assumption, we introduce the Objective Dialectical Classifier (ODC), a non-supervised map for classification based on materialist dialectics and designed as an extension of fuzzy c-means classifier. As a case study, we used ODC to classify 181 magnetic resonance synthetic multispectral images composed by proton density, $T_1$- and $T_2$-weighted synthetic brain images. Comparing ODC to k-means, fuzzy c-means, and Kohonen's self-organized maps, concerning with image fidelity indexes as estimatives of quantization distortion, we proved that ODC can reach almost the same quantization performance as optimal non-supervised classifiers like Kohonen's self-organized maps.\n    ",
        "submission_date": "2017-12-03T00:00:00",
        "last_modified_date": "2017-12-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.01930",
        "title": "Predicting Demographics, Moral Foundations, and Human Values from Digital Behaviors",
        "authors": [
            "Kyriaki Kalimeri",
            "Mariano G. Beiro",
            "Matteo Delfino",
            "Robert Raleigh",
            "Ciro Cattuto"
        ],
        "abstract": "Personal electronic devices including smartphones give access to behavioural signals that can be used to learn about the characteristics and preferences of individuals. In this study, we explore the connection between demographic and psychological attributes and the digital behavioural records, for a cohort of 7,633 people, closely representative of the US population with respect to gender, age, geographical distribution, education, and income. Along with the demographic data, we collected self-reported assessments on validated psychometric questionnaires for moral traits and basic human values and combined this information with passively collected multi-modal digital data from web browsing behaviour and smartphone usage. A machine learning framework was then designed to infer both the demographic and psychological attributes from the behavioural data. In a cross-validated setting, our models predicted demographic attributes with good accuracy as measured by the weighted AUROC score (Area Under the Receiver Operating Characteristic), but were less performant for the moral traits and human values. These results call for further investigation since they are still far from unveiling individuals' psychological fabric. This connection, along with the most predictive features that we provide for each attribute, might prove useful for designing personalised services, communication strategies, and interventions, and can be used to sketch a portrait of people with a similar worldview.\n    ",
        "submission_date": "2017-12-05T00:00:00",
        "last_modified_date": "2018-11-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.01996",
        "title": "An analysis of incorporating an external language model into a sequence-to-sequence model",
        "authors": [
            "Anjuli Kannan",
            "Yonghui Wu",
            "Patrick Nguyen",
            "Tara N. Sainath",
            "Zhifeng Chen",
            "Rohit Prabhavalkar"
        ],
        "abstract": "Attention-based sequence-to-sequence models for automatic speech recognition jointly train an acoustic model, language model, and alignment mechanism. Thus, the language model component is only trained on transcribed audio-text pairs. This leads to the use of shallow fusion with an external language model at inference time. Shallow fusion refers to log-linear interpolation with a separately trained language model at each step of the beam search. In this work, we investigate the behavior of shallow fusion across a range of conditions: different types of language models, different decoding units, and different tasks. On Google Voice Search, we demonstrate that the use of shallow fusion with a neural LM with wordpieces yields a 9.1% relative word error rate reduction (WERR) over our competitive attention-based sequence-to-sequence model, obviating the need for second-pass rescoring.\n    ",
        "submission_date": "2017-12-06T00:00:00",
        "last_modified_date": "2017-12-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.02034",
        "title": "SMILES2Vec: An Interpretable General-Purpose Deep Neural Network for Predicting Chemical Properties",
        "authors": [
            "Garrett B. Goh",
            "Nathan O. Hodas",
            "Charles Siegel",
            "Abhinav Vishnu"
        ],
        "abstract": "Chemical databases store information in text representations, and the SMILES format is a universal standard used in many cheminformatics software. Encoded in each SMILES string is structural information that can be used to predict complex chemical properties. In this work, we develop SMILES2vec, a deep RNN that automatically learns features from SMILES to predict chemical properties, without the need for additional explicit feature engineering. Using Bayesian optimization methods to tune the network architecture, we show that an optimized SMILES2vec model can serve as a general-purpose neural network for predicting distinct chemical properties including toxicity, activity, solubility and solvation energy, while also outperforming contemporary MLP neural networks that uses engineered features. Furthermore, we demonstrate proof-of-concept of interpretability by developing an explanation mask that localizes on the most important characters used in making a prediction. When tested on the solubility dataset, it identified specific parts of a chemical that is consistent with established first-principles knowledge with an accuracy of 88%. Our work demonstrates that neural networks can learn technically accurate chemical concept and provide state-of-the-art accuracy, making interpretable deep neural networks a useful tool of relevance to the chemical industry.\n    ",
        "submission_date": "2017-12-06T00:00:00",
        "last_modified_date": "2018-03-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.02046",
        "title": "Learning General Latent-Variable Graphical Models with Predictive Belief Propagation",
        "authors": [
            "Borui Wang",
            "Geoffrey Gordon"
        ],
        "abstract": "Learning general latent-variable probabilistic graphical models is a key theoretical challenge in machine learning and artificial intelligence. All previous methods, including the EM algorithm and the spectral algorithms, face severe limitations that largely restrict their applicability and affect their performance. In order to overcome these limitations, in this paper we introduce a novel formulation of message-passing inference over junction trees named predictive belief propagation, and propose a new learning and inference algorithm for general latent-variable graphical models based on this formulation. Our proposed algorithm reduces the hard parameter learning problem into a sequence of supervised learning problems, and unifies the learning of different kinds of latent graphical models into a single learning framework, which is local-optima-free and statistically consistent. We then give a proof of the correctness of our algorithm and show in experiments on both synthetic and real datasets that our algorithm significantly outperforms both the EM algorithm and the spectral algorithm while also being orders of magnitude faster to compute.\n    ",
        "submission_date": "2017-12-06T00:00:00",
        "last_modified_date": "2019-11-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.02047",
        "title": "Distance-based Self-Attention Network for Natural Language Inference",
        "authors": [
            "Jinbae Im",
            "Sungzoon Cho"
        ],
        "abstract": "Attention mechanism has been used as an ancillary means to help RNN or CNN. However, the Transformer (Vaswani et al., 2017) recently recorded the state-of-the-art performance in machine translation with a dramatic reduction in training time by solely using attention. Motivated by the Transformer, Directional Self Attention Network (Shen et al., 2017), a fully attention-based sentence encoder, was proposed. It showed good performance with various data by using forward and backward directional information in a sentence. But in their study, not considered at all was the distance between words, an important feature when learning the local dependency to help understand the context of input text. We propose Distance-based Self-Attention Network, which considers the word distance by using a simple distance mask in order to model the local dependency without losing the ability of modeling global dependency which attention has inherent. Our model shows good performance with NLI data, and it records the new state-of-the-art result with SNLI data. Additionally, we show that our model has a strength in long sentences or documents.\n    ",
        "submission_date": "2017-12-06T00:00:00",
        "last_modified_date": "2017-12-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.02224",
        "title": "Human Perception of Performance",
        "authors": [
            "Luca Pappalardo",
            "Paolo Cintia",
            "Dino Pedreschi",
            "Fosca Giannotti",
            "Albert-Laszlo Barabasi"
        ],
        "abstract": "Humans are routinely asked to evaluate the performance of other individuals, separating success from failure and affecting outcomes from science to education and sports. Yet, in many contexts, the metrics driving the human evaluation process remain unclear. Here we analyse a massive dataset capturing players' evaluations by human judges to explore human perception of performance in soccer, the world's most popular sport. We use machine learning to design an artificial judge which accurately reproduces human evaluation, allowing us to demonstrate how human observers are biased towards diverse contextual features. By investigating the structure of the artificial judge, we uncover the aspects of the players' behavior which attract the attention of human judges, demonstrating that human evaluation is based on a noticeability heuristic where only feature values far from the norm are considered to rate an individual's performance.\n    ",
        "submission_date": "2017-12-05T00:00:00",
        "last_modified_date": "2017-12-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.02225",
        "title": "Pose-Normalized Image Generation for Person Re-identification",
        "authors": [
            "Xuelin Qian",
            "Yanwei Fu",
            "Tao Xiang",
            "Wenxuan Wang",
            "Jie Qiu",
            "Yang Wu",
            "Yu-Gang Jiang",
            "Xiangyang Xue"
        ],
        "abstract": "Person Re-identification (re-id) faces two major challenges: the lack of cross-view paired training data and learning discriminative identity-sensitive and view-invariant features in the presence of large pose variations. In this work, we address both problems by proposing a novel deep person image generation model for synthesizing realistic person images conditional on the pose. The model is based on a generative adversarial network (GAN) designed specifically for pose normalization in re-id, thus termed pose-normalization GAN (PN-GAN). With the synthesized images, we can learn a new type of deep re-id feature free of the influence of pose variations. We show that this feature is strong on its own and complementary to features learned with the original images. Importantly, under the transfer learning setting, we show that our model generalizes well to any new re-id dataset without the need for collecting any training data for model fine-tuning. The model thus has the potential to make re-id model truly scalable.\n    ",
        "submission_date": "2017-12-06T00:00:00",
        "last_modified_date": "2018-04-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.02316",
        "title": "Named Entity Sequence Classification",
        "authors": [
            "Mahdi Namazifar"
        ],
        "abstract": "Named Entity Recognition (NER) aims at locating and classifying named entities in text. In some use cases of NER, including cases where detected named entities are used in creating content recommendations, it is crucial to have a reliable confidence level for the detected named entities. In this work we study the problem of finding confidence levels for detected named entities. We refer to this problem as Named Entity Sequence Classification (NESC). We frame NESC as a binary classification problem and we use NER as well as recurrent neural networks to find the probability of candidate named entity is a real named entity. We apply this approach to Tweet texts and we show how we could find named entities with high confidence levels from Tweets.\n    ",
        "submission_date": "2017-12-06T00:00:00",
        "last_modified_date": "2017-12-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.02494",
        "title": "Adversarial Examples that Fool Detectors",
        "authors": [
            "Jiajun Lu",
            "Hussein Sibai",
            "Evan Fabry"
        ],
        "abstract": "An adversarial example is an example that has been adjusted to produce a wrong label when presented to a system at test time. To date, adversarial example constructions have been demonstrated for classifiers, but not for detectors. If adversarial examples that could fool a detector exist, they could be used to (for example) maliciously create security hazards on roads populated with smart vehicles. In this paper, we demonstrate a construction that successfully fools two standard detectors, Faster RCNN and YOLO. The existence of such examples is surprising, as attacking a classifier is very different from attacking a detector, and that the structure of detectors - which must search for their own bounding box, and which cannot estimate that box very accurately - makes it quite likely that adversarial patterns are strongly disrupted. We show that our construction produces adversarial examples that generalize well across sequences digitally, even though large perturbations are needed. We also show that our construction yields physical objects that are adversarial.\n    ",
        "submission_date": "2017-12-07T00:00:00",
        "last_modified_date": "2017-12-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.02734",
        "title": "Using Rule-Based Labels for Weak Supervised Learning: A ChemNet for Transferable Chemical Property Prediction",
        "authors": [
            "Garrett B. Goh",
            "Charles Siegel",
            "Abhinav Vishnu",
            "Nathan O. Hodas"
        ],
        "abstract": "With access to large datasets, deep neural networks (DNN) have achieved human-level accuracy in image and speech recognition tasks. However, in chemistry, data is inherently small and fragmented. In this work, we develop an approach of using rule-based knowledge for training ChemNet, a transferable and generalizable deep neural network for chemical property prediction that learns in a weak-supervised manner from large unlabeled chemical databases. When coupled with transfer learning approaches to predict other smaller datasets for chemical properties that it was not originally trained on, we show that ChemNet's accuracy outperforms contemporary DNN models that were trained using conventional supervised learning. Furthermore, we demonstrate that the ChemNet pre-training approach is equally effective on both CNN (Chemception) and RNN (SMILES2vec) models, indicating that this approach is network architecture agnostic and is effective across multiple data modalities. Our results indicate a pre-trained ChemNet that incorporates chemistry domain knowledge, enables the development of generalizable neural networks for more accurate prediction of novel chemical properties.\n    ",
        "submission_date": "2017-12-07T00:00:00",
        "last_modified_date": "2018-03-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.02820",
        "title": "A Deep Network Model for Paraphrase Detection in Short Text Messages",
        "authors": [
            "Basant Agarwal",
            "Heri Ramampiaro",
            "Helge Langseth",
            "Massimiliano Ruocco"
        ],
        "abstract": "This paper is concerned with paraphrase detection. The ability to detect similar sentences written in natural language is crucial for several applications, such as text mining, text summarization, plagiarism detection, authorship authentication and question answering. Given two sentences, the objective is to detect whether they are semantically identical. An important insight from this work is that existing paraphrase systems perform well when applied on clean texts, but they do not necessarily deliver good performance against noisy texts. Challenges with paraphrase detection on user generated short texts, such as Twitter, include language irregularity and noise. To cope with these challenges, we propose a novel deep neural network-based approach that relies on coarse-grained sentence modeling using a convolutional neural network and a long short-term memory model, combined with a specific fine-grained word-level similarity matching model. Our experimental results show that the proposed approach outperforms existing state-of-the-art approaches on user-generated noisy social media data, such as Twitter texts, and achieves highly competitive performance on a cleaner corpus.\n    ",
        "submission_date": "2017-12-07T00:00:00",
        "last_modified_date": "2017-12-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.03010",
        "title": "Coordinate Descent with Bandit Sampling",
        "authors": [
            "Farnood Salehi",
            "Patrick Thiran",
            "L. Elisa Celis"
        ],
        "abstract": "Coordinate descent methods usually minimize a cost function by updating a random decision variable (corresponding to one coordinate) at a time. Ideally, we would update the decision variable that yields the largest decrease in the cost function. However, finding this coordinate would require checking all of them, which would effectively negate the improvement in computational tractability that coordinate descent is intended to afford. To address this, we propose a new adaptive method for selecting a coordinate. First, we find a lower bound on the amount the cost function decreases when a coordinate is updated. We then use a multi-armed bandit algorithm to learn which coordinates result in the largest lower bound by interleaving this learning with conventional coordinate descent updates except that the coordinate is selected proportionately to the expected decrease. We show that our approach improves the convergence of coordinate descent methods both theoretically and experimentally.\n    ",
        "submission_date": "2017-12-08T00:00:00",
        "last_modified_date": "2018-12-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.03086",
        "title": "FlagIt: A System for Minimally Supervised Human Trafficking Indicator Mining",
        "authors": [
            "Mayank Kejriwal",
            "Jiayuan Ding",
            "Runqi Shao",
            "Anoop Kumar",
            "Pedro Szekely"
        ],
        "abstract": "In this paper, we describe and study the indicator mining problem in the online sex advertising domain. We present an in-development system, FlagIt (Flexible and adaptive generation of Indicators from text), which combines the benefits of both a lightweight expert system and classical semi-supervision (heuristic re-labeling) with recently released state-of-the-art unsupervised text embeddings to tag millions of sentences with indicators that are highly correlated with human trafficking. The FlagIt technology stack is open source. On preliminary evaluations involving five indicators, FlagIt illustrates promising performance compared to several alternatives. The system is being actively developed, refined and integrated into a domain-specific search system used by over 200 law enforcement agencies to combat human trafficking, and is being aggressively extended to mine at least six more indicators with minimal programming effort. FlagIt is a good example of a system that operates in limited label settings, and that requires creative combinations of established machine learning techniques to produce outputs that could be used by real-world non-technical analysts.\n    ",
        "submission_date": "2017-12-05T00:00:00",
        "last_modified_date": "2017-12-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.03132",
        "title": "A Class of Logistic Functions for Approximating State-Inclusive Koopman Operators",
        "authors": [
            "Charles A. Johnson",
            "Enoch Yeung"
        ],
        "abstract": "An outstanding challenge in nonlinear systems theory is identification or learning of a given nonlinear system's Koopman operator directly from data or models. Advances in extended dynamic mode decomposition approaches and machine learning methods have enabled data-driven discovery of Koopman operators, for both continuous and discrete-time systems. Since Koopman operators are often infinite-dimensional, they are approximated in practice using finite-dimensional systems. The fidelity and convergence of a given finite-dimensional Koopman approximation is a subject of ongoing research. In this paper we introduce a class of Koopman observable functions that confer an approximate closure property on their corresponding finite-dimensional approximations of the Koopman operator. We derive error bounds for the fidelity of this class of observable functions, as well as identify two key learning parameters which can be used to tune performance. We illustrate our approach on two classical nonlinear system models: the Van Der Pol oscillator and the bistable toggle switch.\n    ",
        "submission_date": "2017-12-08T00:00:00",
        "last_modified_date": "2017-12-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.03133",
        "title": "Building competitive direct acoustics-to-word models for English conversational speech recognition",
        "authors": [
            "Kartik Audhkhasi",
            "Brian Kingsbury",
            "Bhuvana Ramabhadran",
            "George Saon",
            "Michael Picheny"
        ],
        "abstract": "Direct acoustics-to-word (A2W) models in the end-to-end paradigm have received increasing attention compared to conventional sub-word based automatic speech recognition models using phones, characters, or context-dependent hidden Markov model states. This is because A2W models recognize words from speech without any decoder, pronunciation lexicon, or externally-trained language model, making training and decoding with such models simple. Prior work has shown that A2W models require orders of magnitude more training data in order to perform comparably to conventional models. Our work also showed this accuracy gap when using the English Switchboard-Fisher data set. This paper describes a recipe to train an A2W model that closes this gap and is at-par with state-of-the-art sub-word based models. We achieve a word error rate of 8.8%/13.9% on the Hub5-2000 Switchboard/CallHome test sets without any decoder or language model. We find that model initialization, training data order, and regularization have the most impact on the A2W model performance. Next, we present a joint word-character A2W model that learns to first spell the word and then recognize it. This model provides a rich output to the user instead of simple word hypotheses, making it especially useful in the case of words unseen or rarely-seen during training.\n    ",
        "submission_date": "2017-12-08T00:00:00",
        "last_modified_date": "2017-12-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.03333",
        "title": "Assumed Density Filtering Q-learning",
        "authors": [
            "Heejin Jeong",
            "Clark Zhang",
            "George J. Pappas",
            "Daniel D. Lee"
        ],
        "abstract": "While off-policy temporal difference (TD) methods have widely been used in reinforcement learning due to their efficiency and simple implementation, their Bayesian counterparts have not been utilized as frequently. One reason is that the non-linear max operation in the Bellman optimality equation makes it difficult to define conjugate distributions over the value functions. In this paper, we introduce a novel Bayesian approach to off-policy TD methods, called as ADFQ, which updates beliefs on state-action values, Q, through an online Bayesian inference method known as Assumed Density Filtering. We formulate an efficient closed-form solution for the value update by approximately estimating analytic parameters of the posterior of the Q-beliefs. Uncertainty measures in the beliefs not only are used in exploration but also provide a natural regularization for the value update considering all next available actions. ADFQ converges to Q-learning as the uncertainty measures of the Q-beliefs decrease and improves common drawbacks of other Bayesian RL algorithms such as computational complexity. We extend ADFQ with a neural network. Our empirical results demonstrate that ADFQ outperforms comparable algorithms on various Atari 2600 games, with drastic improvements in highly stochastic domains or domains with a large action space.\n    ",
        "submission_date": "2017-12-09T00:00:00",
        "last_modified_date": "2019-06-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.03390",
        "title": "NAG: Network for Adversary Generation",
        "authors": [
            "Konda Reddy Mopuri",
            "Utkarsh Ojha",
            "Utsav Garg",
            "R. Venkatesh Babu"
        ],
        "abstract": "Adversarial perturbations can pose a serious threat for deploying machine learning systems. Recent works have shown existence of image-agnostic perturbations that can fool classifiers over most natural images. Existing methods present optimization approaches that solve for a fooling objective with an imperceptibility constraint to craft the perturbations. However, for a given classifier, they generate one perturbation at a time, which is a single instance from the manifold of adversarial perturbations. Also, in order to build robust models, it is essential to explore the manifold of adversarial perturbations. In this paper, we propose for the first time, a generative approach to model the distribution of adversarial perturbations. The architecture of the proposed model is inspired from that of GANs and is trained using fooling and diversity objectives. Our trained generator network attempts to capture the distribution of adversarial perturbations for a given classifier and readily generates a wide variety of such perturbations. Our experimental evaluation demonstrates that perturbations crafted by our model (i) achieve state-of-the-art fooling rates, (ii) exhibit wide variety and (iii) deliver excellent cross model generalizability. Our work can be deemed as an important step in the process of inferring about the complex manifolds of adversarial perturbations.\n    ",
        "submission_date": "2017-12-09T00:00:00",
        "last_modified_date": "2018-03-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.03608",
        "title": "Towards Fully Environment-Aware UAVs: Real-Time Path Planning with Online 3D Wind Field Prediction in Complex Terrain",
        "authors": [
            "Philipp Oettershagen",
            "Florian Achermann",
            "Benjamin M\u00fcller",
            "Daniel Schneider",
            "Roland Siegwart"
        ],
        "abstract": "Today, low-altitude fixed-wing Unmanned Aerial Vehicles (UAVs) are largely limited to primitively follow user-defined waypoints. To allow fully-autonomous remote missions in complex environments, real-time environment-aware navigation is required both with respect to terrain and strong wind drafts. This paper presents two relevant initial contributions: First, the literature's first-ever 3D wind field prediction method which can run in real time onboard a UAV is presented. The approach retrieves low-resolution global weather data, and uses potential flow theory to adjust the wind field such that terrain boundaries, mass conservation, and the atmospheric stratification are observed. A comparison with 1D LIDAR data shows an overall wind error reduction of 23% with respect to the zero-wind assumption that is mostly used for UAV path planning today. However, given that the vertical winds are not resolved accurately enough further research is required and identified. Second, a sampling-based path planner that considers the aircraft dynamics in non-uniform wind iteratively via Dubins airplane paths is presented. Performance optimizations, e.g. obstacle-aware sampling and fast 2.5D-map collision checks, render the planner 50% faster than the Open Motion Planning Library (OMPL) implementation. Test cases in Alpine terrain show that the wind-aware planning performs up to 50x less iterations than shortest-path planning and is thus slower in low winds, but that it tends to deliver lower-cost paths in stronger winds. More importantly, in contrast to the shortest-path planner, it always delivers collision-free paths. Overall, our initial research demonstrates the feasibility of 3D wind field prediction from a UAV and the advantages of wind-aware planning. This paves the way for follow-up research on fully-autonomous environment-aware navigation of UAVs in real-life missions and complex terrain.\n    ",
        "submission_date": "2017-12-10T00:00:00",
        "last_modified_date": "2017-12-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.03632",
        "title": "Robust Deep Reinforcement Learning with Adversarial Attacks",
        "authors": [
            "Anay Pattanaik",
            "Zhenyi Tang",
            "Shuijing Liu",
            "Gautham Bommannan",
            "Girish Chowdhary"
        ],
        "abstract": "This paper proposes adversarial attacks for Reinforcement Learning (RL) and then improves the robustness of Deep Reinforcement Learning algorithms (DRL) to parameter uncertainties with the help of these attacks. We show that even a naively engineered attack successfully degrades the performance of DRL algorithm. We further improve the attack using gradient information of an engineered loss function which leads to further degradation in performance. These attacks are then leveraged during training to improve the robustness of RL within robust control framework. We show that this adversarial training of DRL algorithms like Deep Double Q learning and Deep Deterministic Policy Gradients leads to significant increase in robustness to parameter variations for RL benchmarks such as Cart-pole, Mountain Car, Hopper and Half Cheetah environment.\n    ",
        "submission_date": "2017-12-11T00:00:00",
        "last_modified_date": "2017-12-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.03719",
        "title": "A novel model-based heuristic for energy optimal motion planning for automated driving",
        "authors": [
            "Zlatan Ajanovic",
            "Michael Stolz",
            "Martin Horn"
        ],
        "abstract": "Predictive motion planning is the key to achieve energy-efficient driving, which is one of the main benefits of automated driving. Researchers have been studying the planning of velocity trajectories, a simpler form of motion planning, for over a decade now and many different methods are available. Dynamic programming has shown to be the most common choice due to its numerical background and ability to include nonlinear constraints and models. Although planning of an optimal trajectory is done in a systematic way, dynamic programming does not use any knowledge about the considered problem to guide the exploration and therefore explores all possible trajectories.\n",
        "submission_date": "2017-12-11T00:00:00",
        "last_modified_date": "2018-03-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.03724",
        "title": "Cogniculture: Towards a Better Human-Machine Co-evolution",
        "authors": [
            "Rakesh R Pimplikar",
            "Kushal Mukherjee",
            "Gyana Parija",
            "Harit Vishwakarma",
            "Ramasuri Narayanam",
            "Sarthak Ahuja",
            "Rohith D Vallam",
            "Ritwik Chaudhuri",
            "Joydeep Mondal"
        ],
        "abstract": "Research in Artificial Intelligence is breaking technology barriers every day. New algorithms and high performance computing are making things possible which we could only have imagined earlier. Though the enhancements in AI are making life easier for human beings day by day, there is constant fear that AI based systems will pose a threat to humanity. People in AI community have diverse set of opinions regarding the pros and cons of AI mimicking human behavior. Instead of worrying about AI advancements, we propose a novel idea of cognitive agents, including both human and machines, living together in a complex adaptive ecosystem, collaborating on human computation for producing essential social goods while promoting sustenance, survival and evolution of the agents' life cycle. We highlight several research challenges and technology barriers in achieving this goal. We propose a governance mechanism around this ecosystem to ensure ethical behaviors of all cognitive agents. Along with a novel set of use-cases of Cogniculture, we discuss the road map ahead for this journey.\n    ",
        "submission_date": "2017-12-11T00:00:00",
        "last_modified_date": "2017-12-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.03779",
        "title": "Artificial Intelligence and Statistics",
        "authors": [
            "Bin Yu",
            "Karl Kumbier"
        ],
        "abstract": "Artificial intelligence (AI) is intrinsically data-driven. It calls for the application of statistical concepts through human-machine collaboration during generation of data, development of algorithms, and evaluation of results. This paper discusses how such human-machine collaboration can be approached through the statistical concepts of population, question of interest, representativeness of training data, and scrutiny of results (PQRS). The PQRS workflow provides a conceptual framework for integrating statistical ideas with human input into AI products and research. These ideas include experimental design principles of randomization and local control as well as the principle of stability to gain reproducibility and interpretability of algorithms and data results. We discuss the use of these principles in the contexts of self-driving cars, automated medical diagnoses, and examples from the authors' collaborative research.\n    ",
        "submission_date": "2017-12-08T00:00:00",
        "last_modified_date": "2017-12-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.03781",
        "title": "NestedNet: Learning Nested Sparse Structures in Deep Neural Networks",
        "authors": [
            "Eunwoo Kim",
            "Chanho Ahn",
            "Songhwai Oh"
        ],
        "abstract": "Recently, there have been increasing demands to construct compact deep architectures to remove unnecessary redundancy and to improve the inference speed. While many recent works focus on reducing the redundancy by eliminating unneeded weight parameters, it is not possible to apply a single deep architecture for multiple devices with different resources. When a new device or circumstantial condition requires a new deep architecture, it is necessary to construct and train a new network from scratch. In this work, we propose a novel deep learning framework, called a nested sparse network, which exploits an n-in-1-type nested structure in a neural network. A nested sparse network consists of multiple levels of networks with a different sparsity ratio associated with each level, and higher level networks share parameters with lower level networks to enable stable nested learning. The proposed framework realizes a resource-aware versatile architecture as the same network can meet diverse resource requirements. Moreover, the proposed nested network can learn different forms of knowledge in its internal networks at different levels, enabling multiple tasks using a single network, such as coarse-to-fine hierarchical classification. In order to train the proposed nested sparse network, we propose efficient weight connection learning and channel and layer scheduling strategies. We evaluate our network in multiple tasks, including adaptive deep compression, knowledge distillation, and learning class hierarchy, and demonstrate that nested sparse networks perform competitively, but more efficiently, compared to existing methods.\n    ",
        "submission_date": "2017-12-11T00:00:00",
        "last_modified_date": "2018-03-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.03890",
        "title": "DeepConfig: Automating Data Center Network Topologies Management with Machine Learning",
        "authors": [
            "Christopher Streiffer",
            "Huan Chen",
            "Theophilus Benson",
            "Asim Kadav"
        ],
        "abstract": "In recent years, many techniques have been developed to improve the performance and efficiency of data center networks. While these techniques provide high accuracy, they are often designed using heuristics that leverage domain-specific properties of the workload or hardware.\n",
        "submission_date": "2017-12-11T00:00:00",
        "last_modified_date": "2017-12-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.03931",
        "title": "MINOS: Multimodal Indoor Simulator for Navigation in Complex Environments",
        "authors": [
            "Manolis Savva",
            "Angel X. Chang",
            "Alexey Dosovitskiy",
            "Thomas Funkhouser",
            "Vladlen Koltun"
        ],
        "abstract": "We present MINOS, a simulator designed to support the development of multisensory models for goal-directed navigation in complex indoor environments. The simulator leverages large datasets of complex 3D environments and supports flexible configuration of multimodal sensor suites. We use MINOS to benchmark deep-learning-based navigation methods, to analyze the influence of environmental complexity on navigation performance, and to carry out a controlled study of multimodality in sensorimotor learning. The experiments show that current deep reinforcement learning approaches fail in large realistic environments. The experiments also indicate that multimodality is beneficial in learning to navigate cluttered scenes. MINOS is released open-source to the research community at ",
        "submission_date": "2017-12-11T00:00:00",
        "last_modified_date": "2017-12-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.04008",
        "title": "Investigating the Impact of Data Volume and Domain Similarity on Transfer Learning Applications",
        "authors": [
            "Michael Bernico",
            "Yuntao Li",
            "Dingchao Zhang"
        ],
        "abstract": "Transfer learning allows practitioners to recognize and apply knowledge learned in previous tasks (source task) to new tasks or new domains (target task), which share some commonality. The two important factors impacting the performance of transfer learning models are: (a) the size of the target dataset, and (b) the similarity in distribution between source and target domains. Thus far, there has been little investigation into just how important these factors are. In this paper, we investigate the impact of target dataset size and source/target domain similarity on model performance through a series of experiments. We find that more data is always beneficial, and model performance improves linearly with the log of data size, until we are out of data. As source/target domains differ, more data is required and fine tuning will render better performance than feature extraction. When source/target domains are similar and data size is small, fine tuning and feature extraction renders equivalent performance. Our hope is that by beginning this quantitative investigation on the effect of data volume and domain similarity in transfer learning we might inspire others to explore the significance of data in developing more accurate statistical models.\n    ",
        "submission_date": "2017-12-11T00:00:00",
        "last_modified_date": "2018-05-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.04034",
        "title": "Learning Robust Dialog Policies in Noisy Environments",
        "authors": [
            "Maryam Fazel-Zarandi",
            "Shang-Wen Li",
            "Jin Cao",
            "Jared Casale",
            "Peter Henderson",
            "David Whitney",
            "Alborz Geramifard"
        ],
        "abstract": "Modern virtual personal assistants provide a convenient interface for completing daily tasks via voice commands. An important consideration for these assistants is the ability to recover from automatic speech recognition (ASR) and natural language understanding (NLU) errors. In this paper, we focus on learning robust dialog policies to recover from these errors. To this end, we develop a user simulator which interacts with the assistant through voice commands in realistic scenarios with noisy audio, and use it to learn dialog policies through deep reinforcement learning. We show that dialogs generated by our simulator are indistinguishable from human generated dialogs, as determined by human evaluators. Furthermore, preliminary experimental results show that the learned policies in noisy environments achieve the same execution success rate with fewer dialog turns compared to fixed rule-based policies.\n    ",
        "submission_date": "2017-12-11T00:00:00",
        "last_modified_date": "2017-12-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.04076",
        "title": "In a Nutshell -- The Sequential Parameter Optimization Toolbox",
        "authors": [
            "Thomas Bartz-Beielstein",
            "Martin Zaefferer",
            "Frederik Rehbach"
        ],
        "abstract": "The performance of optimization algorithms relies crucially on their parameterizations. Finding good parameter settings is called algorithm tuning. The sequential parameter optimization (SPOT) package for R is a toolbox for tuning and understanding simulation and optimization algorithms. Model-based investigations are common approaches in simulation and optimization. Sequential parameter optimization has been developed, because there is a strong need for sound statistical analysis of simulation and optimization algorithms. SPOT includes methods for tuning based on classical regression and analysis of variance techniques; tree-based models such as CART and random forest; Gaussian process models (Kriging), and combinations of different meta-modeling approaches. Using a simple simulated annealing algorithm, we will demonstrate how optimization algorithms can be tuned using SPOT. The underling concepts of the SPOT approach are explained. This includes key techniques such as exploratory fitness landscape analysis and sensititvity analysis. Many examples illustrate how SPOT can be used for understanding the performance of algorithms and gaining insight into algorithm's behavior. Furthermore, we demonstrate how SPOT can be used as an optimizer and how a sophisticated ensemble approach is able to combine several meta models via stacking. This article exemplifies how SPOT can be used for automatic and interactive tuning.\n    ",
        "submission_date": "2017-12-12T00:00:00",
        "last_modified_date": "2021-03-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.04143",
        "title": "Benchmarking Single Image Dehazing and Beyond",
        "authors": [
            "Boyi Li",
            "Wenqi Ren",
            "Dengpan Fu",
            "Dacheng Tao",
            "Dan Feng",
            "Wenjun Zeng",
            "Zhangyang Wang"
        ],
        "abstract": "We present a comprehensive study and evaluation of existing single image dehazing algorithms, using a new large-scale benchmark consisting of both synthetic and real-world hazy images, called REalistic Single Image DEhazing (RESIDE). RESIDE highlights diverse data sources and image contents, and is divided into five subsets, each serving different training or evaluation purposes. We further provide a rich variety of criteria for dehazing algorithm evaluation, ranging from full-reference metrics, to no-reference metrics, to subjective evaluation and the novel task-driven evaluation. Experiments on RESIDE shed light on the comparisons and limitations of state-of-the-art dehazing algorithms, and suggest promising future directions.\n    ",
        "submission_date": "2017-12-12T00:00:00",
        "last_modified_date": "2019-04-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.04159",
        "title": "Mining Non-Redundant Local Process Models From Sequence Databases",
        "authors": [
            "Niek Tax",
            "Marlon Dumas"
        ],
        "abstract": "Sequential pattern mining techniques extract patterns corresponding to frequent subsequences from a sequence database. A practical limitation of these techniques is that they overload the user with too many patterns. Local Process Model (LPM) mining is an alternative approach coming from the field of process mining. While in traditional sequential pattern mining, a pattern describes one subsequence, an LPM captures a set of subsequences. Also, while traditional sequential patterns only match subsequences that are observed in the sequence database, an LPM may capture subsequences that are not explicitly observed, but that are related to observed subsequences. In other words, LPMs generalize the behavior observed in the sequence database. These properties make it possible for a set of LPMs to cover the behavior of a much larger set of sequential patterns. Yet, existing LPM mining techniques still suffer from the pattern explosion problem because they produce sets of redundant LPMs. In this paper, we propose several heuristics to mine a set of non-redundant LPMs either from a set of redundant LPMs or from a set of sequential patterns. We empirically compare the proposed heuristics between them and against existing (local) process mining techniques in terms of coverage, redundancy, and complexity of the produced sets of LPMs.\n    ",
        "submission_date": "2017-12-12T00:00:00",
        "last_modified_date": "2018-09-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.04323",
        "title": "Deep Echo State Network (DeepESN): A Brief Survey",
        "authors": [
            "Claudio Gallicchio",
            "Alessio Micheli"
        ],
        "abstract": "The study of deep recurrent neural networks (RNNs) and, in particular, of deep Reservoir Computing (RC) is gaining an increasing research attention in the neural networks community. The recently introduced Deep Echo State Network (DeepESN) model opened the way to an extremely efficient approach for designing deep neural networks for temporal data. At the same time, the study of DeepESNs allowed to shed light on the intrinsic properties of state dynamics developed by hierarchical compositions of recurrent layers, i.e. on the bias of depth in RNNs architectural design. In this paper, we summarize the advancements in the development, analysis and applications of DeepESNs.\n    ",
        "submission_date": "2017-12-12T00:00:00",
        "last_modified_date": "2020-09-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.04386",
        "title": "Hawkes Processes for Invasive Species Modeling and Management",
        "authors": [
            "Amrita Gupta",
            "Mehrdad Farajtabar",
            "Bistra Dilkina",
            "Hongyuan Zha"
        ],
        "abstract": "The spread of invasive species to new areas threatens the stability of ecosystems and causes major economic losses in agriculture and forestry. We propose a novel approach to minimizing the spread of an invasive species given a limited intervention budget. We first model invasive species propagation using Hawkes processes, and then derive closed-form expressions for characterizing the effect of an intervention action on the invasion process. We use this to obtain an optimal intervention plan based on an integer programming formulation, and compare the optimal plan against several ecologically-motivated heuristic strategies used in practice. We present an empirical study of two variants of the invasive control problem: minimizing the final rate of invasions, and minimizing the number of invasions at the end of a given time horizon. Our results show that the optimized intervention achieves nearly the same level of control that would be attained by completely eradicating the species, with a 20% cost saving. Additionally, we design a heuristic intervention strategy based on a combination of the density and life stage of the invasive individuals, and find that it comes surprisingly close to the optimized strategy, suggesting that this could serve as a good rule of thumb in invasive species management.\n    ",
        "submission_date": "2017-12-12T00:00:00",
        "last_modified_date": "2017-12-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.04402",
        "title": "Android Malware Characterization using Metadata and Machine Learning Techniques",
        "authors": [
            "Ignacio Mart\u00edn",
            "Jos\u00e9 Alberto Hern\u00e1ndez",
            "Alfonso Mu\u00f1oz",
            "Antonio Guzm\u00e1n"
        ],
        "abstract": "Android Malware has emerged as a consequence of the increasing popularity of smartphones and tablets. While most previous work focuses on inherent characteristics of Android apps to detect malware, this study analyses indirect features and meta-data to identify patterns in malware applications. Our experiments show that: (1) the permissions used by an application offer only moderate performance results; (2) other features publicly available at Android Markets are more relevant in detecting malware, such as the application developer and certificate issuer, and (3) compact and efficient classifiers can be constructed for the early detection of malware applications prior to code inspection or sandboxing.\n    ",
        "submission_date": "2017-12-12T00:00:00",
        "last_modified_date": "2017-12-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.04443",
        "title": "Sequential Prediction of Social Media Popularity with Deep Temporal Context Networks",
        "authors": [
            "Bo Wu",
            "Wen-Huang Cheng",
            "Yongdong Zhang",
            "Qiushi Huang",
            "Jintao Li",
            "Tao Mei"
        ],
        "abstract": "Prediction of popularity has profound impact for social media, since it offers opportunities to reveal individual preference and public attention from evolutionary social systems. Previous research, although achieves promising results, neglects one distinctive characteristic of social data, i.e., sequentiality. For example, the popularity of online content is generated over time with sequential post streams of social media. To investigate the sequential prediction of popularity, we propose a novel prediction framework called Deep Temporal Context Networks (DTCN) by incorporating both temporal context and temporal attention into account. Our DTCN contains three main components, from embedding, learning to predicting. With a joint embedding network, we obtain a unified deep representation of multi-modal user-post data in a common embedding space. Then, based on the embedded data sequence over time, temporal context learning attempts to recurrently learn two adaptive temporal contexts for sequential popularity. Finally, a novel temporal attention is designed to predict new popularity (the popularity of a new user-post pair) with temporal coherence across multiple time-scales. Experiments on our released image dataset with about 600K Flickr photos demonstrate that DTCN outperforms state-of-the-art deep prediction algorithms, with an average of 21.51% relative performance improvement in the popularity prediction (Spearman Ranking Correlation).\n    ",
        "submission_date": "2017-12-12T00:00:00",
        "last_modified_date": "2017-12-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.04603",
        "title": "Multi-focus Attention Network for Efficient Deep Reinforcement Learning",
        "authors": [
            "Jinyoung Choi",
            "Beom-Jin Lee",
            "Byoung-Tak Zhang"
        ],
        "abstract": "Deep reinforcement learning (DRL) has shown incredible performance in learning various tasks to the human level. However, unlike human perception, current DRL models connect the entire low-level sensory input to the state-action values rather than exploiting the relationship between and among entities that constitute the sensory input. Because of this difference, DRL needs vast amount of experience samples to learn. In this paper, we propose a Multi-focus Attention Network (MANet) which mimics human ability to spatially abstract the low-level sensory input into multiple entities and attend to them simultaneously. The proposed method first divides the low-level input into several segments which we refer to as partial states. After this segmentation, parallel attention layers attend to the partial states relevant to solving the task. Our model estimates state-action values using these attended partial states. In our experiments, MANet attains highest scores with significantly less experience samples. Additionally, the model shows higher performance compared to the Deep Q-network and the single attention model as benchmarks. Furthermore, we extend our model to attentive communication model for performing multi-agent cooperative tasks. In multi-agent cooperative task experiments, our model shows 20% faster learning than existing state-of-the-art model.\n    ",
        "submission_date": "2017-12-13T00:00:00",
        "last_modified_date": "2017-12-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.04612",
        "title": "Inverse Reinforcement Learning for Marketing",
        "authors": [
            "Igor Halperin"
        ],
        "abstract": "Learning customer preferences from an observed behaviour is an important topic in the marketing literature. Structural models typically model forward-looking customers or firms as utility-maximizing agents whose utility is estimated using methods of Stochastic Optimal Control. We suggest an alternative approach to study dynamic consumer demand, based on Inverse Reinforcement Learning (IRL). We develop a version of the Maximum Entropy IRL that leads to a highly tractable model formulation that amounts to low-dimensional convex optimization in the search for optimal model parameters. Using simulations of consumer demand, we show that observational noise for identical customers can be easily confused with an apparent consumer heterogeneity.\n    ",
        "submission_date": "2017-12-13T00:00:00",
        "last_modified_date": "2017-12-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.05087",
        "title": "Learning Binary Residual Representations for Domain-specific Video Streaming",
        "authors": [
            "Yi-Hsuan Tsai",
            "Ming-Yu Liu",
            "Deqing Sun",
            "Ming-Hsuan Yang",
            "Jan Kautz"
        ],
        "abstract": "We study domain-specific video streaming. Specifically, we target a streaming setting where the videos to be streamed from a server to a client are all in the same domain and they have to be compressed to a small size for low-latency transmission. Several popular video streaming services, such as the video game streaming services of GeForce Now and Twitch, fall in this category. While conventional video compression standards such as H.264 are commonly used for this task, we hypothesize that one can leverage the property that the videos are all in the same domain to achieve better video quality. Based on this hypothesis, we propose a novel video compression pipeline. Specifically, we first apply H.264 to compress domain-specific videos. We then train a novel binary autoencoder to encode the leftover domain-specific residual information frame-by-frame into binary representations. These binary representations are then compressed and sent to the client together with the H.264 stream. In our experiments, we show that our pipeline yields consistent gains over standard H.264 compression across several benchmark datasets while using the same channel bandwidth.\n    ",
        "submission_date": "2017-12-14T00:00:00",
        "last_modified_date": "2017-12-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.05181",
        "title": "Rasa: Open Source Language Understanding and Dialogue Management",
        "authors": [
            "Tom Bocklisch",
            "Joey Faulkner",
            "Nick Pawlowski",
            "Alan Nichol"
        ],
        "abstract": "We introduce a pair of tools, Rasa NLU and Rasa Core, which are open source python libraries for building conversational software. Their purpose is to make machine-learning based dialogue management and language understanding accessible to non-specialist software developers. In terms of design philosophy, we aim for ease of use, and bootstrapping from minimal (or no) initial training data. Both packages are extensively documented and ship with a comprehensive suite of tests. The code is available at ",
        "submission_date": "2017-12-14T00:00:00",
        "last_modified_date": "2017-12-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.05191",
        "title": "Relation Extraction : A Survey",
        "authors": [
            "Sachin Pawar",
            "Girish K. Palshikar",
            "Pushpak Bhattacharyya"
        ],
        "abstract": "With the advent of the Internet, large amount of digital text is generated everyday in the form of news articles, research publications, blogs, question answering forums and social media. It is important to develop techniques for extracting information automatically from these documents, as lot of important information is hidden within them. This extracted information can be used to improve access and management of knowledge hidden in large text corpora. Several applications such as Question Answering, Information Retrieval would benefit from this information. Entities like persons and organizations, form the most basic unit of the information. Occurrences of entities in a sentence are often linked through well-defined relations; e.g., occurrences of person and organization in a sentence may be linked through relations such as employed at. The task of Relation Extraction (RE) is to identify such relations automatically. In this paper, we survey several important supervised, semi-supervised and unsupervised RE techniques. We also cover the paradigms of Open Information Extraction (OIE) and Distant Supervision. Finally, we describe some of the recent trends in the RE techniques and possible future research directions. This survey would be useful for three kinds of readers - i) Newcomers in the field who want to quickly learn about RE; ii) Researchers who want to know how the various RE techniques evolved over time and what are possible future research directions and iii) Practitioners who just need to know which RE technique works best in various settings.\n    ",
        "submission_date": "2017-12-14T00:00:00",
        "last_modified_date": "2017-12-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.05249",
        "title": "Proximodistal Exploration in Motor Learning as an Emergent Property of Optimization",
        "authors": [
            "Freek Stulp",
            "Pierre-Yves Oudeyer"
        ],
        "abstract": "To harness the complexity of their high-dimensional bodies during sensorimotor development, infants are guided by patterns of freezing and freeing of degrees of freedom. For instance, when learning to reach, infants free the degrees of freedom in their arm proximodistally, i.e. from joints that are closer to the body to those that are more distant. Here, we formulate and study computationally the hypothesis that such patterns can emerge spontaneously as the result of a family of stochastic optimization processes (evolution strategies with covariance-matrix adaptation), without an innate encoding of a maturational schedule. In particular, we present simulated experiments with an arm where a computational learner progressively acquires reaching skills through adaptive exploration, and we show that a proximodistal organization appears spontaneously, which we denote PDFF (ProximoDistal Freezing and Freeing of degrees of freedom). We also compare this emergent organization between different arm morphologies -- from human-like to quite unnatural ones -- to study the effect of different kinematic structures on the emergence of PDFF. Keywords: human motor learning; proximo-distal exploration; stochastic optimization; modelling; evolution strategies; cross-entropy methods; policy search; morphology.}\n    ",
        "submission_date": "2017-12-14T00:00:00",
        "last_modified_date": "2017-12-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.05291",
        "title": "A Bayesian Clearing Mechanism for Combinatorial Auctions",
        "authors": [
            "Gianluca Brero",
            "S\u00e9bastien Lahaie"
        ],
        "abstract": "We cast the problem of combinatorial auction design in a Bayesian framework in order to incorporate prior information into the auction process and minimize the number of rounds to convergence. We first develop a generative model of agent valuations and market prices such that clearing prices become maximum a posteriori estimates given observed agent valuations. This generative model then forms the basis of an auction process which alternates between refining estimates of agent valuations and computing candidate clearing prices. We provide an implementation of the auction using assumed density filtering to estimate valuations and expectation maximization to compute prices. An empirical evaluation over a range of valuation domains demonstrates that our Bayesian auction mechanism is highly competitive against the combinatorial clock auction in terms of rounds to convergence, even under the most favorable choices of price increment for this baseline.\n    ",
        "submission_date": "2017-12-14T00:00:00",
        "last_modified_date": "2018-11-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.05403",
        "title": "Learning to Attend via Word-Aspect Associative Fusion for Aspect-based Sentiment Analysis",
        "authors": [
            "Yi Tay",
            "Anh Tuan Luu",
            "Siu Cheung Hui"
        ],
        "abstract": "Aspect-based sentiment analysis (ABSA) tries to predict the polarity of a given document with respect to a given aspect entity. While neural network architectures have been successful in predicting the overall polarity of sentences, aspect-specific sentiment analysis still remains as an open problem. In this paper, we propose a novel method for integrating aspect information into the neural model. More specifically, we incorporate aspect information into the neural model by modeling word-aspect relationships. Our novel model, \\textit{Aspect Fusion LSTM} (AF-LSTM) learns to attend based on associative relationships between sentence words and aspect which allows our model to adaptively focus on the correct words given an aspect term. This ameliorates the flaws of other state-of-the-art models that utilize naive concatenations to model word-aspect similarity. Instead, our model adopts circular convolution and circular correlation to model the similarity between aspect and words and elegantly incorporates this within a differentiable neural attention framework. Finally, our model is end-to-end differentiable and highly related to convolution-correlation (holographic like) memories. Our proposed neural model achieves state-of-the-art performance on benchmark datasets, outperforming ATAE-LSTM by $4\\%-5\\%$ on average across multiple datasets.\n    ",
        "submission_date": "2017-12-14T00:00:00",
        "last_modified_date": "2017-12-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.05474",
        "title": "AI2-THOR: An Interactive 3D Environment for Visual AI",
        "authors": [
            "Eric Kolve",
            "Roozbeh Mottaghi",
            "Winson Han",
            "Eli VanderBilt",
            "Luca Weihs",
            "Alvaro Herrasti",
            "Matt Deitke",
            "Kiana Ehsani",
            "Daniel Gordon",
            "Yuke Zhu",
            "Aniruddha Kembhavi",
            "Abhinav Gupta",
            "Ali Farhadi"
        ],
        "abstract": "We introduce The House Of inteRactions (THOR), a framework for visual AI research, available at ",
        "submission_date": "2017-12-14T00:00:00",
        "last_modified_date": "2022-08-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.05558",
        "title": "CoDraw: Collaborative Drawing as a Testbed for Grounded Goal-driven Communication",
        "authors": [
            "Jin-Hwa Kim",
            "Nikita Kitaev",
            "Xinlei Chen",
            "Marcus Rohrbach",
            "Byoung-Tak Zhang",
            "Yuandong Tian",
            "Dhruv Batra",
            "Devi Parikh"
        ],
        "abstract": "In this work, we propose a goal-driven collaborative task that combines language, perception, and action. Specifically, we develop a Collaborative image-Drawing game between two agents, called CoDraw. Our game is grounded in a virtual world that contains movable clip art objects. The game involves two players: a Teller and a Drawer. The Teller sees an abstract scene containing multiple clip art pieces in a semantically meaningful configuration, while the Drawer tries to reconstruct the scene on an empty canvas using available clip art pieces. The two players communicate with each other using natural language. We collect the CoDraw dataset of ~10K dialogs consisting of ~138K messages exchanged between human players. We define protocols and metrics to evaluate learned agents in this testbed, highlighting the need for a novel \"crosstalk\" evaluation condition which pairs agents trained independently on disjoint subsets of the training data. We present models for our task and benchmark them using both fully automated evaluation and by having them play the game live with humans.\n    ",
        "submission_date": "2017-12-15T00:00:00",
        "last_modified_date": "2019-06-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.05695",
        "title": "Lightweight Neural Networks",
        "authors": [
            "Altaf H. Khan"
        ],
        "abstract": "Most of the weights in a Lightweight Neural Network have a value of zero, while the remaining ones are either +1 or -1. These universal approximators require approximately 1.1 bits/weight of storage, posses a quick forward pass and achieve classification accuracies similar to conventional continuous-weight networks. Their training regimen focuses on error reduction initially, but later emphasizes discretization of weights. They ignore insignificant inputs, remove unnecessary weights, and drop unneeded hidden neurons. We have successfully tested them on the MNIST, credit card fraud, and credit card defaults data sets using networks having 2 to 16 hidden layers and up to 4.4 million weights.\n    ",
        "submission_date": "2017-12-15T00:00:00",
        "last_modified_date": "2017-12-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.05734",
        "title": "Information Processing by Networks of Quantum Decision Makers",
        "authors": [
            "V.I. Yukalov",
            "E.P. Yukalova",
            "D. Sornette"
        ],
        "abstract": "We suggest a model of a multi-agent society of decision makers taking decisions being based on two criteria, one is the utility of the prospects and the other is the attractiveness of the considered prospects. The model is the generalization of quantum decision theory, developed earlier for single decision makers realizing one-step decisions, in two principal aspects. First, several decision makers are considered simultaneously, who interact with each other through information exchange. Second, a multistep procedure is treated, when the agents exchange information many times. Several decision makers exchanging information and forming their judgement, using quantum rules, form a kind of a quantum information network, where collective decisions develop in time as a result of information exchange. In addition to characterizing collective decisions that arise in human societies, such networks can describe dynamical processes occurring in artificial quantum intelligence composed of several parts or in a cluster of quantum computers. The practical usage of the theory is illustrated on the dynamic disjunction effect for which three quantitative predictions are made: (i) the probabilistic behavior of decision makers at the initial stage of the process is described; (ii) the decrease of the difference between the initial prospect probabilities and the related utility factors is proved; (iii) the existence of a common consensus after multiple exchange of information is predicted. The predicted numerical values are in very good agreement with empirical data.\n    ",
        "submission_date": "2017-12-15T00:00:00",
        "last_modified_date": "2017-12-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.05785",
        "title": "Sentiment Predictability for Stocks",
        "authors": [
            "Jordan Prosky",
            "Xingyou Song",
            "Andrew Tan",
            "Michael Zhao"
        ],
        "abstract": "In this work, we present our findings and experiments for stock-market prediction using various textual sentiment analysis tools, such as mood analysis and event extraction, as well as prediction models, such as LSTMs and specific convolutional architectures.\n    ",
        "submission_date": "2017-12-15T00:00:00",
        "last_modified_date": "2018-01-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.05889",
        "title": "Ray: A Distributed Framework for Emerging AI Applications",
        "authors": [
            "Philipp Moritz",
            "Robert Nishihara",
            "Stephanie Wang",
            "Alexey Tumanov",
            "Richard Liaw",
            "Eric Liang",
            "Melih Elibol",
            "Zongheng Yang",
            "William Paul",
            "Michael I. Jordan",
            "Ion Stoica"
        ],
        "abstract": "The next generation of AI applications will continuously interact with the environment and learn from these interactions. These applications impose new and demanding systems requirements, both in terms of performance and flexibility. In this paper, we consider these requirements and present Ray---a distributed system to address them. Ray implements a unified interface that can express both task-parallel and actor-based computations, supported by a single dynamic execution engine. To meet the performance requirements, Ray employs a distributed scheduler and a distributed and fault-tolerant store to manage the system's control state. In our experiments, we demonstrate scaling beyond 1.8 million tasks per second and better performance than existing specialized systems for several challenging reinforcement learning applications.\n    ",
        "submission_date": "2017-12-16T00:00:00",
        "last_modified_date": "2018-09-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.06015",
        "title": "StackInsights: Cognitive Learning for Hybrid Cloud Readiness",
        "authors": [
            "Mu Qiao",
            "Luis Bathen",
            "Simon-Pierre G\u00e9not",
            "Sunhwan Lee",
            "Ramani Routray"
        ],
        "abstract": "Hybrid cloud is an integrated cloud computing environment utilizing a mix of public cloud, private cloud, and on-premise traditional IT infrastructures. Workload awareness, defined as a detailed full range understanding of each individual workload, is essential in implementing the hybrid cloud. While it is critical to perform an accurate analysis to determine which workloads are appropriate for on-premise deployment versus which workloads can be migrated to a cloud off-premise, the assessment is mainly performed by rule or policy based approaches. In this paper, we introduce StackInsights, a novel cognitive system to automatically analyze and predict the cloud readiness of workloads for an enterprise. Our system harnesses the critical metrics across the entire stack: 1) infrastructure metrics, 2) data relevance metrics, and 3) application taxonomy, to identify workloads that have characteristics of a) low sensitivity with respect to business security, criticality and compliance, and b) low response time requirements and access patterns. Since the capture of the data relevance metrics involves an intrusive and in-depth scanning of the content of storage objects, a machine learning model is applied to perform the business relevance classification by learning from the meta level metrics harnessed across stack. In contrast to traditional methods, StackInsights significantly reduces the total time for hybrid cloud readiness assessment by orders of magnitude.\n    ",
        "submission_date": "2017-12-16T00:00:00",
        "last_modified_date": "2017-12-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.06028",
        "title": "A Spectral Approach for the Design of Experiments: Design, Analysis and Algorithms",
        "authors": [
            "Bhavya Kailkhura",
            "Jayaraman J. Thiagarajan",
            "Charvi Rastogi",
            "Pramod K. Varshney",
            "Peer-Timo Bremer"
        ],
        "abstract": "This paper proposes a new approach to construct high quality space-filling sample designs. First, we propose a novel technique to quantify the space-filling property and optimally trade-off uniformity and randomness in sample designs in arbitrary dimensions. Second, we connect the proposed metric (defined in the spatial domain) to the objective measure of the design performance (defined in the spectral domain). This connection serves as an analytic framework for evaluating the qualitative properties of space-filling designs in general. Using the theoretical insights provided by this spatial-spectral analysis, we derive the notion of optimal space-filling designs, which we refer to as space-filling spectral designs. Third, we propose an efficient estimator to evaluate the space-filling properties of sample designs in arbitrary dimensions and use it to develop an optimization framework to generate high quality space-filling designs. Finally, we carry out a detailed performance comparison on two different applications in 2 to 6 dimensions: a) image reconstruction and b) surrogate modeling on several benchmark optimization functions and an inertial confinement fusion (ICF) simulation code. We demonstrate that the propose spectral designs significantly outperform existing approaches especially in high dimensions.\n    ",
        "submission_date": "2017-12-16T00:00:00",
        "last_modified_date": "2017-12-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.06096",
        "title": "Efficient B-mode Ultrasound Image Reconstruction from Sub-sampled RF Data using Deep Learning",
        "authors": [
            "Yeo Hun Yoon",
            "Shujaat Khan",
            "Jaeyoung Huh",
            "Jong Chul Ye"
        ],
        "abstract": "In portable, three dimensional, and ultra-fast ultrasound imaging systems, there is an increasing demand for the reconstruction of high quality images from a limited number of radio-frequency (RF) measurements due to receiver (Rx) or transmit (Xmit) event sub-sampling. However, due to the presence of side lobe artifacts from RF sub-sampling, the standard beamformer often produces blurry images with less contrast, which are unsuitable for diagnostic purposes. Existing compressed sensing approaches often require either hardware changes or computationally expensive algorithms, but their quality improvements are limited. To address this problem, here we propose a novel deep learning approach that directly interpolates the missing RF data by utilizing redundancy in the Rx-Xmit plane. Our extensive experimental results using sub-sampled RF data from a multi-line acquisition B-mode system confirm that the proposed method can effectively reduce the data rate without sacrificing image quality.\n    ",
        "submission_date": "2017-12-17T00:00:00",
        "last_modified_date": "2018-08-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.06228",
        "title": "Visual Explanations from Hadamard Product in Multimodal Deep Networks",
        "authors": [
            "Jin-Hwa Kim",
            "Byoung-Tak Zhang"
        ],
        "abstract": "The visual explanation of learned representation of models helps to understand the fundamentals of learning. The attentional models of previous works used to visualize the attended regions over an image or text using their learned weights to confirm their intended mechanism. Kim et al. (2016) show that the Hadamard product in multimodal deep networks, which is well-known for the joint function of visual question answering tasks, implicitly performs an attentional mechanism for visual inputs. In this work, we extend their work to show that the Hadamard product in multimodal deep networks performs not only for visual inputs but also for textual inputs simultaneously using the proposed gradient-based visualization technique. The attentional effect of Hadamard product is visualized for both visual and textual inputs by analyzing the two inputs and an output of the Hadamard product with the proposed method and compared with learned attentional weights of a visual question answering model.\n    ",
        "submission_date": "2017-12-18T00:00:00",
        "last_modified_date": "2017-12-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.06272",
        "title": "Automated flow for compressing convolution neural networks for efficient edge-computation with FPGA",
        "authors": [
            "Farhan Shafiq",
            "Takato Yamada",
            "Antonio T. Vilchez",
            "Sakyasingha Dasgupta"
        ],
        "abstract": "Deep convolutional neural networks (CNN) based solutions are the current state- of-the-art for computer vision tasks. Due to the large size of these models, they are typically run on clusters of CPUs or GPUs. However, power requirements and cost budgets can be a major hindrance in adoption of CNN for IoT applications. Recent research highlights that CNN contain significant redundancy in their structure and can be quantized to lower bit-width parameters and activations, while maintaining acceptable accuracy. Low bit-width and especially single bit-width (binary) CNN are particularly suitable for mobile applications based on FPGA implementation, due to the bitwise logic operations involved in binarized CNN. Moreover, the transition to lower bit-widths opens new avenues for performance optimizations and model improvement. In this paper, we present an automatic flow from trained TensorFlow models to FPGA system on chip implementation of binarized CNN. This flow involves quantization of model parameters and activations, generation of network and model in embedded-C, followed by automatic generation of the FPGA accelerator for binary convolutions. The automated flow is demonstrated through implementation of binarized \"YOLOV2\" on the low cost, low power Cyclone- V FPGA device. Experiments on object detection using binarized YOLOV2 demonstrate significant performance benefit in terms of model size and inference speed on FPGA as compared to CPU and mobile CPU platforms. Furthermore, the entire automated flow from trained models to FPGA synthesis can be completed within one hour.\n    ",
        "submission_date": "2017-12-18T00:00:00",
        "last_modified_date": "2017-12-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.06536",
        "title": "Nonparametric Inference for Auto-Encoding Variational Bayes",
        "authors": [
            "Erik Bodin",
            "Iman Malik",
            "Carl Henrik Ek",
            "Neill D. F. Campbell"
        ],
        "abstract": "We would like to learn latent representations that are low-dimensional and highly interpretable. A model that has these characteristics is the Gaussian Process Latent Variable Model. The benefits and negative of the GP-LVM are complementary to the Variational Autoencoder, the former provides interpretable low-dimensional latent representations while the latter is able to handle large amounts of data and can use non-Gaussian likelihoods. Our inspiration for this paper is to marry these two approaches and reap the benefits of both. In order to do so we will introduce a novel approximate inference scheme inspired by the GP-LVM and the VAE. We show experimentally that the approximation allows the capacity of the generative bottle-neck (Z) of the VAE to be arbitrarily large without losing a highly interpretable representation, allowing reconstruction quality to be unlimited by Z at the same time as a low-dimensional space can be used to perform ancestral sampling from as well as a means to reason about the embedded data.\n    ",
        "submission_date": "2017-12-18T00:00:00",
        "last_modified_date": "2017-12-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.06563",
        "title": "Safe Mutations for Deep and Recurrent Neural Networks through Output Gradients",
        "authors": [
            "Joel Lehman",
            "Jay Chen",
            "Jeff Clune",
            "Kenneth O. Stanley"
        ],
        "abstract": "While neuroevolution (evolving neural networks) has a successful track record across a variety of domains from reinforcement learning to artificial life, it is rarely applied to large, deep neural networks. A central reason is that while random mutation generally works in low dimensions, a random perturbation of thousands or millions of weights is likely to break existing functionality, providing no learning signal even if some individual weight changes were beneficial. This paper proposes a solution by introducing a family of safe mutation (SM) operators that aim within the mutation operator itself to find a degree of change that does not alter network behavior too much, but still facilitates exploration. Importantly, these SM operators do not require any additional interactions with the environment. The most effective SM variant capitalizes on the intriguing opportunity to scale the degree of mutation of each individual weight according to the sensitivity of the network's outputs to that weight, which requires computing the gradient of outputs with respect to the weights (instead of the gradient of error, as in conventional deep learning). This safe mutation through gradients (SM-G) operator dramatically increases the ability of a simple genetic algorithm-based neuroevolution method to find solutions in high-dimensional domains that require deep and/or recurrent neural networks (which tend to be particularly brittle to mutation), including domains that require processing raw pixels. By improving our ability to evolve deep neural networks, this new safer approach to mutation expands the scope of domains amenable to neuroevolution.\n    ",
        "submission_date": "2017-12-18T00:00:00",
        "last_modified_date": "2018-05-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.06568",
        "title": "ES Is More Than Just a Traditional Finite-Difference Approximator",
        "authors": [
            "Joel Lehman",
            "Jay Chen",
            "Jeff Clune",
            "Kenneth O. Stanley"
        ],
        "abstract": "An evolution strategy (ES) variant based on a simplification of a natural evolution strategy recently attracted attention because it performs surprisingly well in challenging deep reinforcement learning domains. It searches for neural network parameters by generating perturbations to the current set of parameters, checking their performance, and moving in the aggregate direction of higher reward. Because it resembles a traditional finite-difference approximation of the reward gradient, it can naturally be confused with one. However, this ES optimizes for a different gradient than just reward: It optimizes for the average reward of the entire population, thereby seeking parameters that are robust to perturbation. This difference can channel ES into distinct areas of the search space relative to gradient descent, and also consequently to networks with distinct properties. This unique robustness-seeking property, and its consequences for optimization, are demonstrated in several domains. They include humanoid locomotion, where networks from policy gradient-based reinforcement learning are significantly less robust to parameter perturbation than ES-based policies solving the same task. While the implications of such robustness and robustness-seeking remain open to further study, this work's main contribution is to highlight such differences and their potential importance.\n    ",
        "submission_date": "2017-12-18T00:00:00",
        "last_modified_date": "2018-05-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.06577",
        "title": "Parallel Complexity of Forward and Backward Propagation",
        "authors": [
            "Maxim Naumov"
        ],
        "abstract": "We show that the forward and backward propagation can be formulated as a solution of lower and upper triangular systems of equations. For standard feedforward (FNNs) and recurrent neural networks (RNNs) the triangular systems are always block bi-diagonal, while for a general computation graph (directed acyclic graph) they can have a more complex triangular sparsity pattern. We discuss direct and iterative parallel algorithms that can be used for their solution and interpreted as different ways of performing model parallelism. Also, we show that for FNNs and RNNs with $k$ layers and $\\tau$ time steps the backward propagation can be performed in parallel in O($\\log k$) and O($\\log k \\log \\tau$) steps, respectively. Finally, we outline the generalization of this technique using Jacobians that potentially allows us to handle arbitrary layers.\n    ",
        "submission_date": "2017-12-18T00:00:00",
        "last_modified_date": "2017-12-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.06868",
        "title": "Heinrich Behmann's Contributions to Second-Order Quantifier Elimination from the View of Computational Logic",
        "authors": [
            "Christoph Wernhard"
        ],
        "abstract": "For relational monadic formulas (the L\u00f6wenheim class) second-order quantifier elimination, which is closely related to computation of uniform interpolants, projection and forgetting - operations that currently receive much attention in knowledge processing - always succeeds. The decidability proof for this class by Heinrich Behmann from 1922 explicitly proceeds by elimination with equivalence preserving formula rewriting. Here we reconstruct the results from Behmann's publication in detail and discuss related issues that are relevant in the context of modern approaches to second-order quantifier elimination in computational logic. In addition, an extensive documentation of the letters and manuscripts in Behmann's bequest that concern second-order quantifier elimination is given, including a commented register and English abstracts of the German sources with focus on technical material. In the late 1920s Behmann attempted to develop an elimination-based decision method for formulas with predicates whose arity is larger than one. His manuscripts and the correspondence with Wilhelm Ackermann show technical aspects that are still of interest today and give insight into the genesis of Ackermann's landmark paper \"Untersuchungen \u00fcber das Eliminationsproblem der mathematischen Logik\" from 1935, which laid the foundation of the two prevailing modern approaches to second-order quantifier elimination.\n    ",
        "submission_date": "2017-12-19T00:00:00",
        "last_modified_date": "2017-12-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.06924",
        "title": "Safe Policy Improvement with Baseline Bootstrapping",
        "authors": [
            "Romain Laroche",
            "Paul Trichelair",
            "R\u00e9mi Tachet des Combes"
        ],
        "abstract": "This paper considers Safe Policy Improvement (SPI) in Batch Reinforcement Learning (Batch RL): from a fixed dataset and without direct access to the true environment, train a policy that is guaranteed to perform at least as well as the baseline policy used to collect the data. Our approach, called SPI with Baseline Bootstrapping (SPIBB), is inspired by the knows-what-it-knows paradigm: it bootstraps the trained policy with the baseline when the uncertainty is high. Our first algorithm, $\\Pi_b$-SPIBB, comes with SPI theoretical guarantees. We also implement a variant, $\\Pi_{\\leq b}$-SPIBB, that is even more efficient in practice. We apply our algorithms to a motivational stochastic gridworld domain and further demonstrate on randomly generated MDPs the superiority of SPIBB with respect to existing algorithms, not only in safety but also in mean performance. Finally, we implement a model-free version of SPIBB and show its benefits on a navigation task with deep RL implementation called SPIBB-DQN, which is, to the best of our knowledge, the first RL algorithm relying on a neural network representation able to train efficiently and reliably from batch data, without any interaction with the environment.\n    ",
        "submission_date": "2017-12-19T00:00:00",
        "last_modified_date": "2019-06-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.06957",
        "title": "MURA: Large Dataset for Abnormality Detection in Musculoskeletal Radiographs",
        "authors": [
            "Pranav Rajpurkar",
            "Jeremy Irvin",
            "Aarti Bagul",
            "Daisy Ding",
            "Tony Duan",
            "Hershel Mehta",
            "Brandon Yang",
            "Kaylie Zhu",
            "Dillon Laird",
            "Robyn L. Ball",
            "Curtis Langlotz",
            "Katie Shpanskaya",
            "Matthew P. Lungren",
            "Andrew Y. Ng"
        ],
        "abstract": "We introduce MURA, a large dataset of musculoskeletal radiographs containing 40,561 images from 14,863 studies, where each study is manually labeled by radiologists as either normal or abnormal. To evaluate models robustly and to get an estimate of radiologist performance, we collect additional labels from six board-certified Stanford radiologists on the test set, consisting of 207 musculoskeletal studies. On this test set, the majority vote of a group of three radiologists serves as gold standard. We train a 169-layer DenseNet baseline model to detect and localize abnormalities. Our model achieves an AUROC of 0.929, with an operating point of 0.815 sensitivity and 0.887 specificity. We compare our model and radiologists on the Cohen's kappa statistic, which expresses the agreement of our model and of each radiologist with the gold standard. Model performance is comparable to the best radiologist performance in detecting abnormalities on finger and wrist studies. However, model performance is lower than best radiologist performance in detecting abnormalities on elbow, forearm, hand, humerus, and shoulder studies. We believe that the task is a good challenge for future research. To encourage advances, we have made our dataset freely available at ",
        "submission_date": "2017-12-11T00:00:00",
        "last_modified_date": "2018-05-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.07004",
        "title": "Any-gram Kernels for Sentence Classification: A Sentiment Analysis Case Study",
        "authors": [
            "Rasoul Kaljahi",
            "Jennifer Foster"
        ],
        "abstract": "Any-gram kernels are a flexible and efficient way to employ bag-of-n-gram features when learning from textual data. They are also compatible with the use of word embeddings so that word similarities can be accounted for. While the original any-gram kernels are implemented on top of tree kernels, we propose a new approach which is independent of tree kernels and is more efficient. We also propose a more effective way to make use of word embeddings than the original any-gram formulation. When applied to the task of sentiment classification, our new formulation achieves significantly better performance.\n    ",
        "submission_date": "2017-12-19T00:00:00",
        "last_modified_date": "2017-12-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.07019",
        "title": "PSO-Optimized Hopfield Neural Network-Based Multipath Routing for Mobile Ad-hoc Networks",
        "authors": [
            "Mansour Sheikhan",
            "Ehsan Hemmati"
        ],
        "abstract": "Mobile ad-hoc network (MANET) is a dynamic collection of mobile computers without the need for any existing infrastructure. Nodes in a MANET act as hosts and routers. Designing of robust routing algorithms for MANETs is a challenging task. Disjoint multipath routing protocols address this problem and increase the reliability, security and lifetime of network. However, selecting an optimal multipath is an NP-complete problem. In this paper, Hopfield neural network (HNN) which its parameters are optimized by particle swarm optimization (PSO) algorithm is proposed as multipath routing algorithm. Link expiration time (LET) between each two nodes is used as the link reliability estimation metric. This approach can find either node-disjoint or link-disjoint paths in single phase route discovery. Simulation results confirm that PSO-HNN routing algorithm has better performance as compared to backup path set selection algorithm (BPSA) in terms of the path set reliability and number of paths in the set.\n    ",
        "submission_date": "2017-11-16T00:00:00",
        "last_modified_date": "2017-11-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.07040",
        "title": "The NarrativeQA Reading Comprehension Challenge",
        "authors": [
            "Tom\u00e1\u0161 Ko\u010disk\u00fd",
            "Jonathan Schwarz",
            "Phil Blunsom",
            "Chris Dyer",
            "Karl Moritz Hermann",
            "G\u00e1bor Melis",
            "Edward Grefenstette"
        ],
        "abstract": "Reading comprehension (RC)---in contrast to information retrieval---requires integrating information and reasoning about events, entities, and their relations across a full document. Question answering is conventionally used to assess RC ability, in both artificial agents and children learning to read. However, existing RC datasets and tasks are dominated by questions that can be solved by selecting answers using superficial information (e.g., local context similarity or global term frequency); they thus fail to test for the essential integrative aspect of RC. To encourage progress on deeper comprehension of language, we present a new dataset and set of tasks in which the reader must answer questions about stories by reading entire books or movie scripts. These tasks are designed so that successfully answering their questions requires understanding the underlying narrative rather than relying on shallow pattern matching or salience. We show that although humans solve the tasks easily, standard RC models struggle on the tasks presented here. We provide an analysis of the dataset and the challenges it presents.\n    ",
        "submission_date": "2017-12-19T00:00:00",
        "last_modified_date": "2017-12-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.07199",
        "title": "Cognitive Database: A Step towards Endowing Relational Databases with Artificial Intelligence Capabilities",
        "authors": [
            "Rajesh Bordawekar",
            "Bortik Bandyopadhyay",
            "Oded Shmueli"
        ],
        "abstract": "We propose Cognitive Databases, an approach for transparently enabling Artificial Intelligence (AI) capabilities in relational databases. A novel aspect of our design is to first view the structured data source as meaningful unstructured text, and then use the text to build an unsupervised neural network model using a Natural Language Processing (NLP) technique called word embedding. This model captures the hidden inter-/intra-column relationships between database tokens of different types. For each database token, the model includes a vector that encodes contextual semantic relationships. We seamlessly integrate the word embedding model into existing SQL query infrastructure and use it to enable a new class of SQL-based analytics queries called cognitive intelligence (CI) queries. CI queries use the model vectors to enable complex queries such as semantic matching, inductive reasoning queries such as analogies, predictive queries using entities not present in a database, and, more generally, using knowledge from external sources. We demonstrate unique capabilities of Cognitive Databases using an Apache Spark based prototype to execute inductive reasoning CI queries over a multi-modal database containing text and images. We believe our first-of-a-kind system exemplifies using AI functionality to endow relational databases with capabilities that were previously very hard to realize in practice.\n    ",
        "submission_date": "2017-12-19T00:00:00",
        "last_modified_date": "2017-12-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.07296",
        "title": "Block-diagonal Hessian-free Optimization for Training Neural Networks",
        "authors": [
            "Huishuai Zhang",
            "Caiming Xiong",
            "James Bradbury",
            "Richard Socher"
        ],
        "abstract": "Second-order methods for neural network optimization have several advantages over methods based on first-order gradient descent, including better scaling to large mini-batch sizes and fewer updates needed for convergence. But they are rarely applied to deep learning in practice because of high computational cost and the need for model-dependent algorithmic variations. We introduce a variant of the Hessian-free method that leverages a block-diagonal approximation of the generalized Gauss-Newton matrix. Our method computes the curvature approximation matrix only for pairs of parameters from the same layer or block of the neural network and performs conjugate gradient updates independently for each block. Experiments on deep autoencoders, deep convolutional networks, and multilayer LSTMs demonstrate better convergence and generalization compared to the original Hessian-free approach and the Adam method.\n    ",
        "submission_date": "2017-12-20T00:00:00",
        "last_modified_date": "2017-12-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.07312",
        "title": "Analysis of supervised and semi-supervised GrowCut applied to segmentation of masses in mammography images",
        "authors": [
            "Filipe Rolim Cordeiro",
            "Wellington Pinheiro dos Santos",
            "Abel Guilhermino da Silva Filho"
        ],
        "abstract": "Breast cancer is already one of the most common form of cancer worldwide. Mammography image analysis is still the most effective diagnostic method to promote the early detection of breast cancer. Accurately segmenting tumors in digital mammography images is important to improve diagnosis capabilities of health specialists and avoid misdiagnosis. In this work, we evaluate the feasibility of applying GrowCut to segment regions of tumor and we propose two GrowCut semi-supervised versions. All the analysis was performed by evaluating the application of segmentation techniques to a set of images obtained from the Mini-MIAS mammography image database. GrowCut segmentation was compared to Region Growing, Active Contours, Random Walks and Graph Cut techniques. Experiments showed that GrowCut, when compared to the other techniques, was able to acquire better results for the metrics analyzed. Moreover, the proposed semi-supervised versions of GrowCut was proved to have a clinically satisfactory quality of segmentation.\n    ",
        "submission_date": "2017-12-20T00:00:00",
        "last_modified_date": "2017-12-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.07452",
        "title": "Self-Supervised Damage-Avoiding Manipulation Strategy Optimization via Mental Simulation",
        "authors": [
            "Tobias Doernbach"
        ],
        "abstract": "Everyday robotics are challenged to deal with autonomous product handling in applications like logistics or retail, possibly causing damage on the items during manipulation. Traditionally, most approaches try to minimize physical interaction with goods. However, this paper proposes to take into account any unintended object motion and to learn damage-minimizing manipulation strategies in a self-supervised way. The presented approach consists of a simulation-based planning method for an optimal manipulation sequence with respect to possible damage. The planned manipulation sequences are generalized to new, unseen scenes in the same application scenario using machine learning. This learned manipulation strategy is continuously refined in a self-supervised, simulation-in-the-loop optimization cycle during load-free times of the system, commonly known as mental simulation. In parallel, the generated manipulation strategies can be deployed in near-real time in an anytime fashion. The approach is validated on an industrial container-unloading scenario and on a retail shelf-replenishment scenario.\n    ",
        "submission_date": "2017-12-20T00:00:00",
        "last_modified_date": "2019-08-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.07745",
        "title": "Context-aware Path Ranking for Knowledge Base Completion",
        "authors": [
            "Sahisnu Mazumder",
            "Bing Liu"
        ],
        "abstract": "Knowledge base (KB) completion aims to infer missing facts from existing ones in a KB. Among various approaches, path ranking (PR) algorithms have received increasing attention in recent years. PR algorithms enumerate paths between entity pairs in a KB and use those paths as features to train a model for missing fact prediction. Due to their good performances and high model interpretability, several methods have been proposed. However, most existing methods suffer from scalability (high RAM consumption) and feature explosion (trains on an exponentially large number of features) problems. This paper proposes a Context-aware Path Ranking (C-PR) algorithm to solve these problems by introducing a selective path exploration strategy. C-PR learns global semantics of entities in the KB using word embedding and leverages the knowledge of entity semantics to enumerate contextually relevant paths using bidirectional random walk. Experimental results on three large KBs show that the path features (fewer in number) discovered by C-PR not only improve predictive performance but also are more interpretable than existing baselines.\n    ",
        "submission_date": "2017-12-20T00:00:00",
        "last_modified_date": "2017-12-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.07770",
        "title": "Bit-Vector Model Counting using Statistical Estimation",
        "authors": [
            "Seonmo Kim",
            "Stephen McCamant"
        ],
        "abstract": "Approximate model counting for bit-vector SMT formulas (generalizing \\#SAT) has many applications such as probabilistic inference and quantitative information-flow security, but it is computationally difficult. Adding random parity constraints (XOR streamlining) and then checking satisfiability is an effective approximation technique, but it requires a prior hypothesis about the model count to produce useful results. We propose an approach inspired by statistical estimation to continually refine a probabilistic estimate of the model count for a formula, so that each XOR-streamlined query yields as much information as possible. We implement this approach, with an approximate probability model, as a wrapper around an off-the-shelf SMT solver or SAT solver. Experimental results show that the implementation is faster than the most similar previous approaches which used simpler refinement strategies. The technique also lets us model count formulas over floating-point constraints, which we demonstrate with an application to a vulnerability in differential privacy mechanisms.\n    ",
        "submission_date": "2017-12-21T00:00:00",
        "last_modified_date": "2017-12-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.07822",
        "title": "Geometrical Insights for Implicit Generative Modeling",
        "authors": [
            "Leon Bottou",
            "Martin Arjovsky",
            "David Lopez-Paz",
            "Maxime Oquab"
        ],
        "abstract": "Learning algorithms for implicit generative models can optimize a variety of criteria that measure how the data distribution differs from the implicit model distribution, including the Wasserstein distance, the Energy distance, and the Maximum Mean Discrepancy criterion. A careful look at the geometries induced by these distances on the space of probability measures reveals interesting differences. In particular, we can establish surprising approximate global convergence guarantees for the $1$-Wasserstein distance,even when the parametric generator has a nonconvex parametrization.\n    ",
        "submission_date": "2017-12-21T00:00:00",
        "last_modified_date": "2019-08-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.07887",
        "title": "Multiagent-based Participatory Urban Simulation through Inverse Reinforcement Learning",
        "authors": [
            "Soma Suzuki"
        ],
        "abstract": "The multiagent-based participatory simulation features prominently in urban planning as the acquired model is considered as the hybrid system of the domain and the local knowledge. However, the key problem of generating realistic agents for particular social phenomena invariably remains. The existing models have attempted to dictate the factors involving human behavior, which appeared to be intractable. In this paper, Inverse Reinforcement Learning (IRL) is introduced to address this problem. IRL is developed for computational modeling of human behavior and has achieved great successes in robotics, psychology and machine learning. The possibilities presented by this new style of modeling are drawn out as conclusions, and the relative challenges with this modeling are highlighted.\n    ",
        "submission_date": "2017-12-21T00:00:00",
        "last_modified_date": "2017-12-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.08163",
        "title": "Reachable Set Computation and Safety Verification for Neural Networks with ReLU Activations",
        "authors": [
            "Weiming Xiang",
            "Hoang-Dung Tran",
            "Taylor T. Johnson"
        ],
        "abstract": "Neural networks have been widely used to solve complex real-world problems. Due to the complicate, nonlinear, non-convex nature of neural networks, formal safety guarantees for the output behaviors of neural networks will be crucial for their applications in safety-critical ",
        "submission_date": "2017-12-21T00:00:00",
        "last_modified_date": "2017-12-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.08164",
        "title": "Multi-task learning of time series and its application to the travel demand",
        "authors": [
            "Boris Chidlovskii"
        ],
        "abstract": "We address the problem of modeling and prediction of a set of temporal events in the context of intelligent transportation systems. To leverage the information shared by different events, we propose a multi-task learning framework. We develop a support vector regression model for joint learning of mutually dependent time series. It is the regularization-based multi-task learning previously developed for the classification case and extended to time series. We discuss the relatedness of observed time series and first deploy the dynamic time warping distance measure to identify groups of similar series. Then we take into account both time and scale warping and propose to align multiple time series by inferring their common latent representation. We test the proposed models on the problem of travel demand prediction in Nancy (France) public transport system and analyze the benefits of multi-task learning.\n    ",
        "submission_date": "2017-12-21T00:00:00",
        "last_modified_date": "2017-12-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.08290",
        "title": "CSGNet: Neural Shape Parser for Constructive Solid Geometry",
        "authors": [
            "Gopal Sharma",
            "Rishabh Goyal",
            "Difan Liu",
            "Evangelos Kalogerakis",
            "Subhransu Maji"
        ],
        "abstract": "We present a neural architecture that takes as input a 2D or 3D shape and outputs a program that generates the shape. The instructions in our program are based on constructive solid geometry principles, i.e., a set of boolean operations on shape primitives defined recursively. Bottom-up techniques for this shape parsing task rely on primitive detection and are inherently slow since the search space over possible primitive combinations is large. In contrast, our model uses a recurrent neural network that parses the input shape in a top-down manner, which is significantly faster and yields a compact and easy-to-interpret sequence of modeling instructions. Our model is also more effective as a shape detector compared to existing state-of-the-art detection techniques. We finally demonstrate that our network can be trained on novel datasets without ground-truth program annotations through policy gradient techniques.\n    ",
        "submission_date": "2017-12-22T00:00:00",
        "last_modified_date": "2018-03-31T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.08443",
        "title": "Inverse Classification for Comparison-based Interpretability in Machine Learning",
        "authors": [
            "Thibault Laugel",
            "Marie-Jeanne Lesot",
            "Christophe Marsala",
            "Xavier Renard",
            "Marcin Detyniecki"
        ],
        "abstract": "In the context of post-hoc interpretability, this paper addresses the task of explaining the prediction of a classifier, considering the case where no information is available, neither on the classifier itself, nor on the processed data (neither the training nor the test data). It proposes an instance-based approach whose principle consists in determining the minimal changes needed to alter a prediction: given a data point whose classification must be explained, the proposed method consists in identifying a close neighbour classified differently, where the closeness definition integrates a sparsity constraint. This principle is implemented using observation generation in the Growing Spheres algorithm. Experimental results on two datasets illustrate the relevance of the proposed approach that can be used to gain knowledge about the classifier.\n    ",
        "submission_date": "2017-12-22T00:00:00",
        "last_modified_date": "2017-12-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.08878",
        "title": "How Intelligent is your Intelligent Robot?",
        "authors": [
            "Alan F. T. Winfield"
        ],
        "abstract": "How intelligent is robot A compared with robot B? And how intelligent are robots A and B compared with animals (or plants) X and Y? These are both interesting and deeply challenging questions. In this paper we address the question \"how intelligent is your intelligent robot?\" by proposing that embodied intelligence emerges from the interaction and integration of four different and distinct kinds of intelligence. We then suggest a simple diagrammatic representation on which these kinds of intelligence are shown as four axes in a star diagram. A crude qualitative comparison of the intelligence graphs of animals and robots both exposes and helps to explain the chronic intelligence deficit of intelligent robots. Finally we examine the options for determining numerical values for the four kinds of intelligence in an effort to move toward a quantifiable intelligence vector.\n    ",
        "submission_date": "2017-12-24T00:00:00",
        "last_modified_date": "2017-12-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.08996",
        "title": "Android Malware Detection using Deep Learning on API Method Sequences",
        "authors": [
            "ElMouatez Billah Karbab",
            "Mourad Debbabi",
            "Abdelouahid Derhab",
            "Djedjiga Mouheb"
        ],
        "abstract": "Android OS experiences a blazing popularity since the last few years. This predominant platform has established itself not only in the mobile world but also in the Internet of Things (IoT) devices. This popularity, however, comes at the expense of security, as it has become a tempting target of malicious apps. Hence, there is an increasing need for sophisticated, automatic, and portable malware detection solutions. In this paper, we propose MalDozer, an automatic Android malware detection and family attribution framework that relies on sequences classification using deep learning techniques. Starting from the raw sequence of the app's API method calls, MalDozer automatically extracts and learns the malicious and the benign patterns from the actual samples to detect Android malware. MalDozer can serve as a ubiquitous malware detection system that is not only deployed on servers, but also on mobile and even IoT devices. We evaluate MalDozer on multiple Android malware datasets ranging from 1K to 33K malware apps, and 38K benign apps. The results show that MalDozer can correctly detect malware and attribute them to their actual families with an F1-Score of 96%-99% and a false positive rate of 0.06%-2%, under all tested datasets and settings.\n    ",
        "submission_date": "2017-12-25T00:00:00",
        "last_modified_date": "2017-12-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.09131",
        "title": "A Random Block-Coordinate Douglas-Rachford Splitting Method with Low Computational Complexity for Binary Logistic Regression",
        "authors": [
            "Luis M. Briceno-Arias",
            "Giovanni Chierchia",
            "Emilie Chouzenoux",
            "Jean-Christophe Pesquet"
        ],
        "abstract": "In this paper, we propose a new optimization algorithm for sparse logistic regression based on a stochastic version of the Douglas-Rachford splitting method. Our algorithm sweeps the training set by randomly selecting a mini-batch of data at each iteration, and it allows us to update the variables in a block coordinate manner. Our approach leverages the proximity operator of the logistic loss, which is expressed with the generalized Lambert W function. Experiments carried out on standard datasets demonstrate the efficiency of our approach w.r.t. stochastic gradient-like methods.\n    ",
        "submission_date": "2017-12-25T00:00:00",
        "last_modified_date": "2017-12-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.09327",
        "title": "Building Robust Deep Neural Networks for Road Sign Detection",
        "authors": [
            "Arkar Min Aung",
            "Yousef Fadila",
            "Radian Gondokaryono",
            "Luis Gonzalez"
        ],
        "abstract": "Deep Neural Networks are built to generalize outside of training set in mind by using techniques such as regularization, early stopping and dropout. But considerations to make them more resilient to adversarial examples are rarely taken. As deep neural networks become more prevalent in mission-critical and real-time systems, miscreants start to attack them by intentionally making deep neural networks to misclassify an object of one type to be seen as another type. This can be catastrophic in some scenarios where the classification of a deep neural network can lead to a fatal decision by a machine. In this work, we used GTSRB dataset to craft adversarial samples by Fast Gradient Sign Method and Jacobian Saliency Method, used those crafted adversarial samples to attack another Deep Convolutional Neural Network and built the attacked network to be more resilient against adversarial attacks by making it more robust by Defensive Distillation and Adversarial Training\n    ",
        "submission_date": "2017-12-26T00:00:00",
        "last_modified_date": "2017-12-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.09374",
        "title": "HACS: Human Action Clips and Segments Dataset for Recognition and Temporal Localization",
        "authors": [
            "Hang Zhao",
            "Antonio Torralba",
            "Lorenzo Torresani",
            "Zhicheng Yan"
        ],
        "abstract": "This paper presents a new large-scale dataset for recognition and temporal localization of human actions collected from Web videos. We refer to it as HACS (Human Action Clips and Segments). We leverage both consensus and disagreement among visual classifiers to automatically mine candidate short clips from unlabeled videos, which are subsequently validated by human annotators. The resulting dataset is dubbed HACS Clips. Through a separate process we also collect annotations defining action segment boundaries. This resulting dataset is called HACS Segments. Overall, HACS Clips consists of 1.5M annotated clips sampled from 504K untrimmed videos, and HACS Seg-ments contains 139K action segments densely annotatedin 50K untrimmed videos spanning 200 action categories. HACS Clips contains more labeled examples than any existing video benchmark. This renders our dataset both a large scale action recognition benchmark and an excellent source for spatiotemporal feature learning. In our transferlearning experiments on three target datasets, HACS Clips outperforms Kinetics-600, Moments-In-Time and Sports1Mas a pretraining source. On HACS Segments, we evaluate state-of-the-art methods of action proposal generation and action localization, and highlight the new challenges posed by our dense temporal annotations.\n    ",
        "submission_date": "2017-12-26T00:00:00",
        "last_modified_date": "2019-09-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.09444",
        "title": "Letter-Based Speech Recognition with Gated ConvNets",
        "authors": [
            "Vitaliy Liptchinsky",
            "Gabriel Synnaeve",
            "Ronan Collobert"
        ],
        "abstract": "In the recent literature, \"end-to-end\" speech systems often refer to letter-based acoustic models trained in a sequence-to-sequence manner, either via a recurrent model or via a structured output learning approach (such as CTC). In contrast to traditional phone (or senone)-based approaches, these \"end-to-end'' approaches alleviate the need of word pronunciation modeling, and do not require a \"forced alignment\" step at training time. Phone-based approaches remain however state of the art on classical benchmarks. In this paper, we propose a letter-based speech recognition system, leveraging a ConvNet acoustic model. Key ingredients of the ConvNet are Gated Linear Units and high dropout. The ConvNet is trained to map audio sequences to their corresponding letter transcriptions, either via a classical CTC approach, or via a recent variant called ASG. Coupled with a simple decoder at inference time, our system matches the best existing letter-based systems on WSJ (in word error rate), and shows near state of the art performance on LibriSpeech.\n    ",
        "submission_date": "2017-12-22T00:00:00",
        "last_modified_date": "2019-02-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.09644",
        "title": "PyPhi: A toolbox for integrated information theory",
        "authors": [
            "William G. P. Mayner",
            "William Marshall",
            "Larissa Albantakis",
            "Graham Findlay",
            "Robert Marchman",
            "Giulio Tononi"
        ],
        "abstract": "Integrated information theory provides a mathematical framework to fully characterize the cause-effect structure of a physical system. Here, we introduce PyPhi, a Python software package that implements this framework for causal analysis and unfolds the full cause-effect structure of discrete dynamical systems of binary elements. The software allows users to easily study these structures, serves as an up-to-date reference implementation of the formalisms of integrated information theory, and has been applied in research on complexity, emergence, and certain biological questions. We first provide an overview of the main algorithm and demonstrate PyPhi's functionality in the course of analyzing an example system, and then describe details of the algorithm's design and implementation.\n",
        "submission_date": "2017-12-27T00:00:00",
        "last_modified_date": "2018-06-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.09657",
        "title": "The information bottleneck and geometric clustering",
        "authors": [
            "DJ Strouse",
            "David J Schwab"
        ],
        "abstract": "The information bottleneck (IB) approach to clustering takes a joint distribution $P\\!\\left(X,Y\\right)$ and maps the data $X$ to cluster labels $T$ which retain maximal information about $Y$ (Tishby et al., 1999). This objective results in an algorithm that clusters data points based upon the similarity of their conditional distributions $P\\!\\left(Y\\mid X\\right)$. This is in contrast to classic \"geometric clustering'' algorithms such as $k$-means and gaussian mixture models (GMMs) which take a set of observed data points $\\left\\{ \\mathbf{x}_{i}\\right\\} _{i=1:N}$ and cluster them based upon their geometric (typically Euclidean) distance from one another. Here, we show how to use the deterministic information bottleneck (DIB) (Strouse and Schwab, 2017), a variant of IB, to perform geometric clustering, by choosing cluster labels that preserve information about data point location on a smoothed dataset. We also introduce a novel method to choose the number of clusters, based on identifying solutions where the tradeoff between number of clusters used and spatial information preserved is strongest. We apply this approach to a variety of simple clustering problems, showing that DIB with our model selection procedure recovers the generative cluster labels. We also show that, in particular limits of our model parameters, clustering with DIB and IB is equivalent to $k$-means and EM fitting of a GMM with hard and soft assignments, respectively. Thus, clustering with (D)IB generalizes and provides an information-theoretic perspective on these classic algorithms.\n    ",
        "submission_date": "2017-12-27T00:00:00",
        "last_modified_date": "2020-05-31T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.09709",
        "title": "Report: Dynamic Eye Movement Matching and Visualization Tool in Neuro Gesture",
        "authors": [
            "Qiangeng Xu",
            "John Kender"
        ],
        "abstract": "In the research of the impact of gestures using by a lecturer, one challenging task is to infer the attention of a group of audiences. Two important measurements that can help infer the level of attention are eye movement data and Electroencephalography (EEG) data. Under the fundamental assumption that a group of people would look at the same place if they all pay attention at the same time, we apply a method, \"Time Warp Edit Distance\", to calculate the similarity of their eye movement trajectories. Moreover, we also cluster eye movement pattern of audiences based on these pair-wised similarity metrics. Besides, since we don't have a direct metric for the \"attention\" ground truth, a visual assessment would be beneficial to evaluate the gesture-attention relationship. Thus we also implement a visualization tool.\n    ",
        "submission_date": "2017-12-27T00:00:00",
        "last_modified_date": "2018-01-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.09943",
        "title": "Toward Continual Learning for Conversational Agents",
        "authors": [
            "Sungjin Lee"
        ],
        "abstract": "While end-to-end neural conversation models have led to promising advances in reducing hand-crafted features and errors induced by the traditional complex system architecture, they typically require an enormous amount of data due to the lack of modularity. Previous studies adopted a hybrid approach with knowledge-based components either to abstract out domain-specific information or to augment data to cover more diverse patterns. On the contrary, we propose to directly address the problem using recent developments in the space of continual learning for neural models. Specifically, we adopt a domain-independent neural conversational model and introduce a novel neural continual learning algorithm that allows a conversational agent to accumulate skills across different tasks in a data-efficient way. To the best of our knowledge, this is the first work that applies continual learning to conversation systems. We verified the efficacy of our method through a conversational skill transfer from either synthetic dialogs or human-human dialogs to human-computer conversations in a customer support domain.\n    ",
        "submission_date": "2017-12-28T00:00:00",
        "last_modified_date": "2018-01-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.10011",
        "title": "The Merits of Sharing a Ride",
        "authors": [
            "Pooyan Ehsani",
            "Jia Yuan Yu"
        ],
        "abstract": "The culture of sharing instead of ownership is sharply increasing in individuals behaviors. Particularly in transportation, concepts of sharing a ride in either carpooling or ridesharing have been recently adopted. An efficient optimization approach to match passengers in real-time is the core of any ridesharing system. In this paper, we model ridesharing as an online matching problem on general graphs such that passengers do not drive private cars and use shared taxis. We propose an optimization algorithm to solve it. The outlined algorithm calculates the optimal waiting time when a passenger arrives. This leads to a matching with minimal overall overheads while maximizing the number of partnerships. To evaluate the behavior of our algorithm, we used NYC taxi real-life data set. Results represent a substantial reduction in overall overheads.\n    ",
        "submission_date": "2017-12-19T00:00:00",
        "last_modified_date": "2017-12-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.10050",
        "title": "Kernel Robust Bias-Aware Prediction under Covariate Shift",
        "authors": [
            "Anqi Liu",
            "Rizal Fathony",
            "Brian D. Ziebart"
        ],
        "abstract": "Under covariate shift, training (source) data and testing (target) data differ in input space distribution, but share the same conditional label distribution. This poses a challenging machine learning task. Robust Bias-Aware (RBA) prediction provides the conditional label distribution that is robust to the worstcase logarithmic loss for the target distribution while matching feature expectation constraints from the source distribution. However, employing RBA with insufficient feature constraints may result in high certainty predictions for much of the source data, while leaving too much uncertainty for target data predictions. To overcome this issue, we extend the representer theorem to the RBA setting, enabling minimization of regularized expected target risk by a reweighted kernel expectation under the source distribution. By applying kernel methods, we establish consistency guarantees and demonstrate better performance of the RBA classifier than competing methods on synthetically biased UCI datasets as well as datasets that have natural covariate shift.\n    ",
        "submission_date": "2017-12-28T00:00:00",
        "last_modified_date": "2017-12-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.10054",
        "title": "Corpus specificity in LSA and Word2vec: the role of out-of-domain documents",
        "authors": [
            "Edgar Altszyler",
            "Mariano Sigman",
            "Diego Fernandez Slezak"
        ],
        "abstract": "Latent Semantic Analysis (LSA) and Word2vec are some of the most widely used word embeddings. Despite the popularity of these techniques, the precise mechanisms by which they acquire new semantic relations between words remain unclear. In the present article we investigate whether LSA and Word2vec capacity to identify relevant semantic dimensions increases with size of corpus. One intuitive hypothesis is that the capacity to identify relevant dimensions should increase as the amount of data increases. However, if corpus size grow in topics which are not specific to the domain of interest, signal to noise ratio may weaken. Here we set to examine and distinguish these alternative hypothesis. To investigate the effect of corpus specificity and size in word-embeddings we study two ways for progressive elimination of documents: the elimination of random documents vs. the elimination of documents unrelated to a specific task. We show that Word2vec can take advantage of all the documents, obtaining its best performance when it is trained with the whole corpus. On the contrary, the specialization (removal of out-of-domain documents) of the training corpus, accompanied by a decrease of dimensionality, can increase LSA word-representation quality while speeding up the processing time. Furthermore, we show that the specialization without the decrease in LSA dimensionality can produce a strong performance reduction in specific tasks. From a cognitive-modeling point of view, we point out that LSA's word-knowledge acquisitions may not be efficiently exploiting higher-order co-occurrences and global relations, whereas Word2vec does.\n    ",
        "submission_date": "2017-12-28T00:00:00",
        "last_modified_date": "2017-12-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.10248",
        "title": "Deep Learning Interior Tomography for Region-of-Interest Reconstruction",
        "authors": [
            "Yoseob Han",
            "Jawook Gu",
            "Jong Chul Ye"
        ],
        "abstract": "Interior tomography for the region-of-interest (ROI) imaging has advantages of using a small detector and reducing X-ray radiation dose. However, standard analytic reconstruction suffers from severe cupping artifacts due to existence of null space in the truncated Radon transform. Existing penalized reconstruction methods may address this problem but they require extensive computations due to the iterative reconstruction. Inspired by the recent deep learning approaches to low-dose and sparse view CT, here we propose a deep learning architecture that removes null space signals from the FBP reconstruction. Experimental results have shown that the proposed method provides near-perfect reconstruction with about 7-10 dB improvement in PSNR over existing methods in spite of significantly reduced run-time complexity.\n    ",
        "submission_date": "2017-12-29T00:00:00",
        "last_modified_date": "2018-01-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1712.10280",
        "title": "First Draft on the xInf Model for Universal Physical Computation and Reverse Engineering of Natural Intelligence",
        "authors": [
            "Hongbo Jia"
        ],
        "abstract": "Turing Machines are universal computing machines in theory. It has been a long debate whether Turing Machines can simulate the consciousness mind behaviors in the materialistic universe. Three different hypotheses come out of such debate, in short:(A) Can; (B) Cannot; (C) Super-Turing machines can. Because Turing Machines or other kinds of theoretical computing models are abstract objects while behaviors are real observables, this debate involves at least three distinct fields of science and technology: physics, computer engineering, and experimental neuroscience. However, the languages used in these different fields are highly heterogeneous and not easily interpretable for each other, making it very difficult to reach partial agreements regarding this debate, Therefore, the main goal of this manuscript is to establish a proper language that can translate among those different fields. First, I propose a theoretical model for analyzing how theoretical computing machines would physically run in physical time. This model, termed as the xInf, is at first place Turing-complete in theory, and depending on the properties of physical time, it can be either Turing-equivalent or Super-Turing in the physical universe. The xInf Model is demonstrated to be a suitable universal language to translate among physics, computer engineering, and neuroscience. Finally, I propose a conjecture that there exists a Minimal Complete Set of rules in the xInf Model that enables the construction of a physical machine using inorganic materials that can pass the Turing Test in physical time. I cannot demonstrate whether such a conjecture to be testified or falsified on paper using finite-order logic, my only solution is physical time itself, i.e. an evolutionary competition will eventually tell the conclusion.\n    ",
        "submission_date": "2017-12-26T00:00:00",
        "last_modified_date": "2017-12-26T00:00:00"
    }
]