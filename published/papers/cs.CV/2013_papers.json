[
    {
        "url": "https://arxiv.org/abs/1301.0127",
        "title": "A Semi-automated Statistical Algorithm for Object Separation",
        "authors": [
            "Madhur Srivastava",
            "Satish K. Singh",
            "Prasanta K. Panigrahi"
        ],
        "abstract": "We explicate a semi-automated statistical algorithm for object identification and segregation in both gray scale and color images. The algorithm makes optimal use of the observation that definite objects in an image are typically represented by pixel values having narrow Gaussian distributions about characteristic mean values. Furthermore, for visually distinct objects, the corresponding Gaussian distributions have negligible overlap with each other and hence the Mahalanobis distance between these distributions are large. These statistical facts enable one to sub-divide images into multiple thresholds of variable sizes, each segregating similar objects. The procedure incorporates the sensitivity of human eye to the gray pixel values into the variable threshold size, while mapping the Gaussian distributions into localized \\delta-functions, for object separation. The effectiveness of this recursive statistical algorithm is demonstrated using a wide variety of images.\n    ",
        "submission_date": "2013-01-01T00:00:00",
        "last_modified_date": "2013-08-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1301.0167",
        "title": "Classifier Fusion Method to Recognize Handwritten Kannada Numerals",
        "authors": [
            "H. R. Mamatha",
            "S. Karthik",
            "Murthy K. Srikanta"
        ],
        "abstract": "Optical Character Recognition (OCR) is one of the important fields in image processing and pattern recognition domain. Handwritten character recognition has always been a challenging task. Only a little work can be traced towards the recognition of handwritten characters for the south Indian languages. Kannada is one such south Indian language which is also one of the official language of India. Accurate recognition of Kannada characters is a challenging task because of the high degree of similarity between the characters. Hence, good quality features are to be extracted and better classifiers are needed to improve the accuracy of the OCR for Kannada characters. This paper explores the effectiveness of feature extraction method like run length count (RLC) and directional chain code (DCC) for the recognition of handwritten Kannada numerals. In this paper, a classifier fusion method is implemented to improve the recognition rate. For the classifier fusion, we have considered K-nearest neighbour (KNN) and Linear classifier (LC). The novelty of this method is to achieve better accuracy with few features using classifier fusion approach. Proposed method achieves an average recognition rate of 96%.\n    ",
        "submission_date": "2013-01-02T00:00:00",
        "last_modified_date": "2013-01-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1301.0432",
        "title": "A Self-Organizing Neural Scheme for Door Detection in Different Environments",
        "authors": [
            "F. Mahmood",
            "F. Kunwar"
        ],
        "abstract": "Doors are important landmarks for indoor mobile robot navigation and also assist blind people to independently access unfamiliar buildings. Most existing algorithms of door detection are limited to work for familiar environments because of restricted assumptions about color, texture and shape. In this paper we propose a novel approach which employs feature based classification and uses the Kohonen Self-Organizing Map (SOM) for the purpose of door detection. Generic and stable features are used for the training of SOM that increase the performance significantly: concavity, bottom-edge intensity profile and door edges. To validate the robustness and generalizability of our method, we collected a large dataset of real world door images from a variety of environments and different lighting conditions. The algorithm achieves more than 95% detection which demonstrates that our door detection method is generic and robust with variations of color, texture, occlusions, lighting condition, scales, and viewpoints.\n    ",
        "submission_date": "2013-01-03T00:00:00",
        "last_modified_date": "2013-01-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1301.0435",
        "title": "Investigating the performance of Correspondence Algorithms in Vision based Driver-assistance in Indoor Environment",
        "authors": [
            "F. Mahmood",
            "Syed. M. B. Haider",
            "F. Kunwar"
        ],
        "abstract": "This paper presents the experimental comparison of fourteen stereo matching algorithms in variant illumination conditions. Different adaptations of global and local stereo matching techniques are chosen for evaluation The variant strength and weakness of the chosen correspondence algorithms are explored by employing the methodology of the prediction error strategy. The algorithms are gauged on the basis of their performance on real world data set taken in various indoor lighting conditions and at different times of the day\n    ",
        "submission_date": "2013-01-03T00:00:00",
        "last_modified_date": "2013-01-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1301.0612",
        "title": "Adaptive Foreground and Shadow Detection inImage Sequences",
        "authors": [
            "Yang Wang",
            "Tele Tan"
        ],
        "abstract": "This paper presents a novel method of foreground segmentation that distinguishes moving objects from their moving cast shadows in monocular image sequences. The models of background, edge information, and shadow are set up and adaptively updated. A Bayesian belief network is proposed to describe the relationships among the segmentation label, background, intensity, and edge information. The notion of Markov random field is used to encourage the spatial connectivity of the segmented regions. The solution is obtained by maximizing the posterior possibility density of the segmentation field. \n    ",
        "submission_date": "2012-12-12T00:00:00",
        "last_modified_date": "2012-12-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1301.0998",
        "title": "Stratified SIFT Matching for Human Iris Recognition",
        "authors": [
            "Sambit Bakshi",
            "Hunny Mehrotra",
            "Banshidhar Majhi"
        ],
        "abstract": "This paper proposes an efficient three fold stratified SIFT matching for iris recognition. The objective is to filter wrongly paired conventional SIFT matches. In Strata I, the keypoints from gallery and probe iris images are paired using traditional SIFT approach. Due to high image similarity at different regions of iris there may be some impairments. These are detected and filtered by finding gradient of paired keypoints in Strata II. Further, the scaling factor of paired keypoints is used to remove impairments in Strata III. The pairs retained after Strata III are likely to be potential matches for iris recognition. The proposed system performs with an accuracy of 96.08% and 97.15% on publicly available CASIAV3 and BATH databases respectively. This marks significant improvement of accuracy and FAR over the existing SIFT matching for iris.\n    ",
        "submission_date": "2013-01-06T00:00:00",
        "last_modified_date": "2013-01-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1301.1374",
        "title": "PaFiMoCS: Particle Filtered Modified-CS and Applications in Visual Tracking across Illumination Change",
        "authors": [
            "R. Sarkar",
            "S. Das",
            "N. Vaswani"
        ],
        "abstract": "We study the problem of tracking (causally estimating) a time sequence of sparse spatial signals with changing sparsity patterns, as well as other unknown states, from a sequence of nonlinear observations corrupted by (possibly) non-Gaussian noise. In many applications, particularly those in visual tracking, the unknown state can be split into a small dimensional part, e.g. global motion, and a spatial signal, e.g. illumination or shape deformation. The spatial signal is often well modeled as being sparse in some domain. For a long sequence, its sparsity pattern can change over time, although the changes are usually slow. To address the above problem, we propose a novel solution approach called Particle Filtered Modified-CS (PaFiMoCS). The key idea of PaFiMoCS is to importance sample for the small dimensional state vector, while replacing importance sampling by slow sparsity pattern change constrained posterior mode tracking for recovering the sparse spatial signal. We show that the problem of tracking moving objects across spatially varying illumination change is an example of the above problem and explain how to design PaFiMoCS for it. Experiments on both simulated data as well as on real videos with significant illumination changes demonstrate the superiority of the proposed algorithm as compared with existing particle filter based tracking algorithms.\n    ",
        "submission_date": "2013-01-08T00:00:00",
        "last_modified_date": "2013-01-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1301.1551",
        "title": "A novel processing pipeline for optical multi-touch surfaces",
        "authors": [
            "Philipp Ewerling"
        ],
        "abstract": "In this thesis a new approach for touch detection on optical multi-touch devices is proposed that exploits the fact that the camera images reveal not only the actual touch points but also objects above the screen such as the hand or arm of a user. The touch processing relies on the Maximally Stable Extremal Regions algorithm for finding the users' fingertips in the camera image. The hierarchical structure of the generated extremal regions serves as a starting point for agglomerative clustering of the fingertips into hands. Furthermore, a heuristic is suggested that supports the identification of individual fingers as well as the distinction between left hands and right hands if all five fingers of a hand are in contact with the touch surface.\n",
        "submission_date": "2013-01-08T00:00:00",
        "last_modified_date": "2013-01-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1301.1671",
        "title": "Causal graph-based video segmentation",
        "authors": [
            "Camille Couprie",
            "Cl\u00e9ment Farabet",
            "Yann LeCun"
        ],
        "abstract": "Numerous approaches in image processing and computer vision are making use of super-pixels as a pre-processing step. Among the different methods producing such over-segmentation of an image, the graph-based approach of Felzenszwalb and Huttenlocher is broadly employed. One of its interesting properties is that the regions are computed in a greedy manner in quasi-linear time. The algorithm may be trivially extended to video segmentation by considering a video as a 3D volume, however, this can not be the case for causal segmentation, when subsequent frames are unknown. We propose an efficient video segmentation approach that computes temporally consistent pixels in a causal manner, filling the need for causal and real time applications.\n    ",
        "submission_date": "2013-01-08T00:00:00",
        "last_modified_date": "2013-01-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1301.1897",
        "title": "Image Registration for Stability Testing of MEMS",
        "authors": [
            "Nargess Memarsadeghi",
            "Jacqueline Le Moigne",
            "Peter N. Blake",
            "Peter A. Morey",
            "Wayne B. Landsman",
            "Victor J. Chambers",
            "Samuel H. Moseley"
        ],
        "abstract": "Image registration, or alignment of two or more images covering the same scenes or objects, is of great interest in many disciplines such as remote sensing, medical imaging, astronomy, and computer vision. In this paper, we introduce a new application of image registration algorithms. We demonstrate how through a wavelet based image registration algorithm, engineers can evaluate stability of Micro-Electro-Mechanical Systems (MEMS). In particular, we applied image registration algorithms to assess alignment stability of the MicroShutters Subsystem (MSS) of the Near Infrared Spectrograph (NIRSpec) instrument of the James Webb Space Telescope (JWST). This work introduces a new methodology for evaluating stability of MEMS devices to engineers as well as a new application of image registration algorithms to computer scientists.\n    ",
        "submission_date": "2013-01-09T00:00:00",
        "last_modified_date": "2013-01-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1301.2032",
        "title": "Training Effective Node Classifiers for Cascade Classification",
        "authors": [
            "Chunhua Shen",
            "Peng Wang",
            "Sakrapee Paisitkriangkrai",
            "Anton van den Hengel"
        ],
        "abstract": "Cascade classifiers are widely used in real-time object detection. Different from conventional classifiers that are designed for a low overall classification error rate, a classifier in each node of the cascade is required to achieve an extremely high detection rate and moderate false positive rate. Although there are a few reported methods addressing this requirement in the context of object detection, there is no principled feature selection method that explicitly takes into account this asymmetric node learning objective. We provide such an algorithm here. We show that a special case of the biased minimax probability machine has the same formulation as the linear asymmetric classifier (LAC) of Wu et al (2005). We then design a new boosting algorithm that directly optimizes the cost function of LAC. The resulting totally-corrective boosting algorithm is implemented by the column generation technique in convex optimization. Experimental results on object detection verify the effectiveness of the proposed boosting algorithm as a node classifier in cascade object detection, and show performance better than that of the current state-of-the-art.\n    ",
        "submission_date": "2013-01-10T00:00:00",
        "last_modified_date": "2013-01-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1301.2252",
        "title": "A Factorized Variational Technique for Phase Unwrapping in Markov Random Fields",
        "authors": [
            "Kannan Achan",
            "Brendan J. Frey",
            "Ralf Koetter"
        ],
        "abstract": "Some types of medical and topographic imaging device produce images in which the pixel values are \"phase-wrapped\", i.e. measured modulus a known scalar. Phase unwrapping can be viewed as the problem of inferring the number of shifts between each and every pair of neighboring pixels, subject to an a priori preference for smooth surfaces, and subject to a zero curl constraint, which requires that the shifts must sum to 0 around every loop. We formulate phase unwrapping as a mean field inference problem in a Markov network, where the prior favors the zero curl constraint. We compare our mean field technique with the least squares method on a synthetic 100x100  image, and give results on a 512x512 synthetic aperture radar image from Sandia National Laboratories.<Long Text>\n    ",
        "submission_date": "2013-01-10T00:00:00",
        "last_modified_date": "2013-01-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1301.2351",
        "title": "Application of Hopfield Network to Saccades",
        "authors": [
            "Teruyoshi Washizawa"
        ],
        "abstract": "Human eye movement mechanisms (saccades) are very useful for scene analysis, including object representation and pattern recognition. In this letter, a Hopfield neural network to emulate saccades is proposed. The network uses an energy function that includes location and identification tasks. Computer simulation shows that the network performs those tasks cooperatively. The result suggests that the network is applicable to shift-invariant pattern recognition.\n    ",
        "submission_date": "2013-01-10T00:00:00",
        "last_modified_date": "2013-01-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1301.2542",
        "title": "Enhancing the retrieval performance by combing the texture and edge features",
        "authors": [
            "Mohamed Eisa",
            "Amira Eletrebi",
            "Ebrahim Elhenawy"
        ],
        "abstract": "In this paper, anew algorithm which is based on geometrical moments and local binary patterns (LBP) for content based image retrieval (CBIR) is proposed. In geometrical moments, each vector is compared with the all other vectors for edge map generation. The same concept is utilized at LBP calculation which is generating nine LBP patterns from a given 3x3 pattern. Finally, nine LBP histograms are calculated which are used as a feature vector for image retrieval. Moments are important features used in recognition of different types of images. Two experiments have been carried out for proving the worth of our algorithm. The results after being investigated shows a significant improvement in terms of their evaluation measures as compared to LBP and other existing transform domain techniques.\n    ",
        "submission_date": "2013-01-10T00:00:00",
        "last_modified_date": "2013-01-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1301.2628",
        "title": "Robust Text Detection in Natural Scene Images",
        "authors": [
            "Xu-Cheng Yin",
            "Xuwang Yin",
            "Kaizhu Huang",
            "Hong-Wei Hao"
        ],
        "abstract": "Text detection in natural scene images is an important prerequisite for many content-based image analysis tasks. In this paper, we propose an accurate and robust method for detecting texts in natural scene images. A fast and effective pruning algorithm is designed to extract Maximally Stable Extremal Regions (MSERs) as character candidates using the strategy of minimizing regularized variations. Character candidates are grouped into text candidates by the ingle-link clustering algorithm, where distance weights and threshold of the clustering algorithm are learned automatically by a novel self-training distance metric learning algorithm. The posterior probabilities of text candidates corresponding to non-text are estimated with an character classifier; text candidates with high probabilities are then eliminated and finally texts are identified with a text classifier. The proposed system is evaluated on the ICDAR 2011 Robust Reading Competition dataset; the f measure is over 76% and is significantly better than the state-of-the-art performance of 71%. Experimental results on a publicly available multilingual dataset also show that our proposed method can outperform the other competitive method with the f measure increase of over 9 percent. Finally, we have setup an online demo of our proposed scene text detection system at ",
        "submission_date": "2013-01-11T00:00:00",
        "last_modified_date": "2013-06-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1301.2715",
        "title": "Binocular disparity as an explanation for the moon illusion",
        "authors": [
            "Joseph Antonides",
            "Toshiro Kubota"
        ],
        "abstract": "We present another explanation for the moon illusion, the phenomenon in which the moon looks larger near the horizon than near the zenith. In our model of the moon illusion, the sky is considered a spatially-contiguous and geometrically-smooth surface. When an object such as the moon breaks the contiguity of the surface, instead of perceiving the object as appearing through a hole in the surface, humans perceive an occlusion of the surface. Binocular vision dictates that the moon is distant, but this perception model contradicts our binocular vision, dictating that the moon is closer than the sky. To resolve the contradiction, the brain distorts the projections of the moon to increase the binocular disparity, which results in an increase in the perceived size of the moon. The degree of distortion depends upon the apparent distance to the sky, which is influenced by the surrounding objects and the condition of the sky. As the apparent distance to the sky decreases, the illusion becomes stronger. At the horizon, apparent distance to the sky is minimal, whereas at the zenith, few distance cues are present, causing difficulty with distance estimation and weakening the illusion.\n    ",
        "submission_date": "2013-01-12T00:00:00",
        "last_modified_date": "2016-09-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1301.2820",
        "title": "Clustering Learning for Robotic Vision",
        "authors": [
            "Eugenio Culurciello",
            "Jordan Bates",
            "Aysegul Dundar",
            "Jose Carrasco",
            "Clement Farabet"
        ],
        "abstract": "We present the clustering learning technique applied to multi-layer feedforward deep neural networks. We show that this unsupervised learning technique can compute network filters with only a few minutes and a much reduced set of parameters. The goal of this paper is to promote the technique for general-purpose robotic vision systems. We report its use in static image datasets and object tracking datasets. We show that networks trained with clustering learning can outperform large networks trained for many hours on complex datasets.\n    ",
        "submission_date": "2013-01-13T00:00:00",
        "last_modified_date": "2013-03-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1301.2840",
        "title": "Unsupervised Feature Learning for low-level Local Image Descriptors",
        "authors": [
            "Christian Osendorfer",
            "Justin Bayer",
            "Sebastian Urban",
            "Patrick van der Smagt"
        ],
        "abstract": "Unsupervised feature learning has shown impressive results for a wide range of input modalities, in particular for object classification tasks in computer vision. Using a large amount of unlabeled data, unsupervised feature learning methods are utilized to construct high-level representations that are discriminative enough for subsequently trained supervised classification algorithms. However, it has never been \\emph{quantitatively} investigated yet how well unsupervised learning methods can find \\emph{low-level representations} for image patches without any additional supervision. In this paper we examine the performance of pure unsupervised methods on a low-level correspondence task, a problem that is central to many Computer Vision applications. We find that a special type of Restricted Boltzmann Machines (RBMs) performs comparably to hand-crafted descriptors. Additionally, a simple binarization scheme produces compact representations that perform better than several state-of-the-art descriptors.\n    ",
        "submission_date": "2013-01-14T00:00:00",
        "last_modified_date": "2013-04-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1301.2884",
        "title": "Wavelet-based Scale Saliency",
        "authors": [
            "Anh Cat Le Ngo",
            "Kenneth Li-Minn Ang",
            "Jasmine Kah-Phooi Seng",
            "Guoping Qiu"
        ],
        "abstract": "Both pixel-based scale saliency (PSS) and basis project methods focus on multiscale analysis of data content and structure. Their theoretical relations and practical combination are previously discussed. However, no models have ever been proposed for calculating scale saliency on basis-projected descriptors since then. This paper extend those ideas into mathematical models and implement them in the wavelet-based scale saliency (WSS). While PSS uses pixel-value descriptors, WSS treats wavelet sub-bands as basis descriptors. The paper discusses different wavelet descriptors: discrete wavelet transform (DWT), wavelet packet transform (DWPT), quaternion wavelet transform (QWT) and best basis quaternion wavelet packet transform (QWPTBB). WSS saliency maps of different descriptors are generated and compared against other saliency methods by both quantitative and quanlitative methods. Quantitative results, ROC curves, AUC values and NSS values are collected from simulations on Bruce and Kootstra image databases with human eye-tracking data as ground-truth. Furthermore, qualitative visual results of saliency maps are analyzed and compared against each other as well as eye-tracking data inclusive in the databases.\n    ",
        "submission_date": "2013-01-14T00:00:00",
        "last_modified_date": "2013-01-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1301.3323",
        "title": "Auto-pooling: Learning to Improve Invariance of Image Features from Image Sequences",
        "authors": [
            "Sainbayar Sukhbaatar",
            "Takaki Makino",
            "Kazuyuki Aihara"
        ],
        "abstract": "Learning invariant representations from images is one of the hardest challenges facing computer vision. Spatial pooling is widely used to create invariance to spatial shifting, but it is restricted to convolutional models. In this paper, we propose a novel pooling method that can learn soft clustering of features from image sequences. It is trained to improve the temporal coherence of features, while keeping the information loss at minimum. Our method does not use spatial information, so it can be used with non-convolutional models too. Experiments on images extracted from natural videos showed that our method can cluster similar features together. When trained by convolutional features, auto-pooling outperformed traditional spatial pooling on an image classification task, even though it does not use the spatial topology of features.\n    ",
        "submission_date": "2013-01-15T00:00:00",
        "last_modified_date": "2013-03-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1301.3385",
        "title": "Recurrent Online Clustering as a Spatio-Temporal Feature Extractor in DeSTIN",
        "authors": [
            "Steven R. Young",
            "Itamar Arel"
        ],
        "abstract": "This paper presents a basic enhancement to the DeSTIN deep learning architecture by replacing the explicitly calculated transition tables that are used to capture temporal features with a simpler, more scalable mechanism. This mechanism uses feedback of state information to cluster over a space comprised of both the spatial input and the current state. The resulting architecture achieves state-of-the-art results on the MNIST classification benchmark.\n    ",
        "submission_date": "2013-01-15T00:00:00",
        "last_modified_date": "2013-01-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1301.3457",
        "title": "A Geometric Descriptor for Cell-Division Detection",
        "authors": [
            "Marcelo Cicconet",
            "Italo Lima",
            "Davi Geiger",
            "Kris Gunsalus"
        ],
        "abstract": "We describe a method for cell-division detection based on a geometric-driven descriptor that can be represented as a 5-layers processing network, based mainly on wavelet filtering and a test for mirror symmetry between pairs of pixels. After the centroids of the descriptors are computed for a sequence of frames, the two-steps piecewise constant function that best fits the sequence of centroids determines the frame where the division occurs.\n    ",
        "submission_date": "2013-01-15T00:00:00",
        "last_modified_date": "2013-04-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1301.3516",
        "title": "Learnable Pooling Regions for Image Classification",
        "authors": [
            "Mateusz Malinowski",
            "Mario Fritz"
        ],
        "abstract": "Biologically inspired, from the early HMAX model to Spatial Pyramid Matching, pooling has played an important role in visual recognition pipelines. Spatial pooling, by grouping of local codes, equips these methods with a certain degree of robustness to translation and deformation yet preserving important spatial information. Despite the predominance of this approach in current recognition systems, we have seen little progress to fully adapt the pooling strategy to the task at hand. This paper proposes a model for learning task dependent pooling scheme -- including previously proposed hand-crafted pooling schemes as a particular instantiation. In our work, we investigate the role of different regularization terms showing that the smooth regularization term is crucial to achieve strong performance using the presented architecture. Finally, we propose an efficient and parallel method to train the model. Our experiments show improved performance over hand-crafted pooling schemes on the CIFAR-10 and CIFAR-100 datasets -- in particular improving the state-of-the-art to 56.29% on the latter.\n    ",
        "submission_date": "2013-01-15T00:00:00",
        "last_modified_date": "2015-05-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1301.3560",
        "title": "Complexity of Representation and Inference in Compositional Models with Part Sharing",
        "authors": [
            "Alan L. Yuille",
            "Roozbeh Mottaghi"
        ],
        "abstract": "This paper describes serial and parallel compositional models of multiple objects with part sharing. Objects are built by part-subpart compositions and expressed in terms of a hierarchical dictionary of object parts. These parts are represented on lattices of decreasing sizes which yield an executive summary description. We describe inference and learning algorithms for these models. We analyze the complexity of this model in terms of computation time (for serial computers) and numbers of nodes (e.g., \"neurons\") for parallel computers. In particular, we compute the complexity gains by part sharing and its dependence on how the dictionary scales with the level of the hierarchy. We explore three regimes of scaling behavior where the dictionary size (i) increases exponentially with the level, (ii) is determined by an unsupervised compositional learning algorithm applied to real data, (iii) decreases exponentially with scale. This analysis shows that in some regimes the use of shared parts enables algorithms which can perform inference in time linear in the number of levels for an exponential number of objects. In other regimes part sharing has little advantage for serial computers but can give linear processing on parallel computers.\n    ",
        "submission_date": "2013-01-16T00:00:00",
        "last_modified_date": "2013-01-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1301.3572",
        "title": "Indoor Semantic Segmentation using depth information",
        "authors": [
            "Camille Couprie",
            "Cl\u00e9ment Farabet",
            "Laurent Najman",
            "Yann LeCun"
        ],
        "abstract": "This work addresses multi-class segmentation of indoor scenes with RGB-D inputs. While this area of research has gained much attention recently, most works still rely on hand-crafted features. In contrast, we apply a multiscale convolutional network to learn features directly from the images and the depth information. We obtain state-of-the-art on the NYU-v2 depth dataset with an accuracy of 64.5%. We illustrate the labeling of indoor scenes in videos sequences that could be processed in real-time using appropriate hardware such as an FPGA.\n    ",
        "submission_date": "2013-01-16T00:00:00",
        "last_modified_date": "2013-03-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1301.3644",
        "title": "Regularized Discriminant Embedding for Visual Descriptor Learning",
        "authors": [
            "Kye-Hyeon Kim",
            "Rui Cai",
            "Lei Zhang",
            "Seungjin Choi"
        ],
        "abstract": "Images can vary according to changes in viewpoint, resolution, noise, and illumination. In this paper, we aim to learn representations for an image, which are robust to wide changes in such environmental conditions, using training pairs of matching and non-matching local image patches that are collected under various environmental conditions. We present a regularized discriminant analysis that emphasizes two challenging categories among the given training pairs: (1) matching, but far apart pairs and (2) non-matching, but close pairs in the original feature space (e.g., SIFT feature space). Compared to existing work on metric learning and discriminant analysis, our method can better distinguish relevant images from irrelevant, but look-alike images.\n    ",
        "submission_date": "2013-01-16T00:00:00",
        "last_modified_date": "2013-01-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1301.3666",
        "title": "Zero-Shot Learning Through Cross-Modal Transfer",
        "authors": [
            "Richard Socher",
            "Milind Ganjoo",
            "Hamsa Sridhar",
            "Osbert Bastani",
            "Christopher D. Manning",
            "Andrew Y. Ng"
        ],
        "abstract": "This work introduces a model that can recognize objects in images even if no training data is available for the objects. The only necessary knowledge about the unseen categories comes from unsupervised large text corpora. In our zero-shot framework distributional information in language can be seen as spanning a semantic basis for understanding what objects look like. Most previous zero-shot learning models can only differentiate between unseen classes. In contrast, our model can both obtain state of the art performance on classes that have thousands of training images and obtain reasonable performance on unseen classes. This is achieved by first using outlier detection in the semantic space and then two separate recognition models. Furthermore, our model does not require any manually defined semantic features for either words or images.\n    ",
        "submission_date": "2013-01-16T00:00:00",
        "last_modified_date": "2013-03-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1301.3755",
        "title": "Gradient Driven Learning for Pooling in Visual Pipeline Feature Extraction Models",
        "authors": [
            "Derek Rose",
            "Itamar Arel"
        ],
        "abstract": "Hyper-parameter selection remains a daunting task when building a pattern recognition architecture which performs well, particularly in recently constructed visual pipeline models for feature extraction. We re-formulate pooling in an existing pipeline as a function of adjustable pooling map weight parameters and propose the use of supervised error signals from gradient descent to tune the established maps within the model. This technique allows us to learn what would otherwise be a design choice within the model and specialize the maps to aggregate areas of invariance for the task presented. Preliminary results show moderate potential gains in classification accuracy and highlight areas of importance within the intermediate feature representation space.\n    ",
        "submission_date": "2013-01-16T00:00:00",
        "last_modified_date": "2013-01-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1301.3854",
        "title": "Learning Graphical Models of Images, Videos and Their Spatial Transformations",
        "authors": [
            "Brendan J. Frey",
            "Nebojsa Jojic"
        ],
        "abstract": "Mixtures of Gaussians, factor analyzers (probabilistic PCA) and hidden Markov models are staples of static and dynamic data modeling and image and video modeling in particular. We show how topographic transformations in the input, such as translation and shearing in images, can be accounted for in these models by including a discrete transformation variable. The resulting models perform clustering, dimensionality reduction and time-series analysis in a way that is invariant to transformations in the input. Using the EM algorithm, these transformation-invariant models can be fit to static data and time series. We give results on filtering microscopy images, face and facial pose clustering, handwritten digit modeling and recognition, video clustering, object tracking, and removal of distractions from video sequences.\n    ",
        "submission_date": "2013-01-16T00:00:00",
        "last_modified_date": "2013-01-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1301.3964",
        "title": "Multiscale Discriminant Saliency for Visual Attention",
        "authors": [
            "Anh Cat Le Ngo",
            "Kenneth Ang Li-Minn",
            "Guoping Qiu",
            "Jasmine Seng Kah-Phooi"
        ],
        "abstract": "The bottom-up saliency, an early stage of humans' visual attention, can be considered as a binary classification problem between center and surround classes. Discriminant power of features for the classification is measured as mutual information between features and two classes distribution. The estimated discrepancy of two feature classes very much depends on considered scale levels; then, multi-scale structure and discriminant power are integrated by employing discrete wavelet features and Hidden markov tree (HMT). With wavelet coefficients and Hidden Markov Tree parameters, quad-tree like label structures are constructed and utilized in maximum a posterior probability (MAP) of hidden class variables at corresponding dyadic sub-squares. Then, saliency value for each dyadic square at each scale level is computed with discriminant power principle and the MAP. Finally, across multiple scales is integrated the final saliency map by an information maximization rule. Both standard quantitative tools such as NSS, LCC, AUC and qualitative assessments are used for evaluating the proposed multiscale discriminant saliency method (MDIS) against the well-know information-based saliency method AIM on its Bruce Database wity eye-tracking data. Simulation results are presented and analyzed to verify the validity of MDIS as well as point out its disadvantages for further research direction.\n    ",
        "submission_date": "2013-01-17T00:00:00",
        "last_modified_date": "2013-01-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1301.4377",
        "title": "Multiple models of Bayesian networks applied to offline recognition of Arabic handwritten city names",
        "authors": [
            "Mohamed Ali Mahjoub",
            "Nabil Ghanmy",
            "Khlifia jayech",
            "Ikram Miled"
        ],
        "abstract": "In this paper we address the problem of offline Arabic handwriting word recognition. Off-line recognition of handwritten words is a difficult task due to the high variability and uncertainty of human writing. The majority of the recent systems are constrained by the size of the lexicon to deal with and the number of writers. In this paper, we propose an approach for multi-writers Arabic handwritten words recognition using multiple Bayesian networks. First, we cut the image in several blocks. For each block, we compute a vector of descriptors. Then, we use K-means to cluster the low-level features including Zernik and Hu moments. Finally, we apply four variants of Bayesian networks classifiers (Na\u00efve Bayes, Tree Augmented Na\u00efve Bayes (TAN), Forest Augmented Na\u00efve Bayes (FAN) and DBN (dynamic bayesian network) to classify the whole image of tunisian city name. The results demonstrate FAN and DBN outperform good recognition rates\n    ",
        "submission_date": "2013-01-18T00:00:00",
        "last_modified_date": "2013-01-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1301.4558",
        "title": "Lip Localization and Viseme Classification for Visual Speech Recognition",
        "authors": [
            "Salah Werda",
            "Walid Mahdi",
            "Abdelmajid Ben Hamadou"
        ],
        "abstract": "The need for an automatic lip-reading system is ever increasing. Infact, today, extraction and reliable analysis of facial movements make up an important part in many multimedia systems such as videoconference, low communication systems, lip-reading systems. In addition, visual information is imperative among people with special needs. We can imagine, for example, a dependent person ordering a machine with an easy lip movement or by a simple syllable pronunciation. Moreover, people with hearing problems compensate for their special needs by lip-reading as well as listening to the person with whome they are talking.\n    ",
        "submission_date": "2013-01-19T00:00:00",
        "last_modified_date": "2013-01-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1301.5063",
        "title": "Heteroscedastic Conditional Ordinal Random Fields for Pain Intensity Estimation from Facial Images",
        "authors": [
            "Ognjen Rudovic",
            "Maja Pantic",
            "Vladimir Pavlovic"
        ],
        "abstract": "We propose a novel method for automatic pain intensity estimation from facial images based on the framework of kernel Conditional Ordinal Random Fields (KCORF). We extend this framework to account for heteroscedasticity on the output labels(i.e., pain intensity scores) and introduce a novel dynamic features, dynamic ranks, that impose temporal ordinal constraints on the static ranks (i.e., intensity scores). Our experimental results show that the proposed approach outperforms state-of-the art methods for sequence classification with ordinal data and other ordinal regression models. The approach performs significantly better than other models in terms of Intra-Class Correlation measure, which is the most accepted evaluation measure in the tasks of facial behaviour intensity estimation.\n    ",
        "submission_date": "2013-01-22T00:00:00",
        "last_modified_date": "2013-04-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1301.5356",
        "title": "Efficient MRF Energy Propagation for Video Segmentation via Bilateral Filters",
        "authors": [
            "Ozan Sener",
            "Kemal Ugur",
            "A. Aydin Alatan"
        ],
        "abstract": "Segmentation of an object from a video is a challenging task in multimedia applications. Depending on the application, automatic or interactive methods are desired; however, regardless of the application type, efficient computation of video object segmentation is crucial for time-critical applications; specifically, mobile and interactive applications require near real-time efficiencies. In this paper, we address the problem of video segmentation from the perspective of efficiency. We initially redefine the problem of video object segmentation as the propagation of MRF energies along the temporal domain. For this purpose, a novel and efficient method is proposed to propagate MRF energies throughout the frames via bilateral filters without using any global texture, color or shape model. Recently presented bi-exponential filter is utilized for efficiency, whereas a novel technique is also developed to dynamically solve graph-cuts for varying, non-lattice graphs in general linear filtering scenario. These improvements are experimented for both automatic and interactive video segmentation scenarios. Moreover, in addition to the efficiency, segmentation quality is also tested both quantitatively and qualitatively. Indeed, for some challenging examples, significant time efficiency is observed without loss of segmentation quality.\n    ",
        "submission_date": "2013-01-22T00:00:00",
        "last_modified_date": "2014-10-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1301.5451",
        "title": "Spread spectrum compressed sensing MRI using chirp radio frequency pulses",
        "authors": [
            "Xiaobo Qu",
            "Ying Chen",
            "Xiaoxing Zhuang",
            "Zhiyu Yan",
            "Di Guo",
            "Zhong Chen"
        ],
        "abstract": "Compressed sensing has shown great potential in reducing data acquisition time in magnetic resonance imaging (MRI). Recently, a spread spectrum compressed sensing MRI method modulates an image with a quadratic phase. It performs better than the conventional compressed sensing MRI with variable density sampling, since the coherence between the sensing and sparsity bases are reduced. However, spread spectrum in that method is implemented via a shim coil which limits its modulation intensity and is not convenient to operate. In this letter, we propose to apply chirp (linear frequency-swept) radio frequency pulses to easily control the spread spectrum. To accelerate the image reconstruction, an alternating direction algorithm is modified by exploiting the complex orthogonality of the quadratic phase encoding. Reconstruction on the acquired data demonstrates that more image features are preserved using the proposed approach than those of conventional CS-MRI.\n    ",
        "submission_date": "2013-01-23T00:00:00",
        "last_modified_date": "2013-01-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1301.5491",
        "title": "ChESS - Quick and Robust Detection of Chess-board Features",
        "authors": [
            "Stuart Bennett",
            "Joan Lasenby"
        ],
        "abstract": "Localization of chess-board vertices is a common task in computer vision, underpinning many applications, but relatively little work focusses on designing a specific feature detector that is fast, accurate and robust. In this paper the `Chess-board Extraction by Subtraction and Summation' (ChESS) feature detector, designed to exclusively respond to chess-board vertices, is presented. The method proposed is robust against noise, poor lighting and poor contrast, requires no prior knowledge of the extent of the chess-board pattern, is computationally very efficient, and provides a strength measure of detected features. Such a detector has significant application both in the key field of camera calibration, as well as in Structured Light 3D reconstruction. Evidence is presented showing its robustness, accuracy, and efficiency in comparison to other commonly used detectors both under simulation and in experimental 3D reconstruction of flat plate and cylindrical objects\n    ",
        "submission_date": "2013-01-23T00:00:00",
        "last_modified_date": "2013-01-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1301.5582",
        "title": "Multi-Class Detection and Segmentation of Objects in Depth",
        "authors": [
            "Cheng Zhang",
            "Hedvig Kjellstrom"
        ],
        "abstract": "The quality of life of many people could be improved by autonomous humanoid robots in the home. To function in the human world, a humanoid household robot must be able to locate itself and perceive the environment like a human; scene perception, object detection and segmentation, and object spatial localization in 3D are fundamental capabilities for such humanoid robots. This paper presents a 3D multi-class object detection and segmentation method. The contributions are twofold. Firstly, we present a multi-class detection method, where a minimal joint codebook is learned in a principled manner. Secondly, we incorporate depth information using RGB-D imagery, which increases the robustness of the method and gives the 3D location of objects -- necessary since the robot reasons in 3D space. Experiments show that the multi-class extension improves the detection efficiency with respect to the number of classes and the depth extension improves the detection robustness and give sufficient natural 3D location of the objects.\n    ",
        "submission_date": "2013-01-23T00:00:00",
        "last_modified_date": "2013-01-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1301.6324",
        "title": "An improvement to k-nearest neighbor classifier",
        "authors": [
            "T. Hitendra Sarma",
            "P. Viswanath",
            "D. Sai Koti Reddy",
            "S. Sri Raghava"
        ],
        "abstract": "K-Nearest neighbor classifier (k-NNC) is simple to use and has little design time like finding k values in k-nearest neighbor classifier, hence these are suitable to work with dynamically varying data-sets. There exists some fundamental improvements over the basic k-NNC, like weighted k-nearest neighbors classifier (where weights to nearest neighbors are given based on linear interpolation), using artificially generated training set called bootstrapped training set, etc. These improvements are orthogonal to space reduction and classification time reduction techniques, hence can be coupled with any of them. The paper proposes another improvement to the basic k-NNC where the weights to nearest neighbors are given based on Gaussian distribution (instead of linear interpolation as done in weighted k-NNC) which is also independent of any space reduction and classification time reduction technique. We formally show that our proposed method is closely related to non-parametric density estimation using a Gaussian kernel. We experimentally demonstrate using various standard data-sets that the proposed method is better than the existing ones in most cases.\n    ",
        "submission_date": "2013-01-27T00:00:00",
        "last_modified_date": "2013-01-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1301.6646",
        "title": "Image registration with sparse approximations in parametric dictionaries",
        "authors": [
            "Alhussein Fawzi",
            "Pascal Frossard"
        ],
        "abstract": "We examine in this paper the problem of image registration from the new perspective where images are given by sparse approximations in parametric dictionaries of geometric functions. We propose a registration algorithm that looks for an estimate of the global transformation between sparse images by examining the set of relative geometrical transformations between the respective features. We propose a theoretical analysis of our registration algorithm and we derive performance guarantees based on two novel important properties of redundant dictionaries, namely the robust linear independence and the transformation inconsistency. We propose several illustrations and insights about the importance of these dictionary properties and show that common properties such as coherence or restricted isometry property fail to provide sufficient information in registration problems. We finally show with illustrative experiments on simple visual objects and handwritten digits images that our algorithm outperforms baseline competitor methods in terms of transformation-invariant distance computation and classification.\n    ",
        "submission_date": "2013-01-28T00:00:00",
        "last_modified_date": "2013-07-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1301.6847",
        "title": "Robust Face Recognition via Block Sparse Bayesian Learning",
        "authors": [
            "Taiyong Li",
            "Zhilin Zhang"
        ],
        "abstract": "Face recognition (FR) is an important task in pattern recognition and computer vision. Sparse representation (SR) has been demonstrated to be a powerful framework for FR. In general, an SR algorithm treats each face in a training dataset as a basis function, and tries to find a sparse representation of a test face under these basis functions. The sparse representation coefficients then provide a recognition hint. Early SR algorithms are based on a basic sparse model. Recently, it has been found that algorithms based on a block sparse model can achieve better recognition rates. Based on this model, in this study we use block sparse Bayesian learning (BSBL) to find a sparse representation of a test face for recognition. BSBL is a recently proposed framework, which has many advantages over existing block-sparse-model based algorithms. Experimental results on the Extended Yale B, the AR and the CMU PIE face databases show that using BSBL can achieve better recognition rates and higher robustness than state-of-the-art algorithms in most cases.\n    ",
        "submission_date": "2013-01-29T00:00:00",
        "last_modified_date": "2013-09-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1301.7641",
        "title": "Multi-scale Discriminant Saliency with Wavelet-based Hidden Markov Tree Modelling",
        "authors": [
            "Anh Cat Le Ngo",
            "Kenneth Li-Minn Ang",
            "Guoping Qiu",
            "Jasmine Kah-Phooi Seng"
        ],
        "abstract": "The bottom-up saliency, an early stage of humans' visual attention, can be considered as a binary classification problem between centre and surround classes. Discriminant power of features for the classification is measured as mutual information between distributions of image features and corresponding classes . As the estimated discrepancy very much depends on considered scale level, multi-scale structure and discriminant power are integrated by employing discrete wavelet features and Hidden Markov Tree (HMT). With wavelet coefficients and Hidden Markov Tree parameters, quad-tree like label structures are constructed and utilized in maximum a posterior probability (MAP) of hidden class variables at corresponding dyadic sub-squares. Then, a saliency value for each square block at each scale level is computed with discriminant power principle. Finally, across multiple scales is integrated the final saliency map by an information maximization rule. Both standard quantitative tools such as NSS, LCC, AUC and qualitative assessments are used for evaluating the proposed multi-scale discriminant saliency (MDIS) method against the well-know information based approach AIM on its released image collection with eye-tracking data. Simulation results are presented and analysed to verify the validity of MDIS as well as point out its limitation for further research direction.\n    ",
        "submission_date": "2013-01-31T00:00:00",
        "last_modified_date": "2013-06-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1301.7661",
        "title": "Fast non parametric entropy estimation for spatial-temporal saliency method",
        "authors": [
            "Anh Cat Le Ngo",
            "Guoping Qiu",
            "Geoff Underwood",
            "Kenneth Li-Minn Ang",
            "Jasmine Kah-Phooi Seng"
        ],
        "abstract": "This paper formulates bottom-up visual saliency as center surround conditional entropy and presents a fast and efficient technique for the computation of such a saliency map. It is shown that the new saliency formulation is consistent with self-information based saliency, decision-theoretic saliency and Bayesian definition of surprises but also faces the same significant computational challenge of estimating probability density in very high dimensional spaces with limited samples. We have developed a fast and efficient nonparametric method to make the practical implementation of these types of saliency maps possible. By aligning pixels from the center and surround regions and treating their location coordinates as random variables, we use a k-d partitioning method to efficiently estimating the center surround conditional entropy. We present experimental results on two publicly available eye tracking still image databases and show that the new technique is competitive with state of the art bottom-up saliency computational methods. We have also extended the technique to compute spatiotemporal visual saliency of video and evaluate the bottom-up spatiotemporal saliency against eye tracking data on a video taken onboard a moving vehicle with the driver's eye being tracked by a head mounted eye-tracker.\n    ",
        "submission_date": "2013-01-31T00:00:00",
        "last_modified_date": "2013-01-31T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1302.0077",
        "title": "Sparse MRI for motion correction",
        "authors": [
            "Zai Yang",
            "Cishen Zhang",
            "Lihua Xie"
        ],
        "abstract": "MR image sparsity/compressibility has been widely exploited for imaging acceleration with the development of compressed sensing. A sparsity-based approach to rigid-body motion correction is presented for the first time in this paper. A motion is sought after such that the compensated MR image is maximally sparse/compressible among the infinite candidates. Iterative algorithms are proposed that jointly estimate the motion and the image content. The proposed method has a lot of merits, such as no need of additional data and loose requirement for the sampling sequence. Promising results are presented to demonstrate its performance.\n    ",
        "submission_date": "2013-02-01T00:00:00",
        "last_modified_date": "2013-02-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1302.0439",
        "title": "Correcting Camera Shake by Incremental Sparse Approximation",
        "authors": [
            "Paul Shearer",
            "Anna C. Gilbert",
            "Alfred O. Hero III"
        ],
        "abstract": "The problem of deblurring an image when the blur kernel is unknown remains challenging after decades of work. Recently there has been rapid progress on correcting irregular blur patterns caused by camera shake, but there is still much room for improvement. We propose a new blind deconvolution method using incremental sparse edge approximation to recover images blurred by camera shake. We estimate the blur kernel first from only the strongest edges in the image, then gradually refine this estimate by allowing for weaker and weaker edges. Our method competes with the benchmark deblurring performance of the state-of-the-art while being significantly faster and easier to generalize.\n    ",
        "submission_date": "2013-02-03T00:00:00",
        "last_modified_date": "2013-02-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1302.0446",
        "title": "Sparse Camera Network for Visual Surveillance -- A Comprehensive Survey",
        "authors": [
            "Mingli Song",
            "Dachent Tao",
            "Stephen J. Maybank"
        ],
        "abstract": "Technological advances in sensor manufacture, communication, and computing are stimulating the development of new applications that are transforming traditional vision systems into pervasive intelligent camera networks. The analysis of visual cues in multi-camera networks enables a wide range of applications, from smart home and office automation to large area surveillance and traffic surveillance. While dense camera networks - in which most cameras have large overlapping fields of view - are well studied, we are mainly concerned with sparse camera networks. A sparse camera network undertakes large area surveillance using as few cameras as possible, and most cameras have non-overlapping fields of view with one another. The task is challenging due to the lack of knowledge about the topological structure of the network, variations in the appearance and motion of specific tracking targets in different views, and the difficulties of understanding composite events in the network. In this review paper, we present a comprehensive survey of recent research results to address the problems of intra-camera tracking, topological structure learning, target appearance modeling, and global activity understanding in sparse camera networks. A number of current open research issues are discussed.\n    ",
        "submission_date": "2013-02-03T00:00:00",
        "last_modified_date": "2013-02-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1302.0494",
        "title": "Local Structure Matching Driven by Joint-Saliency-Structure Adaptive Kernel Regression",
        "authors": [
            "Binjie Qin",
            "Zhuangming Shen",
            "Zien Zhou",
            "Jiawei Zhou",
            "Jiuai Sun",
            "Hui Zhang",
            "Mingxing Hu",
            "Yisong Lv"
        ],
        "abstract": "For nonrigid image registration, matching the particular structures (or the outliers) that have missing correspondence and/or local large deformations, can be more difficult than matching the common structures with small deformations in the two images. Most existing works depend heavily on the outlier segmentation to remove the outlier effect in the registration. Moreover, these works do not handle simultaneously the missing correspondences and local large deformations. In this paper, we defined the nonrigid image registration as a local adaptive kernel regression which locally reconstruct the moving image's dense deformation vectors from the sparse deformation vectors in the multi-resolution block matching. The kernel function of the kernel regression adapts its shape and orientation to the reference image's structure to gather more deformation vector samples of the same structure for the iterative regression computation, whereby the moving image's local deformations could be compliant with the reference image's local structures. To estimate the local deformations around the outliers, we use joint saliency map that highlights the corresponding saliency structures (called Joint Saliency Structures, JSSs) in the two images to guide the dense deformation reconstruction by emphasizing those JSSs' sparse deformation vectors in the kernel regression. The experimental results demonstrate that by using local JSS adaptive kernel regression, the proposed method achieves almost the best performance in alignment of all challenging image pairs with outlier structures compared with other five state-of-the-art nonrigid registration algorithms.\n    ",
        "submission_date": "2013-02-03T00:00:00",
        "last_modified_date": "2013-04-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1302.0689",
        "title": "Multi-scale Visual Attention & Saliency Modelling with Decision Theory",
        "authors": [
            "Anh Cat Le Ngo",
            "Li-Minn Ang",
            "Guoping Qiu",
            "Kah-Phooi Seng"
        ],
        "abstract": "Bottom-up saliency, an early human visual processing, behaves like binary classification of interest and null hypothesis. Its discriminant power, mutual information of image features and class distribution, is closely related to saliency value by the well-known centre-surround theory. As classification accuracy very much depends on window sizes, the discriminant saliency (power) varies according to sampling scales. Discriminating power estimation in multi-scales framework needs integrating with wavelet transformation and then estimating statistical discrepancy of two consecutive scales (centre-surround windows) by Hidden Markov Tree (HMT) model. Finally, multi-scale discriminant saliency (MDIS) maps are combined by the maximum information rule to synthesize a final saliency map. All MDIS maps are evaluated with standard quantitative tools (NSS,LCC,AUC) on ",
        "submission_date": "2013-02-04T00:00:00",
        "last_modified_date": "2013-02-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1302.1007",
        "title": "Image Denoising Using Interquartile Range Filter with Local Averaging",
        "authors": [
            "Firas Ajil Jassim"
        ],
        "abstract": "Image denoising is one of the fundamental problems in image processing. In this paper, a novel approach to suppress noise from the image is conducted by applying the interquartile range (IQR) which is one of the statistical methods used to detect outlier effect from a dataset. A window of size kXk was implemented to support IQR filter. Each pixel outside the IQR range of the kXk window is treated as noisy pixel. The estimation of the noisy pixels was obtained by local averaging. The essential advantage of applying IQR filter is to preserve edge sharpness better of the original image. A variety of test images have been used to support the proposed filter and PSNR was calculated and compared with median filter. The experimental results on standard test images demonstrate this filter is simpler and better performing than median filter.\n    ",
        "submission_date": "2013-02-05T00:00:00",
        "last_modified_date": "2013-02-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1302.1294",
        "title": "Image Interpolation Using Kriging Technique for Spatial Data",
        "authors": [
            "Firas Ajil Jassim",
            "Fawzi Hasan Altaany"
        ],
        "abstract": "Image interpolation has been used spaciously by customary interpolation techniques. Recently, Kriging technique has been widely implemented in simulation area and geostatistics for prediction. In this article, Kriging technique was used instead of the classical interpolation methods to predict the unknown points in the digital image array. The efficiency of the proposed technique was proven using the PSNR and compared with the traditional interpolation techniques. The results showed that Kriging technique is almost accurate as cubic interpolation and in some images Kriging has higher accuracy. A miscellaneous test images have been used to consolidate the proposed technique.\n    ",
        "submission_date": "2013-02-06T00:00:00",
        "last_modified_date": "2013-02-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1302.1296",
        "title": "Hybrid Image Segmentation using Discerner Cluster in FCM and Histogram Thresholding",
        "authors": [
            "Firas Ajil Jassim"
        ],
        "abstract": "Image thresholding has played an important role in image segmentation. This paper presents a hybrid approach for image segmentation based on the thresholding by fuzzy c-means (THFCM) algorithm for image segmentation. The goal of the proposed approach is to find a discerner cluster able to find an automatic threshold. The algorithm is formulated by applying the standard FCM clustering algorithm to the frequencies (y-values) on the smoothed histogram. Hence, the frequencies of an image can be used instead of the conventional whole data of image. The cluster that has the highest peak which represents the maximum frequency in the image histogram will play as an excellent role in determining a discerner cluster to the grey level image. Then, the pixels belong to the discerner cluster represent an object in the gray level histogram while the other clusters represent a background. Experimental results with standard test images have been obtained through the proposed approach (THFCM).\n    ",
        "submission_date": "2013-02-06T00:00:00",
        "last_modified_date": "2013-02-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1302.1300",
        "title": "Kriging Interpolation Filter to Reduce High Density Salt and Pepper Noise",
        "authors": [
            "Firas Ajil Jassim"
        ],
        "abstract": "Image denoising is a critical issue in the field of digital image processing. This paper proposes a novel Salt & Pepper noise suppression by developing a Kriging Interpolation Filter (KIF) for image denoising. Gray-level images degraded with Salt & Pepper noise have been considered. A sequential search for noise detection was made using kXk window size to determine non-noisy pixels only. The non-noisy pixels are passed into Kriging interpolation method to predict their absent neighbor pixels that were noisy pixels at the first phase. The utilization of Kriging interpolation filter proves that it is very impressive to suppress high noise density. It has been found that Kriging Interpolation filter achieves noise reduction without loss of edges and detailed information. Comparisons with existing algorithms are done using quality metrics like PSNR and MSE to assess the proposed filter.\n    ",
        "submission_date": "2013-02-06T00:00:00",
        "last_modified_date": "2013-02-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1302.1326",
        "title": "Cloud Computing framework for Computer Vision Research:An Introduction",
        "authors": [
            "Yu Zhou"
        ],
        "abstract": "Cloud computing offers the potential to help scientists to process massive number of computing resources often required in machine learning application such as computer vision problems. This proposal would like to show that which benefits can be obtained from cloud in order to help medical image analysis users (including scientists, clinicians, and research institutes). As security and privacy of algorithms are important for most of algorithms inventors, these algorithms can be hidden in a cloud to allow the users to use the algorithms as a package without any access to see/change their inside. In another word, in the user part, users send their images to the cloud and configure the algorithm via an interface. In the cloud part, the algorithms are applied to this image and the results are returned back to the user. My proposal has two parts: (1) investigate the potential of cloud computing for computer vision problems and (2) study the components of a proposed cloud-based framework for medical image analysis application and develop them (depending on the length of the internship). The investigation part will involve a study on several aspects of the problem including security, usability (for medical end users of the service), appropriate programming abstractions for vision problems, scalability and resource requirements. In the second part of this proposal I am going to thoroughly study of the proposed framework components and their relations and develop them. The proposed cloud-based framework includes an integrated environment to enable scientists and clinicians to access to the previous and current medical image analysis algorithms using a handful user interface without any access to the algorithm codes and procedures.\n    ",
        "submission_date": "2013-02-06T00:00:00",
        "last_modified_date": "2013-02-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1302.1539",
        "title": "Image Segmentation in Video Sequences: A Probabilistic Approach",
        "authors": [
            "Nir Friedman",
            "Stuart Russell"
        ],
        "abstract": "\"Background subtraction\" is an old technique for finding moving objects in a video sequence for example, cars driving on a freeway. The idea is that subtracting the current image from a timeaveraged background image will leave only nonstationary objects. It is, however, a crude approximation to the task of classifying each pixel of the current image; it fails with slow-moving objects and does not distinguish shadows from moving objects. The basic idea of this paper is that we can classify each pixel using a model of how that pixel looks when it is part of different classes. We learn a mixture-of-Gaussians classification model for each pixel using an unsupervised technique- an efficient, incremental version of EM. Unlike the standard image-averaging approach, this automatically updates the mixture component for each class according to likelihood of membership; hence slow-moving objects are handled perfectly. Our approach also identifies and eliminates shadows much more effectively than other techniques such as thresholding. Application of this method as part of the Roadwatch traffic surveillance project is expected to result in significant improvements in vehicle identification and tracking.\n    ",
        "submission_date": "2013-02-06T00:00:00",
        "last_modified_date": "2013-02-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1302.1690",
        "title": "A Fast Learning Algorithm for Image Segmentation with Max-Pooling Convolutional Networks",
        "authors": [
            "Jonathan Masci",
            "Alessandro Giusti",
            "Dan Cire\u015fan",
            "Gabriel Fricout",
            "J\u00fcrgen Schmidhuber"
        ],
        "abstract": "We present a fast algorithm for training MaxPooling Convolutional Networks to segment images. This type of network yields record-breaking performance in a variety of tasks, but is normally trained on a computationally expensive patch-by-patch basis. Our new method processes each training image in a single pass, which is vastly more efficient.\n",
        "submission_date": "2013-02-07T00:00:00",
        "last_modified_date": "2013-02-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1302.1700",
        "title": "Fast Image Scanning with Deep Max-Pooling Convolutional Neural Networks",
        "authors": [
            "Alessandro Giusti",
            "Dan C. Cire\u015fan",
            "Jonathan Masci",
            "Luca M. Gambardella",
            "J\u00fcrgen Schmidhuber"
        ],
        "abstract": "Deep Neural Networks now excel at image classification, detection and segmentation. When used to scan images by means of a sliding window, however, their high computational complexity can bring even the most powerful hardware to its knees. We show how dynamic programming can speedup the process by orders of magnitude, even when max-pooling layers are present.\n    ",
        "submission_date": "2013-02-07T00:00:00",
        "last_modified_date": "2013-02-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1302.1789",
        "title": "Lensless Compressive Sensing Imaging",
        "authors": [
            "Gang Huang",
            "Hong Jiang",
            "Kim Matthews",
            "Paul Wilford"
        ],
        "abstract": "In this paper, we propose a lensless compressive sensing imaging architecture. The architecture consists of two components, an aperture assembly and a sensor. No lens is used. The aperture assembly consists of a two dimensional array of aperture elements. The transmittance of each aperture element is independently controllable. The sensor is a single detection element, such as a single photo-conductive cell. Each aperture element together with the sensor defines a cone of a bundle of rays, and the cones of the aperture assembly define the pixels of an image. Each pixel value of an image is the integration of the bundle of rays in a cone. The sensor is used for taking compressive measurements. Each measurement is the integration of rays in the cones modulated by the transmittance of the aperture elements. A compressive sensing matrix is implemented by adjusting the transmittance of the individual aperture elements according to the values of the sensing matrix. The proposed architecture is simple and reliable because no lens is used. Furthermore, the sharpness of an image from our device is only limited by the resolution of the aperture assembly, but not affected by blurring due to defocus. The architecture can be used for capturing images of visible lights, and other spectra such as infrared, or millimeter waves. Such devices may be used in surveillance applications for detecting anomalies or extracting features such as speed of moving objects. Multiple sensors may be used with a single aperture assembly to capture multi-view images simultaneously. A prototype was built by using a LCD panel and a photoelectric sensor for capturing images of visible spectrum.\n    ",
        "submission_date": "2013-02-07T00:00:00",
        "last_modified_date": "2013-02-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1302.1942",
        "title": "Surveillance Video Processing Using Compressive Sensing",
        "authors": [
            "Hong Jiang",
            "Wei Deng",
            "Zuowei Shen"
        ],
        "abstract": "A compressive sensing method combined with decomposition of a matrix formed with image frames of a surveillance video into low rank and sparse matrices is proposed to segment the background and extract moving objects in a surveillance video. The video is acquired by compressive measurements, and the measurements are used to reconstruct the video by a low rank and sparse decomposition of matrix. The low rank component represents the background, and the sparse component is used to identify moving objects in the surveillance video. The decomposition is performed by an augmented Lagrangian alternating direction method. Experiments are carried out to demonstrate that moving objects can be reliably extracted with a small amount of measurements.\n    ",
        "submission_date": "2013-02-08T00:00:00",
        "last_modified_date": "2013-02-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1302.2073",
        "title": "pROST : A Smoothed Lp-norm Robust Online Subspace Tracking Method for Realtime Background Subtraction in Video",
        "authors": [
            "Florian Seidel",
            "Clemens Hage",
            "Martin Kleinsteuber"
        ],
        "abstract": "An increasing number of methods for background subtraction use Robust PCA to identify sparse foreground objects. While many algorithms use the L1-norm as a convex relaxation of the ideal sparsifying function, we approach the problem with a smoothed Lp-norm and present pROST, a method for robust online subspace tracking. The algorithm is based on alternating minimization on manifolds. Implemented on a graphics processing unit it achieves realtime performance. Experimental results on a state-of-the-art benchmark for background subtraction on real-world video data indicate that the method succeeds at a broad variety of background subtraction scenarios, and it outperforms competing approaches when video quality is deteriorated by camera jitter.\n    ",
        "submission_date": "2013-02-08T00:00:00",
        "last_modified_date": "2013-03-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1302.2575",
        "title": "Coded aperture compressive temporal imaging",
        "authors": [
            "Patrick Llull",
            "Xuejun Liao",
            "Xin Yuan",
            "Jianbo Yang",
            "David Kittle",
            "Lawrence Carin",
            "Guillermo Sapiro",
            "David J. Brady"
        ],
        "abstract": "We use mechanical translation of a coded aperture for code division multiple access compression of video. We present experimental results for reconstruction at 148 frames per coded snapshot.\n    ",
        "submission_date": "2013-02-04T00:00:00",
        "last_modified_date": "2013-02-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1302.2712",
        "title": "Bayesian Nonparametric Dictionary Learning for Compressed Sensing MRI",
        "authors": [
            "Yue Huang",
            "John Paisley",
            "Qin Lin",
            "Xinghao Ding",
            "Xueyang Fu",
            "Xiao-ping Zhang"
        ],
        "abstract": "We develop a Bayesian nonparametric model for reconstructing magnetic resonance images (MRI) from highly undersampled k-space data. We perform dictionary learning as part of the image reconstruction process. To this end, we use the beta process as a nonparametric dictionary learning prior for representing an image patch as a sparse combination of dictionary elements. The size of the dictionary and the patch-specific sparsity pattern are inferred from the data, in addition to other dictionary learning variables. Dictionary learning is performed directly on the compressed image, and so is tailored to the MRI being considered. In addition, we investigate a total variation penalty term in combination with the dictionary learning model, and show how the denoising property of dictionary learning removes dependence on regularization parameters in the noisy setting. We derive a stochastic optimization algorithm based on Markov Chain Monte Carlo (MCMC) for the Bayesian model, and use the alternating direction method of multipliers (ADMM) for efficiently performing total variation minimization. We present empirical results on several MRI, which show that the proposed regularization framework can improve reconstruction accuracy over other methods.\n    ",
        "submission_date": "2013-02-12T00:00:00",
        "last_modified_date": "2014-07-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1302.3119",
        "title": "Comparision and analysis of photo image forgery detection techniques",
        "authors": [
            "S.Murali",
            "Govindraj B. Chittapur",
            "Prabhakara H.S",
            "Basavaraj S. Anami"
        ],
        "abstract": "Digital Photo images are everywhere, on the covers of magazines, in newspapers, in courtrooms, and all over the Internet. We are exposed to them throughout the day and most of the time. Ease with which images can be manipulated; we need to be aware that seeing does not always imply believing. We propose methodologies to identify such unbelievable photo images and succeeded to identify forged region by given only the forged image. Formats are additive tag for every file system and contents are relatively expressed with extension based on most popular digital camera uses JPEG and Other image formats like png, bmp etc. We have designed algorithm running behind with the concept of abnormal anomalies and identify the forgery regions.\n    ",
        "submission_date": "2013-01-10T00:00:00",
        "last_modified_date": "2013-01-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1302.3123",
        "title": "An Analysis of Gene Expression Data using Penalized Fuzzy C-Means Approach",
        "authors": [
            "P. K. Nizar Banu",
            "H. Hannah Inbarani"
        ],
        "abstract": "With the rapid advances of microarray technologies, large amounts of high-dimensional gene expression data are being generated, which poses significant computational challenges. A first step towards addressing this challenge is the use of clustering techniques, which is essential in the data mining process to reveal natural structures and identify interesting patterns in the underlying data. A robust gene expression clustering approach to minimize undesirable clustering is proposed. In this paper, Penalized Fuzzy C-Means (PFCM) Clustering algorithm is described and compared with the most representative off-line clustering techniques: K-Means Clustering, Rough K-Means Clustering and Fuzzy C-Means clustering. These techniques are implemented and tested for a Brain Tumor gene expression Dataset. Analysis of the performance of the proposed approach is presented through qualitative validation experiments. From experimental results, it can be observed that Penalized Fuzzy C-Means algorithm shows a much higher usability than the other projected clustering algorithms used in our comparison study. Significant and promising clustering results are presented using Brain Tumor Gene expression dataset. Thus patterns seen in genome-wide expression experiments can be interpreted as indications of the status of cellular processes. In these clustering results, we find that Penalized Fuzzy C-Means algorithm provides useful information as an aid to diagnosis in oncology.\n    ",
        "submission_date": "2013-01-08T00:00:00",
        "last_modified_date": "2013-01-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1302.3155",
        "title": "Morphological Analusis Of The Left Ventricular Eendocardial Surface Using A Bag-Of-Features Descriptor",
        "authors": [
            "Anirban Mukhopadhyay",
            "Zhen Qian",
            "Suchendra M. Bhandarkar",
            "Tianming Liu",
            "Sarah Rinehart",
            "Szilard Voros"
        ],
        "abstract": "The limitations of conventional imaging techniques have hitherto precluded a thorough and formal investigation of the complex morphology of the left ventricular (LV) endocardial surface and its relation to the severity of Coronary Artery Disease (CAD). Recent developments in high-resolution Multirow-Detector Computed Tomography (MDCT) scanner technology have enabled the imaging of LV endocardial surface morphology in a single heart beat. Analysis of high-resolution Computed Tomography (CT) images from a 320-MDCT scanner allows the study of the relationship between percent Diameter Stenosis (DS) of the major coronary arteries and localization of the cardiac segments affected by coronary arterial stenosis. In this paper a novel approach for the analysis using a combination of rigid transformation-invariant shape descriptors and a more generalized isometry-invariant Bag-of-Features (BoF) descriptor, is proposed and implemented. The proposed approach is shown to be successful in identifying, localizing and quantifying the incidence and extent of CAD and thus, is seen to have a potentially significant clinical impact. Specifically, the association between the incidence and extent of CAD, determined via the percent DS measurements of the major coronary arteries, and the alterations in the endocardial surface morphology is formally quantified. A multivariate regression test performed on a strict leave-one-out basis are shown to exhibit a distinct pattern in terms of the correlation coefficient within the cardiac segments where the incidence of coronary arterial stenosis is localized.\n    ",
        "submission_date": "2013-02-13T00:00:00",
        "last_modified_date": "2013-02-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1302.3556",
        "title": "Object Recognition with Imperfect Perception and Redundant Description",
        "authors": [
            "Claude Barrouil",
            "Jerome Lemaire"
        ],
        "abstract": "This paper deals with a scene recognition system in a robotics contex.  The general problem is to match images with <I>a priori</I> descriptions.  A typical mission would consist in identifying an object in an installation with a vision system situated at the end of a manipulator and with a human operator provided description, formulated in a pseudo-natural language, and possibly redundant.  The originality of this work comes from the nature of the description, from the special attention given to the management of imprecision and uncertainty in the interpretation process and from the way to assess the description redundancy so as to reinforce the overall matching likelihood.\n    ",
        "submission_date": "2013-02-13T00:00:00",
        "last_modified_date": "2013-02-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1302.3785",
        "title": "Analysis of Descent-Based Image Registration",
        "authors": [
            "Elif Vural",
            "Pascal Frossard"
        ],
        "abstract": "We present a performance analysis for image registration with gradient descent methods. We consider a typical multiscale registration setting where the global 2-D translation between a pair of images is estimated by smoothing the images and minimizing the distance between them with gradient descent. Our study particularly concentrates on the effect of noise and low-pass filtering on the alignment accuracy. We adopt an analytic representation for images and analyze the well-behavedness of the image distance function by estimating the neighborhood of translations for which it is free of undesired local minima. This corresponds to the neighborhood of translation vectors that are correctly computable with a simple gradient descent minimization. We show that the area of this neighborhood increases at least quadratically with the smoothing filter size, which justifies the use of a smoothing step in image registration with local optimizers such as gradient descent. We then examine the effect of noise on the alignment accuracy and derive an upper bound for the alignment error in terms of the noise properties and filter size. Our main finding is that the error increases at a rate that is at least linear with respect to the filter size. Therefore, smoothing improves the well-behavedness of the distance function; however, this comes at the cost of amplifying the alignment error in noisy settings. Our results provide a mathematical insight about why hierarchical techniques are effective in image registration, suggesting that the multiscale coarse-to-fine alignment strategy of these techniques is very suitable from the perspective of the trade-off between the well-behavedness of the objective function and the registration accuracy. To the best of our knowledge, this is the first such study for descent-based image registration.\n    ",
        "submission_date": "2013-02-15T00:00:00",
        "last_modified_date": "2013-08-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1302.3900",
        "title": "Robust Image Segmentation in Low Depth Of Field Images",
        "authors": [
            "Franz Graf",
            "Hans-Peter Kriegel",
            "Michael Weiler"
        ],
        "abstract": "In photography, low depth of field (DOF) is an important technique to emphasize the object of interest (OOI) within an image. Thus, low DOF images are widely used in the application area of macro, portrait or sports photography. When viewing a low DOF image, the viewer implicitly concentrates on the regions that are sharper regions of the image and thus segments the image into regions of interest and non regions of interest which has a major impact on the perception of the image. Thus, a robust algorithm for the fully automatic detection of the OOI in low DOF images provides valuable information for subsequent image processing and image retrieval. In this paper we propose a robust and parameterless algorithm for the fully automatic segmentation of low DOF images. We compare our method with three similar methods and show the superior robustness even though our algorithm does not require any parameters to be set by hand. The experiments are conducted on a real world data set with high and low DOF images.\n    ",
        "submission_date": "2013-02-15T00:00:00",
        "last_modified_date": "2013-02-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1302.4043",
        "title": "A new scheme of signature extraction for iris authentication",
        "authors": [
            "Belhassen Akrout",
            "Imen Khanfir Kallel",
            "Chokri Ben Amar"
        ],
        "abstract": "Iris recognition, a relatively new biometric technology, has great advantages, such as variability, stability and security, thus is the most promising for high security environment. Iris recognition is proposed in this report. We describe some methods, the first one is based on grey level histogram to extract the pupil, the second is based on elliptic and parabolic HOUGH transformation to determinate the edge of iris, upper and lower eyelids, the third we used 2D Gabor Wavelets to encode the iris and finally we used the Hamming distance for authentication.\n    ",
        "submission_date": "2013-02-17T00:00:00",
        "last_modified_date": "2013-02-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1302.4673",
        "title": "Good Recognition is Non-Metric",
        "authors": [
            "Walter J. Scheirer",
            "Michael J. Wilber",
            "Michael Eckmann",
            "Terrance E. Boult"
        ],
        "abstract": "Recognition is the fundamental task of visual cognition, yet how to formalize the general recognition problem for computer vision remains an open issue. The problem is sometimes reduced to the simplest case of recognizing matching pairs, often structured to allow for metric constraints. However, visual recognition is broader than just pair matching -- especially when we consider multi-class training data and large sets of features in a learning context. What we learn and how we learn it has important implications for effective algorithms. In this paper, we reconsider the assumption of recognition as a pair matching test, and introduce a new formal definition that captures the broader context of the problem. Through a meta-analysis and an experimental assessment of the top algorithms on popular data sets, we gain a sense of how often metric properties are violated by good recognition algorithms. By studying these violations, useful insights come to light: we make the case that locally metric algorithms should leverage outside information to solve the general recognition problem.\n    ",
        "submission_date": "2013-02-19T00:00:00",
        "last_modified_date": "2013-02-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1302.5010",
        "title": "Matching Pursuit LASSO Part II: Applications and Sparse Recovery over Batch Signals",
        "authors": [
            "Mingkui Tan",
            "Ivor W. Tsang",
            "Li Wang"
        ],
        "abstract": "Matching Pursuit LASSIn Part I \\cite{TanPMLPart1}, a Matching Pursuit LASSO ({MPL}) algorithm has been presented for solving large-scale sparse recovery (SR) problems. In this paper, we present a subspace search to further improve the performance of MPL, and then continue to address another major challenge of SR -- batch SR with many signals, a consideration which is absent from most of previous $\\ell_1$-norm methods. As a result, a batch-mode {MPL} is developed to vastly speed up sparse recovery of many signals simultaneously. Comprehensive numerical experiments on compressive sensing and face recognition tasks demonstrate the superior performance of MPL and BMPL over other methods considered in this paper, in terms of sparse recovery ability and efficiency. In particular, BMPL is up to 400 times faster than existing $\\ell_1$-norm methods considered to be state-of-the-art.O Part II: Applications and Sparse Recovery over Batch Signals\n    ",
        "submission_date": "2013-02-20T00:00:00",
        "last_modified_date": "2014-12-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1302.5056",
        "title": "Pooling-Invariant Image Feature Learning",
        "authors": [
            "Yangqing Jia",
            "Oriol Vinyals",
            "Trevor Darrell"
        ],
        "abstract": "Unsupervised dictionary learning has been a key component in state-of-the-art computer vision recognition architectures. While highly effective methods exist for patch-based dictionary learning, these methods may learn redundant features after the pooling stage in a given early vision architecture. In this paper, we offer a novel dictionary learning scheme to efficiently take into account the invariance of learned features after the spatial pooling stage. The algorithm is built on simple clustering, and thus enjoys efficiency and scalability. We discuss the underlying mechanism that justifies the use of clustering algorithms, and empirically show that the algorithm finds better dictionaries than patch-based methods with the same dictionary size.\n    ",
        "submission_date": "2013-01-15T00:00:00",
        "last_modified_date": "2013-01-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1302.5186",
        "title": "Unsupervised edge map scoring: a statistical complexity approach",
        "authors": [
            "Javier Gimenez",
            "Jorge Martinez",
            "Ana Georgina Flesia"
        ],
        "abstract": "We propose a new Statistical Complexity Measure (SCM) to qualify edge maps without Ground Truth (GT) knowledge. The measure is the product of two indices, an \\emph{Equilibrium} index $\\mathcal{E}$ obtained by projecting the edge map into a family of edge patterns, and an \\emph{Entropy} index $\\mathcal{H}$, defined as a function of the Kolmogorov Smirnov (KS) statistic.\n",
        "submission_date": "2013-02-21T00:00:00",
        "last_modified_date": "2014-02-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1302.5189",
        "title": "Object Detection in Real Images",
        "authors": [
            "Dilip K. Prasad"
        ],
        "abstract": "Object detection and recognition are important problems in computer vision. Since these problems are meta-heuristic, despite a lot of research, practically usable, intelligent, real-time, and dynamic object detection/recognition methods are still unavailable. We propose a new object detection/recognition method, which improves over the existing methods in every stage of the object detection/recognition process. In addition to the usual features, we propose to use geometric shapes, like linear cues, ellipses and quadrangles, as additional features. The full potential of geometric cues is exploited by using them to extract other features in a robust, computationally efficient, and less meta-heuristic manner. We also propose a new hierarchical codebook, which provides good generalization and discriminative properties. The codebook enables fast multi-path inference mechanisms based on propagation of conditional likelihoods, that make it robust to occlusion and noise. It has the capability of dynamic learning. We also propose a new learning method that has generative and discriminative learning capabilities, does not need large and fully supervised training dataset, and is capable of online learning. The preliminary work of detecting geometric shapes in real images has been completed. This preliminary work is the focus of this report. Future path for realizing the proposed object detection/recognition method is also discussed in brief.\n    ",
        "submission_date": "2013-02-21T00:00:00",
        "last_modified_date": "2013-02-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1302.5762",
        "title": "Probabilistic Non-Local Means",
        "authors": [
            "Yue Wu",
            "Brian Tracey",
            "Premkumar Natarajan",
            "Joseph P. Noonan"
        ],
        "abstract": "In this paper, we propose a so-called probabilistic non-local means (PNLM) method for image denoising. Our main contributions are: 1) we point out defects of the weight function used in the classic NLM; 2) we successfully derive all theoretical statistics of patch-wise differences for Gaussian noise; and 3) we employ this prior information and formulate the probabilistic weights truly reflecting the similarity between two noisy patches. The probabilistic nature of the new weight function also provides a theoretical basis to choose thresholds rejecting dissimilar patches for fast computations. Our simulation results indicate the PNLM outperforms the classic NLM and many NLM recent variants in terms of peak signal noise ratio (PSNR) and structural similarity (SSIM) index. Encouraging improvements are also found when we replace the NLM weights with the probabilistic weights in tested NLM variants.\n    ",
        "submission_date": "2013-02-23T00:00:00",
        "last_modified_date": "2013-02-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1302.5894",
        "title": "Four Side Distance: A New Fourier Shape Signature",
        "authors": [
            "Sonya Eini",
            "Abdolah Chalechale"
        ],
        "abstract": "Shape is one of the main features in content based image retrieval (CBIR). This paper proposes a new shape signature. In this technique, features of each shape are extracted based on four sides of the rectangle that covers the shape. The proposed technique is Fourier based and it is invariant to translation, scaling and rotation. The retrieval performance between some commonly used Fourier based signatures and the proposed four sides distance (FSD) signature has been tested using MPEG-7 database. Experimental results are shown that the FSD signature has better performance compared with those signatures.\n    ",
        "submission_date": "2013-02-24T00:00:00",
        "last_modified_date": "2013-02-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1302.5957",
        "title": "Shape Characterization via Boundary Distortion",
        "authors": [
            "Xavier Descombes",
            "Serguei Komech"
        ],
        "abstract": "In this paper, we derive new shape descriptors based on a directional characterization. The main idea is to study the behavior of the shape neighborhood under family of transformations. We obtain a description invariant with respect to rotation, reflection, translation and scaling. A well-defined metric is then proposed on the associated feature space. We show the continuity of this metric. Some results on shape retrieval are provided on two databases to show the accuracy of the proposed shape metric.\n    ",
        "submission_date": "2013-02-24T00:00:00",
        "last_modified_date": "2013-02-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1302.5985",
        "title": "A Meta-Theory of Boundary Detection Benchmarks",
        "authors": [
            "Xiaodi Hou",
            "Alan Yuille",
            "Christof Koch"
        ],
        "abstract": "Human labeled datasets, along with their corresponding evaluation algorithms, play an important role in boundary detection. We here present a psychophysical experiment that addresses the reliability of such benchmarks. To find better remedies to evaluate the performance of any boundary detection algorithm, we propose a computational framework to remove inappropriate human labels and estimate the intrinsic properties of boundaries.\n    ",
        "submission_date": "2013-02-25T00:00:00",
        "last_modified_date": "2013-02-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1302.6379",
        "title": "Image-based Face Detection and Recognition: \"State of the Art\"",
        "authors": [
            "Faizan Ahmad",
            "Aaima Najam",
            "Zeeshan Ahmed"
        ],
        "abstract": "Face recognition from image or video is a popular topic in biometrics research. Many public places usually have surveillance cameras for video capture and these cameras have their significant value for security purpose. It is widely acknowledged that the face recognition have played an important role in surveillance system as it doesn't need the object's cooperation. The actual advantages of face based identification over other biometrics are uniqueness and acceptance. As human face is a dynamic object having high degree of variability in its appearance, that makes face detection a difficult problem in computer vision. In this field, accuracy and speed of identification is a main issue.\n",
        "submission_date": "2013-02-26T00:00:00",
        "last_modified_date": "2013-02-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1302.6557",
        "title": "Geodesic-based Salient Object Detection",
        "authors": [
            "Richard M Jiang"
        ],
        "abstract": "Saliency detection has been an intuitive way to provide useful cues for object detection and segmentation, as desired for many vision and graphics applications. In this paper, we provided a robust method for salient object detection and segmentation. Other than using various pixel-level contrast definitions, we exploited global image structures and proposed a new geodesic method dedicated for salient object detection. In the proposed approach, a new geodesic scheme, namely geodesic tunneling is proposed to tackle with textures and local chaotic structures. With our new geodesic approach, a geodesic saliency map is estimated in correspondence to spatial structures in an image. Experimental evaluation on a salient object benchmark dataset validated that our algorithm consistently outperformed a number of the state-of-art saliency methods, yielding higher precision and better recall rates. With the robust saliency estimation, we also present an unsupervised hierarchical salient object cut scheme simply using adaptive saliency thresholding, which attained the highest score in our F-measure test. We also applied our geodesic cut scheme to a number of image editing tasks as demonstrated in additional experiments.\n    ",
        "submission_date": "2013-02-26T00:00:00",
        "last_modified_date": "2013-08-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1302.6957",
        "title": "Ensemble Sparse Models for Image Analysis",
        "authors": [
            "Karthikeyan Natesan Ramamurthy",
            "Jayaraman J. Thiagarajan",
            "Prasanna Sattigeri",
            "Andreas Spanias"
        ],
        "abstract": "Sparse representations with learned dictionaries have been successful in several image analysis applications. In this paper, we propose and analyze the framework of ensemble sparse models, and demonstrate their utility in image restoration and unsupervised clustering. The proposed ensemble model approximates the data as a linear combination of approximations from multiple \\textit{weak} sparse models. Theoretical analysis of the ensemble model reveals that even in the worst-case, the ensemble can perform better than any of its constituent individual models. The dictionaries corresponding to the individual sparse models are obtained using either random example selection or boosted approaches. Boosted approaches learn one dictionary per round such that the dictionary learned in a particular round is optimized for the training examples having high reconstruction error in the previous round. Results with compressed recovery show that the ensemble representations lead to a better performance compared to using a single dictionary obtained with the conventional alternating minimization approach. The proposed ensemble models are also used for single image superresolution, and we show that they perform comparably to the recent approaches. In unsupervised clustering, experiments show that the proposed model performs better than baseline approaches in several standard datasets.\n    ",
        "submission_date": "2013-02-27T00:00:00",
        "last_modified_date": "2013-02-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1302.7082",
        "title": "K Means Segmentation of Alzheimers Disease in PET scan datasets: An implementation",
        "authors": [
            "A.Meena",
            "K.Raja"
        ],
        "abstract": "The Positron Emission Tomography (PET) scan image requires expertise in the segmentation where clustering algorithm plays an important role in the automation process. The algorithm optimization is concluded based on the performance, quality and number of clusters extracted. This paper is proposed to study the commonly used K Means clustering algorithm and to discuss a brief list of toolboxes for reproducing and extending works presented in medical image analysis. This work is compiled using AForge .NET framework in windows environment and MATrix LABoratory (MATLAB 7.0.1)\n    ",
        "submission_date": "2013-02-28T00:00:00",
        "last_modified_date": "2013-02-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1302.7180",
        "title": "Fast Matching by 2 Lines of Code for Large Scale Face Recognition Systems",
        "authors": [
            "Dong Yi",
            "Zhen Lei",
            "Yang Hu",
            "Stan Z. Li"
        ],
        "abstract": "In this paper, we propose a method to apply the popular cascade classifier into face recognition to improve the computational efficiency while keeping high recognition rate. In large scale face recognition systems, because the probability of feature templates coming from different subjects is very high, most of the matching pairs will be rejected by the early stages of the cascade. Therefore, the cascade can improve the matching speed significantly. On the other hand, using the nested structure of the cascade, we could drop some stages at the end of feature to reduce the memory and bandwidth usage in some resources intensive system while not sacrificing the performance too much. The cascade is learned by two steps. Firstly, some kind of prepared features are grouped into several nested stages. And then, the threshold of each stage is learned to achieve user defined verification rate (VR). In the paper, we take a landmark based Gabor+LDA face recognition system as baseline to illustrate the process and advantages of the proposed method. However, the use of this method is very generic and not limited in face recognition, which can be easily generalized to other biometrics as a post-processing module. Experiments on the FERET database show the good performance of our baseline and an experiment on a self-collected large scale database illustrates that the cascade can improve the matching speed significantly.\n    ",
        "submission_date": "2013-02-28T00:00:00",
        "last_modified_date": "2013-02-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1303.0417",
        "title": "On the convergence of the IRLS algorithm in Non-Local Patch Regression",
        "authors": [
            "Kunal N. Chaudhury"
        ],
        "abstract": "Recently, it was demonstrated in [CS2012,CS2013] that the robustness of the classical Non-Local Means (NLM) algorithm [BCM2005] can be improved by incorporating $\\ell^p (0 < p \\leq 2)$ regression into the NLM framework. This general optimization framework, called Non-Local Patch Regression (NLPR), contains NLM as a special case. Denoising results on synthetic and natural images show that NLPR consistently performs better than NLM beyond a moderate noise level, and significantly so when $p$ is close to zero. An iteratively reweighted least-squares (IRLS) algorithm was proposed for solving the regression problem in NLPR, where the NLM output was used to initialize the iterations. Based on exhaustive numerical experiments, we observe that the IRLS algorithm is globally convergent (for arbitrary initialization) in the convex regime $1 \\leq p \\leq 2$, and locally convergent (fails very rarely using NLM initialization) in the non-convex regime $0 < p < 1$. In this letter, we adapt the \"majorize-minimize\" framework introduced in [Voss1980] to explain these observations.\n",
        "submission_date": "2013-03-02T00:00:00",
        "last_modified_date": "2013-04-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1303.0448",
        "title": "Learning Stable Multilevel Dictionaries for Sparse Representations",
        "authors": [
            "Jayaraman J. Thiagarajan",
            "Karthikeyan Natesan Ramamurthy",
            "Andreas Spanias"
        ],
        "abstract": "Sparse representations using learned dictionaries are being increasingly used with success in several data processing and machine learning applications. The availability of abundant training data necessitates the development of efficient, robust and provably good dictionary learning algorithms. Algorithmic stability and generalization are desirable characteristics for dictionary learning algorithms that aim to build global dictionaries which can efficiently model any test data similar to the training samples. In this paper, we propose an algorithm to learn dictionaries for sparse representations from large scale data, and prove that the proposed learning algorithm is stable and generalizable asymptotically. The algorithm employs a 1-D subspace clustering procedure, the K-hyperline clustering, in order to learn a hierarchical dictionary with multiple levels. We also propose an information-theoretic scheme to estimate the number of atoms needed in each level of learning and develop an ensemble approach to learn robust dictionaries. Using the proposed dictionaries, the sparse code for novel test data can be computed using a low-complexity pursuit procedure. We demonstrate the stability and generalization characteristics of the proposed algorithm using simulations. We also evaluate the utility of the multilevel dictionaries in compressed recovery and subspace learning applications.\n    ",
        "submission_date": "2013-03-03T00:00:00",
        "last_modified_date": "2013-09-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1303.0460",
        "title": "Genetic Programming for Document Segmentation and Region Classification Using Discipulus",
        "authors": [
            "N. Priyadharshini",
            "M.S. Vijaya"
        ],
        "abstract": "Document segmentation is a method of rending the document into distinct regions. A document is an assortment of information and a standard mode of conveying information to others. Pursuance of data from documents involves ton of human effort, time intense and might severely prohibit the usage of data systems. So, automatic information pursuance from the document has become a big issue. It is been shown that document segmentation will facilitate to beat such problems. This paper proposes a new approach to segment and classify the document regions as text, image, drawings and table. Document image is divided into blocks using Run length smearing rule and features are extracted from every blocks. Discipulus tool has been used to construct the Genetic programming based classifier model and located 97.5% classification accuracy.\n    ",
        "submission_date": "2013-03-03T00:00:00",
        "last_modified_date": "2013-03-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1303.0479",
        "title": "Scale Selection of Adaptive Kernel Regression by Joint Saliency Map for Nonrigid Image Registration",
        "authors": [
            "Zhuangming Shen",
            "Jiuai Sun",
            "Hui Zhang",
            "Binjie Qin"
        ],
        "abstract": "Joint saliency map (JSM) [1] was developed to assign high joint saliency values to the corresponding saliency structures (called Joint Saliency Structures, JSSs) but zero or low joint saliency values to the outliers (or mismatches) that are introduced by missing correspondence or local large deformations between the reference and moving images to be registered. JSM guides the local structure matching in nonrigid registration by emphasizing these JSSs' sparse deformation vectors in adaptive kernel regression of hierarchical sparse deformation vectors for iterative dense deformation reconstruction. By designing an effective superpixel-based local structure scale estimator to compute the reference structure's structure scale, we further propose to determine the scale (the width) of kernels in the adaptive kernel regression through combining the structure scales to JSM-based scales of mismatch between the local saliency structures. Therefore, we can adaptively select the sample size of sparse deformation vectors to reconstruct the dense deformation vectors for accurately matching the every local structures in the two images. The experimental results demonstrate better accuracy of our method in aligning two images with missing correspondence and local large deformation than the state-of-the-art methods.\n    ",
        "submission_date": "2013-03-03T00:00:00",
        "last_modified_date": "2013-04-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1303.0582",
        "title": "Multiple Kernel Sparse Representations for Supervised and Unsupervised Learning",
        "authors": [
            "Jayaraman J. Thiagarajan",
            "Karthikeyan Natesan Ramamurthy",
            "Andreas Spanias"
        ],
        "abstract": "In complex visual recognition tasks it is typical to adopt multiple descriptors, that describe different aspects of the images, for obtaining an improved recognition performance. Descriptors that have diverse forms can be fused into a unified feature space in a principled manner using kernel methods. Sparse models that generalize well to the test data can be learned in the unified kernel space, and appropriate constraints can be incorporated for application in supervised and unsupervised learning. In this paper, we propose to perform sparse coding and dictionary learning in the multiple kernel space, where the weights of the ensemble kernel are tuned based on graph-embedding principles such that class discrimination is maximized. In our proposed algorithm, dictionaries are inferred using multiple levels of 1-D subspace clustering in the kernel space, and the sparse codes are obtained using a simple levelwise pursuit scheme. Empirical results for object recognition and image clustering show that our algorithm outperforms existing sparse coding based approaches, and compares favorably to other state-of-the-art methods.\n    ",
        "submission_date": "2013-03-03T00:00:00",
        "last_modified_date": "2013-10-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1303.0633",
        "title": "Omega Model for Human Detection and Counting for application in Smart Surveillance System",
        "authors": [
            "Subra Mukherjee",
            "Karen Das"
        ],
        "abstract": "Driven by the significant advancements in technology and social issues such as security management, there is a strong need for Smart Surveillance System in our society today. One of the key features of a Smart Surveillance System is efficient human detection and counting such that the system can decide and label events on its own. In this paper we propose a new, novel and robust model, The Omega Model, for detecting and counting human beings present in the scene. The proposed model employs a set of four distinct descriptors for identifying the unique features of the head, neck and shoulder regions of a person. This unique head neck shoulder signature given by the Omega Model exploits the challenges such as inter person variations in size and shape of peoples head, neck and shoulder regions to achieve robust detection of human beings even under partial occlusion, dynamically changing background and varying illumination conditions. After experimentation we observe and analyze the influences of each of the four descriptors on the system performance and computation speed and conclude that a weight based decision making system produces the best results. Evaluation results on a number of images indicate the validation of our method in actual situation.\n    ",
        "submission_date": "2013-03-04T00:00:00",
        "last_modified_date": "2013-03-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1303.0634",
        "title": "Indian Sign Language Recognition Using Eigen Value Weighted Euclidean Distance Based Classification Technique",
        "authors": [
            "Joyeeta Singha",
            "Karen Das"
        ],
        "abstract": "Sign Language Recognition is one of the most growing fields of research today. Many new techniques have been developed recently in these fields. Here in this paper, we have proposed a system using Eigen value weighted Euclidean distance as a classification technique for recognition of various Sign Languages of India. The system comprises of four parts: Skin Filtering, Hand Cropping, Feature Extraction and Classification. Twenty four signs were considered in this paper, each having ten samples, thus a total of two hundred forty images was considered for which recognition rate obtained was 97 percent.\n    ",
        "submission_date": "2013-03-04T00:00:00",
        "last_modified_date": "2013-03-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1303.0635",
        "title": "Recognition of Facial Expression Using Eigenvector Based Distributed Features and Euclidean Distance Based Decision Making Technique",
        "authors": [
            "Jeemoni Kalita",
            "Karen Das"
        ],
        "abstract": "In this paper, an Eigenvector based system has been presented to recognize facial expressions from digital facial images. In the approach, firstly the images were acquired and cropping of five significant portions from the image was performed to extract and store the Eigenvectors specific to the expressions. The Eigenvectors for the test images were also computed, and finally the input facial image was recognized when similarity was obtained by calculating the minimum Euclidean distance between the test image and the different expressions.\n    ",
        "submission_date": "2013-03-04T00:00:00",
        "last_modified_date": "2013-03-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1303.0644",
        "title": "Automatic symmetry based cluster approach for anomalous brain identification in PET scan image : An Analysis",
        "authors": [
            "A. Meena",
            "K. Raja"
        ],
        "abstract": "Medical image segmentation is referred to the segmentation of known anatomic structures from different medical images. Normally, the medical data researches are more complicated and an exclusive structures. This computer aided diagnosis is used for assisting doctors in evaluating medical imagery or in recognizing abnormal findings in a medical image. To integrate the specialized knowledge for medical data processing is helpful to form a real useful healthcare decision making system. This paper studies the different symmetry based distances applied in clustering algorithms and analyzes symmetry approach for Positron Emission Tomography (PET) scan image segmentation. Unlike CT and MRI, the PET scan identifies the structure of blood flow to and from organs. PET scan also helps in early diagnosis of cancer and heart, brain and gastro intestinal ailments and to detect the progress of treatment. In this paper, the scope diagnostic task expands for PET image in various brain functions.\n    ",
        "submission_date": "2013-03-04T00:00:00",
        "last_modified_date": "2013-03-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1303.0645",
        "title": "Symmetry Based Cluster Approach for Automatic Recognition of the Epileptic Focus in Brain Using PET Scan Image : An Analysis",
        "authors": [
            "A. Meena",
            "R. Raja"
        ],
        "abstract": "Recognition of epileptic focal point is the important diagnosis when screening the epilepsy patients for latent surgical cures. The accurate localization is challenging one because of the low spatial resolution images with more noisy data. Positron Emission Tomography (PET) has now replaced the issues and caring a high resolution. This paper focuses the research of automated localization of epileptic seizures in brain functional images using symmetry based cluster approach. This approach presents a fully automated symmetry based brain abnormality detection method for PET sequences. PET images are spatially normalized to Digital Imaging and Communications in Medicine (DICOM) standard and then it has been trained using symmetry based cluster approach using Medical Image Processing, Analysis & Visualization (MIPAV) tool. The performance evolution is considered by the metric like accuracy of diagnosis. The obtained result is surely assists the surgeon for the automated identification of seizures focus.\n    ",
        "submission_date": "2013-03-04T00:00:00",
        "last_modified_date": "2013-03-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1303.0647",
        "title": "Spatial Fuzzy C Means PET Image Segmentation of Neurodegenerative Disorder",
        "authors": [
            "A. Meena",
            "R. Raja"
        ],
        "abstract": "Nuclear image has emerged as a promising research work in medical field. Images from different modality meet its own challenge. Positron Emission Tomography (PET) image may help to precisely localize disease to assist in planning the right treatment for each case and saving valuable time. In this paper, a novel approach of Spatial Fuzzy C Means (PET SFCM) clustering algorithm is introduced on PET scan image datasets. The proposed algorithm is incorporated the spatial neighborhood information with traditional FCM and updating the objective function of each cluster. This algorithm is implemented and tested on huge data collection of patients with brain neuro degenerative disorder such as Alzheimers disease. It has demonstrated its effectiveness by testing it for real world patient data sets. Experimental results are compared with conventional FCM and K Means clustering algorithm. The performance of the PET SFCM provides satisfactory results compared with other two algorithms\n    ",
        "submission_date": "2013-03-04T00:00:00",
        "last_modified_date": "2013-03-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1303.0964",
        "title": "GBM Volumetry using the 3D Slicer Medical Image Computing Platform",
        "authors": [
            "Jan Egger",
            "Tina Kapur",
            "Andriy Fedorov",
            "Steve Pieper",
            "James V. Miller",
            "Harini Veeraraghavan",
            "Bernd Freisleben",
            "Alexandra Golby",
            "Christopher Nimsky",
            "Ron Kikinis"
        ],
        "abstract": "Volumetric change in glioblastoma multiforme (GBM) over time is a critical factor in treatment decisions. Typically, the tumor volume is computed on a slice-by-slice basis using MRI scans obtained at regular intervals. (3D)Slicer - a free platform for biomedical research - provides an alternative to this manual slice-by-slice segmentation process, which is significantly faster and requires less user interaction. In this study, 4 physicians segmented GBMs in 10 patients, once using the competitive region-growing based GrowCut segmentation module of Slicer, and once purely by drawing boundaries completely manually on a slice-by-slice basis. Furthermore, we provide a variability analysis for three physicians for 12 GBMs. The time required for GrowCut segmentation was on an average 61% of the time required for a pure manual segmentation. A comparison of Slicer-based segmentation with manual slice-by-slice segmentation resulted in a Dice Similarity Coefficient of 88.43 +/- 5.23% and a Hausdorff Distance of 2.32 +/- 5.23 mm.\n    ",
        "submission_date": "2013-03-05T00:00:00",
        "last_modified_date": "2013-03-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1303.1624",
        "title": "On Robust Face Recognition via Sparse Encoding: the Good, the Bad, and the Ugly",
        "authors": [
            "Yongkang Wong",
            "Mehrtash T. Harandi",
            "Conrad Sanderson"
        ],
        "abstract": "In the field of face recognition, Sparse Representation (SR) has received considerable attention during the past few years. Most of the relevant literature focuses on holistic descriptors in closed-set identification applications. The underlying assumption in SR-based methods is that each class in the gallery has sufficient samples and the query lies on the subspace spanned by the gallery of the same class. Unfortunately, such assumption is easily violated in the more challenging face verification scenario, where an algorithm is required to determine if two faces (where one or both have not been seen before) belong to the same person. In this paper, we first discuss why previous attempts with SR might not be applicable to verification problems. We then propose an alternative approach to face verification via SR. Specifically, we propose to use explicit SR encoding on local image patches rather than the entire face. The obtained sparse signals are pooled via averaging to form multiple region descriptors, which are then concatenated to form an overall face descriptor. Due to the deliberate loss spatial relations within each region (caused by averaging), the resulting descriptor is robust to misalignment & various image deformations. Within the proposed framework, we evaluate several SR encoding techniques: l1-minimisation, Sparse Autoencoder Neural Network (SANN), and an implicit probabilistic technique based on Gaussian Mixture Models. Thorough experiments on AR, FERET, exYaleB, BANCA and ChokePoint datasets show that the proposed local SR approach obtains considerably better and more robust performance than several previous state-of-the-art holistic SR methods, in both verification and closed-set identification problems. The experiments also show that l1-minimisation based encoding has a considerably higher computational than the other techniques, but leads to higher recognition rates.\n    ",
        "submission_date": "2013-03-07T00:00:00",
        "last_modified_date": "2013-03-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1303.1667",
        "title": "ALPRS - A New Approach for License Plate Recognition using the Sift Algorithm",
        "authors": [
            "Francisco Assis da Silva",
            "Almir Olivette Artero",
            "Maria Stela Veludo de Paiva",
            "Ricardo Luis Barbosa"
        ],
        "abstract": "This paper presents a new approach for the automatic license plate recognition, which includes the SIFT algorithm in step to locate the plate in the input image. In this new approach, besides the comparison of the features obtained with the SIFT algorithm, the correspondence between the spatial orientations and the positioning associated with the keypoints is also observed. Afterwards, an algorithm is used for the character recognition of the plates, very fast, which makes it possible its application in real time. The results obtained with the proposed approach presented very good success rates, so much for locating the characters in the input image, as for their recognition.\n    ",
        "submission_date": "2013-03-07T00:00:00",
        "last_modified_date": "2013-03-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1303.1749",
        "title": "Simplifying Energy Optimization using Partial Enumeration",
        "authors": [
            "Carl Olsson",
            "Johannes Ulen",
            "Yuri Boykov",
            "Vladimir Kolmogorov"
        ],
        "abstract": "Energies with high-order non-submodular interactions have been shown to be very useful in vision due to their high modeling power. Optimization of such energies, however, is generally NP-hard. A naive approach that works for small problem instances is exhaustive search, that is, enumeration of all possible labelings of the underlying graph. We propose a general minimization approach for large graphs based on enumeration of labelings of certain small patches. This partial enumeration technique reduces complex high-order energy formulations to pairwise Constraint Satisfaction Problems with unary costs (uCSP), which can be efficiently solved using standard methods like TRW-S. Our approach outperforms a number of existing state-of-the-art algorithms on well known difficult problems (e.g. curvature regularization, stereo, deconvolution); it gives near global minimum and better speed.\n",
        "submission_date": "2013-03-07T00:00:00",
        "last_modified_date": "2013-10-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1303.1761",
        "title": "Improving Automatic Emotion Recognition from speech using Rhythm and Temporal feature",
        "authors": [
            "Mayank Bhargava",
            "Tim Polzehl"
        ],
        "abstract": "This paper is devoted to improve automatic emotion recognition from speech by incorporating rhythm and temporal features. Research on automatic emotion recognition so far has mostly been based on applying features like MFCCs, pitch and energy or intensity. The idea focuses on borrowing rhythm features from linguistic and phonetic analysis and applying them to the speech signal on the basis of acoustic knowledge only. In addition to this we exploit a set of temporal and loudness features. A segmentation unit is employed in starting to separate the voiced/unvoiced and silence parts and features are explored on different segments. Thereafter different classifiers are used for classification. After selecting the top features using an IGR filter we are able to achieve a recognition rate of 80.60 % on the Berlin Emotion Database for the speaker dependent framework.\n    ",
        "submission_date": "2013-03-07T00:00:00",
        "last_modified_date": "2013-03-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1303.1829",
        "title": "Watersheds on edge or node weighted graphs \"par l'exemple\"",
        "authors": [
            "Fernand Meyer"
        ],
        "abstract": "Watersheds have been defined both for node and edge weighted graphs. We show that they are identical: for each edge (resp.\\ node) weighted graph exists a node (resp. edge) weighted graph with the same minima and catchment basin.\n    ",
        "submission_date": "2013-03-07T00:00:00",
        "last_modified_date": "2013-03-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1303.2071",
        "title": "Application of the SP theory of intelligence to the understanding of natural vision and the development of computer vision",
        "authors": [
            "J. Gerard Wolff"
        ],
        "abstract": "The SP theory of intelligence aims to simplify and integrate concepts in computing and cognition, with information compression as a unifying theme. This article discusses how it may be applied to the understanding of natural vision and the development of computer vision. The theory, which is described quite fully elsewhere, is described here in outline but with enough detail to ensure that the rest of the article makes sense.\n",
        "submission_date": "2013-03-08T00:00:00",
        "last_modified_date": "2015-01-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1303.2108",
        "title": "Classification of Segments in PolSAR Imagery by Minimum Stochastic Distances Between Wishart Distributions",
        "authors": [
            "Wagner Barreto da Silva",
            "Corina da Costa Freitas",
            "Sidnei Jo\u00e3o Siqueira Sant'Anna",
            "Alejandro C. Frery"
        ],
        "abstract": "A new classifier for Polarimetric SAR (PolSAR) images is proposed and assessed in this paper. Its input consists of segments, and each one is assigned the class which minimizes a stochastic distance. Assuming the complex Wishart model, several stochastic distances are obtained from the h-phi family of divergences, and they are employed to derive hypothesis test statistics that are also used in the classification process. This article also presents, as a novelty, analytic expressions for the test statistics based on the following stochastic distances between complex Wishart models: Kullback-Leibler, Bhattacharyya, Hellinger, R\u00e9nyi, and Chi-Square; also, the test statistic based on the Bhattacharyya distance between multivariate Gaussian distributions is presented. The classifier performance is evaluated using simulated and real PolSAR data. The simulated data are based on the complex Wishart model, aiming at the analysis of the proposal well controlled data. The real data refer to the complex L-band image, acquired during the 1994 SIR-C mission. The results of the proposed classifier are compared with those obtained by a Wishart per-pixel/contextual classifier, and we show the better performance of the region-based classification. The influence of the statistical modeling is assessed by comparing the results using the Bhattacharyya distance between multivariate Gaussian distributions for amplitude data. The results with simulated data indicate that the proposed classification method has a very good performance when the data follow the Wishart model. The proposed classifier also performs better than the per-pixel/contextual classifier and the Bhattacharyya Gaussian distance using SIR-C PolSAR data.\n    ",
        "submission_date": "2013-03-11T00:00:00",
        "last_modified_date": "2013-03-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1303.2437",
        "title": "Least-Squares FIR Models of Low-Resolution MR data for Efficient Phase-Error Compensation with Simultaneous Artefact Removal",
        "authors": [
            "Joseph Suresh Paul",
            "Uma Krishna Swamy Pillai",
            "Nyjin Thomas"
        ],
        "abstract": "Signal space models in both phase-encode, and frequency-encode directions are presented for extrapolation of 2D partial kspace. Using the boxcar representation of low-resolution spatial data, and a geometrical representation of signal space vectors in both positive and negative phase-encode directions, a robust predictor is constructed using a series of signal space projections. Compared to some of the existing phase-correction methods that require acquisition of a pre-determined set of fractional kspace lines, the proposed predictor is found to be more efficient, due to its capability of exhibiting an equivalent degree of performance using only half the number of fractional lines. Robust filtering of noisy data is achieved using a second signal space model in the frequency-encode direction, bypassing the requirement of a prior highpass filtering operation. The signal space is constructed from Fourier Transformed samples of each row in the low-resolution image. A set of FIR filters are estimated by fitting a least squares model to this signal space. Partial kspace extrapolation using the FIR filters is shown to result in artifact-free reconstruction, particularly in respect of Gibbs ringing and streaking type artifacts.\n    ",
        "submission_date": "2013-03-11T00:00:00",
        "last_modified_date": "2013-03-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1303.2439",
        "title": "Voxel-wise Weighted MR Image Enhancement using an Extended Neighborhood Filter",
        "authors": [
            "Joseph Suresh Paul",
            "Joshin John Mathew",
            "Souparnika Kandoth Naroth",
            "Chandrasekar Kesavadas"
        ],
        "abstract": "We present an edge preserving and denoising filter for enhancing the features in images, which contain an ROI having a narrow spatial extent. Typical examples include angiograms, or ROI spatially distributed in multiple locations and contained within an outlying region, such as in multiple-sclerosis. The filtering involves determination of multiplicative weights in the spatial domain using an extended set of neighborhood directions. Equivalently, the filtering operation may be interpreted as a combination of directional filters in the frequency domain, with selective weighting for spatial frequencies contained within each direction. The advantages of the proposed filter in comparison to specialized non-linear filters, which operate on diffusion principle, are illustrated using numerical phantom data. The performance evaluation is carried out on simulated images from BrainWeb database for multiple-sclerosis, acute ischemic stroke using clinically acquired FLAIR images and MR angiograms.\n    ",
        "submission_date": "2013-03-11T00:00:00",
        "last_modified_date": "2013-03-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1303.2465",
        "title": "A Low-Complexity Algorithm for Static Background Estimation from Cluttered Image Sequences in Surveillance Contexts",
        "authors": [
            "Vikas Reddy",
            "Conrad Sanderson",
            "Brian C. Lovell"
        ],
        "abstract": "For the purposes of foreground estimation, the true background model is unavailable in many practical circumstances and needs to be estimated from cluttered image sequences. We propose a sequential technique for static background estimation in such conditions, with low computational and memory requirements. Image sequences are analysed on a block-by-block basis. For each block location a representative set is maintained which contains distinct blocks obtained along its temporal line. The background estimation is carried out in a Markov Random Field framework, where the optimal labelling solution is computed using iterated conditional modes. The clique potentials are computed based on the combined frequency response of the candidate block and its neighbourhood. It is assumed that the most appropriate block results in the smoothest response, indirectly enforcing the spatial continuity of structures within a scene. Experiments on real-life surveillance videos demonstrate that the proposed method obtains considerably better background estimates (both qualitatively and quantitatively) than median filtering and the recently proposed \"intervals of stable intensity\" method. Further experiments on the Wallflower dataset suggest that the combination of the proposed method with a foreground segmentation algorithm results in improved foreground segmentation.\n    ",
        "submission_date": "2013-03-11T00:00:00",
        "last_modified_date": "2013-03-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1303.2607",
        "title": "Joint optimization of fitting & matching in multi-view reconstruction",
        "authors": [
            "Hossam Isack",
            "Yuri Boykov"
        ],
        "abstract": "Many standard approaches for geometric model fitting are based on pre-matched image features. Typically, such pre-matching uses only feature appearances (e.g. SIFT) and a large number of non-unique features must be discarded in order to control the false positive rate. In contrast, we solve feature matching and multi-model fitting problems in a joint optimization framework. This paper proposes several fit-&-match energy formulations based on a generalization of the assignment problem. We developed an efficient solver based on min-cost-max-flow algorithm that finds near optimal solutions. Our approach significantly increases the number of detected matches. In practice, energy-based joint fitting & matching allows to increase the distance between view-points previously restricted by robustness of local SIFT-matching and to improve the model fitting accuracy when compared to state-of-the-art multi-model fitting techniques.\n    ",
        "submission_date": "2013-03-11T00:00:00",
        "last_modified_date": "2014-04-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1303.2610",
        "title": "Kernel Sparse Models for Automated Tumor Segmentation",
        "authors": [
            "Jayaraman J. Thiagarajan",
            "Karthikeyan Natesan Ramamurthy",
            "Deepta Rajan",
            "Anup Puri",
            "David Frakes",
            "Andreas Spanias"
        ],
        "abstract": "In this paper, we propose sparse coding-based approaches for segmentation of tumor regions from MR images. Sparse coding with data-adapted dictionaries has been successfully employed in several image recovery and vision problems. The proposed approaches obtain sparse codes for each pixel in brain magnetic resonance images considering their intensity values and location information. Since it is trivial to obtain pixel-wise sparse codes, and combining multiple features in the sparse coding setup is not straightforward, we propose to perform sparse coding in a high-dimensional feature space where non-linear similarities can be effectively modeled. We use the training data from expert-segmented images to obtain kernel dictionaries with the kernel K-lines clustering procedure. For a test image, sparse codes are computed with these kernel dictionaries, and they are used to identify the tumor regions. This approach is completely automated, and does not require user intervention to initialize the tumor regions in a test image. Furthermore, a low complexity segmentation approach based on kernel sparse codes, which allows the user to initialize the tumor region, is also presented. Results obtained with both the proposed approaches are validated against manual segmentation by an expert radiologist, and the proposed methods lead to accurate tumor identification.\n    ",
        "submission_date": "2013-03-11T00:00:00",
        "last_modified_date": "2013-03-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1303.2685",
        "title": "Bilateral Filter: Graph Spectral Interpretation and Extensions",
        "authors": [
            "Akshay Gadde",
            "Sunil K Narang",
            "Antonio Ortega"
        ],
        "abstract": "In this paper we study the bilateral filter proposed by Tomasi and Manduchi, as a spectral domain transform defined on a weighted graph. The nodes of this graph represent the pixels in the image and a graph signal defined on the nodes represents the intensity values. Edge weights in the graph correspond to the bilateral filter coefficients and hence are data adaptive. Spectrum of a graph is defined in terms of the eigenvalues and eigenvectors of the graph Laplacian matrix. We use this spectral interpretation to generalize the bilateral filter and propose more flexible and application specific spectral designs of bilateral-like filters. We show that these spectral filters can be implemented with k-iterative bilateral filtering operations and do not require expensive diagonalization of the Laplacian matrix.\n    ",
        "submission_date": "2013-03-11T00:00:00",
        "last_modified_date": "2013-03-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1303.2751",
        "title": "Gaussian Mixture Model for Handwritten Script Identification",
        "authors": [
            "Mallikarjun Hangarge"
        ],
        "abstract": "This paper presents a Gaussian Mixture Model (GMM) to identify the script of handwritten words of Roman, Devanagari, Kannada and Telugu scripts. It emphasizes the significance of directional energies for identification of script of the word. It is robust to varied image sizes and different styles of writing. A GMM is modeled using a set of six novel features derived from directional energy distributions of the underlying image. The standard deviation of directional energy distributions are computed by decomposing an image matrix into right and left diagonals. Furthermore, deviation of horizontal and vertical distributions of energies is also built-in to GMM. A dataset of 400 images out of 800 (200 of each script) are used for training GMM and the remaining is for testing. An exhaustive experimentation is carried out at bi-script, tri-script and multi-script level and achieved script identification accuracies in percentage as 98.7, 98.16 and 96.91 respectively.\n    ",
        "submission_date": "2013-03-12T00:00:00",
        "last_modified_date": "2013-03-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1303.2783",
        "title": "Combined Learning of Salient Local Descriptors and Distance Metrics for Image Set Face Verification",
        "authors": [
            "Conrad Sanderson",
            "Mehrtash T. Harandi",
            "Yongkang Wong",
            "Brian C. Lovell"
        ],
        "abstract": "In contrast to comparing faces via single exemplars, matching sets of face images increases robustness and discrimination performance. Recent image set matching approaches typically measure similarities between subspaces or manifolds, while representing faces in a rigid and holistic manner. Such representations are easily affected by variations in terms of alignment, illumination, pose and expression. While local feature based representations are considerably more robust to such variations, they have received little attention within the image set matching area. We propose a novel image set matching technique, comprised of three aspects: (i) robust descriptors of face regions based on local features, partly inspired by the hierarchy in the human visual system, (ii) use of several subspace and exemplar metrics to compare corresponding face regions, (iii) jointly learning which regions are the most discriminative while finding the optimal mixing weights for combining metrics. Face recognition experiments on LFW, PIE and MOBIO face datasets show that the proposed algorithm obtains considerably better performance than several recent state-of-the-art techniques, such as Local Principal Angle and the Kernel Affine Hull Method.\n    ",
        "submission_date": "2013-03-12T00:00:00",
        "last_modified_date": "2013-03-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1303.2844",
        "title": "A Stochastic Grammar for Natural Shapes",
        "authors": [
            "Pedro F. Felzenszwalb"
        ],
        "abstract": "We consider object detection using a generic model for natural shapes. A common approach for object recognition involves matching object models directly to images. Another approach involves building intermediate representations via a generic grouping processes. We argue that these two processes (model-based recognition and grouping) may use similar computational mechanisms. By defining a generic model for shapes we can use model-based techniques to implement a mid-level vision grouping process.\n    ",
        "submission_date": "2013-03-12T00:00:00",
        "last_modified_date": "2013-03-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1303.3067",
        "title": "Computing Motion with 3D Memristive Grid",
        "authors": [
            "Chuan Kai Kenneth. Lim",
            "T. Prodromakis"
        ],
        "abstract": "Computing the relative motion of objects is an important navigation task that we routinely perform by relying on inherently unreliable biological cells in the retina. The non-linear and adaptive response of memristive devices make them excellent building blocks for realizing complex synaptic-like architectures that are common in the human retina. Here, we introduce a novel memristive thresholding scheme that facilitates the detection of moving edges. In addition, a double-layered 3-D memristive network is employed for modeling the motion computations that take place in both the Outer Plexiform Layer (OPL) and Inner Plexiform Layer (IPL) that enables the detection of on-center and off-center transient responses. Applying the transient detection results, it is shown that it is possible to generate an estimation of the speed and direction a moving object.\n    ",
        "submission_date": "2013-03-13T00:00:00",
        "last_modified_date": "2013-03-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1303.3087",
        "title": "Statistical Texture Features based Handwritten and Printed Text Classification in South Indian Documents",
        "authors": [
            "Mallikarjun Hangarge",
            "K.C. Santosh",
            "Srikanth Doddamani",
            "Rajmohan Pardeshi"
        ],
        "abstract": "In this paper, we use statistical texture features for handwritten and printed text classification. We primarily aim for word level classification in south Indian scripts. Words are first extracted from the scanned document. For each extracted word, statistical texture features are computed such as mean, standard deviation, smoothness, moment, uniformity, entropy and local range including local entropy. These feature vectors are then used to classify words via k-NN classifier. We have validated the approach over several different datasets. Scripts like Kannada, Telugu, Malayalam and Hindi i.e., Devanagari are primarily employed where an average classification rate of 99.26% is achieved. In addition, to provide an extensibility of the approach, we address Roman script by using publicly available dataset and interesting results are reported.\n    ",
        "submission_date": "2013-03-13T00:00:00",
        "last_modified_date": "2013-03-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1303.3152",
        "title": "Material quality assessment of silk nanofibers based on swarm intelligence",
        "authors": [
            "Bruno Brandoli Machado",
            "Wesley Nunes Gon\u00e7alves",
            "Odemir Martinez Bruno"
        ],
        "abstract": "In this paper, we propose a novel approach for texture analysis based on artificial crawler model. Our method assumes that each agent can interact with the environment and each other. The evolution process converges to an equilibrium state according to the set of rules. For each textured image, the feature vector is composed by signatures of the live agents curve at each time. Experimental results revealed that combining the minimum and maximum signatures into one increase the classification rate. In addition, we pioneer the use of autonomous agents for characterizing silk fibroin scaffolds. The results strongly suggest that our approach can be successfully employed for texture analysis.\n    ",
        "submission_date": "2013-03-13T00:00:00",
        "last_modified_date": "2013-03-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1303.4160",
        "title": "Improved Foreground Detection via Block-based Classifier Cascade with Probabilistic Decision Integration",
        "authors": [
            "Vikas Reddy",
            "Conrad Sanderson",
            "Brian C. Lovell"
        ],
        "abstract": "Background subtraction is a fundamental low-level processing task in numerous computer vision applications. The vast majority of algorithms process images on a pixel-by-pixel basis, where an independent decision is made for each pixel. A general limitation of such processing is that rich contextual information is not taken into account. We propose a block-based method capable of dealing with noise, illumination variations and dynamic backgrounds, while still obtaining smooth contours of foreground objects. Specifically, image sequences are analysed on an overlapping block-by-block basis. A low-dimensional texture descriptor obtained from each block is passed through an adaptive classifier cascade, where each stage handles a distinct problem. A probabilistic foreground mask generation approach then exploits block overlaps to integrate interim block-level decisions into final pixel-level foreground segmentation. Unlike many pixel-based methods, ad-hoc post-processing of foreground masks is not required. Experiments on the difficult Wallflower and I2R datasets show that the proposed approach obtains on average better results (both qualitatively and quantitatively) than several prominent methods. We furthermore propose the use of tracking performance as an unbiased approach for assessing the practical usefulness of foreground segmentation methods, and show that the proposed approach leads to considerable improvements in tracking accuracy on the CAVIAR dataset.\n    ",
        "submission_date": "2013-03-18T00:00:00",
        "last_modified_date": "2013-03-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1303.4614",
        "title": "Handwritten and Printed Text Separation in Real Document",
        "authors": [
            "Abdel Bela\u00efd",
            "K.C. Santosh",
            "Vincent Poulain D'Andecy"
        ],
        "abstract": "The aim of the paper is to separate handwritten and printed text from a real document embedded with noise, graphics including annotations. Relying on run-length smoothing algorithm (RLSA), the extracted pseudo-lines and pseudo-words are used as basic blocks for classification. To handle this, a multi-class support vector machine (SVM) with Gaussian kernel performs a first labelling of each pseudo-word including the study of local neighbourhood. It then propagates the context between neighbours so that we can correct possible labelling errors. Considering running time complexity issue, we propose linear complexity methods where we use k-NN with constraint. When using a kd-tree, it is almost linearly proportional to the number of pseudo-words. The performance of our system is close to 90%, even when very small learning dataset where samples are basically composed of complex administrative documents.\n    ",
        "submission_date": "2013-03-19T00:00:00",
        "last_modified_date": "2013-03-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1303.4803",
        "title": "A Survey of Appearance Models in Visual Object Tracking",
        "authors": [
            "Xi Li",
            "Weiming Hu",
            "Chunhua Shen",
            "Zhongfei Zhang",
            "Anthony Dick",
            "Anton van den Hengel"
        ],
        "abstract": "Visual object tracking is a significant computer vision task which  can be applied to many domains such as visual surveillance, human computer interaction, and video compression.  In the literature, researchers have proposed a variety of 2D  appearance models.  To help readers swiftly learn the recent advances in 2D appearance  models for visual object tracking, we contribute this survey,  which provides a detailed review of the existing 2D appearance  models. In particular, this survey takes a module-based  architecture that enables readers to easily grasp the key points of visual object tracking. In this survey, we first decompose the  problem of appearance modeling into two different processing  stages: visual representation and statistical modeling. Then,  different 2D appearance models are categorized and discussed with  respect to their composition modules. Finally, we address several  issues of interest as well as the remaining challenges for future research on this topic.  The contributions of this survey are four-fold. First, we review  the literature of visual representations according to their  feature-construction mechanisms (i.e., local and global). Second, the existing statistical modeling schemes for  tracking-by-detection are reviewed according to their  model-construction mechanisms: generative, discriminative, and  hybrid generative-discriminative. Third, each type of visual  representations or statistical modeling techniques is analyzed and  discussed from a theoretical or practical viewpoint. Fourth, the  existing benchmark resources (e.g., source code and video  datasets) are examined in this survey.\n    ",
        "submission_date": "2013-03-20T00:00:00",
        "last_modified_date": "2013-03-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1303.4839",
        "title": "The State of the Art Recognize in Arabic Script through Combination of Online and Offline",
        "authors": [
            "Dr. Firoj Parwej"
        ],
        "abstract": "Handwriting recognition refers to the identification of written characters. Handwriting recognition has become an acute research area in recent years for the ease of access of computer science. In this paper primarily discussed On-line and Off-line handwriting recognition methods for Arabic words which are often used among then across the Middle East and North Africa People. Arabic word online handwriting recognition is a very challenging task due to its cursive nature. Because of the characteristic of the whole body of the Arabic script, namely connectivity between the characters, thereby the segmentation of An Arabic script is very difficult. In this paper we introduced an Arabic script multiple classifier system for recognizing notes written on a Starboard. This Arabic script multiple classifier system combines one off-line and on-line handwriting recognition systems. The Arabic script recognizers are all based on Hidden Markov Models but vary in the way of preprocessing and normalization. To combine the Arabic script output sequences of the recognizers, we incrementally align the word sequences using a norm string matching algorithm. The Arabic script combination we could increase the system performance over the excellent character recognizer by about 3%. The proposed technique is also the necessary step towards character recognition, person identification, personality determination where input data is processed from all perspectives.\n    ",
        "submission_date": "2013-03-20T00:00:00",
        "last_modified_date": "2013-03-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1303.4840",
        "title": "Asynchronous Cellular Operations on Gray Images Extracting Topographic Shape Features and Their Relations",
        "authors": [
            "Igor Polkovnikov"
        ],
        "abstract": "A variety of operations of cellular automata on gray images is presented. All operations are of a wave-front nature finishing in a stable state. They are used to extract shape descripting gray objects robust to a variety of pattern distortions. Topographic terms are used: \"lakes\", \"dales\", \"dales of dales\". It is shown how mutual object relations like \"above\" can be presented in terms of gray image analysis and how it can be used for character classification and for gray pattern decomposition. Algorithms can be realized with a parallel asynchronous architecture. Keywords: Pattern Recognition, Mathematical Morphology, Cellular Automata, Wave-front Algorithms, Gray Image Analysis, Topographical Shape Descriptors, Asynchronous Parallel Processors, Holes, Cavities, Concavities, Graphs.\n    ",
        "submission_date": "2013-03-20T00:00:00",
        "last_modified_date": "2013-03-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1303.4845",
        "title": "On Constructing the Value Function for Optimal Trajectory Problem and its Application to Image Processing",
        "authors": [
            "Myong-Song Ho",
            "Gwang-Hui Ju",
            "Yong-Bom O",
            "Gwang-Ho Jong"
        ],
        "abstract": "We proposed an algorithm for solving Hamilton-Jacobi equation associated to an optimal trajectory problem for a vehicle moving inside the pre-specified domain with the speed depending upon the direction of the motion and current position of the vehicle. The dynamics of the vehicle is defined by an ordinary differential equation, the right hand of which is given by product of control(a time dependent fuction) and a function dependent on trajectory and control. At some unspecified terminal time, the vehicle reaches the boundary of the pre-specified domain and incurs a terminal cost. We also associate the traveling cost with a type of integral to the trajectory followed by vehicle. We are interested in a numerical method for finding a trajectory that minimizes the sum of the traveling cost and terminal cost. We developed an algorithm solving the value function for general trajectory optimization problem. Our algorithm is closely related to the Tsitsiklis's Fast Marching Method and J. A. Sethian's OUM and SLF-LLL[1-4] and is a generalization of them. On the basis of these results, We applied our algorithm to the image processing such as fingerprint verification.\n    ",
        "submission_date": "2013-03-20T00:00:00",
        "last_modified_date": "2013-03-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1303.4866",
        "title": "A Robust Rapid Approach to Image Segmentation with Optimal Thresholding and Watershed Transform",
        "authors": [
            "Ankit R. Chadha",
            "Neha S. Satam"
        ],
        "abstract": "This paper describes a novel method for partitioning image into meaningful segments. The proposed method employs watershed transform, a well-known image segmentation technique. Along with that, it uses various auxiliary schemes such as Binary Gradient Masking, dilation which segment the image in proper way. The algorithm proposed in this paper considers all these methods in effective way and takes little time. It is organized in such a manner so that it operates on input image adaptively. Its robustness and efficiency makes it more convenient and suitable for all types of images.\n    ",
        "submission_date": "2013-03-20T00:00:00",
        "last_modified_date": "2013-03-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1303.5244",
        "title": "Separable Dictionary Learning",
        "authors": [
            "Simon Hawe",
            "Matthias Seibert",
            "Martin Kleinsteuber"
        ],
        "abstract": "Many techniques in computer vision, machine learning, and statistics rely on the fact that a signal of interest admits a sparse representation over some dictionary. Dictionaries are either available analytically, or can be learned from a suitable training set. While analytic dictionaries permit to capture the global structure of a signal and allow a fast implementation, learned dictionaries often perform better in applications as they are more adapted to the considered class of signals. In imagery, unfortunately, the numerical burden for (i) learning a dictionary and for (ii) employing the dictionary for reconstruction tasks only allows to deal with relatively small image patches that only capture local image information. The approach presented in this paper aims at overcoming these drawbacks by allowing a separable structure on the dictionary throughout the learning process. On the one hand, this permits larger patch-sizes for the learning phase, on the other hand, the dictionary is applied efficiently in reconstruction tasks. The learning procedure is based on optimizing over a product of spheres which updates the dictionary as a whole, thus enforces basic dictionary properties such as mutual coherence explicitly during the learning procedure. In the special case where no separable structure is enforced, our method competes with state-of-the-art dictionary learning methods like K-SVD.\n    ",
        "submission_date": "2013-03-21T00:00:00",
        "last_modified_date": "2013-03-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1303.5492",
        "title": "Sample Distortion for Compressed Imaging",
        "authors": [
            "Chunli Guo",
            "Mike E. Davies"
        ],
        "abstract": "We propose the notion of a sample distortion (SD) function for independent and identically distributed (i.i.d) compressive distributions to fundamentally quantify the achievable reconstruction performance of compressed sensing for certain encoder-decoder pairs at a given sampling ratio. Two lower bounds on the achievable performance and the intrinsic convexity property is derived. A zeroing procedure is then introduced to improve non convex SD functions. The SD framework is then applied to analyse compressed imaging with a multi-resolution statistical image model using both the generalized Gaussian distribution and the two-state Gaussian mixture distribution. We subsequently focus on the Gaussian encoder-Bayesian optimal approximate message passing (AMP) decoder pair, whose theoretical SD function is provided by the rigorous analysis of the AMP algorithm. Given the image statistics, analytic bandwise sample allocation for bandwise independent model is derived as a reverse water-filling scheme. Som and Schniter's turbo message passing approach is further deployed to integrate the bandwise sampling with the exploitation of the hidden Markov tree structure of wavelet coefficients. Natural image simulations confirm that with oracle image statistics, the SD function associated with the optimized sample allocation can accurately predict the possible compressed sensing gains. Finally, a general sample allocation profile based on average image statistics not only illustrates preferable performance but also makes the scheme practical.\n    ",
        "submission_date": "2013-03-22T00:00:00",
        "last_modified_date": "2013-07-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1303.5508",
        "title": "Sparse Projections of Medical Images onto Manifolds",
        "authors": [
            "George H. Chen",
            "Christian Wachinger",
            "Polina Golland"
        ],
        "abstract": "Manifold learning has been successfully applied to a variety of medical imaging problems. Its use in real-time applications requires fast projection onto the low-dimensional space. To this end, out-of-sample extensions are applied by constructing an interpolation function that maps from the input space to the low-dimensional manifold. Commonly used approaches such as the Nystr\u00f6m extension and kernel ridge regression require using all training points. We propose an interpolation function that only depends on a small subset of the input training data. Consequently, in the testing phase each new point only needs to be compared against a small number of input training data in order to project the point onto the low-dimensional space. We interpret our method as an out-of-sample extension that approximates kernel ridge regression. Our method involves solving a simple convex optimization problem and has the attractive property of guaranteeing an upper bound on the approximation error, which is crucial for medical applications. Tuning this error bound controls the sparsity of the resulting interpolation function. We illustrate our method in two clinical applications that require fast mapping of input images onto a low-dimensional space.\n    ",
        "submission_date": "2013-03-22T00:00:00",
        "last_modified_date": "2013-03-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1303.5691",
        "title": "Cortical Surface Co-Registration based on MRI Images and Photos",
        "authors": [
            "Benjamin Berkels",
            "Ivan Cabrilo",
            "Sven Haller",
            "Martin Rumpf",
            "Carlo Schaller"
        ],
        "abstract": "Brain shift, i.e. the change in configuration of the brain after opening the dura mater, is a key problem in neuronavigation. We present an approach to co-register intra-operative microscope images with pre-operative MRI to adapt and optimize intra-operative neuronavigation. The tools are a robust classification of sulci on MRI extracted cortical surfaces, guided user marking of most prominent sulci on a microscope image, and the actual variational registration method with a fidelity energy for 3D deformations of the cortical surface combined with a higher order, linear elastica type prior energy. Furthermore, the actual registration is validated on an artificial testbed with known ground truth deformation and on real data of a neuro clinical patient.\n    ",
        "submission_date": "2013-03-22T00:00:00",
        "last_modified_date": "2013-03-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1303.5913",
        "title": "A Diffusion Process on Riemannian Manifold for Visual Tracking",
        "authors": [
            "Marcus Chen",
            "Cham Tat Jen",
            "Pang Sze Kim",
            "Alvina Goh"
        ],
        "abstract": "Robust visual tracking for long video sequences is a research area that has many important applications. The main challenges include how the target image can be modeled and how this model can be updated. In this paper, we model the target using a covariance descriptor, as this descriptor is robust to problems such as pixel-pixel misalignment, pose and illumination changes, that commonly occur in visual tracking. We model the changes in the template using a generative process. We introduce a new dynamical model for the template update using a random walk on the Riemannian manifold where the covariance descriptors lie in. This is done using log-transformed space of the manifold to free the constraints imposed inherently by positive semidefinite matrices. Modeling template variations and poses kinetics together in the state space enables us to jointly quantify the uncertainties relating to the kinematic states and the template in a principled way. Finally, the sequential inference of the posterior distribution of the kinematic states and the template is done using a particle filter. Our results shows that this principled approach can be robust to changes in illumination, poses and spatial affine transformation. In the experiments, our method outperformed the current state-of-the-art algorithm - the incremental Principal Component Analysis method, particularly when a target underwent fast poses changes and also maintained a comparable performance in stable target tracking cases.\n    ",
        "submission_date": "2013-03-24T00:00:00",
        "last_modified_date": "2013-03-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1303.6021",
        "title": "Spatio-Temporal Covariance Descriptors for Action and Gesture Recognition",
        "authors": [
            "Andres Sanin",
            "Conrad Sanderson",
            "Mehrtash T. Harandi",
            "Brian C. Lovell"
        ],
        "abstract": "We propose a new action and gesture recognition method based on spatio-temporal covariance descriptors and a weighted Riemannian locality preserving projection approach that takes into account the curved space formed by the descriptors. The weighted projection is then exploited during boosting to create a final multiclass classification algorithm that employs the most useful spatio-temporal regions. We also show how the descriptors can be computed quickly through the use of integral video representations. Experiments on the UCF sport, CK+ facial expression and Cambridge hand gesture datasets indicate superior performance of the proposed method compared to several recent state-of-the-art techniques. The proposed method is robust and does not require additional processing of the videos, such as foreground detection, interest-point detection or tracking.\n    ",
        "submission_date": "2013-03-25T00:00:00",
        "last_modified_date": "2013-03-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1303.6066",
        "title": "Asymmetric Pruning for Learning Cascade Detectors",
        "authors": [
            "Sakrapee Paisitkriangkrai",
            "Chunhua Shen",
            "Anton van den Hengel"
        ],
        "abstract": "Cascade classifiers are one of the most important contributions to real-time object detection. Nonetheless, there are many challenging problems arising in training cascade detectors. One common issue is that the node classifier is trained with a symmetric classifier. Having a low misclassification error rate does not guarantee an optimal node learning goal in cascade classifiers, i.e., an extremely high detection rate with a moderate false positive rate. In this work, we present a new approach to train an effective node classifier in a cascade detector. The algorithm is based on two key observations: 1) Redundant weak classifiers can be safely discarded; 2) The final detector should satisfy the asymmetric learning objective of the cascade architecture. To achieve this, we separate the classifier training into two steps: finding a pool of discriminative weak classifiers/features and training the final classifier by pruning weak classifiers which contribute little to the asymmetric learning criterion (asymmetric classifier construction). Our model reduction approach helps accelerate the learning time while achieving the pre-determined learning objective. Experimental results on both face and car data sets verify the effectiveness of the proposed algorithm. On the FDDB face data sets, our approach achieves the state-of-the-art performance, which demonstrates the advantage of our approach.\n    ",
        "submission_date": "2013-03-25T00:00:00",
        "last_modified_date": "2014-02-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1303.6163",
        "title": "Machine learning of hierarchical clustering to segment 2D and 3D images",
        "authors": [
            "Juan Nunez-Iglesias",
            "Ryan Kennedy",
            "Toufiq Parag",
            "Jianbo Shi",
            "Dmitri B. Chklovskii"
        ],
        "abstract": "We aim to improve segmentation through the use of machine learning tools during region agglomeration. We propose an active learning approach for performing hierarchical agglomerative segmentation from superpixels. Our method combines multiple features at all scales of the agglomerative process, works for data with an arbitrary number of dimensions, and scales to very large datasets. We advocate the use of variation of information to measure segmentation accuracy, particularly in 3D electron microscopy (EM) images of neural tissue, and using this metric demonstrate an improvement over competing algorithms in EM and natural images.\n    ",
        "submission_date": "2013-03-25T00:00:00",
        "last_modified_date": "2013-07-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1303.6361",
        "title": "Video Face Matching using Subset Selection and Clustering of Probabilistic Multi-Region Histograms",
        "authors": [
            "Sandra Mau",
            "Shaokang Chen",
            "Conrad Sanderson",
            "Brian C. Lovell"
        ],
        "abstract": "Balancing computational efficiency with recognition accuracy is one of the major challenges in real-world video-based face recognition. A significant design decision for any such system is whether to process and use all possible faces detected over the video frames, or whether to select only a few \"best\" faces. This paper presents a video face recognition system based on probabilistic Multi-Region Histograms to characterise performance trade-offs in: (i) selecting a subset of faces compared to using all faces, and (ii) combining information from all faces via clustering. Three face selection metrics are evaluated for choosing a subset: face detection confidence, random subset, and sequential selection. Experiments on the recently introduced MOBIO dataset indicate that the usage of all faces through clustering always outperformed selecting only a subset of faces. The experiments also show that the face selection metric based on face detection confidence generally provides better recognition performance than random or sequential sampling. Moreover, the optimal number of faces varies drastically across selection metric and subsets of MOBIO. Given the trade-offs between computational effort, recognition accuracy and robustness, it is recommended that face feature clustering would be most advantageous in batch processing (particularly for video-based watchlists), whereas face selection methods should be limited to applications with significant computational restrictions.\n    ",
        "submission_date": "2013-03-26T00:00:00",
        "last_modified_date": "2013-03-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1303.6455",
        "title": "Performance Evaluation of Edge-Directed Interpolation Methods for Images",
        "authors": [
            "Shaode Yu",
            "Qingsong Zhu",
            "Shibin Wu",
            "Yaoqin Xie"
        ],
        "abstract": "Many interpolation methods have been developed for high visual quality, but fail for inability to preserve image structures. Edges carry heavy structural information for detection, determination and classification. Edge-adaptive interpolation approaches become a center of focus. In this paper, performance of four edge-directed interpolation methods comparing with two traditional methods is evaluated on two groups of images. These methods include new edge-directed interpolation (NEDI), edge-guided image interpolation (EGII), iterative curvature-based interpolation (ICBI), directional cubic convolution interpolation (DCCI) and two traditional approaches, bi-linear and bi-cubic. Meanwhile, no parameters are mentioned to measure edge-preserving ability of edge-adaptive interpolation approaches and we proposed two. One evaluates accuracy and the other measures robustness of edge-preservation ability. Performance evaluation is based on six parameters. Objective assessment and visual analysis are illustrated and conclusions are drawn from theoretical backgrounds and practical results.\n    ",
        "submission_date": "2013-03-26T00:00:00",
        "last_modified_date": "2013-03-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1303.6619",
        "title": "An N-dimensional approach towards object based classification of remotely sensed imagery",
        "authors": [
            "Arun p V",
            "S.K. Katiyar"
        ],
        "abstract": "Remote sensing techniques are widely used for land cover classification and urban analysis. The availability of high resolution remote sensing imagery limits the level of classification accuracy attainable from pixel-based approach. In this paper object-based classification scheme based on a hierarchical support vector machine is introduced. By combining spatial and spectral information, the amount of overlap between classes can be decreased; thereby yielding higher classification accuracy and more accurate land cover maps. We have adopted certain automatic approaches based on the advanced techniques as Cellular automata and Genetic Algorithm for kernel and tuning parameter selection. Performance evaluation of the proposed methodology in comparison with the existing approaches is performed with reference to the Bhopal city study area.\n    ",
        "submission_date": "2013-03-26T00:00:00",
        "last_modified_date": "2013-03-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1303.6711",
        "title": "An intelligent approach towards automatic shape modeling and object extraction from satellite images using cellular automata based algorithm",
        "authors": [
            "P. V. Arun",
            "S.K. Katiyar"
        ],
        "abstract": "Automatic feature extraction domain has witnessed the application of many intelligent methodologies over past decade; however detection accuracy of these approaches were limited as object geometry and contextual knowledge were not given enough consideration. In this paper, we propose a frame work for accurate detection of features along with automatic interpolation, and interpretation by modeling feature shape as well as contextual knowledge using advanced techniques such as SVRF, Cellular Neural Network, Core set, and MACA. Developed methodology has been compared with contemporary methods using different statistical measures. Investigations over various satellite images revealed that considerable success was achieved with the CNN approach. CNN has been effective in modeling different complex features effectively and complexity of the approach has been considerably reduced using corset optimization. The system has dynamically used spectral and spatial information for representing contextual knowledge using CNN-prolog approach. System has been also proved to be effective in providing intelligent interpolation and interpretation of random features.\n    ",
        "submission_date": "2013-03-27T00:00:00",
        "last_modified_date": "2013-03-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1303.6926",
        "title": "A Comparative Analysis on the Applicability of Entropy in remote sensing",
        "authors": [
            "Dr. S.K. Katiyar",
            "Arun P. V."
        ],
        "abstract": "Entropy is the measure of uncertainty in any data and is adopted for maximisation of mutual information in many remote sensing operations. The availability of wide entropy variations motivated us for an investigation over the suitability preference of these versions to specific operations. Methodologies were implemented in Matlab and were enhanced with entropy variations. Evaluation of various implementations was based on different statistical parameters with reference to the study area The popular available versions like Tsalli's, Shanon's, and Renyi's entropies were analysed in context of various remote sensing operations namely thresholding, clustering and registration.\n    ",
        "submission_date": "2013-03-27T00:00:00",
        "last_modified_date": "2013-03-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1303.6927",
        "title": "An investigation towards wavelet based optimization of automatic image registration techniques",
        "authors": [
            "Arun P. V.",
            "Dr. S.K. Katiyar"
        ],
        "abstract": "Image registration is the process of transforming different sets of data into one coordinate system and is required for various remote sensing applications like change detection, image fusion, and other related areas. The effect of increased relief displacement, requirement of more control points, and increased data volume are the challenges associated with the registration of high resolution image data. The objective of this research work is to study the most efficient techniques and to investigate the extent of improvement achievable by enhancing them with Wavelet transform. The SIFT feature based method uses the Eigen value for extracting thousands of key points based on scale invariant features and these feature points when further enhanced by the wavelet transform yields the best results.\n    ",
        "submission_date": "2013-03-27T00:00:00",
        "last_modified_date": "2013-03-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1303.7390",
        "title": "Geometric tree kernels: Classification of COPD from airway tree geometry",
        "authors": [
            "Aasa Feragen",
            "Jens Petersen",
            "Dominik Grimm",
            "Asger Dirksen",
            "Jesper Holst Pedersen",
            "Karsten Borgwardt",
            "Marleen de Bruijne"
        ],
        "abstract": "Methodological contributions: This paper introduces a family of kernels for analyzing (anatomical) trees endowed with vector valued measurements made along the tree. While state-of-the-art graph and tree kernels use combinatorial tree/graph structure with discrete node and edge labels, the kernels presented in this paper can include geometric information such as branch shape, branch radius or other vector valued properties. In addition to being flexible in their ability to model different types of attributes, the presented kernels are computationally efficient and some of them can easily be computed for large datasets (N of the order 10.000) of trees with 30-600 branches. Combining the kernels with standard machine learning tools enables us to analyze the relation between disease and anatomical tree structure and geometry. Experimental results: The kernels are used to compare airway trees segmented from low-dose CT, endowed with branch shape descriptors and airway wall area percentage measurements made along the tree. Using kernelized hypothesis testing we show that the geometric airway trees are significantly differently distributed in patients with Chronic Obstructive Pulmonary Disease (COPD) than in healthy individuals. The geometric tree kernels also give a significant increase in the classification accuracy of COPD from geometric tree structure endowed with airway wall thickness measurements in comparison with state-of-the-art methods, giving further insight into the relationship between airway wall thickness and COPD. Software: Software for computing kernels and statistical tests is available at ",
        "submission_date": "2013-03-29T00:00:00",
        "last_modified_date": "2013-04-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.0019",
        "title": "Age group and gender recognition from human facial images",
        "authors": [
            "Tizita Nesibu Shewaye"
        ],
        "abstract": "This work presents an automatic human gender and age group recognition system based on human facial images. It makes an extensive experiment with row pixel intensity valued features and Discrete Cosine Transform (DCT) coefficient features with Principal Component Analysis and k-Nearest Neighbor classification to identify the best recognition approach. The final results show approaches using DCT coefficient outperform their counter parts resulting in a 99% correct gender recognition rate and 68% correct age group recognition rate (considering four distinct age groups) in unseen test images. Detailed experimental settings and obtained results are clearly presented and explained in this report.\n    ",
        "submission_date": "2013-03-29T00:00:00",
        "last_modified_date": "2013-03-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.0023",
        "title": "The two-dimensional Gabor function adapted to natural image statistics: A model of simple-cell receptive fields and sparse structure in images",
        "authors": [
            "Peter Loxley"
        ],
        "abstract": "The two-dimensional Gabor function is adapted to natural image statistics, leading to a tractable probabilistic generative model that can be used to model simple-cell receptive-field profiles, or generate basis functions for sparse coding applications. Learning is found to be most pronounced in three Gabor-function parameters representing the size and spatial frequency of the two-dimensional Gabor function, and characterized by a non-uniform probability distribution with heavy tails. All three parameters are found to be strongly correlated: resulting in a basis of multiscale Gabor functions with similar aspect ratios, and size-dependent spatial frequencies. A key finding is that the distribution of receptive-field sizes is scale-invariant over a wide range of values, so there is no characteristic receptive-field size selected by natural image statistics. The Gabor-function aspect ratio is found to be approximately conserved by the learning rules and is therefore not well-determined by natural image statistics. This allows for three distinct solutions: a basis of Gabor functions with sharp orientation resolution at the expense of spatial-frequency resolution; a basis of Gabor functions with sharp spatial-frequency resolution at the expense of orientation resolution; or a basis with unit aspect ratio. Arbitrary mixtures of all three cases are also possible. Two parameters controlling the shape of the marginal distributions in a probabilistic generative model fully account for all three solutions. The best-performing probabilistic generative model for sparse coding applications is found to be a Gaussian copula with Pareto marginal probability density functions.\n    ",
        "submission_date": "2013-03-29T00:00:00",
        "last_modified_date": "2020-06-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.0035",
        "title": "Translation-Invariant Shrinkage/Thresholding of Group Sparse Signals",
        "authors": [
            "Po-Yu Chen",
            "Ivan W. Selesnick"
        ],
        "abstract": "This paper addresses signal denoising when large-amplitude coefficients form clusters (groups). The L1-norm and other separable sparsity models do not capture the tendency of coefficients to cluster (group sparsity). This work develops an algorithm, called 'overlapping group shrinkage' (OGS), based on the minimization of a convex cost function involving a group-sparsity promoting penalty function. The groups are fully overlapping so the denoising method is translation-invariant and blocking artifacts are avoided. Based on the principle of majorization-minimization (MM), we derive a simple iterative minimization algorithm that reduces the cost function monotonically. A procedure for setting the regularization parameter, based on attenuating the noise to a specified level, is also described. The proposed approach is illustrated on speech enhancement, wherein the OGS approach is applied in the short-time Fourier transform (STFT) domain. The denoised speech produced by OGS does not suffer from musical noise.\n    ",
        "submission_date": "2013-03-29T00:00:00",
        "last_modified_date": "2013-03-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.0421",
        "title": "Stroke-Based Cursive Character Recognition",
        "authors": [
            "K.C. Santosh",
            "E. Iwata"
        ],
        "abstract": "Human eye can see and read what is written or displayed either in natural handwriting or in printed format. The same work in case the machine does is called handwriting recognition. Handwriting recognition can be broken down into two categories: off-line and on-line. ...\n    ",
        "submission_date": "2013-04-01T00:00:00",
        "last_modified_date": "2013-04-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.0823",
        "title": "Lie Algebrized Gaussians for Image Representation",
        "authors": [
            "Liyu Gong",
            "Meng Chen",
            "Chunlong Hu"
        ],
        "abstract": "We present an image representation method which is derived from analyzing Gaussian probability density function (\\emph{pdf}) space using Lie group theory. In our proposed method, images are modeled by Gaussian mixture models (GMMs) which are adapted from a globally trained GMM called universal background model (UBM). Then we vectorize the GMMs based on two facts: (1) components of image-specific GMMs are closely grouped together around their corresponding component of the UBM due to the characteristic of the UBM adaption procedure; (2) Gaussian \\emph{pdf}s form a Lie group, which is a differentiable manifold rather than a vector space. We map each Gaussian component to the tangent vector space (named Lie algebra) of Lie group at the manifold position of UBM. The final feature vector, named Lie algebrized Gaussians (LAG) is then constructed by combining the Lie algebrized Gaussian components with mixture weights. We apply LAG features to scene category recognition problem and observe state-of-the-art performance on 15Scenes benchmark.\n    ",
        "submission_date": "2013-04-03T00:00:00",
        "last_modified_date": "2017-05-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.0839",
        "title": "Multiscale Hybrid Non-local Means Filtering Using Modified Similarity Measure",
        "authors": [
            "Zahid Hussain Shamsi",
            "Dai-Gyoung Kim"
        ],
        "abstract": "A new multiscale implementation of non-local means filtering for image denoising is proposed. The proposed algorithm also introduces a modification of similarity measure for patch comparison. The standard Euclidean norm is replaced by weighted Euclidean norm for patch based comparison. Assuming the patch as an oriented surface, notion of normal vector patch is being associated with each patch. The inner product of these normal vector patches is then used in weighted Euclidean distance of photometric patches as the weight factor. The algorithm involves two steps: The first step is multiscale implementation of an accelerated non-local means filtering in the stationary wavelet domain to obtain a refined version of the noisy patches for later comparison. This step is inspired by a preselection phase of finding similar patches in various non-local means approaches. The next step is to apply the modified non-local means filtering to the noisy image using the reference patches obtained in the first step. These refined patches contain less noise, and consequently the computation of normal vectors and partial derivatives is more accurate. Experimental results indicate equivalent or better performance of proposed algorithm as compared to various state of the art algorithms.\n    ",
        "submission_date": "2013-04-03T00:00:00",
        "last_modified_date": "2013-04-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.0840",
        "title": "A Fast Semidefinite Approach to Solving Binary Quadratic Problems",
        "authors": [
            "Peng Wang",
            "Chunhua Shen",
            "Anton van den Hengel"
        ],
        "abstract": "Many computer vision problems can be formulated as binary quadratic programs (BQPs). Two classic relaxation methods are widely used for solving BQPs, namely, spectral methods and semidefinite programming (SDP), each with their own advantages and disadvantages. Spectral relaxation is simple and easy to implement, but its bound is loose. Semidefinite relaxation has a tighter bound, but its computational complexity is high for large scale problems. We present a new SDP formulation for BQPs, with two desirable properties. First, it has a similar relaxation bound to conventional SDP formulations. Second, compared with conventional SDP methods, the new SDP formulation leads to a significantly more efficient and scalable dual optimization approach, which has the same degree of complexity as spectral methods. Extensive experiments on various applications including clustering, image segmentation, co-segmentation and registration demonstrate the usefulness of our SDP formulation for solving large-scale BQPs.\n    ",
        "submission_date": "2013-04-03T00:00:00",
        "last_modified_date": "2013-04-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.0869",
        "title": "Patch-based Probabilistic Image Quality Assessment for Face Selection and Improved Video-based Face Recognition",
        "authors": [
            "Yongkang Wong",
            "Shaokang Chen",
            "Sandra Mau",
            "Conrad Sanderson",
            "Brian C. Lovell"
        ],
        "abstract": "In video based face recognition, face images are typically captured over multiple frames in uncontrolled conditions, where head pose, illumination, shadowing, motion blur and focus change over the sequence. Additionally, inaccuracies in face localisation can also introduce scale and alignment variations. Using all face images, including images of poor quality, can actually degrade face recognition performance. While one solution it to use only the \"best\" subset of images, current face selection techniques are incapable of simultaneously handling all of the abovementioned issues. We propose an efficient patch-based face image quality assessment algorithm which quantifies the similarity of a face image to a probabilistic face model, representing an \"ideal\" face. Image characteristics that affect recognition are taken into account, including variations in geometric alignment (shift, rotation and scale), sharpness, head pose and cast shadows. Experiments on FERET and PIE datasets show that the proposed algorithm is able to identify images which are simultaneously the most frontal, aligned, sharp and well illuminated. Further experiments on a new video surveillance dataset (termed ChokePoint) show that the proposed method provides better face subsets than existing face selection techniques, leading to significant improvements in recognition accuracy.\n    ",
        "submission_date": "2013-04-03T00:00:00",
        "last_modified_date": "2014-03-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.0886",
        "title": "Improved Anomaly Detection in Crowded Scenes via Cell-based Analysis of Foreground Speed, Size and Texture",
        "authors": [
            "Vikas Reddy",
            "Conrad Sanderson",
            "Brian C. Lovell"
        ],
        "abstract": "A robust and efficient anomaly detection technique is proposed, capable of dealing with crowded scenes where traditional tracking based approaches tend to fail. Initial foreground segmentation of the input frames confines the analysis to foreground objects and effectively ignores irrelevant background dynamics. Input frames are split into non-overlapping cells, followed by extracting features based on motion, size and texture from each cell. Each feature type is independently analysed for the presence of an anomaly. Unlike most methods, a refined estimate of object motion is achieved by computing the optical flow of only the foreground pixels. The motion and size features are modelled by an approximated version of kernel density estimation, which is computationally efficient even for large training datasets. Texture features are modelled by an adaptively grown codebook, with the number of entries in the codebook selected in an online fashion. Experiments on the recently published UCSD Anomaly Detection dataset show that the proposed method obtains considerably better results than three recent approaches: MPPCA, social force, and mixture of dynamic textures (MDT). The proposed method is also several orders of magnitude faster than MDT, the next best performing method.\n    ",
        "submission_date": "2013-04-03T00:00:00",
        "last_modified_date": "2013-04-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.1014",
        "title": "A Novel Frank-Wolfe Algorithm. Analysis and Applications to Large-Scale SVM Training",
        "authors": [
            "Hector Allende",
            "Emanuele Frandi",
            "Ricardo Nanculef",
            "Claudio Sartori"
        ],
        "abstract": "Recently, there has been a renewed interest in the machine learning community for variants of a sparse greedy approximation procedure for concave optimization known as {the Frank-Wolfe (FW) method}. In particular, this procedure has been successfully applied to train large-scale instances of non-linear Support Vector Machines (SVMs). Specializing FW to SVM training has allowed to obtain efficient algorithms but also important theoretical results, including convergence analysis of training algorithms and new characterizations of model sparsity.\n",
        "submission_date": "2013-04-03T00:00:00",
        "last_modified_date": "2013-10-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.1022",
        "title": "A software for aging faces applied to ancient marble busts",
        "authors": [
            "Amelia Carolina Sparavigna"
        ],
        "abstract": "The study and development of software able to show the effect of aging of faces is one of the tasks of face recognition technologies. Some software solutions are used for investigations, some others to show the effects of drugs on healthy appearance, however some other applications can be proposed for the analysis of visual arts. Here we use a freely available software, which is providing interesting results, for the comparison of ancient marble busts. An analysis of Augustus busts is proposed.\n    ",
        "submission_date": "2013-04-03T00:00:00",
        "last_modified_date": "2013-04-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.1233",
        "title": "Shadow Detection: A Survey and Comparative Evaluation of Recent Methods",
        "authors": [
            "Andres Sanin",
            "Conrad Sanderson",
            "Brian C. Lovell"
        ],
        "abstract": "This paper presents a survey and a comparative evaluation of recent techniques for moving cast shadow detection. We identify shadow removal as a critical step for improving object detection and tracking. The survey covers methods published during the last decade, and places them in a feature-based taxonomy comprised of four categories: chromacity, physical, geometry and textures. A selection of prominent methods across the categories is compared in terms of quantitative performance measures (shadow detection and discrimination rates, colour desaturation) as well as qualitative observations. Furthermore, we propose the use of tracking performance as an unbiased approach for determining the practical usefulness of shadow detection methods. The evaluation indicates that all shadow detection approaches make different contributions and all have individual strength and weaknesses. Out of the selected methods, the geometry-based technique has strict assumptions and is not generalisable to various environments, but it is a straightforward choice when the objects of interest are easy to model and their shadows have different orientation. The chromacity based method is the fastest to implement and run, but it is sensitive to noise and less effective in low saturated scenes. The physical method improves upon the accuracy of the chromacity method by adapting to local shadow models, but fails when the spectral properties of the objects are similar to that of the background. The small-region texture based method is especially robust for pixels whose neighbourhood is textured, but may take longer to implement and is the most computationally expensive. The large-region texture based method produces the most accurate results, but has a significant computational load due to its multiple processing steps.\n    ",
        "submission_date": "2013-04-04T00:00:00",
        "last_modified_date": "2013-04-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.1250",
        "title": "Fast Approximate L_infty Minimization: Speeding Up Robust Regression",
        "authors": [
            "Fumin Shen",
            "Chunhua Shen",
            "Rhys Hill",
            "Anton van den Hengel",
            "Zhenmin Tang"
        ],
        "abstract": "Minimization of the $L_\\infty$ norm, which can be viewed as approximately solving the non-convex least median estimation problem, is a powerful method for outlier removal and hence robust regression. However, current techniques for solving the problem at the heart of $L_\\infty$ norm minimization are slow, and therefore cannot scale to large problems. A new method for the minimization of the $L_\\infty$ norm is presented here, which provides a speedup of multiple orders of magnitude for data with high dimension. This method, termed Fast $L_\\infty$ Minimization, allows robust regression to be applied to a class of problems which were previously inaccessible. It is shown how the $L_\\infty$ norm minimization problem can be broken up into smaller sub-problems, which can then be solved extremely efficiently. Experimental results demonstrate the radical reduction in computation time, along with robustness against large numbers of outliers in a few model-fitting problems.\n    ",
        "submission_date": "2013-04-04T00:00:00",
        "last_modified_date": "2013-04-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.1419",
        "title": "Integration of spatio-temporal contrast sensitivity with a multi-slice channelized Hotelling observer",
        "authors": [
            "Ali N. Avanaki",
            "Kathryn S. Espig",
            "Cedric Marchessoux",
            "Elizabeth A. Krupinski",
            "Predrag R. Bakic",
            "Tom R. L. Kimpe",
            "Andrew D. A. Maidment"
        ],
        "abstract": "Barten's model of spatio-temporal contrast sensitivity function of human visual system is embedded in a multi-slice channelized Hotelling observer. This is done by 3D filtering of the stack of images with the spatio-temporal contrast sensitivity function and feeding the result (i.e., the perceived image stack) to the multi-slice channelized Hotelling observer. The proposed procedure of considering spatio-temporal contrast sensitivity function is generic in the sense that it can be used with observers other than multi-slice channelized Hotelling observer. Detection performance of the new observer in digital breast tomosynthesis is measured in a variety of browsing speeds, at two spatial sampling rates, using computer simulations. Our results show a peak in detection performance in mid browsing speeds. We compare our results to those of a human observer study reported earlier (I. Diaz et al. SPIE MI 2011). The effects of display luminance, contrast and spatial sampling rate, with and without considering foveal vision, are also studied. Reported simulations are conducted with real digital breast tomosynthesis image stacks, as well as stacks from an anthropomorphic software breast phantom (P. Bakic et al. Med Phys. 2011). Lesion cases are simulated by inserting single micro-calcifications or masses. Limitations of our methods and ways to improve them are discussed.\n    ",
        "submission_date": "2013-04-04T00:00:00",
        "last_modified_date": "2013-04-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.1517",
        "title": "Model-based Influence Diagrams for Machine Vision",
        "authors": [
            "Tod S. Levitt",
            "John Mark Agosta",
            "Thomas O. Binford"
        ],
        "abstract": "We show an approach to automated control of machine vision systems based on incremental creation and evaluation of a particular family of influence diagrams that represent hypotheses of imagery interpretation and possible subsequent processing decisions.  In our approach, model-based machine vision techniques are integrated with hierarchical Bayesian inference to provide a framework for representing and matching instances of objects and relationships in imagery and for accruing probabilities to rank order conflicting scene interpretations.  We extend a result of Tatman and Shachter to show that the sequence of processing decisions derived from evaluating the diagrams at each stage is the same as the sequence that would have been derived by evaluating the final influence diagram that contains all random variables created during the run of the vision system.\n    ",
        "submission_date": "2013-03-27T00:00:00",
        "last_modified_date": "2013-03-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.1568",
        "title": "Multiscale Fractal Descriptors Applied to Texture Classification",
        "authors": [
            "Jo\u00e3o Batista Florindo",
            "Odemir Martinez Bruno"
        ],
        "abstract": "This work proposes the combination of multiscale transform with fractal descriptors employed in the classification of gray-level texture images. We apply the space-scale transform (derivative + Gaussian filter) over the Bouligand-Minkowski fractal descriptors, followed by a threshold over the filter response, aiming at attenuating noise effects caused by the final part of this response. The method is tested in the classification of a well-known data set (Brodatz) and compared with other classical texture descriptor techniques. The results demonstrate the advantage of the proposed approach, achieving a higher success rate with a reduced amount of descriptors.\n    ",
        "submission_date": "2013-04-04T00:00:00",
        "last_modified_date": "2013-04-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.1572",
        "title": "Stable and Informative Spectral Signatures for Graph Matching",
        "authors": [
            "Nan Hu",
            "Raif M. Rustamov",
            "Leonidas Guibas"
        ],
        "abstract": "In this paper, we consider the approximate weighted graph matching problem and introduce stable and informative first and second order compatibility terms suitable for inclusion into the popular integer quadratic program formulation. Our approach relies on a rigorous analysis of stability of spectral signatures based on the graph Laplacian. In the case of the first order term, we derive an objective function that measures both the stability and informativeness of a given spectral signature. By optimizing this objective, we design new spectral node signatures tuned to a specific graph to be matched. We also introduce the pairwise heat kernel distance as a stable second order compatibility term; we justify its plausibility by showing that in a certain limiting case it converges to the classical adjacency matrix-based second order compatibility function. We have tested our approach on a set of synthetic graphs, the widely-used CMU house sequence, and a set of real images. These experiments show the superior performance of our first and second order compatibility terms as compared with the commonly used ones.\n    ",
        "submission_date": "2013-04-04T00:00:00",
        "last_modified_date": "2018-04-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.1876",
        "title": "Proceedings of the 37th Annual Workshop of the Austrian Association for Pattern Recognition (\u00d6AGM/AAPR), 2013",
        "authors": [
            "Justus Piater",
            "Antonio Rodr\u00edguez-S\u00e1nchez"
        ],
        "abstract": "This volume represents the proceedings of the 37th Annual Workshop of the Austrian Association for Pattern Recognition (\u00d6AGM/AAPR), held May 23-24, 2013, in Innsbruck, Austria.\n    ",
        "submission_date": "2013-04-06T00:00:00",
        "last_modified_date": "2013-05-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.1930",
        "title": "Client-Driven Content Extraction Associated with Table",
        "authors": [
            "K.C. Santosh",
            "Abdel Bela\u00efd"
        ],
        "abstract": "The goal of the project is to extract content within table in document images based on learnt patterns. Real-world users i.e., clients first provide a set of key fields within the table which they think are important. These are first used to represent the graph where nodes are labelled with semantics including other features and edges are attributed with relations. Attributed relational graph (ARG) is then employed to mine similar graphs from a document image. Each mined graph will represent an item within the table, and hence a set of such graphs will compose a table. We have validated the concept by using a real-world industrial problem.\n    ",
        "submission_date": "2013-04-06T00:00:00",
        "last_modified_date": "2013-04-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.1972",
        "title": "Facial transformations of ancient portraits: the face of Caesar",
        "authors": [
            "Amelia Carolina Sparavigna"
        ],
        "abstract": "Some software solutions used to obtain the facial transformations can help investigating the artistic metamorphosis of the ancient portraits of the same person. An analysis with a freely available software of portraitures of Julius Caesar is proposed, showing his several \"morphs\". The software helps enhancing the mood the artist added to a portrait.\n    ",
        "submission_date": "2013-04-07T00:00:00",
        "last_modified_date": "2013-04-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.1995",
        "title": "Image Retrieval using Histogram Factorization and Contextual Similarity Learning",
        "authors": [
            "Liu Liang"
        ],
        "abstract": "Image retrieval has been a top topic in the field of both computer vision and machine learning for a long time. Content based image retrieval, which tries to retrieve images from a database visually similar to a query image, has attracted much attention. Two most important issues of image retrieval are the representation and ranking of the images. Recently, bag-of-words based method has shown its power as a representation method. Moreover, nonnegative matrix factorization is also a popular way to represent the data samples. In addition, contextual similarity learning has also been studied and proven to be an effective method for the ranking problem. However, these technologies have never been used together. In this paper, we developed an effective image retrieval system by representing each image using the bag-of-words method as histograms, and then apply the nonnegative matrix factorization to factorize the histograms, and finally learn the ranking score using the contextual similarity learning method. The proposed novel system is evaluated on a large scale image database and the effectiveness is shown.\n    ",
        "submission_date": "2013-04-07T00:00:00",
        "last_modified_date": "2013-04-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.2109",
        "title": "Automatic Fingerprint Recognition Using Minutiae Matching Technique for the Large Fingerprint Database",
        "authors": [
            "S.M. Mohsen",
            "S.M. Zamshed Farhan",
            "M.M.A. Hashem"
        ],
        "abstract": "Extracting minutiae from fingerprint images is one of the most important steps in automatic fingerprint identification system. Because minutiae matching are certainly the most well-known and widely used method for fingerprint matching, minutiae are local discontinuities in the fingerprint pattern. In this paper a fingerprint matching algorithm is proposed using some specific feature of the minutiae points, also the acquired fingerprint image is considered by minimizing its size by generating a corresponding fingerprint template for a large fingerprint database. The results achieved are compared with those obtained through some other methods also shows some improvement in the minutiae detection process in terms of memory and time required.\n    ",
        "submission_date": "2013-04-08T00:00:00",
        "last_modified_date": "2013-04-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.2133",
        "title": "Dynamic Amelioration of Resolution Mismatches for Local Feature Based Identity Inference",
        "authors": [
            "Yongkang Wong",
            "Conrad Sanderson",
            "Sandra Mau",
            "Brian C. Lovell"
        ],
        "abstract": "While existing face recognition systems based on local features are robust to issues such as misalignment, they can exhibit accuracy degradation when comparing images of differing resolutions. This is common in surveillance environments where a gallery of high resolution mugshots is compared to low resolution CCTV probe images, or where the size of a given image is not a reliable indicator of the underlying resolution (eg. poor optics). To alleviate this degradation, we propose a compensation framework which dynamically chooses the most appropriate face recognition system for a given pair of image resolutions. This framework applies a novel resolution detection method which does not rely on the size of the input images, but instead exploits the sensitivity of local features to resolution using a probabilistic multi-region histogram approach. Experiments on a resolution-modified version of the \"Labeled Faces in the Wild\" dataset show that the proposed resolution detector frontend obtains a 99% average accuracy in selecting the most appropriate face recognition system, resulting in higher overall face discrimination accuracy (across several resolutions) compared to the individual baseline face recognition systems.\n    ",
        "submission_date": "2013-04-08T00:00:00",
        "last_modified_date": "2013-04-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.2310",
        "title": "Embedding of Blink Frequency in Electrooculography Signal using Difference Expansion based Reversible Watermarking Technique",
        "authors": [
            "Nilanjan Dey",
            "Prasenjit Maji",
            "Poulami Das",
            "Shouvik Biswas",
            "Achintya Das",
            "Sheli Sinha Chaudhuri"
        ],
        "abstract": "In the past few years, like other fields, rapid expansion of digitization and globalization has influenced the medical field as well. For progress of diagnostic results most of the reputed hospitals and diagnostic centres all over the world have started exchanging medical information. In this proposed method, the calculated diagnostic parametric values of the original Electrooculography (EOG) signal are embedded as a watermark by using Difference Expansion (DE) algorithm based reversible watermarking technique. The extracted watermark provides the required parametric values at the recipient end without any post computation of the recovered EOG signal. By computing the parametric values from the recovered signal, the integrity of the extracted watermark can be validated. The time domain features of EOG signal are calculated for the generation of watermark. In the current work, various features are studied and two major features related to blink frequency are used to generate the watermark. The high Signal to Noise Ratio (SNR) and the Bit Error Rate (BER) claim the robustness of the proposed method.\n    ",
        "submission_date": "2013-03-09T00:00:00",
        "last_modified_date": "2013-03-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.2367",
        "title": "Utility-Based Control for Computer Vision",
        "authors": [
            "Tod S. Levitt",
            "Thomas O. Binford",
            "Gil J. Ettinger",
            "Patrice Gelband"
        ],
        "abstract": "Several key issues arise in implementing computer vision recognition of world objects in terms of Bayesian networks.  Computational efficiency is a driving force.  Perceptual networks are very deep, typically fifteen levels of structure.  Images are wide, e.g., an unspecified-number of edges may appear anywhere in an image 512 x 512 pixels or larger.  For efficiency, we dynamically instantiate hypotheses of observed objects.  The network is not fixed, but is created incrementally at runtime.  Generation of hypotheses of world objects and indexing of models for recognition are important, but they are not considered here [4,11].  This work is aimed at near-term implementation with parallel computation in a radar surveillance system, ADRIES [5, 15], and a system for industrial part recognition, SUCCESSOR [2].  For many applications, vision must be faster to be practical and so efficiently controlling the machine vision process is critical.  Perceptual operators may scan megapixels and may require minutes of computation time.  It is necessary to avoid unnecessary sensor actions and computation.  Parallel computation is available at several levels of processor capability.  The potential for parallel, distributed computation for high-level vision means distributing non-homogeneous computations. This paper addresses the problem of task control in machine vision systems based on Bayesian probability models.  We separate control and inference to extend the previous work [3] to maximize utility instead of probability.  Maximizing utility allows adopting perceptual strategies for efficient information gathering with sensors and analysis of sensor data.  Results of controlling machine vision via utility to recognize military situations are presented in this paper.  Future work extends this to industrial part recognition for SUCCESSOR.\n    ",
        "submission_date": "2013-03-27T00:00:00",
        "last_modified_date": "2013-03-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.2490",
        "title": "Kernel Reconstruction ICA for Sparse Representation",
        "authors": [
            "Yanhui Xiao",
            "Zhenfeng Zhu",
            "Yao Zhao"
        ],
        "abstract": "Independent Component Analysis (ICA) is an effective unsupervised tool to learn statistically independent representation. However, ICA is not only sensitive to whitening but also difficult to learn an over-complete basis. Consequently, ICA with soft Reconstruction cost(RICA) was presented to learn sparse representations with over-complete basis even on unwhitened data. Whereas RICA is infeasible to represent the data with nonlinear structure due to its intrinsic linearity. In addition, RICA is essentially an unsupervised method and can not utilize the class information. In this paper, we propose a kernel ICA model with reconstruction constraint (kRICA) to capture the nonlinear features. To bring in the class information, we further extend the unsupervised kRICA to a supervised one by introducing a discrimination constraint, namely d-kRICA. This constraint leads to learn a structured basis consisted of basis vectors from different basis subsets corresponding to different class labels. Then each subset will sparsely represent well for its own class but not for the others. Furthermore, data samples belonging to the same class will have similar representations, and thereby the learned sparse representations can take more discriminative power. Experimental results validate the effectiveness of kRICA and d-kRICA for image classification.\n    ",
        "submission_date": "2013-04-09T00:00:00",
        "last_modified_date": "2013-04-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.2683",
        "title": "Image Classification by Feature Dimension Reduction and Graph based Ranking",
        "authors": [
            "Yao Nan",
            "Qian Feng",
            "Sun Zuolei"
        ],
        "abstract": "Dimensionality reduction (DR) of image features plays an important role in image retrieval and classification tasks. Recently, two types of methods have been proposed to improve the both the accuracy and efficiency for the dimensionality reduction problem. One uses Non-negative matrix factorization (NMF) to describe the image distribution on the space of base matrix. Another one for dimension reduction trains a subspace projection matrix to project original data space into some low-dimensional subspaces which have deep architecture, so that the low-dimensional codes would be learned. At the same time, the graph based similarity learning algorithm which tries to exploit contextual information for improving the effectiveness of image rankings is also proposed for image class and retrieval problem. In this paper, after above two methods mentioned are utilized to reduce the high-dimensional features of images respectively, we learn the graph based similarity for the image classification problem. This paper compares the proposed approach with other approaches on an image database.\n    ",
        "submission_date": "2013-04-09T00:00:00",
        "last_modified_date": "2013-04-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.2743",
        "title": "Comparisons of Reasoning Mechanisms for Computer Vision",
        "authors": [
            "Ze-Nian Li"
        ],
        "abstract": "An evidential reasoning mechanism based on the Dempster-Shafer theory of evidence is introduced. Its performance in real-world image analysis is compared with other mechanisms based on the Bayesian formalism and a simple weight combination method.\n    ",
        "submission_date": "2013-03-27T00:00:00",
        "last_modified_date": "2013-03-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.2749",
        "title": "Evidential Reasoning in Image Understanding",
        "authors": [
            "Minchuan Zhang",
            "Su-shing Chen"
        ],
        "abstract": "In this paper, we present some results of evidential reasoning in understanding multispectral images of remote sensing systems. The Dempster-Shafer approach of combination of evidences is pursued to yield contextual classification results, which are compared with previous results of the Bayesian context free classification, contextual classifications of dynamic programming and stochastic relaxation approaches.\n    ",
        "submission_date": "2013-03-27T00:00:00",
        "last_modified_date": "2013-03-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.2999",
        "title": "A New Approach To Two-View Motion Segmentation Using Global Dimension Minimization",
        "authors": [
            "Bryan Poling",
            "Gilad Lerman"
        ],
        "abstract": "We present a new approach to rigid-body motion segmentation from two views. We use a previously developed nonlinear embedding of two-view point correspondences into a 9-dimensional space and identify the different motions by segmenting lower-dimensional subspaces. In order to overcome nonuniform distributions along the subspaces, whose dimensions are unknown, we suggest the novel concept of global dimension and its minimization for clustering subspaces with some theoretical motivation. We propose a fast projected gradient algorithm for minimizing global dimension and thus segmenting motions from 2-views. We develop an outlier detection framework around the proposed method, and we present state-of-the-art results on outlier-free and outlier-corrupted two-view data for segmenting motion.\n    ",
        "submission_date": "2013-04-10T00:00:00",
        "last_modified_date": "2014-01-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.3192",
        "title": "Rotational Projection Statistics for 3D Local Surface Description and Object Recognition",
        "authors": [
            "Yulan Guo",
            "Ferdous Sohel",
            "Mohammed Bennamoun",
            "Min Lu",
            "Jianwei Wan"
        ],
        "abstract": "Recognizing 3D objects in the presence of noise, varying mesh resolution, occlusion and clutter is a very challenging task. This paper presents a novel method named Rotational Projection Statistics (RoPS). It has three major modules: Local Reference Frame (LRF) definition, RoPS feature description and 3D object recognition. We propose a novel technique to define the LRF by calculating the scatter matrix of all points lying on the local surface. RoPS feature descriptors are obtained by rotationally projecting the neighboring points of a feature point onto 2D planes and calculating a set of statistics (including low-order central moments and entropy) of the distribution of these projected points. Using the proposed LRF and RoPS descriptor, we present a hierarchical 3D object recognition algorithm. The performance of the proposed LRF, RoPS descriptor and object recognition algorithm was rigorously tested on a number of popular and publicly available datasets. Our proposed techniques exhibited superior performance compared to existing techniques. We also showed that our method is robust with respect to noise and varying mesh resolution. Our RoPS based algorithm achieved recognition rates of 100%, 98.9%, 95.4% and 96.0% respectively when tested on the Bologna, UWA, Queen's and Ca' Foscari Venezia Datasets.\n    ",
        "submission_date": "2013-04-11T00:00:00",
        "last_modified_date": "2013-04-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.3406",
        "title": "Merging Satellite Measurements of Rainfall Using Multi-scale Imagery Technique",
        "authors": [
            "Seyed Hamed Alemohammad",
            "Dara Entekhabi"
        ],
        "abstract": "Several passive microwave satellites orbit the Earth and measure rainfall. These measurements have the advantage of almost full global coverage when compared to surface rain gauges. However, these satellites have low temporal revisit and missing data over some regions. Image fusion is a useful technique to fill in the gaps of one image (one satellite measurement) using another one. The proposed algorithm uses an iterative fusion scheme to integrate information from two satellite measurements. The algorithm is implemented on two datasets for 7 years of half-hourly data. The results show significant improvements in rain detection and rain intensity in the merged measurements.\n    ",
        "submission_date": "2013-04-11T00:00:00",
        "last_modified_date": "2013-04-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.3447",
        "title": "Developing and Analyzing Boundary Detection Operators Using Probabilistic Models",
        "authors": [
            "David Sher"
        ],
        "abstract": "Most feature detectors such as edge detectors or circle finders are statistical, in the sense that they decide at each point in an image about the presence of a feature, this paper describes the use of Bayesian feature detectors.\n    ",
        "submission_date": "2013-03-27T00:00:00",
        "last_modified_date": "2013-03-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.3915",
        "title": "Single View Depth Estimation from Examples",
        "authors": [
            "Tal Hassner",
            "Ronen Basri"
        ],
        "abstract": "We describe a non-parametric, \"example-based\" method for estimating the depth of an object, viewed in a single photo. Our method consults a database of example 3D geometries, searching for those which look similar to the object in the photo. The known depths of the selected database objects act as shape priors which constrain the process of estimating the object's depth. We show how this process can be performed by optimizing a well defined target likelihood function, via a hard-EM procedure. We address the problem of representing the (possibly infinite) variability of viewing conditions with a finite (and often very small) example set, by proposing an on-the-fly example update scheme. We further demonstrate the importance of non-stationarity in avoiding misleading examples when estimating structured shapes. We evaluate our method and present both qualitative as well as quantitative results for challenging object classes. Finally, we show how this same technique may be readily applied to a number of related problems. These include the novel task of estimating the occluded depth of an object's backside and the task of tailoring custom fitting image-maps for input depths.\n    ",
        "submission_date": "2013-04-14T00:00:00",
        "last_modified_date": "2013-04-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.4041",
        "title": "Multispectral Spatial Characterization: Application to Mitosis Detection in Breast Cancer Histopathology",
        "authors": [
            "H. Irshad",
            "A. Gouaillard",
            "L. Roux",
            "D. Racoceanu"
        ],
        "abstract": "Accurate detection of mitosis plays a critical role in breast cancer histopathology. Manual detection and counting of mitosis is tedious and subject to considerable inter- and intra-reader variations. Multispectral imaging is a recent medical imaging technology, proven successful in increasing the segmentation accuracy in other fields. This study aims at improving the accuracy of mitosis detection by developing a specific solution using multispectral and multifocal imaging of breast cancer histopathological data. We propose to enable clinical routine-compliant quality of mitosis discrimination from other objects. The proposed framework includes comprehensive analysis of spectral bands and z-stack focus planes, detection of expected mitotic regions (candidates) in selected focus planes and spectral bands, computation of multispectral spatial features for each candidate, selection of multispectral spatial features and a study of different state-of-the-art classification methods for candidates classification as mitotic or non mitotic figures. This framework has been evaluated on MITOS multispectral medical dataset and achieved 60% detection rate and 57% F-Measure. Our results indicate that multispectral spatial features have more information for mitosis classification in comparison with white spectral band features, being therefore a very promising exploration area to improve the quality of the diagnosis assistance in histopathology.\n    ",
        "submission_date": "2013-04-15T00:00:00",
        "last_modified_date": "2013-04-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.4112",
        "title": "Shadow Estimation Method for \"The Episolar Constraint: Monocular Shape from Shadow Correspondence\"",
        "authors": [
            "Austin Abrams",
            "Chris Hawley",
            "Kylia Miskell",
            "Adina Stoica",
            "Nathan Jacobs",
            "Robert Pless"
        ],
        "abstract": "Recovering shadows is an important step for many vision algorithms. Current approaches that work with time-lapse sequences are limited to simple thresholding heuristics. We show these approaches only work with very careful tuning of parameters, and do not work well for long-term time-lapse sequences taken over the span of many months. We introduce a parameter-free expectation maximization approach which simultaneously estimates shadows, albedo, surface normals, and skylight. This approach is more accurate than previous methods, works over both very short and very long sequences, and is robust to the effects of nonlinear camera response. Finally, we demonstrate that the shadow masks derived through this algorithm substantially improve the performance of sun-based photometric stereo compared to earlier shadow mask estimation.\n    ",
        "submission_date": "2013-04-15T00:00:00",
        "last_modified_date": "2013-04-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.4535",
        "title": "Heterogeneous patterns enhancing static and dynamic texture classification",
        "authors": [
            "N\u00fabia Rosa da Silva",
            "Odemir Martinez Bruno"
        ],
        "abstract": "Some mixtures, such as colloids like milk, blood, and gelatin, have homogeneous appearance when viewed with the naked eye, however, to observe them at the nanoscale is possible to understand the heterogeneity of its components. The same phenomenon can occur in pattern recognition in which it is possible to see heterogeneous patterns in texture images. However, current methods of texture analysis can not adequately describe such heterogeneous patterns. Common methods used by researchers analyse the image information in a global way, taking all its features in an integrated manner. Furthermore, multi-scale analysis verifies the patterns at different scales, but still preserving the homogeneous analysis. On the other hand various methods use textons to represent the texture, breaking texture down into its smallest unit. To tackle this problem, we propose a method to identify texture patterns not small as textons at distinct scales enhancing the separability among different types of texture. We find sub patterns of texture according to the scale and then group similar patterns for a more refined analysis. Tests were performed in four static texture databases and one dynamic one. Results show that our method provides better classification rate compared with conventional approaches both in static and in dynamic texture.\n    ",
        "submission_date": "2013-04-16T00:00:00",
        "last_modified_date": "2013-04-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.4652",
        "title": "A Health Monitoring System for Elder and Sick Persons",
        "authors": [
            "Ankit Chaudhary",
            "Jagdish L. Raheja"
        ],
        "abstract": "This paper discusses a vision based health monitoring system which would be very easy in use and deployment. Elder and sick people who are not able to talk or walk they are dependent on other human beings for their daily needs and need continuous monitoring. The developed system provides facility to the sick or elder person to describe his or her need to their caretaker in lingual description by showing particular hand gesture with the developed system. This system uses fingertip detection technique for gesture extraction and artificial neural network for gesture classification and recognition. The system is able to work in different light conditions and can be connected to different devices to announce users need on a distant location.\n    ",
        "submission_date": "2013-04-17T00:00:00",
        "last_modified_date": "2013-04-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.4662",
        "title": "Tracking of Fingertips and Centres of Palm using KINECT",
        "authors": [
            "J. L. Raheja",
            "A. Chaudhary",
            "K Singal"
        ],
        "abstract": "Hand Gesture is a popular way to interact or control machines and it has been implemented in many applications. The geometry of hand is such that it is hard to construct in virtual environment and control the joints but the functionality and DOF encourage researchers to make a hand like instrument. This paper presents a novel method for fingertips detection and centres of palms detection distinctly for both hands using MS KINECT in 3D from the input image. KINECT facilitates us by providing the depth information of foreground objects. The hands were segmented using the depth vector and centres of palms were detected using distance transformation on inverse image. This result would be used to feed the inputs to the robotic hands to emulate human hands operation.\n    ",
        "submission_date": "2013-04-17T00:00:00",
        "last_modified_date": "2013-04-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.4711",
        "title": "Automated Switching System for Skin Pixel Segmentation in Varied Lighting",
        "authors": [
            "Ankit Chaudhary",
            "Ankur Gupta"
        ],
        "abstract": "In Computer Vision, colour-based spatial techniquesoften assume a static skin colour model. However, skin colour perceived by a camera can change when lighting changes. In common real environment multiple light sources impinge on the skin. Moreover, detection techniques may vary when the image under study is taken under different lighting condition than the one that was earlier under consideration. Therefore, for robust skin pixel detection, a dynamic skin colour model that can cope with the changes must be employed. This paper shows that skin pixel detection in a digital colour image can be significantly improved by employing automated colour space switching methods. In the root of the switching technique which is employed in this study, lies the statistical mean of value of the skin pixels in the image which in turn has been derived from the Value, measures as a third component of the HSV. The study is based on experimentations on a set of images where capture time conditions varying from highly illuminated to almost dark.\n    ",
        "submission_date": "2013-04-17T00:00:00",
        "last_modified_date": "2013-04-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.4765",
        "title": "Robust Noise Filtering in Image Sequences",
        "authors": [
            "Soumaya Hichri",
            "Faouzi Benzarti",
            "Hamid Amiri"
        ],
        "abstract": "Image sequences filtering have recently become a very important technical problem especially with the advent of new technology in multimedia and video systems applications. Often image sequences are corrupted by some amount of noise introduced by the image sensor and therefore inherently present in the imaging process. The main problem in the image sequences is how to deal with spatio-temporal and non stationary signals. In this paper, we propose a robust method for noise removal of image sequence based on coupled spatial and temporal anisotropic diffusion. The idea is to achieve an adaptive smoothing in both spatial and temporal directions, by solving a nonlinear diffusion equation. This allows removing noise while preserving all spatial and temporal discontinuities\n    ",
        "submission_date": "2013-04-17T00:00:00",
        "last_modified_date": "2013-04-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.4994",
        "title": "Polygon Matching and Indexing Under Affine Transformations",
        "authors": [
            "Edgar Ch\u00e1vez",
            "Ana C. Ch\u00e1vez-C\u00e1liz",
            "Jorge L. L\u00f3pez-L\u00f3pez"
        ],
        "abstract": "Given a collection $\\{Z_1,Z_2,\\ldots,Z_m\\}$ of $n$-sided polygons in the plane and a query polygon $W$ we give algorithms to find all $Z_\\ell$ such that $W=f(Z_\\ell)$ with $f$ an unknown similarity transformation in time independent of the size of the collection. If $f$ is a known affine transformation, we show how to find all $Z_\\ell$ such that $W=f(Z_\\ell)$ in $O(n+\\log(m))$ time.\n",
        "submission_date": "2013-04-18T00:00:00",
        "last_modified_date": "2013-04-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.5063",
        "title": "Combinaison d'information visuelle, conceptuelle, et contextuelle pour la construction automatique de hierarchies semantiques adaptees a l'annotation d'images",
        "authors": [
            "Hichem Bannour",
            "C\u00e9line Hudelot"
        ],
        "abstract": "This paper proposes a new methodology to automatically build semantic hierarchies suitable for image annotation and classification. The building of the hierarchy is based on a new measure of semantic similarity. The proposed measure incorporates several sources of information: visual, conceptual and contextual as we defined in this paper. The aim is to provide a measure that best represents image semantics. We then propose rules based on this measure, for the building of the final hierarchy, and which explicitly encode hierarchical relationships between different concepts. Therefore, the built hierarchy is used in a semantic hierarchical classification framework for image annotation. Our experiments and results show that the hierarchy built improves classification results.\n",
        "submission_date": "2013-04-18T00:00:00",
        "last_modified_date": "2013-04-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.5212",
        "title": "Object Tracking in Videos: Approaches and Issues",
        "authors": [
            "Duc Phu Chau",
            "Fran\u00e7ois Bremond",
            "Monique Thonnat"
        ],
        "abstract": "Mobile object tracking has an important role in the computer vision applications. In this paper, we use a tracked target-based taxonomy to present the object tracking algorithms. The tracked targets are divided into three categories: points of interest, appearance and silhouette of mobile objects. Advantages and limitations of the tracking approaches are also analyzed to find the future directions in the object tracking domain.\n    ",
        "submission_date": "2013-04-18T00:00:00",
        "last_modified_date": "2013-04-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.5319",
        "title": "A Joint Intensity and Depth Co-Sparse Analysis Model for Depth Map Super-Resolution",
        "authors": [
            "Martin Kiechle",
            "Simon Hawe",
            "Martin Kleinsteuber"
        ],
        "abstract": "High-resolution depth maps can be inferred from low-resolution depth measurements and an additional high-resolution intensity image of the same scene. To that end, we introduce a bimodal co-sparse analysis model, which is able to capture the interdependency of registered intensity and depth information. This model is based on the assumption that the co-supports of corresponding bimodal image structures are aligned when computed by a suitable pair of analysis operators. No analytic form of such operators exist and we propose a method for learning them from a set of registered training signals. This learning process is done offline and returns a bimodal analysis operator that is universally applicable to natural scenes. We use this to exploit the bimodal co-sparse analysis model as a prior for solving inverse problems, which leads to an efficient algorithm for depth map super-resolution.\n    ",
        "submission_date": "2013-04-19T00:00:00",
        "last_modified_date": "2013-04-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.5409",
        "title": "Separating the Real from the Synthetic: Minutiae Histograms as Fingerprints of Fingerprints",
        "authors": [
            "Carsten Gottschlich",
            "Stephan Huckemann"
        ],
        "abstract": "In this study we show that by the current state-of-the-art synthetically generated fingerprints can easily be discriminated from real fingerprints. We propose a method based on second order extended minutiae histograms (MHs) which can distinguish between real and synthetic prints with very high accuracy. MHs provide a fixed-length feature vector for a fingerprint which are invariant under rotation and translation. This 'test of realness' can be applied to synthetic fingerprints produced by any method. In this work, tests are conducted on the 12 publicly available databases of FVC2000, FVC2002 and FVC2004 which are well established benchmarks for evaluating the performance of fingerprint recognition algorithms; 3 of these 12 databases consist of artificial fingerprints generated by the SFinGe software. Additionally, we evaluate the discriminative performance on a database of synthetic fingerprints generated by the software of Bicz versus real fingerprint images. We conclude with suggestions for the improvement of synthetic fingerprint generation.\n    ",
        "submission_date": "2013-04-19T00:00:00",
        "last_modified_date": "2014-10-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.5583",
        "title": "Distributed Low-rank Subspace Segmentation",
        "authors": [
            "Ameet Talwalkar",
            "Lester Mackey",
            "Yadong Mu",
            "Shih-Fu Chang",
            "Michael I. Jordan"
        ],
        "abstract": "Vision problems ranging from image clustering to motion segmentation to semi-supervised learning can naturally be framed as subspace segmentation problems, in which one aims to recover multiple low-dimensional subspaces from noisy and corrupted input data. Low-Rank Representation (LRR), a convex formulation of the subspace segmentation problem, is provably and empirically accurate on small problems but does not scale to the massive sizes of modern vision datasets. Moreover, past work aimed at scaling up low-rank matrix factorization is not applicable to LRR given its non-decomposable constraints. In this work, we propose a novel divide-and-conquer algorithm for large-scale subspace segmentation that can cope with LRR's non-decomposable constraints and maintains LRR's strong recovery guarantees. This has immediate implications for the scalability of subspace segmentation, which we demonstrate on a benchmark face recognition dataset and in simulations. We then introduce novel applications of LRR-based subspace segmentation to large-scale semi-supervised learning for multimedia event detection, concept detection, and image tagging. In each case, we obtain state-of-the-art results and order-of-magnitude speed ups.\n    ",
        "submission_date": "2013-04-20T00:00:00",
        "last_modified_date": "2013-10-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.5587",
        "title": "Color image denoising by chromatic edges based vector valued diffusion",
        "authors": [
            "V. B. Surya Prasath",
            "Juan C. Moreno",
            "K. Palaniappan"
        ],
        "abstract": "In this letter we propose to denoise digital color images via an improved geometric diffusion scheme. By introducing edges detected from all three color channels into the diffusion the proposed scheme avoids color smearing artifacts. Vector valued diffusion is used to control the smoothing and the geometry of color images are taken into consideration. Color edge strength function computed from different planes is introduced and it stops the diffusion spread across chromatic edges. Experimental results indicate that the scheme achieves good denoising with edge preservation when compared to other related schemes.\n    ",
        "submission_date": "2013-04-20T00:00:00",
        "last_modified_date": "2013-05-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.5894",
        "title": "Bayesian crack detection in ultra high resolution multimodal images of paintings",
        "authors": [
            "Bruno Cornelis",
            "Yun Yang",
            "Joshua T. Vogelstein",
            "Ann Dooms",
            "Ingrid Daubechies",
            "David Dunson"
        ],
        "abstract": "The preservation of our cultural heritage is of paramount importance. Thanks to recent developments in digital acquisition techniques, powerful image analysis algorithms are developed which can be useful non-invasive tools to assist in the restoration and preservation of art. In this paper we propose a semi-supervised crack detection method that can be used for high-dimensional acquisitions of paintings coming from different modalities. Our dataset consists of a recently acquired collection of images of the Ghent Altarpiece (1432), one of Northern Europe's most important art masterpieces. Our goal is to build a classifier that is able to discern crack pixels from the background consisting of non-crack pixels, making optimal use of the information that is provided by each modality. To accomplish this we employ a recently developed non-parametric Bayesian classifier, that uses tensor factorizations to characterize any conditional probability. A prior is placed on the parameters of the factorization such that every possible interaction between predictors is allowed while still identifying a sparse subset among these predictors. The proposed Bayesian classifier, which we will refer to as conditional Bayesian tensor factorization or CBTF, is assessed by visually comparing classification results with the Random Forest (RF) algorithm.\n    ",
        "submission_date": "2013-04-22T00:00:00",
        "last_modified_date": "2013-04-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.6192",
        "title": "A Bag of Visual Words Approach for Symbols-Based Coarse-Grained Ancient Coin Classification",
        "authors": [
            "Hafeez Anwar",
            "Sebastian Zambanini",
            "Martin Kampel"
        ],
        "abstract": "The field of Numismatics provides the names and descriptions of the symbols minted on the ancient coins. Classification of the ancient coins aims at assigning a given coin to its issuer. Various issuers used various symbols for their coins. We propose to use these symbols for a framework that will coarsely classify the ancient coins. Bag of visual words (BoVWs) is a well established visual recognition technique applied to various problems in computer vision like object and scene recognition. Improvements have been made by incorporating the spatial information to this technique. We apply the BoVWs technique to our problem and use three symbols for coarse-grained classification. We use rectangular tiling, log-polar tiling and circular tiling to incorporate spatial information to BoVWs. Experimental results show that the circular tiling proves superior to the rest of the methods for our problem.\n    ",
        "submission_date": "2013-04-23T00:00:00",
        "last_modified_date": "2013-04-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.6213",
        "title": "Counting people from above: Airborne video based crowd analysis",
        "authors": [
            "Roland Perko",
            "Thomas Schnabel",
            "Gerald Fritz",
            "Alexander Almer",
            "Lucas Paletta"
        ],
        "abstract": "Crowd monitoring and analysis in mass events are highly important technologies to support the security of attending persons. Proposed methods based on terrestrial or airborne image/video data often fail in achieving sufficiently accurate results to guarantee a robust service. We present a novel framework for estimating human count, density and motion from video data based on custom tailored object detection techniques, a regression based density estimate and a total variation based optical flow extraction. From the gathered features we present a detailed accuracy analysis versus ground truth measurements. In addition, all information is projected into world coordinates to enable a direct integration with existing geo-information systems. The resulting human counts demonstrate a mean error of 4% to 9% and thus represent a most efficient measure that can be robustly applied in security critical services.\n    ",
        "submission_date": "2013-04-23T00:00:00",
        "last_modified_date": "2013-04-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.6291",
        "title": "Learning Visual Symbols for Parsing Human Poses in Images",
        "authors": [
            "Fang Wang",
            "Yi Li"
        ],
        "abstract": "Parsing human poses in images is fundamental in extracting critical visual information for artificial intelligent agents. Our goal is to learn self-contained body part representations from images, which we call visual symbols, and their symbol-wise geometric contexts in this parsing process. Each symbol is individually learned by categorizing visual features leveraged by geometric information. In the categorization, we use Latent Support Vector Machine followed by an efficient cross validation procedure to learn visual symbols. Then, these symbols naturally define geometric contexts of body parts in a fine granularity. When the structure of the compositional parts is a tree, we derive an efficient approach to estimating human poses in images. Experiments on two large datasets suggest our approach outperforms state of the art methods.\n    ",
        "submission_date": "2013-04-23T00:00:00",
        "last_modified_date": "2013-04-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.6379",
        "title": "Semi-Optimal Edge Detector based on Simple Standard Deviation with Adjusted Thresholding",
        "authors": [
            "Firas A. Jassim"
        ],
        "abstract": "This paper proposes a novel method which combines both median filter and simple standard deviation to accomplish an excellent edge detector for image processing. First of all, a denoising process must be applied on the grey scale image using median filter to identify pixels which are likely to be contaminated by noise. The benefit of this step is to smooth the image and get rid of the noisy pixels. After that, the simple statistical standard deviation could be computed for each 2X2 window size. If the value of the standard deviation inside the 2X2 window size is greater than a predefined threshold, then the upper left pixel in the 2?2 window represents an edge. The visual differences between the proposed edge detector and the standard known edge detectors have been shown to support the contribution in this paper.\n    ",
        "submission_date": "2013-04-23T00:00:00",
        "last_modified_date": "2013-04-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.6759",
        "title": "k-Modulus Method for Image Transformation",
        "authors": [
            "Firas A. Jassim"
        ],
        "abstract": "In this paper, we propose a new algorithm to make a novel spatial image transformation. The proposed approach aims to reduce the bit depth used for image storage. The basic technique for the proposed transformation is based of the modulus operator. The goal is to transform the whole image into multiples of predefined integer. The division of the whole image by that integer will guarantee that the new image surely less in size from the original image. The k-Modulus Method could not be used as a stand alone transform for image compression because of its high compression ratio. It could be used as a scheme embedded in other image processing fields especially compression. According to its high PSNR value, it could be amalgamated with other methods to facilitate the redundancy criterion.\n    ",
        "submission_date": "2013-04-24T00:00:00",
        "last_modified_date": "2013-04-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.6933",
        "title": "Digit Recognition in Handwritten Weather Records",
        "authors": [
            "Manuel Keglevic",
            "Robert Sablatnig"
        ],
        "abstract": "This paper addresses the automatic recognition of handwritten temperature values in weather records. The localization of table cells is based on line detection using projection profiles. Further, a stroke-preserving line removal method which is based on gradient images is proposed. The presented digit recognition utilizes features which are extracted using a set of filters and a Support Vector Machine classifier. It was evaluated on the MNIST and the USPS dataset and our own database with about 17,000 RGB digit images. An accuracy of 99.36% per digit is achieved for the entire system using a set of 84 weather records.\n    ",
        "submission_date": "2013-04-25T00:00:00",
        "last_modified_date": "2013-04-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.6990",
        "title": "Euclidean Upgrade from a Minimal Number of Segments",
        "authors": [
            "Tanja Schilling",
            "Tomas Pajdla"
        ],
        "abstract": "In this paper, we propose an algebraic approach to upgrade a projective reconstruction to a Euclidean one, and aim at computing the rectifying homography from a minimal number of 9 segments of known length. Constraints are derived from these segments which yield a set of polynomial equations that we solve by means of Gr\u00f6bner bases. We explain how a solver for such a system of equations can be constructed from simplified template data. Moreover, we present experiments that demonstrate that the given problem can be solved in this way.\n    ",
        "submission_date": "2013-04-25T00:00:00",
        "last_modified_date": "2013-04-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.7132",
        "title": "Filament and Flare Detection in H\u03b1 image sequences",
        "authors": [
            "Gernot Riegler",
            "Thomas Pock",
            "Werner P\u00f6tzi",
            "Astrid Veronig"
        ],
        "abstract": "Solar storms can have a major impact on the infrastructure of the earth. Some of the causing events are observable from ground in the H{\\alpha} spectral line. In this paper we propose a new method for the simultaneous detection of flares and filaments in H{\\alpha} image sequences. Therefore we perform several preprocessing steps to enhance and normalize the images. Based on the intensity values we segment the image by a variational approach. In a final postprecessing step we derive essential properties to classify the events and further demonstrate the performance by comparing our obtained results to the data annotated by an expert. The information produced by our method can be used for near real-time alerts and the statistical analysis of existing data by solar physicists.\n    ",
        "submission_date": "2013-04-26T00:00:00",
        "last_modified_date": "2013-04-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.7140",
        "title": "Pulmonary Vascular Tree Segmentation from Contrast-Enhanced CT Images",
        "authors": [
            "M. Helmberger",
            "M. Urschler",
            "M. Pienn",
            "Z.Balint",
            "A. Olschewski",
            "H. Bischof"
        ],
        "abstract": "We present a pulmonary vessel segmentation algorithm, which is fast, fully automatic and robust. It uses a coarse segmentation of the airway tree and a left and right lung labeled volume to restrict a vessel enhancement filter, based on an offset medialness function, to the lungs. We show the application of our algorithm on contrast-enhanced CT images, where we derive a clinical parameter to detect pulmonary hypertension (PH) in patients. Results on a dataset of 24 patients show that quantitative indices derived from the segmentation are applicable to distinguish patients with and without PH. Further work-in-progress results are shown on the VESSEL12 challenge dataset, which is composed of non-contrast-enhanced scans, where we range in the midfield of participating contestants.\n    ",
        "submission_date": "2013-04-26T00:00:00",
        "last_modified_date": "2013-04-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.7153",
        "title": "A Convex Approach for Image Hallucination",
        "authors": [
            "Peter Innerhofer",
            "Thomas Pock"
        ],
        "abstract": "In this paper we propose a global convex approach for image hallucination. Altering the idea of classical multi image super resolution (SU) systems to single image SU, we incorporate aligned images to hallucinate the output. Our work is based on the paper of Tappen et al. where they use a non-convex model for image hallucination. In comparison we formulate a convex primal optimization problem and derive a fast converging primal-dual algorithm with a global optimal solution. We use a database with face images to incorporate high-frequency details to the high-resolution output. We show that we can achieve state-of-the-art results by using a convex approach.\n    ",
        "submission_date": "2013-04-26T00:00:00",
        "last_modified_date": "2013-04-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.7184",
        "title": "Reading Ancient Coin Legends: Object Recognition vs. OCR",
        "authors": [
            "Albert Kavelar",
            "Sebastian Zambanini",
            "Martin Kampel"
        ],
        "abstract": "Standard OCR is a well-researched topic of computer vision and can be considered solved for machine-printed text. However, when applied to unconstrained images, the recognition rates drop drastically. Therefore, the employment of object recognition-based techniques has become state of the art in scene text recognition applications. This paper presents a scene text recognition method tailored to ancient coin legends and compares the results achieved in character and word recognition experiments to a standard OCR engine. The conducted experiments show that the proposed method outperforms the standard OCR engine on a set of 180 cropped coin legend words.\n    ",
        "submission_date": "2013-04-26T00:00:00",
        "last_modified_date": "2013-04-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.7211",
        "title": "Algorithmic Optimisations for Iterative Deconvolution Methods",
        "authors": [
            "Martin Welk",
            "Martin Erler"
        ],
        "abstract": "We investigate possibilities to speed up iterative algorithms for non-blind image deconvolution. We focus on algorithms in which convolution with the point-spread function to be deconvolved is used in each iteration, and aim at accelerating these convolution operations as they are typically the most expensive part of the computation. We follow two approaches: First, for some practically important specific point-spread functions, algorithmically efficient sliding window or list processing techniques can be used. In some constellations this allows faster computation than via the Fourier domain. Second, as iterations progress, computation of convolutions can be restricted to subsets of pixels. For moderate thinning rates this can be done with almost no impact on the reconstruction quality. Both approaches are demonstrated in the context of Richardson-Lucy deconvolution but are not restricted to this method.\n    ",
        "submission_date": "2013-04-26T00:00:00",
        "last_modified_date": "2013-04-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.7236",
        "title": "In the sight of my wearable camera: Classifying my visual experience",
        "authors": [
            "Alessandro Perina",
            "Nebojsa Jojic"
        ],
        "abstract": "We introduce and we analyze a new dataset which resembles the input to biological vision systems much more than most previously published ones. Our analysis leaded to several important conclusions. First, it is possible to disambiguate over dozens of visual scenes (locations) encountered over the course of several weeks of a human life with accuracy of over 80%, and this opens up possibility for numerous novel vision applications, from early detection of dementia to everyday use of wearable camera streams for automatic reminders, and visual stream exchange. Second, our experimental results indicate that, generative models such as Latent Dirichlet Allocation or Counting Grids, are more suitable to such types of data, as they are more robust to overtraining and comfortable with images at low resolution, blurred and characterized by relatively random clutter and a mix of objects.\n    ",
        "submission_date": "2013-04-26T00:00:00",
        "last_modified_date": "2013-04-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.7399",
        "title": "Bingham Procrustean Alignment for Object Detection in Clutter",
        "authors": [
            "Jared Glover",
            "Sanja Popovic"
        ],
        "abstract": "A new system for object detection in cluttered RGB-D images is presented. Our main contribution is a new method called Bingham Procrustean Alignment (BPA) to align models with the scene. BPA uses point correspondences between oriented features to derive a probability distribution over possible model poses. The orientation component of this distribution, conditioned on the position, is shown to be a Bingham distribution. This result also applies to the classic problem of least-squares alignment of point sets, when point features are orientation-less, and gives a principled, probabilistic way to measure pose uncertainty in the rigid alignment problem. Our detection system leverages BPA to achieve more reliable object detections in clutter.\n    ",
        "submission_date": "2013-04-27T00:00:00",
        "last_modified_date": "2013-04-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.7713",
        "title": "Markovian models for one dimensional structure estimation on heavily noisy imagery",
        "authors": [
            "Ana Georgina Flesia",
            "Javier Gimenez",
            "Elena Rufeil Fiori"
        ],
        "abstract": "Radar (SAR) images often exhibit profound appearance variations due to a variety of factors including clutter noise produced by the coherent nature of the illumination. Ultrasound images and infrared images have similar cluttered appearance, that make 1 dimensional structures, as edges and object boundaries difficult to locate. Structure information is usually extracted in two steps: first, building and edge strength mask classifying pixels as edge points by hypothesis testing, and secondly estimating from that mask, pixel wide connected edges. With constant false alarm rate (CFAR) edge strength detectors for speckle clutter, the image needs to be scanned by a sliding window composed of several differently oriented splitting sub-windows. The accuracy of edge location for these ratio detectors depends strongly on the orientation of the sub-windows. In this work we propose to transform the edge strength detection problem into a binary segmentation problem in the undecimated wavelet domain, solvable using parallel 1d Hidden Markov Models. For general dependency models, exact estimation of the state map becomes computationally complex, but in our model, exact MAP is feasible. The effectiveness of our approach is demonstrated on simulated noisy real-life natural images with available ground truth, while the strength of our output edge map is measured with Pratt's, Baddeley an Kappa proficiency measures. Finally, analysis and experiments on three different types of SAR images, with different polarizations, resolutions and textures, illustrate that the proposed method can detect structure on SAR images effectively, providing a very good start point for active contour methods.\n    ",
        "submission_date": "2013-04-29T00:00:00",
        "last_modified_date": "2013-04-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.7948",
        "title": "Convolutional Neural Networks learn compact local image descriptors",
        "authors": [
            "Christian Osendorfer",
            "Justin Bayer",
            "Patrick van der Smagt"
        ],
        "abstract": "A standard deep convolutional neural network paired with a suitable loss function learns compact local image descriptors that perform comparably to state-of-the art approaches.\n    ",
        "submission_date": "2013-04-30T00:00:00",
        "last_modified_date": "2013-06-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.8052",
        "title": "Registration of Images with Outliers Using Joint Saliency Map",
        "authors": [
            "Binjie Qin",
            "Zhijun Gu",
            "Xianjun Sun",
            "Yisong Lv"
        ],
        "abstract": "Mutual information (MI) is a popular similarity measure for image registration, whereby good registration can be achieved by maximizing the compactness of the clusters in the joint histogram. However, MI is sensitive to the \"outlier\" objects that appear in one image but not the other, and also suffers from local and biased maxima. We propose a novel joint saliency map (JSM) to highlight the corresponding salient structures in the two images, and emphatically group those salient structures into the smoothed compact clusters in the weighted joint histogram. This strategy could solve both the outlier and the local maxima problems. Experimental results show that the JSM-MI based algorithm is not only accurate but also robust for registration of challenging image pairs with outliers.\n    ",
        "submission_date": "2013-03-29T00:00:00",
        "last_modified_date": "2013-03-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.8092",
        "title": "Fractal-Based Detection of Microcalcification Clusters in Digital Mammograms",
        "authors": [
            "P.Shanmugavadivu",
            "V.Sivakumar"
        ],
        "abstract": "In this paper, a novel method for edge detection of microcalcification clusters in mammogram images is presented using the concept of Fractal Dimension and Hurst co-efficient that enables to locate the microcalcifications in the mammograms. This technique detects the edges accurately than the ones obtained by the conventional Sobel method. Generally, Sobel method detects the edges of the regions/objects in an image using the Fudge factor that assumes its value as 0.5, by default. In this proposed technique, the Fudge factor is suitably replaced with Hurst Co-efficient, which is computed as the difference of Fractal dimension and the topological dimension of a given input image. These two dimensions are image-dependent, and hence the respective Hurst co-efficient too varies with respect to images. Hence, the image-dependent Hurst co-efficient based Sobel method is proved to produce better results than the Fudge factor based Sobel method. The results of the proposed method substantiate the merit of the proposed technique.\n    ",
        "submission_date": "2013-04-30T00:00:00",
        "last_modified_date": "2013-04-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1305.0020",
        "title": "Image Compression By Embedding Five Modulus Method Into JPEG",
        "authors": [
            "Firas A. Jassim"
        ],
        "abstract": "The standard JPEG format is almost the optimum format in image compression. The compression ratio in JPEG sometimes reaches 30:1. The compression ratio of JPEG could be increased by embedding the Five Modulus Method (FMM) into the JPEG algorithm. The novel algorithm gives twice the time as the standard JPEG algorithm or more. The novel algorithm was called FJPEG (Five-JPEG). The quality of the reconstructed image after compression is approximately approaches the JPEG. Standard test images have been used to support and implement the suggested idea in this paper and the error metrics have been computed and compared with JPEG.\n    ",
        "submission_date": "2013-04-30T00:00:00",
        "last_modified_date": "2013-04-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1305.0218",
        "title": "Video Segmentation via Diffusion Bases",
        "authors": [
            "Dina Dushnik",
            "Alon Schclar",
            "Amir Averbuch"
        ],
        "abstract": "Identifying moving objects in a video sequence, which is produced by a static camera, is a fundamental and critical task in many computer-vision applications. A common approach performs background subtraction, which identifies moving objects as the portion of a video frame that differs significantly from a background model. A good background subtraction algorithm has to be robust to changes in the illumination and it should avoid detecting non-stationary background objects such as moving leaves, rain, snow, and shadows. In addition, the internal background model should quickly respond to changes in background such as objects that start to move or stop. We present a new algorithm for video segmentation that processes the input video sequence as a 3D matrix where the third axis is the time domain. Our approach identifies the background by reducing the input dimension using the \\emph{diffusion bases} methodology. Furthermore, we describe an iterative method for extracting and deleting the background. The algorithm has two versions and thus covers the complete range of backgrounds: one for scenes with static backgrounds and the other for scenes with dynamic (moving) backgrounds.\n    ",
        "submission_date": "2013-05-01T00:00:00",
        "last_modified_date": "2013-05-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1305.0311",
        "title": "An Adaptive Descriptor Design for Object Recognition in the Wild",
        "authors": [
            "Zhenyu Guo",
            "Z.Jane Wang"
        ],
        "abstract": "Digital images nowadays have various styles of appearance, in the aspects of color tones, contrast, vignetting, and etc. These 'picture styles' are directly related to the scene radiance, image pipeline of the camera, and post processing functions. Due to the complexity and nonlinearity of these causes, popular gradient-based image descriptors won't be invariant to different picture styles, which will decline the performance of object recognition. Given that images shared online or created by individual users are taken with a wide range of devices and may be processed by various post processing functions, to find a robust object recognition system is useful and challenging. In this paper, we present the first study on the influence of picture styles for object recognition, and propose an adaptive approach based on the kernel view of gradient descriptors and multiple kernel learning, without estimating or specifying the styles of images used in training and testing. We conduct experiments on Domain Adaptation data set and Oxford Flower data set. The experiments also include several variants of the flower data set by processing the images with popular photo effects. The results demonstrate that our proposed method improve from standard descriptors in all cases.\n    ",
        "submission_date": "2013-05-01T00:00:00",
        "last_modified_date": "2013-05-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1305.0871",
        "title": "Dictionary learning based image enhancement for rarity detection",
        "authors": [
            "Hui Li",
            "Xiaomeng Wang",
            "Weifeng Liu",
            "Yanjiang Wang"
        ],
        "abstract": "Image enhancement is an important image processing technique that processes images suitably for a specific application e.g. image editing. The conventional solutions of image enhancement are grouped into two categories which are spatial domain processing method and transform domain processing method such as contrast manipulation, histogram equalization, homomorphic filtering. This paper proposes a new image enhance method based on dictionary learning. Particularly, the proposed method adjusts the image by manipulating the rarity of dictionary atoms. Firstly, learn the dictionary through sparse coding algorithms on divided sub-image blocks. Secondly, compute the rarity of dictionary atoms on statistics of the corresponding sparse coefficients. Thirdly, adjust the rarity according to specific application and form a new dictionary. Finally, reconstruct the image using the updated dictionary and sparse coefficients. Compared with the traditional techniques, the proposed method enhances image based on the image content not on distribution of pixel grey value or frequency. The advantages of the proposed method lie in that it is in better correspondence with the response of the human visual system and more suitable for salient objects extraction. The experimental results demonstrate the effectiveness of the proposed image enhance method.\n    ",
        "submission_date": "2013-05-04T00:00:00",
        "last_modified_date": "2016-09-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1305.1052",
        "title": "Hybridization of Otsu Method and Median Filter for Color Image Segmentation",
        "authors": [
            "Firas Ajil Jassim",
            "Fawzi H. Altaani"
        ],
        "abstract": "In this article a novel algorithm for color image segmentation has been developed. The proposed algorithm based on combining two existing methods in such a novel way to obtain a significant method to partition the color image into significant regions. On the first phase, the traditional Otsu method for gray channel image segmentation were applied for each of the R,G, and B channels separately to determine the suitable automatic threshold for each channel. After that, the new modified channels are integrated again to formulate a new color image. The resulted image suffers from some kind of distortion. To get rid of this distortion, the second phase is arise which is the median filter to smooth the image and increase the segmented regions. This process looks very significant by the ocular eye. Experimental results were presented on a variety of test images to support the proposed algorithm.\n    ",
        "submission_date": "2013-05-05T00:00:00",
        "last_modified_date": "2013-05-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1305.1163",
        "title": "A Computer Vision System for Attention Mapping in SLAM based 3D Models",
        "authors": [
            "Lucas Paletta",
            "Katrin Santner",
            "Gerald Fritz",
            "Albert Hofmann",
            "Gerald Lodron",
            "Georg Thallinger",
            "Heinz Mayer"
        ],
        "abstract": "The study of human factors in the frame of interaction studies has been relevant for usability engi-neering and ergonomics for decades. Today, with the advent of wearable eye-tracking and Google glasses, monitoring of human factors will soon become ubiquitous. This work describes a computer vision system that enables pervasive mapping and monitoring of human attention. The key contribu-tion is that our methodology enables full 3D recovery of the gaze pointer, human view frustum and associated human centred measurements directly into an automatically computed 3D model in real-time. We apply RGB-D SLAM and descriptor matching methodologies for the 3D modelling, locali-zation and fully automated annotation of ROIs (regions of interest) within the acquired 3D model. This innovative methodology will open new avenues for attention studies in real world environments, bringing new potential into automated processing for human factors technologies.\n    ",
        "submission_date": "2013-05-06T00:00:00",
        "last_modified_date": "2013-05-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1305.1199",
        "title": "How to find real-world applications for compressive sensing",
        "authors": [
            "Leslie N. Smith"
        ],
        "abstract": "The potential of compressive sensing (CS) has spurred great interest in the research community and is a fast growing area of research. However, research translating CS theory into practical hardware and demonstrating clear and significant benefits with this hardware over current, conventional imaging techniques has been limited. This article helps researchers to find those niche applications where the CS approach provides substantial gain over conventional approaches by articulating lessons learned in finding one such application; sea skimming missile detection. As a proof of concept, it is demonstrated that a simplified CS missile detection architecture and algorithm provides comparable results to the conventional imaging approach but using a smaller FPA. The primary message is that all of the excitement surrounding CS is necessary and appropriate for encouraging our creativity but we all must also take off our \"rose colored glasses\" and critically judge our ideas, methods and results relative to conventional imaging approaches.\n    ",
        "submission_date": "2013-05-06T00:00:00",
        "last_modified_date": "2013-06-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1305.1206",
        "title": "A Contrario Selection of Optimal Partitions for Image Segmentation",
        "authors": [
            "Juan Cardelino",
            "Vicent Caselles",
            "Marcelo Bertalmio",
            "Gregory Randall"
        ],
        "abstract": "We present a novel segmentation algorithm based on a hierarchical representation of images. The main contribution of this work is to explore the capabilities of the A Contrario reasoning when applied to the segmentation problem, and to overcome the limitations of current algorithms within that framework. This exploratory approach has three main goals.\n",
        "submission_date": "2013-05-06T00:00:00",
        "last_modified_date": "2013-05-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1305.1344",
        "title": "Speckle Noise Reduction in Medical Ultrasound Images",
        "authors": [
            "Faouzi Benzarti",
            "Hamid Amiri"
        ],
        "abstract": "Ultrasound imaging is an incontestable vital tool for diagnosis, it provides in non-invasive manner the internal structure of the body to detect eventually diseases or abnormalities tissues. Unfortunately, the presence of speckle noise in these images affects edges and fine details which limit the contrast resolution and make diagnostic more difficult. In this paper, we propose a denoising approach which combines logarithmic transformation and a non linear diffusion tensor. Since speckle noise is multiplicative and nonwhite process, the logarithmic transformation is a reasonable choice to convert signaldependent or pure multiplicative noise to an additive one. The key idea from using diffusion tensor is to adapt the flow diffusion towards the local orientation by applying anisotropic diffusion along the coherent structure direction of interesting features in the image. To illustrate the effective performance of our algorithm, we present some experimental results on synthetically and real echographic images.\n    ",
        "submission_date": "2013-05-06T00:00:00",
        "last_modified_date": "2013-05-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1305.1396",
        "title": "A new framework for optimal classifier design",
        "authors": [
            "Mat\u00edas Di Martino",
            "Guzman Hern\u00e1ndez",
            "Marcelo Fiori",
            "Alicia Fern\u00e1ndez"
        ],
        "abstract": "The use of alternative measures to evaluate classifier performance is gaining attention, specially for imbalanced problems. However, the use of these measures in the classifier design process is still unsolved. In this work we propose a classifier designed specifically to optimize one of these alternative measures, namely, the so-called F-measure. Nevertheless, the technique is general, and it can be used to optimize other evaluation measures. An algorithm to train the novel classifier is proposed, and the numerical scheme is tested with several databases, showing the optimality and robustness of the presented classifier.\n    ",
        "submission_date": "2013-05-07T00:00:00",
        "last_modified_date": "2013-09-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1305.1443",
        "title": "Standard Fingerprint Databases: Manual Minutiae Labeling and Matcher Performance Analyses",
        "authors": [
            "Mehmet Kayaoglu",
            "Berkay Topcu",
            "Umut Uludag"
        ],
        "abstract": "Fingerprint verification and identification algorithms based on minutiae features are used in many biometric systems today (e.g., governmental e-ID programs, border control, AFIS, personal authentication for portable devices). Researchers in industry/academia are now able to utilize many publicly available fingerprint databases (e.g., Fingerprint Verification Competition (FVC) & NIST databases) to compare/evaluate their feature extraction and/or matching algorithm performances against those of others. The results from these evaluations are typically utilized by decision makers responsible for implementing the cited biometric systems, in selecting/tuning specific sensors, feature extractors and matchers. In this study, for a subset of the cited public fingerprint databases, we report fingerprint minutiae matching results, which are based on (i) minutiae extracted automatically from fingerprint images, and (ii) minutiae extracted manually by human subjects. By doing so, we are able to (i) quantitatively judge the performance differences between these two cases, (ii) elaborate on performance upper bounds of minutiae matching, utilizing what can be termed as \"ground truth\" minutiae features, (iii) analyze minutiae matching performance, without coupling it with the minutiae extraction performance beforehand. Further, as we will freely distribute the minutiae templates, originating from this manual labeling study, in a standard minutiae template exchange format (ISO 19794-2), we believe that other researchers in the biometrics community will be able to utilize the associated results & templates to create their own evaluations pertaining to their fingerprint minutiae extractors/matchers.\n    ",
        "submission_date": "2013-05-07T00:00:00",
        "last_modified_date": "2013-05-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1305.1520",
        "title": "A Method for Visuo-Spatial Classification of Freehand Shapes Freely Sketched",
        "authors": [
            "Ney Renau-Ferrer",
            "C\u00e9line Remi"
        ],
        "abstract": "We present the principle and the main steps of a new method for the visuo-spatial analysis of geometrical sketches recorded online. Visuo-spatial analysis is a necessary step for multi-level analysis. Multi-level analysis simultaneously allows classification, comparison or clustering of the constituent parts of a pattern according to their visuo-spatial properties, their procedural strategies, their structural or temporal parameters, or any combination of two or more of those parameters. The first results provided by this method concern the comparison of sketches to some perfect patterns of simple geometrical figures and the measure of dissimilarity between real sketches. The mean rates of good decision higher than 95% obtained are promising in both cases.\n    ",
        "submission_date": "2013-05-07T00:00:00",
        "last_modified_date": "2013-05-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1305.1912",
        "title": "Automated polyp detection in colon capsule endoscopy",
        "authors": [
            "Alexander V. Mamonov",
            "Isabel N. Figueiredo",
            "Pedro N. Figueiredo",
            "Yen-Hsi Richard Tsai"
        ],
        "abstract": "Colorectal polyps are important precursors to colon cancer, a major health problem. Colon capsule endoscopy (CCE) is a safe and minimally invasive examination procedure, in which the images of the intestine are obtained via digital cameras on board of a small capsule ingested by a patient. The video sequence is then analyzed for the presence of polyps. We propose an algorithm that relieves the labor of a human operator analyzing the frames in the video sequence. The algorithm acts as a binary classifier, which labels the frame as either containing polyps or not, based on the geometrical analysis and the texture content of the frame. The geometrical analysis is based on a segmentation of an image with the help of a mid-pass filter. The features extracted by the segmentation procedure are classified according to an assumption that the polyps are characterized as protrusions that are mostly round in shape. Thus, we use a best fit ball radius as a decision parameter of a binary classifier. We present a statistical study of the performance of our approach on a data set containing over 18,900 frames from the endoscopic video sequences of five adult patients. The algorithm demonstrates a solid performance, achieving 47% sensitivity per frame and over 81% sensitivity per polyp at a specificity level of 90%. On average, with a video sequence length of 3747 frames, only 367 false positive frames need to be inspected by a human operator.\n    ",
        "submission_date": "2013-05-08T00:00:00",
        "last_modified_date": "2014-03-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1305.2221",
        "title": "Repairing and Inpainting Damaged Images using Diffusion Tensor",
        "authors": [
            "Faouzi Benzarti",
            "Hamid Amiri"
        ],
        "abstract": "Removing or repairing the imperfections of a digital images or videos is a very active and attractive field of research belonging to the image inpainting technique. This later has a wide range of applications, such as removing scratches in old photographic image, removing text and logos or creating cartoon and artistic effects. In this paper, we propose an efficient method to repair a damaged image based on a non linear diffusion tensor. The idea is to track perfectly the local geometry of the damaged image and allowing diffusion only in the isophotes curves direction. To illustrate the effective performance of our method, we present some experimental results on test and real photographic color images\n    ",
        "submission_date": "2013-05-09T00:00:00",
        "last_modified_date": "2013-05-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1305.2269",
        "title": "Beyond Physical Connections: Tree Models in Human Pose Estimation",
        "authors": [
            "Fang Wang",
            "Yi Li"
        ],
        "abstract": "Simple tree models for articulated objects prevails in the last decade. However, it is also believed that these simple tree models are not capable of capturing large variations in many scenarios, such as human pose estimation. This paper attempts to address three questions: 1) are simple tree models sufficient? more specifically, 2) how to use tree models effectively in human pose estimation? and 3) how shall we use combined parts together with single parts efficiently?\n",
        "submission_date": "2013-05-10T00:00:00",
        "last_modified_date": "2013-05-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1305.2362",
        "title": "Revisiting Bayesian Blind Deconvolution",
        "authors": [
            "David Wipf",
            "Haichao Zhang"
        ],
        "abstract": "Blind deconvolution involves the estimation of a sharp signal or image given only a blurry observation. Because this problem is fundamentally ill-posed, strong priors on both the sharp image and blur kernel are required to regularize the solution space. While this naturally leads to a standard MAP estimation framework, performance is compromised by unknown trade-off parameter settings, optimization heuristics, and convergence issues stemming from non-convexity and/or poor prior selections. To mitigate some of these problems, a number of authors have recently proposed substituting a variational Bayesian (VB) strategy that marginalizes over the high-dimensional image space leading to better estimates of the blur kernel. However, the underlying cost function now involves both integrals with no closed-form solution and complex, function-valued arguments, thus losing the transparency of MAP. Beyond standard Bayesian-inspired intuitions, it thus remains unclear by exactly what mechanism these methods are able to operate, rendering understanding, improvements and extensions more difficult. To elucidate these issues, we demonstrate that the VB methodology can be recast as an unconventional MAP problem with a very particular penalty/prior that couples the image, blur kernel, and noise level in a principled way. This unique penalty has a number of useful characteristics pertaining to relative concavity, local minima avoidance, and scale-invariance that allow us to rigorously explain the success of VB including its existing implementational heuristics and approximations. It also provides strict criteria for choosing the optimal image prior that, perhaps counter-intuitively, need not reflect the statistics of natural scenes. In so doing we challenge the prevailing notion of why VB is successful for blind deconvolution while providing a transparent platform for introducing enhancements.\n    ",
        "submission_date": "2013-05-10T00:00:00",
        "last_modified_date": "2013-05-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1305.2395",
        "title": "Shape Reconstruction and Recognition with Isolated Non-directional Cues",
        "authors": [
            "Toshiro Kubota",
            "Jessica Ranck",
            "Briley Acker",
            "Herman De Haan"
        ],
        "abstract": "The paper investigates a hypothesis that our visual system groups visual cues based on how they form a surface, or more specifically triangulation derived from the visual cues. To test our hypothesis, we compare shape recognition with three different representations of visual cues: a set of isolated dots delineating the outline of the shape, a set of triangles obtained from Delaunay triangulation of the set of dots, and a subset of Delaunay triangles excluding those outside of the shape. Each participant was assigned to one particular representation type and increased the number of dots (and consequentially triangles) until the underlying shape could be identified. We compare the average number of dots needed for identification among three types of representations. Our hypothesis predicts that the results from the three representations will be similar. However, they show statistically significant differences. The paper also presents triangulation based algorithms for reconstruction and recognition of a shape from a set of isolated dots. Experiments showed that the algorithms were more effective and perceptually agreeable than similar contour based ones. From these experiments, we conclude that triangulation does affect our shape recognition. However, the surface based approach presents a number of computational advantages over the contour based one and should be studied further.\n    ",
        "submission_date": "2013-05-10T00:00:00",
        "last_modified_date": "2013-05-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1305.2687",
        "title": "Automatic Parameter Adaptation for Multi-object Tracking",
        "authors": [
            "Duc Phu Chau",
            "Monique Thonnat",
            "Fran\u00e7ois Bremond"
        ],
        "abstract": "Object tracking quality usually depends on video context (e.g. object occlusion level, object density). In order to decrease this dependency, this paper presents a learning approach to adapt the tracker parameters to the context variations. In an offline phase, satisfactory tracking parameters are learned for video context clusters. In the online control phase, once a context change is detected, the tracking parameters are tuned using the learned values. The experimental results show that the proposed approach outperforms the recent trackers in state of the art. This paper brings two contributions: (1) a classification method of video sequences to learn offline tracking parameters, (2) a new method to tune online tracking parameters using tracking context.\n    ",
        "submission_date": "2013-05-13T00:00:00",
        "last_modified_date": "2013-05-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1305.2713",
        "title": "Early Detection of Alzheimer's - A Crucial Requirement",
        "authors": [
            "Ijaz Bukhari"
        ],
        "abstract": "Alzheimer's, an old age disease of people over 65 years causes problems with memory, thinking and behavior. This disease progresses very slow and its identification in early stages is very difficult. The symptoms of Alzheimer's appear slowly and gradually will have worse effects. In its early stages, not only the patients themselves but their loved ones are generally unable to accept that the patient is suffering from disease. In this paper, we have proposed a new algorithm to detect patients of Alzheimer's at early stages by comparing the Magnetic Resonance Images (MRI) of the patients with normal persons of their age. The progress of the disease can also be monitored by periodic comparison of the previous and current MRI.\n    ",
        "submission_date": "2013-05-13T00:00:00",
        "last_modified_date": "2013-05-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1305.2827",
        "title": "Human Mood Detection For Human Computer Interaction",
        "authors": [
            "Preeti Badar",
            "Urmila Shrawankar"
        ],
        "abstract": "In this paper we propose an easiest approach for facial expression recognition. Here we are using concept of SVM for Expression Classification. Main problem is sub divided in three main modules. First one is Face detection in which we are using skin filter and Face segmentation. We are given more stress on feature Extraction. This method is effective enough for application where fast execution is required. Second, Facial Feature Extraction which is essential part for expression recognition. In this module we used Edge Projection Analysis. Finally extracted features vector is passed towards SVM classifier for Expression Recognition. We are considering six basic Expressions (Anger, Fear, Disgust, Joy, Sadness, and Surprise)\n    ",
        "submission_date": "2013-05-10T00:00:00",
        "last_modified_date": "2013-05-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1305.2828",
        "title": "Image Optimization and Prediction",
        "authors": [
            "Shweta Jain",
            "Urmila Shrawankar"
        ],
        "abstract": "Image Processing, Optimization and Prediction of an Image play a key role in Computer Science. Image processing provides a way to analyze and identify an image .Many areas like medical image processing, Satellite images, natural images and artificial images requires lots of analysis and research on optimization. In Image Optimization and Prediction we are combining the features of Query Optimization, Image Processing and Prediction . Image optimization is used in Pattern analysis, object recognition, in medical Image processing to predict the type of diseases, in satellite images for predicting weather forecast, availability of water or mineral etc. Image Processing, Optimization and analysis is a wide open area for research .Lots of research has been conducted in the area of Image analysis and many techniques are available for image analysis but, a single technique is not yet identified for image analysis and prediction .our research is focused on identifying a global technique for image analysis and Prediction.\n    ",
        "submission_date": "2013-05-10T00:00:00",
        "last_modified_date": "2013-05-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1305.2949",
        "title": "Unsupervised ensemble of experts (EoE) framework for automatic binarization of document images",
        "authors": [
            "Reza Farrahi Moghaddam",
            "Fereydoun Farrahi Moghaddam",
            "Mohamed Cheriet"
        ],
        "abstract": "In recent years, a large number of binarization methods have been developed, with varying performance generalization and strength against different benchmarks. In this work, to leverage on these methods, an ensemble of experts (EoE) framework is introduced, to efficiently combine the outputs of various methods. The proposed framework offers a new selection process of the binarization methods, which are actually the experts in the ensemble, by introducing three concepts: confidentness, endorsement and schools of experts. The framework, which is highly objective, is built based on two general principles: (i) consolidation of saturated opinions and (ii) identification of schools of experts. After building the endorsement graph of the ensemble for an input document image based on the confidentness of the experts, the saturated opinions are consolidated, and then the schools of experts are identified by thresholding the consolidated endorsement graph. A variation of the framework, in which no selection is made, is also introduced that combines the outputs of all experts using endorsement-dependent weights. The EoE framework is evaluated on the set of participating methods in the H-DIBCO'12 contest and also on an ensemble generated from various instances of grid-based Sauvola method with promising performance.\n    ",
        "submission_date": "2013-05-13T00:00:00",
        "last_modified_date": "2013-05-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1305.3006",
        "title": "Fast Linearized Alternating Direction Minimization Algorithm with Adaptive Parameter Selection for Multiplicative Noise Removal",
        "authors": [
            "Dai-Qiang Chen",
            "Li-Zhi Cheng"
        ],
        "abstract": "Owing to the edge preserving ability and low computational cost of the total variation (TV), variational models with the TV regularization have been widely investigated in the field of multiplicative noise removal. The key points of the successful application of these models lie in: the optimal selection of the regularization parameter which balances the data-fidelity term with the TV regularizer; the efficient algorithm to compute the solution. In this paper, we propose two fast algorithms based on the linearized technique, which are able to estimate the regularization parameter and recover the image simultaneously. In the iteration step of the proposed algorithms, the regularization parameter is adjusted by a special discrepancy function defined for multiplicative noise. The convergence properties of the proposed algorithms are proved under certain conditions, and numerical experiments demonstrate that the proposed algorithms overall outperform some state-of-the-art methods in the PSNR values and computational time.\n    ",
        "submission_date": "2013-05-14T00:00:00",
        "last_modified_date": "2013-05-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1305.3013",
        "title": "Novel variational model for inpainting in the wavelet domain",
        "authors": [
            "Dai-Qiang Chen",
            "Li-Zhi Cheng"
        ],
        "abstract": "Wavelet domain inpainting refers to the process of recovering the missing coefficients during the image compression or transmission stage. Recently, an efficient algorithm framework which is called Bregmanized operator splitting (BOS) was proposed for solving the classical variational model of wavelet inpainting. However, it is still time-consuming to some extent due to the inner iteration. In this paper, a novel variational model is established to formulate this reconstruction problem from the view of image decomposition. Then an efficient iterative algorithm based on the split-Bregman method is adopted to calculate an optimal solution, and it is also proved to be convergent. Compared with the BOS algorithm the proposed algorithm avoids the inner iteration and hence is more simple. Numerical experiments demonstrate that the proposed method is very efficient and outperforms the current state-of-the-art methods, especially in the computational time.\n    ",
        "submission_date": "2013-05-14T00:00:00",
        "last_modified_date": "2013-05-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1305.3189",
        "title": "A Bag of Words Approach for Semantic Segmentation of Monitored Scenes",
        "authors": [
            "Wassim Bouachir",
            "Atousa Torabi",
            "Guillaume-Alexandre Bilodeau",
            "Pascal Blais"
        ],
        "abstract": "This paper proposes a semantic segmentation method for outdoor scenes captured by a surveillance camera. Our algorithm classifies each perceptually homogenous region as one of the predefined classes learned from a collection of manually labelled images. The proposed approach combines two different types of information. First, color segmentation is performed to divide the scene into perceptually similar regions. Then, the second step is based on SIFT keypoints and uses the bag of words representation of the regions for the classification. The prediction is done using a Na\u00efve Bayesian Network as a generative classifier. Compared to existing techniques, our method provides more compact representations of scene contents and the segmentation result is more consistent with human perception due to the combination of the color information with the image keypoints. The experiments conducted on a publicly available data set demonstrate the validity of the proposed method.\n    ",
        "submission_date": "2013-05-14T00:00:00",
        "last_modified_date": "2013-05-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1305.3250",
        "title": "Bioacoustical Periodic Pulse Train Signal Detection and Classification using Spectrogram Intensity Binarization and Energy Projection",
        "authors": [
            "Marian Popescu",
            "Peter J. Dugan",
            "Mohammad Pourhomayoun",
            "Denise Risch",
            "Harold W. Lewis III",
            "Christopher W. Clark"
        ],
        "abstract": "The following work outlines an approach for automatic detection and recognition of periodic pulse train signals using a multi-stage process based on spectrogram edge detection, energy projection and classification. The method has been implemented to automatically detect and recognize pulse train songs of minke whales. While the long term goal of this work is to properly identify and detect minke songs from large multi-year datasets, this effort was developed using sounds off the coast of Massachusetts, in the Stellwagen Bank National Marine Sanctuary. The detection methodology is presented and evaluated on 232 continuous hours of acoustic recordings and a qualitative analysis of machine learning classifiers and their performance is described. The trained automatic detection and classification system is applied to 120 continuous hours, comprised of various challenges such as broadband and narrowband noises, low SNR, and other pulse train signatures. This automatic system achieves a TPR of 63% for FPR of 0.6% (or 0.87 FP/h), at a Precision (PPV) of 84% and an F1 score of 71%.\n    ",
        "submission_date": "2013-05-14T00:00:00",
        "last_modified_date": "2013-06-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1305.3633",
        "title": "Classification for Big Dataset of Bioacoustic Signals Based on Human Scoring System and Artificial Neural Network",
        "authors": [
            "Mohammad Pourhomayoun",
            "Peter Dugan",
            "Marian Popescu",
            "Denise Risch",
            "Hal Lewis",
            "Christopher Clark"
        ],
        "abstract": "In this paper, we propose a method to improve sound classification performance by combining signal features, derived from the time-frequency spectrogram, with human perception. The method presented herein exploits an artificial neural network (ANN) and learns the signal features based on the human perception knowledge. The proposed method is applied to a large acoustic dataset containing 24 months of nearly continuous recordings. The results show a significant improvement in performance of the detection-classification system; yielding as much as 20% improvement in true positive rate for a given false positive rate.\n    ",
        "submission_date": "2013-05-15T00:00:00",
        "last_modified_date": "2013-06-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1305.3635",
        "title": "Bioacoustic Signal Classification Based on Continuous Region Processing, Grid Masking and Artificial Neural Network",
        "authors": [
            "Mohammad Pourhomayoun",
            "Peter Dugan",
            "Marian Popescu",
            "Christopher Clark"
        ],
        "abstract": "In this paper, we develop a novel method based on machine-learning and image processing to identify North Atlantic right whale (NARW) up-calls in the presence of high levels of ambient and interfering noise. We apply a continuous region algorithm on the spectrogram to extract the regions of interest, and then use grid masking techniques to generate a small feature set that is then used in an artificial neural network classifier to identify the NARW up-calls. It is shown that the proposed technique is effective in detecting and capturing even very faint up-calls, in the presence of ambient and interfering noises. The method is evaluated on a dataset recorded in Massachusetts Bay, United States. The dataset includes 20000 sound clips for training, and 10000 sound clips for testing. The results show that the proposed technique can achieve an error rate of less than FPR = 4.5% for a 90% true positive rate.\n    ",
        "submission_date": "2013-05-15T00:00:00",
        "last_modified_date": "2013-06-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1305.3885",
        "title": "Geometric primitive feature extraction - concepts, algorithms, and applications",
        "authors": [
            "Dilip K. Prasad"
        ],
        "abstract": "This thesis presents important insights and concepts related to the topic of the extraction of geometric primitives from the edge contours of digital images. Three specific problems related to this topic have been studied, viz., polygonal approximation of digital curves, tangent estimation of digital curves, and ellipse fitting anddetection from digital curves. For the problem of polygonal approximation, two fundamental problems have been addressed. First, the nature of the performance evaluation metrics in relation to the local and global fitting characteristics has been studied. Second, an explicit error bound of the error introduced by digitizing a continuous line segment has been derived and used to propose a generic non-heuristic parameter independent framework which can be used in several dominant point detection methods. For the problem of tangent estimation for digital curves, a simple method of tangent estimation has been proposed. It is shown that the method has a definite upper bound of the error for conic digital curves. It has been shown that the method performs better than almost all (seventy two) existing tangent estimation methods for conic as well as several non-conic digital curves. For the problem of fitting ellipses on digital curves, a geometric distance minimization model has been considered. An unconstrained, linear, non-iterative, and numerically stable ellipse fitting method has been proposed and it has been shown that the proposed method has better selectivity for elliptic digital curves (high true positive and low false positive) as compared to several other ellipse fitting methods. For the problem of detecting ellipses in a set of digital curves, several innovative and fast pre-processing, grouping, and hypotheses evaluation concepts applicable for digital curves have been proposed and combined to form an ellipse detection method.\n    ",
        "submission_date": "2013-05-16T00:00:00",
        "last_modified_date": "2013-05-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1305.3939",
        "title": "Analysis Of Interest Points Of Curvelet Coefficients Contributions Of Microscopic Images And Improvement Of Edges",
        "authors": [
            "A. Djimeli",
            "D. Tchiotsop",
            "R. Tchinda"
        ],
        "abstract": "This paper focuses on improved edge model based on Curvelet coefficients analysis. Curvelet transform is a powerful tool for multiresolution representation of object with anisotropic edge. Curvelet coefficients contributions have been analyzed using Scale Invariant Feature Transform (SIFT), commonly used to study local structure in images. The permutation of Curvelet coefficients from original image and edges image obtained from gradient operator is used to improve original edges. Experimental results show that this method brings out details on edges when the decomposition scale increases.\n    ",
        "submission_date": "2013-05-16T00:00:00",
        "last_modified_date": "2013-05-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1305.4064",
        "title": "Font Acknowledgment and Character Extraction of Digital and Scanned Images",
        "authors": [
            "Syed Muhammad Arsalan Bashir"
        ],
        "abstract": "The font recognition and character extraction is of immense importance as these are many scenarios where data are in such a form, which cannot be processed like in image form or as a hard copy. So the procedure developed in this paper is basically related to identifying the font (Times New Roman, Arial and Comic Sans MS) and afterwards recovering the text using simple correlation based method where the binary templates are correlated to the input image text characters. All of this extraction is done in the presence of a little noise as images may have noisy patterns due to photocopying. The significance of this method exists in extraction of data from various monitoring (Surveillance) camera footages or even more. The method is developed on Matlab\\c{opyright} which takes input image and recovers text and font information from it in a text file.\n    ",
        "submission_date": "2013-05-17T00:00:00",
        "last_modified_date": "2013-05-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1305.4077",
        "title": "Indexing Medical Images based on Collaborative Experts Reports",
        "authors": [
            "Abir Messaoudi",
            "Riadh Bouslimi",
            "Jalel Akaichi"
        ],
        "abstract": "A patient is often willing to quickly get, from his physician, reliable analysis and concise explanation according to provided linked medical images. The fact of making choices individually by the patient's physician may lead to malpractices and consequently generates unforeseeable damages. The Institute of Medicine of the National Sciences Academy(IMNAS) in USA published a study estimating that up to 98,000 hospital deathseach year can be attributed to medical malpractice [1]. Moreover, physician, in charge of medical image analysis, might be unavailable at the right time, which may complicate the patient's state. The goal of this paper is to provide to physicians and patients, a social network that permits to foster cooperation and to overcome the problem of unavailability of doctors on site any time. Therefore, patients can submit their medical images to be diagnosed and commented by several experts instantly. Consequently, the need to process opinions and to extract information automatically from the proposed social network became a necessity due to the huge number of comments expressing specialist's reviews. For this reason, we propose a kind of comments' summary keywords-based method which extracts the major current terms and relevant words existing on physicians' annotations. The extracted keywords will present a new and robust method for image indexation. In fact, significant extracted terms will be used later to index images in order to facilitate their discovery for any appropriate use. To overcome this challenge, we propose our Terminology Extraction of Annotation (TEA) mixed approach which focuses on algorithms mainly based on statistical methods and on external semantic resources.\n    ",
        "submission_date": "2013-05-17T00:00:00",
        "last_modified_date": "2013-07-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1305.4168",
        "title": "Flying Triangulation - towards the 3D movie camera",
        "authors": [
            "Florian Willomitzer",
            "Svenja Ettl",
            "Christian Faber",
            "Gerd H\u00e4usler"
        ],
        "abstract": "Flying Triangulation sensors enable a free-hand and motion-robust 3D data acquisition of complex shaped objects. The measurement principle is based on a multi-line light-sectioning approach and uses sophisticated algorithms for real-time registration (S. Ettl et al., Appl. Opt. 51 (2012) 281-289). As \"single-shot principle\", light sectioning enables the option to get surface data from one single camera exposure. But there is a drawback: A pixel-dense measurement is not possible because of fundamental information-theoretical reasons. By \"pixel-dense\" we understand that each pixel displays individually measured distance information, neither interpolated from its neighbour pixels nor using lateral context information. Hence, for monomodal single-shot principles, the 3D data generated from one 2D raw image display a significantly lower space-bandwidth than the camera permits. This is the price one must pay for motion robustness. Currently, our sensors project about 10 lines (each with 1000 pixels), reaching an considerable lower data efficiency than theoretically possible for a single-shot sensor. Our aim is to push Flying Triangulation to its information-theoretical limits. Therefore, the line density as well as the measurement depth needs to be significantly increased. This causes serious indexing ambiguities. On the road to a single-shot 3D movie camera, we are working on solutions to overcome the problem of false line indexing by utilizing yet unexploited information. We will present several approaches and will discuss profound information-theoretical questions about the information efficiency of 3D sensors.\n    ",
        "submission_date": "2013-05-17T00:00:00",
        "last_modified_date": "2013-05-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1305.4298",
        "title": "Blockwise SURE Shrinkage for Non-Local Means",
        "authors": [
            "Yue Wu",
            "Brian Tracey",
            "Premkumar Natarajan",
            "Joseph P. Noonan"
        ],
        "abstract": "In this letter, we investigate the shrinkage problem for the non-local means (NLM) image denoising. In particular, we derive the closed-form of the optimal blockwise shrinkage for NLM that minimizes the Stein's unbiased risk estimator (SURE). We also propose a constant complexity algorithm allowing fast blockwise shrinkage. Simulation results show that the proposed blockwise shrinkage method improves NLM performance in attaining higher peak signal noise ratio (PSNR) and structural similarity index (SSIM), and makes NLM more robust against parameter changes. Similar ideas can be applicable to other patchwise image denoising techniques.\n    ",
        "submission_date": "2013-05-18T00:00:00",
        "last_modified_date": "2013-05-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1305.4537",
        "title": "Object Detection with Pixel Intensity Comparisons Organized in Decision Trees",
        "authors": [
            "Nenad Marku\u0161",
            "Miroslav Frljak",
            "Igor S. Pand\u017ei\u0107",
            "J\u00f6rgen Ahlberg",
            "Robert Forchheimer"
        ],
        "abstract": "We describe a method for visual object detection based on an ensemble of optimized decision trees organized in a cascade of rejectors. The trees use pixel intensity comparisons in their internal nodes and this makes them able to process image regions very fast. Experimental analysis is provided through a face detection problem. The obtained results are encouraging and demonstrate that the method has practical value. Additionally, we analyse its sensitivity to noise and show how to perform fast rotation invariant object detection. Complete source code is provided at ",
        "submission_date": "2013-05-20T00:00:00",
        "last_modified_date": "2014-08-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1305.4544",
        "title": "Efficient Image Retargeting for High Dynamic Range Scenes",
        "authors": [
            "Govind Salvi",
            "Puneet Sharma",
            "Shanmuganathan Raman"
        ],
        "abstract": "Most of the real world scenes have a very high dynamic range (HDR). The mobile phone cameras and the digital cameras available in markets are limited in their capability in both the range and spatial resolution. Same argument can be posed about the limited dynamic range display devices which also differ in the spatial resolution and aspect ratios.\n",
        "submission_date": "2013-05-20T00:00:00",
        "last_modified_date": "2013-05-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1305.5160",
        "title": "A novel automatic thresholding segmentation method with local adaptive thresholds",
        "authors": [
            "Bo Xiao",
            "Yuefeng Jing",
            "Yonghong Guan"
        ],
        "abstract": "A novel method for segmenting bright objects from dark background for grayscale image is proposed. The concept of this method can be stated simply as: to pick out the local-thinnest bands on the grayscale grade-map. It turns out to be a threshold-based method with local adaptive thresholds, where each local threshold is determined by requiring the average normal-direction gradient on the object boundary to be local minimal. The method is highly automatic and the segmentation mimics a man's natural expectation even the object boundaries are fuzzy.\n    ",
        "submission_date": "2013-05-22T00:00:00",
        "last_modified_date": "2013-05-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1305.5306",
        "title": "A Supervised Neural Autoregressive Topic Model for Simultaneous Image Classification and Annotation",
        "authors": [
            "Yin Zheng",
            "Yu-Jin Zhang",
            "Hugo Larochelle"
        ],
        "abstract": "Topic modeling based on latent Dirichlet allocation (LDA) has been a framework of choice to perform scene recognition and annotation. Recently, a new type of topic model called the Document Neural Autoregressive Distribution Estimator (DocNADE) was proposed and demonstrated state-of-the-art performance for document modeling. In this work, we show how to successfully apply and extend this model to the context of visual scene modeling. Specifically, we propose SupDocNADE, a supervised extension of DocNADE, that increases the discriminative power of the hidden topic features by incorporating label information into the training objective of the model. We also describe how to leverage information about the spatial position of the visual words and how to embed additional image annotations, so as to simultaneously perform image classification and annotation. We test our model on the Scene15, LabelMe and UIUC-Sports datasets and show that it compares favorably to other topic models such as the supervised variant of LDA.\n    ",
        "submission_date": "2013-05-23T00:00:00",
        "last_modified_date": "2013-05-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1305.5728",
        "title": "Edge Detection in Radar Images Using Weibull Distribution",
        "authors": [
            "Ali El-Zaart",
            "Wafaa Kamel Al-Jibory"
        ],
        "abstract": "Radar images can reveal information about the shape of the surface terrain as well as its physical and biophysical properties. Radar images have long been used in geological studies to map structural features that are revealed by the shape of the landscape. Radar imagery also has applications in vegetation and crop type mapping, landscape ecology, hydrology, and volcanology. Image processing is using for detecting for objects in radar images. Edge detection; which is a method of determining the discontinuities in gray level images; is a very important initial step in Image processing. Many classical edge detectors have been developed over time. Some of the well-known edge detection operators based on the first derivative of the image are Roberts, Prewitt, Sobel which is traditionally implemented by convolving the image with masks. Also Gaussian distribution has been used to build masks for the first and second derivative. However, this distribution has limit to only symmetric shape. This paper will use to construct the masks, the Weibull distribution which was more general than Gaussian because it has symmetric and asymmetric shape. The constructed masks are applied to images and we obtained good results.\n    ",
        "submission_date": "2013-05-24T00:00:00",
        "last_modified_date": "2013-05-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1305.5756",
        "title": "Flooding edge or node weighted graphs",
        "authors": [
            "Fernand Meyer"
        ],
        "abstract": "Reconstruction closings have all properties of a physical flooding of a topographic surface. They are precious for simplifying gradient images or, filling unwanted catchment basins, on which a subsequent watershed transform extracts the targeted objects. Flooding a topographic surface may be modeled as flooding a node weighted graph (TG), with unweighted edges, the node weights representing the ground level. The progression of a flooding may also be modeled on the region adjacency graph (RAG) of a topographic surface. On a RAG each node represents a catchment basin and edges connect neighboring nodes. The edges are weighted by the altitude of the pass point between both adjacent regions. The graph is flooded from sources placed at the marker positions and each node is assigned to the source by which it has been flooded. The level of the flood is represented on the nodes on each type of graphs. The same flooding may thus be modeled on a TG or on a RAG. We characterize all valid floodings on both types of graphs, as they should verify the laws of hydrostatics. We then show that each flooding of a node weighted graph also is a flooding of an edge weighted graph with appropriate edge weights. The highest flooding under a ceiling function may be interpreted as the shortest distance to the root for the ultrametric flooding distance in an augmented graph. The ultrametric distance between two nodes is the minimal altitude of a flooding for which both nodes are flooded. This remark permits to flood edge or node weighted graphs by using shortest path algorithms. It appears that the collection of all lakes of a RAG has the structure of a dendrogram, on which the highest flooding under a ceiling function may be rapidly found.\n    ",
        "submission_date": "2013-05-24T00:00:00",
        "last_modified_date": "2013-05-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1305.5777",
        "title": "Compressive Sensing of Sparse Tensors",
        "authors": [
            "Shmuel Friedland",
            "Qun Li",
            "Dan Schonfeld"
        ],
        "abstract": "Compressive sensing (CS) has triggered enormous research activity since its first appearance. CS exploits the signal's sparsity or compressibility in a particular domain and integrates data compression and acquisition, thus allowing exact reconstruction through relatively few non-adaptive linear measurements. While conventional CS theory relies on data representation in the form of vectors, many data types in various applications such as color imaging, video sequences, and multi-sensor networks, are intrinsically represented by higher-order tensors. Application of CS to higher-order data representation is typically performed by conversion of the data to very long vectors that must be measured using very large sampling matrices, thus imposing a huge computational and memory burden. In this paper, we propose Generalized Tensor Compressive Sensing (GTCS)--a unified framework for compressive sensing of higher-order tensors which preserves the intrinsic structure of tensor data with reduced computational complexity at reconstruction. GTCS offers an efficient means for representation of multidimensional data by providing simultaneous acquisition and compression from all tensor modes. In addition, we propound two reconstruction procedures, a serial method (GTCS-S) and a parallelizable method (GTCS-P). We then compare the performance of the proposed method with Kronecker compressive sensing (KCS) and multi way compressive sensing (MWCS). We demonstrate experimentally that GTCS outperforms KCS and MWCS in terms of both reconstruction accuracy (within a range of compression ratios) and processing speed. The major disadvantage of our methods (and of MWCS as well), is that the compression ratios may be worse than that offered by KCS.\n    ",
        "submission_date": "2013-05-24T00:00:00",
        "last_modified_date": "2014-09-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1305.5905",
        "title": "\u00d6AGM/AAPR 2013 - The 37th Annual Workshop of the Austrian Association for Pattern Recognition",
        "authors": [
            "Justus Piater",
            "Antonio J. Rodr\u00edguez S\u00e1nchez"
        ],
        "abstract": "In this editorial, the organizers summarize facts and background about the event.\n    ",
        "submission_date": "2013-05-25T00:00:00",
        "last_modified_date": "2013-05-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1305.6387",
        "title": "Higher-order Segmentation via Multicuts",
        "authors": [
            "Joerg Hendrik Kappes",
            "Markus Speth",
            "Gerhard Reinelt",
            "Christoph Schnoerr"
        ],
        "abstract": "Multicuts enable to conveniently represent discrete graphical models for unsupervised and supervised image segmentation, in the case of local energy functions that exhibit symmetries. The basic Potts model and natural extensions thereof to higher-order models provide a prominent class of such objectives, that cover a broad range of segmentation problems relevant to image analysis and computer vision. We exhibit a way to systematically take into account such higher-order terms for computational inference. Furthermore, we present results of a comprehensive and competitive numerical evaluation of a variety of dedicated cutting-plane algorithms. Our approach enables the globally optimal evaluation of a significant subset of these models, without compromising runtime. Polynomially solvable relaxations are studied as well, along with advanced rounding schemes for post-processing.\n    ",
        "submission_date": "2013-05-28T00:00:00",
        "last_modified_date": "2015-11-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1305.6883",
        "title": "Rotation invariants of two dimensional curves based on iterated integrals",
        "authors": [
            "Joscha Diehl"
        ],
        "abstract": "We introduce a novel class of rotation invariants of two dimensional curves based on iterated integrals. The invariants we present are in some sense complete and we describe an algorithm to calculate them, giving explicit computations up to order six. We present an application to online (stroke-trajectory based) character recognition. This seems to be the first time in the literature that the use of iterated integrals of a curve is proposed for (invariant) feature extraction in machine learning applications.\n    ",
        "submission_date": "2013-05-29T00:00:00",
        "last_modified_date": "2013-05-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1305.6918",
        "title": "Video Human Segmentation using Fuzzy Object Models and its Application to Body Pose Estimation of Toddlers for Behavior Studies",
        "authors": [
            "Thiago V. Spina",
            "Mariano Tepper",
            "Amy Esler",
            "Vassilios Morellas",
            "Nikolaos Papanikolopoulos",
            "Alexandre X. Falc\u00e3o",
            "Guillermo Sapiro"
        ],
        "abstract": "Video object segmentation is a challenging problem due to the presence of deformable, connected, and articulated objects, intra- and inter-object occlusions, object motion, and poor lighting. Some of these challenges call for object models that can locate a desired object and separate it from its surrounding background, even when both share similar colors and textures. In this work, we extend a fuzzy object model, named cloud system model (CSM), to handle video segmentation, and evaluate it for body pose estimation of toddlers at risk of autism. CSM has been successfully used to model the parts of the brain (cerebrum, left and right brain hemispheres, and cerebellum) in order to automatically locate and separate them from each other, the connected brain stem, and the background in 3D MR-images. In our case, the objects are articulated parts (2D projections) of the human body, which can deform, cause self-occlusions, and move along the video. The proposed CSM extension handles articulation by connecting the individual clouds, body parts, of the system using a 2D stickman model. The stickman representation naturally allows us to extract 2D body pose measures of arm asymmetry patterns during unsupported gait of toddlers, a possible behavioral marker of autism. The results show that our method can provide insightful knowledge to assist the specialist's observations during real in-clinic assessments.\n    ",
        "submission_date": "2013-05-29T00:00:00",
        "last_modified_date": "2013-05-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1305.7053",
        "title": "A Local Active Contour Model for Image Segmentation with Intensity Inhomogeneity",
        "authors": [
            "Kaihua Zhang",
            "Lei Zhang",
            "Kin-Man Lam",
            "David Zhang"
        ],
        "abstract": "A novel locally statistical active contour model (ACM) for image segmentation in the presence of intensity inhomogeneity is presented in this paper. The inhomogeneous objects are modeled as Gaussian distributions of different means and variances, and a moving window is used to map the original image into another domain, where the intensity distributions of inhomogeneous objects are still Gaussian but are better separated. The means of the Gaussian distributions in the transformed domain can be adaptively estimated by multiplying a bias field with the original signal within the window. A statistical energy functional is then defined for each local region, which combines the bias field, the level set function, and the constant approximating the true signal of the corresponding object. Experiments on both synthetic and real images demonstrate the superiority of our proposed algorithm to state-of-the-art and representative methods.\n    ",
        "submission_date": "2013-05-30T00:00:00",
        "last_modified_date": "2013-05-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1305.7181",
        "title": "Lensless Imaging by Compressive Sensing",
        "authors": [
            "Gang Huang",
            "Hong Jiang",
            "Kim Matthews",
            "Paul Wilford"
        ],
        "abstract": "In this paper, we propose a lensless compressive imaging architecture. The architecture consists of two components, an aperture assembly and a sensor. No lens is used. The aperture assembly consists of a two dimensional array of aperture elements. The transmittance of each aperture element is independently controllable. The sensor is a single detection element. A compressive sensing matrix is implemented by adjusting the transmittance of the individual aperture elements according to the values of the sensing matrix. The proposed architecture is simple and reliable because no lens is used. The architecture can be used for capturing images of visible and other spectra such as infrared, or millimeter waves, in surveillance applications for detecting anomalies or extracting features such as speed of moving objects. Multiple sensors may be used with a single aperture assembly to capture multi-view images simultaneously. A prototype was built by using a LCD panel and a photoelectric sensor for capturing images of visible spectrum.\n    ",
        "submission_date": "2013-05-30T00:00:00",
        "last_modified_date": "2013-05-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1305.7311",
        "title": "Robust Hyperspectral Unmixing with Correntropy based Metric",
        "authors": [
            "Ying Wang",
            "Chunhong Pan",
            "Shiming Xiang",
            "Feiyun Zhu"
        ],
        "abstract": "Hyperspectral unmixing is one of the crucial steps for many hyperspectral applications. The problem of hyperspectral unmixing has proven to be a difficult task in unsupervised work settings where the endmembers and abundances are both unknown. What is more, this task becomes more challenging in the case that the spectral bands are degraded with noise. This paper presents a robust model for unsupervised hyperspectral unmixing. Specifically, our model is developed with the correntropy based metric where the non-negative constraints on both endmembers and abundances are imposed to keep physical significance. In addition, a sparsity prior is explicitly formulated to constrain the distribution of the abundances of each endmember. To solve our model, a half-quadratic optimization technique is developed to convert the original complex optimization problem into an iteratively re-weighted NMF with sparsity constraints. As a result, the optimization of our model can adaptively assign small weights to noisy bands and give more emphasis on noise-free bands. In addition, with sparsity constraints, our model can naturally generate sparse abundances. Experiments on synthetic and real data demonstrate the effectiveness of our model in comparison to the related state-of-the-art unmixing models.\n    ",
        "submission_date": "2013-05-31T00:00:00",
        "last_modified_date": "2013-05-31T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1306.0139",
        "title": "Image Inpainting by Kriging Interpolation Technique",
        "authors": [
            "Firas A. Jassim"
        ],
        "abstract": "Image inpainting is the art of predicting damaged regions of an image. The manual way of image inpainting is a time consuming. Therefore, there must be an automatic digital method for image inpainting that recovers the image from the damaged regions. In this paper, a novel statistical image inpainting algorithm based on Kriging interpolation technique was proposed. Kriging technique automatically fills the damaged region in an image using the information available from its surrounding regions in such away that it uses the spatial correlation structure of points inside the k-by-k block. Kriging has the ability to face the challenge of keeping the structure and texture information as the size of damaged region heighten. Experimental results showed that, Kriging has a high PSNR value when recovering a variety of test images from scratches and text as damaged regions.\n    ",
        "submission_date": "2013-06-01T00:00:00",
        "last_modified_date": "2013-06-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1306.0152",
        "title": "An Analysis of the Connections Between Layers of Deep Neural Networks",
        "authors": [
            "Eugenio Culurciello",
            "Jonghoon Jin",
            "Aysegul Dundar",
            "Jordan Bates"
        ],
        "abstract": "We present an analysis of different techniques for selecting the connection be- tween layers of deep neural networks. Traditional deep neural networks use ran- dom connection tables between layers to keep the number of connections small and tune to different image features. This kind of connection performs adequately in supervised deep networks because their values are refined during the training. On the other hand, in unsupervised learning, one cannot rely on back-propagation techniques to learn the connections between layers. In this work, we tested four different techniques for connecting the first layer of the network to the second layer on the CIFAR and SVHN datasets and showed that the accuracy can be im- proved up to 3% depending on the technique used. We also showed that learning the connections based on the co-occurrences of the features does not confer an advantage over a random connection table in small networks. This work is helpful to improve the efficiency of connections between the layers of unsupervised deep neural networks.\n    ",
        "submission_date": "2013-06-01T00:00:00",
        "last_modified_date": "2013-06-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1306.0404",
        "title": "Iterative Grassmannian Optimization for Robust Image Alignment",
        "authors": [
            "Jun He",
            "Dejiao Zhang",
            "Laura Balzano",
            "Tao Tao"
        ],
        "abstract": "Robust high-dimensional data processing has witnessed an exciting development in recent years, as theoretical results have shown that it is possible using convex programming to optimize data fit to a low-rank component plus a sparse outlier component. This problem is also known as Robust PCA, and it has found application in many areas of computer vision. In image and video processing and face recognition, the opportunity to process massive image databases is emerging as people upload photo and video data online in unprecedented volumes. However, data quality and consistency is not controlled in any way, and the massiveness of the data poses a serious computational challenge. In this paper we present t-GRASTA, or \"Transformed GRASTA (Grassmannian Robust Adaptive Subspace Tracking Algorithm)\". t-GRASTA iteratively performs incremental gradient descent constrained to the Grassmann manifold of subspaces in order to simultaneously estimate a decomposition of a collection of images into a low-rank subspace, a sparse part of occlusions and foreground objects, and a transformation such as rotation or translation of the image. We show that t-GRASTA is 4 $\\times$ faster than state-of-the-art algorithms, has half the memory requirement, and can achieve alignment for face images as well as jittered camera surveillance images.\n    ",
        "submission_date": "2013-06-03T00:00:00",
        "last_modified_date": "2013-06-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1306.0974",
        "title": "Distributed Bayesian inference for consistent labeling of tracked objects in non-overlapping camera networks",
        "authors": [
            "Jiuqing Wan",
            "Li Liu"
        ],
        "abstract": "One of the fundamental requirements for visual surveillance using non-overlapping camera networks is the correct labeling of tracked objects on each camera in a consistent way,in the sense that the captured tracklets, or observations in this paper, of the same object at different cameras should be assigned with the same label. In this paper, we formulate this task as a Bayesian inference problem and propose a distributed inference framework in which the posterior distribution of labeling variable corresponding to each observation, conditioned on all history appearance and spatio-temporal evidence made in the whole networks, is calculated based solely on local information processing on each camera and mutual information exchanging between neighboring cameras. In our framework, the number of objects presenting in the monitored region, i.e. the sampling space of labeling variables, does not need to be specified beforehand. Instead, it can be determined automatically on the fly. In addition, we make no assumption about the appearance distribution of a single object, but use similarity scores between appearance pairs, given by advanced object re-identification algorithm, as appearance likelihood for inference. This feature makes our method very flexible and competitive when observing condition undergoes large changes across camera views. To cope with the problem of missing detection, which is critical for distributed inference, we consider an enlarged neighborhood of each camera during inference and use a mixture model to describe the higher order spatio-temporal constraints. The robustness of the algorithm against missing detection is improved at the cost of slightly increased computation and communication burden at each camera node. Finally, we demonstrate the effectiveness of our method through experiments on an indoor Office Building dataset and an outdoor Campus Garden dataset.\n    ",
        "submission_date": "2013-06-05T00:00:00",
        "last_modified_date": "2013-06-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1306.1083",
        "title": "Discriminative Parameter Estimation for Random Walks Segmentation: Technical Report",
        "authors": [
            "Pierre-Yves Baudin",
            "Danny Goodman",
            "Puneet Kumar",
            "Noura Azzabou",
            "Pierre G. Carlier",
            "Nikos Paragios",
            "M. Pawan Kumar"
        ],
        "abstract": "The Random Walks (RW) algorithm is one of the most e - cient and easy-to-use probabilistic segmentation methods. By combining contrast terms with prior terms, it provides accurate segmentations of medical images in a fully automated manner. However, one of the main drawbacks of using the RW algorithm is that its parameters have to be hand-tuned. we propose a novel discriminative learning framework that estimates the parameters using a training dataset. The main challenge we face is that the training samples are not fully supervised. Speci cally, they provide a hard segmentation of the images, instead of a proba-bilistic segmentation. We overcome this challenge by treating the optimal probabilistic segmentation that is compatible with the given hard segmentation as a latent variable. This allows us to employ the latent support vector machine formulation for parameter estimation. We show that our approach signi cantly outperforms the baseline methods on a challenging dataset consisting of real clinical 3D MRI volumes of skeletal muscles.\n    ",
        "submission_date": "2013-06-05T00:00:00",
        "last_modified_date": "2013-06-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1306.1301",
        "title": "Recognition of Indian Sign Language in Live Video",
        "authors": [
            "Joyeeta Singha",
            "Karen Das"
        ],
        "abstract": "Sign Language Recognition has emerged as one of the important area of research in Computer Vision. The difficulty faced by the researchers is that the instances of signs vary with both motion and appearance. Thus, in this paper a novel approach for recognizing various alphabets of Indian Sign Language is proposed where continuous video sequences of the signs have been considered. The proposed system comprises of three stages: Preprocessing stage, Feature Extraction and Classification. Preprocessing stage includes skin filtering, histogram matching. Eigen values and Eigen Vectors were considered for feature extraction stage and finally Eigen value weighted Euclidean distance is used to recognize the sign. It deals with bare hands, thus allowing the user to interact with the system in natural way. We have considered 24 different alphabets in the video sequences and attained a success rate of 96.25%.\n    ",
        "submission_date": "2013-06-06T00:00:00",
        "last_modified_date": "2013-06-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1306.1358",
        "title": "Geometric operations implemented by conformal geometric algebra neural nodes",
        "authors": [
            "Eckhard Hitzer"
        ],
        "abstract": "Geometric algebra is an optimal frame work for calculating with vectors. The geometric algebra of a space includes elements that represent all the its subspaces (lines, planes, volumes, ...). Conformal geometric algebra expands this approach to elementary representations of arbitrary points, point pairs, lines, circles, planes and spheres. Apart from including curved objects, conformal geometric algebra has an elegant unified quaternion like representation for all proper and improper Euclidean transformations, including reflections at spheres, general screw transformations and scaling. Expanding the concepts of real and complex neurons we arrive at the new powerful concept of conformal geometric algebra neurons. These neurons can easily take the above mentioned geometric objects or sets of these objects as inputs and apply a wide range of geometric transformations via the geometric algebra valued weights.\n    ",
        "submission_date": "2013-06-06T00:00:00",
        "last_modified_date": "2013-06-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1306.1462",
        "title": "K-Algorithm A Modified Technique for Noise Removal in Handwritten Documents",
        "authors": [
            "Kanika Bansal",
            "Rajiv Kumar"
        ],
        "abstract": "OCR has been an active research area since last few decades. OCR performs the recognition of the text in the scanned document image and converts it into editable form. The OCR process can have several stages like pre-processing, segmentation, recognition and post processing. The pre-processing stage is a crucial stage for the success of OCR, which mainly deals with noise removal. In the present paper, a modified technique for noise removal named as K-Algorithm has been proposed, which has two stages as filtering and binarization. The proposed technique shows improvised results in comparison to median filtering technique.\n    ",
        "submission_date": "2013-06-06T00:00:00",
        "last_modified_date": "2013-06-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1306.1603",
        "title": "Infrared face recognition: a literature review",
        "authors": [
            "Reza Shoja Ghiass",
            "Ognjen Arandjelovic",
            "Hakim Bendada",
            "Xavier Maldague"
        ],
        "abstract": "Automatic face recognition (AFR) is an area with immense practical potential which includes a wide range of commercial and law enforcement applications, and it continues to be one of the most active research areas of computer vision. Even after over three decades of intense research, the state-of-the-art in AFR continues to improve, benefiting from advances in a range of different fields including image processing, pattern recognition, computer graphics and physiology. However, systems based on visible spectrum images continue to face challenges in the presence of illumination, pose and expression changes, as well as facial disguises, all of which can significantly decrease their accuracy. Amongst various approaches which have been proposed in an attempt to overcome these limitations, the use of infrared (IR) imaging has emerged as a particularly promising research direction. This paper presents a comprehensive and timely review of the literature on this subject.\n    ",
        "submission_date": "2013-06-07T00:00:00",
        "last_modified_date": "2013-06-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1306.1609",
        "title": "Vesselness features and the inverse compositional AAM for robust face recognition using thermal IR",
        "authors": [
            "Reza Shoja Ghiass",
            "Ognjen Arandjelovic",
            "Hakim Bendada",
            "Xavier Maldague"
        ],
        "abstract": "Over the course of the last decade, infrared (IR) and particularly thermal IR imaging based face recognition has emerged as a promising complement to conventional, visible spectrum based approaches which continue to struggle when applied in the real world. While inherently insensitive to visible spectrum illumination changes, IR images introduce specific challenges of their own, most notably sensitivity to factors which affect facial heat emission patterns, e.g. emotional state, ambient temperature, and alcohol intake. In addition, facial expression and pose changes are more difficult to correct in IR images because they are less rich in high frequency detail which is an important cue for fitting any deformable model. We describe a novel method which addresses these challenges. To normalize for pose and facial expression changes we generate a synthetic frontal image of a face in a canonical, neutral facial expression from an image of the face in an arbitrary pose and facial expression. This is achieved by piecewise affine warping which follows active appearance model (AAM) fitting. This is the first publication which explores the use of an AAM on thermal IR images; we propose a pre-processing step which enhances detail in thermal images, making AAM convergence faster and more accurate. To overcome the problem of thermal IR image sensitivity to the pattern of facial temperature emissions we describe a representation based on reliable anatomical features. In contrast to previous approaches, our representation is not binary; rather, our method accounts for the reliability of the extracted features. This makes the proposed representation much more robust both to pose and scale changes. The effectiveness of the proposed approach is demonstrated on the largest public database of thermal IR images of faces on which it achieved 100% identification, significantly outperforming previous methods.\n    ",
        "submission_date": "2013-06-07T00:00:00",
        "last_modified_date": "2013-06-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1306.1619",
        "title": "Statistical Denoising for single molecule fluorescence microscopic images",
        "authors": [
            "Ji Won Yoon"
        ],
        "abstract": "Single molecule fluorescence microscopy is a powerful technique for uncovering detailed information about biological systems, both in vitro and in vivo. In such experiments, the inherently low signal to noise ratios mean that accurate algorithms to separate true signal and background noise are essential to generate meaningful results. To this end, we have developed a new and robust method to reduce noise in single molecule fluorescence images by using a Gaussian Markov Random Field (GMRF) prior in a Bayesian framework. Two different strategies are proposed to build the prior - an intrinsic GMRF, with a stationary relationship between pixels and a heterogeneous intrinsic GMRF, with a differently weighted relationship between pixels classified as molecules and background. Testing with synthetic and real experimental fluorescence images demonstrates that the heterogeneous intrinsic GMRF is superior to other conventional de-noising approaches.\n    ",
        "submission_date": "2013-06-07T00:00:00",
        "last_modified_date": "2013-06-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1306.1676",
        "title": "Algebraic foundations of split hypercomplex nonlinear adaptive filtering",
        "authors": [
            "Eckhard Hitzer"
        ],
        "abstract": "A split hypercomplex learning algorithm for the training of nonlinear finite impulse response adaptive filters for the processing of hypercomplex signals of any dimension is proposed. The derivation strictly takes into account the laws of hypercomplex algebra and hypercomplex calculus, some of which have been neglected in existing learning approaches (e.g. for quaternions). Already in the case of quaternions we can predict improvements in performance of hypercomplex processes. The convergence of the proposed algorithms is rigorously analyzed.\n",
        "submission_date": "2013-06-07T00:00:00",
        "last_modified_date": "2013-06-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1306.1822",
        "title": "Illumination-invariant face recognition from a single image across extreme pose using a dual dimension AAM ensemble in the thermal infrared spectrum",
        "authors": [
            "Reza Shoja Ghiass",
            "Ognjen Arandjelovic",
            "Hakim Bendada",
            "Xavier Maldague"
        ],
        "abstract": "Over the course of the last decade, infrared (IR) and particularly thermal IR imaging based face recognition has emerged as a promising complement to conventional, visible spectrum based approaches which continue to struggle when applied in practice. While inherently insensitive to visible spectrum illumination changes, IR data introduces specific challenges of its own, most notably sensitivity to factors which affect facial heat emission patterns, e.g. emotional state, ambient temperature, and alcohol intake. In addition, facial expression and pose changes are more difficult to correct in IR images because they are less rich in high frequency detail which is an important cue for fitting any deformable model. In this paper we describe a novel method which addresses these major challenges. Specifically, when comparing two thermal IR images of faces, we mutually normalize their poses and facial expressions by using an active appearance model (AAM) to generate synthetic images of the two faces with a neutral facial expression and in the same view (the average of the two input views). This is achieved by piecewise affine warping which follows AAM fitting. A major contribution of our work is the use of an AAM ensemble in which each AAM is specialized to a particular range of poses and a particular region of the thermal IR face space. Combined with the contributions from our previous work which addressed the problem of reliable AAM fitting in the thermal IR spectrum, and the development of a person-specific representation robust to transient changes in the pattern of facial temperature emissions, the proposed ensemble framework accurately matches faces across the full range of yaw from frontal to profile, even in the presence of scale variation (e.g. due to the varying distance of a subject from the camera).\n    ",
        "submission_date": "2013-06-07T00:00:00",
        "last_modified_date": "2013-06-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1306.1894",
        "title": "Speckle Reduction with Adaptive Stack Filters",
        "authors": [
            "Mar\u00eda Elena Buemi",
            "Alejandro C. Frery",
            "Heitor S. Ramos"
        ],
        "abstract": "Stack filters are a special case of non-linear filters. They have a good performance for filtering images with different types of noise while preserving edges and details. A stack filter decomposes an input image into stacks of binary images according to a set of thresholds. Each binary image is then filtered by a Boolean function, which characterizes the filter. Adaptive stack filters can be computed by training using a prototype (ideal) image and its corrupted version, leading to optimized filters with respect to a loss function. In this work we propose the use of training with selected samples for the estimation of the optimal Boolean function. We study the performance of adaptive stack filters when they are applied to speckled imagery, in particular to Synthetic Aperture Radar (SAR) images. This is done by evaluating the quality of the filtered images through the use of suitable image quality indexes and by measuring the classification accuracy of the resulting images. We used SAR images as input, since they are affected by speckle noise that makes classification a difficult task.\n    ",
        "submission_date": "2013-06-08T00:00:00",
        "last_modified_date": "2013-06-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1306.1913",
        "title": "Emotional Expression Classification using Time-Series Kernels",
        "authors": [
            "Andras Lorincz",
            "Laszlo Jeni",
            "Zoltan Szabo",
            "Jeffrey Cohn",
            "Takeo Kanade"
        ],
        "abstract": "Estimation of facial expressions, as spatio-temporal processes, can take advantage of kernel methods if one considers facial landmark positions and their motion in 3D space. We applied support vector classification with kernels derived from dynamic time-warping similarity measures. We achieved over 99% accuracy - measured by area under ROC curve - using only the 'motion pattern' of the PCA compressed representation of the marker point vector, the so-called shape parameters. Beyond the classification of full motion patterns, several expressions were recognized with over 90% accuracy in as few as 5-6 frames from their onset, about 200 milliseconds.\n    ",
        "submission_date": "2013-06-08T00:00:00",
        "last_modified_date": "2013-06-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1306.2100",
        "title": "Discriminative extended canonical correlation analysis for pattern set matching",
        "authors": [
            "Ognjen Arandjelovic"
        ],
        "abstract": "In this paper we address the problem of matching sets of vectors embedded in the same input space. We propose an approach which is motivated by canonical correlation analysis (CCA), a statistical technique which has proven successful in a wide variety of pattern recognition problems. Like CCA when applied to the matching of sets, our extended canonical correlation analysis (E-CCA) aims to extract the most similar modes of variability within two sets. Our first major contribution is the formulation of a principled framework for robust inference of such modes from data in the presence of uncertainty associated with noise and sampling randomness. E-CCA retains the efficiency and closed form computability of CCA, but unlike it, does not possess free parameters which cannot be inferred directly from data (inherent data dimensionality, and the number of canonical correlations used for set similarity computation). Our second major contribution is to show that in contrast to CCA, E-CCA is readily adapted to match sets in a discriminative learning scheme which we call discriminative extended canonical correlation analysis (DE-CCA). Theoretical contributions of this paper are followed by an empirical evaluation of its premises on the task of face recognition from sets of rasterized appearance images. The results demonstrate that our approach, E-CCA, already outperforms both CCA and its quasi-discriminative counterpart constrained CCA (C-CCA), for all values of their free parameters. An even greater improvement is achieved with the discriminative variant, DE-CCA.\n    ",
        "submission_date": "2013-06-10T00:00:00",
        "last_modified_date": "2013-06-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1306.2102",
        "title": "Discriminative k-means clustering",
        "authors": [
            "Ognjen Arandjelovic"
        ],
        "abstract": "The k-means algorithm is a partitional clustering method. Over 60 years old, it has been successfully used for a variety of problems. The popularity of k-means is in large part a consequence of its simplicity and efficiency. In this paper we are inspired by these appealing properties of k-means in the development of a clustering algorithm which accepts the notion of \"positively\" and \"negatively\" labelled data. The goal is to discover the cluster structure of both positive and negative data in a manner which allows for the discrimination between the two sets. The usefulness of this idea is demonstrated practically on the problem of face recognition, where the task of learning the scope of a person's appearance should be done in a manner which allows this face to be differentiated from others.\n    ",
        "submission_date": "2013-06-10T00:00:00",
        "last_modified_date": "2013-06-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1306.2159",
        "title": "Image segmentation by optimal and hierarchical piecewise constant approximations",
        "authors": [
            "M.Kharinov"
        ],
        "abstract": "Piecewise constant image approximations of sequential number of segments or clusters of disconnected pixels are treated. The method of majorizing of optimal approximation sequence by hierarchical sequence of image approximations is proposed. A generalization for multidimensional case of color and multispectral images is foreseen.\n    ",
        "submission_date": "2013-06-10T00:00:00",
        "last_modified_date": "2013-06-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1306.2599",
        "title": "Hand Gesture Recognition Based on Karhunen-Loeve Transform",
        "authors": [
            "Joyeeta Singha",
            "Karen Das"
        ],
        "abstract": "In this paper, we have proposed a system based on K-L Transform to recognize different hand gestures. The system consists of five steps: skin filtering, palm cropping, edge detection, feature extraction, and classification. Firstly the hand is detected using skin filtering and palm cropping was performed to extract out only the palm portion of the hand. The extracted image was then processed using the Canny Edge Detection technique to extract the outline images of palm. After palm extraction, the features of hand were extracted using K-L Transform technique and finally the input gesture was recognized using proper classifier. In our system, we have tested for 10 different hand gestures, and recognizing rate obtained was 96%. Hence we propose an easy approach to recognize different hand gestures.\n    ",
        "submission_date": "2013-06-11T00:00:00",
        "last_modified_date": "2013-06-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1306.2624",
        "title": "Stopping Criterion for the Mean Shift Iterative Algorithm",
        "authors": [
            "Yasel Garc\u00e9s Su\u00e1rez",
            "Esley Torres",
            "Osvaldo Pereira",
            "Claudia P\u00e9rez",
            "Roberto Rogr\u00edguez"
        ],
        "abstract": "Image segmentation is a critical step in computer vision tasks constituting an essential issue for pattern recognition and visual interpretation. In this paper, we propose a new stopping criterion for the mean shift iterative algorithm by using images defined in Zn ring, with the goal of reaching a better segmentation. We carried out also a study on the weak and strong of equivalence classes between two images. An analysis on the convergence with this new stopping criterion is carried out too.\n    ",
        "submission_date": "2013-06-11T00:00:00",
        "last_modified_date": "2013-06-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1306.2727",
        "title": "Sparse Representation-based Image Quality Assessment",
        "authors": [
            "Tanaya Guha",
            "Ehsan Nezhadarya",
            "Rabab K Ward"
        ],
        "abstract": "A successful approach to image quality assessment involves comparing the structural information between a distorted and its reference image. However, extracting structural information that is perceptually important to our visual system is a challenging task. This paper addresses this issue by employing a sparse representation-based approach and proposes a new metric called the \\emph{sparse representation-based quality} (SPARQ) \\emph{index}. The proposed method learns the inherent structures of the reference image as a set of basis vectors, such that any structure in the image can be represented by a linear combination of only a few of those basis vectors. This sparse strategy is employed because it is known to generate basis vectors that are qualitatively similar to the receptive field of the simple cells present in the mammalian primary visual cortex. The visual quality of the distorted image is estimated by comparing the structures of the reference and the distorted images in terms of the learnt basis vectors resembling cortical cells. Our approach is evaluated on six publicly available subject-rated image quality assessment datasets. The proposed SPARQ index consistently exhibits high correlation with the subjective ratings on all datasets and performs better or at par with the state-of-the-art.\n    ",
        "submission_date": "2013-06-12T00:00:00",
        "last_modified_date": "2013-06-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1306.2795",
        "title": "Recurrent Convolutional Neural Networks for Scene Parsing",
        "authors": [
            "Pedro H. O. Pinheiro",
            "Ronan Collobert"
        ],
        "abstract": "Scene parsing is a technique that consist on giving a label to all pixels in an image according to the class they belong to. To ensure a good visual coherence and a high class accuracy, it is essential for a scene parser to capture image long range dependencies. In a feed-forward architecture, this can be simply achieved by considering a sufficiently large input context patch, around each pixel to be labeled. We propose an approach consisting of a recurrent convolutional neural network which allows us to consider a large input context, while limiting the capacity of the model. Contrary to most standard approaches, our method does not rely on any segmentation methods, nor any task-specific features. The system is trained in an end-to-end manner over raw pixels, and models complex spatial dependencies with low inference cost. As the context size increases with the built-in recurrence, the system identifies and corrects its own errors. Our approach yields state-of-the-art performance on both the Stanford Background Dataset and the SIFT Flow Dataset, while remaining very fast at test time.\n    ",
        "submission_date": "2013-06-12T00:00:00",
        "last_modified_date": "2013-06-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1306.2967",
        "title": "Optimization of Clustering for Clustering-based Image Denoising",
        "authors": [
            "Mohsen Joneidi",
            "Mostafa Sadeghi"
        ],
        "abstract": "In this paper, the problem of de-noising of an image contaminated with additive white Gaussian noise (AWGN) is studied. This subject has been continued to be an open problem in signal processing for more than 50 years. In the present paper, we suggest a method based on global clustering of image constructing blocks. Noting that the type of clustering plays an important role in clustering-based de-noising methods, we address two questions about the clustering. First, which parts of data should be considered for clustering? Second, what data clustering method is suitable for de-noising? Clustering is exploited to learn an over complete dictionary. By obtaining sparse decomposition of the noisy image blocks in terms of the dictionary atoms, the de-noised version is achieved. Experimental results show that our dictionary learning framework outperforms traditional dictionary learning methods such as K-SVD.\n    ",
        "submission_date": "2013-06-12T00:00:00",
        "last_modified_date": "2013-10-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1306.3032",
        "title": "A Face-like Structure Detection on Planet and Satellite Surfaces using Image Processing",
        "authors": [
            "Kazutaka Kurihara",
            "Masakazu Takasu",
            "Kazuhiro Sasao",
            "Hal Seki",
            "Takayuki Narabu",
            "Mitsuo Yamamoto",
            "Satoshi Iida",
            "Hiroyuki Yamamoto"
        ],
        "abstract": "This paper demonstrates that face-like structures are everywhere, and can be de-tected automatically even with computers. Huge amount of satellite images of the Earth, the Moon, the Mars are explored and many interesting face-like structure are detected. Throughout this fact, we believe that science and technologies can alert people not to easily become an occultist.\n    ",
        "submission_date": "2013-06-13T00:00:00",
        "last_modified_date": "2013-06-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1306.3084",
        "title": "Segmentation et Interpr\u00e9tation de Nuages de Points pour la Mod\u00e9lisation d'Environnements Urbains",
        "authors": [
            "Jorge Hernandez",
            "Beatriz Marcotegui"
        ],
        "abstract": "Dans cet article, nous pr\u00e9sentons une m\u00e9thode pour la d\u00e9tection et la classification d'artefacts au niveau du sol, comme phase de filtrage pr\u00e9alable \u00e0 la mod\u00e9lisation d'environnements urbains. La m\u00e9thode de d\u00e9tection est r\u00e9alis\u00e9e sur l'image profondeur, une projection de nuage de points sur un plan image o\u00f9 la valeur du pixel correspond \u00e0 la distance du point au plan. En faisant l'hypoth\u00e8se que les artefacts sont situ\u00e9s au sol, ils sont d\u00e9tect\u00e9s par une transformation de chapeau haut de forme par remplissage de trous sur l'image de profondeur. Les composantes connexes ainsi obtenues, sont ensuite caract\u00e9ris\u00e9es et une analyse des variables est utilis\u00e9e pour la s\u00e9lection des caract\u00e9ristiques les plus discriminantes. Les composantes connexes sont donc classifi\u00e9es en quatre cat\u00e9gories (lampadaires, pi\u00e9tons, voitures et \"Reste\") \u00e0 l'aide d'un algorithme d'apprentissage supervis\u00e9. La m\u00e9thode a \u00e9t\u00e9 test\u00e9e sur des nuages de points de la ville de Paris, en montrant de bons r\u00e9sultats de d\u00e9tection et de classification dans l'ensemble de donn\u00e9es.---In this article, we present a method for detection and classification of artifacts at the street level, in order to filter cloud point, facilitating the urban modeling process. Our approach exploits 3D information by using range image, a projection of 3D points onto an image plane where the pixel intensity is a function of the measured distance between 3D points and the plane. By assuming that the artifacts are on the ground, they are detected using a Top-Hat of the hole filling algorithm of range images. Then, several features are extracted from the detected connected components and a stepwise forward variable/model selection by using the Wilk's Lambda criterion is performed. Afterward, CCs are classified in four categories (lampposts, pedestrians, cars and others) by using a supervised machine learning method. The proposed method was tested on cloud points of Paris, and have shown satisfactory results on the whole dataset.\n    ",
        "submission_date": "2013-06-13T00:00:00",
        "last_modified_date": "2013-06-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1306.3162",
        "title": "Learning to encode motion using spatio-temporal synchrony",
        "authors": [
            "Kishore Reddy Konda",
            "Roland Memisevic",
            "Vincent Michalski"
        ],
        "abstract": "We consider the task of learning to extract motion from videos. To this end, we show that the detection of spatial transformations can be viewed as the detection of synchrony between the image sequence and a sequence of features undergoing the motion we wish to detect. We show that learning about synchrony is possible using very fast, local learning rules, by introducing multiplicative \"gating\" interactions between hidden units across frames. This makes it possible to achieve competitive performance in a wide variety of motion estimation tasks, using a small fraction of the time required to learn features, and to outperform hand-crafted spatio-temporal features by a large margin. We also show how learning about synchrony can be viewed as performing greedy parameter estimation in the well-known motion energy model.\n    ",
        "submission_date": "2013-06-13T00:00:00",
        "last_modified_date": "2014-02-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1306.3294",
        "title": "Feature Learning by Multidimensional Scaling and its Applications in Object Recognition",
        "authors": [
            "Quan Wang",
            "Kim L. Boyer"
        ],
        "abstract": "We present the MDS feature learning framework, in which multidimensional scaling (MDS) is applied on high-level pairwise image distances to learn fixed-length vector representations of images. The aspects of the images that are captured by the learned features, which we call MDS features, completely depend on what kind of image distance measurement is employed. With properly selected semantics-sensitive image distances, the MDS features provide rich semantic information about the images that is not captured by other feature extraction techniques. In our work, we introduce the iterated Levenberg-Marquardt algorithm for solving MDS, and study the MDS feature learning with IMage Euclidean Distance (IMED) and Spatial Pyramid Matching (SPM) distance. We present experiments on both synthetic data and real images --- the publicly accessible UIUC car image dataset. The MDS features based on SPM distance achieve exceptional performance for the car recognition task.\n    ",
        "submission_date": "2013-06-14T00:00:00",
        "last_modified_date": "2013-06-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1306.3297",
        "title": "Matching objects across the textured-smooth continuum",
        "authors": [
            "Ognjen Arandjelovic"
        ],
        "abstract": "The problem of 3D object recognition is of immense practical importance, with the last decade witnessing a number of breakthroughs in the state of the art. Most of the previous work has focused on the matching of textured objects using local appearance descriptors extracted around salient image points. The recently proposed bag of boundaries method was the first to address directly the problem of matching smooth objects using boundary features. However, no previous work has attempted to achieve a holistic treatment of the problem by jointly using textural and shape features which is what we describe herein. Due to the complementarity of the two modalities, we fuse the corresponding matching scores and learn their relative weighting in a data specific manner by optimizing discriminative performance on synthetically distorted data. For the textural description of an object we adopt a representation in the form of a histogram of SIFT based visual words. Similarly the apparent shape of an object is represented by a histogram of discretized features capturing local shape. On a large public database of a diverse set of objects, the proposed method is shown to outperform significantly both purely textural and purely shape based approaches for matching across viewpoint variation.\n    ",
        "submission_date": "2013-06-14T00:00:00",
        "last_modified_date": "2013-06-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1306.3415",
        "title": "Live-wire 3D medical images segmentation",
        "authors": [
            "Ognjen Arandjelovic"
        ],
        "abstract": "This report describes the design, implementation, evaluation and original enhancements to the Live-Wire method for 2D and 3D image segmentation. Live-Wire 2D employs a semi-automatic paradigm; the user is asked to select a few boundary points of the object to segment, to steer the process in the right direction, while the result is displayed in real time. In our implementation segmentation is extended to three dimensions by performing this process on a slice-by-slice basis. User's time and involvement is further reduced by allowing him to specify object contours in planes orthogonal to the slices. If these planes are chosen strategically, Live-Wire 3D can perform 2D segmentation in the plane of each slice automatically. This report also proposes two improvements to the original method, path heating and a new graph edge feature function based on variance of path properties along the boundary. We show that these improvements lead up to a 33% reduction in interaction with the user, and improved delineation in presence of strong interfering edges.\n    ",
        "submission_date": "2013-06-14T00:00:00",
        "last_modified_date": "2013-06-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1306.3476",
        "title": "Hyperparameter Optimization and Boosting for Classifying Facial Expressions: How good can a \"Null\" Model be?",
        "authors": [
            "James Bergstra",
            "David D. Cox"
        ],
        "abstract": "One of the goals of the ICML workshop on representation and learning is to establish benchmark scores for a new data set of labeled facial expressions. This paper presents the performance of a \"Null\" model consisting of convolutions with random weights, PCA, pooling, normalization, and a linear readout. Our approach focused on hyperparameter optimization rather than novel model components. On the Facial Expression Recognition Challenge held by the Kaggle website, our hyperparameter optimization approach achieved a score of 60% accuracy on the test data. This paper also introduces a new ensemble construction variant that combines hyperparameter optimization with the construction of ensembles. This algorithm constructed an ensemble of four models that scored 65.5% accuracy. These scores rank 12th and 5th respectively among the 56 challenge participants. It is worth noting that our approach was developed prior to the release of the data set, and applied without modification; our strong competition performance suggests that the TPE hyperparameter optimization algorithm and domain expertise encoded in our Null model can generalize to new image classification data sets.\n    ",
        "submission_date": "2013-06-14T00:00:00",
        "last_modified_date": "2013-06-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1306.3560",
        "title": "iCub World: Friendly Robots Help Building Good Vision Data-Sets",
        "authors": [
            "Sean Ryan Fanello",
            "Carlo Ciliberto",
            "Matteo Santoro",
            "Lorenzo Natale",
            "Giorgio Metta",
            "Lorenzo Rosasco",
            "Francesca Odone"
        ],
        "abstract": "In this paper we present and start analyzing the iCub World data-set, an object recognition data-set, we acquired using a Human-Robot Interaction (HRI) scheme and the iCub humanoid robot platform. Our set up allows for rapid acquisition and annotation of data with corresponding ground truth. While more constrained in its scopes -- the iCub world is essentially a robotics research lab -- we demonstrate how the proposed data-set poses challenges to current recognition systems. The iCubWorld data-set is publicly available. The data-set can be downloaded from: ",
        "submission_date": "2013-06-15T00:00:00",
        "last_modified_date": "2013-06-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1306.3828",
        "title": "Non-Uniform Blind Deblurring with a Spatially-Adaptive Sparse Prior",
        "authors": [
            "Haichao Zhang",
            "David Wipf"
        ],
        "abstract": "Typical blur from camera shake often deviates from the standard uniform convolutional script, in part because of problematic rotations which create greater blurring away from some unknown center point. Consequently, successful blind deconvolution requires the estimation of a spatially-varying or non-uniform blur operator. Using ideas from Bayesian inference and convex analysis, this paper derives a non-uniform blind deblurring algorithm with several desirable, yet previously-unexplored attributes. The underlying objective function includes a spatially adaptive penalty which couples the latent sharp image, non-uniform blur operator, and noise level together. This coupling allows the penalty to automatically adjust its shape based on the estimated degree of local blur and image structure such that regions with large blur or few prominent edges are discounted. Remaining regions with modest blur and revealing edges therefore dominate the overall estimation process without explicitly incorporating structure-selection heuristics. The algorithm can be implemented using a majorization-minimization strategy that is virtually parameter free. Detailed theoretical analysis and empirical validation on real images serve to validate the proposed method.\n    ",
        "submission_date": "2013-06-17T00:00:00",
        "last_modified_date": "2013-06-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1306.3855",
        "title": "Two-View Matching with View Synthesis Revisited",
        "authors": [
            "Dmytro Mishkin",
            "Michal Perdoch",
            "Jiri Matas"
        ],
        "abstract": "Wide-baseline matching focussing on problems with extreme viewpoint change is considered. We introduce the use of view synthesis with affine-covariant detectors to solve such problems and show that matching with the Hessian-Affine or MSER detectors outperforms the state-of-the-art ASIFT.\n",
        "submission_date": "2013-06-17T00:00:00",
        "last_modified_date": "2013-11-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1306.3874",
        "title": "Classifying and Visualizing Motion Capture Sequences using Deep Neural Networks",
        "authors": [
            "Kyunghyun Cho",
            "Xi Chen"
        ],
        "abstract": "The gesture recognition using motion capture data and depth sensors has recently drawn more attention in vision recognition. Currently most systems only classify dataset with a couple of dozens different actions. Moreover, feature extraction from the data is often computational complex. In this paper, we propose a novel system to recognize the actions from skeleton data with simple, but effective, features using deep neural networks. Features are extracted for each frame based on the relative positions of joints (PO), temporal differences (TD), and normalized trajectories of motion (NT). Given these features a hybrid multi-layer perceptron is trained, which simultaneously classifies and reconstructs input data. We use deep autoencoder to visualize learnt features, and the experiments show that deep neural networks can capture more discriminative information than, for instance, principal component analysis can. We test our system on a public database with 65 classes and more than 2,000 motion sequences. We obtain an accuracy above 95% which is, to our knowledge, the state of the art result for such a large dataset.\n    ",
        "submission_date": "2013-06-17T00:00:00",
        "last_modified_date": "2014-09-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1306.4079",
        "title": "A Novel Block-DCT and PCA Based Image Perceptual Hashing Algorithm",
        "authors": [
            "Zeng Jie"
        ],
        "abstract": "Image perceptual hashing finds applications in content indexing, large-scale image database management, certification and authentication and digital watermarking. We propose a Block-DCT and PCA based image perceptual hash in this article and explore the algorithm in the application of tamper detection. The main idea of the algorithm is to integrate color histogram and DCT coefficients of image blocks as perceptual feature, then to compress perceptual features as inter-feature with PCA, and to threshold to create a robust hash. The robustness and discrimination properties of the proposed algorithm are evaluated in detail. Our algorithms first construct a secondary image, derived from input image by pseudo-randomly extracting features that approximately capture semi-global geometric characteristics. From the secondary image (which does not perceptually resemble the input), we further extract the final features which can be used as a hash value (and can be further suitably quantized). In this paper, we use spectral matrix invariants as embodied by Singular Value Decomposition. Surprisingly, formation of the secondary image turns out be quite important since it not only introduces further robustness, but also enhances the security properties. Indeed, our experiments reveal that our hashing algorithms extract most of the geometric information from the images and hence are robust to severe perturbations (e.g. up to %50 cropping by area with 20 degree rotations) on images while avoiding misclassification. Experimental results show that the proposed image perceptual hash algorithm can effectively address the tamper detection problem with advantageous robustness and discrimination.\n    ",
        "submission_date": "2013-06-18T00:00:00",
        "last_modified_date": "2013-06-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1306.4345",
        "title": "An Overview of the Research on Texture Based Plant Leaf Classification",
        "authors": [
            "Vishakha Metre",
            "Jayshree Ghorpade"
        ],
        "abstract": "Plant classification has a broad application prospective in agriculture and medicine, and is especially significant to the biology diversity research. As plants are vitally important for environmental protection, it is more important to identify and classify them accurately. Plant leaf classification is a technique where leaf is classified based on its different morphological features. The goal of this paper is to provide an overview of different aspects of texture based plant leaf classification and related things. At last we will be concluding about the efficient method i.e. the method that gives better performance compared to the other methods.\n    ",
        "submission_date": "2013-06-18T00:00:00",
        "last_modified_date": "2013-06-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1306.4478",
        "title": "Finite Element Based Tracking of Deforming Surfaces",
        "authors": [
            "Stefanie Wuhrer",
            "Jochen Lang",
            "Motahareh Tekieh",
            "Chang Shu"
        ],
        "abstract": "We present an approach to robustly track the geometry of an object that deforms over time from a set of input point clouds captured from a single viewpoint. The deformations we consider are caused by applying forces to known locations on the object's surface. Our method combines the use of prior information on the geometry of the object modeled by a smooth template and the use of a linear finite element method to predict the deformation. This allows the accurate reconstruction of both the observed and the unobserved sides of the object. We present tracking results for noisy low-quality point clouds acquired by either a stereo camera or a depth camera, and simulations with point clouds corrupted by different error terms. We show that our method is also applicable to large non-linear deformations.\n    ",
        "submission_date": "2013-06-19T00:00:00",
        "last_modified_date": "2014-10-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1306.4724",
        "title": "Computer simulation based parameter selection for resistance exercise",
        "authors": [
            "Ognjen Arandjelovic"
        ],
        "abstract": "In contrast to most scientific disciplines, sports science research has been characterized by comparatively little effort investment in the development of relevant phenomenological models. Scarcer yet is the application of said models in practice. We present a framework which allows resistance training practitioners to employ a recently proposed neuromuscular model in actual training program design. The first novelty concerns the monitoring aspect of coaching. A method for extracting training performance characteristics from loosely constrained video sequences, effortlessly and with minimal human input, using computer vision is described. The extracted data is subsequently used to fit the underlying neuromuscular model. This is achieved by solving an inverse dynamics problem corresponding to a particular exercise. Lastly, a computer simulation of hypothetical training bouts, using athlete-specific capability parameters, is used to predict the effected adaptation and changes in performance. The software described here allows the practitioner to manipulate hypothetical training parameters and immediately see their effect on predicted adaptation for a specific athlete. Thus, this work presents a holistic view of the monitoring-assessment-adjustment loop.\n    ",
        "submission_date": "2013-06-20T00:00:00",
        "last_modified_date": "2013-06-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1306.4746",
        "title": "Felzenszwalb-Baum-Welch: Event Detection by Changing Appearance",
        "authors": [
            "Daniel Paul Barrett",
            "Jeffrey Mark Siskind"
        ],
        "abstract": "We propose a method which can detect events in videos by modeling the change in appearance of the event participants over time. This method makes it possible to detect events which are characterized not by motion, but by the changing state of the people or objects involved. This is accomplished by using object detectors as output models for the states of a hidden Markov model (HMM). The method allows an HMM to model the sequence of poses of the event participants over time, and is effective for poses of humans and inanimate objects. The ability to use existing object-detection methods as part of an event model makes it possible to leverage ongoing work in the object-detection community. A novel training method uses an EM loop to simultaneously learn the temporal structure and object models automatically, without the need to specify either the individual poses to be modeled or the frames in which they occur. The E-step estimates the latent assignment of video frames to HMM states, while the M-step estimates both the HMM transition probabilities and state output models, including the object detectors, which are trained on the weighted subset of frames assigned to their state. A new dataset was gathered because little work has been done on events characterized by changing object pose, and suitable datasets are not available. Our method produced results superior to that of comparison systems on this dataset.\n    ",
        "submission_date": "2013-06-20T00:00:00",
        "last_modified_date": "2013-06-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1306.4966",
        "title": "Determining Points on Handwritten Mathematical Symbols",
        "authors": [
            "Rui Hu",
            "Stephen M. Watt"
        ],
        "abstract": "In a variety of applications, such as handwritten mathematics and diagram labelling, it is common to have symbols of many different sizes in use and for the writing not to follow simple baselines. In order to understand the scale and relative positioning of individual characters, it is necessary to identify the location of certain expected features. These are typically identified by particular points in the symbols, for example, the baseline of a lower case \"p\" would be identified by the lowest part of the bowl, ignoring the descender. We investigate how to find these special points automatically so they may be used in a number of problems, such as improving two-dimensional mathematical recognition and in handwriting neatening, while preserving the original style.\n    ",
        "submission_date": "2013-06-20T00:00:00",
        "last_modified_date": "2013-06-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1306.5096",
        "title": "Computer Aided ECG Analysis - State of the Art and Upcoming Challenges",
        "authors": [
            "Marko Velic",
            "Ivan Padavic",
            "Sinisa Car"
        ],
        "abstract": "In this paper we present current achievements in computer aided ECG analysis and their applicability in real world medical diagnosis process. Most of the current work is covering problems of removing noise, detecting heartbeats and rhythm-based analysis. There are some advancements in particular ECG segments detection and beat classifications but with limited evaluations and without clinical approvals. This paper presents state of the art advancements in those areas till present day. Besides this short computer science and signal processing literature review, paper covers future challenges regarding the ECG signal morphology analysis deriving from the medical literature review. Paper is concluded with identified gaps in current advancements and testing, upcoming challenges for future research and a bullseye test is suggested for morphology analysis evaluation.\n    ",
        "submission_date": "2013-06-21T00:00:00",
        "last_modified_date": "2013-06-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1306.5151",
        "title": "Fine-Grained Visual Classification of Aircraft",
        "authors": [
            "Subhransu Maji",
            "Esa Rahtu",
            "Juho Kannala",
            "Matthew Blaschko",
            "Andrea Vedaldi"
        ],
        "abstract": "This paper introduces FGVC-Aircraft, a new dataset containing 10,000 images of aircraft spanning 100 aircraft models, organised in a three-level hierarchy. At the finer level, differences between models are often subtle but always visually measurable, making visual recognition challenging but possible. A benchmark is obtained by defining corresponding classification tasks and evaluation protocols, and baseline results are presented. The construction of this dataset was made possible by the work of aircraft enthusiasts, a strategy that can extend to the study of number of other object classes. Compared to the domains usually considered in fine-grained visual classification (FGVC), for example animals, aircraft are rigid and hence less deformable. They, however, present other interesting modes of variation, including purpose, size, designation, structure, historical style, and branding.\n    ",
        "submission_date": "2013-06-21T00:00:00",
        "last_modified_date": "2013-06-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1306.5226",
        "title": "Global registration of multiple point clouds using semidefinite programming",
        "authors": [
            "Kunal N. Chaudhury",
            "Yuehaw Khoo",
            "Amit Singer"
        ],
        "abstract": "Consider $N$ points in $\\mathbb{R}^d$ and $M$ local coordinate systems that are related through unknown rigid transforms. For each point we are given (possibly noisy) measurements of its local coordinates in some of the coordinate systems. Alternatively, for each coordinate system, we observe the coordinates of a subset of the points. The problem of estimating the global coordinates of the $N$ points (up to a rigid transform) from such measurements comes up in distributed approaches to molecular conformation and sensor network localization, and also in computer vision and graphics.\n",
        "submission_date": "2013-06-21T00:00:00",
        "last_modified_date": "2014-12-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1306.5263",
        "title": "Discriminative Training: Learning to Describe Video with Sentences, from Video Described with Sentences",
        "authors": [
            "Haonan Yu",
            "Jeffrey Mark Siskind"
        ],
        "abstract": "We present a method for learning word meanings from complex and realistic video clips by discriminatively training (DT) positive sentential labels against negative ones, and then use the trained word models to generate sentential descriptions for new video. This new work is inspired by recent work which adopts a maximum likelihood (ML) framework to address the same problem using only positive sentential labels. The new method, like the ML-based one, is able to automatically determine which words in the sentence correspond to which concepts in the video (i.e., ground words to meanings) in a weakly supervised fashion. While both DT and ML yield comparable results with sufficient training data, DT outperforms ML significantly with smaller training sets because it can exploit negative training labels to better constrain the learning problem.\n    ",
        "submission_date": "2013-06-21T00:00:00",
        "last_modified_date": "2013-06-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1306.5293",
        "title": "New Approach of Estimating PSNR-B For De-blocked Images",
        "authors": [
            "S. Aruna Mastani",
            "K. Shilpa"
        ],
        "abstract": "Measurement of image quality is very crucial to many image processing applications. Quality metrics are used to measure the quality of improvement in the images after they are processed and compared with the original images. Compression is one of the applications where it is required to monitor the quality of decompressed or decoded image. JPEG compression is the lossy compression which is most prevalent technique for image codecs. But it suffers from blocking artifacts. Various deblocking filters are used to reduce blocking artifacts. The efficiency of deblocking filters which improves visual signals degraded by blocking artifacts from compression will also be studied. Objective quality metrics like PSNR, SSIM, and PSNRB for analyzing the quality of deblocked images will be studied. We introduce a new approach of PSNR-B for analyzing quality of deblocked images. Simulation results show that new approach of PSNR-B called modified PSNR-B. it gives even better results compared to existing well known blockiness specific indices\n    ",
        "submission_date": "2013-06-22T00:00:00",
        "last_modified_date": "2013-06-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1306.5480",
        "title": "Characterizing Ambiguity in Light Source Invariant Shape from Shading",
        "authors": [
            "Benjamin Kunsberg",
            "Steven W. Zucker"
        ],
        "abstract": "Shape from shading is a classical inverse problem in computer vision. This shape reconstruction problem is inherently ill-defined; it depends on the assumed light source direction. We introduce a novel mathematical formulation for calculating local surface shape based on covariant derivatives of the shading flow field, rather than the customary integral minimization or P.D.E approaches. On smooth surfaces, we show second derivatives of brightness are independent of the light sources and can be directly related to surface properties. We use these measurements to define the matching local family of surfaces that can result from any given shading patch, changing the emphasis to characterizing ambiguity in the problem. We give an example of how these local surface ambiguities collapse along certain image contours and how this can be used for the reconstruction problem.\n    ",
        "submission_date": "2013-06-23T00:00:00",
        "last_modified_date": "2013-06-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1306.6058",
        "title": "A maximal-information color to gray conversion method for document images: Toward an optimal grayscale representation for document image binarization",
        "authors": [
            "Reza Farrahi Moghaddam",
            "Shaohua Chen",
            "Rachid Hedjam",
            "Mohamed Cheriet"
        ],
        "abstract": "A novel method to convert color/multi-spectral images to gray-level images is introduced to increase the performance of document binarization methods. The method uses the distribution of the pixel data of the input document image in a color space to find a transformation, called the dual transform, which balances the amount of information on all color channels. Furthermore, in order to reduce the intensity variations on the gray output, a color reduction preprocessing step is applied. Then, a channel is selected as the gray value representation of the document image based on the homogeneity criterion on the text regions. In this way, the proposed method can provide a luminance-independent contrast enhancement. The performance of the method is evaluated against various images from two databases, the ICDAR'03 Robust Reading, the KAIST and the DIBCO'09 datasets, subjectively and objectively with promising results. The ground truth images for the images from the ICDAR'03 Robust Reading dataset have been created manually by the authors.\n    ",
        "submission_date": "2013-06-25T00:00:00",
        "last_modified_date": "2013-06-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1306.6263",
        "title": "Persian Heritage Image Binarization Competition (PHIBC 2012)",
        "authors": [
            "Seyed Morteza Ayatollahi",
            "Hossein Ziaei Nafchi"
        ],
        "abstract": "The first competition on the binarization of historical Persian documents and manuscripts (PHIBC 2012) has been organized in conjunction with the first Iranian conference on pattern recognition and image analysis (PRIA 2013). The main objective of PHIBC 2012 is to evaluate performance of the binarization methodologies, when applied on the Persian heritage images. This paper provides a report on the methodology and performance of the three submitted algorithms based on evaluation measures has been used.\n    ",
        "submission_date": "2013-06-26T00:00:00",
        "last_modified_date": "2016-04-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1306.6269",
        "title": "Active Contour Models for Manifold Valued Image Segmentation",
        "authors": [
            "Sumukh Bansal",
            "Aditya Tatu"
        ],
        "abstract": "Image segmentation is the process of partitioning a image into different regions or groups based on some characteristics like color, texture, motion or shape etc. Active contours is a popular variational method for object segmentation in images, in which the user initializes a contour which evolves in order to optimize an objective function designed such that the desired object boundary is the optimal solution. Recently, imaging modalities that produce Manifold valued images have come up, for example, DT-MRI images, vector fields. The traditional active contour model does not work on such images. In this paper, we generalize the active contour model to work on Manifold valued images. As expected, our algorithm detects regions with similar Manifold values in the image. Our algorithm also produces expected results on usual gray-scale images, since these are nothing but trivial examples of Manifold valued images. As another application of our general active contour model, we perform texture segmentation on gray-scale images by first creating an appropriate Manifold valued image. We demonstrate segmentation results for manifold valued images and texture images.\n    ",
        "submission_date": "2013-06-26T00:00:00",
        "last_modified_date": "2013-11-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1306.6726",
        "title": "A Novel Active Contour Model for Texture Segmentation",
        "authors": [
            "Aditya Tatu",
            "Sumukh Bansal"
        ],
        "abstract": "Texture is intuitively defined as a repeated arrangement of a basic pattern or object in an image. There is no mathematical definition of a texture though. The human visual system is able to identify and segment different textures in a given image. Automating this task for a computer is far from trivial. There are three major components of any texture segmentation algorithm: (a) The features used to represent a texture, (b) the metric induced on this representation space and (c) the clustering algorithm that runs over these features in order to segment a given image into different textures. In this paper, we propose an active contour based novel unsupervised algorithm for texture segmentation. We use intensity covariance matrices of regions as the defining feature of textures and find regions that have the most inter-region dissimilar covariance matrices using active contours. Since covariance matrices are symmetric positive definite, we use geodesic distance defined on the manifold of symmetric positive definite matrices PD(n) as a measure of dissimlarity between such matrices. We demonstrate performance of our algorithm on both artificial and real texture images.\n    ",
        "submission_date": "2013-06-28T00:00:00",
        "last_modified_date": "2013-06-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1306.6842",
        "title": "New Mathematical and Algorithmic Schemes for Pattern Classification with Application to the Identification of Writers of Important Ancient Documents",
        "authors": [
            "Dimitris Arabadjis",
            "Fotios Giannopoulos",
            "Constantin Papaodysseus",
            "Solomon Zannos",
            "Panayiotis Rousopoulos",
            "Michail Panagopoulos",
            "Christopher Blackwell"
        ],
        "abstract": "In this paper, a novel approach is introduced for classifying curves into proper families, according to their similarity. First, a mathematical quantity we call plane curvature is introduced and a number of propositions are stated and proved. Proper similarity measures of two curves are introduced and a subsequent statistical analysis is applied. First, the efficiency of the curve fitting process has been tested on 2 shapes datasets of reference. Next, the methodology has been applied to the very important problem of classifying 23 Byzantine codices and 46 Ancient inscriptions to their writers, thus achieving correct dating of their content. The inscriptions have been attributed to ten individual hands and the Byzantine codices to four writers.\n    ",
        "submission_date": "2013-06-28T00:00:00",
        "last_modified_date": "2013-06-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1307.0036",
        "title": "Increasing Compression Ratio in PNG Images by k-Modulus Method for Image Transformation",
        "authors": [
            "Firas A. Jassim"
        ],
        "abstract": "Image compression is an important filed in image processing. The science welcomes any tinny contribution that may increase the compression ratio by whichever insignificant percentage. Therefore, the essential contribution in this paper is to increase the compression ratio for the well known Portable Network Graphics (PNG) image file format. The contribution starts with converting the original PNG image into k-Modulus Method (k-MM). Practically, taking k equals to ten, and then the pixels in the constructed image will be integers divisible by ten. Since PNG uses Lempel-Ziv compression algorithm, then the ability to reduce file size will increase according to the repetition in pixels in each k-by-k window according to the transformation done by k-MM. Experimental results show that the proposed technique (k-PNG) produces high compression ratio with smaller file size in comparison to the original PNG file.\n    ",
        "submission_date": "2013-06-28T00:00:00",
        "last_modified_date": "2013-06-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1307.0129",
        "title": "Hyperspectral Data Unmixing Using GNMF Method and Sparseness Constraint",
        "authors": [
            "Roozbeh Rajabi",
            "Hassan Ghassemian"
        ],
        "abstract": "Hyperspectral images contain mixed pixels due to low spatial resolution of hyperspectral sensors. Mixed pixels are pixels containing more than one distinct material called endmembers. The presence percentages of endmembers in mixed pixels are called abundance fractions. Spectral unmixing problem refers to decomposing these pixels into a set of endmembers and abundance fractions. Due to nonnegativity constraint on abundance fractions, nonnegative matrix factorization methods (NMF) have been widely used for solving spectral unmixing problem. In this paper we have used graph regularized (GNMF) method with sparseness constraint to unmix hyperspectral data. This method applied on simulated data using AVIRIS Indian Pines dataset and USGS library and results are quantified based on AAD and SAD measures. Results in comparison with other methods show that the proposed method can unmix data more effectively.\n    ",
        "submission_date": "2013-06-29T00:00:00",
        "last_modified_date": "2013-06-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1307.0277",
        "title": "Multilevel Threshold Based Gray Scale Image Segmentation using Cuckoo Search",
        "authors": [
            "Sourav Samantaa",
            "Nilanjan Dey",
            "Poulami Das",
            "Suvojit Acharjee",
            "Sheli Sinha Chaudhuri"
        ],
        "abstract": "Image Segmentation is a technique of partitioning the original image into some distinct classes. Many possible solutions may be available for segmenting an image into a certain number of classes, each one having different quality of segmentation. In our proposed method, multilevel thresholding technique has been used for image segmentation. A new approach of Cuckoo Search (CS) is used for selection of optimal threshold value. In other words, the algorithm is used to achieve the best solution from the initial random threshold values or solutions and to evaluate the quality of a solution correlation function is used. Finally, MSE and PSNR are measured to understand the segmentation quality.\n    ",
        "submission_date": "2013-07-01T00:00:00",
        "last_modified_date": "2013-07-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1307.0426",
        "title": "An Empirical Study into Annotator Agreement, Ground Truth Estimation, and Algorithm Evaluation",
        "authors": [
            "Thomas A. Lampert",
            "Andr\u00e9 Stumpf",
            "Pierre Gan\u00e7arski"
        ],
        "abstract": "Although agreement between annotators has been studied in the past from a statistical viewpoint, little work has attempted to quantify the extent to which this phenomenon affects the evaluation of computer vision (CV) object detection algorithms. Many researchers utilise ground truth (GT) in experiments and more often than not this GT is derived from one annotator's opinion. How does the difference in opinion affect an algorithm's evaluation? Four examples of typical CV problems are chosen, and a methodology is applied to each to quantify the inter-annotator variance and to offer insight into the mechanisms behind agreement and the use of GT. It is found that when detecting linear objects annotator agreement is very low. The agreement in object position, linear or otherwise, can be partially explained through basic image properties. Automatic object detectors are compared to annotator agreement and it is found that a clear relationship exists. Several methods for calculating GTs from a number of annotations are applied and the resulting differences in the performance of the object detectors are quantified. It is found that the rank of a detector is highly dependent upon the method used to form the GT. It is also found that although the STAPLE and LSML GT estimation methods appear to represent the mean of the performance measured using the individual annotations, when there are few annotations, or there is a large variance in them, these estimates tend to degrade. Furthermore, one of the most commonly adopted annotation combination methods--consensus voting--accentuates more obvious features, which results in an overestimation of the algorithm's performance. Finally, it is concluded that in some datasets it may not be possible to state with any confidence that one algorithm outperforms another when evaluating upon one GT and a method for calculating confidence bounds is discussed.\n    ",
        "submission_date": "2013-07-01T00:00:00",
        "last_modified_date": "2016-04-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1307.0776",
        "title": "Regularized Spherical Polar Fourier Diffusion MRI with Optimal Dictionary Learning",
        "authors": [
            "Jian Cheng",
            "Tianzi Jiang",
            "Rachid Deriche",
            "Dinggang Shen",
            "Pew-Thian Yap"
        ],
        "abstract": "Compressed Sensing (CS) takes advantage of signal sparsity or compressibility and allows superb signal reconstruction from relatively few measurements. Based on CS theory, a suitable dictionary for sparse representation of the signal is required. In diffusion MRI (dMRI), CS methods were proposed to reconstruct diffusion-weighted signal and the Ensemble Average Propagator (EAP), and there are two kinds of Dictionary Learning (DL) methods: 1) Discrete Representation DL (DR-DL), and 2) Continuous Representation DL (CR-DL). DR-DL is susceptible to numerical inaccuracy owing to interpolation and regridding errors in a discretized q-space. In this paper, we propose a novel CR-DL approach, called Dictionary Learning - Spherical Polar Fourier Imaging (DL-SPFI) for effective compressed-sensing reconstruction of the q-space diffusion-weighted signal and the EAP. In DL-SPFI, an dictionary that sparsifies the signal is learned from the space of continuous Gaussian diffusion signals. The learned dictionary is then adaptively applied to different voxels using a weighted LASSO framework for robust signal reconstruction. The adaptive dictionary is proved to be optimal. Compared with the start-of-the-art CR-DL and DR-DL methods proposed by Merlet et al. and Bilgic et al., espectively, our work offers the following advantages. First, the learned dictionary is proved to be optimal for Gaussian diffusion signals. Second, to our knowledge, this is the first work to learn a voxel-adaptive dictionary. The importance of the adaptive dictionary in EAP reconstruction will be demonstrated theoretically and empirically. Third, optimization in DL-SPFI is only performed in a small subspace resided by the SPF coefficients, as opposed to the q-space approach utilized by Merlet et al. The experiment results demonstrate the advantages of DL-SPFI over the original SPF basis and Bilgic et al.'s method.\n    ",
        "submission_date": "2013-07-02T00:00:00",
        "last_modified_date": "2013-07-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1307.0937",
        "title": "Extending UML for Conceptual Modeling of Annotation of Medical Images",
        "authors": [
            "Mouhamed Gaith Ayadi",
            "Riadh Bouslimi",
            "Jalel Akaichi"
        ],
        "abstract": "Imaging has occupied a huge role in the management of patients, whether hospitalized or not. Depending on the patients clinical problem, a variety of imaging modalities were available for use. This gave birth of the annotation of medical image process. The annotation is intended to image analysis and solve the problem of semantic gap. The reason for image annotation is due to increase in acquisition of images. Physicians and radiologists feel better while using annotation techniques for faster remedy in surgery and medicine due to the following reasons: giving details to the patients, searching the present and past records from the larger databases, and giving solutions to them in a faster and more accurate way. However, classical conceptual modeling does not incorporate the specificity of medical domain specially the annotation of medical image. The design phase is the most important activity in the successful building of annotation process. For this reason, we focus in this paper on presenting the conceptual modeling of the annotation of medical image by defining a new profile using the StarUML extensibility mechanism.\n    ",
        "submission_date": "2013-07-03T00:00:00",
        "last_modified_date": "2013-07-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1307.0998",
        "title": "A Unified Framework of Elementary Geometric Transformation Representation",
        "authors": [
            "F. Lu",
            "Z. Chen"
        ],
        "abstract": "As an extension of projective homology, stereohomology is proposed via an extension of Desargues theorem and the extended Desargues configuration. Geometric transformations such as reflection, translation, central symmetry, central projection, parallel projection, shearing, central dilation, scaling, and so on are all included in stereohomology and represented as Householder-Chen elementary matrices. Hence all these geometric transformations are called elementary. This makes it possible to represent these elementary geometric transformations in homogeneous square matrices independent of a particular choice of coordinate system.\n    ",
        "submission_date": "2013-07-03T00:00:00",
        "last_modified_date": "2014-07-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1307.1166",
        "title": "A Novel Robust Method to Add Watermarks to Bitmap Images by Fading Technique",
        "authors": [
            "Firas A. Jassim"
        ],
        "abstract": "Digital water marking is one of the essential fields in image security and copyright protection. The proposed technique in this paper was based on the principle of protecting images by hide an invisible watermark in the image. The technique starts with merging the cover image and the watermark image with suitable ratios, i.e., 99% from the cover image will be merged with 1% from the watermark image. Technically, the fading process is irreversible but with the proposed technique, the probability to reconstruct the original watermark image is great. There is no perceptible difference between the original and watermarked image by human eye. The experimental results show that the proposed technique proven its ability to hide images that have the same size of the cover image. Three performance measures were implemented to support the proposed techniques which are MSE, PSNR, and SSIM. Fortunately, all the three measures have excellent values.\n    ",
        "submission_date": "2013-07-03T00:00:00",
        "last_modified_date": "2013-07-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1307.1303",
        "title": "Submodularity of a Set Label Disagreement Function",
        "authors": [
            "Toufiq Parag"
        ],
        "abstract": "A set label disagreement function is defined over the number of variables that deviates from the dominant label. The dominant label is the value assumed by the largest number of variables within a set of binary variables. The submodularity of a certain family of set label disagreement function is discussed in this manuscript. Such disagreement function could be utilized as a cost function in combinatorial optimization approaches for problems defined over hypergraphs.\n    ",
        "submission_date": "2013-07-02T00:00:00",
        "last_modified_date": "2013-07-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1307.1437",
        "title": "Toward Guaranteed Illumination Models for Non-Convex Objects",
        "authors": [
            "Yuqian Zhang",
            "Cun Mu",
            "Han-wen Kuo",
            "John Wright"
        ],
        "abstract": "Illumination variation remains a central challenge in object detection and recognition. Existing analyses of illumination variation typically pertain to convex, Lambertian objects, and guarantee quality of approximation in an average case sense. We show that it is possible to build V(vertex)-description convex cone models with worst-case performance guarantees, for non-convex Lambertian objects. Namely, a natural verification test based on the angle to the constructed cone guarantees to accept any image which is sufficiently well-approximated by an image of the object under some admissible lighting condition, and guarantees to reject any image that does not have a sufficiently good approximation. The cone models are generated by sampling point illuminations with sufficient density, which follows from a new perturbation bound for point images in the Lambertian model. As the number of point images required for guaranteed verification may be large, we introduce a new formulation for cone preserving dimensionality reduction, which leverages tools from sparse and low-rank decomposition to reduce the complexity, while controlling the approximation error with respect to the original cone.\n    ",
        "submission_date": "2013-07-04T00:00:00",
        "last_modified_date": "2013-07-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1307.1739",
        "title": "Anatomical Feature-guided Volumeric Registration of Multimodal Prostate MRI",
        "authors": [
            "Xin Zhao",
            "Arie Kaufman"
        ],
        "abstract": "Radiological imaging of prostate is becoming more popular among researchers and clinicians in searching for diseases, primarily cancer. Scans might be acquired at different times, with patient movement between scans, or with different equipment, resulting in multiple datasets that need to be registered. For this issue, we introduce a registration method using anatomical feature-guided mutual information. Prostate scans of the same patient taken in three different orientations are first aligned for the accurate detection of anatomical features in 3D. Then, our pipeline allows for multiple modalities registration through the use of anatomical features, such as the interior urethra of prostate and gland utricle, in a bijective way. The novelty of this approach is the application of anatomical features as the pre-specified corresponding landmarks for prostate registration. We evaluate the registration results through both artificial and clinical datasets. Registration accuracy is evaluated by performing statistical analysis of local intensity differences or spatial differences of anatomical landmarks between various MR datasets. Evaluation results demonstrate that our method statistics-significantly improves the quality of registration. Although this strategy is tested for MRI-guided brachytherapy, the preliminary results from these experiments suggest that it can be also applied to other settings such as transrectal ultrasound-guided or CT-guided therapy, where the integration of preoperative MRI may have a significant impact upon treatment planning and guidance.\n    ",
        "submission_date": "2013-07-06T00:00:00",
        "last_modified_date": "2013-11-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1307.2434",
        "title": "Major Limitations of Satellite images",
        "authors": [
            "Firouz A. Al-Wassai",
            "N.V. Kalyankar"
        ],
        "abstract": "Remote sensing has proven to be a powerful tool for the monitoring of the Earth surface to improve our perception of our surroundings has led to unprecedented developments in sensor and information technologies. However, technologies for effective use of the data and for extracting useful information from the data of Remote sensing are still very limited since no single sensor combines the optimal spectral, spatial and temporal resolution. This paper briefly reviews the limitations of satellite remote sensing. Also, reviews on the problems of image fusion techniques. The conclusion of this, According to literature, the remote sensing is still the lack of software tools for effective information extraction from remote sensing data. The trade-off in spectral and spatial resolution will remain and new advanced data fusion approaches are needed to make optimal use of remote sensors for extract the most useful information.\n    ",
        "submission_date": "2013-07-09T00:00:00",
        "last_modified_date": "2013-07-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1307.2440",
        "title": "Image Fusion Technologies In Commercial Remote Sensing Packages",
        "authors": [
            "Firouz Abdullah Al-Wassai",
            "N.V. Kalyankar"
        ],
        "abstract": "Several remote sensing software packages are used to the explicit purpose of analyzing and visualizing remotely sensed data, with the developing of remote sensing sensor technologies from last ten years. Accord-ing to literature, the remote sensing is still the lack of software tools for effective information extraction from remote sensing data. So, this paper provides a state-of-art of multi-sensor image fusion technologies as well as review on the quality evaluation of the single image or fused images in the commercial remote sensing pack-ages. It also introduces program (ALwassaiProcess) developed for image fusion and classification.\n    ",
        "submission_date": "2013-07-09T00:00:00",
        "last_modified_date": "2013-07-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1307.2457",
        "title": "Detection of Outer Rotations on 3D-Vector Fields with Iterative Geometric Correlation and its Efficiency",
        "authors": [
            "Roxana Bujack",
            "Gerik Scheuermann",
            "Eckhard Hitzer"
        ],
        "abstract": "Correlation is a common technique for the detection of shifts. Its generalization to the multidimensional geometric correlation in Clifford algebras has been proven a useful tool for color image processing, because it additionally contains information about a rotational misalignment. But so far the exact correction of a three-dimensional outer rotation could only be achieved in certain special cases. In this paper we prove that applying the geometric correlation iteratively has the potential to detect the outer rotational misalignment for arbitrary three-dimensional vector fields. We further present the explicit iterative algorithm, analyze its efficiency detecting the rotational misalignment in the color space of a color image. The experiments suggest a method for the acceleration of the algorithm, which is practically tested with great success.\n    ",
        "submission_date": "2013-06-10T00:00:00",
        "last_modified_date": "2013-06-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1307.2965",
        "title": "Semantic Context Forests for Learning-Based Knee Cartilage Segmentation in 3D MR Images",
        "authors": [
            "Quan Wang",
            "Dijia Wu",
            "Le Lu",
            "Meizhu Liu",
            "Kim L. Boyer",
            "Shaohua Kevin Zhou"
        ],
        "abstract": "The automatic segmentation of human knee cartilage from 3D MR images is a useful yet challenging task due to the thin sheet structure of the cartilage with diffuse boundaries and inhomogeneous intensities. In this paper, we present an iterative multi-class learning method to segment the femoral, tibial and patellar cartilage simultaneously, which effectively exploits the spatial contextual constraints between bone and cartilage, and also between different cartilages. First, based on the fact that the cartilage grows in only certain area of the corresponding bone surface, we extract the distance features of not only to the surface of the bone, but more informatively, to the densely registered anatomical landmarks on the bone surface. Second, we introduce a set of iterative discriminative classifiers that at each iteration, probability comparison features are constructed from the class confidence maps derived by previously learned classifiers. These features automatically embed the semantic context information between different cartilages of interest. Validated on a total of 176 volumes from the Osteoarthritis Initiative (OAI) dataset, the proposed approach demonstrates high robustness and accuracy of segmentation in comparison with existing state-of-the-art MR cartilage segmentation methods.\n    ",
        "submission_date": "2013-07-11T00:00:00",
        "last_modified_date": "2014-04-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1307.2982",
        "title": "Fast Exact Search in Hamming Space with Multi-Index Hashing",
        "authors": [
            "Mohammad Norouzi",
            "Ali Punjani",
            "David J. Fleet"
        ],
        "abstract": "There is growing interest in representing image data and feature descriptors using compact binary codes for fast near neighbor search. Although binary codes are motivated by their use as direct indices (addresses) into a hash table, codes longer than 32 bits are not being used as such, as it was thought to be ineffective. We introduce a rigorous way to build multiple hash tables on binary code substrings that enables exact k-nearest neighbor search in Hamming space. The approach is storage efficient and straightforward to implement. Theoretical analysis shows that the algorithm exhibits sub-linear run-time behavior for uniformly distributed codes. Empirical results show dramatic speedups over a linear scan baseline for datasets of up to one billion codes of 64, 128, or 256 bits.\n    ",
        "submission_date": "2013-07-11T00:00:00",
        "last_modified_date": "2014-04-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1307.2997",
        "title": "Conversion of Braille to Text in English, Hindi and Tamil Languages",
        "authors": [
            "S. Padmavathi",
            "Manojna K.S.S",
            "S. Sphoorthy Reddy",
            "D. Meenakshy"
        ],
        "abstract": "The Braille system has been used by the visually impaired for reading and writing. Due to limited availability of the Braille text books an efficient usage of the books becomes a necessity. This paper proposes a method to convert a scanned Braille document to text which can be read out to many through the computer. The Braille documents are pre processed to enhance the dots and reduce the noise. The Braille cells are segmented and the dots from each cell is extracted and converted in to a number sequence. These are mapped to the appropriate alphabets of the language. The converted text is spoken out through a speech synthesizer. The paper also provides a mechanism to type the Braille characters through the number pad of the keyboard. The typed Braille character is mapped to the alphabet and spoken out. The Braille cell has a standard representation but the mapping differs for each language. In this paper mapping of English, Hindi and Tamil are considered.\n    ",
        "submission_date": "2013-07-11T00:00:00",
        "last_modified_date": "2013-07-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1307.3043",
        "title": "A two-layer Conditional Random Field for the classification of partially occluded objects",
        "authors": [
            "Sergey Kosov",
            "Pushmeet Kohli",
            "Franz Rottensteiner",
            "Christian Heipke"
        ],
        "abstract": "Conditional Random Fields (CRF) are among the most popular techniques for image labelling because of their flexibility in modelling dependencies between the labels and the image features. This paper proposes a novel CRF-framework for image labeling problems which is capable to classify partially occluded objects. Our approach is evaluated on aerial near-vertical images as well as on urban street-view images and compared with another methods.\n    ",
        "submission_date": "2013-07-11T00:00:00",
        "last_modified_date": "2013-09-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1307.3054",
        "title": "Contrast Enhancement And Brightness Preservation Using Multi- Decomposition Histogram Equalization",
        "authors": [
            "Sayali Nimkar",
            "Sanal Varghese",
            "Sucheta Shrivastava"
        ],
        "abstract": "Histogram Equalization (HE) has been an essential addition to the Image Enhancement world. Enhancement techniques like Classical Histogram Equalization (CHE), Adaptive Histogram Equalization (ADHE), Bi-Histogram Equalization (BHE) and Recursive Mean Separate Histogram Equalization (RMSHE) methods enhance contrast, however, brightness is not well preserved with these methods, which gives an unpleasant look to the final image obtained. Thus, we introduce a novel technique Multi-Decomposition Histogram Equalization (MDHE) to eliminate the drawbacks of the earlier methods. In MDHE, we have decomposed the input sixty-four parts, applied CHE in each of the sub-images and then finally interpolated them in correct order. The final image after MDHE results in contrast enhanced and brightness preserved image compared to all other techniques mentioned above. We have calculated the various parameters like PSNR, SNR, RMSE, MSE, etc. for every technique. Our results are well supported by bar graphs, histograms and the parameter calculations at the end.\n    ",
        "submission_date": "2013-07-11T00:00:00",
        "last_modified_date": "2013-07-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1307.3271",
        "title": "Fuzzy Fibers: Uncertainty in dMRI Tractography",
        "authors": [
            "Thomas Schultz",
            "Anna Vilanova",
            "Ralph Brecheisen",
            "Gordon Kindlmann"
        ],
        "abstract": "Fiber tracking based on diffusion weighted Magnetic Resonance Imaging (dMRI) allows for noninvasive reconstruction of fiber bundles in the human brain. In this chapter, we discuss sources of error and uncertainty in this technique, and review strategies that afford a more reliable interpretation of the results. This includes methods for computing and rendering probabilistic tractograms, which estimate precision in the face of measurement noise and artifacts. However, we also address aspects that have received less attention so far, such as model selection, partial voluming, and the impact of parameters, both in preprocessing and in fiber tracking itself. We conclude by giving impulses for future research.\n    ",
        "submission_date": "2013-07-11T00:00:00",
        "last_modified_date": "2013-07-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1307.3439",
        "title": "Speedy Object Detection based on Shape",
        "authors": [
            "Y. Jayanta Singh",
            "Shalu Gupta"
        ],
        "abstract": "This study is a part of design of an audio system for in-house object detection system for visually impaired, low vision personnel by birth or by an accident or due to old age. The input of the system will be scene and output as audio. Alert facility is provided based on severity levels of the objects (snake, broke glass etc) and also during difficulties. The study proposed techniques to provide speedy detection of objects based on shapes and its scale. Features are extraction to have minimum spaces using dynamic scaling. From a scene, clusters of objects are formed based on the scale and shape. Searching is performed among the clusters initially based on the shape, scale, mean cluster value and index of object(s). The minimum operation to detect the possible shape of the object is performed. In case the object does not have a likely matching shape, scale etc, then the several operations required for an object detection will not perform; instead, it will declared as a new object. In such way, this study finds a speedy way of detecting objects.\n    ",
        "submission_date": "2013-07-12T00:00:00",
        "last_modified_date": "2013-07-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1307.3581",
        "title": "Image color transfer to evoke different emotions based on color combinations",
        "authors": [
            "Li He",
            "Hairong Qi",
            "Russell Zaretzki"
        ],
        "abstract": "In this paper, a color transfer framework to evoke different emotions for images based on color combinations is proposed. The purpose of this color transfer is to change the \"look and feel\" of images, i.e., evoking different emotions. Colors are confirmed as the most attractive factor in images. In addition, various studies in both art and science areas have concluded that other than single color, color combinations are necessary to evoke specific emotions. Therefore, we propose a novel framework to transfer color of images based on color combinations, using a predefined color emotion model. The contribution of this new framework is three-fold. First, users do not need to provide reference images as used in traditional color transfer algorithms. In most situations, users may not have enough aesthetic knowledge or path to choose desired reference images. Second, because of the usage of color combinations instead of single color for emotions, a new color transfer algorithm that does not require an image library is proposed. Third, again because of the usage of color combinations, artifacts that are normally seen in traditional frameworks using single color are avoided. We present encouraging results generated from this new framework and its potential in several possible applications including color transfer of photos and paintings.\n    ",
        "submission_date": "2013-07-12T00:00:00",
        "last_modified_date": "2014-11-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1307.3759",
        "title": "A Minimal Six-Point Auto-Calibration Algorithm",
        "authors": [
            "Evgeniy Martyushev"
        ],
        "abstract": "A non-iterative auto-calibration algorithm is presented. It deals with a minimal set of six scene points in three views taken by a camera with fixed but unknown intrinsic parameters. Calibration is based on the image correspondences only. The algorithm is implemented and validated on synthetic image data.\n    ",
        "submission_date": "2013-07-14T00:00:00",
        "last_modified_date": "2013-07-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1307.4516",
        "title": "Mammogram Edge Detection Using Hybrid Soft Computing Methods",
        "authors": [
            "I. Laurence Aroquiaraj",
            "K. Thangavel"
        ],
        "abstract": "Image segmentation is a crucial step in a wide range of method image processing systems. It is useful in visualization of the different objects present in the image. In spite of the several methods available in the literature, image segmentation still a challenging problem in most of image processing applications. The challenge comes from the fuzziness of image objects and the overlapping of the different regions. Detection of edges in an image is a very important step towards understanding image features. There are large numbers of edge detection operators available, each designed to be sensitive to certain types of edges. The Quality of edge detection can be measured from several criteria objectively. Some criteria are proposed in terms of mathematical measurement, some of them are based on application and implementation requirements. Since edges often occur at image locations representing object boundaries, edge detection is extensively used in image segmentation when images are divided into areas corresponding to different objects. This can be used specifically for enhancing the tumor area in mammographic images. Different methods are available for edge detection like Roberts, Sobel, Prewitt, Canny, Log edge operators. In this paper a novel algorithms for edge detection has been proposed for mammographic images. Breast boundary, pectoral region and tumor location can be seen clearly by using this method. For comparison purpose Roberts, Sobel, Prewitt, Canny, Log edge operators are used and their results are displayed. Experimental results demonstrate the effectiveness of the proposed approach.\n    ",
        "submission_date": "2013-07-17T00:00:00",
        "last_modified_date": "2013-07-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1307.4592",
        "title": "Processing stationary noise: model and parameter selection in variational methods",
        "authors": [
            "J\u00e9r\u00f4me Fehrenbach",
            "Pierre Weiss"
        ],
        "abstract": "Additive or multiplicative stationary noise recently became an important issue in applied fields such as microscopy or satellite imaging. Relatively few works address the design of dedicated denoising methods compared to the usual white noise setting. We recently proposed a variational algorithm to tackle this issue. In this paper, we analyze this problem from a statistical point of view and provide deterministic properties of the solutions of the associated variational problems. In the first part of this work, we demonstrate that in many practical problems, the noise can be assimilated to a colored Gaussian noise. We provide a quantitative measure of the distance between a stationary process and the corresponding Gaussian process. In the second part, we focus on the Gaussian setting and analyze denoising methods which consist of minimizing the sum of a total variation term and an $l^2$ data fidelity term. While the constrained formulation of this problem allows to easily tune the parameters, the Lagrangian formulation can be solved more efficiently since the problem is strongly convex. Our second contribution consists in providing analytical values of the regularization parameter in order to approximately satisfy Morozov's discrepancy principle.\n    ",
        "submission_date": "2013-07-17T00:00:00",
        "last_modified_date": "2013-07-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1307.4717",
        "title": "Content Based Image Retrieval System using Feature Classification with Modified KNN Algorithm",
        "authors": [
            "T. Dharani",
            "I. Laurence Aroquiaraj"
        ],
        "abstract": "Feature means countenance, remote sensing scene objects with similar characteristics, associated to interesting scene elements in the image formation process. They are classified into three types in image processing, that is low, middle and high. Low level features are color, texture and middle level feature is shape and high level feature is semantic gap of objects. An image retrieval system is a computer system for browsing, searching and retrieving images from a large image database. Content Based Image Retrieval is a technique which uses visual features of image such as color, shape, texture to search user required image from large image database according to user requests in the form of a query. MKNN is an enhancing method of KNN. The proposed KNN classification is called MKNN. MKNN contains two parts for processing, they are validity of the train samples and applying weighted KNN. The validity of each point is computed according to its neighbors. In our proposal, Modified K-Nearest Neighbor can be considered a kind of weighted KNN so that the query label is approximated by weighting the neighbors of the query.\n    ",
        "submission_date": "2013-07-17T00:00:00",
        "last_modified_date": "2013-07-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1307.4990",
        "title": "Video Text Localization using Wavelet and Shearlet Transforms",
        "authors": [
            "Purnendu Banerjee",
            "B. B. Chaudhuri"
        ],
        "abstract": "Text in video is useful and important in indexing and retrieving the video documents efficiently and accurately. In this paper, we present a new method of text detection using a combined dictionary consisting of wavelets and a recently introduced transform called shearlets. Wavelets provide optimally sparse expansion for point-like structures and shearlets provide optimally sparse expansions for curve-like structures. By combining these two features we have computed a high frequency sub-band to brighten the text part. Then K-means clustering is used for obtaining text pixels from the Standard Deviation (SD) of combined coefficient of wavelets and shearlets as well as the union of wavelets and shearlets features. Text parts are obtained by grouping neighboring regions based on geometric properties of the classified output frame of unsupervised K-means classification. The proposed method tested on a standard as well as newly collected database shows to be superior to some existing methods.\n    ",
        "submission_date": "2013-07-18T00:00:00",
        "last_modified_date": "2013-11-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1307.5102",
        "title": "Automated Defect Localization via Low Rank Plus Outlier Modeling of Propagating Wavefield Data",
        "authors": [
            "Stefano Gonella",
            "Jarvis D. Haupt"
        ],
        "abstract": "This work proposes an agnostic inference strategy for material diagnostics, conceived within the context of laser-based non-destructive evaluation methods, which extract information about structural anomalies from the analysis of acoustic wavefields measured on the structure's surface by means of a scanning laser interferometer. The proposed approach couples spatiotemporal windowing with low rank plus outlier modeling, to identify a priori unknown deviations in the propagating wavefields caused by material inhomogeneities or defects, using virtually no knowledge of the structural and material properties of the medium. This characteristic makes the approach particularly suitable for diagnostics scenarios where the mechanical and material models are complex, unknown, or unreliable. We demonstrate our approach in a simulated environment using benchmark point and line defect localization problems based on propagating flexural waves in a thin plate.\n    ",
        "submission_date": "2013-07-19T00:00:00",
        "last_modified_date": "2013-07-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1307.5161",
        "title": "Random Binary Mappings for Kernel Learning and Efficient SVM",
        "authors": [
            "Gemma Roig",
            "Xavier Boix",
            "Luc Van Gool"
        ],
        "abstract": "Support Vector Machines (SVMs) are powerful learners that have led to state-of-the-art results in various computer vision problems. SVMs suffer from various drawbacks in terms of selecting the right kernel, which depends on the image descriptors, as well as computational and memory efficiency. This paper introduces a novel kernel, which serves such issues well. The kernel is learned by exploiting a large amount of low-complex, randomized binary mappings of the input feature. This leads to an efficient SVM, while also alleviating the task of kernel selection. We demonstrate the capabilities of our kernel on 6 standard vision benchmarks, in which we combine several common image descriptors, namely histograms (Flowers17 and Daimler), attribute-like descriptors (UCI, OSR, and a-VOC08), and Sparse Quantization (ImageNet). Results show that our kernel learning adapts well to the different descriptors types, achieving the performance of the kernels specifically tuned for each image descriptor, and with similar evaluation cost as efficient SVM methods.\n    ",
        "submission_date": "2013-07-19T00:00:00",
        "last_modified_date": "2014-03-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1307.5348",
        "title": "Tensor-based formulation and nuclear norm regularization for multi-energy computed tomography",
        "authors": [
            "Oguz Semerci",
            "Ning Hao",
            "Misha E. Kilmer",
            "Eric L. Miller"
        ],
        "abstract": "The development of energy selective, photon counting X-ray detectors allows for a wide range of new possibilities in the area of computed tomographic image formation. Under the assumption of perfect energy resolution, here we propose a tensor-based iterative algorithm that simultaneously reconstructs the X-ray attenuation distribution for each energy. We use a multi-linear image model rather than a more standard \"stacked vector\" representation in order to develop novel tensor-based regularizers. Specifically, we model the multi-spectral unknown as a 3-way tensor where the first two dimensions are space and the third dimension is energy. This approach allows for the design of tensor nuclear norm regularizers, which like its two dimensional counterpart, is a convex function of the multi-spectral unknown. The solution to the resulting convex optimization problem is obtained using an alternating direction method of multipliers (ADMM) approach. Simulation results shows that the generalized tensor nuclear norm can be used as a stand alone regularization technique for the energy selective (spectral) computed tomography (CT) problem and when combined with total variation regularization it enhances the regularization capabilities especially at low energy images where the effects of noise are most prominent.\n    ",
        "submission_date": "2013-07-19T00:00:00",
        "last_modified_date": "2013-07-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1307.5551",
        "title": "Regularized Discrete Optimal Transport",
        "authors": [
            "Sira Ferradans",
            "Nicolas Papadakis",
            "Gabriel Peyr\u00e9",
            "Jean-Fran\u00e7ois Aujol"
        ],
        "abstract": "This article introduces a generalization of the discrete optimal transport, with applications to color image manipulations. This new formulation includes a relaxation of the mass conservation constraint and a regularization term. These two features are crucial for image processing tasks, which necessitate to take into account families of multimodal histograms, with large mass variation across modes. \n",
        "submission_date": "2013-07-21T00:00:00",
        "last_modified_date": "2013-07-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1307.5591",
        "title": "A Novel Equation based Classifier for Detecting Human in Images",
        "authors": [
            "Subra Mukherjee",
            "Karen Das"
        ],
        "abstract": "Shape based classification is one of the most challenging tasks in the field of computer vision. Shapes play a vital role in object recognition. The basic shapes in an image can occur in varying scale, position and orientation. And specially when detecting human, the task becomes more challenging owing to the largely varying size, shape, posture and clothing of human. So, in our work we detect human, based on the head-shoulder shape as it is the most unvarying part of human body. Here, firstly a new and a novel equation named as the Omega Equation that describes the shape of human head-shoulder is developed and based on this equation, a classifier is designed particularly for detecting human presence in a scene. The classifier detects human by analyzing some of the discriminative features of the values of the parameters obtained from the Omega equation. The proposed method has been tested on a variety of shape dataset taking into consideration the complexities of human head-shoulder shape. In all the experiments the proposed method demonstrated satisfactory results.\n    ",
        "submission_date": "2013-07-22T00:00:00",
        "last_modified_date": "2013-07-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1307.5653",
        "title": "Online Tracking Parameter Adaptation based on Evaluation",
        "authors": [
            "Duc Phu Chau",
            "Julien Badie",
            "Fran\u00e7ois Bremond",
            "Monique Thonnat"
        ],
        "abstract": "Parameter tuning is a common issue for many tracking algorithms. In order to solve this problem, this paper proposes an online parameter tuning to adapt a tracking algorithm to various scene contexts. In an offline training phase, this approach learns how to tune the tracker parameters to cope with different contexts. In the online control phase, once the tracking quality is evaluated as not good enough, the proposed approach computes the current context and tunes the tracking parameters using the learned values. The experimental results show that the proposed approach improves the performance of the tracking algorithm and outperforms recent state of the art trackers. This paper brings two contributions: (1) an online tracking evaluation, and (2) a method to adapt online tracking parameters to scene contexts.\n    ",
        "submission_date": "2013-07-22T00:00:00",
        "last_modified_date": "2013-07-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1307.5691",
        "title": "A study of parameters affecting visual saliency assessment",
        "authors": [
            "Nicolas Riche",
            "Matthieu Duvinage",
            "Matei Mancas",
            "Bernard Gosselin",
            "Thierry Dutoit"
        ],
        "abstract": "Since the early 2000s, computational visual saliency has been a very active research area. Each year, more and more new models are published in the main computer vision conferences. Nowadays, one of the big challenges is to find a way to fairly evaluate all of these models. In this paper, a new framework is proposed to assess models of visual saliency. This evaluation is divided into three experiments leading to the proposition of a new evaluation framework. Each experiment is based on a basic question: 1) there are two ground truths for saliency evaluation: what are the differences between eye fixations and manually segmented salient regions?, 2) the properties of the salient regions: for example, do large, medium and small salient regions present different difficulties for saliency models? and 3) the metrics used to assess saliency models: what advantages would there be to mix them with PCA? Statistical analysis is used here to answer each of these three questions.\n    ",
        "submission_date": "2013-07-22T00:00:00",
        "last_modified_date": "2013-07-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1307.5693",
        "title": "Visual saliency estimation by integrating features using multiple kernel learning",
        "authors": [
            "Yasin Kavak",
            "Erkut Erdem",
            "Aykut Erdem"
        ],
        "abstract": "In the last few decades, significant achievements have been attained in predicting where humans look at images through different computational models. However, how to determine contributions of different visual features to overall saliency still remains an open problem. To overcome this issue, a recent class of models formulates saliency estimation as a supervised learning problem and accordingly apply machine learning techniques. In this paper, we also address this challenging problem and propose to use multiple kernel learning (MKL) to combine information coming from different feature dimensions and to perform integration at an intermediate level. Besides, we suggest to use responses of a recently proposed filterbank of object detectors, known as Object-Bank, as additional semantic high-level features. Here we show that our MKL-based framework together with the proposed object-specific features provide state-of-the-art performance as compared to SVM or AdaBoost-based saliency models.\n    ",
        "submission_date": "2013-07-22T00:00:00",
        "last_modified_date": "2013-07-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1307.5702",
        "title": "Is Bottom-Up Attention Useful for Scene Recognition?",
        "authors": [
            "Samuel F. Dodge",
            "Lina J. Karam"
        ],
        "abstract": "The human visual system employs a selective attention mechanism to understand the visual world in an eficient manner. In this paper, we show how computational models of this mechanism can be exploited for the computer vision application of scene recognition. First, we consider saliency weighting and saliency pruning, and provide a comparison of the performance of different attention models in these approaches in terms of classification accuracy. Pruning can achieve a high degree of computational savings without significantly sacrificing classification accuracy. In saliency weighting, however, we found that classification performance does not improve. In addition, we present a new method to incorporate salient and non-salient regions for improved classification accuracy. We treat the salient and non-salient regions separately and combine them using Multiple Kernel Learning. We evaluate our approach using the UIUC sports dataset and find that with a small training size, our method improves upon the classification accuracy of the baseline bag of features approach.\n    ",
        "submission_date": "2013-07-22T00:00:00",
        "last_modified_date": "2013-07-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1307.5710",
        "title": "Saliency-Guided Perceptual Grouping Using Motion Cues in Region-Based Artificial Visual Attention",
        "authors": [
            "Jan T\u007f\u00fcnnermann",
            "Dieter Enns",
            "B\u007f\u00e4rbel Mertsching"
        ],
        "abstract": "Region-based artificial attention constitutes a framework for bio-inspired attentional processes on an intermediate abstraction level for the use in computer vision and mobile robotics. Segmentation algorithms produce regions of coherently colored pixels. These serve as proto-objects on which the attentional processes determine image portions of relevance. A single region---which not necessarily represents a full object---constitutes the focus of attention. For many post-attentional tasks, however, such as identifying or tracking objects, single segments are not sufficient. Here, we present a saliency-guided approach that groups regions that potentially belong to the same object based on proximity and similarity of motion. We compare our results to object selection by thresholding saliency maps and a further attention-guided strategy.\n    ",
        "submission_date": "2013-07-22T00:00:00",
        "last_modified_date": "2013-07-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1307.5713",
        "title": "Understanding Humans' Strategies in Maze Solving",
        "authors": [
            "Min Zhao",
            "Andre G. Marquez"
        ],
        "abstract": "Navigating through a visual maze relies on the strategic use of eye movements to select and identify the route. When navigating the maze, there are trade-offs between exploring to the environment and relying on memory. This study examined strategies used to navigating through novel and familiar mazes that were viewed from above and traversed by a mouse cursor. Eye and mouse movements revealed two modes that almost never occurred concurrently: exploration and guidance. Analyses showed that people learned mazes and were able to devise and carry out complex, multi-faceted strategies that traded-off visual exploration against active motor performance. These strategies took into account available visual information, memory, confidence, the estimated cost in time for exploration, and idiosyncratic tolerance for error. Understanding the strategies humans used for maze solving is valuable for applications in cognitive neuroscience as well as in AI, robotics and human-robot interactions.\n    ",
        "submission_date": "2013-07-22T00:00:00",
        "last_modified_date": "2013-07-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1307.5748",
        "title": "Appearance Descriptors for Person Re-identification: a Comprehensive Review",
        "authors": [
            "Riccardo Satta"
        ],
        "abstract": "In video-surveillance, person re-identification is the task of recognising whether an individual has already been observed over a network of cameras. Typically, this is achieved by exploiting the clothing appearance, as classical biometric traits like the face are impractical in real-world video surveillance scenarios. Clothing appearance is represented by means of low-level \\textit{local} and/or \\textit{global} features of the image, usually extracted according to some part-based body model to treat different body parts (e.g. torso and legs) independently. This paper provides a comprehensive review of current approaches to build appearance descriptors for person re-identification. The most relevant techniques are described in detail, and categorised according to the body models and features used. The aim of this work is to provide a structured body of knowledge and a starting point for researchers willing to conduct novel investigations on this challenging topic.\n    ",
        "submission_date": "2013-07-22T00:00:00",
        "last_modified_date": "2013-07-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1307.5800",
        "title": "An Adaptive GMM Approach to Background Subtraction for Application in Real Time Surveillance",
        "authors": [
            "Subra Mukherjee",
            "Karen Das"
        ],
        "abstract": "Efficient security management has become an important parameter in todays world. As the problem is growing, there is an urgent need for the introduction of advanced technology and equipment to improve the state-of art of surveillance. In this paper we propose a model for real time background subtraction using AGMM. The proposed model is robust and adaptable to dynamic background, fast illumination changes, repetitive motion. Also we have incorporated a method for detecting shadows using the Horpresert color model. The proposed model can be employed for monitoring areas where movement or entry is highly restricted. So on detection of any unexpected events in the scene an alarm can be triggered and hence we can achieve real time surveillance even in the absence of constant human monitoring.\n    ",
        "submission_date": "2013-07-22T00:00:00",
        "last_modified_date": "2013-07-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1307.5996",
        "title": "Bayesian Fusion of Multi-Band Images",
        "authors": [
            "Qi Wei",
            "Nicolas Dobigeon",
            "Jean-Yves Tourneret"
        ],
        "abstract": "In this paper, a Bayesian fusion technique for remotely sensed multi-band images is presented. The observed images are related to the high spectral and high spatial resolution image to be recovered through physical degradations, e.g., spatial and spectral blurring and/or subsampling defined by the sensor characteristics. The fusion problem is formulated within a Bayesian estimation framework. An appropriate prior distribution exploiting geometrical consideration is introduced. To compute the Bayesian estimator of the scene of interest from its posterior distribution, a Markov chain Monte Carlo algorithm is designed to generate samples asymptotically distributed according to the target distribution. To efficiently sample from this high-dimension distribution, a Hamiltonian Monte Carlo step is introduced in the Gibbs sampling strategy. The efficiency of the proposed fusion method is evaluated with respect to several state-of-the-art fusion techniques. In particular, low spatial resolution hyperspectral and multispectral images are fused to produce a high spatial resolution hyperspectral image.\n    ",
        "submission_date": "2013-07-23T00:00:00",
        "last_modified_date": "2014-08-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1307.6008",
        "title": "Numerical Methods for Coupled Reconstruction and Registration in Digital Breast Tomosynthesis",
        "authors": [
            "Guang Yang",
            "John H. Hipwell",
            "David J. Hawkes",
            "Simon R. Arridge"
        ],
        "abstract": "Digital Breast Tomosynthesis (DBT) provides an insight into the fine details of normal fibroglandular tissues and abnormal lesions by reconstructing a pseudo-3D image of the breast. In this respect, DBT overcomes a major limitation of conventional X-ray mammography by reducing the confounding effects caused by the superposition of breast tissue. In a breast cancer screening or diagnostic context, a radiologist is interested in detecting change, which might be indicative of malignant disease. To help automate this task image registration is required to establish spatial correspondence between time points. Typically, images, such as MRI or CT, are first reconstructed and then registered. This approach can be effective if reconstructing using a complete set of data. However, for ill-posed, limited-angle problems such as DBT, estimating the deformation is complicated by the significant artefacts associated with the reconstruction, leading to severe inaccuracies in the registration. This paper presents a mathematical framework, which couples the two tasks and jointly estimates both image intensities and the parameters of a transformation.\n",
        "submission_date": "2013-07-23T00:00:00",
        "last_modified_date": "2013-07-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1307.6170",
        "title": "6th International Symposium on Attention in Cognitive Systems 2013",
        "authors": [
            "Lucas Paletta",
            "Laurent Itti",
            "Bj\u00f6rn Schuller",
            "Fang Fang"
        ],
        "abstract": "This volume contains the papers accepted at the 6th International Symposium on Attention in Cognitive Systems (ISACS 2013), held in Beijing, August 5, 2013. The aim of this symposium is to highlight the central role of attention on various kinds of performance in cognitive systems processing. It brings together researchers and developers from both academia and industry, from computer vision, robotics, perception psychology, psychophysics and neuroscience, in order to provide an interdisciplinary forum to present and communicate on computational models of attention, with the focus on interdependencies with visual cognition. Furthermore, it intends to investigate relevant objectives for performance comparison, to document and to investigate promising application domains, and to discuss visual attention with reference to other aspects of AI enabled systems.\n    ",
        "submission_date": "2013-07-22T00:00:00",
        "last_modified_date": "2013-07-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1307.6303",
        "title": "Matching-Constrained Active Contours",
        "authors": [
            "Junyan Wang",
            "Kap Luk Chan"
        ],
        "abstract": "In object segmentation by active contours, the initial contour is often required. Conventionally, the initial contour is provided by the user. This paper extends the conventional active contour model by incorporating feature matching in the formulation, which gives rise to a novel matching-constrained active contour. The numerical solution to the new optimization model provides an automated framework of object segmentation without user intervention. The main idea is to incorporate feature point matching as a constraint in active contour models. To this effect, we obtain a mathematical model of interior points to boundary contour such that matching of interior feature points gives contour alignment, and we formulate the matching score as a constraint to active contour model such that the feature matching of maximum score that gives the contour alignment provides the initial feasible solution to the constrained optimization model of segmentation. The constraint also ensures that the optimal contour does not deviate too much from the initial contour. Projected-gradient descent equations are derived to solve the constrained optimization. In the experiments, we show that our method is capable of achieving the automatic object segmentation, and it outperforms the related methods.\n    ",
        "submission_date": "2013-07-24T00:00:00",
        "last_modified_date": "2013-07-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1307.6542",
        "title": "Selection Mammogram Texture Descriptors Based on Statistics Properties Backpropagation Structure",
        "authors": [
            "Shofwatul 'Uyun",
            "Sri Hartati",
            "Agus Harjoko",
            "Subanar"
        ],
        "abstract": "Computer Aided Diagnosis (CAD) system has been developed for the early detection of breast cancer, one of the most deadly cancer for women. The benign of mammogram has different texture from malignant. There are fifty mammogram images used in this work which are divided for training and testing. Therefore, the selection of the right texture to determine the level of accuracy of CAD system is important. The first and second order statistics are the texture feature extraction methods which can be used on a mammogram. This work classifies texture descriptor into nine groups where the extraction of features is classified using backpropagation learning with two types of multi-layer perceptron (MLP). The best texture descriptor as selected when the value of regression 1 appears in both the MLP-1 and the MLP-2 with the number of epoches less than 1000. The results of testing show that the best selected texture descriptor is the second order (combination) using all direction (0, 45, 90 and 135) that have twenty four descriptors.\n    ",
        "submission_date": "2013-07-10T00:00:00",
        "last_modified_date": "2013-07-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1307.6544",
        "title": "Veni Vidi Vici, A Three-Phase Scenario For Parameter Space Analysis in Image Analysis and Visualization",
        "authors": [
            "M. A. El-Dosuky"
        ],
        "abstract": "Automatic analysis of the enormous sets of images is a critical task in life sciences. This faces many challenges such as: algorithms are highly parameterized, significant human input is intertwined, and lacking a standard meta-visualization approach. This paper proposes an alternative iterative approach for optimizing input parameters, saving time by minimizing the user involvement, and allowing for understanding the workflow of algorithms and discovering new ones. The main focus is on developing an interactive visualization technique that enables users to analyze the relationships between sampled input parameters and corresponding output. This technique is implemented as a prototype called Veni Vidi Vici, or \"I came, I saw, I conquered.\" This strategy is inspired by the mathematical formulas of numbering computable functions and is developed atop ImageJ, a scientific image processing program. A case study is presented to investigate the proposed framework. Finally, the paper explores some potential future issues in the application of the proposed approach in parameter space analysis in visualization.\n    ",
        "submission_date": "2013-07-17T00:00:00",
        "last_modified_date": "2013-07-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1307.6549",
        "title": "Making Laplacians commute",
        "authors": [
            "Michael M. Bronstein",
            "Klaus Glashoff",
            "Terry A. Loring"
        ],
        "abstract": "In this paper, we construct multimodal spectral geometry by finding a pair of closest commuting operators (CCO) to a given pair of Laplacians. The CCOs are jointly diagonalizable and hence have the same eigenbasis. Our construction naturally extends classical data analysis tools based on spectral geometry, such as diffusion maps and spectral clustering. We provide several synthetic and real examples of applications in dimensionality reduction, shape analysis, and clustering, demonstrating that our method better captures the inherent structure of multi-modal data.\n    ",
        "submission_date": "2013-07-19T00:00:00",
        "last_modified_date": "2013-07-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1307.6962",
        "title": "Reduced egomotion estimation drift using omnidirectional views",
        "authors": [
            "Yalin Bastanlar"
        ],
        "abstract": "Estimation of camera motion from a given image sequence becomes degraded as the length of the sequence increases. In this letter, this phenomenon is demonstrated and an approach to increase the estimation accuracy is proposed. The proposed method uses an omnidirectional camera in addition to the perspective one and takes advantage of its enlarged view by exploiting the correspondences between the omnidirectional and perspective images. Simulated and real image experiments show that the proposed approach improves the estimation accuracy.\n    ",
        "submission_date": "2013-07-26T00:00:00",
        "last_modified_date": "2013-12-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1307.7198",
        "title": "Self-Learning for Player Localization in Sports Video",
        "authors": [
            "Kenji Okuma",
            "David G. Lowe",
            "James J. Little"
        ],
        "abstract": "This paper introduces a novel self-learning framework that automates the label acquisition process for improving models for detecting players in broadcast footage of sports games. Unlike most previous self-learning approaches for improving appearance-based object detectors from videos, we allow an unknown, unconstrained number of target objects in a more generalized video sequence with non-static camera views. Our self-learning approach uses a latent SVM learning algorithm and deformable part models to represent the shape and colour information of players, constraining their motions, and learns the colour of the playing field by a gentle Adaboost algorithm. We combine those image cues and discover additional labels automatically from unlabelled data. In our experiments, our approach exploits both labelled and unlabelled data in sparsely labelled videos of sports games, providing a mean performance improvement of over 20% in the average precision for detecting sports players and improved tracking, when videos contain very few labelled images.\n    ",
        "submission_date": "2013-07-27T00:00:00",
        "last_modified_date": "2013-07-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1307.7474",
        "title": "Automatic Mammogram image Breast Region Extraction and Removal of Pectoral Muscle",
        "authors": [
            "R. Subash Chandra Boss",
            "K. Thangavel",
            "D. Arul Pon Daniel"
        ],
        "abstract": "Currently Mammography is a most effective imaging modality used by radiologists for the screening of breast cancer. Finding an accurate, robust and efficient breast region segmentation technique still remains a challenging problem in digital mammography. Extraction of the breast profile region and the removal of pectoral muscle are essential pre-processing steps in Computer Aided Diagnosis (CAD) system for the diagnosis of breast cancer. Primarily it allows the search for abnormalities to be limited to the region of the breast tissue without undue influence from the background of the mammogram. The presence of pectoral muscle in mammograms biases detection procedures, which recommends removing the pectoral muscle during mammogram image pre-processing. The presence of pectoral muscle in mammograms may disturb or influence the detection of breast cancer as the pectoral muscle and mammographic parenchymas appear similar. The goal of breast region extraction is reducing the image size without losing anatomic information, it improve the accuracy of the overall CAD system. The main objective of this study is to propose an automated method to identify the pectoral muscle in Medio-Lateral Oblique (MLO) view mammograms. In this paper, we proposed histogram based 8-neighborhood connected component labelling method for breast region extraction and removal of pectoral muscle. The proposed method is evaluated by using the mean values of accuracy and error. The comparative analysis shows that the proposed method identifies the breast region more accurately.\n    ",
        "submission_date": "2013-07-29T00:00:00",
        "last_modified_date": "2013-07-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1307.7800",
        "title": "Efficient Energy Minimization for Enforcing Statistics",
        "authors": [
            "Yongsub Lim",
            "Kyomin Jung",
            "Pushmeet Kohli"
        ],
        "abstract": "Energy minimization algorithms, such as graph cuts, enable the computation of the MAP solution under certain probabilistic models such as Markov random fields. However, for many computer vision problems, the MAP solution under the model is not the ground truth solution. In many problem scenarios, the system has access to certain statistics of the ground truth. For instance, in image segmentation, the area and boundary length of the object may be known. In these cases, we want to estimate the most probable solution that is consistent with such statistics, i.e., satisfies certain equality or inequality constraints.\n",
        "submission_date": "2013-07-30T00:00:00",
        "last_modified_date": "2013-07-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1307.7848",
        "title": "An Integrated System for 3D Gaze Recovery and Semantic Analysis of Human Attention",
        "authors": [
            "Lucas Paletta",
            "Katrin Santner",
            "Gerald Fritz"
        ],
        "abstract": "This work describes a computer vision system that enables pervasive mapping and monitoring of human attention. The key contribution is that our methodology enables full 3D recovery of the gaze pointer, human view frustum and associated human centered measurements directly into an automatically computed 3D model in real-time. We apply RGB-D SLAM and descriptor matching methodologies for the 3D modeling, localization and fully automated annotation of ROIs (regions of interest) within the acquired 3D model. This innovative methodology will open new avenues for attention studies in real world environments, bringing new potential into automated processing for human factors technologies.\n    ",
        "submission_date": "2013-07-30T00:00:00",
        "last_modified_date": "2013-07-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1307.7851",
        "title": "Hybrid Affinity Propagation",
        "authors": [
            "Jingdong Wang",
            "Hao Xu",
            "Xian-Sheng Hua",
            "Shipeng Li"
        ],
        "abstract": "In this paper, we address a problem of managing tagged images with hybrid summarization. We formulate this problem as finding a few image exemplars to represent the image set semantically and visually, and solve it in a hybrid way by exploiting both visual and textual information associated with images. We propose a novel approach, called homogeneous and heterogeneous message propagation ($\\text{H}^\\text{2}\\text{MP}$). Similar to the affinity propagation (AP) approach, $\\text{H}^\\text{2}\\text{MP}$ reduce the conventional \\emph{vector} message propagation to \\emph{scalar} message propagation to make the algorithm more efficient. Beyond AP that can only handle homogeneous data, $\\text{H}^\\text{2}\\text{MP}$ generalizes it to exploit extra heterogeneous relations and the generalization is non-trivial as the reduction to scalar messages from vector messages is more challenging. The main advantages of our approach lie in 1) that $\\text{H}^\\text{2}\\text{MP}$ exploits visual similarity and in addition the useful information from the associated tags, including the associations relation between images and tags and the relations within tags, and 2) that the summary is both visually and semantically satisfactory. In addition, our approach can also present a textual summary to a tagged image collection, which can be used to automatically generate a textual description. The experimental results demonstrate the effectiveness and efficiency of the roposed approach.\n    ",
        "submission_date": "2013-07-30T00:00:00",
        "last_modified_date": "2013-07-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1307.7852",
        "title": "Scalable $k$-NN graph construction",
        "authors": [
            "Jingdong Wang",
            "Jing Wang",
            "Gang Zeng",
            "Zhuowen Tu",
            "Rui Gan",
            "Shipeng Li"
        ],
        "abstract": "The $k$-NN graph has played a central role in increasingly popular data-driven techniques for various learning and vision tasks; yet, finding an efficient and effective way to construct $k$-NN graphs remains a challenge, especially for large-scale high-dimensional data. In this paper, we propose a new approach to construct approximate $k$-NN graphs with emphasis in: efficiency and accuracy. We hierarchically and randomly divide the data points into subsets and build an exact neighborhood graph over each subset, achieving a base approximate neighborhood graph; we then repeat this process for several times to generate multiple neighborhood graphs, which are combined to yield a more accurate approximate neighborhood graph. Furthermore, we propose a neighborhood propagation scheme to further enhance the accuracy. We show both theoretical and empirical accuracy and efficiency of our approach to $k$-NN graph construction and demonstrate significant speed-up in dealing with large scale visual data.\n    ",
        "submission_date": "2013-07-30T00:00:00",
        "last_modified_date": "2013-07-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1307.8233",
        "title": "A Prototyping Environment for Integrated Artificial Attention Systems",
        "authors": [
            "Jan T\u007f\u00fcnnermann",
            "Markus Hennig",
            "Michael Silbernagel",
            "B\u007f\u00e4rbel Mertsching"
        ],
        "abstract": "Artificial visual attention systems aim to support technical systems in visual tasks by applying the concepts of selective attention observed in humans and other animals. Such systems are typically evaluated against ground truth obtained from human gaze-data or manually annotated test images. When applied to robotics, the systems are required to be adaptable to the target system. Here, we describe a flexible environment based on a robotic middleware layer allowing the development and testing of attention-guided vision systems. In such a framework, the systems can be tested with input from various sources, different attention algorithms at the core, and diverse subsequent tasks.\n    ",
        "submission_date": "2013-07-31T00:00:00",
        "last_modified_date": "2013-07-31T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1307.8405",
        "title": "Who and Where: People and Location Co-Clustering",
        "authors": [
            "Zixuan Wang",
            "Jinyun Yan"
        ],
        "abstract": "In this paper, we consider the clustering problem on images where each image contains patches in people and location domains. We exploit the correlation between people and location domains, and proposed a semi-supervised co-clustering algorithm to cluster images. Our algorithm updates the correlation links at the runtime, and produces clustering in both domains simultaneously. We conduct experiments in a manually collected dataset and a Flickr dataset. The result shows that the such correlation improves the clustering performance.\n    ",
        "submission_date": "2013-07-31T00:00:00",
        "last_modified_date": "2013-07-31T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1308.0271",
        "title": "Compositional Dictionaries for Domain Adaptive Face Recognition",
        "authors": [
            "Qiang Qiu",
            "Rama Chellappa"
        ],
        "abstract": "We present a dictionary learning approach to compensate for the transformation of faces due to changes in view point, illumination, resolution, etc. The key idea of our approach is to force domain-invariant sparse coding, i.e., design a consistent sparse representation of the same face in different domains. In this way, classifiers trained on the sparse codes in the source domain consisting of frontal faces for example can be applied to the target domain (consisting of faces in different poses, illumination conditions, etc) without much loss in recognition accuracy. The approach is to first learn a domain base dictionary, and then describe each domain shift (identity, pose, illumination) using a sparse representation over the base dictionary. The dictionary adapted to each domain is expressed as sparse linear combinations of the base dictionary. In the context of face recognition, with the proposed compositional dictionary approach, a face image can be decomposed into sparse representations for a given subject, pose and illumination respectively. This approach has three advantages: first, the extracted sparse representation for a subject is consistent across domains and enables pose and illumination insensitive face recognition. Second, sparse representations for pose and illumination can subsequently be used to estimate the pose and illumination condition of a face image. Finally, by composing sparse representations for subject and the different domains, we can also perform pose alignment and illumination normalization. Extensive experiments using two public face datasets are presented to demonstrate the effectiveness of our approach for face recognition.\n    ",
        "submission_date": "2013-08-01T00:00:00",
        "last_modified_date": "2015-09-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1308.0273",
        "title": "Learning Robust Subspace Clustering",
        "authors": [
            "Qiang Qiu",
            "Guillermo Sapiro"
        ],
        "abstract": "We propose a low-rank transformation-learning framework to robustify subspace clustering. Many high-dimensional data, such as face images and motion sequences, lie in a union of low-dimensional subspaces. The subspace clustering problem has been extensively studied in the literature to partition such high-dimensional data into clusters corresponding to their underlying low-dimensional subspaces. However, low-dimensional intrinsic structures are often violated for real-world observations, as they can be corrupted by errors or deviate from ideal models. We propose to address this by learning a linear transformation on subspaces using matrix rank, via its convex surrogate nuclear norm, as the optimization criteria. The learned linear transformation restores a low-rank structure for data from the same subspace, and, at the same time, forces a high-rank structure for data from different subspaces. In this way, we reduce variations within the subspaces, and increase separations between the subspaces for more accurate subspace clustering. This proposed learned robust subspace clustering framework significantly enhances the performance of existing subspace clustering methods. To exploit the low-rank structures of the transformed subspaces, we further introduce a subspace clustering technique, called Robust Sparse Subspace Clustering, which efficiently combines robust PCA with sparse modeling. We also discuss the online learning of the transformation, and learning of the transformation while simultaneously reducing the data dimensionality. Extensive experiments using public datasets are presented, showing that the proposed approach significantly outperforms state-of-the-art subspace clustering methods.\n    ",
        "submission_date": "2013-08-01T00:00:00",
        "last_modified_date": "2013-08-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1308.0275",
        "title": "Domain-invariant Face Recognition using Learned Low-rank Transformation",
        "authors": [
            "Qiang Qiu",
            "Guillermo Sapiro",
            "Ching-Hui Chen"
        ],
        "abstract": "We present a low-rank transformation approach to compensate for face variations due to changes in visual domains, such as pose and illumination. The key idea is to learn discriminative linear transformations for face images using matrix rank as the optimization criteria. The learned linear transformations restore a shared low-rank structure for faces from the same subject, and, at the same time, force a high-rank structure for faces from different subjects. In this way, among the transformed faces, we reduce variations caused by domain changes within the classes, and increase separations between the classes for better face recognition across domains. Extensive experiments using public datasets are presented to demonstrate the effectiveness of our approach for face recognition across domains. The potential of the approach for feature extraction in generic object recognition and coded aperture design are discussed as well.\n    ",
        "submission_date": "2013-08-01T00:00:00",
        "last_modified_date": "2013-08-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1308.0290",
        "title": "Sparse Dictionary-based Attributes for Action Recognition and Summarization",
        "authors": [
            "Qiang Qiu",
            "Zhuolin Jiang",
            "Rama Chellappa"
        ],
        "abstract": "We present an approach for dictionary learning of action attributes via information maximization. We unify the class distribution and appearance information into an objective function for learning a sparse dictionary of action attributes. The objective function maximizes the mutual information between what has been learned and what remains to be learned in terms of appearance information and class distribution for each dictionary atom. We propose a Gaussian Process (GP) model for sparse representation to optimize the dictionary objective function. The sparse coding property allows a kernel with compact support in GP to realize a very efficient dictionary learning process. Hence we can describe an action video by a set of compact and discriminative action attributes. More importantly, we can recognize modeled action categories in a sparse feature space, which can be generalized to unseen and unmodeled action categories. Experimental results demonstrate the effectiveness of our approach in action recognition and summarization.\n    ",
        "submission_date": "2013-08-01T00:00:00",
        "last_modified_date": "2013-08-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1308.0365",
        "title": "Hybrid Focal Stereo Networks for Pattern Analysis in Homogeneous Scenes",
        "authors": [
            "Emanuel Aldea",
            "Khurom H. Kiyani"
        ],
        "abstract": "In this paper we address the problem of multiple camera calibration in the presence of a homogeneous scene, and without the possibility of employing calibration object based methods. The proposed solution exploits salient features present in a larger field of view, but instead of employing active vision we replace the cameras with stereo rigs featuring a long focal analysis camera, as well as a short focal registration camera. Thus, we are able to propose an accurate solution which does not require intrinsic variation models as in the case of zooming cameras. Moreover, the availability of the two views simultaneously in each rig allows for pose re-estimation between rigs as often as necessary. The algorithm has been successfully validated in an indoor setting, as well as on a difficult scene featuring a highly dense pilgrim crowd in Makkah.\n    ",
        "submission_date": "2013-08-01T00:00:00",
        "last_modified_date": "2013-08-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1308.0371",
        "title": "Sparse arrays of signatures for online character recognition",
        "authors": [
            "Benjamin Graham"
        ],
        "abstract": "In mathematics the signature of a path is a collection of iterated integrals, commonly used for solving differential equations. We show that the path signature, used as a set of features for consumption by a convolutional neural network (CNN), improves the accuracy of online character recognition---that is the task of reading characters represented as a collection of paths. Using datasets of letters, numbers, Assamese and Chinese characters, we show that the first, second, and even the third iterated integrals contain useful information for consumption by a CNN.\n",
        "submission_date": "2013-08-01T00:00:00",
        "last_modified_date": "2013-12-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1308.0890",
        "title": "Head Gesture Recognition using Optical Flow based Classification with Reinforcement of GMM based Background Subtraction",
        "authors": [
            "Parimita Saikia",
            "Karen Das"
        ],
        "abstract": "This paper describes a technique of real time head gesture recognition system. The method includes Gaussian mixture model (GMM) accompanied by optical flow algorithm which provided us the required information regarding head movement. The proposed model can be implemented in various control system. We are also presenting the result and implementation of both mentioned method.\n    ",
        "submission_date": "2013-08-05T00:00:00",
        "last_modified_date": "2013-08-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1308.1126",
        "title": "Image interpolation using Shearlet based iterative refinement",
        "authors": [
            "H. Lakshman",
            "W.-Q Lim",
            "H. Schwarz",
            "D. Marpe",
            "G. Kutyniok",
            "T. Wiegand"
        ],
        "abstract": "This paper proposes an image interpolation algorithm exploiting sparse representation for natural images. It involves three main steps: (a) obtaining an initial estimate of the high resolution image using linear methods like FIR filtering, (b) promoting sparsity in a selected dictionary through iterative thresholding, and (c) extracting high frequency information from the approximation to refine the initial estimate. For the sparse modeling, a shearlet dictionary is chosen to yield a multiscale directional representation. The proposed algorithm is compared to several state-of-the-art methods to assess its objective as well as subjective performance. Compared to the cubic spline interpolation method, an average PSNR gain of around 0.8 dB is observed over a dataset of 200 images.\n    ",
        "submission_date": "2013-08-05T00:00:00",
        "last_modified_date": "2013-08-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1308.1187",
        "title": "Spatial-Aware Dictionary Learning for Hyperspectral Image Classification",
        "authors": [
            "Ali Soltani-Farani",
            "Hamid R. Rabiee",
            "Seyyed Abbas Hosseini"
        ],
        "abstract": "This paper presents a structured dictionary-based model for hyperspectral data that incorporates both spectral and contextual characteristics of a spectral sample, with the goal of hyperspectral image classification. The idea is to partition the pixels of a hyperspectral image into a number of spatial neighborhoods called contextual groups and to model each pixel with a linear combination of a few dictionary elements learned from the data. Since pixels inside a contextual group are often made up of the same materials, their linear combinations are constrained to use common elements from the dictionary. To this end, dictionary learning is carried out with a joint sparse regularizer to induce a common sparsity pattern in the sparse coefficients of each contextual group. The sparse coefficients are then used for classification using a linear SVM. Experimental results on a number of real hyperspectral images confirm the effectiveness of the proposed representation for hyperspectral image classification. Moreover, experiments with simulated multispectral data show that the proposed model is capable of finding representations that may effectively be used for classification of multispectral-resolution samples.\n    ",
        "submission_date": "2013-08-06T00:00:00",
        "last_modified_date": "2013-08-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1308.1374",
        "title": "Bayesian ensemble learning for image denoising",
        "authors": [
            "Hyuntaek Oh"
        ],
        "abstract": "Natural images are often affected by random noise and image denoising has long been a central topic in Computer Vision. Many algorithms have been introduced to remove the noise from the natural images, such as Gaussian, Wiener filtering and wavelet thresholding. However, many of these algorithms remove the fine edges and make them blur. Recently, many promising denoising algorithms have been introduced such as Non-local Means, Fields of Experts, and BM3D. In this paper, we explore Bayesian method of ensemble learning for image denoising. Ensemble methods seek to combine multiple different algorithms to retain the strengths of all methods and the weaknesses of none. Bayesian ensemble models are Non-local Means and Fields of Experts, the very successful recent algorithms. The Non-local Means presumes that the image contains an extensive amount of self-similarity. The approach of the Fields of Experts model extends traditional Markov Random Field model by learning potential functions over extended pixel neighborhoods. The two models are implemented and image denoising is performed on natural images. The experimental results obtained are used to compare with the single algorithm and discuss the ensemble learning and their approaches. Comparing to the results of Non-local Means and Fields of Experts, Ensemble learning showed improvement nearly 1dB.\n    ",
        "submission_date": "2013-08-06T00:00:00",
        "last_modified_date": "2013-08-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1308.1801",
        "title": "Satellite image classification methods and Landsat 5TM bands",
        "authors": [
            "Jamshid Tamouk",
            "Nasser Lotfi",
            "Mina Farmanbar"
        ],
        "abstract": "This paper attempts to find the most accurate classification method among parallelepiped, minimum distance and chain methods. Moreover, this study also challenges to find the suitable combination of bands, which can lead to better results in case combinations of bands occur. After comparing these three methods, the chain method over perform the other methods with 79% overall accuracy. Hence, it is more accurate than minimum distance with 67% and parallelepiped with 65%. On the other hand, based on bands features, and also by combining several researchers' findings, a table was created which includes the main objects on the land and the suitable combination of the bands for accurately detecting of landcover objects. During this process, it was observed that band 4 (out of 7 bands of Landsat 5TM) is the band, which can be used for increasing the accuracy of the combined bands in detecting objects on the land.\n    ",
        "submission_date": "2013-08-08T00:00:00",
        "last_modified_date": "2013-08-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1308.1981",
        "title": "A Framework for the Analysis of Computational Imaging Systems with Practical Applications",
        "authors": [
            "Kaushik Mitra",
            "Oliver Cossairt",
            "Ashok Veeraraghavan"
        ],
        "abstract": "Over the last decade, a number of Computational Imaging (CI) systems have been proposed for tasks such as motion deblurring, defocus deblurring and multispectral imaging. These techniques increase the amount of light reaching the sensor via multiplexing and then undo the deleterious effects of multiplexing by appropriate reconstruction algorithms. Given the widespread appeal and the considerable enthusiasm generated by these techniques, a detailed performance analysis of the benefits conferred by this approach is important.\n",
        "submission_date": "2013-08-08T00:00:00",
        "last_modified_date": "2014-03-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1308.2292",
        "title": "Fast image segmentation and restoration using parametric curve evolution with junctions and topology changes",
        "authors": [
            "Heike Benninghoff",
            "Harald Garcke"
        ],
        "abstract": "Curve evolution schemes for image segmentation based on a region based contour model allowing for junctions, vector-valued images and topology changes are introduced. Together with an a posteriori denoising in the segmented homogeneous regions this leads to a fast and efficient method for image segmentation and restoration. An uneven spread of mesh points is avoided by using the tangential degrees of freedom. Several numerical simulations on artificial test problems and on real images illustrate the performance of the method.\n    ",
        "submission_date": "2013-08-10T00:00:00",
        "last_modified_date": "2013-08-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1308.2464",
        "title": "Faster gradient descent and the efficient recovery of images",
        "authors": [
            "Hui Huang",
            "Uri Ascher"
        ],
        "abstract": "Much recent attention has been devoted to gradient descent algorithms where the steepest descent step size is replaced by a similar one from a previous iteration or gets updated only once every second step, thus forming a {\\em faster gradient descent method}. For unconstrained convex quadratic optimization these methods can converge much faster than steepest descent. But the context of interest here is application to certain ill-posed inverse problems, where the steepest descent method is known to have a smoothing, regularizing effect, and where a strict optimization solution is not necessary.\n",
        "submission_date": "2013-08-12T00:00:00",
        "last_modified_date": "2013-08-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1308.2654",
        "title": "Local image registration a comparison for bilateral registration mammography",
        "authors": [
            "Jos\u00e9 M. Celaya-Padilla",
            "Juan Rodriguez-Rojas",
            "Victor Trevino",
            "Jos\u00e9 G. Gerardo Tamez-Pena"
        ],
        "abstract": "Early tumor detection is key in reducing the number of breast cancer death and screening mammography is one of the most widely available and reliable method for early detection. However, it is difficult for the radiologist to process with the same attention each case, due the large amount of images to be read. Computer aided detection (CADe) systems improve tumor detection rate; but the current efficiency of these systems is not yet adequate and the correct interpretation of CADe outputs requires expert human intervention. Computer aided diagnosis systems (CADx) are being designed to improve cancer diagnosis accuracy, but they have not been efficiently applied in breast cancer. CADx efficiency can be enhanced by considering the natural mirror symmetry between the right and left breast. The objective of this work is to evaluate co-registration algorithms for the accurate alignment of the left to right breast for CADx enhancement. A set of mammograms were artificially altered to create a ground truth set to evaluate the registration efficiency of DEMONs, and SPLINE deformable registration algorithms. The registration accuracy was evaluated using mean square errors, mutual information and correlation. The results on the 132 images proved that the SPLINE deformable registration over-perform the DEMONS on mammography images.\n    ",
        "submission_date": "2013-08-12T00:00:00",
        "last_modified_date": "2013-08-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1308.3052",
        "title": "Gradient Magnitude Similarity Deviation: A Highly Efficient Perceptual Image Quality Index",
        "authors": [
            "Wufeng Xue",
            "Lei Zhang",
            "Xuanqin Mou",
            "Alan C. Bovik"
        ],
        "abstract": "It is an important task to faithfully evaluate the perceptual quality of output images in many applications such as image compression, image restoration and multimedia streaming. A good image quality assessment (IQA) model should not only deliver high quality prediction accuracy but also be computationally efficient. The efficiency of IQA metrics is becoming particularly important due to the increasing proliferation of high-volume visual data in high-speed networks. We present a new effective and efficient IQA model, called gradient magnitude similarity deviation (GMSD). The image gradients are sensitive to image distortions, while different local structures in a distorted image suffer different degrees of degradations. This motivates us to explore the use of global variation of gradient based local quality map for overall image quality prediction. We find that the pixel-wise gradient magnitude similarity (GMS) between the reference and distorted images combined with a novel pooling strategy the standard deviation of the GMS map can predict accurately perceptual image quality. The resulting GMSD algorithm is much faster than most state-of-the-art IQA methods, and delivers highly competitive prediction accuracy.\n    ",
        "submission_date": "2013-08-14T00:00:00",
        "last_modified_date": "2013-11-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1308.3101",
        "title": "Compact Relaxations for MAP Inference in Pairwise MRFs with Piecewise Linear Priors",
        "authors": [
            "Christopher Zach",
            "Christian H\u00e4ne"
        ],
        "abstract": "Label assignment problems with large state spaces are important tasks especially in computer vision. Often the pairwise interaction (or smoothness prior) between labels assigned at adjacent nodes (or pixels) can be described as a function of the label difference. Exact inference in such labeling tasks is still difficult, and therefore approximate inference methods based on a linear programming (LP) relaxation are commonly used in practice. In this work we study how compact linear programs can be constructed for general piecwise linear smoothness priors. The number of unknowns is O(LK) per pairwise clique in terms of the state space size $L$ and the number of linear segments K. This compares to an O(L^2) size complexity of the standard LP relaxation if the piecewise linear structure is ignored. Our compact construction and the standard LP relaxation are equivalent and lead to the same (approximate) label assignment.\n    ",
        "submission_date": "2013-08-14T00:00:00",
        "last_modified_date": "2017-04-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1308.3383",
        "title": "Axioms for graph clustering quality functions",
        "authors": [
            "Twan van Laarhoven",
            "Elena Marchiori"
        ],
        "abstract": "We investigate properties that intuitively ought to be satisfied by graph clustering quality functions, that is, functions that assign a score to a clustering of a graph. Graph clustering, also known as network community detection, is often performed by optimizing such a function. Two axioms tailored for graph clustering quality functions are introduced, and the four axioms introduced in previous work on distance based clustering are reformulated and generalized for the graph setting. We show that modularity, a standard quality function for graph clustering, does not satisfy all of these six properties. This motivates the derivation of a new family of quality functions, adaptive scale modularity, which does satisfy the proposed axioms. Adaptive scale modularity has two parameters, which give greater flexibility in the kinds of clusterings that can be found. Standard graph clustering quality functions, such as normalized cut and unnormalized cut, are obtained as special cases of adaptive scale modularity.\n",
        "submission_date": "2013-08-15T00:00:00",
        "last_modified_date": "2014-07-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1308.4189",
        "title": "Seeing What You're Told: Sentence-Guided Activity Recognition In Video",
        "authors": [
            "N. Siddharth",
            "Andrei Barbu",
            "Jeffrey Mark Siskind"
        ],
        "abstract": "We present a system that demonstrates how the compositional structure of events, in concert with the compositional structure of language, can interplay with the underlying focusing mechanisms in video action recognition, thereby providing a medium, not only for top-down and bottom-up integration, but also for multi-modal integration between vision and language. We show how the roles played by participants (nouns), their characteristics (adjectives), the actions performed (verbs), the manner of such actions (adverbs), and changing spatial relations between participants (prepositions) in the form of whole sentential descriptions mediated by a grammar, guides the activity-recognition process. Further, the utility and expressiveness of our framework is demonstrated by performing three separate tasks in the domain of multi-activity videos: sentence-guided focus of attention, generation of sentential descriptions of video, and query-based video search, simply by leveraging the framework in different manners.\n    ",
        "submission_date": "2013-08-19T00:00:00",
        "last_modified_date": "2014-05-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1308.4200",
        "title": "Towards Adapting ImageNet to Reality: Scalable Domain Adaptation with Implicit Low-rank Transformations",
        "authors": [
            "Erik Rodner",
            "Judy Hoffman",
            "Jeff Donahue",
            "Trevor Darrell",
            "Kate Saenko"
        ],
        "abstract": "Images seen during test time are often not from the same distribution as images used for learning. This problem, known as domain shift, occurs when training classifiers from object-centric internet image databases and trying to apply them directly to scene understanding tasks. The consequence is often severe performance degradation and is one of the major barriers for the application of classifiers in real-world systems. In this paper, we show how to learn transform-based domain adaptation classifiers in a scalable manner. The key idea is to exploit an implicit rank constraint, originated from a max-margin domain adaptation formulation, to make optimization tractable. Experiments show that the transformation between domains can be very efficiently learned from data and easily applied to new categories. This begins to bridge the gap between large-scale internet image collections and object images captured in everyday life environments.\n    ",
        "submission_date": "2013-08-20T00:00:00",
        "last_modified_date": "2013-08-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1308.4440",
        "title": "Influences Combination of Multi-Sensor Images on Classification Accuracy",
        "authors": [
            "AL-Wassai Firouz",
            "N.V.Kalyankar"
        ],
        "abstract": "This paper focuses on two main issues; first one is the impact of combination of multi-sensor images on the supervised learning classification accuracy using segment Fusion (SF). The second issue attempts to undertake the study of supervised machine learning classification technique of remote sensing images by using four classifiers like Parallelepiped (Pp), Mahalanobis Distance (MD), Maximum-Likelihood (ML) and Euclidean Distance(ED) classifiers, and their accuracies have been evaluated on their respected classification to choose the best technique for classification of remote sensing images. QuickBird multispectral data (MS) and panchromatic data (PAN) have been used in this study to demonstrate the enhancement and accuracy assessment of fused image over the original images using ALwassaiProcess software. According to experimental result of this study, is that the test results indicate the supervised classification results of fusion image, which generated better than the MS did. As well as the result with Euclidean classifier is robust and provides better results than the other classifiers do, despite of the popular belief that the maximum-likelihood classifier is the most accurate classifier.\n    ",
        "submission_date": "2013-08-20T00:00:00",
        "last_modified_date": "2013-08-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1308.4902",
        "title": "A review on handwritten character and numeral recognition for Roman, Arabic, Chinese and Indian scripts",
        "authors": [
            "Aini Najwa Azmi",
            "Dewi Nasien",
            "Siti Mariyam Shamsuddin"
        ],
        "abstract": "There are a lot of intensive researches on handwritten character recognition (HCR) for almost past four decades. The research has been done on some of popular scripts such as Roman, Arabic, Chinese and Indian. In this paper we present a review on HCR work on the four popular scripts. We have summarized most of the published paper from 2005 to recent and also analyzed the various methods in creating a robust HCR system. We also added some future direction of research on HCR.\n    ",
        "submission_date": "2013-08-22T00:00:00",
        "last_modified_date": "2013-08-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1308.4908",
        "title": "A Unified Framework for Multi-Sensor HDR Video Reconstruction",
        "authors": [
            "Joel Kronander",
            "Stefan Gustavson",
            "Gerhard Bonnet",
            "Anders Ynnerman",
            "Jonas Unger"
        ],
        "abstract": "One of the most successful approaches to modern high quality HDR-video capture is to use camera setups with multiple sensors imaging the scene through a common optical system. However, such systems pose several challenges for HDR reconstruction algorithms. Previous reconstruction techniques have considered debayering, denoising, resampling (align- ment) and exposure fusion as separate problems. In contrast, in this paper we present a unifying approach, performing HDR assembly directly from raw sensor data. Our framework includes a camera noise model adapted to HDR video and an algorithm for spatially adaptive HDR reconstruction based on fitting of local polynomial approximations to observed sensor data. The method is easy to implement and allows reconstruction to an arbitrary resolution and output mapping. We present an implementation in CUDA and show real-time performance for an experimental 4 Mpixel multi-sensor HDR video system. We further show that our algorithm has clear advantages over existing methods, both in terms of flexibility and reconstruction quality.\n    ",
        "submission_date": "2013-08-22T00:00:00",
        "last_modified_date": "2013-08-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1308.5038",
        "title": "Group-Sparse Signal Denoising: Non-Convex Regularization, Convex Optimization",
        "authors": [
            "Po-Yu Chen",
            "Ivan W. Selesnick"
        ],
        "abstract": "Convex optimization with sparsity-promoting convex regularization is a standard approach for estimating sparse signals in noise. In order to promote sparsity more strongly than convex regularization, it is also standard practice to employ non-convex optimization. In this paper, we take a third approach. We utilize a non-convex regularization term chosen such that the total cost function (consisting of data consistency and regularization terms) is convex. Therefore, sparsity is more strongly promoted than in the standard convex formulation, but without sacrificing the attractive aspects of convex optimization (unique minimum, robust algorithms, etc.). We use this idea to improve the recently developed 'overlapping group shrinkage' (OGS) algorithm for the denoising of group-sparse signals. The algorithm is applied to the problem of speech enhancement with favorable results in terms of both SNR and perceptual quality.\n    ",
        "submission_date": "2013-08-23T00:00:00",
        "last_modified_date": "2013-11-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1308.5063",
        "title": "Suspicious Object Recognition Method in Video Stream Based on Visual Attention",
        "authors": [
            "Panqu Wang",
            "Yan Zhang"
        ],
        "abstract": "We propose a state of the art method for intelligent object recognition and video surveillance based on human visual attention. Bottom up and top down attention are applied respectively in the process of acquiring interested object(saliency map) and object recognition. The revision of 4 channel PFT method is proposed for bottom up attention and enhances the speed and accuracy. Inhibit of return (IOR) is applied in judging the sequence of saliency object pop out. Euclidean distance of color distribution, object center coordinates and speed are considered in judging whether the target is match and suspicious. The extensive tests on videos and images show that our method in video analysis has high accuracy and fast speed compared with traditional method. The method can be applied into many fields such as video surveillance and security.\n    ",
        "submission_date": "2013-08-23T00:00:00",
        "last_modified_date": "2013-08-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1308.5315",
        "title": "Edge-detection applied to moving sand dunes on Mars",
        "authors": [
            "Amelia Carolina Sparavigna"
        ],
        "abstract": "Here we discuss the application of an edge detection filter, the Sobel filter of GIMP, to the recently discovered motion of some sand dunes on Mars. The filter allows a good comparison of an image HiRISE of 2007 and an image of 1999 recorded by the Mars Global Surveyor of the dunes in the Nili Patera caldera, measuring therefore the motion of the dunes on a longer period of time than that previously investigated.\n    ",
        "submission_date": "2013-08-24T00:00:00",
        "last_modified_date": "2013-08-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1308.5661",
        "title": "Detection of copy-move forgery in digital images based on DCT",
        "authors": [
            "Nathalie Diane Wandji",
            "Sun Xingming",
            "Moise Fah Kue"
        ],
        "abstract": "With rapid advances in digital information processing systems, and more specifically in digital image processing software, there is a widespread development of advanced tools and techniques for digital image forgery. One of the techniques most commonly used is the Copy-move forgery which proceeds by copying a part of an image and pasting it into the same image, in order to maliciously hide an object or a region. In this paper, we propose a method to detect this specific kind of counterfeit. Firstly, the color image is converted from RGB color space to YCbCr color space and then the R, G, B and Y-component are splitted into fixed-size overlapping blocks and, features are extracted from the R, G and B-components image blocks on one hand and on the other, from the DCT representation of the R, G, B and Ycomponent image block. The feature vectors obtained are then lexicographically sorted to make similar image blocks neighbors and duplicated image blocks are identified using Euclidean distance as similarity criterion. Experimental results showed that the proposed method can detect the duplicated regions when there is more than one copy move forged area in the image and even in case of slight rotations, JPEG compression, shift, scale, blur and noise addition.\n    ",
        "submission_date": "2013-08-26T00:00:00",
        "last_modified_date": "2013-08-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1308.5876",
        "title": "Hierarchized block wise image approximation by greedy pursuit strategies",
        "authors": [
            "Laura Rebollo-Neira",
            "Ryszard Maciol",
            "Shabnam Bibi"
        ],
        "abstract": "An approach for effective implementation of greedy selection methodologies, to approximate an image partitioned into blocks, is proposed. The method is specially designed for approximating partitions on a transformed image. It evolves by selecting, at each iteration step, i) the elements for approximating each of the blocks partitioning the image and ii) the hierarchized sequence in which the blocks are approximated to reach the required global condition on sparsity.\n    ",
        "submission_date": "2013-08-27T00:00:00",
        "last_modified_date": "2013-08-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1308.6056",
        "title": "Brain MRI Segmentation with Fast and Globally Convex Multiphase Active Contours",
        "authors": [
            "Juan C. Moreno",
            "V. B. S. Prasath",
            "Hugo Proenca",
            "K. Palaniappan"
        ],
        "abstract": "Multiphase active contour based models are useful in identifying multiple regions with different characteristics such as the mean values of regions. This is relevant in brain magnetic resonance images (MRIs), allowing the differentiation of white matter against gray matter. We consider a well defined globally convex formulation of Vese and Chan multiphase active contour model for segmenting brain MRI images. A well-established theory and an efficient dual minimization scheme are thoroughly described which guarantees optimal solutions and provides stable segmentations. Moreover, under the dual minimization implementation our model perfectly describes disjoint regions by avoiding local minima solutions. Experimental results indicate that the proposed approach provides better accuracy than other related multiphase active contour algorithms even under severe noise, intensity inhomogeneities, and partial volume effects.\n    ",
        "submission_date": "2013-08-28T00:00:00",
        "last_modified_date": "2013-08-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1308.6309",
        "title": "Text recognition in both ancient and cartographic documents",
        "authors": [
            "Nizar Zaghden",
            "Badreddine Khelifi",
            "Adel M. Alimi",
            "Remy Mullot"
        ],
        "abstract": "This paper deals with the recognition and matching of text in both cartographic maps and ancient documents. The purpose of this work is to find similar text regions based on statistical and global features. A phase of normalization is done first, in object to well categorize the same quantity of information. A phase of wordspotting is done next by combining local and global features. We make different experiments by combining the different techniques of extracting features in order to obtain better results in recognition phase. We applied fontspotting on both ancient documents and cartographic ones. We also applied the wordspotting in which we adopted a new technique which tries to compare the images of character and not the entire images words. We present the precision and recall values obtained with three methods for the new method of wordspotting applied on characters only.\n    ",
        "submission_date": "2013-08-28T00:00:00",
        "last_modified_date": "2013-08-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1308.6311",
        "title": "Categorizing ancient documents",
        "authors": [
            "Nizar Zaghden",
            "Remy Mullot",
            "Mohamed Adel Alimi"
        ],
        "abstract": "The analysis of historical documents is still a topical issue given the importance of information that can be extracted and also the importance given by the institutions to preserve their heritage. The main idea in order to characterize the content of the images of ancient documents after attempting to clean the image is segmented blocks texts from the same image and tries to find similar blocks in either the same image or the entire image database. Most approaches of offline handwriting recognition proceed by segmenting words into smaller pieces (usually characters) which are recognized separately. Recognition of a word then requires the recognition of all characters (OCR) that compose it. Our work focuses mainly on the characterization of classes in images of old documents. We use Som toolbox for finding classes in documents. We applied also fractal dimensions and points of interest to categorize and match ancient documents.\n    ",
        "submission_date": "2013-08-28T00:00:00",
        "last_modified_date": "2013-08-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1308.6319",
        "title": "A proposition of a robust system for historical document images indexation",
        "authors": [
            "Nizar Zaghden",
            "Remy Mullot",
            "Mohamed Adel Alimi"
        ],
        "abstract": "Characterizing noisy or ancient documents is a challenging problem up to now. Many techniques have been done in order to effectuate feature extraction and image indexation for such documents. Global approaches are in general less robust and exact than local approaches. That's why, we propose in this paper, a hybrid system based on global approach(fractal dimension), and a local one based on SIFT descriptor. The Scale Invariant Feature Transform seems to do well with our application since it's rotation invariant and relatively robust to changing ",
        "submission_date": "2013-08-28T00:00:00",
        "last_modified_date": "2013-08-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1308.6388",
        "title": "GNCGCP - Graduated NonConvexity and Graduated Concavity Procedure",
        "authors": [
            "Zhi-Yong Liu",
            "Hong Qiao"
        ],
        "abstract": "In this paper we propose the Graduated NonConvexity and Graduated Concavity Procedure (GNCGCP) as a general optimization framework to approximately solve the combinatorial optimization problems on the set of partial permutation matrices. GNCGCP comprises two sub-procedures, graduated nonconvexity (GNC) which realizes a convex relaxation and graduated concavity (GC) which realizes a concave relaxation. It is proved that GNCGCP realizes exactly a type of convex-concave relaxation procedure (CCRP), but with a much simpler formulation without needing convex or concave relaxation in an explicit way. Actually, GNCGCP involves only the gradient of the objective function and is therefore very easy to use in practical applications. Two typical NP-hard problems, (sub)graph matching and quadratic assignment problem (QAP), are employed to demonstrate its simplicity and state-of-the-art performance.\n    ",
        "submission_date": "2013-08-29T00:00:00",
        "last_modified_date": "2013-08-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1308.6401",
        "title": "A Synergistic Approach for Recovering Occlusion-Free Textured 3D Maps of Urban Facades from Heterogeneous Cartographic Data",
        "authors": [
            "Karim Hammoudi",
            "Fadi Dornaika",
            "Bahman Soheilian",
            "Bruno Vallet",
            "John McDonald",
            "Nicolas Paparoditis"
        ],
        "abstract": "In this paper we present a practical approach for generating an occlusion-free textured 3D map of urban facades by the synergistic use of terrestrial images, 3D point clouds and area-based information. Particularly in dense urban environments, the high presence of urban objects in front of the facades causes significant difficulties for several stages in computational building modeling. Major challenges lie on the one hand in extracting complete 3D facade quadrilateral delimitations and on the other hand in generating occlusion-free facade textures. For these reasons, we describe a straightforward approach for completing and recovering facade geometry and textures by exploiting the data complementarity of terrestrial multi-source imagery and area-based information.\n    ",
        "submission_date": "2013-08-29T00:00:00",
        "last_modified_date": "2013-08-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1308.6628",
        "title": "Joint Video and Text Parsing for Understanding Events and Answering Queries",
        "authors": [
            "Kewei Tu",
            "Meng Meng",
            "Mun Wai Lee",
            "Tae Eun Choe",
            "Song-Chun Zhu"
        ],
        "abstract": "We propose a framework for parsing video and text jointly for understanding events and answering user queries. Our framework produces a parse graph that represents the compositional structures of spatial information (objects and scenes), temporal information (actions and events) and causal information (causalities between events and fluents) in the video and text. The knowledge representation of our framework is based on a spatial-temporal-causal And-Or graph (S/T/C-AOG), which jointly models possible hierarchical compositions of objects, scenes and events as well as their interactions and mutual contexts, and specifies the prior probabilistic distribution of the parse graphs. We present a probabilistic generative model for joint parsing that captures the relations between the input video/text, their corresponding parse graphs and the joint parse graph. Based on the probabilistic model, we propose a joint parsing system consisting of three modules: video parsing, text parsing and joint inference. Video parsing and text parsing produce two parse graphs from the input video and text respectively. The joint inference module produces a joint parse graph by performing matching, deduction and revision on the video and text parse graphs. The proposed framework has the following objectives: Firstly, we aim at deep semantic parsing of video and text that goes beyond the traditional bag-of-words approaches; Secondly, we perform parsing and reasoning across the spatial, temporal and causal dimensions based on the joint S/T/C-AOG representation; Thirdly, we show that deep joint parsing facilitates subsequent applications such as generating narrative text descriptions and answering queries in the forms of who, what, when, where and why. We empirically evaluated our system based on comparison against ground-truth as well as accuracy of query answering and obtained satisfactory results.\n    ",
        "submission_date": "2013-08-29T00:00:00",
        "last_modified_date": "2014-02-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1308.6687",
        "title": "Image Set based Collaborative Representation for Face Recognition",
        "authors": [
            "Pengfei Zhu",
            "Wangmeng Zuo",
            "Lei Zhang",
            "Simon C.K. Shiu",
            "David Zhang"
        ],
        "abstract": "With the rapid development of digital imaging and communication technologies, image set based face recognition (ISFR) is becoming increasingly important. One key issue of ISFR is how to effectively and efficiently represent the query face image set by using the gallery face image sets. The set-to-set distance based methods ignore the relationship between gallery sets, while representing the query set images individually over the gallery sets ignores the correlation between query set images. In this paper, we propose a novel image set based collaborative representation and classification method for ISFR. By modeling the query set as a convex or regularized hull, we represent this hull collaboratively over all the gallery sets. With the resolved representation coefficients, the distance between the query set and each gallery set can then be calculated for classification. The proposed model naturally and effectively extends the image based collaborative representation to an image set based one, and our extensive experiments on benchmark ISFR databases show the superiority of the proposed method to state-of-the-art ISFR methods under different set sizes in terms of both recognition rate and efficiency.\n    ",
        "submission_date": "2013-08-30T00:00:00",
        "last_modified_date": "2013-08-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1308.6721",
        "title": "Discriminative Parameter Estimation for Random Walks Segmentation",
        "authors": [
            "Pierre-Yves Baudin",
            "Danny Goodman",
            "Puneet Kumar",
            "Noura Azzabou",
            "Pierre G. Carlier",
            "Nikos Paragios",
            "M. Pawan Kumar"
        ],
        "abstract": "The Random Walks (RW) algorithm is one of the most e - cient and easy-to-use probabilistic segmentation methods. By combining contrast terms with prior terms, it provides accurate segmentations of medical images in a fully automated manner. However, one of the main drawbacks of using the RW algorithm is that its parameters have to be hand-tuned. we propose a novel discriminative learning framework that estimates the parameters using a training dataset. The main challenge we face is that the training samples are not fully supervised. Speci cally, they provide a hard segmentation of the images, instead of a proba- bilistic segmentation. We overcome this challenge by treating the opti- mal probabilistic segmentation that is compatible with the given hard segmentation as a latent variable. This allows us to employ the latent support vector machine formulation for parameter estimation. We show that our approach signi cantly outperforms the baseline methods on a challenging dataset consisting of real clinical 3D MRI volumes of skeletal muscles.\n    ",
        "submission_date": "2013-08-30T00:00:00",
        "last_modified_date": "2013-08-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1308.6804",
        "title": "A Low-Dimensional Representation for Robust Partial Isometric Correspondences Computation",
        "authors": [
            "Alan Brunton",
            "Michael Wand",
            "Stefanie Wuhrer",
            "Hans-Peter Seidel",
            "Tino Weinkauf"
        ],
        "abstract": "Intrinsic isometric shape matching has become the standard approach for pose invariant correspondence estimation among deformable shapes. Most existing approaches assume global consistency, i.e., the metric structure of the whole manifold must not change significantly. While global isometric matching is well understood, only a few heuristic solutions are known for partial matching. Partial matching is particularly important for robustness to topological noise (incomplete data and contacts), which is a common problem in real-world 3D scanner data. In this paper, we introduce a new approach to partial, intrinsic isometric matching. Our method is based on the observation that isometries are fully determined by purely local information: a map of a single point and its tangent space fixes an isometry for both global and the partial maps. From this idea, we develop a new representation for partial isometric maps based on equivalence classes of correspondences between pairs of points and their tangent spaces. From this, we derive a local propagation algorithm that find such mappings efficiently. In contrast to previous heuristics based on RANSAC or expectation maximization, our method is based on a simple and sound theoretical model and fully deterministic. We apply our approach to register partial point clouds and compare it to the state-of-the-art methods, where we obtain significant improvements over global methods for real-world data and stronger guarantees than previous heuristic partial matching algorithms.\n    ",
        "submission_date": "2013-08-30T00:00:00",
        "last_modified_date": "2014-01-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1309.0123",
        "title": "A Robust Alternating Direction Method for Constrained Hybrid Variational Deblurring Model",
        "authors": [
            "Ryan Wen Liu",
            "Tian Xu"
        ],
        "abstract": "In this work, a new constrained hybrid variational deblurring model is developed by combining the non-convex first- and second-order total variation regularizers. Moreover, a box constraint is imposed on the proposed model to guarantee high deblurring performance. The developed constrained hybrid variational model could achieve a good balance between preserving image details and alleviating ringing artifacts. In what follows, we present the corresponding numerical solution by employing an iteratively reweighted algorithm based on alternating direction method of multipliers. The experimental results demonstrate the superior performance of the proposed method in terms of quantitative and qualitative image quality assessments.\n    ",
        "submission_date": "2013-08-31T00:00:00",
        "last_modified_date": "2013-10-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1309.0213",
        "title": "Learning to Rank for Blind Image Quality Assessment",
        "authors": [
            "Fei Gao",
            "Dacheng Tao",
            "Xinbo Gao",
            "Xuelong Li"
        ],
        "abstract": "Blind image quality assessment (BIQA) aims to predict perceptual image quality scores without access to reference images. State-of-the-art BIQA methods typically require subjects to score a large number of images to train a robust model. However, subjective quality scores are imprecise, biased, and inconsistent, and it is challenging to obtain a large scale database, or to extend existing databases, because of the inconvenience of collecting images, training the subjects, conducting subjective experiments, and realigning human quality evaluations. To combat these limitations, this paper explores and exploits preference image pairs (PIPs) such as \"the quality of image $I_a$ is better than that of image $I_b$\" for training a robust BIQA model. The preference label, representing the relative quality of two images, is generally precise and consistent, and is not sensitive to image content, distortion type, or subject identity; such PIPs can be generated at very low cost. The proposed BIQA method is one of learning to rank. We first formulate the problem of learning the mapping from the image features to the preference label as one of classification. In particular, we investigate the utilization of a multiple kernel learning algorithm based on group lasso (MKLGL) to provide a solution. A simple but effective strategy to estimate perceptual image quality scores is then presented. Experiments show that the proposed BIQA method is highly effective and achieves comparable performance to state-of-the-art BIQA algorithms. Moreover, the proposed method can be easily extended to new distortion categories.\n    ",
        "submission_date": "2013-09-01T00:00:00",
        "last_modified_date": "2019-04-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1309.0261",
        "title": "Multi-Column Deep Neural Networks for Offline Handwritten Chinese Character Classification",
        "authors": [
            "Dan Cire\u015fan",
            "J\u00fcrgen Schmidhuber"
        ],
        "abstract": "Our Multi-Column Deep Neural Networks achieve best known recognition rates on Chinese characters from the ICDAR 2011 and 2013 offline handwriting competitions, approaching human performance.\n    ",
        "submission_date": "2013-09-01T00:00:00",
        "last_modified_date": "2013-09-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1309.0309",
        "title": "A Study on Unsupervised Dictionary Learning and Feature Encoding for Action Classification",
        "authors": [
            "Xiaojiang Peng",
            "Qiang Peng",
            "Yu Qiao",
            "Junzhou Chen",
            "Mehtab Afzal"
        ],
        "abstract": "Many efforts have been devoted to develop alternative methods to traditional vector quantization in image domain such as sparse coding and soft-assignment. These approaches can be split into a dictionary learning phase and a feature encoding phase which are often closely connected. In this paper, we investigate the effects of these phases by separating them for video-based action classification. We compare several dictionary learning methods and feature encoding schemes through extensive experiments on KTH and HMDB51 datasets. Experimental results indicate that sparse coding performs consistently better than the other encoding methods in large complex dataset (i.e., HMDB51), and it is robust to different dictionaries. For small simple dataset (i.e., KTH) with less variation, however, all the encoding strategies perform competitively. In addition, we note that the strength of sophisticated encoding approaches comes not from their corresponding dictionaries but the encoding mechanisms, and we can just use randomly selected exemplars as dictionaries for video-based action classification.\n    ",
        "submission_date": "2013-09-02T00:00:00",
        "last_modified_date": "2013-09-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1309.0999",
        "title": "Minutiae Based Thermal Face Recognition using Blood Perfusion Data",
        "authors": [
            "Ayan Seal",
            "Mita Nasipuri",
            "Debotosh Bhattacharjee",
            "Dipak Kumar Basu"
        ],
        "abstract": "This paper describes an efficient approach for human face recognition based on blood perfusion data from infra-red face images. Blood perfusion data are characterized by the regional blood flow in human tissue and therefore do not depend entirely on surrounding temperature. These data bear a great potential for deriving discriminating facial thermogram for better classification and recognition of face images in comparison to optical image data. Blood perfusion data are related to distribution of blood vessels under the face skin. A distribution of blood vessels are unique for each person and as a set of extracted minutiae points from a blood perfusion data of a human face should be unique for that face. There may be several such minutiae point sets for a single face but all of these correspond to that particular face only. Entire face image is partitioned into equal blocks and the total number of minutiae points from each block is computed to construct final vector. Therefore, the size of the feature vectors is found to be same as total number of blocks considered. For classification, a five layer feed-forward backpropagation neural network has been used. A number of experiments were conducted to evaluate the performance of the proposed face recognition system with varying block sizes. Experiments have been performed on the database created at our own laboratory. The maximum success of 91.47% recognition has been achieved with block size 8X8.\n    ",
        "submission_date": "2013-09-04T00:00:00",
        "last_modified_date": "2013-09-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1309.1000",
        "title": "Automated Thermal Face recognition based on Minutiae Extraction",
        "authors": [
            "Ayan Seal",
            "Suranjan Ganguly",
            "Debotosh Bhattacharjee",
            "Mita Nasipuri",
            "Dipak Kr.Basu"
        ],
        "abstract": "In this paper an efficient approach for human face recognition based on the use of minutiae points in thermal face image is proposed. The thermogram of human face is captured by thermal infra-red camera. Image processing methods are used to pre-process the captured thermogram, from which different physiological features based on blood perfusion data are extracted. Blood perfusion data are related to distribution of blood vessels under the face skin. In the present work, three different methods have been used to get the blood perfusion image, namely bit-plane slicing and medial axis transform, morphological erosion and medial axis transform, sobel edge operators. Distribution of blood vessels is unique for each person and a set of extracted minutiae points from a blood perfusion data of a human face should be unique for that face. Two different methods are discussed for extracting minutiae points from blood perfusion data. For extraction of features entire face image is partitioned into equal size blocks and the total number of minutiae points from each block is computed to construct final feature vector. Therefore, the size of the feature vectors is found to be same as total number of blocks considered. A five layer feed-forward back propagation neural network is used as the classification tool. A number of experiments were conducted to evaluate the performance of the proposed face recognition methodologies with varying block size on the database created at our own laboratory. It has been found that the first method supercedes the other two producing an accuracy of 97.62% with block size 16X16 for bit-plane 4.\n    ",
        "submission_date": "2013-09-04T00:00:00",
        "last_modified_date": "2013-09-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1309.1009",
        "title": "A Comparative Study of Human thermal face recognition based on Haar wavelet transform (HWT) and Local Binary Pattern (LBP)",
        "authors": [
            "Ayan Seal",
            "Suranjan Ganguly",
            "Debotosh Bhattacharjee",
            "Mita Nasipuri",
            "Dipak Kumar Basu"
        ],
        "abstract": "Thermal infra-red (IR) images focus on changes of temperature distribution on facial muscles and blood vessels. These temperature changes can be regarded as texture features of images. A comparative study of face recognition methods working in thermal spectrum is carried out in this paper. In these study two local-matching methods based on Haar wavelet transform and Local Binary Pattern (LBP) are analyzed. Wavelet transform is a good tool to analyze multi-scale, multi-direction changes of texture. Local binary patterns (LBP) are a type of feature used for classification in computer vision. Firstly, human thermal IR face image is preprocessed and cropped the face region only from the entire image. Secondly, two different approaches are used to extract the features from the cropped face region. In the first approach, the training images and the test images are processed with Haar wavelet transform and the LL band and the average of LH/HL/HH bands sub-images are created for each face image. Then a total confidence matrix is formed for each face image by taking a weighted sum of the corresponding pixel values of the LL band and average band. For LBP feature extraction, each of the face images in training and test datasets is divided into 161 numbers of sub images, each of size 8X8 pixels. For each such sub images, LBP features are extracted which are concatenated in row wise manner. PCA is performed separately on the individual feature set for dimensionality reeducation. Finally two different classifiers are used to classify face images. One such classifier multi-layer feed forward neural network and another classifier is minimum distance classifier. The Experiments have been performed on the database created at our own laboratory and Terravic Facial IR Database.\n    ",
        "submission_date": "2013-09-04T00:00:00",
        "last_modified_date": "2013-09-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1309.1080",
        "title": "Boosting in Location Space",
        "authors": [
            "Damian Eads",
            "David Helmbold",
            "Ed Rosten"
        ],
        "abstract": "The goal of object detection is to find objects in an image. An object detector accepts an image and produces a list of locations as $(x,y)$ pairs. Here we introduce a new concept: {\\bf location-based boosting}. Location-based boosting differs from previous boosting algorithms because it optimizes a new spatial loss function to combine object detectors, each of which may have marginal performance, into a single, more accurate object detector. A structured representation of object locations as a list of $(x,y)$ pairs is a more natural domain for object detection than the spatially unstructured representation produced by classifiers. Furthermore, this formulation allows us to take advantage of the intuition that large areas of the background are uninteresting and it is not worth expending computational effort on them. This results in a more scalable algorithm because it does not need to take measures to prevent the background data from swamping the foreground data such as subsampling or applying an ad-hoc weighting to the pixels. We first present the theory of location-based boosting, and then motivate it with empirical results on a challenging data set.\n    ",
        "submission_date": "2013-09-04T00:00:00",
        "last_modified_date": "2013-09-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1309.1155",
        "title": "Minutiae Based Thermal Human Face Recognition using Label Connected Component Algorithm",
        "authors": [
            "Ayan Seal",
            "Suranjan Ganguly",
            "Debotosh Bhattacharjee",
            "Mita Nasipuri",
            "Dipak Kumar Basu"
        ],
        "abstract": "In this paper, a thermal infra red face recognition system for human identification and verification using blood perfusion data and back propagation feed forward neural network is proposed. The system consists of three steps. At the very first step face region is cropped from the colour 24-bit input images. Secondly face features are extracted from the croped region, which will be taken as the input of the back propagation feed forward neural network in the third step and classification and recognition is carried out. The proposed approaches are tested on a number of human thermal infra red face images created at our own laboratory. Experimental results reveal the higher degree performance\n    ",
        "submission_date": "2013-09-04T00:00:00",
        "last_modified_date": "2013-09-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1309.1156",
        "title": "Thermal Human face recognition based on Haar wavelet transform and series matching technique",
        "authors": [
            "Ayan Seal",
            "Suranjan Ganguly",
            "Debotosh Bhattacharjee",
            "Mita Nasipuri",
            "Dipak kr. Basu"
        ],
        "abstract": "Thermal infrared (IR) images represent the heat patterns emitted from hot object and they do not consider the energies reflected from an object. Objects living or non-living emit different amounts of IR energy according to their body temperature and characteristics. Humans are homoeothermic and hence capable of maintaining constant temperature under different surrounding temperature. Face recognition from thermal (IR) images should focus on changes of temperature on facial blood vessels. These temperature changes can be regarded as texture features of images and wavelet transform is a very good tool to analyze multi-scale and multi-directional texture. Wavelet transform is also used for image dimensionality reduction, by removing redundancies and preserving original features of the image. The sizes of the facial images are normally large. So, the wavelet transform is used before image similarity is measured. Therefore this paper describes an efficient approach of human face recognition based on wavelet transform from thermal IR images. The system consists of three steps. At the very first step, human thermal IR face image is preprocessed and the face region is only cropped from the entire image. Secondly, Haar wavelet is used to extract low frequency band from the cropped face region. Lastly, the image classification between the training images and the test images is done, which is based on low-frequency components. The proposed approach is tested on a number of human thermal infrared face images created at our own laboratory and Terravic Facial IR Database. Experimental results indicated that the thermal infra red face images can be recognized by the proposed system effectively. The maximum success of 95% recognition has been achieved.\n    ",
        "submission_date": "2013-09-04T00:00:00",
        "last_modified_date": "2013-09-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1309.1539",
        "title": "Practical Matrix Completion and Corruption Recovery using Proximal Alternating Robust Subspace Minimization",
        "authors": [
            "Yu-Xiang Wang",
            "Choon Meng Lee",
            "Loong-Fah Cheong",
            "Kim-Chuan Toh"
        ],
        "abstract": "Low-rank matrix completion is a problem of immense practical importance. Recent works on the subject often use nuclear norm as a convex surrogate of the rank function. Despite its solid theoretical foundation, the convex version of the problem often fails to work satisfactorily in real-life applications. Real data often suffer from very few observations, with support not meeting the random requirements, ubiquitous presence of noise and potentially gross corruptions, sometimes with these simultaneously occurring.\n",
        "submission_date": "2013-09-06T00:00:00",
        "last_modified_date": "2014-10-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1309.1628",
        "title": "Topology preserving thinning for cell complexes",
        "authors": [
            "Pawe\u0142 D\u0142otko",
            "Ruben Specogna"
        ],
        "abstract": "A topology preserving skeleton is a synthetic representation of an object that retains its topology and many of its significant morphological properties. The process of obtaining the skeleton, referred to as skeletonization or thinning, is a very active research area. It plays a central role in reducing the amount of information to be processed during image analysis and visualization, computer-aided diagnosis or by pattern recognition algorithms.\n",
        "submission_date": "2013-09-06T00:00:00",
        "last_modified_date": "2014-02-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1309.1830",
        "title": "Radar shadow detection in SAR images using DEM and projections",
        "authors": [
            "V. B. S. Prasath",
            "O. Haddad"
        ],
        "abstract": "Synthetic aperture radar (SAR) images are widely used in target recognition tasks nowadays. In this letter, we propose an automatic approach for radar shadow detection and extraction from SAR images utilizing geometric projections along with the digital elevation model (DEM) which corresponds to the given geo-referenced SAR image. First, the DEM is rotated into the radar geometry so that each row would match that of a radar line of sight. Next, we extract the shadow regions by processing row by row until the image is covered fully. We test the proposed shadow detection approach on different DEMs and a simulated 1D signals and 2D hills and volleys modeled by various variance based Gaussian functions. Experimental results indicate the proposed algorithm produces good results in detecting shadows in SAR images with high resolution.\n    ",
        "submission_date": "2013-09-07T00:00:00",
        "last_modified_date": "2013-09-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1309.2057",
        "title": "Single image super resolution in spatial and wavelet domain",
        "authors": [
            "Sapan Naik",
            "Nikunj Patel"
        ],
        "abstract": "Recently single image super resolution is very important research area to generate high resolution image from given low resolution image. Algorithms of single image resolution are mainly based on wavelet domain and spatial domain. Filters support to model the regularity of natural images is exploited in wavelet domain while edges of images get sharp during up sampling in spatial domain. Here single image super resolution algorithm is presented which based on both spatial and wavelet domain and take the advantage of both. Algorithm is iterative and use back projection to minimize reconstruction error. Wavelet based denoising method is also introduced to remove noise.\n    ",
        "submission_date": "2013-09-09T00:00:00",
        "last_modified_date": "2013-09-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1309.2074",
        "title": "Learning Transformations for Clustering and Classification",
        "authors": [
            "Qiang Qiu",
            "Guillermo Sapiro"
        ],
        "abstract": "A low-rank transformation learning framework for subspace clustering and classification is here proposed. Many high-dimensional data, such as face images and motion sequences, approximately lie in a union of low-dimensional subspaces. The corresponding subspace clustering problem has been extensively studied in the literature to partition such high-dimensional data into clusters corresponding to their underlying low-dimensional subspaces. However, low-dimensional intrinsic structures are often violated for real-world observations, as they can be corrupted by errors or deviate from ideal models. We propose to address this by learning a linear transformation on subspaces using matrix rank, via its convex surrogate nuclear norm, as the optimization criteria. The learned linear transformation restores a low-rank structure for data from the same subspace, and, at the same time, forces a a maximally separated structure for data from different subspaces. In this way, we reduce variations within subspaces, and increase separation between subspaces for a more robust subspace clustering. This proposed learned robust subspace clustering framework significantly enhances the performance of existing subspace clustering methods. Basic theoretical results here presented help to further support the underlying framework. To exploit the low-rank structures of the transformed subspaces, we further introduce a fast subspace clustering technique, which efficiently combines robust PCA with sparse modeling. When class labels are present at the training stage, we show this low-rank transformation framework also significantly enhances classification performance. Extensive experiments using public datasets are presented, showing that the proposed approach significantly outperforms state-of-the-art methods for subspace clustering and classification.\n    ",
        "submission_date": "2013-09-09T00:00:00",
        "last_modified_date": "2014-03-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1309.2506",
        "title": "A multi-stream hmm approach to offline handwritten arabic word recognition",
        "authors": [
            "Ahlam Maqqor",
            "Akram Halli",
            "Khaled Satori"
        ],
        "abstract": "In This paper we presented new approach for cursive Arabic text recognition system. The objective is to propose methodology analytical offline recognition of handwritten Arabic for rapid implementation. The first part in the writing recognition system is the preprocessing phase is the preprocessing phase to prepare the data was introduces and extracts a set of simple statistical features by two methods : from a window which is sliding long that text line the right to left and the approach VH2D (consists in projecting every character on the abscissa, on the ordinate and the diagonals 45\u00b0 and 135\u00b0) . It then injects the resulting feature vectors to Hidden Markov Model (HMM) and combined the two HMM by multi-stream approach.\n    ",
        "submission_date": "2013-09-10T00:00:00",
        "last_modified_date": "2013-09-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1309.2752",
        "title": "Robust Periocular Recognition By Fusing Sparse Representations of Color and Geometry Information",
        "authors": [
            "Juan C. Moreno",
            "V. B. S. Prasath",
            "Gil Santos",
            "Hugo Proenca"
        ],
        "abstract": "In this paper, we propose a re-weighted elastic net (REN) model for biometric recognition. The new model is applied to data separated into geometric and color spatial components. The geometric information is extracted using a fast cartoon - texture decomposition model based on a dual formulation of the total variation norm allowing us to carry information about the overall geometry of images. Color components are defined using linear and nonlinear color spaces, namely the red-green-blue (RGB), chromaticity-brightness (CB) and hue-saturation-value (HSV). Next, according to a Bayesian fusion-scheme, sparse representations for classification purposes are obtained. The scheme is numerically solved using a gradient projection (GP) algorithm. In the empirical validation of the proposed model, we have chosen the periocular region, which is an emerging trait known for its robustness against low quality data. Our results were obtained in the publicly available UBIRIS.v2 data set and show consistent improvements in recognition effectiveness when compared to related state-of-the-art techniques.\n    ",
        "submission_date": "2013-09-11T00:00:00",
        "last_modified_date": "2013-09-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1309.3006",
        "title": "The Classification Accuracy of Multiple-Metric Learning Algorithm on Multi-Sensor Fusion",
        "authors": [
            "Firouz Abdullah Al-Wassai",
            "N.V. Kalyankar"
        ],
        "abstract": "This paper focuses on two main issues; first one is the impact of Similarity Search to learning the training sample in metric space, and searching based on supervised learning classi-fication. In particular, four metrics space searching are based on spatial information that are introduced as the following; Cheby-shev Distance (CD); Bray Curtis Distance (BCD); Manhattan Distance (MD) and Euclidean Distance(ED) classifiers. The second issue investigates the performance of combination of mul-ti-sensor images on the supervised learning classification accura-cy. QuickBird multispectral data (MS) and panchromatic data (PAN) have been used in this study to demonstrate the enhance-ment and accuracy assessment of fused image over the original images. The supervised classification results of fusion image generated better than the MS did. QuickBird and the best results with ED classifier than the other did.\n    ",
        "submission_date": "2013-09-11T00:00:00",
        "last_modified_date": "2013-09-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1309.3418",
        "title": "A Novel Approach in detecting pose orientation of a 3D face required for face",
        "authors": [
            "Parama Bagchi",
            "Debotosh Bhattacharjee",
            "Mita Nasipuri",
            "Dipak Kumar Basu"
        ],
        "abstract": "In this paper we present a novel approach that takes as input a 3D image and gives as output its pose i.e. it tells whether the face is oriented with respect the X, Y or Z axes with angles of rotation up to 40 degree. All the experiments have been performed on the FRAV3D Database. After applying the proposed algorithm to the 3D facial surface we have obtained i.e. on 848 3D face images our method detected the pose correctly for 566 face images,thus giving an approximately 67 % of correct pose detection.\n    ",
        "submission_date": "2013-09-13T00:00:00",
        "last_modified_date": "2013-09-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1309.3425",
        "title": "A method for nose-tip based 3D face registration using maximum intensity algorithm",
        "authors": [
            "Parama Bagchi",
            "Debotosh Bhattacharjee",
            "Mita Nasipuri",
            "Dipak kr. Basu"
        ],
        "abstract": "In this paper we present a novel technique of registering 3D images across pose. In this context, we have taken into account the images which are aligned across X, Y and Z axes. We have first determined the angle across which the image is rotated with respect to X, Y and Z axes and then translation is performed on the images. After testing the proposed method on 472 images from the FRAV3D database, the method correctly registers 358 images thus giving a performance rate of 75.84%.\n    ",
        "submission_date": "2013-09-13T00:00:00",
        "last_modified_date": "2013-09-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1309.3809",
        "title": "Visual-Semantic Scene Understanding by Sharing Labels in a Context Network",
        "authors": [
            "Ishani Chakraborty",
            "Ahmed Elgammal"
        ],
        "abstract": "We consider the problem of naming objects in complex, natural scenes containing widely varying object appearance and subtly different names. Informed by cognitive research, we propose an approach based on sharing context based object hypotheses between visual and lexical spaces. To this end, we present the Visual Semantic Integration Model (VSIM) that represents object labels as entities shared between semantic and visual contexts and infers a new image by updating labels through context switching. At the core of VSIM is a semantic Pachinko Allocation Model and a visual nearest neighbor Latent Dirichlet Allocation Model. For inference, we derive an iterative Data Augmentation algorithm that pools the label probabilities and maximizes the joint label posterior of an image. Our model surpasses the performance of state-of-art methods in several visual tasks on the challenging SUN09 dataset.\n    ",
        "submission_date": "2013-09-16T00:00:00",
        "last_modified_date": "2013-09-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1309.3848",
        "title": "SEEDS: Superpixels Extracted via Energy-Driven Sampling",
        "authors": [
            "Michael Van den Bergh",
            "Xavier Boix",
            "Gemma Roig",
            "Luc Van Gool"
        ],
        "abstract": "Superpixel algorithms aim to over-segment the image by grouping pixels that belong to the same object. Many state-of-the-art superpixel algorithms rely on minimizing objective functions to enforce color ho- mogeneity. The optimization is accomplished by sophis- ticated methods that progressively build the superpix- els, typically by adding cuts or growing superpixels. As a result, they are computationally too expensive for real-time applications. We introduce a new approach based on a simple hill-climbing optimization. Starting from an initial superpixel partitioning, it continuously refines the superpixels by modifying the boundaries. We define a robust and fast to evaluate energy function, based on enforcing color similarity between the bound- aries and the superpixel color histogram. In a series of experiments, we show that we achieve an excellent com- promise between accuracy and efficiency. We are able to achieve a performance comparable to the state-of- the-art, but in real-time on a single Intel i7 CPU at 2.8GHz.\n    ",
        "submission_date": "2013-09-16T00:00:00",
        "last_modified_date": "2013-09-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1309.4024",
        "title": "The Cyborg Astrobiologist: Matching of Prior Textures by Image Compression for Geological Mapping and Novelty Detection",
        "authors": [
            "P.C. McGuire",
            "A. Bonnici",
            "K.R. Bruner",
            "C. Gross",
            "J. Orm\u00f6",
            "R.A. Smosna",
            "S. Walter",
            "L. Wendt"
        ],
        "abstract": "(abridged) We describe an image-comparison technique of Heidemann and Ritter that uses image compression, and is capable of: (i) detecting novel textures in a series of images, as well as of: (ii) alerting the user to the similarity of a new image to a previously-observed texture. This image-comparison technique has been implemented and tested using our Astrobiology Phone-cam system, which employs Bluetooth communication to send images to a local laptop server in the field for the image-compression analysis. We tested the system in a field site displaying a heterogeneous suite of sandstones, limestones, mudstones and coalbeds. Some of the rocks are partly covered with lichen. The image-matching procedure of this system performed very well with data obtained through our field test, grouping all images of yellow lichens together and grouping all images of a coal bed together, and giving a 91% accuracy for similarity detection. Such similarity detection could be employed to make maps of different geological units. The novelty-detection performance of our system was also rather good (a 64% accuracy). Such novelty detection may become valuable in searching for new geological units, which could be of astrobiological interest. The image-comparison technique is an unsupervised technique that is not capable of directly classifying an image as containing a particular geological feature; labeling of such geological features is done post facto by human geologists associated with this study, for the purpose of analyzing the system's performance. By providing more advanced capabilities for similarity detection and novelty detection, this image-compression technique could be useful in giving more scientific autonomy to robotic planetary rovers, and in assisting human astronauts in their geological exploration and assessment.\n    ",
        "submission_date": "2013-09-16T00:00:00",
        "last_modified_date": "2013-09-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1309.4306",
        "title": "Sparsity Based Poisson Denoising with Dictionary Learning",
        "authors": [
            "Raja Giryes",
            "Michael Elad"
        ],
        "abstract": "The problem of Poisson denoising appears in various imaging applications, such as low-light photography, medical imaging and microscopy. In cases of high SNR, several transformations exist so as to convert the Poisson noise into an additive i.i.d. Gaussian noise, for which many effective algorithms are available. However, in a low SNR regime, these transformations are significantly less accurate, and a strategy that relies directly on the true noise statistics is required. A recent work by Salmon et al. took this route, proposing a patch-based exponential image representation model based on GMM (Gaussian mixture model), leading to state-of-the-art results. In this paper, we propose to harness sparse-representation modeling to the image patches, adopting the same exponential idea. Our scheme uses a greedy pursuit with boot-strapping based stopping condition and dictionary learning within the denoising process. The reconstruction performance of the proposed scheme is competitive with leading methods in high SNR, and achieving state-of-the-art results in cases of low SNR.\n    ",
        "submission_date": "2013-09-17T00:00:00",
        "last_modified_date": "2014-10-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1309.4426",
        "title": "GRED: Graph-Regularized 3D Shape Reconstruction from Highly Anisotropic and Noisy Images",
        "authors": [
            "Christian Widmer",
            "Philipp Drewe",
            "Xinghua Lou",
            "Shefali Umrania",
            "Stephanie Heinrich",
            "Gunnar R\u00e4tsch"
        ],
        "abstract": "Analysis of microscopy images can provide insight into many biological processes. One particularly challenging problem is cell nuclear segmentation in highly anisotropic and noisy 3D image data. Manually localizing and segmenting each and every cell nuclei is very time consuming, which remains a bottleneck in large scale biological experiments. In this work we present a tool for automated segmentation of cell nuclei from 3D fluorescent microscopic data. Our tool is based on state-of-the-art image processing and machine learning techniques and supports a friendly graphical user interface (GUI). We show that our tool is as accurate as manual annotation but greatly reduces the time for the registration.\n    ",
        "submission_date": "2013-09-17T00:00:00",
        "last_modified_date": "2013-09-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1309.4573",
        "title": "A novel approach for nose tip detection using smoothing by weighted median filtering applied to 3D face images in variant poses",
        "authors": [
            "Parama Bagchi",
            "Debotosh Bhattacharjee",
            "Mita Nasipuri",
            "Dipak Kumar Basu"
        ],
        "abstract": "This paper is based on an application of smoothing of 3D face images followed by feature detection i.e. detecting the nose tip. The present method uses a weighted mesh median filtering technique for smoothing. In this present smoothing technique we have built the neighborhood surrounding a particular point in 3D face and replaced that with the weighted value of the surrounding points in 3D face image. After applying the smoothing technique to the 3D face images our experimental results show that we have obtained considerable improvement as compared to the algorithm without smoothing. We have used here the maximum intensity algorithm for detecting the nose-tip and this method correctly detects the nose-tip in case of any pose i.e. along X, Y, and Z axes. The present technique gave us worked successfully on 535 out of 542 3D face images as compared to the method without smoothing which worked only on 521 3D face images out of 542 face images. Thus we have obtained a 98.70% performance rate over 96.12% performance rate of the algorithm without smoothing. All the experiments have been performed on the FRAV3D database.\n    ",
        "submission_date": "2013-09-18T00:00:00",
        "last_modified_date": "2013-09-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1309.4577",
        "title": "Detection of pose orientation across single and multiple axes in case of 3D face images",
        "authors": [
            "Parama Bagchi",
            "Debotosh Bhattacharjee",
            "Mita Nasipuri",
            "Dipak Kumar Basu"
        ],
        "abstract": "In this paper, we propose a new approach that takes as input a 3D face image across X, Y and Z axes as well as both Y and X axes and gives output as its pose i.e. it tells whether the face is oriented with respect the X, Y or Z axes or is it oriented across multiple axes with angles of rotation up to 42 degree. All the experiments have been performed on the FRAV3D, GAVADB and Bosphorus database which has two figures of each individual across multiple axes. After applying the proposed algorithm to the 3D facial surface from FRAV3D on 848 3D faces, 566 3D faces were correctly recognized for pose thus giving 67% of correct identification rate. We had experimented on 420 images from the GAVADB database, and only 336 images were detected for correct pose identification rate i.e. 80% and from Bosphorus database on 560 images only 448 images were detected for correct pose identification i.e. 80%.abstract goes here.\n    ",
        "submission_date": "2013-09-18T00:00:00",
        "last_modified_date": "2013-09-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1309.4582",
        "title": "A novel approach to nose-tip and eye corners detection using H-K Curvature Analysis in case of 3D images",
        "authors": [
            "Parama Bagchi",
            "Debotosh Bhattacharjee",
            "Mita Nasipuri",
            "Dipak Kumar Basu"
        ],
        "abstract": "In this paper we present a novel method that combines a HK curvature-based approach for three-dimensional (3D) face detection in different poses (X-axis, Y-axis and Z-axis). Salient face features, such as the eyes and nose, are detected through an analysis of the curvature of the entire facial surface. All the experiments have been performed on the FRAV3D Database. After applying the proposed algorithm to the 3D facial surface we have obtained considerably good results i.e. on 752 3D face images our method detected the eye corners for 543 face images, thus giving a 72.20% of eye corners detection and 743 face images for nose-tip detection thus giving a 98.80% of good nose tip localization\n    ",
        "submission_date": "2013-09-18T00:00:00",
        "last_modified_date": "2013-09-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1309.5004",
        "title": "Blind Deconvolution via Maximum Kurtosis Adaptive Filtering",
        "authors": [
            "Deborah Pereg",
            "Doron Benzvi"
        ],
        "abstract": "In this paper, we present an algorithm for identifying a parametrically described destructive unknown system based on a non-gaussianity measure. It is known that under certain conditions the output of a linear system is more gaussian than the input. Hence, an inverse filter is searched, such that its output is minimally gaussian. We use the kurtosis as a measure of the non-gaussianity of the signal. A maximum of the kurtosis as a function of the deconvolving filter coefficients is searched. The search is done iteratively using the gradient ascent algorithm, and the coefficients at the maximum point correspond to the inverse filter coefficients. This filter may be applied to the distorted signal to obtain the original undistorted signal. While a similar approach has been used before, it was always directed at a particular kind of a signal, commonly of impulsive characteristics. In this paper a successful attempt has been made to apply the algorithm to a wider range of signals, such as to process distorted audio signals and destructed images. This innovative implementation required the revelation of a way to preprocess the distorted signal at hand. The experimental results show very good performance in terms of recovering audio signals and blurred images, both for an FIR and IIR distorting filters.\n    ",
        "submission_date": "2013-09-19T00:00:00",
        "last_modified_date": "2013-09-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1309.5174",
        "title": "Saying What You're Looking For: Linguistics Meets Video Search",
        "authors": [
            "Andrei Barbu",
            "N. Siddharth",
            "Jeffrey Mark Siskind"
        ],
        "abstract": "We present an approach to searching large video corpora for video clips which depict a natural-language query in the form of a sentence. This approach uses compositional semantics to encode subtle meaning that is lost in other systems, such as the difference between two sentences which have identical words but entirely different meaning: \"The person rode the horse} vs. \\emph{The horse rode the person\". Given a video-sentence pair and a natural-language parser, along with a grammar that describes the space of sentential queries, we produce a score which indicates how well the video depicts the sentence. We produce such a score for each video clip in a corpus and return a ranked list of clips. Furthermore, this approach addresses two fundamental problems simultaneously: detecting and tracking objects, and recognizing whether those tracks depict the query. Because both tracking and object detection are unreliable, this uses knowledge about the intended sentential query to focus the tracker on the relevant participants and ensures that the resulting tracks are described by the sentential query. While earlier work was limited to single-word queries which correspond to either verbs or nouns, we show how one can search for complex queries which contain multiple phrases, such as prepositional phrases, and modifiers, such as adverbs. We demonstrate this approach by searching for 141 queries involving people and horses interacting with each other in 10 full-length Hollywood movies.\n    ",
        "submission_date": "2013-09-20T00:00:00",
        "last_modified_date": "2013-09-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1309.5357",
        "title": "Development of Comprehensive Devnagari Numeral and Character Database for Offline Handwritten Character Recognition",
        "authors": [
            "Vikas J. Dongre",
            "Vijay H.Mankar"
        ],
        "abstract": "In handwritten character recognition, benchmark database plays an important role in evaluating the performance of various algorithms and the results obtained by various researchers. In Devnagari script, there is lack of such official benchmark. This paper focuses on the generation of offline benchmark database for Devnagari handwritten numerals and characters. The present work generated 5137 and 20305 isolated samples for numeral and character database, respectively, from 750 writers of all ages, sex, education, and profession. The offline sample images are stored in TIFF image format as it occupies less memory. Also, the data is presented in binary level so that memory requirement is further reduced. It will facilitate research on handwriting recognition of Devnagari script through free access to the researchers.\n    ",
        "submission_date": "2013-08-17T00:00:00",
        "last_modified_date": "2013-08-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1309.5594",
        "title": "Generic Image Classification Approaches Excel on Face Recognition",
        "authors": [
            "Fumin Shen",
            "Chunhua Shen"
        ],
        "abstract": "The main finding of this work is that the standard image classification pipeline, which consists of dictionary learning, feature encoding, spatial pyramid pooling and linear classification, outperforms all state-of-the-art face recognition methods on the tested benchmark datasets (we have tested on AR, Extended Yale B, the challenging FERET, and LFW-a datasets). This surprising and prominent result suggests that those advances in generic image classification can be directly applied to improve face recognition systems. In other words, face recognition may not need to be viewed as a separate object classification problem.\n",
        "submission_date": "2013-09-22T00:00:00",
        "last_modified_date": "2013-09-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1309.6195",
        "title": "Scan-based Compressed Terahertz Imaging and Real-Time Reconstruction via the Complex-valued Fast Block Sparse Bayesian Learning Algorithm",
        "authors": [
            "Benyuan Liu",
            "Hongqi Fan",
            "Zaiqi Lu",
            "Qiang Fu"
        ],
        "abstract": "Compressed Sensing based Terahertz imaging (CS-THz) is a computational imaging technique. It uses only one THz receiver to accumulate the random modulated image measurements where the original THz image is reconstruct from these measurements using compressed sensing solvers. The advantage of the CS-THz is its reduced acquisition time compared with the raster scan mode. However, when it applied to large-scale two-dimensional (2D) imaging, the increased dimension resulted in both high computational complexity and excessive memory usage. In this paper, we introduced a novel CS-based THz imaging system that progressively compressed the THz image column by column. Therefore, the CS-THz system could be simplified with a much smaller sized modulator and reduced dimension. In order to utilize the block structure and the correlation of adjacent columns of the THz image, a complex-valued block sparse Bayesian learning algorithm was proposed. We conducted systematic evaluation of state-of-the-art CS algorithms under the scan based CS-THz architecture. The compression ratios and the choices of the sensing matrices were analyzed in detail using both synthetic and real-life THz images. Simulation results showed that both the scan based architecture and the proposed recovery algorithm were superior and efficient for large scale CS-THz applications.\n    ",
        "submission_date": "2013-09-20T00:00:00",
        "last_modified_date": "2013-09-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1309.6301",
        "title": "Solving OSCAR regularization problems by proximal splitting algorithms",
        "authors": [
            "Xiangrong Zeng",
            "M\u00e1rio A. T. Figueiredo"
        ],
        "abstract": "The OSCAR (octagonal selection and clustering algorithm for regression) regularizer consists of a L_1 norm plus a pair-wise L_inf norm (responsible for its grouping behavior) and was proposed to encourage group sparsity in scenarios where the groups are a priori unknown. The OSCAR regularizer has a non-trivial proximity operator, which limits its applicability. We reformulate this regularizer as a weighted sorted L_1 norm, and propose its grouping proximity operator (GPO) and approximate proximity operator (APO), thus making state-of-the-art proximal splitting algorithms (PSAs) available to solve inverse problems with OSCAR regularization. The GPO is in fact the APO followed by additional grouping and averaging operations, which are costly in time and storage, explaining the reason why algorithms with APO are much faster than that with GPO. The convergences of PSAs with GPO are guaranteed since GPO is an exact proximity operator. Although convergence of PSAs with APO is may not be guaranteed, we have experimentally found that APO behaves similarly to GPO when the regularization parameter of the pair-wise L_inf norm is set to an appropriately small value. Experiments on recovery of group-sparse signals (with unknown groups) show that PSAs with APO are very fast and accurate.\n    ",
        "submission_date": "2013-09-24T00:00:00",
        "last_modified_date": "2013-09-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1309.6379",
        "title": "Diffeomorphic Metric Mapping and Probabilistic Atlas Generation of Hybrid Diffusion Imaging based on BFOR Signal Basis",
        "authors": [
            "Jia Du",
            "A. Pasha Hosseinbor",
            "Moo K. Chung",
            "Barbara B. Bendlin",
            "Gaurav Suryawanshi",
            "Andrew L. Alexander",
            "Anqi Qiu"
        ],
        "abstract": "We propose a large deformation diffeomorphic metric mapping algorithm to align multiple b-value diffusion weighted imaging (mDWI) data, specifically acquired via hybrid diffusion imaging (HYDI), denoted as LDDMM-HYDI. We then propose a Bayesian model for estimating the white matter atlas from HYDIs. We adopt the work given in Hosseinbor et al. (2012) and represent the q-space diffusion signal with the Bessel Fourier orientation reconstruction (BFOR) signal basis. The BFOR framework provides the representation of mDWI in the q-space and thus reduces memory requirement. In addition, since the BFOR signal basis is orthonormal, the L2 norm that quantifies the differences in the q-space signals of any two mDWI datasets can be easily computed as the sum of the squared differences in the BFOR expansion coefficients. In this work, we show that the reorientation of the $q$-space signal due to spatial transformation can be easily defined on the BFOR signal basis. We incorporate the BFOR signal basis into the LDDMM framework and derive the gradient descent algorithm for LDDMM-HYDI with explicit orientation optimization. Additionally, we extend the previous Bayesian atlas estimation framework for scalar-valued images to HYDIs and derive the expectation-maximization algorithm for solving the HYDI atlas estimation problem. Using real HYDI datasets, we show the Bayesian model generates the white matter atlas with anatomical details. Moreover, we show that it is important to consider the variation of mDWI reorientation due to a small change in diffeomorphic transformation in the LDDMM-HYDI optimization and to incorporate the full information of HYDI for aligning mDWI.\n    ",
        "submission_date": "2013-09-25T00:00:00",
        "last_modified_date": "2013-09-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1309.6390",
        "title": "Contextually learnt detection of unusual motion-based behaviour in crowded public spaces",
        "authors": [
            "Ognjen Arandjelovi\u0107"
        ],
        "abstract": "In this paper we are interested in analyzing behaviour in crowded public places at the level of holistic motion. Our aim is to learn, without user input, strong scene priors or labelled data, the scope of \"normal behaviour\" for a particular scene and thus alert to novelty in unseen footage. The first contribution is a low-level motion model based on what we term tracklet primitives, which are scene-specific elementary motions. We propose a clustering-based algorithm for tracklet estimation from local approximations to tracks of appearance features. This is followed by two methods for motion novelty inference from tracklet primitives: (a) we describe an approach based on a non-hierarchial ensemble of Markov chains as a means of capturing behavioural characteristics at different scales, and (b) a more flexible alternative which exhibits a higher generalizing power by accounting for constraints introduced by intentionality and goal-oriented planning of human motion in a particular scene. Evaluated on a 2h long video of a busy city marketplace, both algorithms are shown to be successful at inferring unusual behaviour, the latter model achieving better performance for novelties at a larger spatial scale.\n    ",
        "submission_date": "2013-09-25T00:00:00",
        "last_modified_date": "2013-09-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1309.6391",
        "title": "Multiple-object tracking in cluttered and crowded public spaces",
        "authors": [
            "Rhys Martin",
            "Ognjen Arandjelovi\u0107"
        ],
        "abstract": "This paper addresses the problem of tracking moving objects of variable appearance in challenging scenes rich with features and texture. Reliable tracking is of pivotal importance in surveillance applications. It is made particularly difficult by the nature of objects encountered in such scenes: these too change in appearance and scale, and are often articulated (e.g. humans). We propose a method which uses fast motion detection and segmentation as a constraint for both building appearance models and their robust propagation (matching) in time. The appearance model is based on sets of local appearances automatically clustered using spatio-kinetic similarity, and is updated with each new appearance seen. This integration of all seen appearances of a tracked object makes it extremely resilient to errors caused by occlusion and the lack of permanence of due to low data quality, appearance change or background clutter. These theoretical strengths of our algorithm are empirically demonstrated on two hour long video footage of a busy city marketplace.\n    ",
        "submission_date": "2013-09-25T00:00:00",
        "last_modified_date": "2013-09-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1309.6691",
        "title": "Characterness: An Indicator of Text in the Wild",
        "authors": [
            "Yao Li",
            "Wenjing Jia",
            "Chunhua Shen",
            "Anton van den Hengel"
        ],
        "abstract": "Text in an image provides vital information for interpreting its contents, and text in a scene can aide with a variety of tasks from navigation, to obstacle avoidance, and odometry. Despite its value, however, identifying general text in images remains a challenging research problem. Motivated by the need to consider the widely varying forms of natural text, we propose a bottom-up approach to the problem which reflects the `characterness' of an image region. In this sense our approach mirrors the move from saliency detection methods to measures of `objectness'. In order to measure the characterness we develop three novel cues that are tailored for character detection, and a Bayesian method for their integration. Because text is made up of sets of characters, we then design a Markov random field (MRF) model so as to exploit the inherent dependencies between characters.\n",
        "submission_date": "2013-09-25T00:00:00",
        "last_modified_date": "2013-09-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1309.6964",
        "title": "Online Algorithms for Factorization-Based Structure from Motion",
        "authors": [
            "Ryan Kennedy",
            "Laura Balzano",
            "Stephen J. Wright",
            "Camillo J. Taylor"
        ],
        "abstract": "We present a family of online algorithms for real-time factorization-based structure from motion, leveraging a relationship between incremental singular value decomposition and recently proposed methods for online matrix completion. Our methods are orders of magnitude faster than previous state of the art, can handle missing data and a variable number of feature points, and are robust to noise and sparse outliers. We demonstrate our methods on both real and synthetic sequences and show that they perform well in both online and batch settings. We also provide an implementation which is able to produce 3D models in real time using a laptop with a webcam.\n    ",
        "submission_date": "2013-09-26T00:00:00",
        "last_modified_date": "2016-07-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1309.7170",
        "title": "An Efficient Index for Visual Search in Appearance-based SLAM",
        "authors": [
            "Kiana Hajebi",
            "Hong Zhang"
        ],
        "abstract": "Vector-quantization can be a computationally expensive step in visual bag-of-words (BoW) search when the vocabulary is large. A BoW-based appearance SLAM needs to tackle this problem for an efficient real-time operation. We propose an effective method to speed up the vector-quantization process in BoW-based visual SLAM. We employ a graph-based nearest neighbor search (GNNS) algorithm to this aim, and experimentally show that it can outperform the state-of-the-art. The graph-based search structure used in GNNS can efficiently be integrated into the BoW model and the SLAM framework. The graph-based index, which is a k-NN graph, is built over the vocabulary words and can be extracted from the BoW's vocabulary construction procedure, by adding one iteration to the k-means clustering, which adds small extra cost. Moreover, exploiting the fact that images acquired for appearance-based SLAM are sequential, GNNS search can be initiated judiciously which helps increase the speedup of the quantization process considerably.\n    ",
        "submission_date": "2013-09-27T00:00:00",
        "last_modified_date": "2013-09-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1309.7276",
        "title": "Adopting level set theory based algorithms to segment human ear",
        "authors": [
            "Bijeesh T. V",
            "Nimmi I. P"
        ],
        "abstract": "Human identification has always been a topic that interested researchers around the world. Biometric methods are found to be more effective and much easier for the users than the traditional identification methods like keys, smart cards and passwords. Unlike with the traditional methods, with biometric methods the data acquisition is most of the times passive, which means the users do not take active part in data acquisition. Data acquisition can be performed using cameras, scanners or sensors. Human physiological biometrics such as face, eye and ear are good candidates for uniquely identifying an individual. However, human ear scores over face and eye because of certain advantages it has over face. The most challenging phase in human identification based on ear biometric is the segmentation of the ear image from the captured image which may contain many unwanted details. In this work, PDE based image processing techniques are used to segment out the ear image. Level Set Theory based image processing is employed to obtain the contour of the ear image. A few Level set algorithms are compared for their efficiency in segmenting test ear images.\n    ",
        "submission_date": "2013-09-26T00:00:00",
        "last_modified_date": "2013-09-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1309.7434",
        "title": "Face Verification Using Boosted Cross-Image Features",
        "authors": [
            "Dong Zhang",
            "Omar Oreifej",
            "Mubarak Shah"
        ],
        "abstract": "This paper proposes a new approach for face verification, where a pair of images needs to be classified as belonging to the same person or not. This problem is relatively new and not well-explored in the literature. Current methods mostly adopt techniques borrowed from face recognition, and process each of the images in the pair independently, which is counter intuitive. In contrast, we propose to extract cross-image features, i.e. features across the pair of images, which, as we demonstrate, is more discriminative to the similarity and the dissimilarity of faces. Our features are derived from the popular Haar-like features, however, extended to handle the face verification problem instead of face detection. We collect a large bank of cross-image features using filters of different sizes, locations, and orientations. Consequently, we use AdaBoost to select and weight the most discriminative features. We carried out extensive experiments on the proposed ideas using three standard face verification datasets, and obtained promising results outperforming state-of-the-art.\n    ",
        "submission_date": "2013-09-28T00:00:00",
        "last_modified_date": "2013-09-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1309.7484",
        "title": "CSIFT Based Locality-constrained Linear Coding for Image Classification",
        "authors": [
            "Chen Junzhou",
            "Li Qing",
            "Peng Qiang",
            "Kin Hong Wong"
        ],
        "abstract": "In the past decade, SIFT descriptor has been witnessed as one of the most robust local invariant feature descriptors and widely used in various vision tasks. Most traditional image classification systems depend on the luminance-based SIFT descriptors, which only analyze the gray level variations of the images. Misclassification may happen since their color contents are ignored. In this article, we concentrate on improving the performance of existing image classification algorithms by adding color information. To achieve this purpose, different kinds of colored SIFT descriptors are introduced and implemented. Locality-constrained Linear Coding (LLC), a state-of-the-art sparse coding technology, is employed to construct the image classification system for the evaluation. The real experiments are carried out on several benchmarks. With the enhancements of color SIFT, the proposed image classification system obtains approximate 3% improvement of classification accuracy on the Caltech-101 dataset and approximate 4% improvement of classification accuracy on the Caltech-256 dataset.\n    ",
        "submission_date": "2013-09-28T00:00:00",
        "last_modified_date": "2013-09-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1309.7512",
        "title": "Structured learning of sum-of-submodular higher order energy functions",
        "authors": [
            "Alexander Fix",
            "Thorsten Joachims",
            "Sam Park",
            "Ramin Zabih"
        ],
        "abstract": "Submodular functions can be exactly minimized in polynomial time, and the special case that graph cuts solve with max flow \\cite{KZ:PAMI04} has had significant impact in computer vision \\cite{BVZ:PAMI01,Kwatra:SIGGRAPH03,Rother:GrabCut04}. In this paper we address the important class of sum-of-submodular (SoS) functions \\cite{Arora:ECCV12,Kolmogorov:DAM12}, which can be efficiently minimized via a variant of max flow called submodular flow \\cite{Edmonds:ADM77}. SoS functions can naturally express higher order priors involving, e.g., local image patches; however, it is difficult to fully exploit their expressive power because they have so many parameters. Rather than trying to formulate existing higher order priors as an SoS function, we take a discriminative learning approach, effectively searching the space of SoS functions for a higher order prior that performs well on our training set. We adopt a structural SVM approach \\cite{Joachims/etal/09a,Tsochantaridis/etal/04} and formulate the training problem in terms of quadratic programming; as a result we can efficiently search the space of SoS priors via an extended cutting-plane algorithm. We also show how the state-of-the-art max flow method for vision problems \\cite{Goldberg:ESA11} can be modified to efficiently solve the submodular flow problem. Experimental comparisons are made against the OpenCV implementation of the GrabCut interactive segmentation technique \\cite{Rother:GrabCut04}, which uses hand-tuned parameters instead of machine learning. On a standard dataset \\cite{Gulshan:CVPR10} our method learns higher order priors with hundreds of parameter values, and produces significantly better segmentations. While our focus is on binary labeling problems, we show that our techniques can be naturally generalized to handle more than two labels.\n    ",
        "submission_date": "2013-09-28T00:00:00",
        "last_modified_date": "2013-10-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1309.7609",
        "title": "Identificaci\u00f3n y Registro Catastral de Cuerpos de Agua mediante T\u00e9cnicas de Procesamiento Digital de Imagenes",
        "authors": [
            "Kevin Rojas Laura",
            "Christhian Cardenas Alvarez"
        ],
        "abstract": "The effects of global climate change on Peruvian glaciers have brought about several processes of deglaciation during the last few years. The immediate effect is the change of size of lakes and rivers. Public institutions that monitor water resources currently have only recent studies which make up less than 10% of the total. The effects of climate change and the lack of updated information intensify social-economic problems related to water resources in Peru. The objective of this research is to develop a software application to automate the Cadastral Registry of Water Bodies in Peru, using techniques of digital image processing, which would provide tools for detection, record, temporal analysis and visualization of water bodies. The images used are from the satellite Landsat5, which undergo a pre-processing of calibration and correction of the satellite. Detection results are archived into a file that contains location vectors and images of the segmentated bodies of water.\n    ",
        "submission_date": "2013-09-29T00:00:00",
        "last_modified_date": "2013-09-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1309.7615",
        "title": "Correcting Multi-focus Images via Simple Standard Deviation for Image Fusion",
        "authors": [
            "Firas A. Jassim"
        ],
        "abstract": "Image fusion is one of the recent trends in image registration which is an essential field of image processing. The basic principle of this paper is to fuse multi-focus images using simple statistical standard deviation. Firstly, the simple standard deviation for the k-by-k window inside each of the multi-focus images was computed. The contribution in this paper came from the idea that the focused part inside an image had high details rather than the unfocused part. Hence, the dispersion between pixels inside the focused part is higher than the dispersion inside the unfocused part. Secondly, a simple comparison between the standard deviation for each k-by-k window in the multi-focus images could be computed. The highest standard deviation between all the computed standard deviations for the multi-focus images could be treated as the optimal that is to be placed in the fused image. The experimental visual results show that the proposed method produces very satisfactory results in spite of its simplicity.\n    ",
        "submission_date": "2013-09-29T00:00:00",
        "last_modified_date": "2013-09-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1309.7912",
        "title": "An Image-Based Fluid Surface Pattern Model",
        "authors": [
            "Mauro de Amorim",
            "Ricardo Fabbri",
            "Lucia Maria dos Santos Pinto",
            "Francisco Duarte Moura Neto"
        ],
        "abstract": "This work aims at generating a model of the ocean surface and its dynamics from one or more video cameras. The idea is to model wave patterns from video as a first step towards a larger system of photogrammetric monitoring of marine conditions for use in offshore oil drilling platforms. The first part of the proposed approach consists in reducing the dimensionality of sensor data made up of the many pixels of each frame of the input video streams. This enables finding a concise number of most relevant parameters to model the temporal dataset, yielding an efficient data-driven model of the evolution of the observed surface. The second part proposes stochastic modeling to better capture the patterns embedded in the data. One can then draw samples from the final model, which are expected to simulate the behavior of previously observed flow, in order to determine conditions that match new observations. In this paper we focus on proposing and discussing the overall approach and on comparing two different techniques for dimensionality reduction in the first stage: principal component analysis and diffusion maps. Work is underway on the second stage of constructing better stochastic models of fluid surface dynamics as proposed here.\n    ",
        "submission_date": "2013-09-30T00:00:00",
        "last_modified_date": "2013-09-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1310.0036",
        "title": "Personal Identification from Lip-Print Features using a Statistical Model",
        "authors": [
            "Saptarshi Bhattacharjee",
            "S Arunkumar",
            "Samir Kumar Bandyopadhyay"
        ],
        "abstract": "This paper presents a novel approach towards identification of human beings from the statistical analysis of their lip prints. Lip features are extracted by studying the spatial orientations of the grooves present in lip prints of individuals using standard edge detection techniques. Horizontal, vertical and diagonal groove features are analysed using connected-component analysis to generate the region-specific edge datasets. Comparison between test and reference sample datasets against a threshold value to define a match yield satisfactory results. FAR, FRR and ROC metrics have been used to gauge the performance of the algorithm for real-world deployment in unimodal and multimodal biometric verification systems.\n    ",
        "submission_date": "2013-09-30T00:00:00",
        "last_modified_date": "2013-09-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1310.0097",
        "title": "Analysis of Amoeba Active Contours",
        "authors": [
            "Martin Welk"
        ],
        "abstract": "Subject of this paper is the theoretical analysis of structure-adaptive median filter algorithms that approximate curvature-based PDEs for image filtering and segmentation. These so-called morphological amoeba filters are based on a concept introduced by Lerallut et al. They achieve similar results as the well-known geodesic active contour and self-snakes PDEs. In the present work, the PDE approximated by amoeba active contours is derived for a general geometric situation and general amoeba metric. This PDE is structurally similar but not identical to the geodesic active contour equation. It reproduces the previous PDE approximation results for amoeba median filters as special cases. Furthermore, modifications of the basic amoeba active contour algorithm are analysed that are related to the morphological force terms frequently used with geodesic active contours. Experiments demonstrate the basic behaviour of amoeba active contours and its similarity to geodesic active contours.\n    ",
        "submission_date": "2013-09-30T00:00:00",
        "last_modified_date": "2014-07-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1310.0171",
        "title": "Object Detection Using Keygraphs",
        "authors": [
            "Marcelo Hashimoto",
            "Roberto Marcondes Cesar Junior"
        ],
        "abstract": "We propose a new framework for object detection based on a generalization of the keypoint correspondence framework. This framework is based on replacing keypoints by keygraphs, i.e. isomorph directed graphs whose vertices are keypoints, in order to explore relative and structural information. Unlike similar works in the literature, we deal directly with graphs in the entire pipeline: we search for graph correspondences instead of searching for individual point correspondences and then building graph correspondences from them afterwards. We also estimate the pose from graph correspondences instead of falling back to point correspondences through a voting table. The contributions of this paper are the proposed framework and an implementation that properly handles its inherent issues of loss of locality and combinatorial explosion, showing its viability for real-time applications. In particular, we introduce the novel concept of keytuples to solve a running time issue. The accuracy of the implementation is shown by results of over 800 experiments with a well-known database of images. The speed is illustrated by real-time tracking with two different cameras in ordinary hardware.\n    ",
        "submission_date": "2013-10-01T00:00:00",
        "last_modified_date": "2013-10-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1310.0302",
        "title": "Surface Registration Using Genetic Algorithm in Reduced Search Space",
        "authors": [
            "Vedran Hrgeti\u0107",
            "Tomislav Pribani\u0107"
        ],
        "abstract": "Surface registration is a technique that is used in various areas such as object recognition and 3D model reconstruction. Problem of surface registration can be analyzed as an optimization problem of seeking a rigid motion between two different views. Genetic algorithms can be used for solving this optimization problem, both for obtaining the robust parameter estimation and for its fine-tuning. The main drawback of genetic algorithms is that they are time consuming which makes them unsuitable for online applications. Modern acquisition systems enable the implementation of the solutions that would immediately give the information on the rotational angles between the different views, thus reducing the dimension of the optimization problem. The paper gives an analysis of the genetic algorithm implemented in the conditions when the rotation matrix is known and a comparison of these results with results when this information is not available.\n    ",
        "submission_date": "2013-10-01T00:00:00",
        "last_modified_date": "2013-10-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1310.0305",
        "title": "Filtering for More Accurate Dense Tissue Segmentation in Digitized Mammograms",
        "authors": [
            "Mario Mu\u0161tra",
            "Mislav Grgi\u0107"
        ],
        "abstract": "Breast tissue segmentation into dense and fat tissue is important for determining the breast density in mammograms. Knowing the breast density is important both in diagnostic and computer-aided detection applications. There are many different ways to express the density of a breast and good quality segmentation should provide the possibility to perform accurate classification no matter which classification rule is being used. Knowing the right breast density and having the knowledge of changes in the breast density could give a hint of a process which started to happen within a patient. Mammograms generally suffer from a problem of different tissue overlapping which results in the possibility of inaccurate detection of tissue types. Fibroglandular tissue presents rather high attenuation of X-rays and is visible as brighter in the resulting image but overlapping fibrous tissue and blood vessels could easily be replaced with fibroglandular tissue in automatic segmentation algorithms. Small blood vessels and microcalcifications are also shown as bright objects with similar intensities as dense tissue but do have some properties which makes possible to suppress them from the final results. In this paper we try to divide dense and fat tissue by suppressing the scattered structures which do not represent glandular or dense tissue in order to divide mammograms more accurately in the two major tissue types. For suppressing blood vessels and microcalcifications we have used Gabor filters of different size and orientation and a combination of morphological operations on filtered image with enhanced contrast.\n    ",
        "submission_date": "2013-10-01T00:00:00",
        "last_modified_date": "2013-10-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1310.0306",
        "title": "Flexible Visual Quality Inspection in Discrete Manufacturing",
        "authors": [
            "Tomislav Petkovi\u0107",
            "Darko Juri\u0107",
            "Sven Lon\u010dari\u0107"
        ],
        "abstract": "Most visual quality inspections in discrete manufacturing are composed of length, surface, angle or intensity measurements. Those are implemented as end-user configurable inspection tools that should not require an image processing expert to set up. Currently available software solutions providing such capability use a flowchart based programming environment, but do not fully address an inspection flowchart robustness and can require a redefinition of the flowchart if a small variation is introduced. In this paper we propose an acquire-register-analyze image processing pattern designed for discrete manufacturing that aims to increase the robustness of the inspection flowchart by consistently addressing variations in product position, orientation and size. A proposed pattern is transparent to the end-user and simplifies the flowchart. We describe a developed software solution that is a practical implementation of the proposed pattern. We give an example of its real-life use in industrial production of electric components.\n    ",
        "submission_date": "2013-10-01T00:00:00",
        "last_modified_date": "2013-10-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1310.0307",
        "title": "Using the Random Sprays Retinex Algorithm for Global Illumination Estimation",
        "authors": [
            "Nikola Bani\u0107",
            "Sven Lon\u010dari\u0107"
        ],
        "abstract": "In this paper the use of Random Sprays Retinex (RSR) algorithm for global illumination estimation is proposed and its feasibility tested. Like other algorithms based on the Retinex model, RSR also provides local illumination estimation and brightness adjustment for each pixel and it is faster than other path-wise Retinex algorithms. As the assumption of the uniform illumination holds in many cases, it should be possible to use the mean of local illumination estimations of RSR as a global illumination estimation for images with (assumed) uniform illumination allowing also the accuracy to be easily measured. Therefore we propose a method for estimating global illumination estimation based on local RSR results. To our best knowledge this is the first time that RSR algorithm is used to obtain global illumination estimation. For our tests we use a publicly available color constancy image database for testing. The results are presented and discussed and it turns out that the proposed method outperforms many existing unsupervised color constancy algorithms. The source code is available at ",
        "submission_date": "2013-10-01T00:00:00",
        "last_modified_date": "2013-10-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1310.0308",
        "title": "Combining Spatio-Temporal Appearance Descriptors and Optical Flow for Human Action Recognition in Video Data",
        "authors": [
            "Karla Brki\u0107",
            "Sr\u0111an Ra\u0161i\u0107",
            "Axel Pinz",
            "Sini\u0161a \u0160egvi\u0107",
            "Zoran Kalafati\u0107"
        ],
        "abstract": "This paper proposes combining spatio-temporal appearance (STA) descriptors with optical flow for human action recognition. The STA descriptors are local histogram-based descriptors of space-time, suitable for building a partial representation of arbitrary spatio-temporal phenomena. Because of the possibility of iterative refinement, they are interesting in the context of online human action recognition. We investigate the use of dense optical flow as the image function of the STA descriptor for human action recognition, using two different algorithms for computing the flow: the Farneb\u00e4ck algorithm and the TVL1 algorithm. We provide a detailed analysis of the influencing optical flow algorithm parameters on the produced optical flow fields. An extensive experimental validation of optical flow-based STA descriptors in human action recognition is performed on the KTH human action dataset. The encouraging experimental results suggest the potential of our approach in online human action recognition.\n    ",
        "submission_date": "2013-10-01T00:00:00",
        "last_modified_date": "2013-10-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1310.0310",
        "title": "A Novel Georeferenced Dataset for Stereo Visual Odometry",
        "authors": [
            "Ivan Kre\u0161o",
            "Marko \u0160evrovi\u0107",
            "Sini\u0161a \u0160egvi\u0107"
        ],
        "abstract": "In this work, we present a novel dataset for assessing the accuracy of stereo visual odometry. The dataset has been acquired by a small-baseline stereo rig mounted on the top of a moving car. The groundtruth is supplied by a consumer grade GPS device without IMU. Synchronization and alignment between GPS readings and stereo frames are recovered after the acquisition. We show that the attained groundtruth accuracy allows to draw useful conclusions in practice. The presented experiments address influence of camera calibration, baseline distance and zero-disparity features to the achieved reconstruction performance.\n    ",
        "submission_date": "2013-10-01T00:00:00",
        "last_modified_date": "2013-10-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1310.0311",
        "title": "Multiclass Road Sign Detection using Multiplicative Kernel",
        "authors": [
            "Valentina Zadrija",
            "Sini\u0161a \u0160egvi\u0107"
        ],
        "abstract": "We consider the problem of multiclass road sign detection using a classification function with multiplicative kernel comprised from two kernels. We show that problems of detection and within-foreground classification can be jointly solved by using one kernel to measure object-background differences and another one to account for within-class variations. The main idea behind this approach is that road signs from different foreground variations can share features that discriminate them from backgrounds. The classification function training is accomplished using SVM, thus feature sharing is obtained through support vector sharing. Training yields a family of linear detectors, where each detector corresponds to a specific foreground training sample. The redundancy among detectors is alleviated using k-medoids clustering. Finally, we report detection and classification results on a set of road sign images obtained from a camera on a moving vehicle.\n    ",
        "submission_date": "2013-10-01T00:00:00",
        "last_modified_date": "2013-10-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1310.0314",
        "title": "Global Localization Based on 3D Planar Surface Segments",
        "authors": [
            "Robert Cupec",
            "Emmanuel Karlo Nyarko",
            "Damir Filko",
            "Andrej Kitanov",
            "Ivan Petrovi\u0107"
        ],
        "abstract": "Global localization of a mobile robot using planar surface segments extracted from depth images is considered. The robot's environment is represented by a topological map consisting of local models, each representing a particular location modeled by a set of planar surface segments. The discussed localization approach segments a depth image acquired by a 3D camera into planar surface segments which are then matched to model surface segments. The robot pose is estimated by the Extended Kalman Filter using surface segment pairs as measurements. The reliability and accuracy of the considered approach are experimentally evaluated using a mobile robot equipped by a Microsoft Kinect sensor.\n    ",
        "submission_date": "2013-10-01T00:00:00",
        "last_modified_date": "2013-10-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1310.0315",
        "title": "Computer Vision Systems in Road Vehicles: A Review",
        "authors": [
            "Kristian Kova\u010di\u0107",
            "Edouard Ivanjko",
            "Hrvoje Gold"
        ],
        "abstract": "The number of road vehicles significantly increased in recent decades. This trend accompanied a build-up of road infrastructure and development of various control systems to increase road traffic safety, road capacity and travel comfort. In traffic safety significant development has been made and today's systems more and more include cameras and computer vision methods. Cameras are used as part of the road infrastructure or in vehicles. In this paper a review on computer vision systems in vehicles from the stand point of traffic engineering is given. Safety problems of road vehicles are presented, current state of the art in-vehicle vision systems is described and open problems with future research directions are discussed.\n    ",
        "submission_date": "2013-10-01T00:00:00",
        "last_modified_date": "2013-10-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1310.0316",
        "title": "Classifying Traffic Scenes Using The GIST Image Descriptor",
        "authors": [
            "Ivan Sikiri\u0107",
            "Karla Brki\u0107",
            "Sini\u0161a \u0160egvi\u0107"
        ],
        "abstract": "This paper investigates classification of traffic scenes in a very low bandwidth scenario, where an image should be coded by a small number of features. We introduce a novel dataset, called the FM1 dataset, consisting of 5615 images of eight different traffic scenes: open highway, open road, settlement, tunnel, tunnel exit, toll booth, heavy traffic and the overpass. We evaluate the suitability of the GIST descriptor as a representation of these images, first by exploring the descriptor space using PCA and k-means clustering, and then by using an SVM classifier and recording its 10-fold cross-validation performance on the introduced FM1 dataset. The obtained recognition rates are very encouraging, indicating that the use of the GIST descriptor alone could be sufficiently descriptive even when very high performance is required.\n    ",
        "submission_date": "2013-10-01T00:00:00",
        "last_modified_date": "2013-10-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1310.0317",
        "title": "An Overview and Evaluation of Various Face and Eyes Detection Algorithms for Driver Fatigue Monitoring Systems",
        "authors": [
            "Markan Lopar",
            "Slobodan Ribari\u0107"
        ],
        "abstract": "In this work various methods and algorithms for face and eyes detection are examined in order to decide which of them are applicable for use in a driver fatigue monitoring system. In the case of face detection the standard Viola-Jones face detector has shown best results, while the method of finding the eye centers by means of gradients has proven to be most appropriate in the case of eyes detection. The later method has also a potential for retrieving behavioral parameters needed for estimation of the level of driver fatigue. This possibility will be examined in future work.\n    ",
        "submission_date": "2013-10-01T00:00:00",
        "last_modified_date": "2013-10-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1310.0319",
        "title": "Second Croatian Computer Vision Workshop (CCVW 2013)",
        "authors": [
            "Sven Lon\u010dari\u0107",
            "Sini\u0161a \u0160egvi\u0107"
        ],
        "abstract": "Proceedings of the Second Croatian Computer Vision Workshop (CCVW 2013, ",
        "submission_date": "2013-10-01T00:00:00",
        "last_modified_date": "2013-11-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1310.0354",
        "title": "Deep and Wide Multiscale Recursive Networks for Robust Image Labeling",
        "authors": [
            "Gary B. Huang",
            "Viren Jain"
        ],
        "abstract": "Feedforward multilayer networks trained by supervised learning have recently demonstrated state of the art performance on image labeling problems such as boundary prediction and scene parsing. As even very low error rates can limit practical usage of such systems, methods that perform closer to human accuracy remain desirable. In this work, we propose a new type of network with the following properties that address what we hypothesize to be limiting aspects of existing methods: (1) a `wide' structure with thousands of features, (2) a large field of view, (3) recursive iterations that exploit statistical dependencies in label space, and (4) a parallelizable architecture that can be trained in a fraction of the time compared to benchmark multilayer convolutional networks. For the specific image labeling problem of boundary prediction, we also introduce a novel example weighting algorithm that improves segmentation accuracy. Experiments in the challenging domain of connectomic reconstruction of neural circuity from 3d electron microscopy data show that these \"Deep And Wide Multiscale Recursive\" (DAWMR) networks lead to new levels of image labeling performance. The highest performing architecture has twelve layers, interwoven supervised and unsupervised stages, and uses an input field of view of 157,464 voxels ($54^3$) to make a prediction at each image location. We present an associated open source software package that enables the simple and flexible creation of DAWMR networks.\n    ",
        "submission_date": "2013-10-01T00:00:00",
        "last_modified_date": "2013-12-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1310.0365",
        "title": "The complex-valued encoding for dicision-making based on aliasing data",
        "authors": [
            "P.A. Golovinski",
            "V.A. Astapenko"
        ],
        "abstract": "It is proposed a complex valued channel encoding for multidimensional data. The basic approach contains overlapping of complex nonlinear mappings. Its development leads to sparse representation of multi-channel data, increasing their dimensions and the distance between the images.\n    ",
        "submission_date": "2013-10-01T00:00:00",
        "last_modified_date": "2013-10-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1310.0900",
        "title": "Efficient pedestrian detection by directly optimize the partial area under the ROC curve",
        "authors": [
            "Sakrapee Paisitkriangkrai",
            "Chunhua Shen",
            "Anton van den Hengel"
        ],
        "abstract": "Many typical applications of object detection operate within a prescribed false-positive range. In this situation the performance of a detector should be assessed on the basis of the area under the ROC curve over that range, rather than over the full curve, as the performance outside the range is irrelevant.\n",
        "submission_date": "2013-10-03T00:00:00",
        "last_modified_date": "2013-10-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1310.1257",
        "title": "Second order scattering descriptors predict fMRI activity due to visual textures",
        "authors": [
            "Michael Eickenberg",
            "Fabian Pedregosa",
            "Senoussi Mehdi",
            "Alexandre Gramfort",
            "Bertrand Thirion"
        ],
        "abstract": "Second layer scattering descriptors are known to provide good classification performance on natural quasi-stationary processes such as visual textures due to their sensitivity to higher order moments and continuity with respect to small deformations. In a functional Magnetic Resonance Imaging (fMRI) experiment we present visual textures to subjects and evaluate the predictive power of these descriptors with respect to the predictive power of simple contour energy - the first scattering layer. We are able to conclude not only that invariant second layer scattering coefficients better encode voxel activity, but also that well predicted voxels need not necessarily lie in known retinotopic regions.\n    ",
        "submission_date": "2013-08-10T00:00:00",
        "last_modified_date": "2013-08-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1310.1371",
        "title": "Robust and highly performant ring detection algorithm for 3d particle tracking using 2d microscope imaging",
        "authors": [
            "Eldad Afik"
        ],
        "abstract": "Three-dimensional particle tracking is an essential tool in studying dynamics under the microscope, namely, fluid dynamics in microfluidic devices, bacteria taxis, cellular trafficking. The 3d position can be determined using 2d imaging alone by measuring the diffraction rings generated by an out-of-focus fluorescent particle, imaged on a single camera. Here I present a ring detection algorithm exhibiting a high detection rate, which is robust to the challenges arising from ring occlusion, inclusions and overlaps, and allows resolving particles even when near to each other. It is capable of real time analysis thanks to its high performance and low memory footprint. The proposed algorithm, an offspring of the circle Hough transform, addresses the need to efficiently trace the trajectories of many particles concurrently, when their number in not necessarily fixed, by solving a classification problem, and overcomes the challenges of finding local maxima in the complex parameter space which results from ring clusters and noise. Several algorithmic concepts introduced here can be advantageous in other cases, particularly when dealing with noisy and sparse data. The implementation is based on open-source and cross-platform software packages only, making it easy to distribute and modify. It is implemented in a microfluidic experiment allowing real-time multi-particle tracking at 70 Hz, achieving a detection rate which exceeds 94% and only 1% false-detection.\n    ",
        "submission_date": "2013-10-02T00:00:00",
        "last_modified_date": "2015-09-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1310.1531",
        "title": "DeCAF: A Deep Convolutional Activation Feature for Generic Visual Recognition",
        "authors": [
            "Jeff Donahue",
            "Yangqing Jia",
            "Oriol Vinyals",
            "Judy Hoffman",
            "Ning Zhang",
            "Eric Tzeng",
            "Trevor Darrell"
        ],
        "abstract": "We evaluate whether features extracted from the activation of a deep convolutional network trained in a fully supervised fashion on a large, fixed set of object recognition tasks can be re-purposed to novel generic tasks. Our generic tasks may differ significantly from the originally trained tasks and there may be insufficient labeled or unlabeled data to conventionally train or adapt a deep architecture to the new tasks. We investigate and visualize the semantic clustering of deep convolutional features with respect to a variety of such tasks, including scene recognition, domain adaptation, and fine-grained recognition challenges. We compare the efficacy of relying on various network levels to define a fixed feature, and report novel results that significantly outperform the state-of-the-art on several important vision challenges. We are releasing DeCAF, an open-source implementation of these deep convolutional activation features, along with all associated network parameters to enable vision researchers to be able to conduct experimentation with deep representations across a range of visual concept learning paradigms.\n    ",
        "submission_date": "2013-10-06T00:00:00",
        "last_modified_date": "2013-10-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1310.1690",
        "title": "Online Unsupervised Feature Learning for Visual Tracking",
        "authors": [
            "Fayao Liu",
            "Chunhua Shen",
            "Ian Reid",
            "Anton van den Hengel"
        ],
        "abstract": "Feature encoding with respect to an over-complete dictionary learned by unsupervised methods, followed by spatial pyramid pooling, and linear classification, has exhibited powerful strength in various vision applications. Here we propose to use the feature learning pipeline for visual tracking. Tracking is implemented using tracking-by-detection and the resulted framework is very simple yet effective. First, online dictionary learning is used to build a dictionary, which captures the appearance changes of the tracking target as well as the background changes. Given a test image window, we extract local image patches from it and each local patch is encoded with respect to the dictionary. The encoded features are then pooled over a spatial pyramid to form an aggregated feature vector. Finally, a simple linear classifier is trained on these features.\n",
        "submission_date": "2013-10-07T00:00:00",
        "last_modified_date": "2013-10-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1310.1771",
        "title": "Potts model, parametric maxflow and k-submodular functions",
        "authors": [
            "Igor Gridchyn",
            "Vladimir Kolmogorov"
        ],
        "abstract": "The problem of minimizing the Potts energy function frequently occurs in computer vision applications. One way to tackle this NP-hard problem was proposed by Kovtun [19,20]. It identifies a part of an optimal solution by running $k$ maxflow computations, where $k$ is the number of labels. The number of \"labeled\" pixels can be significant in some applications, e.g. 50-93% in our tests for stereo. We show how to reduce the runtime to $O(\\log k)$ maxflow computations (or one {\\em parametric maxflow} computation). Furthermore, the output of our algorithm allows to speed-up the subsequent alpha expansion for the unlabeled part, or can be used as it is for time-critical applications.\n",
        "submission_date": "2013-10-07T00:00:00",
        "last_modified_date": "2013-10-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1310.1811",
        "title": "End-to-End Text Recognition with Hybrid HMM Maxout Models",
        "authors": [
            "Ouais Alsharif",
            "Joelle Pineau"
        ],
        "abstract": "The problem of detecting and recognizing text in natural scenes has proved to be more challenging than its counterpart in documents, with most of the previous work focusing on a single part of the problem. In this work, we propose new solutions to the character and word recognition problems and then show how to combine these solutions in an end-to-end text-recognition system. We do so by leveraging the recently introduced Maxout networks along with hybrid HMM models that have proven useful for voice recognition. Using these elements, we build a tunable and highly accurate recognition system that beats state-of-the-art results on all the sub-problems for both the ICDAR 2003 and SVT benchmark datasets.\n    ",
        "submission_date": "2013-10-07T00:00:00",
        "last_modified_date": "2013-10-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1310.1855",
        "title": "Early Fire Detection Using HEP and Space-time Analysis",
        "authors": [
            "Junzhou Chen",
            "Yong You"
        ],
        "abstract": "In this article, a video base early fire alarm system is developed by monitoring the smoke in the scene. There are two major contributions in this work. First, to find the best texture feature for smoke detection, a general framework, named Histograms of Equivalent Patterns (HEP), is adopted to achieve an extensive evaluation of various kinds of texture features. Second, the \\emph{Block based Inter-Frame Difference} (BIFD) and a improved version of LBP-TOP are proposed and ensembled to describe the space-time characteristics of the smoke. In order to reduce the false alarms, the Smoke History Image (SHI) is utilized to register the recent classification results of candidate smoke blocks. Experimental results using SVM show that the proposed method can achieve better accuracy and less false alarm compared with the state-of-the-art technologies.\n    ",
        "submission_date": "2013-10-07T00:00:00",
        "last_modified_date": "2013-10-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1310.1869",
        "title": "Singular Value Decomposition of Images from Scanned Photographic Plates",
        "authors": [
            "Vasil Kolev",
            "Katya Tsvetkova",
            "Milcho Tsvetkov"
        ],
        "abstract": "We want to approximate the mxn image A from scanned astronomical photographic plates (from the Sofia Sky Archive Data Center) by using far fewer entries than in the original matrix. By using rank of a matrix, k we remove the redundant information or noise and use as Wiener filter, when rank k<m or k<n. With this approximation more than 98% compression ration of image of astronomical plate without that image details, is obtained. The SVD of images from scanned photographic plates (SPP) is considered and its possible image compression.\n    ",
        "submission_date": "2013-10-07T00:00:00",
        "last_modified_date": "2021-08-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1310.2050",
        "title": "A State Of the Art Report on Research in Multiple RGB-D sensor Setups",
        "authors": [
            "Kai Berger"
        ],
        "abstract": "That the Microsoft Kinect, an RGB-D sensor, transformed the gaming and end consumer sector has been anticipated by the developers. That it also impacted in rigorous computer vision research has probably been a surprise to the whole community. Shortly before the commercial deployment of its successor, Kinect One, the research literature fills with resumees and state-of-the art papers to summarize the development over the past 3 years. This particular report describes significant research projects which have built on sensoring setups that include two or more RGB-D sensors in one scene.\n    ",
        "submission_date": "2013-10-08T00:00:00",
        "last_modified_date": "2013-10-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1310.2053",
        "title": "The role of RGB-D benchmark datasets: an overview",
        "authors": [
            "Kai Berger"
        ],
        "abstract": "The advent of the Microsoft Kinect three years ago stimulated not only the computer vision community for new algorithms and setups to tackle well-known problems in the community but also sparked the launch of several new benchmark datasets to which future algorithms can be compared 019 to. This review of the literature and industry developments concludes that the current RGB-D benchmark datasets can be useful to determine the accuracy of a variety of applications of a single or multiple RGB-D sensors.\n    ",
        "submission_date": "2013-10-08T00:00:00",
        "last_modified_date": "2013-10-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1310.2085",
        "title": "A Robust Variational Model for Positive Image Deconvolution",
        "authors": [
            "Martin Welk"
        ],
        "abstract": "In this paper, an iterative method for robust deconvolution with positivity constraints is discussed. It is based on the known variational interpretation of the Richardson-Lucy iterative deconvolution as fixed-point iteration for the minimisation of an information divergence functional under a multiplicative perturbation model. The asymmetric penaliser function involved in this functional is then modified into a robust penaliser, and complemented with a regulariser. The resulting functional gives rise to a fixed point iteration that we call robust and regularised Richardson-Lucy deconvolution. It achieves an image restoration quality comparable to state-of-the-art robust variational deconvolution with a computational efficiency similar to that of the original Richardson-Lucy method. Experiments on synthetic and real-world image data demonstrate the performance of the proposed method.\n    ",
        "submission_date": "2013-10-08T00:00:00",
        "last_modified_date": "2013-10-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1310.2418",
        "title": "Linear Algorithm for Digital Euclidean Connected Skeleton",
        "authors": [
            "Aur\u00e9lie Leborgne",
            "Julien Mille",
            "Laure Tougne"
        ],
        "abstract": "The skeleton is an essential shape characteristic providing a compact representation of the studied shape. Its computation on the image grid raises many issues. Due to the effects of discretization, the required properties of the skeleton - thinness, homotopy to the shape, reversibility, connectivity - may become incompatible. However, as regards practical use, the choice of a specific skeletonization algorithm depends on the application. This allows to classify the desired properties by order of importance, and tend towards the most critical ones. Our goal is to make a skeleton dedicated to shape matching for recognition. So, the discrete skeleton has to be thin - so that it can be represented by a graph -, robust to noise, reversible - so that the initial shape can be fully reconstructed - and homotopic to the shape. We propose a linear-time skeletonization algorithm based on the squared Euclidean distance map from which we extract the maximal balls and ridges. After a thinning and pruning process, we obtain the skeleton. The proposed method is finally compared to fairly recent methods.\n    ",
        "submission_date": "2013-10-09T00:00:00",
        "last_modified_date": "2014-06-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1310.2916",
        "title": "From Shading to Local Shape",
        "authors": [
            "Ying Xiong",
            "Ayan Chakrabarti",
            "Ronen Basri",
            "Steven J. Gortler",
            "David W. Jacobs",
            "Todd Zickler"
        ],
        "abstract": "We develop a framework for extracting a concise representation of the shape information available from diffuse shading in a small image patch. This produces a mid-level scene descriptor, comprised of local shape distributions that are inferred separately at every image patch across multiple scales. The framework is based on a quadratic representation of local shape that, in the absence of noise, has guarantees on recovering accurate local shape and lighting. And when noise is present, the inferred local shape distributions provide useful shape information without over-committing to any particular image explanation. These local shape distributions naturally encode the fact that some smooth diffuse regions are more informative than others, and they enable efficient and robust reconstruction of object-scale shape. Experimental results show that this approach to surface reconstruction compares well against the state-of-art on both synthetic images and captured photographs.\n    ",
        "submission_date": "2013-10-10T00:00:00",
        "last_modified_date": "2014-04-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1310.3233",
        "title": "Bayesian Estimation of White Matter Atlas from High Angular Resolution Diffusion Imaging",
        "authors": [
            "Jia Du",
            "Alvina Goh",
            "Anqi Qiu"
        ],
        "abstract": "We present a Bayesian probabilistic model to estimate the brain white matter atlas from high angular resolution diffusion imaging (HARDI) data. This model incorporates a shape prior of the white matter anatomy and the likelihood of individual observed HARDI datasets. We first assume that the atlas is generated from a known hyperatlas through a flow of diffeomorphisms and its shape prior can be constructed based on the framework of large deformation diffeomorphic metric mapping (LDDMM). LDDMM characterizes a nonlinear diffeomorphic shape space in a linear space of initial momentum uniquely determining diffeomorphic geodesic flows from the hyperatlas. Therefore, the shape prior of the HARDI atlas can be modeled using a centered Gaussian random field (GRF) model of the initial momentum. In order to construct the likelihood of observed HARDI datasets, it is necessary to study the diffeomorphic transformation of individual observations relative to the atlas and the probabilistic distribution of orientation distribution functions (ODFs). To this end, we construct the likelihood related to the transformation using the same construction as discussed for the shape prior of the atlas. The probabilistic distribution of ODFs is then constructed based on the ODF Riemannian manifold. We assume that the observed ODFs are generated by an exponential map of random tangent vectors at the deformed atlas ODF. Hence, the likelihood of the ODFs can be modeled using a GRF of their tangent vectors in the ODF Riemannian manifold. We solve for the maximum a posteriori using the Expectation-Maximization algorithm and derive the corresponding update equations. Finally, we illustrate the HARDI atlas constructed based on a Chinese aging cohort of 94 adults and compare it with that generated by averaging the coefficients of spherical harmonics of the ODF across subjects.\n    ",
        "submission_date": "2013-10-10T00:00:00",
        "last_modified_date": "2013-10-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1310.3366",
        "title": "PCG-Cut: Graph Driven Segmentation of the Prostate Central Gland",
        "authors": [
            "Jan Egger"
        ],
        "abstract": "Prostate cancer is the most abundant cancer in men, with over 200,000 expected new cases and around 28,000 deaths in 2012 in the US alone. In this study, the segmentation results for the prostate central gland (PCG) in MR scans are presented. The aim of this research study is to apply a graph-based algorithm to automated segmentation (i.e. delineation) of organ limits for the prostate central gland. The ultimate goal is to apply automated segmentation approach to facilitate efficient MR-guided biopsy and radiation treatment planning. The automated segmentation algorithm used is graph-driven based on a spherical template. Therefore, rays are sent through the surface points of a polyhedron to sample the graph's nodes. After graph construction - which only requires the center of the polyhedron defined by the user and located inside the prostate center gland - the minimal cost closed set on the graph is computed via a polynomial time s-t-cut, which results in the segmentation of the prostate center gland's boundaries and volume. The algorithm has been realized as a C++ modul within the medical research platform MeVisLab and the ground truth of the central gland boundaries were manually extracted by clinical experts (interventional radiologists) with several years of experience in prostate treatment. For evaluation the automated segmentations of the proposed scheme have been compared with the manual segmentations, yielding an average Dice Similarity Coefficient (DSC) of 78.94 +/- 10.85%.\n    ",
        "submission_date": "2013-10-12T00:00:00",
        "last_modified_date": "2013-10-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1310.3399",
        "title": "An Improved K-means Clustering Based Approach to Detect a DNA Structure in H&E Image of Mouse Tissue Reacted with CD4-Green Antigen",
        "authors": [
            "B U V Prashanth",
            "P Narahari Sastry",
            "V Rajesh"
        ],
        "abstract": "In this manuscript we present the technique to detect and analyze the DNA rich structure in Haemotoxylin & Eosin (H&E) image of a tissue treated with anti CD4 green antigen. The detection of DNA rich structure can be considered as a detection of blue nuclei present through the biomedical signal/image processing technique performed on the image of the tissue obtained by the Scanning Electron Microscope(SEM). Earlier the tissue treated with the anti CD4 green antigen, is stained with the H&E staining solution.\n    ",
        "submission_date": "2013-10-12T00:00:00",
        "last_modified_date": "2013-10-31T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1310.3447",
        "title": "Image Restoration using Total Variation with Overlapping Group Sparsity",
        "authors": [
            "Jun Liu",
            "Ting-Zhu Huang",
            "Ivan W. Selesnick",
            "Xiao-Guang Lv",
            "Po-Yu Chen"
        ],
        "abstract": "Image restoration is one of the most fundamental issues in imaging science. Total variation (TV) regularization is widely used in image restoration problems for its capability to preserve edges. In the literature, however, it is also well known for producing staircase-like artifacts. Usually, the high-order total variation (HTV) regularizer is an good option except its over-smoothing property. In this work, we study a minimization problem where the objective includes an usual $l_2$ data-fidelity term and an overlapping group sparsity total variation regularizer which can avoid staircase effect and allow edges preserving in the restored image. We also proposed a fast algorithm for solving the corresponding minimization problem and compare our method with the state-of-the-art TV based methods and HTV based method. The numerical experiments illustrate the efficiency and effectiveness of the proposed method in terms of PSNR, relative error and computing time.\n    ",
        "submission_date": "2013-10-13T00:00:00",
        "last_modified_date": "2013-10-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1310.3452",
        "title": "Dense Scattering Layer Removal",
        "authors": [
            "Qiong Yan",
            "Li Xu",
            "Jiaya Jia"
        ],
        "abstract": "We propose a new model, together with advanced optimization, to separate a thick scattering media layer from a single natural image. It is able to handle challenging underwater scenes and images taken in fog and sandstorm, both of which are with significantly reduced visibility. Our method addresses the critical issue -- this is, originally unnoticeable impurities will be greatly magnified after removing the scattering media layer -- with transmission-aware optimization. We introduce non-local structure-aware regularization to properly constrain transmission estimation without introducing the halo artifacts. A selective-neighbor criterion is presented to convert the unconventional constrained optimization problem to an unconstrained one where the latter can be efficiently solved.\n    ",
        "submission_date": "2013-10-13T00:00:00",
        "last_modified_date": "2013-10-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1310.3717",
        "title": "Misfire Detection in IC Engine using Kstar Algorithm",
        "authors": [
            "Anish Bahri",
            "V Sugumaran",
            "S Babu Devasenapati"
        ],
        "abstract": "Misfire in an IC Engine continues to be a problem leading to reduced fuel efficiency, increased power loss and emissions containing heavy concentration of hydrocarbons. Misfiring creates a unique vibration pattern attributed to a particular cylinder. Useful features can be extracted from these patterns and can be analyzed to detect misfire. Statistical features from these vibration signals were extracted. Out of these, useful features were identified using the J48 decision tree algorithm and selected features were used for classification using the Kstar algorithm. In this paper performance analysis of Kstar algorithm is presented.\n    ",
        "submission_date": "2013-10-14T00:00:00",
        "last_modified_date": "2013-10-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1310.4217",
        "title": "Optimal Sensor Placement and Enhanced Sparsity for Classification",
        "authors": [
            "B. W. Brunton",
            "S. L. Brunton",
            "J. L. Proctor",
            "J. N. Kutz"
        ],
        "abstract": "The goal of compressive sensing is efficient reconstruction of data from few measurements, sometimes leading to a categorical decision. If only classification is required, reconstruction can be circumvented and the measurements needed are orders-of-magnitude sparser still. We define enhanced sparsity as the reduction in number of measurements required for classification over reconstruction. In this work, we exploit enhanced sparsity and learn spatial sensor locations that optimally inform a categorical decision. The algorithm solves an l1-minimization to find the fewest entries of the full measurement vector that exactly reconstruct the discriminant vector in feature space. Once the sensor locations have been identified from the training data, subsequent test samples are classified with remarkable efficiency, achieving performance comparable to that obtained by discrimination using the full image. Sensor locations may be learned from full images, or from a random subsample of pixels. For classification between more than two categories, we introduce a coupling parameter whose value tunes the number of sensors selected, trading accuracy for economy. We demonstrate the algorithm on example datasets from image recognition using PCA for feature extraction and LDA for discrimination; however, the method can be broadly applied to non-image data and adapted to work with other methods for feature extraction and discrimination.\n    ",
        "submission_date": "2013-10-15T00:00:00",
        "last_modified_date": "2013-10-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1310.4713",
        "title": "Calibration of an Articulated Camera System with Scale Factor Estimation",
        "authors": [
            "Junzhou Chen",
            "Kin Hong Wong"
        ],
        "abstract": "Multiple Camera Systems (MCS) have been widely used in many vision applications and attracted much attention recently. There are two principle types of MCS, one is the Rigid Multiple Camera System (RMCS); the other is the Articulated Camera System (ACS). In a RMCS, the relative poses (relative 3-D position and orientation) between the cameras are invariant. While, in an ACS, the cameras are articulated through movable joints, the relative pose between them may change. Therefore, through calibration of an ACS we want to find not only the relative poses between the cameras but also the positions of the joints in the ACS.\n",
        "submission_date": "2013-10-17T00:00:00",
        "last_modified_date": "2013-10-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1310.4759",
        "title": "Fine-grained Categorization -- Short Summary of our Entry for the ImageNet Challenge 2012",
        "authors": [
            "Christoph G\u00f6ring",
            "Alexander Freytag",
            "Erik Rodner",
            "Joachim Denzler"
        ],
        "abstract": "In this paper, we tackle the problem of visual categorization of dog breeds, which is a surprisingly challenging task due to simultaneously present low interclass distances and high intra-class variances. Our approach combines several techniques well known in our community but often not utilized for fine-grained recognition:\n",
        "submission_date": "2013-10-17T00:00:00",
        "last_modified_date": "2013-10-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1310.4822",
        "title": "Principal motion components for gesture recognition using a single-example",
        "authors": [
            "Hugo Jair Escalante",
            "Isabelle Guyon",
            "Vassilis Athitsos",
            "Pat Jangyodsuk",
            "Jun Wan"
        ],
        "abstract": "This paper introduces principal motion components (PMC), a new method for one-shot gesture recognition. In the considered scenario a single training-video is available for each gesture to be recognized, which limits the application of traditional techniques (e.g., HMMs). In PMC, a 2D map of motion energy is obtained per each pair of consecutive frames in a video. Motion maps associated to a video are processed to obtain a PCA model, which is used for recognition under a reconstruction-error approach. The main benefits of the proposed approach are its simplicity, easiness of implementation, competitive performance and efficiency. We report experimental results in one-shot gesture recognition using the ChaLearn Gesture Dataset; a benchmark comprising more than 50,000 gestures, recorded as both RGB and depth video with a Kinect camera. Results obtained with PMC are competitive with alternative methods proposed for the same data set.\n    ",
        "submission_date": "2013-10-17T00:00:00",
        "last_modified_date": "2014-01-31T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1310.4891",
        "title": "Dictionary Learning and Sparse Coding on Grassmann Manifolds: An Extrinsic Solution",
        "authors": [
            "Mehrtash Harandi",
            "Conrad Sanderson",
            "Chunhua Shen",
            "Brian C. Lovell"
        ],
        "abstract": "Recent advances in computer vision and machine learning suggest that a wide range of problems can be addressed more appropriately by considering non-Euclidean geometry. In this paper we explore sparse dictionary learning over the space of linear subspaces, which form Riemannian structures known as Grassmann manifolds. To this end, we propose to embed Grassmann manifolds into the space of symmetric matrices by an isometric mapping, which enables us to devise a closed-form solution for updating a Grassmann dictionary, atom by atom. Furthermore, to handle non-linearity in data, we propose a kernelised version of the dictionary learning algorithm. Experiments on several classification tasks (face recognition, action recognition, dynamic texture classification) show that the proposed approach achieves considerable improvements in discrimination accuracy, in comparison to state-of-the-art methods such as kernelised Affine Hull Method and graph-embedding Grassmann discriminant analysis.\n    ",
        "submission_date": "2013-10-18T00:00:00",
        "last_modified_date": "2013-10-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1310.5082",
        "title": "On the Suitable Domain for SVM Training in Image Coding",
        "authors": [
            "Gustavo Camps-Valls",
            "Juan Guti\u00e9rrez",
            "Gabriel G\u00f3mez-P\u00e9rez",
            "Jes\u00fas Malo"
        ],
        "abstract": "Conventional SVM-based image coding methods are founded on independently restricting the distortion in every image coefficient at some particular image representation. Geometrically, this implies allowing arbitrary signal distortions in an $n$-dimensional rectangle defined by the $\\varepsilon$-insensitivity zone in each dimension of the selected image representation domain. Unfortunately, not every image representation domain is well-suited for such a simple, scalar-wise, approach because statistical and/or perceptual interactions between the coefficients may exist. These interactions imply that scalar approaches may induce distortions that do not follow the image statistics and/or are perceptually annoying. Taking into account these relations would imply using non-rectangular $\\varepsilon$-insensitivity regions (allowing coupled distortions in different coefficients), which is beyond the conventional SVM formulation.\n",
        "submission_date": "2013-10-18T00:00:00",
        "last_modified_date": "2013-10-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1310.5107",
        "title": "Advances in Hyperspectral Image Classification: Earth monitoring with statistical learning methods",
        "authors": [
            "Gustavo Camps-Valls",
            "Devis Tuia",
            "Lorenzo Bruzzone",
            "J\u00f3n Atli Benediktsson"
        ],
        "abstract": "Hyperspectral images show similar statistical properties to natural grayscale or color photographic images. However, the classification of hyperspectral images is more challenging because of the very high dimensionality of the pixels and the small number of labeled examples typically available for learning. These peculiarities lead to particular signal processing problems, mainly characterized by indetermination and complex manifolds. The framework of statistical learning has gained popularity in the last decade. New methods have been presented to account for the spatial homogeneity of images, to include user's interaction via active learning, to take advantage of the manifold structure with semisupervised learning, to extract and encode invariances, or to adapt classifiers and image representations to unseen yet similar scenes. This tutuorial reviews the main advances for hyperspectral remote sensing image classification through illustrative examples.\n    ",
        "submission_date": "2013-10-18T00:00:00",
        "last_modified_date": "2013-10-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1310.5542",
        "title": "Ship Detection and Segmentation using Image Correlation",
        "authors": [
            "Alexander Kadyrov",
            "Hui Yu",
            "Honghai Liu"
        ],
        "abstract": "There have been intensive research interests in ship detection and segmentation due to high demands on a wide range of civil applications in the last two decades. However, existing approaches, which are mainly based on statistical properties of images, fail to detect smaller ships and boats. Specifically, known techniques are not robust enough in view of inevitable small geometric and photometric changes in images consisting of ships. In this paper a novel approach for ship detection is proposed based on correlation of maritime images. The idea comes from the observation that a fine pattern of the sea surface changes considerably from time to time whereas the ship appearance basically keeps unchanged. We want to examine whether the images have a common unaltered part, a ship in this case. To this end, we developed a method - Focused Correlation (FC) to achieve robustness to geometric distortions of the image content. Various experiments have been conducted to evaluate the effectiveness of the proposed approach.\n    ",
        "submission_date": "2013-10-21T00:00:00",
        "last_modified_date": "2013-10-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1310.5619",
        "title": "Devnagari Handwritten Numeral Recognition using Geometric Features and Statistical Combination Classifier",
        "authors": [
            "Vikas J. Dongre",
            "Vijay H. Mankar"
        ],
        "abstract": "This paper presents a Devnagari Numerical recognition method based on statistical discriminant functions. 17 geometric features based on pixel connectivity, lines, line directions, holes, image area, perimeter, eccentricity, solidity, orientation etc. are used for representing the numerals. Five discriminant functions viz. Linear, Quadratic, Diaglinear, Diagquadratic and Mahalanobis distance are used for classification. 1500 handwritten numerals are used for training. Another 1500 handwritten numerals are used for testing. Experimental results show that Linear, Quadratic and Mahalanobis discriminant functions provide better results. Results of these three Discriminants are fed to a majority voting type Combination classifier. It is found that Combination classifier offers better results over individual classifiers.\n    ",
        "submission_date": "2013-10-21T00:00:00",
        "last_modified_date": "2013-10-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1310.5755",
        "title": "Determination, Calculation and Representation of the Upper and Lower Sealing Zones During Virtual Stenting of Aneurysms",
        "authors": [
            "Jan Egger",
            "Miriam H. A. Bauer",
            "Stefan Gro\u00dfkopf",
            "Christina Biermann",
            "Bernd Freisleben",
            "Christopher Nimsky"
        ],
        "abstract": "In this contribution, a novel method for stent simulation in preoperative computed tomography angiography (CTA) acquisitions of patients is presented where the sealing zones are automatically calculated and visualized. The method is eligible for non-bifurcated and bifurcated stents (Y-stents). Results of the proposed stent simulation with an automatic calculation of the sealing zones for specific diseases (abdominal aortic aneurysms (AAA), thoracic aortic aneurysms (TAA), iliac aneurysms) are presented. The contribution is organized as follows. Section 2 presents the proposed approach. In Section 3, experimental results are discussed. Section 4 concludes the contribution and outlines areas for future work.\n    ",
        "submission_date": "2013-10-21T00:00:00",
        "last_modified_date": "2013-10-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1310.5767",
        "title": "Contextual Hypergraph Modelling for Salient Object Detection",
        "authors": [
            "Xi Li",
            "Yao Li",
            "Chunhua Shen",
            "Anthony Dick",
            "Anton van den Hengel"
        ],
        "abstract": "Salient object detection aims to locate objects that capture human attention within images. Previous approaches often pose this as a problem of image contrast analysis. In this work, we model an image as a hypergraph that utilizes a set of hyperedges to capture the contextual properties of image pixels or regions. As a result, the problem of salient object detection becomes one of finding salient vertices and hyperedges in the hypergraph. The main advantage of hypergraph modeling is that it takes into account each pixel's (or region's) affinity with its neighborhood as well as its separation from image background. Furthermore, we propose an alternative approach based on center-versus-surround contextual contrast analysis, which performs salient object detection by optimizing a cost-sensitive support vector machine (SVM) objective function. Experimental results on four challenging datasets demonstrate the effectiveness of the proposed approaches against the state-of-the-art approaches to salient object detection.\n    ",
        "submission_date": "2013-10-22T00:00:00",
        "last_modified_date": "2013-10-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1310.5965",
        "title": "Fusion of Hyperspectral and Panchromatic Images using Spectral Uumixing Results",
        "authors": [
            "Roozbeh Rajabi",
            "Hassan Ghassemian"
        ],
        "abstract": "Hyperspectral imaging, due to providing high spectral resolution images, is one of the most important tools in the remote sensing field. Because of technological restrictions hyperspectral sensors has a limited spatial resolution. On the other hand panchromatic image has a better spatial resolution. Combining this information together can provide a better understanding of the target scene. Spectral unmixing of mixed pixels in hyperspectral images results in spectral signature and abundance fractions of endmembers but gives no information about their location in a mixed pixel. In this paper we have used spectral unmixing results of hyperspectral images and segmentation results of panchromatic image for data fusion. The proposed method has been applied on simulated data using AVRIS Indian Pines datasets. Results show that this method can effectively combine information in hyperspectral and panchromatic images.\n    ",
        "submission_date": "2013-10-22T00:00:00",
        "last_modified_date": "2013-10-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1310.5999",
        "title": "Improvement of Automatic Hemorrhages Detection Methods Using Shapes Recognition",
        "authors": [
            "Nidhal Khdhair El Abbadi",
            "Enas Hamood Al Saadi"
        ],
        "abstract": "Diabetic Retinopathy is a medical condition where the retina is damaged because fluid leaks from blood vessels into the retina. The presence of hemorrhages in the retina is the earliest symptom of diabetic retinopathy. The number and shape of hemorrhages is used to indicate the severity of the disease. Early automated hemorrhage detection can help reduce the incidence of blindness. This paper introduced new method depending on the hemorrhage shape to detect the dot hemorrhage (DH), its number, and size at early stage, this can be achieved by reducing the retinal image details. Detection and recognize the DH by following three sequential steps, removing the fovea, removing the vasculature and recognize DH by determining the circularity for all the objects in the image, finally determine the shape factor which is related to DH recognition, this stage strengthens the recognition process. The proposed method recognizes and separates all the DH.\n    ",
        "submission_date": "2013-10-22T00:00:00",
        "last_modified_date": "2013-10-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1310.6063",
        "title": "Word Spotting in Cursive Handwritten Documents using Modified Character Shape Codes",
        "authors": [
            "Sayantan Sarkar"
        ],
        "abstract": "There is a large collection of Handwritten English paper documents of Historical and Scientific importance. But paper documents are not recognized directly by computer. Hence the closest way of indexing these documents is by storing their document digital image. Hence a large database of document images can replace the paper documents. But the document and data corresponding to each image cannot be directly recognized by the computer.\n",
        "submission_date": "2013-10-22T00:00:00",
        "last_modified_date": "2013-10-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1310.6066",
        "title": "Skin Segmentation based Elastic Bunch Graph Matching for efficient multiple Face Recognition",
        "authors": [
            "Sayantan Sarkar"
        ],
        "abstract": "This paper is aimed at developing and combining different algorithms for face detection and face recognition to generate an efficient mechanism that can detect and recognize the facial regions of input image. For the detection of face from complex region, skin segmentation isolates the face-like regions in a complex image and following operations of morphology and template matching rejects false matches to extract facial region. For the recognition of the face, the image database is now converted into a database of facial segments. Hence, implementing the technique of Elastic Bunch Graph matching (EBGM) after skin segmentation generates Face Bunch Graphs that acutely represents the features of an individual face enhances the quality of the training set. This increases the matching probability significantly.\n    ",
        "submission_date": "2013-10-22T00:00:00",
        "last_modified_date": "2013-10-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1310.6092",
        "title": "A Ray-based Approach for Boundary Estimation of Fiber Bundles Derived from Diffusion Tensor Imaging",
        "authors": [
            "Miriam H. A. Bauer",
            "Sebastiano Barbieri",
            "Jan Klein",
            "Jan Egger",
            "Daniela Kuhnt",
            "Bernd Freisleben",
            "Horst K. Hahn",
            "Christopher Nimsky"
        ],
        "abstract": "Diffusion Tensor Imaging (DTI) is a non-invasive imaging technique that allows estimation of the location of white matter tracts in-vivo, based on the measurement of water diffusion properties. For each voxel, a second-order tensor can be calculated by using diffusion-weighted sequences (DWI) that are sensitive to the random motion of water molecules. Given at least 6 diffusion-weighted images with different gradients and one unweighted image, the coefficients of the symmetric diffusion tensor matrix can be calculated. Deriving the eigensystem of the tensor, the eigenvectors and eigenvalues can be calculated to describe the three main directions of diffusion and its magnitude. Using DTI data, fiber bundles can be determined, to gain information about eloquent brain structures. Especially in neurosurgery, information about location and dimension of eloquent structures like the corticospinal tract or the visual pathways is of major interest. Therefore, the fiber bundle boundary has to be determined. In this paper, a novel ray-based approach for boundary estimation of tubular structures is presented.\n    ",
        "submission_date": "2013-10-23T00:00:00",
        "last_modified_date": "2013-10-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1310.6376",
        "title": "Can Facial Uniqueness be Inferred from Impostor Scores?",
        "authors": [
            "Abhishek Dutta",
            "Raymond Veldhuis",
            "Luuk Spreeuwers"
        ],
        "abstract": "In Biometrics, facial uniqueness is commonly inferred from impostor similarity scores. In this paper, we show that such uniqueness measures are highly unstable in the presence of image quality variations like pose, noise and blur. We also experimentally demonstrate the instability of a recently introduced impostor-based uniqueness measure of [Klare and Jain 2013] when subject to poor quality facial images.\n    ",
        "submission_date": "2013-10-23T00:00:00",
        "last_modified_date": "2013-10-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1310.6654",
        "title": "Pseudo vs. True Defect Classification in Printed Circuits Boards using Wavelet Features",
        "authors": [
            "Sahil Sikka",
            "Karan Sikka",
            "M.K. Bhuyan",
            "Yuji Iwahori"
        ],
        "abstract": "In recent years, Printed Circuit Boards (PCB) have become the backbone of a large number of consumer electronic devices leading to a surge in their production. This has made it imperative to employ automatic inspection systems to identify manufacturing defects in PCB before they are installed in the respective systems. An important task in this regard is the classification of defects as either true or pseudo defects, which decides if the PCB is to be re-manufactured or not. This work proposes a novel approach to detect most common defects in the PCBs. The problem has been approached by employing highly discriminative features based on multi-scale wavelet transform, which are further boosted by using a kernalized version of the support vector machines (SVM). A real world printed circuit board dataset has been used for quantitative analysis. Experimental results demonstrated the efficacy of the proposed method.\n    ",
        "submission_date": "2013-10-24T00:00:00",
        "last_modified_date": "2013-10-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1310.6719",
        "title": "Two Dimensional Array Imaging with Beam Steered Data",
        "authors": [
            "Sujeet Patole",
            "Murat Torlak"
        ],
        "abstract": "This paper discusses different approaches used for millimeter wave imaging of two-dimensional objects. Imaging of a two dimensional object requires reflected wave data to be collected across two distinct dimensions. In this paper, we propose a reconstruction method that uses narrowband waveforms along with two dimensional beam steering. The beam is steered in azimuthal and elevation direction, which forms the two distinct dimensions required for the reconstruction. The Reconstruction technique uses inverse Fourier transform along with amplitude and phase correction factors. In addition, this reconstruction technique does not require interpolation of the data in either wavenumber or spatial domain. Use of the two dimensional beam steering offers better performance in the presence of noise compared with the existing methods, such as switched array imaging system. Effects of RF impairments such as quantization of the phase of beam steering weights and timing jitter which add to phase noise, are analyzed.\n    ",
        "submission_date": "2013-10-24T00:00:00",
        "last_modified_date": "2014-04-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1310.6736",
        "title": "Fast 3D Salient Region Detection in Medical Images using GPUs",
        "authors": [
            "Rahul Thota",
            "Sharan Vaswani",
            "Amit Kale",
            "Nagavijayalakshmi Vydyanathan"
        ],
        "abstract": "Automated detection of visually salient regions is an active area of research in computer vision. Salient regions can serve as inputs for object detectors as well as inputs for region based registration algorithms. In this paper we consider the problem of speeding up computationally intensive bottom-up salient region detection in 3D medical ",
        "submission_date": "2013-10-24T00:00:00",
        "last_modified_date": "2013-10-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1310.6808",
        "title": "Gender Classification Using Gradient Direction Pattern",
        "authors": [
            "Mohammad shahidul Islam"
        ],
        "abstract": "A novel methodology for gender classification is presented in this paper. It extracts feature from local region of a face using gray color intensity difference. The facial area is divided into sub-regions and GDP histogram extracted from those regions are concatenated into a single vector to represent the face. The classification accuracy obtained by using support vector machine has outperformed all traditional feature descriptors for gender classification. It is evaluated on the images collected from FERET database and obtained very high accuracy.\n    ",
        "submission_date": "2013-10-25T00:00:00",
        "last_modified_date": "2013-10-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1310.7114",
        "title": "Efficient Information Theoretic Clustering on Discrete Lattices",
        "authors": [
            "Christian Bauckhage",
            "Kristian Kersting"
        ],
        "abstract": "We consider the problem of clustering data that reside on discrete, low dimensional lattices. Canonical examples for this setting are found in image segmentation and key point extraction. Our solution is based on a recent approach to information theoretic clustering where clusters result from an iterative procedure that minimizes a divergence measure. We replace costly processing steps in the original algorithm by means of convolutions. These allow for highly efficient implementations and thus significantly reduce runtime. This paper therefore bridges a gap between machine learning and signal processing.\n    ",
        "submission_date": "2013-10-26T00:00:00",
        "last_modified_date": "2013-10-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1310.7170",
        "title": "Object Recognition System Design in Computer Vision: a Universal Approach",
        "authors": [
            "Andrew Gleibman"
        ],
        "abstract": "The first contribution of this paper is architecture of a multipurpose system, which delegates a range of object detection tasks to a classifier, applied in special grid positions of the tested image. The second contribution is Gray Level-Radius Co-occurrence Matrix, which describes local image texture and topology and, unlike common second order statistics methods, is robust to image resolution. The third contribution is a parametrically controlled automatic synthesis of unlimited number of numerical features for classification. The fourth contribution is a method of optimizing parameters C and gamma in LibSVM-based classifier, which is 20-100 times faster than the commonly applied method. The work is essentially experimental, with demonstration of various methods for definition of objects of interest in images and video sequences.\n    ",
        "submission_date": "2013-10-27T00:00:00",
        "last_modified_date": "2013-12-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1310.7440",
        "title": "Neural perceptual model to global-local vision for recognition of the logical structure of administrative documents",
        "authors": [
            "Boulbaba Ben Ammar"
        ],
        "abstract": "This paper gives the definition of Transparent Neural Network \"TNN\" for the simulation of the globallocal vision and its application to the segmentation of administrative document image. We have developed and have adapted a recognition method which models the contextual effects reported from studies in experimental psychology. Then, we evaluated and tested the TNN and the multi-layer perceptron \"MLP\", which showed its effectiveness in the field of the recognition, in order to show that the TNN is clearer for the user and more powerful on the level of the recognition. Indeed, the TNN is the only system which makes it possible to recognize the document and its structure.\n    ",
        "submission_date": "2013-10-09T00:00:00",
        "last_modified_date": "2013-10-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1310.7441",
        "title": "Hierarchical Clustering of Hyperspectral Images using Rank-Two Nonnegative Matrix Factorization",
        "authors": [
            "Nicolas Gillis",
            "Da Kuang",
            "Haesun Park"
        ],
        "abstract": "In this paper, we design a hierarchical clustering algorithm for high-resolution hyperspectral images. At the core of the algorithm, a new rank-two nonnegative matrix factorizations (NMF) algorithm is used to split the clusters, which is motivated by convex geometry concepts. The method starts with a single cluster containing all pixels, and, at each step, (i) selects a cluster in such a way that the error at the next step is minimized, and (ii) splits the selected cluster into two disjoint clusters using rank-two NMF in such a way that the clusters are well balanced and stable. The proposed method can also be used as an endmember extraction algorithm in the presence of pure pixels. The effectiveness of this approach is illustrated on several synthetic and real-world hyperspectral images, and shown to outperform standard clustering techniques such as k-means, spherical k-means and standard NMF.\n    ",
        "submission_date": "2013-09-14T00:00:00",
        "last_modified_date": "2014-08-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1310.7443",
        "title": "On Convergent Finite Difference Schemes for Variational - PDE Based Image Processing",
        "authors": [
            "V. B. S. Prasath",
            "Juan C. Moreno"
        ],
        "abstract": "We study an adaptive anisotropic Huber functional based image restoration scheme. By using a combination of L2-L1 regularization functions, an adaptive Huber functional based energy minimization model provides denoising with edge preservation in noisy digital images. We study a convergent finite difference scheme based on continuous piecewise linear functions and use a variable splitting scheme, namely the Split Bregman, to obtain the discrete minimizer. Experimental results are given in image denoising and comparison with additive operator splitting, dual fixed point, and projected gradient schemes illustrate that the best convergence rates are obtained for our algorithm.\n    ",
        "submission_date": "2013-09-16T00:00:00",
        "last_modified_date": "2013-09-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1310.7447",
        "title": "Impulse Noise Removal In Speech Using Wavelets",
        "authors": [
            "R. C. Nongpiur"
        ],
        "abstract": "A new method for removing impulse noise from speech in the wavelet transform domain is proposed. The method utilizes the multiresolution property of the wavelet transform, which provides finer time resolution at the higher frequencies than the short-time Fourier transform (STFT), to effectively identify and remove impulse noise. It uses two features of speech to discriminate speech from impulse noise: one is the slow time-varying nature of speech and the other is the Lipschitz regularity of the speech components. On the basis of these features, an algorithm has been developed to identify and suppress wavelet coefficients that correspond to impulse noise. Experiment results show that the new method is able to significantly reduce impulse noise without degrading the quality of the speech signal or introducing any audible artifacts.\n    ",
        "submission_date": "2013-08-14T00:00:00",
        "last_modified_date": "2013-08-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1310.7448",
        "title": "An iterative algorithm for computed tomography image reconstruction from limited-angle projections",
        "authors": [
            "Yuli Sun",
            "Jinxu Tao",
            "Conggui Liu"
        ],
        "abstract": "In application of tomography imaging, limited-angle problem is a quite practical and important issue. In this paper, an iterative reprojection-reconstruction (IRR) algorithm using a modified Papoulis-Gerchberg (PG) iterative scheme is developed for reconstruction from limited-angle projections which contain noise. The proposed algorithm has two iterative update processes, one is the extrapolation of unknown data, and the other is the modification of the known noisy observation data. And the algorithm introduces scaling factors to control the two processes, respectively. The convergence of the algorithm is guaranteed, and the method of choosing the scaling factors is given with energy constraints. The simulation result demonstrates our conclusions and indicates that the algorithm proposed in this paper can obviously improve the reconstruction quality.\n    ",
        "submission_date": "2013-09-16T00:00:00",
        "last_modified_date": "2013-09-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1310.7813",
        "title": "Smoothness-Constrained Image Recovery from Block-Based Random Projections",
        "authors": [
            "Giulio Coluccia",
            "Diego Valsesia",
            "Enrico Magli"
        ],
        "abstract": "In this paper we address the problem of visual quality of images reconstructed from block-wise random projections. Independent reconstruction of the blocks can severely affect visual quality, by displaying artifacts along block borders. We propose a method to enforce smoothness across block borders by modifying the sensing and reconstruction process so as to employ partially overlapping blocks. The proposed algorithm accomplishes this by computing a fast preview from the blocks, whose purpose is twofold. On one hand, it allows to enforce a set of constraints to drive the reconstruction algorithm towards a smooth solution, imposing the similarity of block borders. On the other hand, the preview is used as a predictor of the entire block, allowing to recover the prediction error, only. The quality improvement over the result of independent reconstruction can be easily assessed both visually and in terms of PSNR and SSIM index.\n    ",
        "submission_date": "2013-10-08T00:00:00",
        "last_modified_date": "2013-10-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1311.0053",
        "title": "Robust Compressed Sensing and Sparse Coding with the Difference Map",
        "authors": [
            "Will Landecker",
            "Rick Chartrand",
            "Simon DeDeo"
        ],
        "abstract": "In compressed sensing, we wish to reconstruct a sparse signal $x$ from observed data $y$. In sparse coding, on the other hand, we wish to find a representation of an observed signal $y$ as a sparse linear combination, with coefficients $x$, of elements from an overcomplete dictionary. While many algorithms are competitive at both problems when $x$ is very sparse, it can be challenging to recover $x$ when it is less sparse. We present the Difference Map, which excels at sparse recovery when sparseness is lower and noise is higher. The Difference Map out-performs the state of the art with reconstruction from random measurements and natural image reconstruction via sparse coding.\n    ",
        "submission_date": "2013-10-31T00:00:00",
        "last_modified_date": "2013-11-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1311.0119",
        "title": "Structure-preserving color transformations using Laplacian commutativity",
        "authors": [
            "Davide Eynard",
            "Artiom Kovnatsky",
            "Michael M. Bronstein"
        ],
        "abstract": "Mappings between color spaces are ubiquitous in image processing problems such as gamut mapping, decolorization, and image optimization for color-blind people. Simple color transformations often result in information loss and ambiguities (for example, when mapping from RGB to grayscale), and one wishes to find an image-specific transformation that would preserve as much as possible the structure of the original image in the target color space. In this paper, we propose Laplacian colormaps, a generic framework for structure-preserving color transformations between images. We use the image Laplacian to capture the structural information, and show that if the color transformation between two images preserves the structure, the respective Laplacians have similar eigenvectors, or in other words, are approximately jointly diagonalizable. Employing the relation between joint diagonalizability and commutativity of matrices, we use Laplacians commutativity as a criterion of color mapping quality and minimize it w.r.t. the parameters of a color transformation to achieve optimal structure preservation. We show numerous applications of our approach, including color-to-gray conversion, gamut mapping, multispectral image fusion, and image optimization for color deficient viewers.\n    ",
        "submission_date": "2013-11-01T00:00:00",
        "last_modified_date": "2013-11-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1311.0124",
        "title": "Reconstruction of Complex-Valued Fractional Brownian Motion Fields Based on Compressive Sampling and Its Application to PSF Interpolation in Weak Lensing Survey",
        "authors": [
            "Andriyan B. Suksmono"
        ],
        "abstract": "A new reconstruction method of complex-valued fractional Brownian motion (CV-fBm) field based on Compressive Sampling (CS) is proposed. The decay property of Fourier coefficients magnitude of the fBm signals/ fields indicates that fBms are compressible. Therefore, a few numbers of samples will be sufficient for a CS based method to reconstruct the full field. The effectiveness of the proposed method is showed by simulating, random sampling, and reconstructing CV-fBm fields. Performance evaluation shows advantages of the proposed method over boxcar filtering and thin plate methods. It is also found that the reconstruction performance depends on both of the fBm's Hurst parameter and the number of samples, which in fact is consistent with the CS reconstruction theory. In contrast to other fBm or fractal interpolation methods, the proposed CS based method does not require the knowledge of fractal parameters in the reconstruction process; the inherent sparsity is just sufficient for the CS to do the reconstruction. Potential applicability of the proposed method in weak gravitational lensing survey, particularly for interpolating non-smooth PSF (Point Spread Function) distribution representing distortion by a turbulent field is also discussed.\n    ",
        "submission_date": "2013-11-01T00:00:00",
        "last_modified_date": "2013-11-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1311.0162",
        "title": "Iterative Bilateral Filtering of Polarimetric SAR Data",
        "authors": [
            "Olivier D'Hondt",
            "St\u00e9phane Guillaso",
            "Olaf Hellwich"
        ],
        "abstract": "In this paper, we introduce an iterative speckle filtering method for polarimetric SAR (PolSAR) images based on the bilateral filter. To locally adapt to the spatial structure of images, this filter relies on pixel similarities in both spatial and radiometric domains. To deal with polarimetric data, we study the use of similarities based on a statistical distance called Kullback-Leibler divergence as well as two geodesic distances on Riemannian manifolds. To cope with speckle, we propose to progressively refine the result thanks to an iterative scheme. Experiments are run over synthetic and experimental data. First, simulations are generated to study the effects of filtering parameters in terms of polarimetric reconstruction error, edge preservation and smoothing of homogeneous areas. Comparison with other methods shows that our approach compares well to other state of the art methods in the extraction of polarimetric information and shows superior performance for edge restoration and noise smoothing. The filter is then applied to experimental data sets from ESAR and FSAR sensors (DLR) at L-band and S-band, respectively. These last experiments show the ability of the filter to restore structures such as buildings and roads and to preserve boundaries between regions while achieving a high amount of smoothing in homogeneous areas.\n    ",
        "submission_date": "2013-11-01T00:00:00",
        "last_modified_date": "2013-11-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1311.0262",
        "title": "Tracking Deformable Parts via Dynamic Conditional Random Fields",
        "authors": [
            "Suofei Zhang",
            "Zhixin Sun",
            "Xu Cheng",
            "Zhenyang Wu"
        ],
        "abstract": "Despite the success of many advanced tracking methods in this area, tracking targets with drastic variation of appearance such as deformation, view change and partial occlusion in video sequences is still a challenge in practical applications. In this letter, we take these serious tracking problems into account simultaneously, proposing a dynamic graph based model to track object and its deformable parts at multiple resolutions. The method introduces well learned structural object detection models into object tracking applications as prior knowledge to deal with deformation and view change. Meanwhile, it explicitly formulates partial occlusion by integrating spatial potentials and temporal potentials with an unparameterized occlusion handling mechanism in the dynamic conditional random field framework. Empirical results demonstrate that the method outperforms state-of-the-art trackers on different challenging video sequences.\n    ",
        "submission_date": "2013-10-30T00:00:00",
        "last_modified_date": "2013-10-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1311.0646",
        "title": "A Parallel Compressive Imaging Architecture for One-Shot Acquisition",
        "authors": [
            "Tomas Bj\u00f6rklund",
            "Enrico Magli"
        ],
        "abstract": "A limitation of many compressive imaging architectures lies in the sequential nature of the sensing process, which leads to long sensing times. In this paper we present a novel architecture that uses fewer detectors than the number of reconstructed pixels and is able to acquire the image in a single acquisition. This paves the way for the development of video architectures that acquire several frames per second. We specifically address the diffraction problem, showing that deconvolution normally used to recover diffraction blur can be replaced by convolution of the sensing matrix, and how measurements of a 0/1 physical sensing matrix can be converted to -1/1 compressive sensing matrix without any extra acquisitions. Simulations of our architecture show that the image quality is comparable to that of a classic Compressive Imaging camera, whereas the proposed architecture avoids long acquisition times due to sequential sensing. This one-shot procedure also allows to employ a fixed sensing matrix instead of a complex device such as a Digital Micro Mirror array or Spatial Light Modulator. It also enables imaging at bandwidths where these are not efficient.\n    ",
        "submission_date": "2013-11-04T00:00:00",
        "last_modified_date": "2013-11-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1311.1223",
        "title": "Quality Assessment of Pixel-Level ImageFusion Using Fuzzy Logic",
        "authors": [
            "Srinivasa Rao Dammavalam",
            "Seetha Maddala",
            "M.H.M. Krishna Prasad"
        ],
        "abstract": "Image fusion is to reduce uncertainty and minimize redundancy in the output while maximizing relevant information from two or more images of a scene into a single composite image that is more informative and is more suitable for visual perception or processing tasks like medical imaging, remote sensing, concealed weapon detection, weather forecasting, biometrics etc. Image fusion combines registered images to produce a high quality fused image with spatial and spectral information. The fused image with more information will improve the performance of image analysis algorithms used in different applications. In this paper, we proposed a fuzzy logic method to fuse images from different sensors, in order to enhance the quality and compared proposed method with two other methods i.e. image fusion using wavelet transform and weighted average discrete wavelet transform based image fusion using genetic algorithm (here onwards abbreviated as GA) along with quality evaluation parameters image quality index (IQI), mutual information measure (MIM), root mean square error (RMSE), peak signal to noise ratio (PSNR), fusion factor (FF), fusion symmetry (FS) and fusion index (FI) and entropy. The results obtained from proposed fuzzy based image fusion approach improves quality of fused image as compared to earlier reported methods, wavelet transform based image fusion and weighted average discrete wavelet transform based image fusion using genetic algorithm.\n    ",
        "submission_date": "2013-11-05T00:00:00",
        "last_modified_date": "2013-11-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1311.1279",
        "title": "Face Recognition via Globality-Locality Preserving Projections",
        "authors": [
            "Sheng Huang",
            "Dan Yang",
            "Fei Yang",
            "Yongxin Ge",
            "Xiaohong Zhang",
            "Jiwen Lu"
        ],
        "abstract": "We present an improved Locality Preserving Projections (LPP) method, named Gloablity-Locality Preserving Projections (GLPP), to preserve both the global and local geometric structures of data. In our approach, an additional constraint of the geometry of classes is imposed to the objective function of conventional LPP for respecting some more global manifold structures. Moreover, we formulate a two-dimensional extension of GLPP (2D-GLPP) as an example to show how to extend GLPP with some other statistical techniques. We apply our works to face recognition on four popular face databases, namely ORL, Yale, FERET and LFW-A databases, and extensive experimental results demonstrate that the considered global manifold information can significantly improve the performance of LPP and the proposed face recognition methods outperform the state-of-the-arts.\n    ",
        "submission_date": "2013-11-06T00:00:00",
        "last_modified_date": "2013-11-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1311.1406",
        "title": "TOP-SPIN: TOPic discovery via Sparse Principal component INterference",
        "authors": [
            "Martin Tak\u00e1\u010d",
            "Selin Damla Ahipa\u015fao\u011flu",
            "Ngai-Man Cheung",
            "Peter Richt\u00e1rik"
        ],
        "abstract": "We propose a novel topic discovery algorithm for unlabeled images based on the bag-of-words (BoW) framework. We first extract a dictionary of visual words and subsequently for each image compute a visual word occurrence histogram. We view these histograms as rows of a large matrix from which we extract sparse principal components (PCs). Each PC identifies a sparse combination of visual words which co-occur frequently in some images but seldom appear in others. Each sparse PC corresponds to a topic, and images whose interference with the PC is high belong to that topic, revealing the common parts possessed by the images. We propose to solve the associated sparse PCA problems using an Alternating Maximization (AM) method, which we modify for purpose of efficiently extracting multiple PCs in a deflation scheme. Our approach attacks the maximization problem in sparse PCA directly and is scalable to high-dimensional data. Experiments on automatic topic discovery and category prediction demonstrate encouraging performance of our approach.\n    ",
        "submission_date": "2013-11-04T00:00:00",
        "last_modified_date": "2013-11-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1311.1694",
        "title": "Biometric Signature Processing & Recognition Using Radial Basis Function Network",
        "authors": [
            "Ankit Chadha",
            "Neha Satam",
            "Vibha Wali"
        ],
        "abstract": "Automatic recognition of signature is a challenging problem which has received much attention during recent years due to its many applications in different fields. Signature has been used for long time for verification and authentication purpose. Earlier methods were manual but nowadays they are getting digitized. This paper provides an efficient method to signature recognition using Radial Basis Function Network. The network is trained with sample images in database. Feature extraction is performed before using them for training. For testing purpose, an image is made to undergo rotation-translation-scaling correction and then given to network. The network successfully identifies the original image and gives correct output for stored database images also. The method provides recognition rate of approximately 80% for 200 samples.\n    ",
        "submission_date": "2013-11-07T00:00:00",
        "last_modified_date": "2013-11-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1311.1838",
        "title": "Efficient Regularization of Squared Curvature",
        "authors": [
            "Claudia Nieuwenhuis",
            "Eno Toeppe",
            "Lena Gorelick",
            "Olga Veksler",
            "Yuri Boykov"
        ],
        "abstract": "Curvature has received increased attention as an important alternative to length based regularization in computer vision. In contrast to length, it preserves elongated structures and fine details. Existing approaches are either inefficient, or have low angular resolution and yield results with strong block artifacts. We derive a new model for computing squared curvature based on integral geometry. The model counts responses of straight line triple cliques. The corresponding energy decomposes into submodular and supermodular pairwise potentials. We show that this energy can be efficiently minimized even for high angular resolutions using the trust region framework. Our results confirm that we obtain accurate and visually pleasing solutions without strong artifacts at reasonable run times.\n    ",
        "submission_date": "2013-11-07T00:00:00",
        "last_modified_date": "2014-04-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1311.1856",
        "title": "Submodularization for Quadratic Pseudo-Boolean Optimization",
        "authors": [
            "Lena Gorelick",
            "Yuri Boykov",
            "Olga Veksler",
            "Ismail Ben Ayed",
            "Andrew Delong"
        ],
        "abstract": "Many computer vision problems require optimization of binary non-submodular energies. We propose a general optimization framework based on local submodular approximations (LSA). Unlike standard LP relaxation methods that linearize the whole energy globally, our approach iteratively approximates the energies locally. On the other hand, unlike standard local optimization methods (e.g. gradient descent or projection techniques) we use non-linear submodular approximations and optimize them without leaving the domain of integer solutions. We discuss two specific LSA algorithms based on \"trust region\" and \"auxiliary function\" principles, LSA-TR and LSA-AUX. These methods obtain state-of-the-art results on a wide range of applications outperforming many standard techniques such as LBP, QPBO, and TRWS. While our paper is focused on pairwise energies, our ideas extend to higher-order problems. The code is available online (",
        "submission_date": "2013-11-08T00:00:00",
        "last_modified_date": "2014-04-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1311.1939",
        "title": "Fast Tracking via Spatio-Temporal Context Learning",
        "authors": [
            "Kaihua Zhang",
            "Lei Zhang",
            "Ming-Hsuan Yang",
            "David Zhang"
        ],
        "abstract": "In this paper, we present a simple yet fast and robust algorithm which exploits the spatio-temporal context for visual tracking. Our approach formulates the spatio-temporal relationships between the object of interest and its local context based on a Bayesian framework, which models the statistical correlation between the low-level features (i.e., image intensity and position) from the target and its surrounding regions. The tracking problem is posed by computing a confidence map, and obtaining the best target location by maximizing an object location likelihood function. The Fast Fourier Transform is adopted for fast learning and detection in this work. Implemented in MATLAB without code optimization, the proposed tracker runs at 350 frames per second on an i7 machine. Extensive experimental results show that the proposed algorithm performs favorably against state-of-the-art methods in terms of efficiency, accuracy and robustness.\n    ",
        "submission_date": "2013-11-08T00:00:00",
        "last_modified_date": "2013-11-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1311.2014",
        "title": "A new stopping criterion for the mean shift iterative algorithm",
        "authors": [
            "Roberto Rodr\u00edguez",
            "Esley Torres",
            "Yasel Garc\u00e9s",
            "Osvaldo Pereira",
            "Humberto Sossa"
        ],
        "abstract": "The mean shift iterative algorithm was proposed in 2006, for using the entropy as a stopping criterion. From then on, a theoretical base has been developed and a group of applications has been carried out using this algorithm. This paper proposes a new stopping criterion for the mean shift iterative algorithm, where stopping threshold via entropy is used now, but in another way. Many segmentation experiments were carried out by utilizing standard images and it was verified that a better segmentation was reached, and that the algorithm had better stability. An analysis on the convergence, through a theorem, with the new stopping criterion was carried out. The goal of this paper is to compare the new stopping criterion with the old criterion. For this reason, the obtained results were not compared with other segmentation approaches, since with the old stopping criterion were previously carried out.\n    ",
        "submission_date": "2013-11-08T00:00:00",
        "last_modified_date": "2013-11-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1311.2102",
        "title": "An Experimental Comparison of Trust Region and Level Sets",
        "authors": [
            "Lena Gorelick",
            "Ismail BenAyed",
            "Frank R. Schmidt",
            "Yuri Boykov"
        ],
        "abstract": "High-order (non-linear) functionals have become very popular in segmentation, stereo and other computer vision problems. Level sets is a well established general gradient descent framework, which is directly applicable to optimization of such functionals and widely used in practice. Recently, another general optimization approach based on trust region methodology was proposed for regional non-linear functionals. Our goal is a comprehensive experimental comparison of these two frameworks in regard to practical efficiency, robustness to parameters, and optimality. We experiment on a wide range of problems with non-linear constraints on segment volume, appearance and shape.\n    ",
        "submission_date": "2013-11-08T00:00:00",
        "last_modified_date": "2013-11-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1311.2191",
        "title": "Neighborhood filters and the decreasing rearrangement",
        "authors": [
            "Gonzalo Galiano",
            "Juli\u00e1n Velasco"
        ],
        "abstract": "Nonlocal filters are simple and powerful techniques for image denoising. In this paper, we give new insights into the analysis of one kind of them, the Neighborhood filter, by using a classical although not very common transformation: the decreasing rearrangement of a function (the image). Independently of the dimension of the image, we reformulate the Neighborhood filter and its iterative variants as an integral operator defined in a one-dimensional space. The simplicity of this formulation allows to perform a detailed analysis of its properties. Among others, we prove that the filter behaves asymptotically as a shock filter combined with a border diffusive term, responsible for the staircaising effect and the loss of contrast.\n    ",
        "submission_date": "2013-11-09T00:00:00",
        "last_modified_date": "2014-06-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1311.2492",
        "title": "Notes on Elementary Spectral Graph Theory. Applications to Graph Clustering Using Normalized Cuts",
        "authors": [
            "Jean Gallier"
        ],
        "abstract": "These are notes on the method of normalized graph cuts and its applications to graph clustering. I provide a fairly thorough treatment of this deeply original method due to Shi and Malik, including complete proofs. I include the necessary background on graphs and graph Laplacians. I then explain in detail how the eigenvectors of the graph Laplacian can be used to draw a graph. This is an attractive application of graph Laplacians. The main thrust of this paper is the method of normalized cuts. I give a detailed account for K = 2 clusters, and also for K > 2 clusters, based on the work of Yu and Shi. Three points that do not appear to have been clearly articulated before are elaborated:\n",
        "submission_date": "2013-11-11T00:00:00",
        "last_modified_date": "2013-11-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1311.2524",
        "title": "Rich feature hierarchies for accurate object detection and semantic segmentation",
        "authors": [
            "Ross Girshick",
            "Jeff Donahue",
            "Trevor Darrell",
            "Jitendra Malik"
        ],
        "abstract": "Object detection performance, as measured on the canonical PASCAL VOC dataset, has plateaued in the last few years. The best-performing methods are complex ensemble systems that typically combine multiple low-level image features with high-level context. In this paper, we propose a simple and scalable detection algorithm that improves mean average precision (mAP) by more than 30% relative to the previous best result on VOC 2012---achieving a mAP of 53.3%. Our approach combines two key insights: (1) one can apply high-capacity convolutional neural networks (CNNs) to bottom-up region proposals in order to localize and segment objects and (2) when labeled training data is scarce, supervised pre-training for an auxiliary task, followed by domain-specific fine-tuning, yields a significant performance boost. Since we combine region proposals with CNNs, we call our method R-CNN: Regions with CNN features. We also compare R-CNN to OverFeat, a recently proposed sliding-window detector based on a similar CNN architecture. We find that R-CNN outperforms OverFeat by a large margin on the 200-class ILSVRC2013 detection dataset. Source code for the complete system is available at ",
        "submission_date": "2013-11-11T00:00:00",
        "last_modified_date": "2014-10-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1311.2561",
        "title": "Performing edge detection by difference of Gaussians using q-Gaussian kernels",
        "authors": [
            "Lucas Assirati",
            "N\u00fabia R. da Silva",
            "Lilian Berton",
            "Alneu de A. Lopes",
            "Odemir M. Bruno"
        ],
        "abstract": "In image processing, edge detection is a valuable tool to perform the extraction of features from an image. This detection reduces the amount of information to be processed, since the redundant information (considered less relevant) can be unconsidered. The technique of edge detection consists of determining the points of a digital image whose intensity changes sharply. This changes are due to the discontinuities of the orientation on a surface for example. A well known method of edge detection is the Difference of Gaussians (DoG). The method consists of subtracting two Gaussians, where a kernel has a standard deviation smaller than the previous one. The convolution between the subtraction of kernels and the input image results in the edge detection of this image. This paper introduces a method of extracting edges using DoG with kernels based on the q-Gaussian probability distribution, derived from the q-statistic proposed by Constantino Tsallis. To demonstrate the method's potential, we compare the introduced method with the traditional DoG using Gaussians kernels. The results showed that the proposed method can extract edges with more accurate details.\n    ",
        "submission_date": "2013-11-11T00:00:00",
        "last_modified_date": "2013-11-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1311.2621",
        "title": "Determining Leishmania Infection Levels by Automatic Analysis of Microscopy Images",
        "authors": [
            "P. A Nogueira"
        ],
        "abstract": "Analysis of microscopy images is one important tool in many fields of biomedical research, as it allows the quantification of a multitude of parameters at the cellular level. However, manual counting of these images is both tiring and unreliable and ultimately very time-consuming for biomedical researchers. Not only does this slow down the overall research process, it also introduces counting errors due to a lack of objectivity and consistency inherent to the researchers own human nature.\n",
        "submission_date": "2013-11-11T00:00:00",
        "last_modified_date": "2013-11-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1311.2626",
        "title": "Second-order Shape Optimization for Geometric Inverse Problems in Vision",
        "authors": [
            "J. Balzer",
            "S. Soatto"
        ],
        "abstract": "We develop a method for optimization in shape spaces, i.e., sets of surfaces modulo re-parametrization. Unlike previously proposed gradient flows, we achieve superlinear convergence rates through a subtle approximation of the shape Hessian, which is generally hard to compute and suffers from a series of degeneracies. Our analysis highlights the role of mean curvature motion in comparison with first-order schemes: instead of surface area, our approach penalizes deformation, either by its Dirichlet energy or total variation. Latter regularizer sparks the development of an alternating direction method of multipliers on triangular meshes. Therein, a conjugate-gradients solver enables us to bypass formation of the Gaussian normal equations appearing in the course of the overall optimization. We combine all of the aforementioned ideas in a versatile geometric variation-regularized Levenberg-Marquardt-type method applicable to a variety of shape functionals, depending on intrinsic properties of the surface such as normal field and curvature as well as its embedding into space. Promising experimental results are reported.\n    ",
        "submission_date": "2013-11-11T00:00:00",
        "last_modified_date": "2014-04-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1311.2642",
        "title": "Volumetric Reconstruction Applied to Perceptual Studies of Size and Weight",
        "authors": [
            "J. Balzer",
            "M. Peters",
            "S. Soatto"
        ],
        "abstract": "We explore the application of volumetric reconstruction from structured-light sensors in cognitive neuroscience, specifically in the quantification of the size-weight illusion, whereby humans tend to systematically perceive smaller objects as heavier. We investigate the performance of two commercial structured-light scanning systems in comparison to one we developed specifically for this application. Our method has two main distinct features: First, it only samples a sparse series of viewpoints, unlike other systems such as the Kinect Fusion. Second, instead of building a distance field for the purpose of points-to-surface conversion directly, we pursue a first-order approach: the distance function is recovered from its gradient by a screened Poisson reconstruction, which is very resilient to noise and yet preserves high-frequency signal components. Our experiments show that the quality of metric reconstruction from structured light sensors is subject to systematic biases, and highlights the factors that influence it. Our main performance index rates estimates of volume (a proxy of size), for which we review a well-known formula applicable to incomplete meshes. Our code and data will be made publicly available upon completion of the anonymous review process.\n    ",
        "submission_date": "2013-11-11T00:00:00",
        "last_modified_date": "2013-11-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1311.2901",
        "title": "Visualizing and Understanding Convolutional Networks",
        "authors": [
            "Matthew D Zeiler",
            "Rob Fergus"
        ],
        "abstract": "Large Convolutional Network models have recently demonstrated impressive classification performance on the ImageNet benchmark. However there is no clear understanding of why they perform so well, or how they might be improved. In this paper we address both issues. We introduce a novel visualization technique that gives insight into the function of intermediate feature layers and the operation of the classifier. We also perform an ablation study to discover the performance contribution from different model layers. This enables us to find model architectures that outperform Krizhevsky \\etal on the ImageNet classification benchmark. We show our ImageNet model generalizes well to other datasets: when the softmax classifier is retrained, it convincingly beats the current state-of-the-art results on Caltech-101 and Caltech-256 datasets.\n    ",
        "submission_date": "2013-11-12T00:00:00",
        "last_modified_date": "2013-11-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1311.3076",
        "title": "An Efficient Method for Recognizing the Low Quality Fingerprint Verification by Means of Cross Correlation",
        "authors": [
            "V.Karthikeyan",
            "V.J.Vijayalakshmi"
        ],
        "abstract": " In this paper, we propose an efficient method to provide personal identification using fingerprint to get better accuracy even in noisy condition. The fingerprint matching based on the number of corresponding minutia pairings, has been in use for a long time, which is not very efficient for recognizing the low quality fingerprints. To overcome this problem, correlation technique is used. The correlation-based fingerprint verification system is capable of dealing with low quality images from which no minutiae can be extracted reliably and with fingerprints that suffer from non-uniform shape distortions, also in case of damaged and partial images. Orientation Field Methodology (OFM) has been used as a preprocessing module, and it converts the images into a field pattern based on the direction of the ridges, loops and bifurcations in the image of a fingerprint. The input image is then Cross Correlated (CC) with all the images in the cluster and the highest correlated image is taken as the output. The result gives a good recognition rate, as the proposed scheme uses Cross Correlation of Field Orientation (CCFO = OFM + CC) for fingerprint identification.\n    ",
        "submission_date": "2013-11-13T00:00:00",
        "last_modified_date": "2013-11-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1311.3269",
        "title": "On a non-local spectrogram for denoising one-dimensional signals",
        "authors": [
            "Gonzalo Galiano",
            "Juli\u00e1n Velasco"
        ],
        "abstract": "In previous works, we investigated the use of local filters based on partial differential equations (PDE) to denoise one-dimensional signals through the image processing of time-frequency representations, such as the spectrogram. In this image denoising algorithms, the particularity of the image was hardly taken into account. We turn, in this paper, to study the performance of non-local filters, like Neighborhood or Yaroslavsky filters, in the same problem. We show that, for certain iterative schemes involving the Neighborhood filter, the computational time is drastically reduced with respect to Yaroslavsky or nonlinear PDE based filters, while the outputs of the filtering processes are similar. This is heuristically justified by the connection between the (fast) Neighborhood filter applied to a spectrogram and the corresponding Nonlocal Means filter (accurate) applied to the Wigner-Ville distribution of the signal. This correspondence holds only for time-frequency representations of one-dimensional signals, not to usual images, and in this sense the particularity of the image is exploited. We compare though a series of experiments on synthetic and biomedical signals the performance of local and non-local filters.\n    ",
        "submission_date": "2013-11-13T00:00:00",
        "last_modified_date": "2013-11-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1311.3318",
        "title": "A Study of Actor and Action Semantic Retention in Video Supervoxel Segmentation",
        "authors": [
            "Chenliang Xu",
            "Richard F. Doell",
            "Stephen Jos\u00e9 Hanson",
            "Catherine Hanson",
            "Jason J. Corso"
        ],
        "abstract": "Existing methods in the semantic computer vision community seem unable to deal with the explosion and richness of modern, open-source and social video content. Although sophisticated methods such as object detection or bag-of-words models have been well studied, they typically operate on low level features and ultimately suffer from either scalability issues or a lack of semantic meaning. On the other hand, video supervoxel segmentation has recently been established and applied to large scale data processing, which potentially serves as an intermediate representation to high level video semantic extraction. The supervoxels are rich decompositions of the video content: they capture object shape and motion well. However, it is not yet known if the supervoxel segmentation retains the semantics of the underlying video content. In this paper, we conduct a systematic study of how well the actor and action semantics are retained in video supervoxel segmentation. Our study has human observers watching supervoxel segmentation videos and trying to discriminate both actor (human or animal) and action (one of eight everyday actions). We gather and analyze a large set of 640 human perceptions over 96 videos in 3 different supervoxel scales. Furthermore, we conduct machine recognition experiments on a feature defined on supervoxel segmentation, called supervoxel shape context, which is inspired by the higher order processes in human perception. Our ultimate findings suggest that a significant amount of semantics have been well retained in the video supervoxel segmentation and can be used for further video analysis.\n    ",
        "submission_date": "2013-11-13T00:00:00",
        "last_modified_date": "2013-11-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1311.3405",
        "title": "The STONE Transform: Multi-Resolution Image Enhancement and Real-Time Compressive Video",
        "authors": [
            "Tom Goldstein",
            "Lina Xu",
            "Kevin F. Kelly",
            "Richard Baraniuk"
        ],
        "abstract": "Compressed sensing enables the reconstruction of high-resolution signals from under-sampled data. While compressive methods simplify data acquisition, they require the solution of difficult recovery problems to make use of the resulting measurements. This article presents a new sensing framework that combines the advantages of both conventional and compressive sensing. Using the proposed \\stone transform, measurements can be reconstructed instantly at Nyquist rates at any power-of-two resolution. The same data can then be \"enhanced\" to higher resolutions using compressive methods that leverage sparsity to \"beat\" the Nyquist limit. The availability of a fast direct reconstruction enables compressive measurements to be processed on small embedded devices. We demonstrate this by constructing a real-time compressive video camera.\n    ",
        "submission_date": "2013-11-14T00:00:00",
        "last_modified_date": "2013-11-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1311.3618",
        "title": "Describing Textures in the Wild",
        "authors": [
            "Mircea Cimpoi",
            "Subhransu Maji",
            "Iasonas Kokkinos",
            "Sammy Mohamed",
            "Andrea Vedaldi"
        ],
        "abstract": "Patterns and textures are defining characteristics of many natural objects: a shirt can be striped, the wings of a butterfly can be veined, and the skin of an animal can be scaly. Aiming at supporting this analytical dimension in image understanding, we address the challenging problem of describing textures with semantic attributes. We identify a rich vocabulary of forty-seven texture terms and use them to describe a large dataset of patterns collected in the ",
        "submission_date": "2013-11-14T00:00:00",
        "last_modified_date": "2013-11-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1311.3715",
        "title": "Recognizing Image Style",
        "authors": [
            "Sergey Karayev",
            "Matthew Trentacoste",
            "Helen Han",
            "Aseem Agarwala",
            "Trevor Darrell",
            "Aaron Hertzmann",
            "Holger Winnemoeller"
        ],
        "abstract": "The style of an image plays a significant role in how it is viewed, but style has received little attention in computer vision research. We describe an approach to predicting style of images, and perform a thorough evaluation of different image features for these tasks. We find that features learned in a multi-layer network generally perform best -- even when trained with object class (not style) labels. Our large-scale learning methods results in the best published performance on an existing dataset of aesthetic ratings and photographic style annotations. We present two novel datasets: 80K Flickr photographs annotated with 20 curated style labels, and 85K paintings annotated with 25 style/genre labels. Our approach shows excellent classification performance on both datasets. We use the learned classifiers to extend traditional tag-based image search to consider stylistic constraints, and demonstrate cross-dataset understanding of style.\n    ",
        "submission_date": "2013-11-15T00:00:00",
        "last_modified_date": "2014-07-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1311.3808",
        "title": "Periodicity Extraction using Superposition of Distance Matching Function and One-dimensional Haar Wavelet Transform",
        "authors": [
            "V.Asha",
            "N.U.Bhajantri",
            "P.Nagabhushan"
        ],
        "abstract": "Periodicity of a texture is one of the important visual characteristics and is often used as a measure for textural discrimination at the structural level. Knowledge about periodicity of a texture is very essential in the field of texture synthesis and texture compression and also in the design of frieze and wall papers. In this paper, we propose a method of periodicity extraction from noisy images based on superposition of distance matching function (DMF) and wavelet decomposition without de-noising the test images. Overall DMFs are subjected to single-level Haar wavelet decomposition to obtain approximate and detailed coefficients. Extracted coefficients help in determination of periodicities in row and column directions. We illustrate the usefulness and the effectiveness of the proposed method in a texture synthesis application.\n    ",
        "submission_date": "2013-11-15T00:00:00",
        "last_modified_date": "2013-11-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1311.4029",
        "title": "Blind Deconvolution with Non-local Sparsity Reweighting",
        "authors": [
            "Dilip Krishnan",
            "Joan Bruna",
            "Rob Fergus"
        ],
        "abstract": "Blind deconvolution has made significant progress in the past decade. Most successful algorithms are classified either as Variational or Maximum a-Posteriori ($MAP$). In spite of the superior theoretical justification of variational techniques, carefully constructed $MAP$ algorithms have proven equally effective in practice. In this paper, we show that all successful $MAP$ and variational algorithms share a common framework, relying on the following key principles: sparsity promotion in the gradient domain, $l_2$ regularization for kernel estimation, and the use of convex (often quadratic) cost functions. Our observations lead to a unified understanding of the principles required for successful blind deconvolution. We incorporate these principles into a novel algorithm that improves significantly upon the state of the art.\n    ",
        "submission_date": "2013-11-16T00:00:00",
        "last_modified_date": "2014-06-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1311.4033",
        "title": "A Comparative Study of Histogram Equalization Based Image Enhancement Techniques for Brightness Preservation and Contrast Enhancement",
        "authors": [
            "Omprakash Patel",
            "Yogendra P. S. Maravi",
            "Sanjeev Sharma"
        ],
        "abstract": "Histogram Equalization is a contrast enhancement technique in the image processing which uses the histogram of image. However histogram equalization is not the best method for contrast enhancement because the mean brightness of the output image is significantly different from the input image. There are several extensions of histogram equalization has been proposed to overcome the brightness preservation challenge. Contrast enhancement using brightness preserving bi-histogram equalization (BBHE) and Dualistic sub image histogram equalization (DSIHE) which divides the image histogram into two parts based on the input mean and median respectively then equalizes each sub histogram independently. This paper provides review of different popular histogram equalization techniques and experimental study based on the absolute mean brightness error (AMBE), peak signal to noise ratio (PSNR), Structure similarity index (SSI) and Entropy.\n    ",
        "submission_date": "2013-11-16T00:00:00",
        "last_modified_date": "2013-11-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1311.4082",
        "title": "Can a biologically-plausible hierarchy effectively replace face detection, alignment, and recognition pipelines?",
        "authors": [
            "Qianli Liao",
            "Joel Z Leibo",
            "Youssef Mroueh",
            "Tomaso Poggio"
        ],
        "abstract": "The standard approach to unconstrained face recognition in natural photographs is via a detection, alignment, recognition pipeline. While that approach has achieved impressive results, there are several reasons to be dissatisfied with it, among them is its lack of biological plausibility. A recent theory of invariant recognition by feedforward hierarchical networks, like HMAX, other convolutional networks, or possibly the ventral stream, implies an alternative approach to unconstrained face recognition. This approach accomplishes detection and alignment implicitly by storing transformations of training images (called templates) rather than explicitly detecting and aligning faces at test time. Here we propose a particular locality-sensitive hashing based voting scheme which we call \"consensus of collisions\" and show that it can be used to approximate the full 3-layer hierarchy implied by the theory. The resulting end-to-end system for unconstrained face recognition operates on photographs of faces taken under natural conditions, e.g., Labeled Faces in the Wild (LFW), without aligning or cropping them, as is normally done. It achieves a drastic improvement in the state of the art on this end-to-end task, reaching the same level of performance as the best systems operating on aligned, closely cropped images (no outside training data). It also performs well on two newer datasets, similar to LFW, but more difficult: LFW-jittered (new here) and SUFR-W.\n    ",
        "submission_date": "2013-11-16T00:00:00",
        "last_modified_date": "2014-03-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1311.4158",
        "title": "Unsupervised Learning of Invariant Representations in Hierarchical Architectures",
        "authors": [
            "Fabio Anselmi",
            "Joel Z. Leibo",
            "Lorenzo Rosasco",
            "Jim Mutch",
            "Andrea Tacchetti",
            "Tomaso Poggio"
        ],
        "abstract": "The present phase of Machine Learning is characterized by supervised learning algorithms relying on large sets of labeled examples ($n \\to \\infty$). The next phase is likely to focus on algorithms capable of learning from very few labeled examples ($n \\to 1$), like humans seem able to do. We propose an approach to this problem and describe the underlying theory, based on the unsupervised, automatic learning of a ``good'' representation for supervised learning, characterized by small sample complexity ($n$). We consider the case of visual object recognition though the theory applies to other domains. The starting point is the conjecture, proved in specific cases, that image representations which are invariant to translations, scaling and other transformations can considerably reduce the sample complexity of learning. We prove that an invariant and unique (discriminative) signature can be computed for each image patch, $I$, in terms of empirical distributions of the dot-products between $I$ and a set of templates stored during unsupervised learning. A module performing filtering and pooling, like the simple and complex cells described by Hubel and Wiesel, can compute such estimates. Hierarchical architectures consisting of this basic Hubel-Wiesel moduli inherit its properties of invariance, stability, and discriminability while capturing the compositional organization of the visual world in terms of wholes and parts. The theory extends existing deep learning convolutional architectures for image and speech recognition. It also suggests that the main computational goal of the ventral stream of visual cortex is to provide a hierarchical representation of new objects/images which is invariant to transformations, stable, and discriminative for recognition---and that this representation may be continuously learned in an unsupervised way during development and visual experience.\n    ",
        "submission_date": "2013-11-17T00:00:00",
        "last_modified_date": "2014-03-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1311.4963",
        "title": "Comparative Study Of Image Edge Detection Algorithms",
        "authors": [
            "Shubham Saini",
            "Bhavesh Kasliwal",
            "Shraey Bhatia"
        ],
        "abstract": "Since edge detection is in the forefront of image processing for object detection, it is crucial to have a good understanding of edge detection algorithms. The reason for this is that edges form the outline of an object. An edge is the boundary between an object and the background, and indicates the boundary between overlapping objects. This means that if the edges in an image can be identified accurately, all of the objects can be located and basic properties such as area, perimeter, and shape can be measured. Since computer vision involves the identification and classification of objects in an image, edge detection is an essential tool. We tested two edge detectors that use different methods for detecting edges and compared their results under a variety of situations to determine which detector was preferable under different sets of conditions.\n    ",
        "submission_date": "2013-11-20T00:00:00",
        "last_modified_date": "2013-11-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1311.5590",
        "title": "Adaptive Learning of Region-based pLSA Model for Total Scene Annotation",
        "authors": [
            "Yuzhu Zhou",
            "Le Li",
            "Honggang Zhang"
        ],
        "abstract": "In this paper, we present a region-based pLSA model to accomplish the task of total scene annotation. To be more specific, we not only properly generate a list of tags for each image, but also localizing each region with its corresponding tag. We integrate advantages of different existing region-based works: employ efficient and powerful JSEG algorithm for segmentation so that each region can easily express meaningful object information; the introduction of pLSA model can help better capturing semantic information behind the low-level features. Moreover, we also propose an adaptive padding mechanism to automatically choose the optimal padding strategy for each region, which directly increases the overall system performance. Finally we conduct 3 experiments to verify our ideas on Corel database and demonstrate the effectiveness and accuracy of our system.\n    ",
        "submission_date": "2013-11-21T00:00:00",
        "last_modified_date": "2013-11-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1311.5591",
        "title": "PANDA: Pose Aligned Networks for Deep Attribute Modeling",
        "authors": [
            "Ning Zhang",
            "Manohar Paluri",
            "Marc'Aurelio Ranzato",
            "Trevor Darrell",
            "Lubomir Bourdev"
        ],
        "abstract": "We propose a method for inferring human attributes (such as gender, hair style, clothes style, expression, action) from images of people under large variation of viewpoint, pose, appearance, articulation and occlusion. Convolutional Neural Nets (CNN) have been shown to perform very well on large scale object recognition problems. In the context of attribute classification, however, the signal is often subtle and it may cover only a small part of the image, while the image is dominated by the effects of pose and viewpoint. Discounting for pose variation would require training on very large labeled datasets which are not presently available. Part-based models, such as poselets and DPM have been shown to perform well for this problem but they are limited by shallow low-level features. We propose a new method which combines part-based models and deep learning by training pose-normalized CNNs. We show substantial improvement vs. state-of-the-art methods on challenging attribute classification tasks in unconstrained settings. Experiments confirm that our method outperforms both the best part-based methods on this problem and conventional CNNs trained on the full bounding box of the person.\n    ",
        "submission_date": "2013-11-21T00:00:00",
        "last_modified_date": "2014-05-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1311.5595",
        "title": "On Nonrigid Shape Similarity and Correspondence",
        "authors": [
            "Alon Shtern",
            "Ron Kimmel"
        ],
        "abstract": "An important operation in geometry processing is finding the correspondences between pairs of shapes. The Gromov-Hausdorff distance, a measure of dissimilarity between metric spaces, has been found to be highly useful for nonrigid shape comparison. Here, we explore the applicability of related shape similarity measures to the problem of shape correspondence, adopting spectral type distances. We propose to evaluate the spectral kernel distance, the spectral embedding distance and the novel spectral quasi-conformal distance, comparing the manifolds from different viewpoints. By matching the shapes in the spectral domain, important attributes of surface structure are being aligned. For the purpose of testing our ideas, we introduce a fully automatic framework for finding intrinsic correspondence between two shapes. The proposed method achieves state-of-the-art results on the Princeton isometric shape matching protocol applied, as usual, to the TOSCA and SCAPE benchmarks.\n    ",
        "submission_date": "2013-11-18T00:00:00",
        "last_modified_date": "2013-11-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1311.5829",
        "title": "Neural Network Application on Foliage Plant Identification",
        "authors": [
            "Abdul Kadir",
            "Lukito Edi Nugroho",
            "Adhi Susanto",
            "Paulus Insap Santosa"
        ],
        "abstract": "Several researches in leaf identification did not include color information as features. The main reason is caused by a fact that they used green colored leaves as samples. However, for foliage plants, plants with colorful leaves, fancy patterns in their leaves, and interesting plants with unique shape, color and also texture could not be neglected. For example, Epipremnum pinnatum 'Aureum' and Epipremnum pinnatum 'Marble Queen' have similar patterns, same shape, but different colors. Combination of shape, color, texture features, and other attribute contained on the leaf is very useful in leaf identification. In this research, Polar Fourier Transform and three kinds of geometric features were used to represent shape features, color moments that consist of mean, standard deviation, skewness were used to represent color features, texture features are extracted from GLCMs, and vein features were added to improve performance of the identification system. The identification system uses Probabilistic Neural Network (PNN) as a classifier. The result shows that the system gives average accuracy of 93.0833% for 60 kinds of foliage plants.\n    ",
        "submission_date": "2013-11-20T00:00:00",
        "last_modified_date": "2013-11-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1311.5830",
        "title": "Dictionary-Learning-Based Reconstruction Method for Electron Tomography",
        "authors": [
            "Baodong Liu",
            "Hengyong Yu",
            "Scott S. Verbridge",
            "Lizhi Sun",
            "Ge Wang"
        ],
        "abstract": "Electron tomography usually suffers from so called missing wedge artifacts caused by limited tilt angle range. An equally sloped tomography (EST) acquisition scheme (which should be called the linogram sampling scheme) was recently applied to achieve 2.4-angstrom resolution. On the other hand, a compressive sensing-inspired reconstruction algorithm, known as adaptive dictionary based statistical iterative reconstruction (ADSIR), has been reported for x-ray computed tomography. In this paper, we evaluate the EST, ADSIR and an ordered-subset simultaneous algebraic reconstruction technique (OS-SART), and compare the ES and equally angled (EA) data acquisition modes. Our results show that OS-SART is comparable to EST, and the ADSIR outperforms EST and OS-SART. Furthermore, the equally sloped projection data acquisition mode has no advantage over the conventional equally angled mode in the context.\n    ",
        "submission_date": "2013-11-22T00:00:00",
        "last_modified_date": "2013-11-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1311.5947",
        "title": "Fast Training of Effective Multi-class Boosting Using Coordinate Descent Optimization",
        "authors": [
            "Guosheng Lin",
            "Chunhua Shen",
            "Anton van den Hengel",
            "David Suter"
        ],
        "abstract": "Wepresentanovelcolumngenerationbasedboostingmethod for multi-class classification. Our multi-class boosting is formulated in a single optimization problem as in Shen and Hao (2011). Different from most existing multi-class boosting methods, which use the same set of weak learners for all the classes, we train class specified weak learners (i.e., each class has a different set of weak learners). We show that using separate weak learner sets for each class leads to fast convergence, without introducing additional computational overhead in the training procedure. To further make the training more efficient and scalable, we also propose a fast co- ordinate descent method for solving the optimization problem at each boosting iteration. The proposed coordinate descent method is conceptually simple and easy to implement in that it is a closed-form solution for each coordinate update. Experimental results on a variety of datasets show that, compared to a range of existing multi-class boosting meth- ods, the proposed method has much faster convergence rate and better generalization performance in most cases. We also empirically show that the proposed fast coordinate descent algorithm needs less training time than the MultiBoost algorithm in Shen and Hao (2011).\n    ",
        "submission_date": "2013-11-23T00:00:00",
        "last_modified_date": "2013-11-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1311.6007",
        "title": "Dynamic Model of Facial Expression Recognition based on Eigen-face Approach",
        "authors": [
            "Nikunj Bajaj",
            "Aurobinda Routray",
            "S L Happy"
        ],
        "abstract": "Emotions are best way of communicating information; and sometimes it carry more information than words. Recently, there has been a huge interest in automatic recognition of human emotion because of its wide spread application in security, surveillance, marketing, advertisement, and human-computer interaction. To communicate with a computer in a natural way, it will be desirable to use more natural modes of human communication based on voice, gestures and facial expressions. In this paper, a holistic approach for facial expression recognition is proposed which captures the variation in facial features in temporal domain and classifies the sequence of images in different emotions. The proposed method uses Haar-like features to detect face in an image. The dimensionality of the eigenspace is reduced using Principal Component Analysis (PCA). By projecting the subsequent face images into principal eigen directions, the variation pattern of the obtained weight vector is modeled to classify it into different emotions. Owing to the variations of expressions for different people and its intensity, a person specific method for emotion recognition is followed. Using the gray scale images of the frontal face, the system is able to classify four basic emotions such as happiness, sadness, surprise, and anger.\n    ",
        "submission_date": "2013-11-23T00:00:00",
        "last_modified_date": "2013-11-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1311.6048",
        "title": "On the Design and Analysis of Multiple View Descriptors",
        "authors": [
            "Jingming Dong",
            "Jonathan Balzer",
            "Damek Davis",
            "Joshua Hernandez",
            "Stefano Soatto"
        ],
        "abstract": "We propose an extension of popular descriptors based on gradient orientation histograms (HOG, computed in a single image) to multiple views. It hinges on interpreting HOG as a conditional density in the space of sampled images, where the effects of nuisance factors such as viewpoint and illumination are marginalized. However, such marginalization is performed with respect to a very coarse approximation of the underlying distribution. Our extension leverages on the fact that multiple views of the same scene allow separating intrinsic from nuisance variability, and thus afford better marginalization of the latter. The result is a descriptor that has the same complexity of single-view HOG, and can be compared in the same manner, but exploits multiple views to better trade off insensitivity to nuisance variability with specificity to intrinsic variability. We also introduce a novel multi-view wide-baseline matching dataset, consisting of a mixture of real and synthetic objects with ground truthed camera motion and dense three-dimensional geometry.\n    ",
        "submission_date": "2013-11-23T00:00:00",
        "last_modified_date": "2013-11-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1311.6049",
        "title": "Skin Texture Recognition Using Neural Networks",
        "authors": [
            "Nidhal K. El Abbadi",
            "Nazar Dahir",
            "Zaid Abd Alkareem"
        ],
        "abstract": "Skin recognition is used in many applications ranging from algorithms for face detection, hand gesture analysis, and to objectionable image filtering. In this work a skin recognition system was developed and tested. While many skin segmentation algorithms relay on skin color, our work relies on both skin color and texture features (features derives from the GLCM) to give a better and more efficient recognition accuracy of skin textures. We used feed forward neural networks to classify input textures images to be skin or non skin textures. The system gave very encouraging results during the neural network generalization face.\n    ",
        "submission_date": "2013-11-23T00:00:00",
        "last_modified_date": "2013-11-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1311.6079",
        "title": "Local Similarities, Global Coding: An Algorithm for Feature Coding and its Applications",
        "authors": [
            "Amirreza Shaban",
            "Hamid R. Rabiee",
            "Mahyar Najibi"
        ],
        "abstract": "Data coding as a building block of several image processing algorithms has been received great attention recently. Indeed, the importance of the locality assumption in coding approaches is studied in numerous works and several methods are proposed based on this concept. We probe this assumption and claim that taking the similarity between a data point and a more global set of anchor points does not necessarily weaken the coding method as long as the underlying structure of the anchor points are taken into account. Based on this fact, we propose to capture this underlying structure by assuming a random walker over the anchor points. We show that our method is a fast approximate learning algorithm based on the diffusion map kernel. The experiments on various datasets show that making different state-of-the-art coding algorithms aware of this structure boosts them in different learning tasks.\n    ",
        "submission_date": "2013-11-24T00:00:00",
        "last_modified_date": "2014-03-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1311.6500",
        "title": "Stitched Panoramas from Toy Airborne Video Cameras",
        "authors": [
            "Camille Goudeseune"
        ],
        "abstract": "Effective panoramic photographs are taken from vantage points that are high. High vantage points have recently become easier to reach as the cost of quadrotor helicopters has dropped to nearly disposable levels. Although cameras carried by such aircraft weigh only a few grams, their low-quality video can be converted into panoramas of high quality and high resolution. Also, the small size of these aircraft vastly reduces the risks inherent to flight.\n    ",
        "submission_date": "2013-11-11T00:00:00",
        "last_modified_date": "2013-11-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1311.6510",
        "title": "Are all training examples equally valuable?",
        "authors": [
            "Agata Lapedriza",
            "Hamed Pirsiavash",
            "Zoya Bylinskii",
            "Antonio Torralba"
        ],
        "abstract": "When learning a new concept, not all training examples may prove equally useful for training: some may have higher or lower training value than others. The goal of this paper is to bring to the attention of the vision community the following considerations: (1) some examples are better than others for training detectors or classifiers, and (2) in the presence of better examples, some examples may negatively impact performance and removing them may be beneficial. In this paper, we propose an approach for measuring the training value of an example, and use it for ranking and greedily sorting examples. We test our methods on different vision tasks, models, datasets and classifiers. Our experiments show that the performance of current state-of-the-art detectors and classifiers can be improved when training on a subset, rather than the whole training set.\n    ",
        "submission_date": "2013-11-25T00:00:00",
        "last_modified_date": "2013-11-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1311.6740",
        "title": "Hilditchs Algorithm Based Tamil Character Recognition",
        "authors": [
            "V. Karthikeyan"
        ],
        "abstract": "Character identification plays a vital role in the contemporary world of Image processing. It can solve many composite problems and makes humans work easier. An instance is Handwritten Character detection. Handwritten recognition is not a novel expertise, but it has not gained community notice until Now. The eventual aim of designing Handwritten Character recognition structure with an accurateness rate of 100% is pretty illusionary. Tamil Handwritten Character recognition system uses the Neural Networks to distinguish them. Neural Network and structural characteristics are used to instruct and recognize written characters. After training and testing the exactness rate reached 99%. This correctness rate is extremely high. In this paper we are exploring image processing through the Hilditch algorithm foundation and structural characteristics of a character in the image. And we recognized some character of the Tamil language, and we are trying to identify all the character of Tamil In our future works.\n    ",
        "submission_date": "2013-11-19T00:00:00",
        "last_modified_date": "2013-11-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1311.6758",
        "title": "Detection of Partially Visible Objects",
        "authors": [
            "Patrick Ott",
            "Mark Everingham",
            "Jiri Matas"
        ],
        "abstract": "An \"elephant in the room\" for most current object detection and localization methods is the lack of explicit modelling of partial visibility due to occlusion by other objects or truncation by the image boundary. Based on a sliding window approach, we propose a detection method which explicitly models partial visibility by treating it as a latent variable. A novel non-maximum suppression scheme is proposed which takes into account the inferred partial visibility of objects while providing a globally optimal solution. The method gives more detailed scene interpretations than conventional detectors in that we are able to identify the visible parts of an object. We report improved average precision on the PASCAL VOC 2010 dataset compared to a baseline detector.\n    ",
        "submission_date": "2013-11-24T00:00:00",
        "last_modified_date": "2013-11-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1311.6799",
        "title": "Wavelet and Fast Fourier Transform based analysis of Solar Image",
        "authors": [
            "Sabyasachi Mukhopadhyay",
            "Debadatta Dash",
            "Swapnil Barmase",
            "Prasanta K Panigrahi"
        ],
        "abstract": "Both of Wavelet and Fast Fourier Transform are strong signal processing tools in the field of Data Analysis. In this paper fast fourier transform (FFT) and Wavelet Transform are employed to observe some important features of Solar image (December, 2004). We have tried to find out the periodicity and coherence of different sections of the solar image. We plotted the distribution of energy in solar surface by analyzing the solar image with scalograms and 3D-coefficient plots.\n    ",
        "submission_date": "2013-10-30T00:00:00",
        "last_modified_date": "2013-12-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1311.6881",
        "title": "Color and Shape Content Based Image Classification using RBF Network and PSO Technique: A Survey",
        "authors": [
            "Abhishek Pandey",
            "Anjna Jayant Deen",
            "Rajeev Pandey"
        ],
        "abstract": "The improvement of the accuracy of image query retrieval used image classification technique. Image classification is well known technique of supervised learning. The improved method of image classification increases the working efficiency of image query retrieval. For the improvements of classification technique we used RBF neural network function for better prediction of feature used in image ",
        "submission_date": "2013-11-27T00:00:00",
        "last_modified_date": "2013-11-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1311.6887",
        "title": "Modeling Radiometric Uncertainty for Vision with Tone-mapped Color Images",
        "authors": [
            "Ayan Chakrabarti",
            "Ying Xiong",
            "Baochen Sun",
            "Trevor Darrell",
            "Daniel Scharstein",
            "Todd Zickler",
            "Kate Saenko"
        ],
        "abstract": "To produce images that are suitable for display, tone-mapping is widely used in digital cameras to map linear color measurements into narrow gamuts with limited dynamic range. This introduces non-linear distortion that must be undone, through a radiometric calibration process, before computer vision systems can analyze such photographs radiometrically. This paper considers the inherent uncertainty of undoing the effects of tone-mapping. We observe that this uncertainty varies substantially across color space, making some pixels more reliable than others. We introduce a model for this uncertainty and a method for fitting it to a given camera or imaging pipeline. Once fit, the model provides for each pixel in a tone-mapped digital photograph a probability distribution over linear scene colors that could have induced it. We demonstrate how these distributions can be useful for visual inference by incorporating them into estimation algorithms for a representative set of vision tasks.\n    ",
        "submission_date": "2013-11-27T00:00:00",
        "last_modified_date": "2014-04-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1311.6932",
        "title": "A novel framework for image forgery localization",
        "authors": [
            "Davide Cozzolino",
            "Diego Gragnaniello",
            "Luisa Verdoliva"
        ],
        "abstract": "Image forgery localization is a very active and open research field for the difficulty to handle the large variety of manipulations a malicious user can perform by means of more and more sophisticated image editing tools. Here, we propose a localization framework based on the fusion of three very different tools, based, respectively, on sensor noise, patch-matching, and machine learning. The binary masks provided by these tools are finally fused based on some suitable reliability indexes. According to preliminary experiments on the training set, the proposed framework provides often a very good localization accuracy and sometimes valuable clues for visual scrutiny.\n    ",
        "submission_date": "2013-11-27T00:00:00",
        "last_modified_date": "2013-11-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1311.6934",
        "title": "Image forgery detection based on the fusion of machine learning and block-matching methods",
        "authors": [
            "Davide Cozzolino",
            "Diego Gragnaniello",
            "Luisa Verdoliva"
        ],
        "abstract": "Dense local descriptors and machine learning have been used with success in several applications, like classification of textures, steganalysis, and forgery detection. We develop a new image forgery detector building upon some descriptors recently proposed in the steganalysis field suitably merging some of such descriptors, and optimizing a SVM classifier on the available training set. Despite the very good performance, very small forgeries are hardly ever detected because they contribute very little to the descriptors. Therefore we also develop a simple, but extremely specific, copy-move detector based on region matching and fuse decisions so as to reduce the missing detection rate. Overall results appear to be extremely encouraging.\n    ",
        "submission_date": "2013-11-27T00:00:00",
        "last_modified_date": "2013-11-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1311.7080",
        "title": "Cross-Domain Sparse Coding",
        "authors": [
            "Jim Jing-Yan Wang"
        ],
        "abstract": "Sparse coding has shown its power as an effective data representation method. However, up to now, all the sparse coding approaches are limited within the single domain learning problem. In this paper, we extend the sparse coding to cross domain learning problem, which tries to learn from a source domain to a target domain with significant different distribution. We impose the Maximum Mean Discrepancy (MMD) criterion to reduce the cross-domain distribution difference of sparse codes, and also regularize the sparse codes by the class labels of the samples from both domains to increase the discriminative ability. The encouraging experiment results of the proposed cross-domain sparse coding algorithm on two challenging tasks --- image classification of photograph and oil painting domains, and multiple user spam detection --- show the advantage of the proposed method over other cross-domain data representation methods.\n    ",
        "submission_date": "2013-11-27T00:00:00",
        "last_modified_date": "2013-11-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1311.7186",
        "title": "A Novel Illumination-Invariant Loss for Monocular 3D Pose Estimation",
        "authors": [
            "Srimal Jayawardena",
            "Marcus Hutter",
            "Nathan Brewer"
        ],
        "abstract": "The problem of identifying the 3D pose of a known object from a given 2D image has important applications in Computer Vision. Our proposed method of registering a 3D model of a known object on a given 2D photo of the object has numerous advantages over existing methods. It does not require prior training, knowledge of the camera parameters, explicit point correspondences or matching features between the image and model. Unlike techniques that estimate a partial 3D pose (as in an overhead view of traffic or machine parts on a conveyor belt), our method estimates the complete 3D pose of the object. It works on a single static image from a given view under varying and unknown lighting conditions. For this purpose we derive a novel illumination-invariant distance measure between the 2D photo and projected 3D model, which is then minimised to find the best pose parameters. Results for vehicle pose detection in real photographs are presented.\n    ",
        "submission_date": "2013-11-28T00:00:00",
        "last_modified_date": "2013-11-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1311.7251",
        "title": "Spatially-Adaptive Reconstruction in Computed Tomography using Neural Networks",
        "authors": [
            "Joseph Shtok",
            "Michael Zibulevsky",
            "Michael Elad"
        ],
        "abstract": "We propose a supervised machine learning approach for boosting existing signal and image recovery methods and demonstrate its efficacy on example of image reconstruction in computed tomography. Our technique is based on a local nonlinear fusion of several image estimates, all obtained by applying a chosen reconstruction algorithm with different values of its control parameters. Usually such output images have different bias/variance trade-off. The fusion of the images is performed by feed-forward neural network trained on a set of known examples. Numerical experiments show an improvement in reconstruction quality relatively to existing direct and iterative reconstruction methods.\n    ",
        "submission_date": "2013-11-28T00:00:00",
        "last_modified_date": "2013-11-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1311.7327",
        "title": "Unobtrusive Low Cost Pupil Size Measurements using Web cameras",
        "authors": [
            "Sergios Petridis",
            "Theodoros Giannakopoulos",
            "Costantine D. Spyropoulos"
        ],
        "abstract": "Unobtrusive every day health monitoring can be of important use for the elderly population. In particular, pupil size may be a valuable source of information, since, apart from pathological cases, it can reveal the emotional state, the fatigue and the ageing. To allow for unobtrusive monitoring to gain acceptance, one should seek for efficient methods of monitoring using com- mon low-cost hardware. This paper describes a method for monitoring pupil sizes using a common web camera in real time. Our method works by first detecting the face and the eyes area. Subsequently, optimal iris and sclera location and radius, modelled as ellipses, are found using efficient filtering. Finally, the pupil center and radius is estimated by optimal filtering within the area of the iris. Experimental result show both the efficiency and the effectiveness of our approach.\n    ",
        "submission_date": "2013-11-28T00:00:00",
        "last_modified_date": "2013-11-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.0072",
        "title": "Improving Texture Categorization with Biologically Inspired Filtering",
        "authors": [
            "Ngoc-Son Vu",
            "Thanh Phuong Nguyen",
            "Christophe Garcia"
        ],
        "abstract": "Within the domain of texture classification, a lot of effort has been spent on local descriptors, leading to many powerful algorithms. However, preprocessing techniques have received much less attention despite their important potential for improving the overall classification performance. We address this question by proposing a novel, simple, yet very powerful biologically-inspired filtering (BF) which simulates the performance of human retina. In the proposed approach, given a texture image, after applying a DoG filter to detect the \"edges\", we first split the filtered image into two \"maps\" alongside the sides of its edges. The feature extraction step is then carried out on the two \"maps\" instead of the input image. Our algorithm has several advantages such as simplicity, robustness to illumination and noise, and discriminative power. Experimental results on three large texture databases show that with an extremely low computational cost, the proposed method improves significantly the performance of many texture classification systems, notably in noisy environments. The source codes of the proposed algorithm can be downloaded from ",
        "submission_date": "2013-11-30T00:00:00",
        "last_modified_date": "2013-11-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.0760",
        "title": "Template-Based Active Contours",
        "authors": [
            "Jayanth Krishna Mogali",
            "Adithya Kumar Pediredla",
            "Chandra Sekhar Seelamantula"
        ],
        "abstract": "We develop a generalized active contour formalism for image segmentation based on shape templates. The shape template is subjected to a restricted affine transformation (RAT) in order to segment the object of interest. RAT allows for translation, rotation, and scaling, which give a total of five degrees of freedom. The proposed active contour comprises an inner and outer contour pair, which are closed and concentric. The active contour energy is a contrast function defined based on the intensities of pixels that lie inside the inner contour and those that lie in the annulus between the inner and outer contours. We show that the contrast energy functional is optimal under certain conditions. The optimal RAT parameters are computed by maximizing the contrast function using a gradient descent optimizer. We show that the calculations are made efficient through use of Green's theorem. The proposed formalism is capable of handling a variety of shapes because for a chosen template, optimization is carried with respect to the RAT parameters only. The proposed formalism is validated on multiple images to show robustness to Gaussian and Poisson noise, to initialization, and to partial loss of structure in the object to be segmented.\n    ",
        "submission_date": "2013-12-03T00:00:00",
        "last_modified_date": "2013-12-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.0788",
        "title": "A compact formula for the derivative of a 3-D rotation in exponential coordinates",
        "authors": [
            "Guillermo Gallego",
            "Anthony Yezzi"
        ],
        "abstract": "We present a compact formula for the derivative of a 3-D rotation matrix with respect to its exponential coordinates. A geometric interpretation of the resulting expression is provided, as well as its agreement with other less-compact but better-known formulas. To the best of our knowledge, this simpler formula does not appear anywhere in the literature. We hope by providing this more compact expression to alleviate the common pressure to reluctantly resort to alternative representations in various computational applications simply as a means to avoid the complexity of differential analysis in exponential coordinates.\n    ",
        "submission_date": "2013-12-03T00:00:00",
        "last_modified_date": "2014-08-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.0852",
        "title": "Feature Extraction of Human Lip Prints",
        "authors": [
            "Samir Kumar Bandyopadhyay",
            "S Arunkumar",
            "Saptarshi Bhattacharjee"
        ],
        "abstract": "Methods have been used for identification of human by recognizing lip prints. Human lips have a number of elevation and depressions features called lip prints and examination of lip prints is referred to as cheiloscopy. Lip prints of each human being are unique in nature like many others features of human. In this paper lip print is first smoothened using a Gaussian Filter. Next Sobel Edge Detector and Canny Edge Detector are used to detect the vertical and horizontal groove pattern in the lip. This method of identification will be useful both in criminal forensics and personal identification. It is our assumption that study of lip prints and their types are well connected to play a song in a better way that are well accepted to people who loves to hear songs.\n    ",
        "submission_date": "2013-12-03T00:00:00",
        "last_modified_date": "2013-12-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.1461",
        "title": "Multi-Sensor Image Fusion Based on Moment Calculation",
        "authors": [
            "Sourav Pramanik",
            "Debotosh Bhattacharjee"
        ],
        "abstract": "An image fusion method based on salient features is proposed in this paper. In this work, we have concentrated on salient features of the image for fusion in order to preserve all relevant information contained in the input images and tried to enhance the contrast in fused image and also suppressed noise to a maximum extent. In our system, first we have applied a mask on two input images in order to conserve the high frequency information along with some low frequency information and stifle noise to a maximum extent. Thereafter, for identification of salience features from sources images, a local moment is computed in the neighborhood of a coefficient. Finally, a decision map is generated based on local moment in order to get the fused image. To verify our proposed algorithm, we have tested it on 120 sensor image pairs collected from Manchester University UK database. The experimental results show that the proposed method can provide superior fused image in terms of several quantitative fusion evaluation index.\n    ",
        "submission_date": "2013-12-05T00:00:00",
        "last_modified_date": "2013-12-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.1462",
        "title": "Geometric Feature Based Face-Sketch Recognition",
        "authors": [
            "Sourav Pramanik",
            "Debotosh Bhattacharjee"
        ],
        "abstract": "This paper presents a novel facial sketch image or face-sketch recognition approach based on facial feature extraction. To recognize a face-sketch, we have concentrated on a set of geometric face features like eyes, nose, eyebrows, lips, etc and their length and width ratio because it is difficult to match photos and sketches because they belong to two different modalities. In this system, first the facial features/components from training images are extracted, then ratios of length, width, and area etc. are calculated and those are stored as feature vectors for individual images. After that the mean feature vectors are computed and subtracted from each feature vector for centering of the feature vectors. In the next phase, feature vector for the incoming probe face-sketch is also computed in similar fashion. Here, K-NN classifier is used to recognize probe face-sketch. It is experimentally verified that the proposed method is robust against faces are in a frontal pose, with normal lighting and neutral expression and have no occlusions. The experiment has been conducted with 80 male and female face images from different face databases. It has useful applications for both law enforcement and digital entertainment.\n    ",
        "submission_date": "2013-12-05T00:00:00",
        "last_modified_date": "2013-12-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.1512",
        "title": "An adaptive block based integrated LDP,GLCM,and Morphological features for Face Recognition",
        "authors": [
            "Arindam Kar",
            "Debotosh Bhattacharjee",
            "Dipak Kumar Basu",
            "Mita Nasipuri",
            "Mahantapas Kundu"
        ],
        "abstract": "This paper proposes a technique for automatic face recognition using integrated multiple feature sets extracted from the significant blocks of a gradient image. We discuss about the use of novel morphological, local directional pattern (LDP) and gray-level co-occurrence matrix GLCM based feature extraction technique to recognize human faces. Firstly, the new morphological features i.e., features based on number of runs of pixels in four directions (N,NE,E,NW) are extracted, together with the GLCM based statistical features and LDP features that are less sensitive to the noise and non-monotonic illumination changes, are extracted from the significant blocks of the gradient image. Then these features are concatenated together. We integrate the above mentioned methods to take full advantage of the three approaches. Extraction of the significant blocks from the absolute gradient image and hence from the original image to extract pertinent information with the idea of dimension reduction forms the basis of the work. The efficiency of our method is demonstrated by the experiment on 1100 images from the FRAV2D face database, 2200 images from the FERET database, where the images vary in pose, expression, illumination and scale and 400 images from the ORL face database, where the images slightly vary in pose. Our method has shown 90.3%, 93% and 98.75% recognition accuracy for the FRAV2D, FERET and the ORL database respectively.\n    ",
        "submission_date": "2013-12-05T00:00:00",
        "last_modified_date": "2013-12-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.1517",
        "title": "A Gabor block based Kernel Discriminative Common Vector (KDCV) approach using cosine kernels for Human Face Recognition",
        "authors": [
            "Arindam Kar",
            "Debotosh Bhattacharjee",
            "Dipak Kumar Basu",
            "Mita Nasipuri",
            "Mahantapas Kundu"
        ],
        "abstract": "In this paper a nonlinear Gabor Wavelet Transform (GWT) discriminant feature extraction approach for enhanced face recognition is proposed. Firstly, the low-energized blocks from Gabor wavelet transformed images are extracted. Secondly, the nonlinear discriminating features are analyzed and extracted from the selected low-energized blocks by the generalized Kernel Discriminative Common Vector (KDCV) method. The KDCV method is extended to include cosine kernel function in the discriminating method. The KDCV with the cosine kernels is then applied on the extracted low energized discriminating feature vectors to obtain the real component of a complex quantity for face recognition. In order to derive positive kernel discriminative vectors; we apply only those kernel discriminative eigenvectors that are associated with non-zero eigenvalues. The feasibility of the low energized Gabor block based generalized KDCV method with cosine kernel function models has been successfully tested for image classification using the L1, L2 distance measures; and the cosine similarity measure on both frontal and pose-angled face recognition. Experimental results on the FRAV2D and the FERET database demonstrate the effectiveness of this new approach.\n    ",
        "submission_date": "2013-12-05T00:00:00",
        "last_modified_date": "2013-12-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.1520",
        "title": "A Face Recognition approach based on entropy estimate of the nonlinear DCT features in the Logarithm Domain together with Kernel Entropy Component Analysis",
        "authors": [
            "Arindam Kar",
            "Debotosh Bhattacharjee",
            "Dipak Kumar Basu",
            "Mita Nasipuri",
            "Mahantapas Kundu"
        ],
        "abstract": "This paper exploits the feature extraction capabilities of the discrete cosine transform (DCT) together with an illumination normalization approach in the logarithm domain that increase its robustness to variations in facial geometry and illumination. Secondly in the same domain the entropy measures are applied on the DCT coefficients so that maximum entropy preserving pixels can be extracted as the feature vector. Thus the informative features of a face can be extracted in a low dimensional space. Finally, the kernel entropy component analysis (KECA) with an extension of arc cosine kernels is applied on the extracted DCT coefficients that contribute most to the entropy estimate to obtain only those real kernel ECA eigenvectors that are associated with eigenvalues having high positive entropy contribution. The resulting system was successfully tested on real image sequences and is robust to significant partial occlusion and illumination changes, validated with the experiments on the FERET, AR, FRAV2D and ORL face databases. Experimental comparison is demonstrated to prove the superiority of the proposed approach in respect to recognition accuracy. Using specificity and sensitivity we find that the best is achieved when Renyi entropy is applied on the DCT coefficients. Extensive experimental comparison is demonstrated to prove the superiority of the proposed approach in respect to recognition accuracy. Moreover, the proposed approach is very simple, computationally fast and can be implemented in any real-time face recognition system.\n    ",
        "submission_date": "2013-12-05T00:00:00",
        "last_modified_date": "2013-12-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.1681",
        "title": "An Approach: Modality Reduction and Face-Sketch Recognition",
        "authors": [
            "Sourav Pramanik",
            "Dr. Debotosh Bhattacharjee"
        ],
        "abstract": "To recognize face sketch through face photo database is a challenging task for todays researchers. Because face photo images in training set and face sketch images in testing set have different modality. Difference between two face photos of difference person is smaller than the difference between same person in a face photo and face sketched. In this paper, for reduction of the modality between face photo and face sketch we first bring face photo and face sketch images in a new dimension using 2D Discrete Haar wavelet transform with scale 3 followed by a negative approach. After that, extract features from transformed images using Principal Component Analysis (PCA). Thereafter, we use SVM classifier and K-NN classifier for better classification. Our proposed method is experimentally verified by its robustness against faces that are captured in a good lighting condition and in a frontal pose. The experiment has been conducted with 100 male and female face images as training set and 100 male and female face sketch images as testing set collected from CUHK training and testing cropped photos and CUHK training and testing cropped sketches.\n    ",
        "submission_date": "2013-12-05T00:00:00",
        "last_modified_date": "2013-12-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.1683",
        "title": "Face Recognition using Hough Peaks extracted from the significant blocks of the Gradient Image",
        "authors": [
            "Arindam Kar",
            "Debotosh Bhattacharjee",
            "Dipak Kumar Basu",
            "Mita Nasipuri",
            "Mahantapas Kundu"
        ],
        "abstract": "This paper proposes a new technique for automatic face recognition using integrated peaks of the Hough transformed significant blocks of the binary gradient image. In this approach firstly the gradient of an image is calculated and a threshold is set to obtain a binary gradient image, which is less sensitive to noise and illumination changes. Secondly, significant blocks are extracted from the absolute gradient image, to extract pertinent information with the idea of dimension reduction. Finally the best fitted Hough peaks are extracted from the Hough transformed significant blocks for efficient face recognition. Then these Hough peaks are concatenated together, which are used as feature in classification process. The efficiency of the proposed method is demonstrated by the experiment on 1100 images from the FRAV2D face database, 2200 images from the FERET database, where the images vary in pose, expression, illumination and scale and 400 images from the ORL face database, where the images slightly vary in pose. Our method has shown 93.3%, 88.5% and 99% recognition accuracy for the FRAV2D, FERET and the ORL database respectively.\n    ",
        "submission_date": "2013-12-05T00:00:00",
        "last_modified_date": "2013-12-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.1684",
        "title": "High Performance Human Face Recognition using Gabor based Pseudo Hidden Markov Model",
        "authors": [
            "Arindam Kar",
            "Debotosh Bhattacharjee",
            "Dipak Kumar Basu",
            "Mita Nasipuri",
            "Mahantapas Kundu"
        ],
        "abstract": "This paper introduces a novel methodology that combines the multi-resolution feature of the Gabor wavelet transformation (GWT) with the local interactions of the facial structures expressed through the Pseudo Hidden Markov model (PHMM). Unlike the traditional zigzag scanning method for feature extraction a continuous scanning method from top-left corner to right then top-down and right to left and so on until right-bottom of the image i.e. a spiral scanning technique has been proposed for better feature selection. Unlike traditional HMMs, the proposed PHMM does not perform the state conditional independence of the visible observation sequence assumption. This is achieved via the concept of local structures introduced by the PHMM used to extract facial bands and automatically select the most informative features of a face image. Thus, the long-range dependency problem inherent to traditional HMMs has been drastically reduced. Again with the use of most informative pixels rather than the whole image makes the proposed method reasonably faster for face recognition. This method has been successfully tested on frontal face images from the ORL, FRAV2D and FERET face databases where the images vary in pose, illumination, expression, and scale. The FERET data set contains 2200 frontal face images of 200 subjects, while the FRAV2D data set consists of 1100 images of 100 subjects and the full ORL database is considered. The results reported in this application are far better than the recent and most referred systems.\n    ",
        "submission_date": "2013-12-05T00:00:00",
        "last_modified_date": "2013-12-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.1685",
        "title": "Human Face Recognition using Gabor based Kernel Entropy Component Analysis",
        "authors": [
            "Arindam Kar",
            "Debotosh Bhattacharjee",
            "Dipak Kumar Basu",
            "Mita Nasipuri",
            "Mahantapas Kundu"
        ],
        "abstract": "In this paper, we present a novel Gabor wavelet based Kernel Entropy Component Analysis (KECA) method by integrating the Gabor wavelet transformation (GWT) of facial images with the KECA method for enhanced face recognition performance. Firstly, from the Gabor wavelet transformed images the most important discriminative desirable facial features characterized by spatial frequency, spatial locality and orientation selectivity to cope with the variations due to illumination and facial expression changes were derived. After that KECA, relating to the Renyi entropy is extended to include cosine kernel function. The KECA with the cosine kernels is then applied on the extracted most important discriminating feature vectors of facial images to obtain only those real kernel ECA eigenvectors that are associated with eigenvalues having positive entropy contribution. Finally, these real KECA features are used for image classification using the L1, L2 distance measures; the Mahalanobis distance measure and the cosine similarity measure. The feasibility of the Gabor based KECA method with the cosine kernel has been successfully tested on both frontal and pose-angled face recognition, using datasets from the ORL, FRAV2D and the FERET database.\n    ",
        "submission_date": "2013-12-05T00:00:00",
        "last_modified_date": "2013-12-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.1931",
        "title": "Multi-frame denoising of high speed optical coherence tomography data using inter-frame and intra-frame priors",
        "authors": [
            "Liheng Bian",
            "Jinli Suo",
            "Feng Chen",
            "Qionghai Dai"
        ],
        "abstract": "Optical coherence tomography (OCT) is an important interferometric diagnostic technique which provides cross-sectional views of the subsurface microstructure of biological tissues. However, the imaging quality of high-speed OCT is limited due to the large speckle noise. To address this problem, this paper proposes a multi-frame algorithmic method to denoise OCT volume. Mathematically, we build an optimization model which forces the temporally registered frames to be low rank, and the gradient in each frame to be sparse, under logarithmic image formation and noise variance constraints. Besides, a convex optimization algorithm based on the augmented Lagrangian method is derived to solve the above model. The results reveal that our approach outperforms the other methods in terms of both speckle noise suppression and crucial detail preservation.\n    ",
        "submission_date": "2013-12-06T00:00:00",
        "last_modified_date": "2014-11-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.2061",
        "title": "Region and Location Based Indexing and Retrieval of MR-T2 Brain Tumor Images",
        "authors": [
            "Krishna A N",
            "B G Prasad"
        ],
        "abstract": "In this paper, region based and location based retrieval systems have been implemented for retrieval of MR-T2 axial 2-D brain images. This is done by extracting and characterizing the tumor portion of 2-D brain slices by use of a suitable threshold computed over the entire image. Indexing and retrieval is then performed by computing texture features based on gray-tone spatial-dependence matrix of segmented regions. A Hash structure is used to index all images. A combined index is adopted to point to all similar images in terms of the texture features. At query time, only those images that are in the same hash bucket as those of the queried image are compared for similarity, thus reducing the search space and time.\n    ",
        "submission_date": "2013-12-07T00:00:00",
        "last_modified_date": "2013-12-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.2249",
        "title": "Scalable Object Detection using Deep Neural Networks",
        "authors": [
            "Dumitru Erhan",
            "Christian Szegedy",
            "Alexander Toshev",
            "Dragomir Anguelov"
        ],
        "abstract": "Deep convolutional neural networks have recently achieved state-of-the-art performance on a number of image recognition benchmarks, including the ImageNet Large-Scale Visual Recognition Challenge (ILSVRC-2012). The winning model on the localization sub-task was a network that predicts a single bounding box and a confidence score for each object category in the image. Such a model captures the whole-image context around the objects but cannot handle multiple instances of the same object in the image without naively replicating the number of outputs for each instance. In this work, we propose a saliency-inspired neural network model for detection, which predicts a set of class-agnostic bounding boxes along with a single score for each box, corresponding to its likelihood of containing any object of interest. The model naturally handles a variable number of instances for each class and allows for cross-class generalization at the highest levels of the network. We are able to obtain competitive recognition performance on VOC2007 and ILSVRC2012, while using only the top few predicted locations in each image and a small number of neural network evaluations.\n    ",
        "submission_date": "2013-12-08T00:00:00",
        "last_modified_date": "2013-12-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.2383",
        "title": "On the Performance of Filters for Reduction of Speckle Noise in SAR Images off the Coast of the Gulf of Guinea",
        "authors": [
            "Griffith S. Klogo",
            "Akpeko Gasonoo",
            "Isaac K. E. Ampomah"
        ],
        "abstract": "Synthetic Aperture Radar (SAR) imagery to monitor oil spills are some methods that have been proposed for the West African sub-region. With the increase in the number of oil exploration companies in Ghana (and her neighbors) and the rise in the coastal activities in the sub-region, there is the need for proper monitoring of the environmental impact of these socio-economic activities on the environment. Detection and near real-time information about oil spills are fundamental in reducing oil spill environmental impact. SAR images are prone to some noise, which is predominantly speckle noise around the coastal areas. This paper evaluates the performance of the mean and median filters used in the preprocessing filtering to reduce speckle noise in SAR images for most image processing algorithms.\n    ",
        "submission_date": "2013-12-09T00:00:00",
        "last_modified_date": "2013-12-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.3035",
        "title": "Heat kernel coupling for multiple graph analysis",
        "authors": [
            "Michael M. Bronstein",
            "Klaus Glashoff"
        ],
        "abstract": "In this paper, we introduce heat kernel coupling (HKC) as a method of constructing multimodal spectral geometry on weighted graphs of different size without vertex-wise bijective correspondence. We show that Laplacian averaging can be derived as a limit case of HKC, and demonstrate its applications on several problems from the manifold learning and pattern recognition domain.\n    ",
        "submission_date": "2013-12-11T00:00:00",
        "last_modified_date": "2013-12-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.3061",
        "title": "Fast Approximate $K$-Means via Cluster Closures",
        "authors": [
            "Jingdong Wang",
            "Jing Wang",
            "Qifa Ke",
            "Gang Zeng",
            "Shipeng Li"
        ],
        "abstract": "$K$-means, a simple and effective clustering algorithm, is one of the most widely used algorithms in multimedia and computer vision community. Traditional $k$-means is an iterative algorithm---in each iteration new cluster centers are computed and each data point is re-assigned to its nearest center. The cluster re-assignment step becomes prohibitively expensive when the number of data points and cluster centers are large.\n",
        "submission_date": "2013-12-11T00:00:00",
        "last_modified_date": "2013-12-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.3062",
        "title": "Fast Neighborhood Graph Search using Cartesian Concatenation",
        "authors": [
            "Jingdong Wang",
            "Jing Wang",
            "Gang Zeng",
            "Rui Gan",
            "Shipeng Li",
            "Baining Guo"
        ],
        "abstract": "In this paper, we propose a new data structure for approximate nearest neighbor search. This structure augments the neighborhood graph with a bridge graph. We propose to exploit Cartesian concatenation to produce a large set of vectors, called bridge vectors, from several small sets of subvectors. Each bridge vector is connected with a few reference vectors near to it, forming a bridge graph. Our approach finds nearest neighbors by simultaneously traversing the neighborhood graph and the bridge graph in the best-first strategy. The success of our approach stems from two factors: the exact nearest neighbor search over a large number of bridge vectors can be done quickly, and the reference vectors connected to a bridge (reference) vector near the query are also likely to be near the query. Experimental results on searching over large scale datasets (SIFT, GIST and HOG) show that our approach outperforms state-of-the-art ANN search algorithms in terms of efficiency and accuracy. The combination of our approach with the IVFADC system also shows superior performance over the BIGANN dataset of $1$ billion SIFT features compared with the best previously published result.\n    ",
        "submission_date": "2013-12-11T00:00:00",
        "last_modified_date": "2013-12-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.3199",
        "title": "Thickness Mapping of Eleven Retinal Layers in Normal Eyes Using Spectral Domain Optical Coherence Tomography",
        "authors": [
            "Raheleh Kafieh",
            "Hossein Rabbani",
            "Fedra Hajizadeh",
            "Michael D. Abramoff",
            "Milan Sonka"
        ],
        "abstract": "Purpose. This study was conducted to determine the thickness map of eleven retinal layers in normal subjects by spectral domain optical coherence tomography (SD-OCT) and evaluate their association with sex and age. Methods. Mean regional retinal thickness of 11 retinal layers were obtained by automatic three-dimensional diffusion-map-based method in 112 normal eyes of 76 Iranian subjects. Results. The thickness map of central foveal area in layer 1, 3, and 4 displayed the minimum thickness (P<0.005 for all). Maximum thickness was observed in nasal to the fovea of layer 1 (P<0.001) and in a circular pattern in the parafoveal retinal area of layers 2, 3 and 4 and in central foveal area of layer 6 (P<0.001). Temporal and inferior quadrants of the total retinal thickness and most of other quadrants of layer 1 were significantly greater in the men than in the women. Surrounding eight sectors of total retinal thickness and a limited number of sectors in layer 1 and 4 significantly correlated with age. Conclusion. SD-OCT demonstrated the three-dimensional thickness distribution of retinal layers in normal eyes. Thickness of layers varied with sex and age and in different sectors. These variables should be considered while evaluating macular thickness.\n    ",
        "submission_date": "2013-12-11T00:00:00",
        "last_modified_date": "2013-12-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.3240",
        "title": "Associative embeddings for large-scale knowledge transfer with self-assessment",
        "authors": [
            "Alexander Vezhnevets",
            "Vittorio Ferrari"
        ],
        "abstract": "We propose a method for knowledge transfer between semantically related classes in ImageNet. By transferring knowledge from the images that have bounding-box annotations to the others, our method is capable of automatically populating ImageNet with many more bounding-boxes and even pixel-level segmentations. The underlying assumption that objects from semantically related classes look alike is formalized in our novel Associative Embedding (AE) representation. AE recovers the latent low-dimensional space of appearance variations among image windows. The dimensions of AE space tend to correspond to aspects of window appearance (e.g. side view, close up, background). We model the overlap of a window with an object using Gaussian Processes (GP) regression, which spreads annotation smoothly through AE space. The probabilistic nature of GP allows our method to perform self-assessment, i.e. assigning a quality estimate to its own output. It enables trading off the amount of returned annotations for their quality. A large scale experiment on 219 classes and 0.5 million images demonstrates that our method outperforms state-of-the-art methods and baselines for both object localization and segmentation. Using self-assessment we can automatically return bounding-box annotations for 30% of all images with high localization accuracy (i.e.~73% average overlap with ground-truth).\n    ",
        "submission_date": "2013-12-11T00:00:00",
        "last_modified_date": "2014-07-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.3429",
        "title": "Unsupervised learning of depth and motion",
        "authors": [
            "Kishore Konda",
            "Roland Memisevic"
        ],
        "abstract": "We present a model for the joint estimation of disparity and motion. The model is based on learning about the interrelations between images from multiple cameras, multiple frames in a video, or the combination of both. We show that learning depth and motion cues, as well as their combinations, from data is possible within a single type of architecture and a single type of learning algorithm, by using biologically inspired \"complex cell\" like units, which encode correlations between the pixels across image pairs. Our experimental results show that the learning of depth and motion makes it possible to achieve state-of-the-art performance in 3-D activity analysis, and to outperform existing hand-engineered 3-D motion features by a very large margin.\n    ",
        "submission_date": "2013-12-12T00:00:00",
        "last_modified_date": "2013-12-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.3724",
        "title": "ARIANNA: pAth Recognition for Indoor Assisted NavigatioN with Augmented perception",
        "authors": [
            "Pierluigi Gallo",
            "Ilenia Tinnirello",
            "Laura Giarr\u00e9",
            "Domenico Garlisi",
            "Daniele Croce",
            "Adriano Fagiolini"
        ],
        "abstract": "ARIANNA stands for pAth Recognition for Indoor Assisted Navigation with Augmented perception. It is a flexible and low cost navigation system for vi- sually impaired people. Arianna permits to navigate colored paths painted or sticked on the floor revealing their directions through vibrational feedback on commercial smartphones.\n    ",
        "submission_date": "2013-12-13T00:00:00",
        "last_modified_date": "2013-12-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.3787",
        "title": "Analysis and Understanding of Various Models for Efficient Representation and Accurate Recognition of Human Faces",
        "authors": [
            "Dharini S.",
            "Guru Prasad M.",
            "Hari haran. V.",
            "Kiran Tej J. L.",
            "Kunal Ghosh"
        ],
        "abstract": "In this paper we have tried to compare the various face recognition models against their classical problems. We look at the methods followed by these approaches and evaluate to what extent they are able to solve the problems. All methods proposed have some drawbacks under certain conditions. To overcome these drawbacks we propose a multi-model approach\n    ",
        "submission_date": "2013-12-13T00:00:00",
        "last_modified_date": "2015-02-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.3989",
        "title": "Classifiers With a Reject Option for Early Time-Series Classification",
        "authors": [
            "Nima Hatami",
            "Camelia Chira"
        ],
        "abstract": "Early classification of time-series data in a dynamic environment is a challenging problem of great importance in signal processing. This paper proposes a classifier architecture with a reject option capable of online decision making without the need to wait for the entire time series signal to be present. The main idea is to classify an odor/gas signal with an acceptable accuracy as early as possible. Instead of using posterior probability of a classifier, the proposed method uses the \"agreement\" of an ensemble to decide whether to accept or reject the candidate label. The introduced algorithm is applied to the bio-chemistry problem of odor classification to build a novel Electronic-Nose called Forefront-Nose. Experimental results on wind tunnel test-bed facility confirms the robustness of the forefront-nose compared to the standard classifiers from both earliness and recognition perspectives.\n    ",
        "submission_date": "2013-12-14T00:00:00",
        "last_modified_date": "2013-12-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.3990",
        "title": "ECOC-Based Training of Neural Networks for Face Recognition",
        "authors": [
            "Nima Hatami",
            "Reza Ebrahimpour",
            "Reza Ghaderi"
        ],
        "abstract": "Error Correcting Output Codes, ECOC, is an output representation method capable of discovering some of the errors produced in classification tasks. This paper describes the application of ECOC to the training of feed forward neural networks, FFNN, for improving the overall accuracy of classification systems. Indeed, to improve the generalization of FFNN classifiers, this paper proposes an ECOC-Based training method for Neural Networks that use ECOC as the output representation, and adopts the traditional Back-Propagation algorithm, BP, to adjust weights of the network. Experimental results for face recognition problem on Yale database demonstrate the effectiveness of our method. With a rejection scheme defined by a simple robustness rate, high reliability is achieved in this application.\n    ",
        "submission_date": "2013-12-14T00:00:00",
        "last_modified_date": "2013-12-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.4074",
        "title": "Clustering using Vector Membership: An Extension of the Fuzzy C-Means Algorithm",
        "authors": [
            "Srinjoy Ganguly",
            "Digbalay Bose",
            "Amit Konar"
        ],
        "abstract": "Clustering is an important facet of explorative data mining and finds extensive use in several fields. In this paper, we propose an extension of the classical Fuzzy C-Means clustering algorithm. The proposed algorithm, abbreviated as VFC, adopts a multi-dimensional membership vector for each data point instead of the traditional, scalar membership value defined in the original algorithm. The membership vector for each point is obtained by considering each feature of that point separately and obtaining individual membership values for the same. We also propose an algorithm to efficiently allocate the initial cluster centers close to the actual centers, so as to facilitate rapid convergence. Further, we propose a scheme to achieve crisp clustering using the VFC algorithm. The proposed, novel clustering scheme has been tested on two standard data sets in order to analyze its performance. We also examine the efficacy of the proposed scheme by analyzing its performance on image segmentation examples and comparing it with the classical Fuzzy C-means clustering algorithm.\n    ",
        "submission_date": "2013-12-14T00:00:00",
        "last_modified_date": "2013-12-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.4124",
        "title": "A robust Iris recognition method on adverse conditions",
        "authors": [
            "Maryam Soltanali Khalili",
            "Hamed Sadjedi"
        ],
        "abstract": "As a stable biometric system, iris has recently attracted great attention among the researchers. However, research is still needed to provide appropriate solutions to ensure the resistance of the system against error factors. The present study has tried to apply a mask to the image so that the unexpected factors affecting the location of the iris can be removed. So, pupil localization will be faster and robust. Then to locate the exact location of the iris, a simple stage of boundary displacement due to the Canny edge detector has been applied. Then, with searching left and right IRIS edge point, outer radios of IRIS will be detect. Through the process of extracting the iris features, it has been sought to obtain the distinctive iris texture features by using a discrete stationary wavelets transform 2-D (DSWT2). Using DSWT2 tool and symlet 4 wavelet, distinctive features are extracted. To reduce the computational cost, the features obtained from the application of the wavelet have been investigated and a feature selection procedure, using similarity criteria, has been implemented. Finally, the iris matching has been performed using a semi-correlation criterion. The accuracy of the proposed method for localization on CASIA-v1, CASIA-v3 is 99.73%, 98.24% and 97.04%, respectively. The accuracy of the feature extraction proposed method for CASIA3 iris images database is 97.82%, which confirms the efficiency of the proposed method.\n    ",
        "submission_date": "2013-12-15T00:00:00",
        "last_modified_date": "2013-12-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.4190",
        "title": "One-Shot-Learning Gesture Recognition using HOG-HOF Features",
        "authors": [
            "Jakub Kone\u010dn\u00fd",
            "Michal Hagara"
        ],
        "abstract": "The purpose of this paper is to describe one-shot-learning gesture recognition systems developed on the \\textit{ChaLearn Gesture Dataset}. We use RGB and depth images and combine appearance (Histograms of Oriented Gradients) and motion descriptors (Histogram of Optical Flow) for parallel temporal segmentation and recognition. The Quadratic-Chi distance family is used to measure differences between histograms to capture cross-bin relationships. We also propose a new algorithm for trimming videos --- to remove all the unimportant frames from videos. We present two methods that use combination of HOG-HOF descriptors together with variants of Dynamic Time Warping technique. Both methods outperform other published methods and help narrow down the gap between human performance and algorithms on this task. The code has been made publicly available in the MLOSS repository.\n    ",
        "submission_date": "2013-12-15T00:00:00",
        "last_modified_date": "2014-02-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.4384",
        "title": "Rectifying Self Organizing Maps for Automatic Concept Learning from Web Images",
        "authors": [
            "Eren Golge",
            "Pinar Duygulu"
        ],
        "abstract": "We attack the problem of learning concepts automatically from noisy web image search results. Going beyond low level attributes, such as colour and texture, we explore weakly-labelled datasets for the learning of higher level concepts, such as scene categories. The idea is based on discovering common characteristics shared among subsets of images by posing a method that is able to organise the data while eliminating irrelevant instances. We propose a novel clustering and outlier detection method, namely Rectifying Self Organizing Maps (RSOM). Given an image collection returned for a concept query, RSOM provides clusters pruned from outliers. Each cluster is used to train a model representing a different characteristics of the concept. The proposed method outperforms the state-of-the-art studies on the task of learning low-level concepts, and it is competitive in learning higher level concepts as well. It is capable to work at large scale with no supervision through exploiting the available sources.\n    ",
        "submission_date": "2013-12-16T00:00:00",
        "last_modified_date": "2013-12-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.4569",
        "title": "Dropout improves Recurrent Neural Networks for Handwriting Recognition",
        "authors": [
            "Vu Pham",
            "Th\u00e9odore Bluche",
            "Christopher Kermorvant",
            "J\u00e9r\u00f4me Louradour"
        ],
        "abstract": "Recurrent neural networks (RNNs) with Long Short-Term memory cells currently hold the best known results in unconstrained handwriting recognition. We show that their performance can be greatly improved using dropout - a recently proposed regularization method for deep architectures. While previous works showed that dropout gave superior performance in the context of convolutional networks, it had never been applied to RNNs. In our approach, dropout is carefully used in the network so that it does not affect the recurrent connections, hence the power of RNNs in modeling sequence is preserved. Extensive experiments on a broad range of handwritten databases confirm the effectiveness of dropout on deep architectures even when the network mainly consists of recurrent and shared connections.\n    ",
        "submission_date": "2013-11-05T00:00:00",
        "last_modified_date": "2014-03-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.4637",
        "title": "Constraint Reduction using Marginal Polytope Diagrams for MAP LP Relaxations",
        "authors": [
            "Zhen Zhang",
            "Qinfeng Shi",
            "Yanning Zhang",
            "Chunhua Shen",
            "Anton van den Hengel"
        ],
        "abstract": "LP relaxation-based message passing algorithms provide an effective tool for MAP inference over Probabilistic Graphical Models. However, different LP relaxations often have different objective functions and variables of differing dimensions, which presents a barrier to effective comparison and analysis. In addition, the computational complexity of LP relaxation-based methods grows quickly with the number of constraints. Reducing the number of constraints without sacrificing the quality of the solutions is thus desirable.\n",
        "submission_date": "2013-12-17T00:00:00",
        "last_modified_date": "2014-04-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.4659",
        "title": "DeepPose: Human Pose Estimation via Deep Neural Networks",
        "authors": [
            "Alexander Toshev",
            "Christian Szegedy"
        ],
        "abstract": "We propose a method for human pose estimation based on Deep Neural Networks (DNNs). The pose estimation is formulated as a DNN-based regression problem towards body joints. We present a cascade of such DNN regressors which results in high precision pose estimates. The approach has the advantage of reasoning about pose in a holistic fashion and has a simple but yet powerful formulation which capitalizes on recent advances in Deep Learning. We present a detailed empirical analysis with state-of-art or better performance on four academic benchmarks of diverse real-world images.\n    ",
        "submission_date": "2013-12-17T00:00:00",
        "last_modified_date": "2014-08-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.4740",
        "title": "Learning High-level Image Representation for Image Retrieval via Multi-Task DNN using Clickthrough Data",
        "authors": [
            "Yalong Bai",
            "Kuiyuan Yang",
            "Wei Yu",
            "Wei-Ying Ma",
            "Tiejun Zhao"
        ],
        "abstract": "Image retrieval refers to finding relevant images from an image database for a query, which is considered difficult for the gap between low-level representation of images and high-level representation of queries. Recently further developed Deep Neural Network sheds light on automatically learning high-level image representation from raw pixels. In this paper, we proposed a multi-task DNN learned for image retrieval, which contains two parts, i.e., query-sharing layers for image representation computation and query-specific layers for relevance estimation. The weights of multi-task DNN are learned on clickthrough data by Ring Training. Experimental results on both simulated and real dataset show the effectiveness of the proposed method.\n    ",
        "submission_date": "2013-12-17T00:00:00",
        "last_modified_date": "2013-12-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.4746",
        "title": "Co-Sparse Textural Similarity for Image Segmentation",
        "authors": [
            "Claudia Nieuwenhuis",
            "Daniel Cremers",
            "Simon Hawe",
            "Martin Kleinsteuber"
        ],
        "abstract": "We propose an algorithm for segmenting natural images based on texture and color information, which leverages the co-sparse analysis model for image segmentation within a convex multilabel optimization framework. As a key ingredient of this method, we introduce a novel textural similarity measure, which builds upon the co-sparse representation of image patches. We propose a Bayesian approach to merge textural similarity with information about color and location. Combined with recently developed convex multilabel optimization methods this leads to an efficient algorithm for both supervised and unsupervised segmentation, which is easily parallelized on graphics hardware. The approach provides competitive results in unsupervised segmentation and outperforms state-of-the-art interactive segmentation methods on the Graz Benchmark.\n    ",
        "submission_date": "2013-12-17T00:00:00",
        "last_modified_date": "2013-12-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.4752",
        "title": "BW - Eye Ophthalmologic decision support system based on clinical workflow and data mining techniques-image registration algorithm",
        "authors": [
            "Ricardo Martins"
        ],
        "abstract": "Blueworks - Medical Expert Diagnosis is developing an application, BWEye, to be used as an ophthalmology consultation decision support system. The implementation of this application involves several different tasks and one of them is the implementation of an ophthalmology images registration algorithm. The work reported in this document is related with the implementation of an algorithm to register images of angiography, colour retinography and redfree retinography. The implementations described were developed in the software MATLAB.\n",
        "submission_date": "2013-12-17T00:00:00",
        "last_modified_date": "2013-12-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.4894",
        "title": "Deep Convolutional Ranking for Multilabel Image Annotation",
        "authors": [
            "Yunchao Gong",
            "Yangqing Jia",
            "Thomas Leung",
            "Alexander Toshev",
            "Sergey Ioffe"
        ],
        "abstract": "Multilabel image annotation is one of the most important challenges in computer vision with many real-world applications. While existing work usually use conventional visual features for multilabel annotation, features based on Deep Neural Networks have shown potential to significantly boost performance. In this work, we propose to leverage the advantage of such features and analyze key components that lead to better performances. Specifically, we show that a significant performance gain could be obtained by combining convolutional architectures with approximate top-$k$ ranking objectives, as thye naturally fit the multilabel tagging problem. Our experiments on the NUS-WIDE dataset outperforms the conventional visual features by about 10%, obtaining the best reported performance in the literature.\n    ",
        "submission_date": "2013-12-17T00:00:00",
        "last_modified_date": "2014-04-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.4967",
        "title": "Estimation of Human Body Shape and Posture Under Clothing",
        "authors": [
            "Stefanie Wuhrer",
            "Leonid Pishchulin",
            "Alan Brunton",
            "Chang Shu",
            "Jochen Lang"
        ],
        "abstract": "Estimating the body shape and posture of a dressed human subject in motion represented as a sequence of (possibly incomplete) 3D meshes is important for virtual change rooms and security. To solve this problem, statistical shape spaces encoding human body shape and posture variations are commonly used to constrain the search space for the shape estimate. In this work, we propose a novel method that uses a posture-invariant shape space to model body shape variation combined with a skeleton-based deformation to model posture variation. Our method can estimate the body shape and posture of both static scans and motion sequences of dressed human body scans. In case of motion sequences, our method takes advantage of motion cues to solve for a single body shape estimate along with a sequence of posture estimates. We apply our approach to both static scans and motion sequences and demonstrate that using our method, higher fitting accuracy is achieved than when using a variant of the popular SCAPE model as statistical model.\n    ",
        "submission_date": "2013-12-17T00:00:00",
        "last_modified_date": "2014-06-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.5045",
        "title": "Comparative analysis of evolutionary algorithms for image enhancement",
        "authors": [
            "Anupriya Gogna",
            "Akash Tayal"
        ],
        "abstract": "Evolutionary algorithms are metaheuristic techniques that derive inspiration from the natural process of evolution. They can efficiently solve (generate acceptable quality of solution in reasonable time) complex optimization (NP-Hard) problems. In this paper, automatic image enhancement is considered as an optimization problem and three evolutionary algorithms (Genetic Algorithm, Differential Evolution and Self Organizing Migration Algorithm) are employed to search for an optimum solution. They are used to find an optimum parameter set for an image enhancement transfer function. The aim is to maximize a fitness criterion which is a measure of image contrast and the visibility of details in the enhanced image. The enhancement results obtained using all three evolutionary algorithms are compared amongst themselves and also with the output of histogram equalization method.\n    ",
        "submission_date": "2013-12-18T00:00:00",
        "last_modified_date": "2013-12-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.5047",
        "title": "Stable Camera Motion Estimation Using Convex Programming",
        "authors": [
            "Onur Ozyesil",
            "Amit Singer",
            "Ronen Basri"
        ],
        "abstract": "We study the inverse problem of estimating n locations $t_1, ..., t_n$ (up to global scale, translation and negation) in $R^d$ from noisy measurements of a subset of the (unsigned) pairwise lines that connect them, that is, from noisy measurements of $\\pm (t_i - t_j)/\\|t_i - t_j\\|$ for some pairs (i,j) (where the signs are unknown). This problem is at the core of the structure from motion (SfM) problem in computer vision, where the $t_i$'s represent camera locations in $R^3$. The noiseless version of the problem, with exact line measurements, has been considered previously under the general title of parallel rigidity theory, mainly in order to characterize the conditions for unique realization of locations. For noisy pairwise line measurements, current methods tend to produce spurious solutions that are clustered around a few locations. This sensitivity of the location estimates is a well-known problem in SfM, especially for large, irregular collections of images.\n",
        "submission_date": "2013-12-18T00:00:00",
        "last_modified_date": "2015-01-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.5242",
        "title": "Unsupervised feature learning by augmenting single images",
        "authors": [
            "Alexey Dosovitskiy",
            "Jost Tobias Springenberg",
            "Thomas Brox"
        ],
        "abstract": "When deep learning is applied to visual object recognition, data augmentation is often used to generate additional training data without extra labeling cost. It helps to reduce overfitting and increase the performance of the algorithm. In this paper we investigate if it is possible to use data augmentation as the main component of an unsupervised feature learning architecture. To that end we sample a set of random image patches and declare each of them to be a separate single-image surrogate class. We then extend these trivial one-element classes by applying a variety of transformations to the initial 'seed' patches. Finally we train a convolutional neural network to discriminate between these surrogate classes. The feature representation learned by the network can then be used in various vision tasks. We find that this simple feature learning algorithm is surprisingly successful, achieving competitive classification results on several popular vision datasets (STL-10, CIFAR-10, Caltech-101).\n    ",
        "submission_date": "2013-12-18T00:00:00",
        "last_modified_date": "2014-02-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.5402",
        "title": "Some Improvements on Deep Convolutional Neural Network Based Image Classification",
        "authors": [
            "Andrew G. Howard"
        ],
        "abstract": "We investigate multiple techniques to improve upon the current state of the art deep convolutional neural network based image classification pipeline. The techiques include adding more image transformations to training data, adding more transformations to generate additional predictions at test time and using complementary models applied to higher resolution images. This paper summarizes our entry in the Imagenet Large Scale Visual Recognition Challenge 2013. Our system achieved a top 5 classification error rate of 13.55% using no external data which is over a 20% relative improvement on the previous year's winner.\n    ",
        "submission_date": "2013-12-19T00:00:00",
        "last_modified_date": "2013-12-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.5479",
        "title": "Sparse similarity-preserving hashing",
        "authors": [
            "Jonathan Masci",
            "Alex M. Bronstein",
            "Michael M. Bronstein",
            "Pablo Sprechmann",
            "Guillermo Sapiro"
        ],
        "abstract": "In recent years, a lot of attention has been devoted to efficient nearest neighbor search by means of similarity-preserving hashing. One of the plights of existing hashing techniques is the intrinsic trade-off between performance and computational complexity: while longer hash codes allow for lower false positive rates, it is very difficult to increase the embedding dimensionality without incurring in very high false negatives rates or prohibiting computational costs. In this paper, we propose a way to overcome this limitation by enforcing the hash codes to be sparse. Sparse high-dimensional codes enjoy from the low false positive rates typical of long hashes, while keeping the false negative rates similar to those of a shorter dense hashing scheme with equal number of degrees of freedom. We use a tailored feed-forward neural network for the hashing function. Extensive experimental evaluation involving visual and multi-modal data shows the benefits of the proposed method.\n    ",
        "submission_date": "2013-12-19T00:00:00",
        "last_modified_date": "2014-02-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.5568",
        "title": "An Adaptive Dictionary Learning Approach for Modeling Dynamical Textures",
        "authors": [
            "Xian Wei",
            "Hao Shen",
            "Martin Kleinsteuber"
        ],
        "abstract": "Video representation is an important and challenging task in the computer vision community. In this paper, we assume that image frames of a moving scene can be modeled as a Linear Dynamical System. We propose a sparse coding framework, named adaptive video dictionary learning (AVDL), to model a video adaptively. The developed framework is able to capture the dynamics of a moving scene by exploring both sparse properties and the temporal correlations of consecutive video frames. The proposed method is compared with state of the art video processing methods on several benchmark data sequences, which exhibit appearance changes and heavy occlusions.\n    ",
        "submission_date": "2013-12-19T00:00:00",
        "last_modified_date": "2013-12-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.5604",
        "title": "Learning Transformations for Classification Forests",
        "authors": [
            "Qiang Qiu",
            "Guillermo Sapiro"
        ],
        "abstract": "This work introduces a transformation-based learner model for classification forests. The weak learner at each split node plays a crucial role in a classification tree. We propose to optimize the splitting objective by learning a linear transformation on subspaces using nuclear norm as the optimization criteria. The learned linear transformation restores a low-rank structure for data from the same class, and, at the same time, maximizes the separation between different classes, thereby improving the performance of the split function. Theoretical and experimental results support the proposed framework.\n    ",
        "submission_date": "2013-12-19T00:00:00",
        "last_modified_date": "2014-02-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.5697",
        "title": "Using Web Co-occurrence Statistics for Improving Image Categorization",
        "authors": [
            "Samy Bengio",
            "Jeff Dean",
            "Dumitru Erhan",
            "Eugene Ie",
            "Quoc Le",
            "Andrew Rabinovich",
            "Jonathon Shlens",
            "Yoram Singer"
        ],
        "abstract": "Object recognition and localization are important tasks in computer vision. The focus of this work is the incorporation of contextual information in order to improve object recognition and localization. For instance, it is natural to expect not to see an elephant to appear in the middle of an ocean. We consider a simple approach to encapsulate such common sense knowledge using co-occurrence statistics from web documents. By merely counting the number of times nouns (such as elephants, sharks, oceans, etc.) co-occur in web documents, we obtain a good estimate of expected co-occurrences in visual data. We then cast the problem of combining textual co-occurrence statistics with the predictions of image-based classifiers as an optimization problem. The resulting optimization problem serves as a surrogate for our inference procedure. Albeit the simplicity of the resulting optimization problem, it is effective in improving both recognition and localization accuracy. Concretely, we observe significant improvements in recognition and localization rates for both ImageNet Detection 2012 and Sun 2012 datasets.\n    ",
        "submission_date": "2013-12-19T00:00:00",
        "last_modified_date": "2013-12-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.5785",
        "title": "EXMOVES: Classifier-based Features for Scalable Action Recognition",
        "authors": [
            "Du Tran",
            "Lorenzo Torresani"
        ],
        "abstract": "This paper introduces EXMOVES, learned exemplar-based features for efficient recognition of actions in videos. The entries in our descriptor are produced by evaluating a set of movement classifiers over spatial-temporal volumes of the input sequence. Each movement classifier is a simple exemplar-SVM trained on low-level features, i.e., an SVM learned using a single annotated positive space-time volume and a large number of unannotated videos.\n",
        "submission_date": "2013-12-20T00:00:00",
        "last_modified_date": "2014-03-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.5851",
        "title": "Fast Training of Convolutional Networks through FFTs",
        "authors": [
            "Michael Mathieu",
            "Mikael Henaff",
            "Yann LeCun"
        ],
        "abstract": "Convolutional networks are one of the most widely employed architectures in computer vision and machine learning. In order to leverage their ability to learn complex functions, large amounts of data are required for training. Training a large convolutional network to produce state-of-the-art results can take weeks, even when using modern GPUs. Producing labels using a trained network can also be costly when dealing with web-scale datasets. In this work, we present a simple algorithm which accelerates training and inference by a significant factor, and can yield improvements of over an order of magnitude compared to existing state-of-the-art implementations. This is done by computing convolutions as pointwise products in the Fourier domain while reusing the same transformed feature map many times. The algorithm is implemented on a GPU architecture and addresses a number of related challenges.\n    ",
        "submission_date": "2013-12-20T00:00:00",
        "last_modified_date": "2014-03-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.5940",
        "title": "Generic Deep Networks with Wavelet Scattering",
        "authors": [
            "Edouard Oyallon",
            "St\u00e9phane Mallat",
            "Laurent Sifre"
        ],
        "abstract": "We introduce a two-layer wavelet scattering network, for object classification. This scattering transform computes a spatial wavelet transform on the first layer and a new joint wavelet transform along spatial, angular and scale variables in the second layer. Numerical experiments demonstrate that this two layer convolution network, which involves no learning and no max pooling, performs efficiently on complex image data sets such as CalTech, with structural objects variability and clutter. It opens the possibility to simplify deep neural network learning by initializing the first layers with wavelet filters.\n    ",
        "submission_date": "2013-12-20T00:00:00",
        "last_modified_date": "2014-03-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.6024",
        "title": "Occupancy Detection in Vehicles Using Fisher Vector Image Representation",
        "authors": [
            "Yusuf Artan",
            "Peter Paul"
        ],
        "abstract": "Due to the high volume of traffic on modern roadways, transportation agencies have proposed High Occupancy Vehicle (HOV) lanes and High Occupancy Tolling (HOT) lanes to promote car pooling. However, enforcement of the rules of these lanes is currently performed by roadside enforcement officers using visual observation. Manual roadside enforcement is known to be inefficient, costly, potentially dangerous, and ultimately ineffective. Violation rates up to 50%-80% have been reported, while manual enforcement rates of less than 10% are typical. Therefore, there is a need for automated vehicle occupancy detection to support HOV/HOT lane enforcement. A key component of determining vehicle occupancy is to determine whether or not the vehicle's front passenger seat is occupied. In this paper, we examine two methods of determining vehicle front seat occupancy using a near infrared (NIR) camera system pointed at the vehicle's front windshield. The first method examines a state-of-the-art deformable part model (DPM) based face detection system that is robust to facial pose. The second method examines state-of- the-art local aggregation based image classification using bag-of-visual-words (BOW) and Fisher vectors (FV). A dataset of 3000 images was collected on a public roadway and is used to perform the comparison. From these experiments it is clear that the image classification approach is superior for this problem.\n    ",
        "submission_date": "2013-12-20T00:00:00",
        "last_modified_date": "2013-12-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.6034",
        "title": "Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps",
        "authors": [
            "Karen Simonyan",
            "Andrea Vedaldi",
            "Andrew Zisserman"
        ],
        "abstract": "This paper addresses the visualisation of image classification models, learnt using deep Convolutional Networks (ConvNets). We consider two visualisation techniques, based on computing the gradient of the class score with respect to the input image. The first one generates an image, which maximises the class score [Erhan et al., 2009], thus visualising the notion of the class, captured by a ConvNet. The second technique computes a class saliency map, specific to a given image and class. We show that such maps can be employed for weakly supervised object segmentation using classification ConvNets. Finally, we establish the connection between the gradient-based ConvNet visualisation methods and deconvolutional networks [Zeiler et al., 2013].\n    ",
        "submission_date": "2013-12-20T00:00:00",
        "last_modified_date": "2014-04-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.6077",
        "title": "Efficient Visual Coding: From Retina To V2",
        "authors": [
            "Honghao Shan",
            "Garrison Cottrell"
        ],
        "abstract": "The human visual system has a hierarchical structure consisting of layers of processing, such as the retina, V1, V2, etc. Understanding the functional roles of these visual processing layers would help to integrate the psychophysiological and neurophysiological models into a consistent theory of human vision, and would also provide insights to computer vision research. One classical theory of the early visual pathway hypothesizes that it serves to capture the statistical structure of the visual inputs by efficiently coding the visual information in its outputs. Until recently, most computational models following this theory have focused upon explaining the receptive field properties of one or two visual layers. Recent work in deep networks has eliminated this concern, however, there is till the retinal layer to consider. Here we improve on a previously-described hierarchical model Recursive ICA (RICA) [1] which starts with PCA, followed by a layer of sparse coding or ICA, followed by a component-wise nonlinearity derived from considerations of the variable distributions expected by ICA. This process is then repeated. In this work, we improve on this model by using a new version of sparse PCA (sPCA), which results in biologically-plausible receptive fields for both the sPCA and ICA/sparse coding. When applied to natural image patches, our model learns visual features exhibiting the receptive field properties of retinal ganglion cells/lateral geniculate nucleus (LGN) cells, V1 simple cells, V1 complex cells, and V2 cells. Our work provides predictions for experimental neuroscience studies. For example, our result suggests that a previous neurophysiological study improperly discarded some of their recorded neurons; we predict that their discarded neurons capture the shape contour of objects.\n    ",
        "submission_date": "2013-12-20T00:00:00",
        "last_modified_date": "2014-12-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.6082",
        "title": "Multi-digit Number Recognition from Street View Imagery using Deep Convolutional Neural Networks",
        "authors": [
            "Ian J. Goodfellow",
            "Yaroslav Bulatov",
            "Julian Ibarz",
            "Sacha Arnoud",
            "Vinay Shet"
        ],
        "abstract": "Recognizing arbitrary multi-character text in unconstrained natural photographs is a hard problem. In this paper, we address an equally hard sub-problem in this domain viz. recognizing arbitrary multi-digit numbers from Street View imagery. Traditional approaches to solve this problem typically separate out the localization, segmentation, and recognition steps. In this paper we propose a unified approach that integrates these three steps via the use of a deep convolutional neural network that operates directly on the image pixels. We employ the DistBelief implementation of deep neural networks in order to train large, distributed neural networks on high quality images. We find that the performance of this approach increases with the depth of the convolutional network, with the best performance occurring in the deepest architecture we trained, with eleven hidden layers. We evaluate this approach on the publicly available SVHN dataset and achieve over $96\\%$ accuracy in recognizing complete street numbers. We show that on a per-digit recognition task, we improve upon the state-of-the-art, achieving $97.84\\%$ accuracy. We also evaluate this approach on an even more challenging dataset generated from Street View imagery containing several tens of millions of street number annotations and achieve over $90\\%$ accuracy. To further explore the applicability of the proposed system to broader text recognition tasks, we apply it to synthetic distorted text from reCAPTCHA. reCAPTCHA is one of the most secure reverse turing tests that uses distorted text to distinguish humans from bots. We report a $99.8\\%$ accuracy on the hardest category of reCAPTCHA. Our evaluations on both tasks indicate that at specific operating thresholds, the performance of the proposed system is comparable to, and in some cases exceeds, that of human operators.\n    ",
        "submission_date": "2013-12-20T00:00:00",
        "last_modified_date": "2014-04-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.6095",
        "title": "Multi-View Priors for Learning Detectors from Sparse Viewpoint Data",
        "authors": [
            "Bojan Pepik",
            "Michael Stark",
            "Peter Gehler",
            "Bernt Schiele"
        ],
        "abstract": "While the majority of today's object class models provide only 2D bounding boxes, far richer output hypotheses are desirable including viewpoint, fine-grained category, and 3D geometry estimate. However, models trained to provide richer output require larger amounts of training data, preferably well covering the relevant aspects such as viewpoint and fine-grained categories. In this paper, we address this issue from the perspective of transfer learning, and design an object class model that explicitly leverages correlations between visual features. Specifically, our model represents prior distributions over permissible multi-view detectors in a parametric way -- the priors are learned once from training data of a source object class, and can later be used to facilitate the learning of a detector for a target class. As we show in our experiments, this transfer is not only beneficial for detectors based on basic-level category representations, but also enables the robust learning of detectors that represent classes at finer levels of granularity, where training data is typically even scarcer and more unbalanced. As a result, we report largely improved performance in simultaneous 2D object localization and viewpoint estimation on a recent dataset of challenging street scenes.\n    ",
        "submission_date": "2013-12-20T00:00:00",
        "last_modified_date": "2014-02-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.6110",
        "title": "Learning Generative Models with Visual Attention",
        "authors": [
            "Yichuan Tang",
            "Nitish Srivastava",
            "Ruslan Salakhutdinov"
        ],
        "abstract": "Attention has long been proposed by psychologists as important for effectively dealing with the enormous sensory stimulus available in the neocortex. Inspired by the visual attention models in computational neuroscience and the need of object-centric data for generative models, we describe for generative learning framework using attentional mechanisms. Attentional mechanisms can propagate signals from region of interest in a scene to an aligned canonical representation, where generative modeling takes place. By ignoring background clutter, generative models can concentrate their resources on the object of interest. Our model is a proper graphical model where the 2D Similarity transformation is a part of the top-down process. A ConvNet is employed to provide good initializations during posterior inference which is based on Hamiltonian Monte Carlo. Upon learning images of faces, our model can robustly attend to face regions of novel test subjects. More importantly, our model can learn generative models of new faces from a novel dataset of large images where the face locations are not known.\n    ",
        "submission_date": "2013-12-20T00:00:00",
        "last_modified_date": "2015-02-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.6150",
        "title": "A Review on Automated Brain Tumor Detection and Segmentation from MRI of Brain",
        "authors": [
            "Sudipta Roy",
            "Sanjay Nag",
            "Indra Kanta Maitra",
            "Samir Kumar Bandyopadhyay"
        ],
        "abstract": "Tumor segmentation from magnetic resonance imaging (MRI) data is an important but time consuming manual task performed by medical experts. Automating this process is a challenging task because of the high diversity in the appearance of tumor tissues among different patients and in many cases similarity with the normal tissues. MRI is an advanced medical imaging technique providing rich information about the human soft-tissue anatomy. There are different brain tumor detection and segmentation methods to detect and segment a brain tumor from MRI images. These detection and segmentation approaches are reviewed with an importance placed on enlightening the advantages and drawbacks of these methods for brain tumor detection and segmentation. The use of MRI image detection and segmentation in different procedures are also described. Here a brief review of different segmentation for detection of brain tumor from MRI of brain has been discussed.\n    ",
        "submission_date": "2013-12-16T00:00:00",
        "last_modified_date": "2013-12-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.6159",
        "title": "Learned versus Hand-Designed Feature Representations for 3d Agglomeration",
        "authors": [
            "John A. Bogovic",
            "Gary B. Huang",
            "Viren Jain"
        ],
        "abstract": "For image recognition and labeling tasks, recent results suggest that machine learning methods that rely on manually specified feature representations may be outperformed by methods that automatically derive feature representations based on the data. Yet for problems that involve analysis of 3d objects, such as mesh segmentation, shape retrieval, or neuron fragment agglomeration, there remains a strong reliance on hand-designed feature descriptors. In this paper, we evaluate a large set of hand-designed 3d feature descriptors alongside features learned from the raw data using both end-to-end and unsupervised learning techniques, in the context of agglomeration of 3d neuron fragments. By combining unsupervised learning techniques with a novel dynamic pooling scheme, we show how pure learning-based methods are for the first time competitive with hand-designed 3d shape descriptors. We investigate data augmentation strategies for dramatically increasing the size of the training set, and show how combining both learned and hand-designed features leads to the highest accuracy.\n    ",
        "submission_date": "2013-12-20T00:00:00",
        "last_modified_date": "2013-12-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.6186",
        "title": "GPU Asynchronous Stochastic Gradient Descent to Speed Up Neural Network Training",
        "authors": [
            "Thomas Paine",
            "Hailin Jin",
            "Jianchao Yang",
            "Zhe Lin",
            "Thomas Huang"
        ],
        "abstract": "The ability to train large-scale neural networks has resulted in state-of-the-art performance in many areas of computer vision. These results have largely come from computational break throughs of two forms: model parallelism, e.g. GPU accelerated training, which has seen quick adoption in computer vision circles, and data parallelism, e.g. A-SGD, whose large scale has been used mostly in industry. We report early experiments with a system that makes use of both model parallelism and data parallelism, we call GPU A-SGD. We show using GPU A-SGD it is possible to speed up training of large convolutional neural networks useful for computer vision. We believe GPU A-SGD will make it possible to train larger networks on larger training sets in a reasonable amount of time.\n    ",
        "submission_date": "2013-12-21T00:00:00",
        "last_modified_date": "2013-12-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.6199",
        "title": "Intriguing properties of neural networks",
        "authors": [
            "Christian Szegedy",
            "Wojciech Zaremba",
            "Ilya Sutskever",
            "Joan Bruna",
            "Dumitru Erhan",
            "Ian Goodfellow",
            "Rob Fergus"
        ],
        "abstract": "Deep neural networks are highly expressive models that have recently achieved state of the art performance on speech and visual recognition tasks. While their expressiveness is the reason they succeed, it also causes them to learn uninterpretable solutions that could have counter-intuitive properties. In this paper we report two such properties.\n",
        "submission_date": "2013-12-21T00:00:00",
        "last_modified_date": "2014-02-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.6204",
        "title": "One-Shot Adaptation of Supervised Deep Convolutional Models",
        "authors": [
            "Judy Hoffman",
            "Eric Tzeng",
            "Jeff Donahue",
            "Yangqing Jia",
            "Kate Saenko",
            "Trevor Darrell"
        ],
        "abstract": "Dataset bias remains a significant barrier towards solving real world computer vision tasks. Though deep convolutional networks have proven to be a competitive approach for image classification, a question remains: have these models have solved the dataset bias problem? In general, training or fine-tuning a state-of-the-art deep model on a new domain requires a significant amount of data, which for many applications is simply not available. Transfer of models directly to new domains without adaptation has historically led to poor recognition performance. In this paper, we pose the following question: is a single image dataset, much larger than previously explored for adaptation, comprehensive enough to learn general deep models that may be effectively applied to new image domains? In other words, are deep CNNs trained on large amounts of labeled data as susceptible to dataset bias as previous methods have been shown to be? We show that a generic supervised deep CNN model trained on a large dataset reduces, but does not remove, dataset bias. Furthermore, we propose several methods for adaptation with deep models that are able to operate with little (one example per category) or no labeled domain specific data. Our experiments show that adaptation of deep models on benchmark visual domain adaptation datasets can provide a significant performance boost.\n    ",
        "submission_date": "2013-12-21T00:00:00",
        "last_modified_date": "2014-02-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.6219",
        "title": "Extracting Region of Interest for Palm Print Authentication",
        "authors": [
            "Kasturika B. Ray"
        ],
        "abstract": "Biometrics authentication is an effective method for automatically recognizing individuals. The authentication consists of an enrollment phase and an identification or verification phase. In the stages of enrollment known (training) samples after the pre-processing stage are used for suitable feature extraction to generate the template database. In the verification stage, the test sample is similarly pre processed and subjected to feature extraction modules, and then it is matched with the training feature templates to decide whether it is a genuine or not. This paper presents use of a region of interest (ROI) for palm print technology. First some of the existing methods for palm print identification have been introduced. Then focus has been given on extraction of a suitable smaller region from the acquired palm print to improve the identification method accuracy. Several existing work in the topic of region extraction have been examined. Subsequently, a simple and original method has then proposed for locating the ROI that can be effectively used for palm print analysis. The ROI extracted using this new technique is suitable for different types of processing as it creates a rectangular or square area around the center of activity represented by the lines, wrinkles and ridges of the palm print. The effectiveness of the ROI approach has been tested by integrating it with a texture based identification / authentication system proposed earlier. The improvement has been shown by comparing the identification accuracy rate before and after the ROI pre-processing.\n    ",
        "submission_date": "2013-12-21T00:00:00",
        "last_modified_date": "2013-12-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.6229",
        "title": "OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks",
        "authors": [
            "Pierre Sermanet",
            "David Eigen",
            "Xiang Zhang",
            "Michael Mathieu",
            "Rob Fergus",
            "Yann LeCun"
        ],
        "abstract": "We present an integrated framework for using Convolutional Networks for classification, localization and detection. We show how a multiscale and sliding window approach can be efficiently implemented within a ConvNet. We also introduce a novel deep learning approach to localization by learning to predict object boundaries. Bounding boxes are then accumulated rather than suppressed in order to increase detection confidence. We show that different tasks can be learned simultaneously using a single shared network. This integrated framework is the winner of the localization task of the ImageNet Large Scale Visual Recognition Challenge 2013 (ILSVRC2013) and obtained very competitive results for the detection and classifications tasks. In post-competition work, we establish a new state of the art for the detection task. Finally, we release a feature extractor from our best model called OverFeat.\n    ",
        "submission_date": "2013-12-21T00:00:00",
        "last_modified_date": "2014-02-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.6370",
        "title": "An Efficient Edge Detection Technique by Two Dimensional Rectangular Cellular Automata",
        "authors": [
            "Jahangir Mohammed",
            "Deepak Ranjan Nayak"
        ],
        "abstract": "This paper proposes a new pattern of two dimensional cellular automata linear rules that are used for efficient edge detection of an image. Since cellular automata is inherently parallel in nature, it has produced desired output within a unit time interval. We have observed four linear rules among 512 total linear rules of a rectangular cellular automata in adiabatic or reflexive boundary condition that produces an optimal result. These four rules are directly applied once to the images and produced edge detected output. We compare our results with the existing edge detection algorithms and found that our results shows better edge detection with an enhancement of edges.\n    ",
        "submission_date": "2013-12-22T00:00:00",
        "last_modified_date": "2013-12-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.6410",
        "title": "A Survey on Eye-Gaze Tracking Techniques",
        "authors": [
            "H.R. Chennamma",
            "Xiaohui Yuan"
        ],
        "abstract": "Study of eye-movement is being employed in Human Computer Interaction (HCI) research. Eye - gaze tracking is one of the most challenging problems in the area of computer vision. The goal of this paper is to present a review of latest research in this continued growth of remote eye-gaze tracking. This overview includes the basic definitions and terminologies, recent advances in the field and finally the need of future development in the field.\n    ",
        "submission_date": "2013-12-22T00:00:00",
        "last_modified_date": "2013-12-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.6430",
        "title": "Growing Regression Forests by Classification: Applications to Object Pose Estimation",
        "authors": [
            "Kota Hara",
            "Rama Chellappa"
        ],
        "abstract": "In this work, we propose a novel node splitting method for regression trees and incorporate it into the regression forest framework. Unlike traditional binary splitting, where the splitting rule is selected from a predefined set of binary splitting rules via trial-and-error, the proposed node splitting method first finds clusters of the training data which at least locally minimize the empirical loss without considering the input space. Then splitting rules which preserve the found clusters as much as possible are determined by casting the problem into a classification problem. Consequently, our new node splitting method enjoys more freedom in choosing the splitting rules, resulting in more efficient tree structures. In addition to the Euclidean target space, we present a variant which can naturally deal with a circular target space by the proper use of circular statistics. We apply the regression forest employing our node splitting to head pose estimation (Euclidean target space) and car direction estimation (circular target space) and demonstrate that the proposed method significantly outperforms state-of-the-art methods (38.5% and 22.5% error reduction respectively).\n    ",
        "submission_date": "2013-12-22T00:00:00",
        "last_modified_date": "2014-07-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.6506",
        "title": "Top Down Approach to Multiple Plane Detection",
        "authors": [
            "Prateek Singhal",
            "Aditya Deshpande",
            "N Dinesh Reddy",
            "K Madhava Krishna"
        ],
        "abstract": "Detecting multiple planes in images is a challenging problem, but one with many applications. Recent work such as J-Linkage and Ordered Residual Kernels have focussed on developing a domain independent approach to detect multiple structures. These multiple structure detection methods are then used for estimating multiple homographies given feature matches between two images. Features participating in the multiple homographies detected, provide us the multiple scene planes. We show that these methods provide locally optimal results and fail to merge detected planar patches to the true scene planes. These methods use only residues obtained on applying homography of one plane to another as cue for merging. In this paper, we develop additional cues such as local consistency of planes, local normals, texture etc. to perform better classification and merging . We formulate the classification as an MRF problem and use TRWS message passing algorithm to solve non metric energy terms and complex sparse graph structure. We show results on challenging dataset common in robotics navigation scenarios where our method shows accuracy of more than 85 percent on average while being close or same as the actual number of scene planes.\n    ",
        "submission_date": "2013-12-23T00:00:00",
        "last_modified_date": "2013-12-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.6594",
        "title": "Sequentially Generated Instance-Dependent Image Representations for Classification",
        "authors": [
            "Gabriel Dulac-Arnold",
            "Ludovic Denoyer",
            "Nicolas Thome",
            "Matthieu Cord",
            "Patrick Gallinari"
        ],
        "abstract": "In this paper, we investigate a new framework for image classification that adaptively generates spatial representations. Our strategy is based on a sequential process that learns to explore the different regions of any image in order to infer its category. In particular, the choice of regions is specific to each image, directed by the actual content of previously selected ",
        "submission_date": "2013-12-20T00:00:00",
        "last_modified_date": "2014-02-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.6599",
        "title": "Image Processing based Systems and Techniques for the Recognition of Ancient and Modern Coins",
        "authors": [
            "Shatrughan Modi",
            "Dr. Seema Bawa"
        ],
        "abstract": "Coins are frequently used in everyday life at various places like in banks, grocery stores, supermarkets, automated weighing machines, vending machines etc. So, there is a basic need to automate the counting and sorting of coins. For this machines need to recognize the coins very fast and accurately, as further transaction processing depends on this recognition. Three types of systems are available in the market: Mechanical method based systems, Electromagnetic method based systems and Image processing based systems. This paper presents an overview of available systems and techniques based on image processing to recognize ancient and modern coins.\n    ",
        "submission_date": "2013-12-23T00:00:00",
        "last_modified_date": "2013-12-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.6615",
        "title": "Automated Coin Recognition System using ANN",
        "authors": [
            "Shatrughan Modi",
            "Dr. Seema Bawa"
        ],
        "abstract": "Coins are integral part of our day to day life. We use coins everywhere like grocery store, banks, buses, trains etc. So it becomes a basic need that coins can be sorted and counted automatically. For this it is necessary that coins can be recognized automatically. In this paper we have developed an ANN (Artificial Neural Network) based Automated Coin Recognition System for the recognition of Indian Coins of denomination Rs. 1, 2, 5 and 10 with rotation invariance. We have taken images from both sides of coin. So this system is capable of recognizing coins from both sides. Features are extracted from images using techniques of Hough Transformation, Pattern Averaging etc. Then, the extracted features are passed as input to a trained Neural Network. 97.74% recognition rate has been achieved during the experiments i.e. only 2.26% miss recognition, which is quite encouraging.\n    ",
        "submission_date": "2013-12-23T00:00:00",
        "last_modified_date": "2013-12-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.6782",
        "title": "IVSS Integration of Color Feature Extraction Techniques for Intelligent Video Search Systems",
        "authors": [
            "Avinash N Bhute",
            "B. B. Meshram"
        ],
        "abstract": "As large amount of visual Information is available on web in form of images, graphics, animations and videos, so it is important in internet era to have an effective video search system. As there are number of video search engine (blinkx, Videosurf, Google, YouTube, etc.) which search for relevant videos based on user keyword or term, But very less commercial video search engine are available which search videos based on visual image/clip/video. In this paper we are recommending a system that will search for relevant video using color feature of video in response of user Query.\n    ",
        "submission_date": "2013-12-24T00:00:00",
        "last_modified_date": "2013-12-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.6826",
        "title": "3D Interest Point Detection via Discriminative Learning",
        "authors": [
            "Leizer Teran",
            "Philippos Mordohai"
        ],
        "abstract": "The task of detecting the interest points in 3D meshes has typically been handled by geometric methods. These methods, while greatly describing human preference, can be ill-equipped for handling the variety and subjectivity in human responses. Different tasks have different requirements for interest point detection; some tasks may necessitate high precision while other tasks may require high recall. Sometimes points with high curvature may be desirable, while in other cases high curvature may be an indication of noise. Geometric methods lack the required flexibility to adapt to such changes. As a consequence, interest point detection seems to be well suited for machine learning methods that can be trained to match the criteria applied on the annotated training data. In this paper, we formulate interest point detection as a supervised binary classification problem using a random forest as our classifier. Among other challenges, we are faced with an imbalanced learning problem due to the substantial difference in the priors between interest and non-interest points. We address this by re-sampling the training set. We validate the accuracy of our method and compare our results to those of five state of the art methods on a new, standard benchmark.\n    ",
        "submission_date": "2013-12-24T00:00:00",
        "last_modified_date": "2013-12-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.6834",
        "title": "Face Detection from still and Video Images using Unsupervised Cellular Automata with K means clustering algorithm",
        "authors": [
            "P. Kiran Sree",
            "I. Ramesh Babu"
        ],
        "abstract": "Pattern recognition problem rely upon the features inherent in the pattern of images. Face detection and recognition is one of the challenging research areas in the field of computer vision. In this paper, we present a method to identify skin pixels from still and video images using skin color. Face regions are identified from this skin pixel region. Facial features such as eyes, nose and mouth are then located. Faces are recognized from color images using an RBF based neural network. Unsupervised Cellular Automata with K means clustering algorithm is used to locate different facial elements. Orientation is corrected by using eyes. Parameters like inter eye distance, nose length, mouth position, Discrete Cosine Transform (DCT) coefficients etc. are computed and used for a Radial Basis Function (RBF) based neural network. This approach reliably works for face sequence with orientation in head, expressions etc.\n    ",
        "submission_date": "2013-12-15T00:00:00",
        "last_modified_date": "2013-12-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.6885",
        "title": "Deep learning for class-generic object detection",
        "authors": [
            "Brody Huval",
            "Adam Coates",
            "Andrew Ng"
        ],
        "abstract": "We investigate the use of deep neural networks for the novel task of class generic object detection. We show that neural networks originally designed for image recognition can be trained to detect objects within images, regardless of their class, including objects for which no bounding box labels have been provided. In addition, we show that bounding box labels yield a 1% performance increase on the ImageNet recognition challenge.\n    ",
        "submission_date": "2013-12-24T00:00:00",
        "last_modified_date": "2013-12-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.7085",
        "title": "Finding More Relevance: Propagating Similarity on Markov Random Field for Image Retrieval",
        "authors": [
            "Peng Lu",
            "Xujun Peng",
            "Xinshan Zhu",
            "Xiaojie Wang"
        ],
        "abstract": "To effectively retrieve objects from large corpus with high accuracy is a challenge task. In this paper, we propose a method that propagates visual feature level similarities on a Markov random field (MRF) to obtain a high level correspondence in image space for image pairs. The proposed correspondence between image pair reflects not only the similarity of low-level visual features but also the relations built through other images in the database and it can be easily integrated into the existing bag-of-visual-words(BoW) based systems to reduce the missing rate. We evaluate our method on the standard Oxford-5K, Oxford-105K and Paris-6K dataset. The experiment results show that the proposed method significantly improves the retrieval accuracy on three datasets and exceeds the current state-of-the-art retrieval performance.\n    ",
        "submission_date": "2013-12-26T00:00:00",
        "last_modified_date": "2013-12-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.7302",
        "title": "Learning Human Pose Estimation Features with Convolutional Networks",
        "authors": [
            "Arjun Jain",
            "Jonathan Tompson",
            "Mykhaylo Andriluka",
            "Graham W. Taylor",
            "Christoph Bregler"
        ],
        "abstract": "This paper introduces a new architecture for human pose estimation using a multi- layer convolutional network architecture and a modified learning technique that learns low-level features and higher-level weak spatial models. Unconstrained human pose estimation is one of the hardest problems in computer vision, and our new architecture and learning schema shows significant improvement over the current state-of-the-art results. The main contribution of this paper is showing, for the first time, that a specific variation of deep learning is able to outperform all existing traditional architectures on this task. The paper also discusses several lessons learned while researching alternatives, most notably, that it is possible to learn strong low-level feature detectors on features that might even just cover a few pixels in the image. Higher-level spatial models improve somewhat the overall result, but to a much lesser extent then expected. Many researchers previously argued that the kinematic structure and top-down information is crucial for this domain, but with our purely bottom up, and weak spatial model, we could improve other more complicated architectures that currently produce the best results. This mirrors what many other researchers, like those in the speech recognition, object recognition, and other domains have experienced.\n    ",
        "submission_date": "2013-12-27T00:00:00",
        "last_modified_date": "2014-04-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.7335",
        "title": "Correlation-based construction of neighborhood and edge features",
        "authors": [
            "Bal\u00e1zs K\u00e9gl"
        ],
        "abstract": "Motivated by an abstract notion of low-level edge detector filters, we propose a simple method of unsupervised feature construction based on pairwise statistics of features. In the first step, we construct neighborhoods of features by regrouping features that correlate. Then we use these subsets as filters to produce new neighborhood features. Next, we connect neighborhood features that correlate, and construct edge features by subtracting the correlated neighborhood features of each other. To validate the usefulness of the constructed features, we ran ",
        "submission_date": "2013-12-20T00:00:00",
        "last_modified_date": "2014-02-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.7345",
        "title": "Lesion Border Detection in Dermoscopy Images Using Ensembles of Thresholding Methods",
        "authors": [
            "M. Emre Celebi",
            "Quan Wen",
            "Sae Hwang",
            "Hitoshi Iyatomi",
            "Gerald Schaefer"
        ],
        "abstract": "Dermoscopy is one of the major imaging modalities used in the diagnosis of melanoma and other pigmented skin lesions. Due to the difficulty and subjectivity of human interpretation, automated analysis of dermoscopy images has become an important research area. Border detection is often the first step in this analysis. In many cases, the lesion can be roughly separated from the background skin using a thresholding method applied to the blue channel. However, no single thresholding method appears to be robust enough to successfully handle the wide variety of dermoscopy images encountered in clinical practice. In this paper, we present an automated method for detecting lesion borders in dermoscopy images using ensembles of thresholding methods. Experiments on a difficult set of 90 images demonstrate that the proposed method is robust, fast, and accurate when compared to nine state-of-the-art methods.\n    ",
        "submission_date": "2013-12-26T00:00:00",
        "last_modified_date": "2013-12-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.7366",
        "title": "Monte Carlo non local means: Random sampling for large-scale image filtering",
        "authors": [
            "Stanley H. Chan",
            "Todd Zickler",
            "Yue M. Lu"
        ],
        "abstract": "We propose a randomized version of the non-local means (NLM) algorithm for large-scale image filtering. The new algorithm, called Monte Carlo non-local means (MCNLM), speeds up the classical NLM by computing a small subset of image patch distances, which are randomly selected according to a designed sampling pattern. We make two contributions. First, we analyze the performance of the MCNLM algorithm and show that, for large images or large external image databases, the random outcomes of MCNLM are tightly concentrated around the deterministic full NLM result. In particular, our error probability bounds show that, at any given sampling ratio, the probability for MCNLM to have a large deviation from the original NLM solution decays exponentially as the size of the image or database grows. Second, we derive explicit formulas for optimal sampling patterns that minimize the error probability bound by exploiting partial knowledge of the pairwise similarity weights. Numerical experiments show that MCNLM is competitive with other state-of-the-art fast NLM algorithms for single-image denoising. When applied to denoising images using an external database containing ten billion patches, MCNLM returns a randomized solution that is within 0.2 dB of the full NLM solution while reducing the runtime by three orders of magnitude.\n    ",
        "submission_date": "2013-12-27T00:00:00",
        "last_modified_date": "2014-05-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.7414",
        "title": "Stopping Rules for Bag-of-Words Image Search and Its Application in Appearance-Based Localization",
        "authors": [
            "Kiana Hajebi",
            "Hong Zhang"
        ],
        "abstract": "We propose a technique to improve the search efficiency of the bag-of-words (BoW) method for image retrieval. We introduce a notion of difficulty for the image matching problems and propose methods that reduce the amount of computations required for the feature vector-quantization task in BoW by exploiting the fact that easier queries need less computational resources. Measuring the difficulty of a query and stopping the search accordingly is formulated as a stopping problem. We introduce stopping rules that terminate the image search depending on the difficulty of each query, thereby significantly reducing the computational cost. Our experimental results show the effectiveness of our approach when it is applied to appearance-based localization problem.\n    ",
        "submission_date": "2013-12-28T00:00:00",
        "last_modified_date": "2013-12-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.7446",
        "title": "Shape Primitive Histogram: A Novel Low-Level Face Representation for Face Recognition",
        "authors": [
            "Sheng Huang",
            "Dan Yang",
            "Haopeng Zhang",
            "Luwen Huangfu",
            "Xiaohong Zhang"
        ],
        "abstract": "We further exploit the representational power of Haar wavelet and present a novel low-level face representation named Shape Primitives Histogram (SPH) for face recognition. Since human faces exist abundant shape features, we address the face representation issue from the perspective of the shape feature extraction. In our approach, we divide faces into a number of tiny shape fragments and reduce these shape fragments to several uniform atomic shape patterns called Shape Primitives. A convolution with Haar Wavelet templates is applied to each shape fragment to identify its belonging shape primitive. After that, we do a histogram statistic of shape primitives in each spatial local image patch for incorporating the spatial information. Finally, each face is represented as a feature vector via concatenating all the local histograms of shape primitives. Four popular face databases, namely ORL, AR, Yale-B and LFW-a databases, are employed to evaluate SPH and experimentally study the choices of the parameters. Extensive experimental results demonstrate that the proposed approach outperform the state-of-the-arts.\n    ",
        "submission_date": "2013-12-28T00:00:00",
        "last_modified_date": "2014-07-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.7469",
        "title": "Collaborative Discriminant Locality Preserving Projections With its Application to Face Recognition",
        "authors": [
            "Sheng Huang",
            "Dan Yang",
            "Dong Yang",
            "Ahmed Elgammal"
        ],
        "abstract": "We present a novel Discriminant Locality Preserving Projections (DLPP) algorithm named Collaborative Discriminant Locality Preserving Projection (CDLPP). In our algorithm, the discriminating power of DLPP are further exploited from two aspects. On the one hand, the global optimum of class scattering is guaranteed via using the between-class scatter matrix to replace the original denominator of DLPP. On the other hand, motivated by collaborative representation, an $L_2$-norm constraint is imposed to the projections to discover the collaborations of dimensions in the sample space. We apply our algorithm to face recognition. Three popular face databases, namely AR, ORL and LFW-A, are employed for evaluating the performance of CDLPP. Extensive experimental results demonstrate that CDLPP significantly improves the discriminating power of DLPP and outperforms the state-of-the-arts.\n    ",
        "submission_date": "2013-12-28T00:00:00",
        "last_modified_date": "2014-02-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.7511",
        "title": "A Novel Scheme for Generating Secure Face Templates Using BDA",
        "authors": [
            "Shraddha S. Shinde",
            "Prof. Anagha P. Khedkar"
        ],
        "abstract": "In identity management system, frequently used biometric recognition system needs awareness towards issue of protecting biometric template as far as more reliable solution is apprehensive. In sight of this biometric template protection algorithm should gratify the basic requirements viz. security, discriminability and cancelability. As no single template protection method is capable of satisfying these requirements, a novel scheme for face template generation and protection is proposed. The novel scheme is proposed to provide security and accuracy in new user enrolment and authentication process. This novel scheme takes advantage of both the hybrid approach and the binary discriminant analysis algorithm. This algorithm is designed on the basis of random projection, binary discriminant analysis and fuzzy commitment scheme. Publicly available benchmark face databases (FERET, FRGC, CMU-PIE) and other datasets are used for evaluation. The proposed novel scheme enhances the discriminability and recognition accuracy in terms of matching score of the face images for each stage and provides high security against potential attacks namely brute force and smart attacks. In this paper, we discuss results viz. averages matching score, computation time and security for hybrid approach and novel approach.\n    ",
        "submission_date": "2013-12-29T00:00:00",
        "last_modified_date": "2013-12-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.7557",
        "title": "A Novel Retinal Vessel Segmentation Based On Histogram Transformation Using 2-D Morlet Wavelet and Supervised Classification",
        "authors": [
            "Saeid Fazli",
            "Sevin Samadi"
        ],
        "abstract": "The appearance and structure of blood vessels in retinal images have an important role in diagnosis of diseases. This paper proposes a method for automatic retinal vessel segmentation. In this work, a novel preprocessing based on local histogram equalization is used to enhance the original image then pixels are classified as vessel and non-vessel using a classifier. For this classification, special feature vectors are organized based on responses to Morlet wavelet. Morlet wavelet is a continues transform which has the ability to filter existing noises after preprocessing. Bayesian classifier is used and Gaussian mixture model (GMM) is its likelihood function. The probability distributions are approximated according to training set of manual that has been segmented by a specialist. After this, morphological transforms are used in different directions to make the existing discontinuities uniform on the DRIVE database, it achieves the accuracy about 0.9571 which shows that it is an accurate method among the available ones for retinal vessel segmentation.\n    ",
        "submission_date": "2013-12-29T00:00:00",
        "last_modified_date": "2013-12-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.7560",
        "title": "Implementation of Hand Detection based Techniques for Human Computer Interaction",
        "authors": [
            "Amiraj Dhawan",
            "Vipul Honrao"
        ],
        "abstract": "The computer industry is developing at a fast pace. With this development almost all of the fields under computers have advanced in the past couple of decades. But the same technology is being used for human computer interaction that was used in 1970s. Even today the same type of keyboard and mouse is used for interacting with computer systems. With the recent boom in the mobile segment touchscreens have become popular for interaction with cell phones. But these touchscreens are rarely used on traditional systems. This paper tries to introduce methods for human computer interaction using the users hand which can be used both on traditional computer platforms as well as cell phones. The methods explain how the users detected hand can be used as input for applications and also explain applications that can take advantage of this type of interaction mechanism.\n    ",
        "submission_date": "2013-12-29T00:00:00",
        "last_modified_date": "2013-12-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.7570",
        "title": "Actions in the Eye: Dynamic Gaze Datasets and Learnt Saliency Models for Visual Recognition",
        "authors": [
            "Stefan Mathe",
            "Cristian Sminchisescu"
        ],
        "abstract": "Systems based on bag-of-words models from image features collected at maxima of sparse interest point operators have been used successfully for both computer visual object and action recognition tasks. While the sparse, interest-point based approach to recognition is not inconsistent with visual processing in biological systems that operate in `saccade and fixate' regimes, the methodology and emphasis in the human and the computer vision communities remains sharply distinct. Here, we make three contributions aiming to bridge this gap. First, we complement existing state-of-the art large scale dynamic computer vision annotated datasets like Hollywood-2 and UCF Sports with human eye movements collected under the ecological constraints of the visual action recognition task. To our knowledge these are the first large human eye tracking datasets to be collected and made publicly available for video, ",
        "submission_date": "2013-12-29T00:00:00",
        "last_modified_date": "2013-12-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.7573",
        "title": "A Novel Method for Automatic Segmentation of Brain Tumors in MRI Images",
        "authors": [
            "Saeid Fazli",
            "Parisa Nadirkhanlou"
        ],
        "abstract": "The brain tumor segmentation on MRI images is a very difficult and important task which is used in surgical and medical planning and assessments. If experts do the segmentation manually with their own medical knowledge, it will be time-consuming. Therefore, researchers propose methods and systems which can do the segmentation automatically and without any interference. In this article, an unsupervised automatic method for brain tumor segmentation on MRI images is presented. In this method, at first in the pre-processing level, the extra parts which are outside the skull and don't have any helpful information are removed and then anisotropic diffusion filter with 8-connected neighborhood is applied to the MRI images to remove noise. By applying the fast bounding box(FBB) algorithm, the tumor area is displayed on the MRI image with a bounding box and the central part is selected as sample points for training of a One Class SVM classifier. A database is also provided by the Zanjan MRI Center. The MRI images are related to 10 patients who have brain tumor. 100 T2-weighted MRI images are used in this study. Experimental results show the high precision and dependability of the proposed algorithm. The results are also highly helpful for specialists and radiologists to easily estimate the size and position of a tumor.\n    ",
        "submission_date": "2013-12-29T00:00:00",
        "last_modified_date": "2013-12-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.7715",
        "title": "Constrained Parametric Proposals and Pooling Methods for Semantic Segmentation in RGB-D Images",
        "authors": [
            "Dan Banica",
            "Cristian Sminchisescu"
        ],
        "abstract": "We focus on the problem of semantic segmentation based on RGB-D data, with emphasis on analyzing cluttered indoor scenes containing many instances from many visual categories. Our approach is based on a parametric figure-ground intensity and depth-constrained proposal process that generates spatial layout hypotheses at multiple locations and scales in the image followed by a sequential inference algorithm that integrates the proposals into a complete scene estimate. Our contributions can be summarized as proposing the following: (1) a generalization of parametric max flow figure-ground proposal methodology to take advantage of intensity and depth information, in order to systematically and efficiently generate the breakpoints of an underlying spatial model in polynomial time, (2) new region description methods based on second-order pooling over multiple features constructed using both intensity and depth channels, (3) an inference procedure that can resolve conflicts in overlapping spatial partitions, and handles scenes with a large number of objects category instances, of very different scales, (4) extensive evaluation of the impact of depth, as well as the effectiveness of a large number of descriptors, both pre-designed and automatically obtained using deep learning, in a difficult RGB-D semantic segmentation problem with 92 classes. We report state of the art results in the challenging NYU Depth v2 dataset, extended for RMRC 2013 Indoor Segmentation Challenge, where currently the proposed model ranks first, with an average score of 24.61% and a number of 39 classes won. Moreover, we show that by combining second-order and deep learning features, over 15% relative accuracy improvements can be additionally achieved. In a scene classification benchmark, our methodology further improves the state of the art by 24%.\n    ",
        "submission_date": "2013-12-30T00:00:00",
        "last_modified_date": "2014-07-31T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1301.1295",
        "title": "Time-Frequency Representation of Microseismic Signals using the Synchrosqueezing Transform",
        "authors": [
            "Roberto H. Herrera",
            "Jean-Baptiste Tary",
            "Mirko van der Baan"
        ],
        "abstract": "Resonance frequencies can provide useful information on the deformation occurring during fracturing experiments or $CO_2$ management, complementary to the microseismic event distribution. An accurate time-frequency representation is of crucial importance prior to interpreting the cause of resonance frequencies during microseismic experiments. The popular methods of Short-Time Fourier Transform (STFT) and wavelet analysis have limitations in representing close frequencies and dealing with fast varying instantaneous frequencies and this is often the nature of microseismic signals. The synchrosqueezing transform (SST) is a promising tool to track these resonant frequencies and provide a detailed time-frequency representation. Here we apply the synchrosqueezing transform to microseismic signals and also show its potential to general seismic signal processing applications.\n    ",
        "submission_date": "2013-01-07T00:00:00",
        "last_modified_date": "2013-01-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1301.1576",
        "title": "Optical Flow on Evolving Surfaces with an Application to the Analysis of 4D Microscopy Data",
        "authors": [
            "Clemens Kirisits",
            "Lukas F. Lang",
            "Otmar Scherzer"
        ],
        "abstract": "We extend the concept of optical flow to a dynamic non-Euclidean setting. Optical flow is traditionally computed from a sequence of flat images. It is the purpose of this paper to introduce variational motion estimation for images that are defined on an evolving surface. Volumetric microscopy images depicting a live zebrafish embryo serve as both biological motivation and test data.\n    ",
        "submission_date": "2013-01-08T00:00:00",
        "last_modified_date": "2013-05-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1301.1907",
        "title": "Moon Search Algorithms for NASA's Dawn Mission to Asteroid Vesta",
        "authors": [
            "Nargess Memarsadeghi",
            "Lucy A. McFadden",
            "David Skillman",
            "Brian McLean",
            "Max Mutchler",
            "Uri Carsenty",
            "Eric E. Palmer",
            "Dawn Mission's Satellite Working Group"
        ],
        "abstract": "A moon or natural satellite is a celestial body that orbits a planetary body such as a planet, dwarf planet, or an asteroid. Scientists seek understanding the origin and evolution of our solar system by studying moons of these bodies. Additionally, searches for satellites of planetary bodies can be important to protect the safety of a spacecraft as it approaches or orbits a planetary body. If a satellite of a celestial body is found, the mass of that body can also be calculated once its orbit is determined. Ensuring the Dawn spacecraft's safety on its mission to the asteroid (4) Vesta primarily motivated the work of Dawn's Satellite Working Group (SWG) in summer of 2011. Dawn mission scientists and engineers utilized various computational tools and techniques for Vesta's satellite search. The objectives of this paper are to 1) introduce the natural satellite search problem, 2) present the computational challenges, approaches, and tools used when addressing this problem, and 3) describe applications of various image processing and computational algorithms for performing satellite searches to the electronic imaging and computer science community. Furthermore, we hope that this communication would enable Dawn mission scientists to improve their satellite search algorithms and tools and be better prepared for performing the same investigation in 2015, when the spacecraft is scheduled to approach and orbit the dwarf planet (1) Ceres.\n    ",
        "submission_date": "2013-01-09T00:00:00",
        "last_modified_date": "2013-01-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1301.2298",
        "title": "Lattice Particle Filters",
        "authors": [
            "Dirk Ormoneit",
            "Christiane Lemieux",
            "David J. Fleet"
        ],
        "abstract": "A standard approach to approximate inference in state-space models isto apply a particle filter, e.g., the Condensation ",
        "submission_date": "2013-01-10T00:00:00",
        "last_modified_date": "2013-01-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1301.3193",
        "title": "Learning Graphical Model Parameters with Approximate Marginal Inference",
        "authors": [
            "Justin Domke"
        ],
        "abstract": "Likelihood based-learning of graphical models faces challenges of computational-complexity and robustness to model mis-specification. This paper studies methods that fit parameters directly to maximize a measure of the accuracy of predicted marginals, taking into account both model and inference approximations at training time. Experiments on imaging problems suggest marginalization-based learning performs better than likelihood-based approximations on difficult problems where the model being fit is approximate in nature.\n    ",
        "submission_date": "2013-01-15T00:00:00",
        "last_modified_date": "2013-01-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1301.3342",
        "title": "Barnes-Hut-SNE",
        "authors": [
            "Laurens van der Maaten"
        ],
        "abstract": "The paper presents an O(N log N)-implementation of t-SNE -- an embedding technique that is commonly used for the visualization of high-dimensional data in scatter plots and that normally runs in O(N^2). The new implementation uses vantage-point trees to compute sparse pairwise similarities between the input data objects, and it uses a variant of the Barnes-Hut algorithm - an algorithm used by astronomers to perform N-body simulations - to approximate the forces between the corresponding points in the embedding. Our experiments show that the new algorithm, called Barnes-Hut-SNE, leads to substantial computational advantages over standard t-SNE, and that it makes it possible to learn embeddings of data sets with millions of objects.\n    ",
        "submission_date": "2013-01-15T00:00:00",
        "last_modified_date": "2013-03-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1301.3461",
        "title": "Factorized Topic Models",
        "authors": [
            "Cheng Zhang",
            "Carl Henrik Ek",
            "Andreas Damianou",
            "Hedvig Kjellstrom"
        ],
        "abstract": "In this paper we present a modification to a latent topic model, which makes the model exploit supervision to produce a factorized representation of the observed data. The structured parameterization separately encodes variance that is shared between classes from variance that is private to each class by the introduction of a new prior over the topic space. The approach allows for a more eff{}icient inference and provides an intuitive interpretation of the data in terms of an informative signal together with structured noise. The factorized representation is shown to enhance inference performance for image, text, and video classification.\n    ",
        "submission_date": "2013-01-15T00:00:00",
        "last_modified_date": "2013-04-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1301.3468",
        "title": "Boltzmann Machines and Denoising Autoencoders for Image Denoising",
        "authors": [
            "Kyunghyun Cho"
        ],
        "abstract": "Image denoising based on a probabilistic model of local image patches has been employed by various researchers, and recently a deep (denoising) autoencoder has been proposed by Burger et al. [2012] and Xie et al. [2012] as a good model for this. In this paper, we propose that another popular family of models in the field of deep learning, called Boltzmann machines, can perform image denoising as well as, or in certain cases of high level of noise, better than denoising autoencoders. We empirically evaluate the two models on three different sets of images with different types and levels of noise. Throughout the experiments we also examine the effect of the depth of the models. The experiments confirmed our claim and revealed that the performance can be improved by adding more hidden layers, especially when the level of noise is high.\n    ",
        "submission_date": "2013-01-15T00:00:00",
        "last_modified_date": "2013-03-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1301.3476",
        "title": "Pushing Stochastic Gradient towards Second-Order Methods -- Backpropagation Learning with Transformations in Nonlinearities",
        "authors": [
            "Tommi Vatanen",
            "Tapani Raiko",
            "Harri Valpola",
            "Yann LeCun"
        ],
        "abstract": "Recently, we proposed to transform the outputs of each hidden neuron in a multi-layer perceptron network to have zero output and zero slope on average, and use separate shortcut connections to model the linear dependencies instead. We continue the work by firstly introducing a third transformation to normalize the scale of the outputs of each hidden neuron, and secondly by analyzing the connections to second order optimization methods. We show that the transformations make a simple stochastic gradient behave closer to second-order optimization methods and thus speed up learning. This is shown both in theory and with experiments. The experiments on the third transformation show that while it further increases the speed of learning, it can also hurt performance by converging to a worse local optimum, where both the inputs and outputs of many hidden neurons are close to zero.\n    ",
        "submission_date": "2013-01-15T00:00:00",
        "last_modified_date": "2013-03-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1301.3530",
        "title": "The Neural Representation Benchmark and its Evaluation on Brain and Machine",
        "authors": [
            "Charles F. Cadieu",
            "Ha Hong",
            "Dan Yamins",
            "Nicolas Pinto",
            "Najib J. Majaj",
            "James J. DiCarlo"
        ],
        "abstract": "A key requirement for the development of effective learning representations is their evaluation and comparison to representations we know to be effective. In natural sensory domains, the community has viewed the brain as a source of inspiration and as an implicit benchmark for success. However, it has not been possible to directly test representational learning algorithms directly against the representations contained in neural systems. Here, we propose a new benchmark for visual representations on which we have directly tested the neural representation in multiple visual cortical areas in macaque (utilizing data from [Majaj et al., 2012]), and on which any computer vision algorithm that produces a feature space can be tested. The benchmark measures the effectiveness of the neural or machine representation by computing the classification loss on the ordered eigendecomposition of a kernel matrix [Montavon et al., 2011]. In our analysis we find that the neural representation in visual area IT is superior to visual area V4. In our analysis of representational learning algorithms, we find that three-layer models approach the representational performance of V4 and the algorithm in [Le et al., 2012] surpasses the performance of V4. Impressively, we find that a recent supervised algorithm [Krizhevsky et al., 2012] achieves performance comparable to that of IT for an intermediate level of image variation difficulty, and surpasses IT at a higher difficulty level. We believe this result represents a major milestone: it is the first learning algorithm we have found that exceeds our current estimate of IT representation performance. We hope that this benchmark will assist the community in matching the representational performance of visual cortex and will serve as an initial rallying point for further correspondence between representations derived in brains and machines.\n    ",
        "submission_date": "2013-01-15T00:00:00",
        "last_modified_date": "2013-01-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1301.3541",
        "title": "Deep Predictive Coding Networks",
        "authors": [
            "Rakesh Chalasani",
            "Jose C. Principe"
        ],
        "abstract": "The quality of data representation in deep learning methods is directly related to the prior model imposed on the representations; however, generally used fixed priors are not capable of adjusting to the context in the data. To address this issue, we propose deep predictive coding networks, a hierarchical generative model that empirically alters priors on the latent representations in a dynamic and context-sensitive manner. This model captures the temporal dependencies in time-varying signals and uses top-down information to modulate the representation in lower layers. The centerpiece of our model is a novel procedure to infer sparse states of a dynamic model which is used for feature extraction. We also extend this feature extraction block to introduce a pooling function that captures locally invariant representations. When applied on a natural video data, we show that our method is able to learn high-level visual features. We also demonstrate the role of the top-down connections by showing the robustness of the proposed model to structured noise.\n    ",
        "submission_date": "2013-01-16T00:00:00",
        "last_modified_date": "2013-03-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1301.3551",
        "title": "Information Theoretic Learning with Infinitely Divisible Kernels",
        "authors": [
            "Luis G. Sanchez Giraldo",
            "Jose C. Principe"
        ],
        "abstract": "In this paper, we develop a framework for information theoretic learning based on infinitely divisible matrices. We formulate an entropy-like functional on positive definite matrices based on Renyi's axiomatic definition of entropy and examine some key properties of this functional that lead to the concept of infinite divisibility. The proposed formulation avoids the plug in estimation of density and brings along the representation power of reproducing kernel Hilbert spaces. As an application example, we derive a supervised metric learning algorithm using a matrix based analogue to conditional entropy achieving results comparable with the state of the art.\n    ",
        "submission_date": "2013-01-16T00:00:00",
        "last_modified_date": "2013-06-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1301.3575",
        "title": "Kernelized Locality-Sensitive Hashing for Semi-Supervised Agglomerative Clustering",
        "authors": [
            "Boyi Xie",
            "Shuheng Zheng"
        ],
        "abstract": "Large scale agglomerative clustering is hindered by computational burdens. We propose a novel scheme where exact inter-instance distance calculation is replaced by the Hamming distance between Kernelized Locality-Sensitive Hashing (KLSH) hashed values. This results in a method that drastically decreases computation time. Additionally, we take advantage of certain labeled data points via distance metric learning to achieve a competitive precision and recall comparing to K-Means but in much less computation time.\n    ",
        "submission_date": "2013-01-16T00:00:00",
        "last_modified_date": "2013-01-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1301.3583",
        "title": "Big Neural Networks Waste Capacity",
        "authors": [
            "Yann N. Dauphin",
            "Yoshua Bengio"
        ],
        "abstract": "This article exposes the failure of some big neural networks to leverage added capacity to reduce underfitting. Past research suggest diminishing returns when increasing the size of neural networks. Our experiments on ImageNet LSVRC-2010 show that this may be due to the fact there are highly diminishing returns for capacity in terms of training error, leading to underfitting. This suggests that the optimization method - first order gradient descent - fails at this regime. Directly attacking this problem, either through the optimization method or the choices of parametrization, may allow to improve the generalization error on large datasets, for which a large capacity is required.\n    ",
        "submission_date": "2013-01-16T00:00:00",
        "last_modified_date": "2013-03-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1301.3590",
        "title": "Tree structured sparse coding on cubes",
        "authors": [
            "Arthur Szlam"
        ],
        "abstract": "A brief description of tree structured sparse coding on the binary cube.\n    ",
        "submission_date": "2013-01-16T00:00:00",
        "last_modified_date": "2013-01-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1301.3592",
        "title": "Deep Learning for Detecting Robotic Grasps",
        "authors": [
            "Ian Lenz",
            "Honglak Lee",
            "Ashutosh Saxena"
        ],
        "abstract": "We consider the problem of detecting robotic grasps in an RGB-D view of a scene containing objects. In this work, we apply a deep learning approach to solve this problem, which avoids time-consuming hand-design of features. This presents two main challenges. First, we need to evaluate a huge number of candidate grasps. In order to make detection fast, as well as robust, we present a two-step cascaded structure with two deep networks, where the top detections from the first are re-evaluated by the second. The first network has fewer features, is faster to run, and can effectively prune out unlikely candidate grasps. The second, with more features, is slower but has to run only on the top few detections. Second, we need to handle multimodal inputs well, for which we present a method to apply structured regularization on the weights based on multimodal group regularization. We demonstrate that our method outperforms the previous state-of-the-art methods in robotic grasp detection, and can be used to successfully execute grasps on two different robotic platforms.\n    ",
        "submission_date": "2013-01-16T00:00:00",
        "last_modified_date": "2014-08-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1301.3683",
        "title": "Convex Variational Image Restoration with Histogram Priors",
        "authors": [
            "Paul Swoboda",
            "Christoph Schn\u00f6rr"
        ],
        "abstract": "We present a novel variational approach to image restoration (e.g., denoising, inpainting, labeling) that enables to complement established variational approaches with a histogram-based prior enforcing closeness of the solution to some given empirical measure. By minimizing a single objective function, the approach utilizes simultaneously two quite different sources of information for restoration: spatial context in terms of some smoothness prior and non-spatial statistics in terms of the novel prior utilizing the Wasserstein distance between probability measures. We study the combination of the functional lifting technique with two different relaxations of the histogram prior and derive a jointly convex variational approach. Mathematical equivalence of both relaxations is established and cases where optimality holds are discussed. Additionally, we present an efficient algorithmic scheme for the numerical treatment of the presented model. Experiments using the basic total-variation based denoising approach as a case study demonstrate our novel regularization approach.\n    ",
        "submission_date": "2013-01-16T00:00:00",
        "last_modified_date": "2013-07-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1301.3775",
        "title": "Discriminative Recurrent Sparse Auto-Encoders",
        "authors": [
            "Jason Tyler Rolfe",
            "Yann LeCun"
        ],
        "abstract": "We present the discriminative recurrent sparse auto-encoder model, comprising a recurrent encoder of rectified linear units, unrolled for a fixed number of iterations, and connected to two linear decoders that reconstruct the input and predict its supervised classification. Training via backpropagation-through-time initially minimizes an unsupervised sparse reconstruction error; the loss function is then augmented with a discriminative term on the supervised classification. The depth implicit in the temporally-unrolled form allows the system to exhibit all the power of deep networks, while substantially reducing the number of trainable parameters.\n",
        "submission_date": "2013-01-16T00:00:00",
        "last_modified_date": "2013-03-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1301.4083",
        "title": "Knowledge Matters: Importance of Prior Information for Optimization",
        "authors": [
            "\u00c7a\u011flar G\u00fcl\u00e7ehre",
            "Yoshua Bengio"
        ],
        "abstract": "We explore the effect of introducing prior information into the intermediate level of neural networks for a learning task on which all the state-of-the-art machine learning algorithms tested failed to learn. We motivate our work from the hypothesis that humans learn such intermediate concepts from other individuals via a form of supervision or guidance using a curriculum. The experiments we have conducted provide positive evidence in favor of this hypothesis. In our experiments, a two-tiered MLP architecture is trained on a dataset with 64x64 binary inputs images, each image with three sprites. The final task is to decide whether all the sprites are the same or one of them is different. Sprites are pentomino tetris shapes and they are placed in an image with different locations using scaling and rotation transformations. The first part of the two-tiered MLP is pre-trained with intermediate-level targets being the presence of sprites at each location, while the second part takes the output of the first part as input and predicts the final task's target binary event. The two-tiered MLP architecture, with a few tens of thousand examples, was able to learn the task perfectly, whereas all other algorithms (include unsupervised pre-training, but also traditional algorithms like SVMs, decision trees and boosting) all perform no better than chance. We hypothesize that the optimization difficulty involved when the intermediate pre-training is not performed is due to the {\\em composition} of two highly non-linear tasks. Our findings are also consistent with hypotheses on cultural learning inspired by the observations of optimization problems with deep learning, presumably because of effective local minima.\n    ",
        "submission_date": "2013-01-17T00:00:00",
        "last_modified_date": "2013-07-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1301.4157",
        "title": "On the Product Rule for Classification Problems",
        "authors": [
            "Marcelo Cicconet"
        ],
        "abstract": "We discuss theoretical aspects of the product rule for classification problems in supervised machine learning for the case of combining classifiers. We show that (1) the product rule arises from the MAP classifier supposing equivalent priors and conditional independence given a class; (2) under some conditions, the product rule is equivalent to minimizing the sum of the squared distances to the respective centers of the classes related with different features, such distances being weighted by the spread of the classes; (3) observing some hypothesis, the product rule is equivalent to concatenating the vectors of features.\n    ",
        "submission_date": "2013-01-17T00:00:00",
        "last_modified_date": "2013-01-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1301.4862",
        "title": "Active Learning of Inverse Models with Intrinsically Motivated Goal Exploration in Robots",
        "authors": [
            "Adrien Baranes",
            "Pierre-Yves Oudeyer"
        ],
        "abstract": "We introduce the Self-Adaptive Goal Generation - Robust Intelligent Adaptive Curiosity (SAGG-RIAC) architecture as an intrinsi- cally motivated goal exploration mechanism which allows active learning of inverse models in high-dimensional redundant robots. This allows a robot to efficiently and actively learn distributions of parameterized motor skills/policies that solve a corresponding distribution of parameterized tasks/goals. The architecture makes the robot sample actively novel parameterized tasks in the task space, based on a measure of competence progress, each of which triggers low-level goal-directed learning of the motor policy pa- rameters that allow to solve it. For both learning and generalization, the system leverages regression techniques which allow to infer the motor policy parameters corresponding to a given novel parameterized task, and based on the previously learnt correspondences between policy and task parameters. We present experiments with high-dimensional continuous sensorimotor spaces in three different robotic setups: 1) learning the inverse kinematics in a highly-redundant robotic arm, 2) learning omnidirectional locomotion with motor primitives in a quadruped robot, 3) an arm learning to control a fishing rod with a flexible wire. We show that 1) exploration in the task space can be a lot faster than exploration in the actuator space for learning inverse models in redundant robots; 2) selecting goals maximizing competence progress creates developmental trajectories driving the robot to progressively focus on tasks of increasing complexity and is statistically significantly more efficient than selecting tasks randomly, as well as more efficient than different standard active motor babbling methods; 3) this architecture allows the robot to actively discover which parts of its task space it can learn to reach and which part it cannot.\n    ",
        "submission_date": "2013-01-21T00:00:00",
        "last_modified_date": "2013-01-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1301.5348",
        "title": "Why Size Matters: Feature Coding as Nystrom Sampling",
        "authors": [
            "Oriol Vinyals",
            "Yangqing Jia",
            "Trevor Darrell"
        ],
        "abstract": "Recently, the computer vision and machine learning community has been in favor of feature extraction pipelines that rely on a coding step followed by a linear classifier, due to their overall simplicity, well understood properties of linear classifiers, and their computational efficiency. In this paper we propose a novel view of this pipeline based on kernel methods and Nystrom sampling. In particular, we focus on the coding of a data point with a local representation based on a dictionary with fewer elements than the number of data points, and view it as an approximation to the actual function that would compute pair-wise similarity to all data points (often too many to compute in practice), followed by a Nystrom sampling step to select a subset of all data points.\n",
        "submission_date": "2013-01-15T00:00:00",
        "last_modified_date": "2013-04-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1301.6701",
        "title": "Multi-objects association in perception of dynamical situation",
        "authors": [
            "Dominique Gruyer",
            "Veronique Berge-Cherfaoui"
        ],
        "abstract": "In current perception systems applied to the rebuilding of the environment for intelligent vehicles, the part reserved to object association for the tracking is increasingly significant. This allows firstly to follow the objects temporal evolution and secondly to increase the reliability of environment perception. We propose in this communication the development of a multi-objects association algorithm with ambiguity removal entering into the design of such a dynamic perception system for intelligent vehicles. This algorithm uses the belief theory and data modelling with fuzzy mathematics in order to be able to handle inaccurate as well as uncertain information due to imperfect sensors. These theories also allow the fusion of numerical as well as symbolic data. We develop in this article the problem of matching between known and perceived objects. This makes it possible to update a dynamic environment map for a vehicle. The belief theory will enable us to quantify the belief in the association of each perceived object with each known object. Conflicts can appear in the case of object appearance or disappearance, or in the case of a confused situation or bad perception. These conflicts are removed or solved using an assignment algorithm, giving a solution called the \" best \" and so ensuring the tracking of some objects present in our environment.\n    ",
        "submission_date": "2013-01-23T00:00:00",
        "last_modified_date": "2013-01-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1301.6791",
        "title": "Guarantees of Total Variation Minimization for Signal Recovery",
        "authors": [
            "Jian-Feng Cai",
            "Weiyu Xu"
        ],
        "abstract": "In this paper, we consider using total variation minimization to recover signals whose gradients have a sparse support, from a small number of measurements. We establish the proof for the performance guarantee of total variation (TV) minimization in recovering \\emph{one-dimensional} signal with sparse gradient support. This partially answers the open problem of proving the fidelity of total variation minimization in such a setting \\cite{TVMulti}. In particular, we have shown that the recoverable gradient sparsity can grow linearly with the signal dimension when TV minimization is used. Recoverable sparsity thresholds of TV minimization are explicitly computed for 1-dimensional signal by using the Grassmann angle framework. We also extend our results to TV minimization for multidimensional signals. Stability of recovering signal itself using 1-D TV minimization has also been established through a property called \"almost Euclidean property for 1-dimensional TV norm\". We further give a lower bound on the number of random Gaussian measurements for recovering 1-dimensional signal vectors with $N$ elements and $K$-sparse gradients. Interestingly, the number of needed measurements is lower bounded by $\\Omega((NK)^{\\frac{1}{2}})$, rather than the $O(K\\log(N/K))$ bound frequently appearing in recovering $K$-sparse signal vectors.\n    ",
        "submission_date": "2013-01-28T00:00:00",
        "last_modified_date": "2013-10-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1301.6952",
        "title": "PyXNAT: XNAT in Python",
        "authors": [
            "Yannick Schwartz",
            "Alexis Barbot",
            "Benjamin Thyreau",
            "Vincent Frouin",
            "Ga\u00ebl Varoquaux",
            "Aditya Siram",
            "Daniel Marcus",
            "Jean-Baptiste Poline"
        ],
        "abstract": "As neuroimaging databases grow in size and complexity, the time researchers spend investigating and managing the data increases to the expense of data analysis. As a result, investigators rely more and more heavily on scripting using high-level languages to automate data management and processing tasks. For this, a structured and programmatic access to the data store is necessary. Web services are a first step toward this goal. They however lack in functionality and ease of use because they provide only low level interfaces to databases. We introduce here PyXNAT, a Python module that interacts with The Extensible Neuroimaging Archive Toolkit (XNAT) through native Python calls across multiple operating systems. The choice of Python enables PyXNAT to expose the XNAT Web Services and unify their features with a higher level and more expressive language. PyXNAT provides XNAT users direct access to all the scientific packages in Python. Finally PyXNAT aims to be efficient and easy to use, both as a backend library to build XNAT clients and as an alternative frontend from the command line.\n    ",
        "submission_date": "2013-01-29T00:00:00",
        "last_modified_date": "2013-01-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1302.0435",
        "title": "Parallel D2-Clustering: Large-Scale Clustering of Discrete Distributions",
        "authors": [
            "Yu Zhang",
            "James Z. Wang",
            "Jia Li"
        ],
        "abstract": "The discrete distribution clustering algorithm, namely D2-clustering, has demonstrated its usefulness in image classification and annotation where each object is represented by a bag of weighed vectors. The high computational complexity of the algorithm, however, limits its applications to large-scale problems. We present a parallel D2-clustering algorithm with substantially improved scalability. A hierarchical structure for parallel computing is devised to achieve a balance between the individual-node computation and the integration process of the algorithm. Additionally, it is shown that even with a single CPU, the hierarchical structure results in significant speed-up. Experiments on real-world large-scale image data, Youtube video data, and protein sequence data demonstrate the efficiency and wide applicability of the parallel D2-clustering algorithm. The loss in clustering accuracy is minor in comparison with the original sequential algorithm.\n    ",
        "submission_date": "2013-02-02T00:00:00",
        "last_modified_date": "2013-02-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1302.0870",
        "title": "Centrality-constrained graph embedding",
        "authors": [
            "Brian Baingana",
            "Georgios B. Giannakis"
        ],
        "abstract": "Visual rendering of graphs is a key task in the mapping of complex network data. Although most graph drawing algorithms emphasize aesthetic appeal, certain applications such as travel-time maps place more importance on visualization of structural network properties. The present paper advocates a graph embedding approach with centrality considerations to comply with node hierarchy. The problem is formulated as one of constrained multi-dimensional scaling (MDS), and it is solved via block coordinate descent iterations with successive approximations and guaranteed convergence to a KKT point. In addition, a regularization term enforcing graph smoothness is incorporated with the goal of reducing edge crossings. Experimental results demonstrate that the algorithm converges, and can be used to efficiently embed large graphs on the order of thousands of nodes.\n    ",
        "submission_date": "2013-02-04T00:00:00",
        "last_modified_date": "2013-02-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1302.1610",
        "title": "Adaptive low rank and sparse decomposition of video using compressive sensing",
        "authors": [
            "Fei Yang",
            "Hong Jiang",
            "Zuowei Shen",
            "Wei Deng",
            "Dimitris Metaxas"
        ],
        "abstract": "We address the problem of reconstructing and analyzing surveillance videos using compressive sensing. We develop a new method that performs video reconstruction by low rank and sparse decomposition adaptively. Background subtraction becomes part of the reconstruction. In our method, a background model is used in which the background is learned adaptively as the compressive measurements are processed. The adaptive method has low latency, and is more robust than previous methods. We will present experimental results to demonstrate the advantages of the proposed method.\n    ",
        "submission_date": "2013-02-06T00:00:00",
        "last_modified_date": "2013-05-31T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1302.1649",
        "title": "Eye-GUIDE (Eye-Gaze User Interface Design) Messaging for Physically-Impaired People",
        "authors": [
            "Rommel Anacan",
            "James Greggory Alcayde",
            "Retchel Antegra",
            "Leah Luna"
        ],
        "abstract": "Eye-GUIDE is an assistive communication tool designed for the paralyzed or physically impaired people who were unable to move parts of their bodies especially people whose communications are limited only to eye movements. The prototype consists of a camera and a computer. Camera captures images then it will be send to the computer, where the computer will be the one to interpret the data. Thus, Eye-GUIDE focuses on camera-based gaze tracking. The proponent designed the prototype to perform simple tasks and provides graphical user interface in order the paralyzed or physically impaired person can easily use it.\n    ",
        "submission_date": "2013-02-07T00:00:00",
        "last_modified_date": "2013-02-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1302.1772",
        "title": "An ANN-based Method for Detecting Vocal Fold Pathology",
        "authors": [
            "Vahid Majidnezhad",
            "Igor Kheidorov"
        ],
        "abstract": "There are different algorithms for vocal fold pathology diagnosis. These algorithms usually have three stages which are Feature Extraction, Feature Reduction and Classification. While the third stage implies a choice of a variety of machine learning methods, the first and second stages play a critical role in performance and accuracy of the classification system. In this paper we present initial study of feature extraction and feature reduction in the task of vocal fold pathology diagnosis. A new type of feature vector, based on wavelet packet decomposition and Mel-Frequency-Cepstral-Coefficients (MFCCs), is proposed. Also Principal Component Analysis (PCA) is used for feature reduction. An Artificial Neural Network is used as a classifier for evaluating the performance of our proposed method.\n    ",
        "submission_date": "2013-02-07T00:00:00",
        "last_modified_date": "2013-02-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1302.1947",
        "title": "A new compressive video sensing framework for mobile broadcast",
        "authors": [
            "Chengbo Li",
            "Hong Jiang",
            "Paul Wilford",
            "Yin Zhang",
            "Mike Scheutzow"
        ],
        "abstract": "A new video coding method based on compressive sampling is proposed. In this method, a video is coded using compressive measurements on video cubes. Video reconstruction is performed by minimization of total variation (TV) of the pixelwise DCT coefficients along the temporal direction. A new reconstruction algorithm is developed from TVAL3, an efficient TV minimization algorithm based on the alternating minimization and augmented Lagrangian methods. Video coding with this method is inherently scalable, and has applications in mobile broadcast.\n    ",
        "submission_date": "2013-02-08T00:00:00",
        "last_modified_date": "2013-02-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1302.2606",
        "title": "A new bio-inspired method for remote sensing imagery classification",
        "authors": [
            "Amghar Yasmina Teldja",
            "Fizazi Hadria"
        ],
        "abstract": "The problem of supervised classification of the satellite image is considered to be the task of grouping pixels into a number of homogeneous regions in space intensity. This paper proposes a novel approach that combines a radial basic function clustering network with a growing neural gas include utility factor classifier to yield improved solutions, obtained with previous networks. The double objective technique is first used to the development of a method to perform the satellite images classification, and finally, the implementation to address the issue of the number of nodes in the hidden layer of the classic Radial Basis functions network. Results demonstrating the effectiveness of the proposed technique are provided for numeric remote sensing imagery. Moreover, the remotely sensed image of Oran city in Algeria has been classified using the proposed technique to establish its utility.\n    ",
        "submission_date": "2013-02-11T00:00:00",
        "last_modified_date": "2013-11-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1302.3446",
        "title": "Adaptive Temporal Compressive Sensing for Video",
        "authors": [
            "Xin Yuan",
            "Jianbo Yang",
            "Patrick Llull",
            "Xuejun Liao",
            "Guillermo Sapiro",
            "David J. Brady",
            "Lawrence Carin"
        ],
        "abstract": "This paper introduces the concept of adaptive temporal compressive sensing (CS) for video. We propose a CS algorithm to adapt the compression ratio based on the scene's temporal complexity, computed from the compressed data, without compromising the quality of the reconstructed video. The temporal adaptivity is manifested by manipulating the integration time of the camera, opening the possibility to real-time implementation. The proposed algorithm is a generalized temporal CS approach that can be incorporated with a diverse set of existing hardware systems.\n    ",
        "submission_date": "2013-02-14T00:00:00",
        "last_modified_date": "2013-10-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1302.3702",
        "title": "A Fresnelet-Based Encryption of Medical Images using Arnold Transform",
        "authors": [
            "Muhammad Nazeer",
            "Bibi Nargis",
            "Yasir Mehmood Malik",
            "Dai-Gyoung Kim"
        ],
        "abstract": "Medical images are commonly stored in digital media and transmitted via Internet for certain uses. If a medical information image alters, this can lead to a wrong diagnosis which may create a serious health problem. Moreover, medical images in digital form can easily be modified by wiping off or adding small pieces of information intentionally for certain illegal purposes. Hence, the reliability of medical images is an important criterion in a hospital information system. In this paper, Fresnelet transform is employed along with appropriate handling of the Arnold transform and the discrete cosine transform to provide secure distribution of medical images. This method presents a new data hiding system in which steganography and cryptography are used to prevent unauthorized data access. The experimental results exhibit high imperceptibility for embedded images and significant encryption of information images.\n    ",
        "submission_date": "2013-02-15T00:00:00",
        "last_modified_date": "2013-02-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1302.4784",
        "title": "An Optical Watermarking Solution for Color Personal Identification Pictures",
        "authors": [
            "Tan Yi-zhou",
            "Liu Hai-bo",
            "Huang Shui-hua",
            "Sheng Ben-jian",
            "Pan Zhong-ming"
        ],
        "abstract": "This paper presents a new approach for embedding authentication information into image on printed materials based on optical projection technique. Our experimental setup consists of two parts, one is a common camera, and the other is a LCD projector, which project a pattern on personnel's body (especially on the face). The pattern, generated by a computer, act as the illumination light source with sinusoidal distribution and it is also the watermark signal. For a color image, the watermark is embedded into the blue channel. While we take pictures (256 *256 and 512*512, 567*390 pixels, respectively), an invisible mark is embedded directly into magnitude oefficients of Discrete Fourier transform (DFT) at exposure moment. Both optical an d digital correlation is suitable for detection of this type of watermark. The decoded watermark is a set of concentric circles or sectors in the DFT domain (middle frequencies region) which is robust to photographing, printing and scanning. The unlawful people modify or replace the original photograph, and make fake passport (drivers' license and so on). Experiments show, it is difficult to forge certificates in which a watermark was embedded by our projector-camera combination based on analogue watermark method rather than classical digital method.\n    ",
        "submission_date": "2013-02-20T00:00:00",
        "last_modified_date": "2013-02-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1302.5449",
        "title": "Nonparametric Basis Pursuit via Sparse Kernel-based Learning",
        "authors": [
            "Juan Andres Bazerque",
            "Georgios B. Giannakis"
        ],
        "abstract": "Signal processing tasks as fundamental as sampling, reconstruction, minimum mean-square error interpolation and prediction can be viewed under the prism of reproducing kernel Hilbert spaces. Endowing this vantage point with contemporary advances in sparsity-aware modeling and processing, promotes the nonparametric basis pursuit advocated in this paper as the overarching framework for the confluence of kernel-based learning (KBL) approaches leveraging sparse linear regression, nuclear-norm regularization, and dictionary learning. The novel sparse KBL toolbox goes beyond translating sparse parametric approaches to their nonparametric counterparts, to incorporate new possibilities such as multi-kernel selection and matrix smoothing. The impact of sparse KBL to signal processing applications is illustrated through test cases from cognitive radio sensing, microarray data imputation, and network traffic prediction.\n    ",
        "submission_date": "2013-02-21T00:00:00",
        "last_modified_date": "2013-02-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1302.5554",
        "title": "Self-similar prior and wavelet bases for hidden incompressible turbulent motion",
        "authors": [
            "Patrick H\u00e9as",
            "Fr\u00e9d\u00e9ric Lavancier",
            "Souleymane Kadri-Harouna"
        ],
        "abstract": "This work is concerned with the ill-posed inverse problem of estimating turbulent flows from the observation of an image sequence. From a Bayesian perspective, a divergence-free isotropic fractional Brownian motion (fBm) is chosen as a prior model for instantaneous turbulent velocity fields. This self-similar prior characterizes accurately second-order statistics of velocity fields in incompressible isotropic turbulence. Nevertheless, the associated maximum a posteriori involves a fractional Laplacian operator which is delicate to implement in practice. To deal with this issue, we propose to decompose the divergent-free fBm on well-chosen wavelet bases. As a first alternative, we propose to design wavelets as whitening filters. We show that these filters are fractional Laplacian wavelets composed with the Leray projector. As a second alternative, we use a divergence-free wavelet basis, which takes implicitly into account the incompressibility constraint arising from physics. Although the latter decomposition involves correlated wavelet coefficients, we are able to handle this dependence in practice. Based on these two wavelet decompositions, we finally provide effective and efficient algorithms to approach the maximum a posteriori. An intensive numerical evaluation proves the relevance of the proposed wavelet-based self-similar priors.\n    ",
        "submission_date": "2013-02-22T00:00:00",
        "last_modified_date": "2014-03-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1302.6105",
        "title": "Image restoration using sparse approximations of spatially varying blur operators in the wavelet domain",
        "authors": [
            "Paul Escande",
            "Pierre Weiss",
            "Francois Malgouyres"
        ],
        "abstract": "Restoration of images degraded by spatially varying blurs is an issue of increasing importance in the context of photography, satellite or microscopy imaging. One of the main difficulty to solve this problem comes from the huge dimensions of the blur matrix. It prevents the use of naive approaches for performing matrix-vector multiplications. In this paper, we propose to approximate the blur operator by a matrix sparse in the wavelet domain. We justify this approach from a mathematical point of view and investigate the approximation quality numerically. We finish by showing that the sparsity pattern of the matrix can be pre-defined, which is central in tasks such as blind deconvolution.\n    ",
        "submission_date": "2013-02-25T00:00:00",
        "last_modified_date": "2013-05-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1302.7039",
        "title": "Content Based Image Retrieval System Using NOHIS-tree",
        "authors": [
            "Mounira Taileb"
        ],
        "abstract": "Content-based image retrieval (CBIR) has been one of the most important research areas in computer vision. It is a widely used method for searching images in huge databases. In this paper we present a CBIR system called NOHIS-Search. The system is based on the indexing technique NOHIS-tree. The two phases of the system are described and the performance of the system is illustrated with the image database ImagEval. NOHIS-Search system was compared to other two CBIR systems; the first that using PDDP indexing algorithm and the second system is that using the sequential search. Results show that NOHIS-Search system outperforms the two other systems.\n    ",
        "submission_date": "2013-02-28T00:00:00",
        "last_modified_date": "2013-02-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1303.0018",
        "title": "Sparse Shape Reconstruction",
        "authors": [
            "Alireza Aghasi",
            "Justin Romberg"
        ],
        "abstract": "This paper introduces a new shape-based image reconstruction technique applicable to a large class of imaging problems formulated in a variational sense. Given a collection of shape priors (a shape dictionary), we define our problem as choosing the right elements and geometrically composing them through basic set operations to characterize desired regions in the image. This combinatorial problem can be relaxed and then solved using classical descent methods. The main component of this relaxation is forming certain compactly supported functions which we call \"knolls\", and reformulating the shape representation as a basis expansion in terms of such functions. To select suitable elements of the dictionary, our problem ultimately reduces to solving a nonlinear program with sparsity constraints. We provide a new sparse nonlinear reconstruction technique to approach this problem. The performance of proposed technique is demonstrated with some standard imaging problems including image segmentation, X-ray tomography and diffusive tomography.\n    ",
        "submission_date": "2013-02-28T00:00:00",
        "last_modified_date": "2013-02-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1303.1420",
        "title": "Verifying a platform for digital imaging: a multi-tool strategy",
        "authors": [
            "J\u00f3nathan Heras",
            "Gadea Mata",
            "Ana Romero",
            "Julio Rubio",
            "Rub\u00e9n S\u00e1enz"
        ],
        "abstract": "Fiji is a Java platform widely used by biologists and other experimental scientists to process digital images. In particular, in our research - made together with a biologists team; we use Fiji in some pre-processing steps before undertaking a homological digital processing of images. In a previous work, we have formalised the correctness of the programs which use homological techniques to analyse digital images. However, the verification of Fiji's pre-processing step was missed. In this paper, we present a multi-tool approach filling this gap, based on the combination of Why/Krakatoa, Coq and ACL2.\n    ",
        "submission_date": "2013-03-05T00:00:00",
        "last_modified_date": "2013-05-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1303.1460",
        "title": "On Considering Uncertainty and Alternatives in Low-Level Vision",
        "authors": [
            "Steven M. LaValle",
            "Seth A. Hutchinson"
        ],
        "abstract": "In this paper we address the uncertainty issues involved in the low-level vision task of image segmentation.  Researchers in computer vision have worked extensively on this problem, in which the goal is to partition (or segment) an image into regions that are homogeneous or uniform in some sense.  This segmentation is often utilized by some higher level process, such as an object recognition system. We show that by considering uncertainty in a Bayesian formalism, we can use statistical image models to build an approximate representation of a probability distribution over a space of alternative segmentations.  We give detailed descriptions of the various levels of uncertainty associated with this problem, discuss the interaction of prior and posterior distributions, and provide the operations for constructing this representation.\n    ",
        "submission_date": "2013-03-06T00:00:00",
        "last_modified_date": "2013-03-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1303.2211",
        "title": "Medical Information Embedding in Compressed Watermarked Intravascular Ultrasound Video",
        "authors": [
            "Nilanjan Dey",
            "Suvojit Acharjee",
            "Debalina Biswas",
            "Achintya Das",
            "Sheli Sinha Chaudhuri"
        ],
        "abstract": "In medical field, intravascular ultrasound (IVUS) is a tomographic imaging modality, which can identify the boundaries of different layers of blood vessels. IVUS can detect myocardial infarction (heart attack) that remains ignored and unattended when only angioplasty is done. During the past decade, it became easier for some individuals or groups to copy and transmits digital information without the permission of the owner. For increasing authentication and security of copyrights, digital watermarking, an information hiding technique, was introduced. Achieving watermarking technique with lesser amount of distortion in biomedical data is a challenging task. Watermark can be embedded into an image or in a video. As video data is a huge amount of information, therefore a large storage area is needed which is not feasible. In this case motion vector based video compression is done to reduce size. In this present paper, an Electronic Patient Record (EPR) is embedded as watermark within an IVUS video and then motion vector is calculated. This proposed method proves robustness as the extracted watermark has good PSNR value and less MSE.\n    ",
        "submission_date": "2013-03-09T00:00:00",
        "last_modified_date": "2013-03-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1303.2221",
        "title": "Clustering on Multi-Layer Graphs via Subspace Analysis on Grassmann Manifolds",
        "authors": [
            "Xiaowen Dong",
            "Pascal Frossard",
            "Pierre Vandergheynst",
            "Nikolai Nefedov"
        ],
        "abstract": "Relationships between entities in datasets are often of multiple nature, like geographical distance, social relationships, or common interests among people in a social network, for example. This information can naturally be modeled by a set of weighted and undirected graphs that form a global multilayer graph, where the common vertex set represents the entities and the edges on different layers capture the similarities of the entities in term of the different modalities. In this paper, we address the problem of analyzing multi-layer graphs and propose methods for clustering the vertices by efficiently merging the information provided by the multiple modalities. To this end, we propose to combine the characteristics of individual graph layers using tools from subspace analysis on a Grassmann manifold. The resulting combination can then be viewed as a low dimensional representation of the original data which preserves the most important information from diverse relationships between entities. We use this information in new clustering methods and test our algorithm on several synthetic and real world datasets where we demonstrate superior or competitive performances compared to baseline and state-of-the-art techniques. Our generic framework further extends to numerous analysis and learning problems that involve different types of information on graphs.\n    ",
        "submission_date": "2013-03-09T00:00:00",
        "last_modified_date": "2013-03-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1303.2292",
        "title": "Intelligent Approaches to interact with Machines using Hand Gesture Recognition in Natural way: A Survey",
        "authors": [
            "Ankit Chaudhary",
            "J. L. Raheja",
            "Karen Das",
            "Sonia Raheja"
        ],
        "abstract": "Hand gestures recognition (HGR) is one of the main areas of research for the engineers, scientists and bioinformatics. HGR is the natural way of Human Machine interaction and today many researchers in the academia and industry are working on different application to make interactions more easy, natural and convenient without wearing any extra device. HGR can be applied from games control to vision enabled robot control, from virtual reality to smart home systems. In this paper we are discussing work done in the area of hand gesture recognition where focus is on the intelligent approaches including soft computing based methods like artificial neural network, fuzzy logic, genetic algorithms etc. The methods in the preprocessing of image for segmentation and hand image construction also taken into study. Most researchers used fingertips for hand detection in appearance based modeling. Finally the comparison of results given by different researchers is also presented.\n    ",
        "submission_date": "2013-03-10T00:00:00",
        "last_modified_date": "2013-03-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1303.2330",
        "title": "Image compression using anti-forensics method",
        "authors": [
            "M.S.Sreelakshmi",
            "D. Venkataraman"
        ],
        "abstract": "A large number of image forensics methods are available which are capable of identifying image tampering. But these techniques are not capable of addressing the anti-forensics method which is able to hide the trace of image tampering. In this paper anti-forensics method for digital image compression has been proposed. This anti-forensics method is capable of removing the traces of image compression. Additionally, technique is also able to remove the traces of blocking artifact that are left by image compression algorithms that divide an image into segments during compression process. This method is targeted to remove the compression fingerprints of JPEG compression.\n    ",
        "submission_date": "2013-03-10T00:00:00",
        "last_modified_date": "2013-03-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1303.3134",
        "title": "Egocentric vision IT technologies for Alzheimer disease assessment and studies",
        "authors": [
            "Hugo Boujut",
            "Vincent Buso",
            "Guillaume Bourmaud",
            "Jenny Benois-Pineau",
            "R\u00e9mi M\u00e9gret",
            "Jean-Philippe Domenger",
            "Yann Ga\u00ebstel",
            "Jean-Fran\u00e7ois Dartigues"
        ],
        "abstract": "Egocentric vision technology consists in capturing the actions of persons from their own visual point of view using wearable camera sensors. We apply this new paradigm to instrumental activities monitoring with the objective of providing new tools for the clinical evaluation of the impact of the disease on persons with dementia. In this paper, we introduce the current state of the development of this technology and focus on two technology modules: automatic location estimation and visual saliency estimation for content interpretation.\n    ",
        "submission_date": "2013-03-13T00:00:00",
        "last_modified_date": "2013-03-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1303.3240",
        "title": "A Unified Framework for Probabilistic Component Analysis",
        "authors": [
            "Mihalis A. Nicolaou",
            "Stefanos Zafeiriou",
            "Maja Pantic"
        ],
        "abstract": "We present a unifying framework which reduces the construction of probabilistic component analysis techniques to a mere selection of the latent neighbourhood, thus providing an elegant and principled framework for creating novel component analysis models as well as constructing probabilistic equivalents of deterministic component analysis methods. Under our framework, we unify many very popular and well-studied component analysis algorithms, such as Principal Component Analysis (PCA), Linear Discriminant Analysis (LDA), Locality Preserving Projections (LPP) and Slow Feature Analysis (SFA), some of which have no probabilistic equivalents in literature thus far. We firstly define the Markov Random Fields (MRFs) which encapsulate the latent connectivity of the aforementioned component analysis techniques; subsequently, we show that the projection directions produced by all PCA, LDA, LPP and SFA are also produced by the Maximum Likelihood (ML) solution of a single joint probability density function, composed by selecting one of the defined MRF priors while utilising a simple observation model. Furthermore, we propose novel Expectation Maximization (EM) algorithms, exploiting the proposed joint PDF, while we generalize the proposed methodologies to arbitrary connectivities via parameterizable MRF products. Theoretical analysis and experiments on both simulated and real world data show the usefulness of the proposed framework, by deriving methods which well outperform state-of-the-art equivalents.\n    ",
        "submission_date": "2013-03-13T00:00:00",
        "last_modified_date": "2014-11-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1303.3605",
        "title": "A survey on sensing methods and feature extraction algorithms for SLAM problem",
        "authors": [
            "Adheen Ajay",
            "D. Venkataraman"
        ],
        "abstract": "This paper is a survey work for a bigger project for designing a Visual SLAM robot to generate 3D dense map of an unknown unstructured environment. A lot of factors have to be considered while designing a SLAM robot. Sensing method of the SLAM robot should be determined by considering the kind of environment to be modeled. Similarly the type of environment determines the suitable feature extraction method. This paper goes through the sensing methods used in some recently published papers. The main objective of this survey is to conduct a comparative study among the current sensing methods and feature extraction algorithms and to extract out the best for our work.\n    ",
        "submission_date": "2013-03-14T00:00:00",
        "last_modified_date": "2013-03-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1303.3987",
        "title": "$l_{2,p}$ Matrix Norm and Its Application in Feature Selection",
        "authors": [
            "Liping Wang",
            "Songcan Chen"
        ],
        "abstract": "Recently, $l_{2,1}$ matrix norm has been widely applied to many areas such as computer vision, pattern recognition, biological study and etc. As an extension of $l_1$ vector norm, the mixed $l_{2,1}$ matrix norm is often used to find jointly sparse solutions. Moreover, an efficient iterative algorithm has been designed to solve $l_{2,1}$-norm involved minimizations. Actually, computational studies have showed that $l_p$-regularization ($0<p<1$) is sparser than $l_1$-regularization, but the extension to matrix norm has been seldom considered. This paper presents a definition of mixed $l_{2,p}$ $(p\\in (0, 1])$ matrix pseudo norm which is thought as both generalizations of $l_p$ vector norm to matrix and $l_{2,1}$-norm to nonconvex cases $(0<p<1)$. Fortunately, an efficient unified algorithm is proposed to solve the induced $l_{2,p}$-norm $(p\\in (0, 1])$ optimization problems. The convergence can also be uniformly demonstrated for all $p\\in (0, 1]$. Typical $p\\in (0,1]$ are applied to select features in computational biology and the experimental results show that some choices of $0<p<1$ do improve the sparse pattern of using $p=1$.\n    ",
        "submission_date": "2013-03-16T00:00:00",
        "last_modified_date": "2013-03-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1303.5248",
        "title": "Methods Of Measurement The Three-Dimensional Wind Waves Spectra, Based On The Processing Of Video Images Of The Sea Surface",
        "authors": [
            "Boris M. Salin",
            "Mikhail B. Salin"
        ],
        "abstract": "Optical instruments for measuring surface-wave characteristics provide a better spatial and temporal resolution than other methods, but they face difficulties while converting the results of indirect measurements into absolute levels of the waves. We have solved this problem to some extent. In this paper, we propose an optical method for measuring the 3D power spectral density of the surface waves and spatio-temporal samples of the wave profiles. The method involves, first, synchronous recording of the brightness field over a patch of a rough surface and measurement of surface oscillations at one or more points and, second, filtering of the spatial image spectrum. Filter parameters are chosen to maximize the correlation of the surface oscillations recovered and measured at one or two points. In addition to the measurement procedure, the paper provides experimental results of measuring multidimensional spectra of roughness, which generally agree with theoretical expectations and the results of other authors.\n    ",
        "submission_date": "2013-03-21T00:00:00",
        "last_modified_date": "2014-04-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1303.5403",
        "title": "An Entropy-based Learning Algorithm of Bayesian Conditional Trees",
        "authors": [
            "Dan Geiger"
        ],
        "abstract": "This article offers a modification of Chow and Liu's learning algorithm in the context of handwritten digit recognition.  The modified algorithm directs the user to group digits into several classes consisting of digits that are hard to distinguish and then constructing an optimal conditional tree representation for each class of digits instead of for each single digit as done by Chow and Liu (1968).  Advantages and extensions of the new method are discussed.  Related works of Wong and Wang (1977) and Wong and Poon (1989) which offer a different entropy-based learning algorithm are shown to rest on inappropriate assumptions.\n    ",
        "submission_date": "2013-03-13T00:00:00",
        "last_modified_date": "2013-03-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1303.6001",
        "title": "Generalizing k-means for an arbitrary distance matrix",
        "authors": [
            "Bal\u00e1zs Szalkai"
        ],
        "abstract": "The original k-means clustering method works only if the exact vectors representing the data points are known. Therefore calculating the distances from the centroids needs vector operations, since the average of abstract data points is undefined. Existing algorithms can be extended for those cases when the sole input is the distance matrix, and the exact representing vectors are unknown. This extension may be named relational k-means after a notation for a similar algorithm invented for fuzzy clustering. A method is then proposed for generalizing k-means for scenarios when the data points have absolutely no connection with a Euclidean space.\n    ",
        "submission_date": "2013-03-24T00:00:00",
        "last_modified_date": "2013-03-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1303.6377",
        "title": "Simulation of Fractional Brownian Surfaces via Spectral Synthesis on Manifolds",
        "authors": [
            "Zachary Gelbaum",
            "Mathew Titus"
        ],
        "abstract": "Using the spectral decomposition of the Laplace-Beltrami operator we simulate fractal surfaces as random series of eigenfunctions. This approach allows us to generate random fields over smooth manifolds of arbitrary dimension, generalizing previous work with fractional Brownian motion with multi-dimensional parameter. We give examples of surfaces with and without boundary and discuss implementation.\n    ",
        "submission_date": "2013-03-26T00:00:00",
        "last_modified_date": "2013-03-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1303.7186",
        "title": "Large-Scale Automatic Reconstruction of Neuronal Processes from Electron Microscopy Images",
        "authors": [
            "Verena Kaynig",
            "Amelio Vazquez-Reina",
            "Seymour Knowles-Barley",
            "Mike Roberts",
            "Thouis R. Jones",
            "Narayanan Kasthuri",
            "Eric Miller",
            "Jeff Lichtman",
            "Hanspeter Pfister"
        ],
        "abstract": "Automated sample preparation and electron microscopy enables acquisition of very large image data sets. These technical advances are of special importance to the field of neuroanatomy, as 3D reconstructions of neuronal processes at the nm scale can provide new insight into the fine grained structure of the brain. Segmentation of large-scale electron microscopy data is the main bottleneck in the analysis of these data sets. In this paper we present a pipeline that provides state-of-the art reconstruction performance while scaling to data sets in the GB-TB range. First, we train a random forest classifier on interactive sparse user annotations. The classifier output is combined with an anisotropic smoothing prior in a Conditional Random Field framework to generate multiple segmentation hypotheses per image. These segmentations are then combined into geometrically consistent 3D objects by segmentation fusion. We provide qualitative and quantitative evaluation of the automatic segmentation and demonstrate large-scale 3D reconstructions of neuronal processes from a $\\mathbf{27,000}$ $\\mathbf{\\mu m^3}$ volume of brain tissue over a cube of $\\mathbf{30 \\; \\mu m}$ in each dimension corresponding to 1000 consecutive image sections. We also introduce Mojo, a proofreading tool including semi-automated correction of merge errors based on sparse user scribbles.\n    ",
        "submission_date": "2013-03-28T00:00:00",
        "last_modified_date": "2013-03-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.0243",
        "title": "Compressive adaptive computational ghost imaging",
        "authors": [
            "Marc A\u00dfmann",
            "Manfred Bayer"
        ],
        "abstract": "Compressive sensing is considered a huge breakthrough in signal acquisition. It allows recording an image consisting of $N^2$ pixels using much fewer than $N^2$ measurements if it can be transformed to a basis where most pixels take on negligibly small values. Standard compressive sensing techniques suffer from the computational overhead needed to reconstruct an image with typical computation times between hours and days and are thus not optimal for applications in physics and spectroscopy. We demonstrate an adaptive compressive sampling technique that performs measurements directly in a sparse basis. It needs much fewer than $N^2$ measurements without any computational overhead, so the result is available instantly.\n    ",
        "submission_date": "2013-03-31T00:00:00",
        "last_modified_date": "2013-03-31T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.0725",
        "title": "Improved Performance of Unsupervised Method by Renovated K-Means",
        "authors": [
            "P. Ashok",
            "G.M Kadhar Nawaz",
            "E. Elayaraja",
            "V. Vadivel"
        ],
        "abstract": "Clustering is a separation of data into groups of similar objects. Every group called cluster consists of objects that are similar to one another and dissimilar to objects of other groups. In this paper, the K-Means algorithm is implemented by three distance functions and to identify the optimal distance function for clustering methods. The proposed K-Means algorithm is compared with K-Means, Static Weighted K-Means (SWK-Means) and Dynamic Weighted K-Means (DWK-Means) algorithm by using Davis Bouldin index, Execution Time and Iteration count methods. Experimental results show that the proposed K-Means algorithm performed better on Iris and Wine dataset when compared with other three clustering methods.\n    ",
        "submission_date": "2013-03-11T00:00:00",
        "last_modified_date": "2013-03-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.1209",
        "title": "Highly comparative time-series analysis: The empirical structure of time series and their methods",
        "authors": [
            "Ben D. Fulcher",
            "Max A. Little",
            "Nick S. Jones"
        ],
        "abstract": "The process of collecting and organizing sets of observations represents a common theme throughout the history of science. However, despite the ubiquity of scientists measuring, recording, and analyzing the dynamics of different processes, an extensive organization of scientific time-series data and analysis methods has never been performed. Addressing this, annotated collections of over 35 000 real-world and model-generated time series and over 9000 time-series analysis algorithms are analyzed in this work. We introduce reduced representations of both time series, in terms of their properties measured by diverse scientific methods, and of time-series analysis methods, in terms of their behaviour on empirical time series, and use them to organize these interdisciplinary resources. This new approach to comparing across diverse scientific data and methods allows us to organize time-series datasets automatically according to their properties, retrieve alternatives to particular analysis methods developed in other scientific disciplines, and automate the selection of useful methods for time-series classification and regression tasks. The broad scientific utility of these tools is demonstrated on datasets of electroencephalograms, self-affine time series, heart beat intervals, speech signals, and others, in each case contributing novel analysis techniques to the existing literature. Highly comparative techniques that compare across an interdisciplinary literature can thus be used to guide more focused research in time-series analysis for applications across the scientific disciplines.\n    ",
        "submission_date": "2013-04-03T00:00:00",
        "last_modified_date": "2013-04-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.1262",
        "title": "Classification of Human Epithelial Type 2 Cell Indirect Immunofluoresence Images via Codebook Based Descriptors",
        "authors": [
            "Arnold Wiliem",
            "Yongkang Wong",
            "Conrad Sanderson",
            "Peter Hobson",
            "Shaokang Chen",
            "Brian C. Lovell"
        ],
        "abstract": "The Anti-Nuclear Antibody (ANA) clinical pathology test is commonly used to identify the existence of various diseases. A hallmark method for identifying the presence of ANAs is the Indirect Immunofluorescence method on Human Epithelial (HEp-2) cells, due to its high sensitivity and the large range of antigens that can be detected. However, the method suffers from numerous shortcomings, such as being subjective as well as time and labour intensive. Computer Aided Diagnostic (CAD) systems have been developed to address these problems, which automatically classify a HEp-2 cell image into one of its known patterns (eg., speckled, homogeneous). Most of the existing CAD systems use handpicked features to represent a HEp-2 cell image, which may only work in limited scenarios. In this paper, we propose a cell classification system comprised of a dual-region codebook-based descriptor, combined with the Nearest Convex Hull Classifier. We evaluate the performance of several variants of the descriptor on two publicly available datasets: ICPR HEp-2 cell classification contest dataset and the new SNPHEp-2 dataset. To our knowledge, this is the first time codebook-based descriptors are applied and studied in this domain. Experiments show that the proposed system has consistent high performance and is more robust than two recent CAD systems.\n    ",
        "submission_date": "2013-04-04T00:00:00",
        "last_modified_date": "2013-04-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.1408",
        "title": "Restoration of Images Corrupted by Impulse Noise and Mixed Gaussian Impulse Noise using Blind Inpainting",
        "authors": [
            "Ming Yan"
        ],
        "abstract": "This article studies the problem of image restoration of observed images corrupted by impulse noise and mixed Gaussian impulse noise. Since the pixels damaged by impulse noise contain no information about the true image, how to find this set correctly is a very important problem. We propose two methods based on blind inpainting and $\\ell_0$ minimization that can simultaneously find the damaged pixels and restore the image. By iteratively restoring the image and updating the set of damaged pixels, these methods have better performance than other methods, as shown in the experiments. In addition, we provide convergence analysis for these methods, these algorithms will converge to coordinatewise minimum points. In addition, they will converge to local minimum points (or with probability one) with some modifications in the algorithms.\n    ",
        "submission_date": "2013-04-04T00:00:00",
        "last_modified_date": "2013-04-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.1571",
        "title": "Hiding Image in Image by Five Modulus Method for Image Steganography",
        "authors": [
            "Firas A. Jassim"
        ],
        "abstract": "This paper is to create a practical steganographic implementation to hide color image (stego) inside another color image (cover). The proposed technique uses Five Modulus Method to convert the whole pixels within both the cover and the stego images into multiples of five. Since each pixels inside the stego image is divisible by five then the whole stego image could be divided by five to get new range of pixels 0..51. Basically, the reminder of each number that is not divisible by five is either 1,2,3 or 4 when divided by 5. Subsequently, then a 4-by-4 window size has been implemented to accommodate the proposed technique. For each 4-by-4 window inside the cover image, a number from 1 to 4 could be embedded secretly from the stego image. The previous discussion must be applied separately for each of the R, G, and B arrays. Moreover, a stego-key could be combined with the proposed algorithm to make it difficult for any adversary to extract the secret image from the cover image. Based on the PSNR value, the extracted stego image has high PSNR value. Hence this new steganography algorithm is very efficient to hide color images.\n    ",
        "submission_date": "2013-04-04T00:00:00",
        "last_modified_date": "2013-04-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.2014",
        "title": "Image Compression predicated on Recurrent Iterated Function Systems",
        "authors": [
            "Chol-Hui Yun",
            "W. Metzler",
            "M. Barski"
        ],
        "abstract": "Recurrent iterated function systems (RIFSs) are improvements of iterated function systems (IFSs) using elements of the theory of Marcovian stochastic processes which can produce more natural looking images. We construct new RIFSs consisting substantially of a vertical contraction factor function and nonlinear transformations. These RIFSs are applied to image compression.\n    ",
        "submission_date": "2013-04-07T00:00:00",
        "last_modified_date": "2013-04-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.2998",
        "title": "Detecting Directionality in Random Fields Using the Monogenic Signal",
        "authors": [
            "Sofia Olhede",
            "David Ram\u00edrez",
            "Peter J. Schreier"
        ],
        "abstract": "Detecting and analyzing directional structures in images is important in many applications since one-dimensional patterns often correspond to important features such as object contours or trajectories. Classifying a structure as directional or non-directional requires a measure to quantify the degree of directionality and a threshold, which needs to be chosen based on the statistics of the image. In order to do this, we model the image as a random field. So far, little research has been performed on analyzing directionality in random fields. In this paper, we propose a measure to quantify the degree of directionality based on the random monogenic signal, which enables a unique decomposition of a 2D signal into local amplitude, local orientation, and local phase. We investigate the second-order statistical properties of the monogenic signal for isotropic, anisotropic, and unidirectional random fields. We analyze our measure of directionality for finite-size sample images, and determine a threshold to distinguish between unidirectional and non-unidirectional random fields, which allows the automatic classification of images.\n    ",
        "submission_date": "2013-04-10T00:00:00",
        "last_modified_date": "2014-06-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.3098",
        "title": "Evidential Reasoning in Parallel Hierarchical Vision Programs",
        "authors": [
            "Ze-Nian Li",
            "Leonard Uhr"
        ],
        "abstract": "This paper presents an efficient adaptation and application of the Dempster-Shafer theory of evidence, one that can be used effectively in a massively parallel hierarchical system for visual pattern perception. It describes the techniques used, and shows in an extended example how they serve to improve the system's performance as it applies a multiple-level set of processes.\n    ",
        "submission_date": "2013-03-27T00:00:00",
        "last_modified_date": "2013-03-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.3573",
        "title": "Astronomical Image Denoising Using Dictionary Learning",
        "authors": [
            "Simon Beckouche",
            "Jean-Luc Starck",
            "Jalal Fadili"
        ],
        "abstract": "Astronomical images suffer a constant presence of multiple defects that are consequences of the intrinsic properties of the acquisition equipments, and atmospheric conditions. One of the most frequent defects in astronomical imaging is the presence of additive noise which makes a denoising step mandatory before processing data. During the last decade, a particular modeling scheme, based on sparse representations, has drawn the attention of an ever growing community of researchers. Sparse representations offer a promising framework to many image and signal processing tasks, especially denoising and restoration applications. At first, the harmonics, wavelets, and similar bases and overcomplete representations have been considered as candidate domains to seek the sparsest representation. A new generation of algorithms, based on data-driven dictionaries, evolved rapidly and compete now with the off-the-shelf fixed dictionaries. While designing a dictionary beforehand leans on a guess of the most appropriate representative elementary forms and functions, the dictionary learning framework offers to construct the dictionary upon the data themselves, which provides us with a more flexible setup to sparse modeling and allows to build more sophisticated dictionaries. In this paper, we introduce the Centered Dictionary Learning (CDL) method and we study its performances for astronomical image denoising. We show how CDL outperforms wavelet or classic dictionary learning denoising techniques on astronomical images, and we give a comparison of the effect of these different algorithms on the photometry of the denoised images.\n    ",
        "submission_date": "2013-04-12T00:00:00",
        "last_modified_date": "2013-04-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.3992",
        "title": "GPU Acclerated Automated Feature Extraction from Satellite Images",
        "authors": [
            "K. Phani Tejaswi",
            "D. Shanmukha Rao",
            "Thara Nair",
            "A. V. V. Prasad"
        ],
        "abstract": "The availability of large volumes of remote sensing data insists on higher degree of automation in feature extraction, making it a need of the ",
        "submission_date": "2013-04-15T00:00:00",
        "last_modified_date": "2013-04-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.4077",
        "title": "A new Bayesian ensemble of trees classifier for identifying multi-class labels in satellite images",
        "authors": [
            "Reshu Agarwal",
            "Pritam Ranjan",
            "Hugh Chipman"
        ],
        "abstract": "Classification of satellite images is a key component of many remote sensing applications. One of the most important products of a raw satellite image is the classified map which labels the image pixels into meaningful classes. Though several parametric and non-parametric classifiers have been developed thus far, accurate labeling of the pixels still remains a challenge. In this paper, we propose a new reliable multiclass-classifier for identifying class labels of a satellite image in remote sensing applications. The proposed multiclass-classifier is a generalization of a binary classifier based on the flexible ensemble of regression trees model called Bayesian Additive Regression Trees (BART). We used three small areas from the LANDSAT 5 TM image, acquired on August 15, 2009 (path/row: 08/29, L1T product, UTM map projection) over Kings County, Nova Scotia, Canada to classify the land-use. Several prediction accuracy and uncertainty measures have been used to compare the reliability of the proposed classifier with the state-of-the-art classifiers in remote sensing.\n    ",
        "submission_date": "2013-04-15T00:00:00",
        "last_modified_date": "2013-05-31T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.4344",
        "title": "Sparse Coding and Dictionary Learning for Symmetric Positive Definite Matrices: A Kernel Approach",
        "authors": [
            "Mehrtash T. Harandi",
            "Conrad Sanderson",
            "Richard Hartley",
            "Brian C. Lovell"
        ],
        "abstract": "Recent advances suggest that a wide range of computer vision problems can be addressed more appropriately by considering non-Euclidean geometry. This paper tackles the problem of sparse coding and dictionary learning in the space of symmetric positive definite matrices, which form a Riemannian manifold. With the aid of the recently introduced Stein kernel (related to a symmetric version of Bregman matrix divergence), we propose to perform sparse coding by embedding Riemannian manifolds into reproducing kernel Hilbert spaces. This leads to a convex and kernel version of the Lasso problem, which can be solved efficiently. We furthermore propose an algorithm for learning a Riemannian dictionary (used for sparse coding), closely tied to the Stein kernel. Experiments on several classification tasks (face recognition, texture classification, person re-identification) show that the proposed sparse coding approach achieves notable improvements in discrimination accuracy, in comparison to state-of-the-art methods such as tensor sparse coding, Riemannian locality preserving projection, and symmetry-driven accumulation of local features.\n    ",
        "submission_date": "2013-04-16T00:00:00",
        "last_modified_date": "2013-04-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.4634",
        "title": "Speckle Reduction in Polarimetric SAR Imagery with Stochastic Distances and Nonlocal Means",
        "authors": [
            "Leonardo Torres",
            "Sidnei J. S. Sant'Anna",
            "Corina C. Freitas",
            "Alejandro C. Frery"
        ],
        "abstract": "This paper presents a technique for reducing speckle in Polarimetric Synthetic Aperture Radar (PolSAR) imagery using Nonlocal Means and a statistical test based on stochastic divergences. The main objective is to select homogeneous pixels in the filtering area through statistical tests between distributions. This proposal uses the complex Wishart model to describe PolSAR data, but the technique can be extended to other models. The weights of the location-variant linear filter are function of the p-values of tests which verify the hypothesis that two samples come from the same distribution and, therefore, can be used to compute a local mean. The test stems from the family of (h-phi) divergences which originated in Information Theory. This novel technique was compared with the Boxcar, Refined Lee and IDAN filters. Image quality assessment methods on simulated and real data are employed to validate the performance of this approach. We show that the proposed filter also enhances the polarimetric entropy and preserves the scattering information of the targets.\n    ",
        "submission_date": "2013-04-16T00:00:00",
        "last_modified_date": "2013-04-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.6108",
        "title": "The varifold representation of non-oriented shapes for diffeomorphic registration",
        "authors": [
            "Nicolas Charon",
            "Alain Trouv\u00e9"
        ],
        "abstract": "In this paper, we address the problem of orientation that naturally arises when representing shapes like curves or surfaces as currents. In the field of computational anatomy, the framework of currents has indeed proved very efficient to model a wide variety of shapes. However, in such approaches, orientation of shapes is a fundamental issue that can lead to several drawbacks in treating certain kind of datasets. More specifically, problems occur with structures like acute pikes because of canceling effects of currents or with data that consists in many disconnected pieces like fiber bundles for which currents require a consistent orientation of all pieces. As a promising alternative to currents, varifolds, introduced in the context of geometric measure theory by F. Almgren, allow the representation of any non-oriented manifold (more generally any non-oriented rectifiable set). In particular, we explain how varifolds can encode numerically non-oriented objects both from the discrete and continuous point of view. We show various ways to build a Hilbert space structure on the set of varifolds based on the theory of reproducing kernels. We show that, unlike the currents' setting, these metrics are consistent with shape volume (theorem 4.1) and we derive a formula for the variation of metric with respect to the shape (theorem 4.2). Finally, we propose a generalization to non-oriented shapes of registration algorithms in the context of Large Deformations Metric Mapping (LDDMM), which we detail with a few examples in the last part of the paper.\n    ",
        "submission_date": "2013-04-22T00:00:00",
        "last_modified_date": "2013-04-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.6899",
        "title": "An implementation of the relational k-means algorithm",
        "authors": [
            "Bal\u00e1zs Szalkai"
        ],
        "abstract": "A C# implementation of a generalized k-means variant called relational k-means is described here. Relational k-means is a generalization of the well-known k-means clustering method which works for non-Euclidean scenarios as well. The input is an arbitrary distance matrix, as opposed to the traditional k-means method, where the clustered objects need to be identified with vectors.\n    ",
        "submission_date": "2013-04-25T00:00:00",
        "last_modified_date": "2013-04-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1304.7465",
        "title": "Deterministic Initialization of the K-Means Algorithm Using Hierarchical Clustering",
        "authors": [
            "M. Emre Celebi",
            "Hassan A. Kingravi"
        ],
        "abstract": "K-means is undoubtedly the most widely used partitional clustering algorithm. Unfortunately, due to its gradient descent nature, this algorithm is highly sensitive to the initial placement of the cluster centers. Numerous initialization methods have been proposed to address this problem. Many of these methods, however, have superlinear complexity in the number of data points, making them impractical for large data sets. On the other hand, linear methods are often random and/or order-sensitive, which renders their results unrepeatable. Recently, Su and Dy proposed two highly successful hierarchical initialization methods named Var-Part and PCA-Part that are not only linear, but also deterministic (non-random) and order-invariant. In this paper, we propose a discriminant analysis based approach that addresses a common deficiency of these two methods. Experiments on a large and diverse collection of data sets from the UCI Machine Learning Repository demonstrate that Var-Part and PCA-Part are highly competitive with one of the best random initialization methods to date, i.e., k-means++, and that the proposed approach significantly improves the performance of both hierarchical methods.\n    ",
        "submission_date": "2013-04-28T00:00:00",
        "last_modified_date": "2013-04-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1305.1256",
        "title": "A Convex Functional for Image Denoising based on Patches with Constrained Overlaps and its vectorial application to Low Dose Differential Phase Tomography",
        "authors": [
            "Alessandro Mirone",
            "Emmanuel Brun",
            "Paola Coan"
        ],
        "abstract": "We solve the image denoising problem with a dictionary learning technique by writing a convex functional of a new form. This functional contains beside the usual sparsity inducing term and fidelity term, a new term which induces similarity between overlapping patches in the overlap regions. The functional depends on two free regularization parameters: a coefficient multiplying the sparsity-inducing $L_{1}$ norm of the patch basis functions coefficients, and a coefficient multiplying the $L_{2}$ norm of the differences between patches in the overlapping regions. The solution is found by applying the iterative proximal gradient descent method with FISTA acceleration. In the case of tomography reconstruction we calculate the gradient by applying projection of the solution and its error backprojection at each iterative step. We study the quality of the solution, as a function of the regularization parameters and noise, on synthetic datas for which the solution is a-priori known. We apply the method on experimental data in the case of Differential Phase Tomography. For this case we use an original approach which consists in using vectorial patches, each patch having two components: one per each gradient component. The resulting algorithm, implemented in the ESRF tomography reconstruction code PyHST, results to be robust, efficient, and well adapted to strongly reduce the required dose and the number of projections in medical tomography.\n    ",
        "submission_date": "2013-05-06T00:00:00",
        "last_modified_date": "2013-05-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1305.1495",
        "title": "GReTA - a novel Global and Recursive Tracking Algorithm in three dimensions",
        "authors": [
            "Alessandro Attanasi",
            "Andrea Cavagna",
            "Lorenzo Del Castello",
            "Irene Giardina",
            "Asja Jelic",
            "Stefania Melillo",
            "Leonardo Parisi",
            "Fabio Pellacini",
            "Edward Shen",
            "Edmondo Silvestri",
            "Massimiliano Viale"
        ],
        "abstract": "Tracking multiple moving targets allows quantitative measure of the dynamic behavior in systems as diverse as animal groups in biology, turbulence in fluid dynamics and crowd and traffic control. In three dimensions, tracking several targets becomes increasingly hard since optical occlusions are very likely, i.e. two featureless targets frequently overlap for several frames. Occlusions are particularly frequent in biological groups such as bird flocks, fish schools, and insect swarms, a fact that has severely limited collective animal behavior field studies in the past. This paper presents a 3D tracking method that is robust in the case of severe occlusions. To ensure robustness, we adopt a global optimization approach that works on all objects and frames at once. To achieve practicality and scalability, we employ a divide and conquer formulation, thanks to which the computational complexity of the problem is reduced by orders of magnitude. We tested our algorithm with synthetic data, with experimental data of bird flocks and insect swarms and with public benchmark datasets, and show that our system yields high quality trajectories for hundreds of moving targets with severe overlap. The results obtained on very heterogeneous data show the potential applicability of our method to the most diverse experimental situations.\n    ",
        "submission_date": "2013-05-07T00:00:00",
        "last_modified_date": "2015-04-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1305.1986",
        "title": "An Adaptive Statistical Non-uniform Quantizer for Detail Wavelet Components in Lossy JPEG2000 Image Compression",
        "authors": [
            "Madhur Srivastava",
            "Satish K. Singh",
            "Prasanta K. Panigrahi"
        ],
        "abstract": "The paper presents a non-uniform quantization method for the Detail components in the JPEG2000 standard. Incorporating the fact that the coefficients lying towards the ends of the histogram plot of each Detail component represent the structural information of an image, the quantization step sizes become smaller at they approach the ends of the histogram plot. The variable quantization step sizes are determined by the actual statistics of the wavelet coefficients. Mean and standard deviation are the two statistical parameters used iteratively to obtain the variable step sizes. Moreover, the mean of the coefficients lying within the step size is chosen as the quantized value, contrary to the deadzone uniform quantizer which selects the midpoint of the quantization step size as the quantized value. The experimental results of the deadzone uniform quantizer and the proposed non-uniform quantizer are objectively compared by using Mean-Squared Error (MSE) and Mean Structural Similarity Index Measure (MSSIM), to evaluate the quantization error and reconstructed image quality, respectively. Subjective analysis of the reconstructed images is also carried out. Through the objective and subjective assessments, it is shown that the non-uniform quantizer performs better than the deadzone uniform quantizer in the perceptual quality of the reconstructed image, especially at low bitrates. More importantly, unlike the deadzone uniform quantizer, the non-uniform quantizer accomplishes better visual quality with a few quantized values.\n    ",
        "submission_date": "2013-05-09T00:00:00",
        "last_modified_date": "2014-08-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1305.2876",
        "title": "Multi-q Pattern Classification of Polarization Curves",
        "authors": [
            "Ricardo Fabbri",
            "Ivan N. Bastos",
            "Francisco D. Moura Neto",
            "Francisco J. P. Lopes",
            "Wesley N. Goncalves",
            "Odemir M. Bruno"
        ],
        "abstract": "Several experimental measurements are expressed in the form of one-dimensional profiles, for which there is a scarcity of methodologies able to classify the pertinence of a given result to a specific group. The polarization curves that evaluate the corrosion kinetics of electrodes in corrosive media are an application where the behavior is chiefly analyzed from profiles. Polarization curves are indeed a classic method to determine the global kinetics of metallic electrodes, but the strong nonlinearity from different metals and alloys can overlap and the discrimination becomes a challenging problem. Moreover, even finding a typical curve from replicated tests requires subjective judgement. In this paper we used the so-called multi-q approach based on the Tsallis statistics in a classification engine to separate multiple polarization curve profiles of two stainless steels. We collected 48 experimental polarization curves in aqueous chloride medium of two stainless steel types, with different resistance against localized corrosion. Multi-q pattern analysis was then carried out on a wide potential range, from cathodic up to anodic regions. An excellent classification rate was obtained, at a success rate of 90%, 80%, and 83% for low (cathodic), high (anodic), and both potential ranges, respectively, using only 2% of the original profile data. These results show the potential of the proposed approach towards efficient, robust, systematic and automatic classification of highly non-linear profile curves.\n    ",
        "submission_date": "2013-05-10T00:00:00",
        "last_modified_date": "2013-05-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1305.3971",
        "title": "Sparse Norm Filtering",
        "authors": [
            "Chengxi Ye",
            "Dacheng Tao",
            "Mingli Song",
            "David W. Jacobs",
            "Min Wu"
        ],
        "abstract": "Optimization-based filtering smoothes an image by minimizing a fidelity function and simultaneously preserves edges by exploiting a sparse norm penalty over gradients. It has obtained promising performance in practical problems, such as detail manipulation, HDR compression and deblurring, and thus has received increasing attentions in fields of graphics, computer vision and image processing. This paper derives a new type of image filter called sparse norm filter (SNF) from optimization-based filtering. SNF has a very simple form, introduces a general class of filtering techniques, and explains several classic filters as special implementations of SNF, e.g. the averaging filter and the median filter. It has advantages of being halo free, easy to implement, and low time and memory costs (comparable to those of the bilateral filter). Thus, it is more generic than a smoothing operator and can better adapt to different tasks. We validate the proposed SNF by a wide variety of applications including edge-preserving smoothing, outlier tolerant filtering, detail manipulation, HDR compression, non-blind deconvolution, image segmentation, and colorization.\n    ",
        "submission_date": "2013-05-17T00:00:00",
        "last_modified_date": "2013-05-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1305.4204",
        "title": "Machine learning on images using a string-distance",
        "authors": [
            "Uzi Chester",
            "Joel Ratsaby"
        ],
        "abstract": "We present a new method for image feature-extraction which is based on representing an image by a finite-dimensional vector of distances that measure how different the image is from a set of image prototypes. We use the recently introduced Universal Image Distance (UID) \\cite{RatsabyChesterIEEE2012} to compare the similarity between an image and a prototype image. The advantage in using the UID is the fact that no domain knowledge nor any image analysis need to be done. Each image is represented by a finite dimensional feature vector whose components are the UID values between the image and a finite set of image prototypes from each of the feature categories. The method is automatic since once the user selects the prototype images, the feature vectors are automatically calculated without the need to do any image analysis. The prototype images can be of different size, in particular, different than the image size. Based on a collection of such cases any supervised or unsupervised learning algorithm can be used to train and produce an image classifier or image cluster analysis. In this paper we present the image feature-extraction method and use it on several supervised and unsupervised learning experiments for satellite image data.\n    ",
        "submission_date": "2013-05-17T00:00:00",
        "last_modified_date": "2013-05-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1305.5663",
        "title": "Applications of Clifford's Geometric Algebra",
        "authors": [
            "Eckhard Hitzer",
            "Tohru Nitta",
            "Yasuaki Kuroe"
        ],
        "abstract": "We survey the development of Clifford's geometric algebra and some of its engineering applications during the last 15 years. Several recently developed applications and their merits are discussed in some detail. We thus hope to clearly demonstrate the benefit of developing problem solutions in a unified framework for algebra and geometry with the widest possible scope: from quantum computing and electromagnetism to satellite navigation, from neural computing to camera geometry, image processing, robotics and beyond.\n    ",
        "submission_date": "2013-05-24T00:00:00",
        "last_modified_date": "2013-05-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1305.6441",
        "title": "Matrices of forests, analysis of networks, and ranking problems",
        "authors": [
            "Pavel Chebotarev",
            "Rafig Agaev"
        ],
        "abstract": "The matrices of spanning rooted forests are studied as a tool for analysing the structure of networks and measuring their properties. The problems of revealing the basic bicomponents, measuring vertex proximity, and ranking from preference relations / sports competitions are considered. It is shown that the vertex accessibility measure based on spanning forests has a number of desirable properties. An interpretation for the stochastic matrix of out-forests in terms of information dissemination is given.\n    ",
        "submission_date": "2013-05-28T00:00:00",
        "last_modified_date": "2013-05-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1305.6650",
        "title": "Active Sensing as Bayes-Optimal Sequential Decision Making",
        "authors": [
            "Sheeraz Ahmad",
            "Angela J. Yu"
        ],
        "abstract": "Sensory inference under conditions of uncertainty is a major problem in both machine learning and computational neuroscience. An important but poorly understood aspect of sensory processing is the role of active sensing. Here, we present a Bayes-optimal inference and control framework for active sensing, C-DAC (Context-Dependent Active Controller). Unlike previously proposed algorithms that optimize abstract statistical objectives such as information maximization (Infomax) [Butko & Movellan, 2010] or one-step look-ahead accuracy [Najemnik & Geisler, 2005], our active sensing model directly minimizes a combination of behavioral costs, such as temporal delay, response error, and effort. We simulate these algorithms on a simple visual search task to illustrate scenarios in which context-sensitivity is particularly beneficial and optimization with respect to generic statistical objectives particularly inadequate. Motivated by the geometric properties of the C-DAC policy, we present both parametric and non-parametric approximations, which retain context-sensitivity while significantly reducing computational complexity. These approximations enable us to investigate the more complex problem involving peripheral vision, and we notice that the difference between C-DAC and statistical policies becomes even more evident in this scenario.\n    ",
        "submission_date": "2013-05-28T00:00:00",
        "last_modified_date": "2013-05-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1306.0178",
        "title": "Using a bag of Words for Automatic Medical Image Annotation with a Latent Semantic",
        "authors": [
            "Riadh Bouslimi",
            "Abir Messaoudi",
            "Jalel Akaichi"
        ],
        "abstract": "We present in this paper a new approach for the automatic annotation of medical images, using the approach of \"bag-of-words\" to represent the visual content of the medical image combined with text descriptors based approach ",
        "submission_date": "2013-06-02T00:00:00",
        "last_modified_date": "2013-06-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1306.1023",
        "title": "Quaternion Fourier Transform on Quaternion Fields and Generalizations",
        "authors": [
            "Eckhard Hitzer"
        ],
        "abstract": "We treat the quaternionic Fourier transform (QFT) applied to quaternion fields and investigate QFT properties useful for applications. Different forms of the QFT lead us to different Plancherel theorems. We relate the QFT computation for quaternion fields to the QFT of real signals. We research the general linear ($GL$) transformation behavior of the QFT with matrices, Clifford geometric algebra and with examples. We finally arrive at wide-ranging non-commutative multivector FT generalizations of the QFT. Examples given are new volume-time and spacetime algebra Fourier transformations.\n    ",
        "submission_date": "2013-06-05T00:00:00",
        "last_modified_date": "2013-06-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1306.1034",
        "title": "ROTUNDE - A Smart Meeting Cinematography Initiative: Tools, Datasets, and Benchmarks for Cognitive Interpretation and Control",
        "authors": [
            "Mehul Bhatt",
            "Jakob Suchan",
            "Christian Freksa"
        ],
        "abstract": "We construe smart meeting cinematography with a focus on professional situations such as meetings and seminars, possibly conducted in a distributed manner across socio-spatially separated groups. The basic objective in smart meeting cinematography is to interpret professional interactions involving people, and automatically produce dynamic recordings of discussions, debates, presentations etc in the presence of multiple communication modalities. Typical modalities include gestures (e.g., raising one's hand for a question, applause), voice and interruption, electronic apparatus (e.g., pressing a button), movement (e.g., standing-up, moving around) etc. ROTUNDE, an instance of smart meeting cinematography concept, aims to: (a) develop functionality-driven benchmarks with respect to the interpretation and control capabilities of human-cinematographers, real-time video editors, surveillance personnel, and typical human performance in everyday situations; (b) Develop general tools for the commonsense cognitive interpretation of dynamic scenes from the viewpoint of visuo-spatial cognition centred perceptual narrativisation. Particular emphasis is placed on declarative representations and interfacing mechanisms that seamlessly integrate within large-scale cognitive (interaction) systems and companion technologies consisting of diverse AI sub-components. For instance, the envisaged tools would provide general capabilities for high-level commonsense reasoning about space, events, actions, change, and interaction.\n    ",
        "submission_date": "2013-06-05T00:00:00",
        "last_modified_date": "2013-06-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1306.1392",
        "title": "PyHST2: an hybrid distributed code for high speed tomographic reconstruction with iterative reconstruction and a priori knowledge capabilities",
        "authors": [
            "Alessandro Mirone",
            "Emmanuelle Gouillart",
            "Emmanuel Brun",
            "Paul Tafforeau",
            "Jerome Kieffer"
        ],
        "abstract": "We present the PyHST2 code which is in service at ESRF for phase-contrast and absorption tomography. This code has been engineered to sustain the high data flow typical of the third generation synchrotron facilities (10 terabytes per experiment) by adopting a distributed and pipelined architecture. The code implements, beside a default filtered backprojection reconstruction, iterative reconstruction techniques with a-priori knowledge. These latter are used to improve the reconstruction quality or in order to reduce the required data volume and reach a given quality goal. The implemented a-priori knowledge techniques are based on the total variation penalisation and a new recently found convex functional which is based on overlapping patches.\n",
        "submission_date": "2013-06-06T00:00:00",
        "last_modified_date": "2013-06-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1306.1650",
        "title": "OPS-QFTs: A new type of quaternion Fourier transforms based on the orthogonal planes split with one or two general pure quaternions",
        "authors": [
            "Eckhard Hitzer"
        ],
        "abstract": "We explain the orthogonal planes split (OPS) of quaternions based on the arbitrary choice of one or two linearly independent pure unit quaternions $f,g$. Next we systematically generalize the quaternionic Fourier transform (QFT) applied to quaternion fields to conform with the OPS determined by $f,g$, or by only one pure unit quaternion $f$, comment on their geometric meaning, and establish inverse transformations.\n",
        "submission_date": "2013-06-07T00:00:00",
        "last_modified_date": "2013-06-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1306.1653",
        "title": "Non-constant bounded holomorphic functions of hyperbolic numbers - Candidates for hyperbolic activation functions",
        "authors": [
            "Eckhard Hitzer"
        ],
        "abstract": "The Liouville theorem states that bounded holomorphic complex functions are necessarily constant. Holomorphic functions fulfill the socalled Cauchy-Riemann (CR) conditions. The CR conditions mean that a complex $z$-derivative is independent of the direction. Holomorphic functions are ideal for activation functions of complex neural networks, but the Liouville theorem makes them useless. Yet recently the use of hyperbolic numbers, lead to the construction of hyperbolic number neural networks. We will describe the Cauchy-Riemann conditions for hyperbolic numbers and show that there exists a new interesting type of bounded holomorphic functions of hyperbolic numbers, which are not constant. We give examples of such functions. They therefore substantially expand the available candidates for holomorphic activation functions for hyperbolic number neural networks.\n",
        "submission_date": "2013-06-07T00:00:00",
        "last_modified_date": "2013-06-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1306.1669",
        "title": "Quaternionic Fourier-Mellin Transform",
        "authors": [
            "Eckhard Hitzer"
        ],
        "abstract": "In this contribution we generalize the classical Fourier Mellin transform [S. Dorrode and F. Ghorbel, Robust and efficient Fourier-Mellin transform approximations for gray-level image reconstruction and complete invariant description, Computer Vision and Image Understanding, 83(1) (2001), 57-78, DOI ",
        "submission_date": "2013-06-07T00:00:00",
        "last_modified_date": "2013-06-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1306.1679",
        "title": "Clifford Fourier-Mellin transform with two real square roots of -1 in Cl(p,q), p+q=2",
        "authors": [
            "Eckhard Hitzer"
        ],
        "abstract": "We describe a non-commutative generalization of the complex Fourier-Mellin transform to Clifford algebra valued signal functions over the domain $\\R^{p,q}$ taking values in Cl(p,q), p+q=2.\n",
        "submission_date": "2013-06-07T00:00:00",
        "last_modified_date": "2013-06-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1306.2003",
        "title": "Comparing Edge Detection Methods based on Stochastic Entropies and Distances for PolSAR Imagery",
        "authors": [
            "Abra\u00e3o D. C. Nascimento",
            "Michelle M. Horta",
            "Alejandro C. Frery",
            "Renato J. Cintra"
        ],
        "abstract": "Polarimetric synthetic aperture radar (PolSAR) has achieved a prominent position as a remote imaging method. However, PolSAR images are contaminated by speckle noise due to the coherent illumination employed during the data acquisition. This noise provides a granular aspect to the image, making its processing and analysis (such as in edge detection) hard tasks. This paper discusses seven methods for edge detection in multilook PolSAR images. In all methods, the basic idea consists in detecting transition points in the finest possible strip of data which spans two regions. The edge is contoured using the transitions points and a B-spline curve. Four stochastic distances, two differences of entropies, and the maximum likelihood criterion were used under the scaled complex Wishart distribution; the first six stem from the h-phi class of measures. The performance of the discussed detection methods was quantified and analyzed by the computational time and probability of correct edge detection, with respect to the number of looks, the backscatter matrix as a whole, the SPAN, the covariance an the spatial resolution. The detection procedures were applied to three real PolSAR images. Results provide evidence that the methods based on the Bhattacharyya distance and the difference of Shannon entropies outperform the other techniques.\n    ",
        "submission_date": "2013-06-09T00:00:00",
        "last_modified_date": "2013-06-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1306.2081",
        "title": "3D model retrieval using global and local radial distances",
        "authors": [
            "Bo Li",
            "Henry Johan"
        ],
        "abstract": "3D model retrieval techniques can be classified as histogram-based, view-based and graph-based approaches. We propose a hybrid shape descriptor which combines the global and local radial distance features by utilizing the histogram-based and view-based approaches respectively. We define an area-weighted global radial distance with respect to the center of the bounding sphere of the model and encode its distribution into a 2D histogram as the global radial distance shape descriptor. We then uniformly divide the bounding cube of a 3D model into a set of small cubes and define their centers as local centers. Then, we compute the local radial distance of a point based on the nearest local center. By sparsely sampling a set of views and encoding the local radial distance feature on the rendered views by color coding, we extract the local radial distance shape descriptor. Based on these two shape descriptors, we develop a hybrid radial distance shape descriptor for 3D model retrieval. Experiment results show that our hybrid shape descriptor outperforms several typical histogram-based and view-based approaches.\n    ",
        "submission_date": "2013-06-10T00:00:00",
        "last_modified_date": "2013-06-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1306.3003",
        "title": "Non-parametric Power-law Data Clustering",
        "authors": [
            "Xuhui Fan",
            "Yiling Zeng",
            "Longbing Cao"
        ],
        "abstract": "It has always been a great challenge for clustering algorithms to automatically determine the cluster numbers according to the distribution of datasets. Several approaches have been proposed to address this issue, including the recent promising work which incorporate Bayesian Nonparametrics into the $k$-means clustering procedure. This approach shows simplicity in implementation and solidity in theory, while it also provides a feasible way to inference in large scale datasets. However, several problems remains unsolved in this pioneering work, including the power-law data applicability, mechanism to merge centers to avoid the over-fitting problem, clustering order problem, e.t.c.. To address these issues, the Pitman-Yor Process based k-means (namely \\emph{pyp-means}) is proposed in this paper. Taking advantage of the Pitman-Yor Process, \\emph{pyp-means} treats clusters differently by dynamically and adaptively changing the threshold to guarantee the generation of power-law clustering results. Also, one center agglomeration procedure is integrated into the implementation to be able to merge small but close clusters and then adaptively determine the cluster number. With more discussion on the clustering order, the convergence proof, complexity analysis and extension to spectral clustering, our approach is compared with traditional clustering algorithm and variational inference methods. The advantages and properties of pyp-means are validated by experiments on both synthetic datasets and real world datasets.\n    ",
        "submission_date": "2013-06-13T00:00:00",
        "last_modified_date": "2013-06-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1306.3309",
        "title": "Symmetries in LDDMM with higher order momentum distributions",
        "authors": [
            "Henry Jacobs"
        ],
        "abstract": "In some implementations of the Large Deformation Diffeomorphic Metric Mapping formulation for image registration we consider the motion of particles which locally translate image data. We then lift the motion of the particles to obtain a motion on the entire image. However, it is certainly possible to consider particles which do more than translate, and this is what will be described in this paper. As the unreduced Lagrangian associated to EPDiff possesses $\\Diff(M)$ symmetry, it must also exhibit $G \\subset \\Diff(M)$ symmetry, for any Lie subgroup. In this paper we will describe a tower of Lie groups $G^{(0)} \\subseteq G^{(1)} \\subseteq G^{(2)} \\subseteq...$ which correspond to preserving $k$-th order jet-data. The reduced configuration spaces $Q^{(k)} := \\Diff(M) / G^{(k)}$ will be finite-dimensional (in particular, $Q^{(0)}$ is the configuration manifold for $N$ particles in $M$). We will observe that $G^{(k)}$ is a normal subgroup of $G^{(0)}$ and so the quotient $G^{(0)} / G^{(k)}$ is itself a (finite dimensional) Lie group which acts on $Q^{(k)}$. This makes $Q^{(k)}$ a principle bundle over $Q^{(0)}$ and the reduced geodesic equations on $Q^{(k)}$ will possess $G^{(0)} / G^{(k)}$-symmetry. Noether's theorem implies the existence of conserved momenta for the reduced system on $T^{\\ast}Q^{(k)}$.\n    ",
        "submission_date": "2013-06-14T00:00:00",
        "last_modified_date": "2013-07-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1306.3946",
        "title": "Multi-view in Lensless Compressive Imaging",
        "authors": [
            "Hong Jiang",
            "Gang Huang",
            "Paul Wilford"
        ],
        "abstract": "Multi-view images are acquired by a lensless compressive imaging architecture, which consists of an aperture assembly and multiple sensors. The aperture assembly consists of a two dimensional array of aperture elements whose transmittance can be individually controlled to implement a compressive sensing matrix. For each transmittance pattern of the aperture assembly, each of the sensors takes a measurement. The measurement vectors from the multiple sensors represent multi-view images of the same scene. We present theoretical framework for multi-view reconstruction and experimental results for enhancing quality of image using multi-view.\n    ",
        "submission_date": "2013-06-17T00:00:00",
        "last_modified_date": "2013-09-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1306.4592",
        "title": "Time Efficient Approach To Offline Hand Written Character Recognition Using Associative Memory Net",
        "authors": [
            "Tirtharaj Dash"
        ],
        "abstract": "In this paper, an efficient Offline Hand Written Character Recognition algorithm is proposed based on Associative Memory Net (AMN). The AMN used in this work is basically auto associative. The implementation is carried out completely in 'C' language. To make the system perform to its best with minimal computation time, a Parallel algorithm is also developed using an API package OpenMP. Characters are mainly English alphabets (Small (26), Capital (26)) collected from system (52) and from different persons (52). The characters collected from system are used to train the AMN and characters collected from different persons are used for testing the recognition ability of the net. The detailed analysis showed that the network recognizes the hand written characters with recognition rate of 72.20% in average case. However, in best case, it recognizes the collected hand written characters with 88.5%. The developed network consumes 3.57 sec (average) in Serial implementation and 1.16 sec (average) in Parallel implementation using OpenMP.\n    ",
        "submission_date": "2013-06-19T00:00:00",
        "last_modified_date": "2013-06-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1306.4629",
        "title": "Non-Correlated Character Recognition using Artificial Neural Network",
        "authors": [
            "Tirtharaj Dash",
            "Tanistha Nayak"
        ],
        "abstract": "This paper investigates a method of Handwritten English Character Recognition using Artificial Neural Network (ANN). This work has been done in offline Environment for non correlated characters, which do not possess any linear relationships among them. We test that whether the particular tested character belongs to a cluster or not. The implementation is carried out in Matlab environment and successfully tested. Fifty-two sets of English alphabets are used to train the ANN and test the network. The algorithms are tested with 26 capital letters and 26 small letters. The testing result showed that the proposed ANN based algorithm showed a maximum recognition rate of 85%.\n    ",
        "submission_date": "2013-06-19T00:00:00",
        "last_modified_date": "2013-06-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1306.4758",
        "title": "Analysing Word Importance for Image Annotation",
        "authors": [
            "Payal Gulati",
            "A. K. Sharma"
        ],
        "abstract": "Image annotation provides several keywords automatically for a given image based on various tags to describe its contents which is useful in Image retrieval. Various researchers are working on text based and content based image annotations [7,9]. It is seen, in traditional Image annotation approaches, annotation words are treated equally without considering the importance of each word in real world. In context of this, in this work, images are annotated with keywords based on their frequency count and word correlation. Moreover this work proposes an approach to compute importance score of candidate keywords, having same frequency count.\n    ",
        "submission_date": "2013-06-20T00:00:00",
        "last_modified_date": "2013-06-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1306.5308",
        "title": "Cognitive Interpretation of Everyday Activities: Toward Perceptual Narrative Based Visuo-Spatial Scene Interpretation",
        "authors": [
            "Mehul Bhatt",
            "Jakob Suchan",
            "Carl Schultz"
        ],
        "abstract": "We position a narrative-centred computational model for high-level knowledge representation and reasoning in the context of a range of assistive technologies concerned with \"visuo-spatial perception and cognition\" tasks. Our proposed narrative model encompasses aspects such as \\emph{space, events, actions, change, and interaction} from the viewpoint of commonsense reasoning and learning in large-scale cognitive systems. The broad focus of this paper is on the domain of \"human-activity interpretation\" in smart environments, ambient intelligence etc. In the backdrop of a \"smart meeting cinematography\" domain, we position the proposed narrative model, preliminary work on perceptual narrativisation, and the immediate outlook on constructing general-purpose open-source tools for perceptual narrativisation.\n",
        "submission_date": "2013-06-22T00:00:00",
        "last_modified_date": "2013-06-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1306.5390",
        "title": "P-HGRMS: A Parallel Hypergraph Based Root Mean Square Algorithm for Image Denoising",
        "authors": [
            "Tejaswi Agarwal",
            "Saurabh Jha",
            "B. Rajesh Kanna"
        ],
        "abstract": "This paper presents a parallel Salt and Pepper (SP) noise removal algorithm in a grey level digital image based on the Hypergraph Based Root Mean Square (HGRMS) approach. HGRMS is generic algorithm for identifying noisy pixels in any digital image using a two level hierarchical serial approach. However, for SP noise removal, we reduce this algorithm to a parallel model by introducing a cardinality matrix and an iteration factor, k, which helps us reduce the dependencies in the existing approach. We also observe that the performance of the serial implementation is better on smaller images, but once the threshold is achieved in terms of image resolution, its computational complexity increases drastically. We test P-HGRMS using standard images from the Berkeley Segmentation dataset on NVIDIAs Compute Unified Device Architecture (CUDA) for noise identification and attenuation. We also compare the noise removal efficiency of the proposed algorithm using Peak Signal to Noise Ratio (PSNR) to the existing approach. P-HGRMS maintains the noise removal efficiency and outperforms its sequential counterpart by 6 to 18 times (6x - 18x) in computational efficiency.\n    ",
        "submission_date": "2013-06-23T00:00:00",
        "last_modified_date": "2013-06-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1306.6281",
        "title": "Compressive Coded Aperture Keyed Exposure Imaging with Optical Flow Reconstruction",
        "authors": [
            "Zachary T. Harmany",
            "Roummel F. Marcia",
            "Rebecca M. Willett"
        ],
        "abstract": "This paper describes a coded aperture and keyed exposure approach to compressive video measurement which admits a small physical platform, high photon efficiency, high temporal resolution, and fast reconstruction algorithms. The proposed projections satisfy the Restricted Isometry Property (RIP), and hence compressed sensing theory provides theoretical guarantees on the video reconstruction quality. Moreover, the projections can be easily implemented using existing optical elements such as spatial light modulators (SLMs). We extend these coded mask designs to novel dual-scale masks (DSMs) which enable the recovery of a coarse-resolution estimate of the scene with negligible computational cost. We develop fast numerical algorithms which utilize both temporal correlations and optical flow in the video sequence as well as the innovative structure of the projections. Our numerical experiments demonstrate the efficacy of the proposed approach on short-wave infrared data.\n    ",
        "submission_date": "2013-06-26T00:00:00",
        "last_modified_date": "2013-06-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1306.6737",
        "title": "Digital Image Tamper Detection Techniques - A Comprehensive Study",
        "authors": [
            "Minati Mishra",
            "Flt. Lt. Dr. M. C. Adhikary"
        ],
        "abstract": "Photographs are considered to be the most powerful and trustworthy media of expression. For a long time, those were accepted as proves of evidences in varied fields such as journalism, forensic investigations, military intelligence, scientific research and publications, crime detection and legal proceedings, investigation of insurance claims, medical imaging etc. Today, digital images have completely replaced the conventional photographs from every sphere of life but unfortunately, they seldom enjoy the credibility of their conventional counterparts, thanks to the rapid advancements in the field of digital image processing. The increasing availability of low cost and sometimes free of cost image editing software such as Photoshop, Corel Paint Shop, Photoscape, PhotoPlus, GIMP and Pixelmator have made the tampering of digital images even more easier and a common practice. Now it has become quite impossible to say whether a photograph is a genuine camera output or a manipulated version of it just by looking at it. As a result, photographs have almost lost their reliability and place as proves of evidences in all fields. This is why digital image tamper detection has emerged as an important research area to establish the authenticity of digital photographs by separating the tampered lots from the original ones. This paper gives a brief history of image tampering and a state-of-the-art review of the tamper detection techniques.\n    ",
        "submission_date": "2013-06-28T00:00:00",
        "last_modified_date": "2013-06-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1307.0060",
        "title": "Approximate Bayesian Image Interpretation using Generative Probabilistic Graphics Programs",
        "authors": [
            "Vikash K. Mansinghka",
            "Tejas D. Kulkarni",
            "Yura N. Perov",
            "Joshua B. Tenenbaum"
        ],
        "abstract": "The idea of computer vision as the Bayesian inverse problem to computer graphics has a long history and an appealing elegance, but it has proved difficult to directly implement. Instead, most vision tasks are approached via complex bottom-up processing pipelines. Here we show that it is possible to write short, simple probabilistic graphics programs that define flexible generative models and to automatically invert them to interpret real-world images. Generative probabilistic graphics programs consist of a stochastic scene generator, a renderer based on graphics software, a stochastic likelihood model linking the renderer's output and the data, and latent variables that adjust the fidelity of the renderer and the tolerance of the likelihood model. Representations and algorithms from computer graphics, originally designed to produce high-quality images, are instead used as the deterministic backbone for highly approximate and stochastic generative models. This formulation combines probabilistic programming, computer graphics, and approximate Bayesian computation, and depends only on general-purpose, automatic inference techniques. We describe two applications: reading sequences of degraded and adversarially obscured alphanumeric characters, and inferring 3D road models from vehicle-mounted camera images. Each of the probabilistic graphics programs we present relies on under 20 lines of probabilistic code, and supports accurate, approximately Bayesian inferences about ambiguous real-world images.\n    ",
        "submission_date": "2013-06-29T00:00:00",
        "last_modified_date": "2013-06-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1307.0805",
        "title": "Novel Factorization Strategies for Higher Order Tensors: Implications for Compression and Recovery of Multi-linear Data",
        "authors": [
            "Zemin Zhang",
            "Gregory Ely",
            "Shuchin Aeron",
            "Ning Hao",
            "Misha Kilmer"
        ],
        "abstract": "In this paper we propose novel methods for compression and recovery of multilinear data under limited sampling. We exploit the recently proposed tensor- Singular Value Decomposition (t-SVD)[1], which is a group theoretic framework for tensor decomposition. In contrast to popular existing tensor decomposition techniques such as higher-order SVD (HOSVD), t-SVD has optimality properties similar to the truncated SVD for matrices. Based on t-SVD, we first construct novel tensor-rank like measures to characterize informational and structural complexity of multilinear data. Following that we outline a complexity penalized algorithm for tensor completion from missing entries. As an application, 3-D and 4-D (color) video data compression and recovery are considered. We show that videos with linear camera motion can be represented more efficiently using t-SVD compared to traditional approaches based on vectorizing or flattening of the tensors. Application of the proposed tensor completion algorithm for video recovery from missing entries is shown to yield a superior performance over existing methods. In conclusion we point out several research directions and implications to online prediction of multilinear data.\n    ",
        "submission_date": "2013-07-02T00:00:00",
        "last_modified_date": "2013-10-31T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1307.1289",
        "title": "Further results on dissimilarity spaces for hyperspectral images RF-CBIR",
        "authors": [
            "Miguel Angel Veganzones",
            "Mihai Datcu",
            "Manuel Gra\u00f1a"
        ],
        "abstract": "Content-Based Image Retrieval (CBIR) systems are powerful search tools in image databases that have been little applied to hyperspectral images. Relevance feedback (RF) is an iterative process that uses machine learning techniques and user's feedback to improve the CBIR systems performance. We pursued to expand previous research in hyperspectral CBIR systems built on dissimilarity functions defined either on spectral and spatial features extracted by spectral unmixing techniques, or on dictionaries extracted by dictionary-based compressors. These dissimilarity functions were not suitable for direct application in common machine learning techniques. We propose to use a RF general approach based on dissimilarity spaces which is more appropriate for the application of machine learning algorithms to the hyperspectral RF-CBIR. We validate the proposed RF method for hyperspectral CBIR systems over a real hyperspectral dataset.\n    ",
        "submission_date": "2013-07-04T00:00:00",
        "last_modified_date": "2013-07-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1307.1561",
        "title": "A Sub-block Based Image Retrieval Using Modified Integrated Region Matching",
        "authors": [
            "E. R. Vimina",
            "K. Poulose Jacob"
        ],
        "abstract": "This paper proposes a content based image retrieval (CBIR) system using the local colour and texture features of selected image sub-blocks and global colour and shape features of the image. The image sub-blocks are roughly identified by segmenting the image into partitions of different configuration, finding the edge density in each partition using edge thresholding followed by morphological dilation. The colour and texture features of the identified regions are computed from the histograms of the quantized HSV colour space and Gray Level Co- occurrence Matrix (GLCM) respectively. The colour and texture feature vectors is computed for each region. The shape features are computed from the Edge Histogram Descriptor (EHD). A modified Integrated Region Matching (IRM) algorithm is used for finding the minimum distance between the sub-blocks of the query and target image. Experimental results show that the proposed method provides better retrieving result than retrieval using some of the existing methods.\n    ",
        "submission_date": "2013-07-05T00:00:00",
        "last_modified_date": "2013-07-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1307.2560",
        "title": "Exploiting Data Parallelism in the yConvex Hypergraph Algorithm for Image Representation using GPGPUs",
        "authors": [
            "Saurabh Jha",
            "Tejaswi Agarwal",
            "B. Rajesh Kanna"
        ],
        "abstract": "To define and identify a region-of-interest (ROI) in a digital image, the shape descriptor of the ROI has to be described in terms of its boundary characteristics. To address the generic issues of contour tracking, the yConvex Hypergraph (yCHG) model was proposed by Kanna et al [1]. In this work, we propose a parallel approach to implement the yCHG model by exploiting massively parallel cores of NVIDIA's Compute Unified Device Architecture (CUDA). We perform our experiments on the MODIS satellite image database by NASA, and based on our analysis we observe that the performance of the serial implementation is better on smaller images, but once the threshold is achieved in terms of image resolution, the parallel implementation outperforms its sequential counterpart by 2 to 10 times (2x-10x). We also conclude that an increase in the number of hyperedges in the ROI of a given size does not impact the performance of the overall algorithm.\n    ",
        "submission_date": "2013-06-23T00:00:00",
        "last_modified_date": "2013-06-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1307.2818",
        "title": "Anisotropic Diffusion for Details Enhancement in Multi-Exposure Image Fusion",
        "authors": [
            "Harbinder Singh",
            "Vinay Kumar",
            "Sunil Bhooshan"
        ],
        "abstract": "We develop a multiexposure image fusion method based on texture features, which exploits the edge preserving and intraregion smoothing property of nonlinear diffusion filters based on partial differential equations (PDE). With the captured multiexposure image series, we first decompose images into base layers and detail layers to extract sharp details and fine details, respectively. The magnitude of the gradient of the image intensity is utilized to encourage smoothness at homogeneous regions in preference to inhomogeneous regions. Then, we have considered texture features of the base layer to generate a mask (i.e., decision mask) that guides the fusion of base layers in multiresolution fashion. Finally, well-exposed fused image is obtained that combines fused base layer and the detail layers at each scale across all the input exposures. Proposed algorithm skipping complex High Dynamic Range Image (HDRI) generation and tone mapping steps to produce detail preserving image for display on standard dynamic range display devices. Moreover, our technique is effective for blending flash/no-flash image pair and multifocus images, that is, images focused on different targets.\n    ",
        "submission_date": "2013-07-10T00:00:00",
        "last_modified_date": "2013-07-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1307.2971",
        "title": "Accuracy of MAP segmentation with hidden Potts and Markov mesh prior models via Path Constrained Viterbi Training, Iterated Conditional Modes and Graph Cut based algorithms",
        "authors": [
            "Ana Georgina Flesia",
            "Josef Baumgartner",
            "Javier Gimenez",
            "Jorge Martinez"
        ],
        "abstract": "In this paper, we study statistical classification accuracy of two different Markov field environments for pixelwise image segmentation, considering the labels of the image as hidden states and solving the estimation of such labels as a solution of the MAP equation. The emission distribution is assumed the same in all models, and the difference lays in the Markovian prior hypothesis made over the labeling random field. The a priori labeling knowledge will be modeled with a) a second order anisotropic Markov Mesh and b) a classical isotropic Potts model. Under such models, we will consider three different segmentation procedures, 2D Path Constrained Viterbi training for the Hidden Markov Mesh, a Graph Cut based segmentation for the first order isotropic Potts model, and ICM (Iterated Conditional Modes) for the second order isotropic Potts model.\n",
        "submission_date": "2013-07-11T00:00:00",
        "last_modified_date": "2013-07-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1307.3040",
        "title": "Between Sense and Sensibility: Declarative narrativisation of mental models as a basis and benchmark for visuo-spatial cognition and computation focussed collaborative cognitive systems",
        "authors": [
            "Mehul Bhatt"
        ],
        "abstract": "What lies between `\\emph{sensing}' and `\\emph{sensibility}'? In other words, what kind of cognitive processes mediate sensing capability, and the formation of sensible impressions ---e.g., abstractions, analogies, hypotheses and theory formation, beliefs and their revision, argument formation--- in domain-specific problem solving, or in regular activities of everyday living, working and simply going around in the environment? How can knowledge and reasoning about such capabilities, as exhibited by humans in particular problem contexts, be used as a model and benchmark for the development of collaborative cognitive (interaction) systems concerned with human assistance, assurance, and empowerment?\n",
        "submission_date": "2013-07-11T00:00:00",
        "last_modified_date": "2014-03-31T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1307.3755",
        "title": "Map of Life: Measuring and Visualizing Species' Relatedness with \"Molecular Distance Maps\"",
        "authors": [
            "Lila Kari",
            "Kathleen A. Hill",
            "Abu Sadat Sayem",
            "Nathaniel Bryans",
            "Katelyn Davis",
            "Nikesh S. Dattani"
        ],
        "abstract": "We propose a novel combination of methods that (i) portrays quantitative characteristics of a DNA sequence as an image, (ii) computes distances between these images, and (iii) uses these distances to output a map wherein each sequence is a point in a common Euclidean space. In the resulting \"Molecular Distance Map\" each point signifies a DNA sequence, and the geometric distance between any two points reflects the degree of relatedness between the corresponding sequences and species.\n",
        "submission_date": "2013-07-14T00:00:00",
        "last_modified_date": "2013-07-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1307.3782",
        "title": "Handwritten Digits Recognition using Deep Convolutional Neural Network: An Experimental Study using EBlearn",
        "authors": [
            "Karim M. Mahmoud"
        ],
        "abstract": "In this paper, results of an experimental study of a deep convolution neural network architecture which can classify different handwritten digits using EBLearn library are reported. The purpose of this neural network is to classify input images into 10 different classes or digits (0-9) and to explore new findings. The input dataset used consists of digits images of size 32X32 in grayscale (MNIST dataset).\n    ",
        "submission_date": "2013-07-14T00:00:00",
        "last_modified_date": "2016-04-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1307.3811",
        "title": "Multiview Hessian Discriminative Sparse Coding for Image Annotation",
        "authors": [
            "Weifeng Liu",
            "Dacheng Tao",
            "Jun Cheng",
            "Yuanyan Tang"
        ],
        "abstract": "Sparse coding represents a signal sparsely by using an overcomplete dictionary, and obtains promising performance in practical computer vision applications, especially for signal restoration tasks such as image denoising and image inpainting. In recent years, many discriminative sparse coding algorithms have been developed for classification problems, but they cannot naturally handle visual data represented by multiview features. In addition, existing sparse coding algorithms use graph Laplacian to model the local geometry of the data distribution. It has been identified that Laplacian regularization biases the solution towards a constant function which possibly leads to poor extrapolating power. In this paper, we present multiview Hessian discriminative sparse coding (mHDSC) which seamlessly integrates Hessian regularization with discriminative sparse coding for multiview learning problems. In particular, mHDSC exploits Hessian regularization to steer the solution which varies smoothly along geodesics in the manifold, and treats the label information as an additional view of feature for incorporating the discriminative power for image annotation. We conduct extensive experiments on PASCAL VOC'07 dataset and demonstrate the effectiveness of mHDSC for image annotation.\n    ",
        "submission_date": "2013-07-15T00:00:00",
        "last_modified_date": "2013-07-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1307.4048",
        "title": "Modified SPLICE and its Extension to Non-Stereo Data for Noise Robust Speech Recognition",
        "authors": [
            "D. S. Pavan Kumar",
            "N. Vishnu Prasad",
            "Vikas Joshi",
            "S. Umesh"
        ],
        "abstract": "In this paper, a modification to the training process of the popular SPLICE algorithm has been proposed for noise robust speech recognition. The modification is based on feature correlations, and enables this stereo-based algorithm to improve the performance in all noise conditions, especially in unseen cases. Further, the modified framework is extended to work for non-stereo datasets where clean and noisy training utterances, but not stereo counterparts, are required. Finally, an MLLR-based computationally efficient run-time noise adaptation method in SPLICE framework has been proposed. The modified SPLICE shows 8.6% absolute improvement over SPLICE in Test C of Aurora-2 database, and 2.93% overall. Non-stereo method shows 10.37% and 6.93% absolute improvements over Aurora-2 and Aurora-4 baseline models respectively. Run-time adaptation shows 9.89% absolute improvement in modified framework as compared to SPLICE for Test C, and 4.96% overall w.r.t. standard MLLR adaptation on HMMs.\n    ",
        "submission_date": "2013-07-15T00:00:00",
        "last_modified_date": "2013-07-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1307.5684",
        "title": "Using a Dynamic Neural Field Model to Explore a Direct Collicular Inhibition Account of Inhibition of Return",
        "authors": [
            "Jason Satel",
            "Ross Story",
            "Matthew D. Hilchey",
            "Zhiguo Wang",
            "Raymond M. Klein"
        ],
        "abstract": "When the interval between a transient ash of light (a \"cue\") and a second visual response signal (a \"target\") exceeds at least 200ms, responding is slowest in the direction indicated by the first signal. This phenomenon is commonly referred to as inhibition of return (IOR). The dynamic neural field model (DNF) has proven to have broad explanatory power for IOR, effectively capturing many empirical results. Previous work has used a short-term depression (STD) implementation of IOR, but this approach fails to explain many behavioral phenomena observed in the literature. Here, we explore a variant model of IOR involving a combination of STD and delayed direct collicular inhibition. We demonstrate that this hybrid model can better reproduce established behavioural results. We use the results of this model to propose several experiments that would yield particularly valuable insight into the nature of the neurophysiological mechanisms underlying IOR.\n    ",
        "submission_date": "2013-07-22T00:00:00",
        "last_modified_date": "2013-07-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1307.5720",
        "title": "Top-down and Bottom-up Feature Combination for Multi-sensor Attentive Robots",
        "authors": [
            "Esther L. Colombini",
            "Alexandre S. Sim\u00f5es",
            "Carlos H. C. Ribeiro"
        ],
        "abstract": "The information available to robots in real tasks is widely distributed both in time and space, requiring the agent to search for relevant data. In humans, that face the same problem when sounds, images and smells are presented to their sensors in a daily scene, a natural system is applied: Attention. As vision plays an important role in our routine, most research regarding attention has involved this sensorial system and the same has been replicated to the robotics field. However,most of the robotics tasks nowadays do not rely only in visual data, that are still costly. To allow the use of attentive concepts with other robotics sensors that are usually used in tasks such as navigation, self-localization, searching and mapping, a generic attentional model has been previously proposed. In this work, feature mapping functions were designed to build feature maps to this attentive model from data from range scanner and sonar sensors. Experiments were performed in a high fidelity simulated robotics environment and results have demonstrated the capability of the model on dealing with both salient stimuli and goal-driven attention over multiple features extracted from multiple sensors.\n    ",
        "submission_date": "2013-07-22T00:00:00",
        "last_modified_date": "2013-07-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1307.7466",
        "title": "Integration of 3D Object Recognition and Planning for Robotic Manipulation: A Preliminary Report",
        "authors": [
            "Damien Jade Duff",
            "Esra Erdem",
            "Volkan Patoglu"
        ],
        "abstract": "We investigate different approaches to integrating object recognition and planning in a tabletop manipulation domain with the set of objects used in the 2012 RoboCup@Work competition. Results of our preliminary experiments show that, with some approaches, close integration of perception and planning improves the quality of plans, as well as the computation times of feasible plans.\n    ",
        "submission_date": "2013-07-29T00:00:00",
        "last_modified_date": "2013-07-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1307.7521",
        "title": "Union of Low-Rank Subspaces Detector",
        "authors": [
            "Mohsen Joneidi",
            "Parvin Ahmadi",
            "Mostafa Sadeghi",
            "Nazanin Rahnavard"
        ],
        "abstract": "The problem of signal detection using a flexible and general model is considered. Due to applicability and flexibility of sparse signal representation and approximation, it has attracted a lot of attention in many signal processing areas. In this paper, we propose a new detection method based on sparse decomposition in a union of subspaces (UoS) model. Our proposed detector uses a dictionary that can be interpreted as a bank of matched subspaces. This improves the performance of signal detection, as it is a generalization for detectors. Low-rank assumption for the desired signals implies that the representations of these signals in terms of some proper bases would be sparse. Our proposed detector exploits sparsity in its decision rule. We demonstrate the high efficiency of our method in the cases of voice activity detection in speech processing.\n    ",
        "submission_date": "2013-07-29T00:00:00",
        "last_modified_date": "2016-02-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1308.0315",
        "title": "MAS for video objects segmentation and tracking based on active contours and SURF descriptor",
        "authors": [
            "Mohamed Chakroun",
            "Ali Wali",
            "Adel M. Alimi"
        ],
        "abstract": "In computer vision, video segmentation and tracking is an important challenging issue. In this paper, we describe a new video sequences segmentation and tracking algorithm based on MAS \"multi-agent systems\" and SURF \"Speeded Up Robust Features\". Our approach consists in modelling a multi-agent system for segmenting the first image from a video sequence and tracking objects in the video sequences. The used agents are supervisor and explorator agents, they are communicating between them and they inspire in their behavior from active contours approaches. The tracking of objects is based on SURF descriptors \"Speed Up Robust Features\". We used the DIMA platform and \"API Ateji PX\" (an extension of the Java language to facilitate parallel programming on heterogeneous architectures) to implement this algorithm. The experimental results indicate that the proposed algorithm is more robust and faster than previous approaches.\n    ",
        "submission_date": "2013-08-01T00:00:00",
        "last_modified_date": "2013-08-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1308.1150",
        "title": "Multimodal Approach for Video Surveillance Indexing and Retrieval",
        "authors": [
            "Ali Wali",
            "Adel M. Alimi"
        ],
        "abstract": "In this paper, we present an overview of a multimodal system to indexing and searching video sequence by the content that has been developed within the REGIMVid project. A large part of our system has been developed as part of TRECVideo evaluation. The MAVSIR platform provides High-level feature extraction from audio-visual content and concept/event-based video retrieval. We illustrate the architecture of the system as well as provide an overview of the descriptors supported to date. Then we demonstrate the usefulness of the toolbox in the context of feature extraction, concepts/events learning and retrieval in large collections of video surveillance dataset. The results are encouraging as we are able to get good results on several event categories, while for all events we have gained valuable insights and experience.\n    ",
        "submission_date": "2013-08-06T00:00:00",
        "last_modified_date": "2013-08-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1308.2350",
        "title": "Learning Features and their Transformations by Spatial and Temporal Spherical Clustering",
        "authors": [
            "Jayanta K. Dutta",
            "Bonny Banerjee"
        ],
        "abstract": "Learning features invariant to arbitrary transformations in the data is a requirement for any recognition system, biological or artificial. It is now widely accepted that simple cells in the primary visual cortex respond to features while the complex cells respond to features invariant to different transformations. We present a novel two-layered feedforward neural model that learns features in the first layer by spatial spherical clustering and invariance to transformations in the second layer by temporal spherical clustering. Learning occurs in an online and unsupervised manner following the Hebbian rule. When exposed to natural videos acquired by a camera mounted on a cat's head, the first and second layer neurons in our model develop simple and complex cell-like receptive field properties. The model can predict by learning lateral connections among the first layer neurons. A topographic map to their spatial features emerges by exponentially decaying the flow of activation with distance from one neuron to another in the first layer that fire in close temporal proximity, thereby minimizing the pooling length in an online manner simultaneously with feature learning.\n    ",
        "submission_date": "2013-08-10T00:00:00",
        "last_modified_date": "2013-08-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1308.3225",
        "title": "An interactive engine for multilingual video browsing using semantic content",
        "authors": [
            "M. Ben Halima",
            "M. Hamroun",
            "S. Ben Moussa",
            "A. M. Alimi"
        ],
        "abstract": "The amount of audio-visual information has increased dramatically with the advent of High Speed Internet. Furthermore, technological advances in recent years in the field of information technology, have simplified the use of video data in various fields by the general public. This made it possible to store large collections of video documents into computer systems. To enable efficient use of these collections, it is necessary to develop tools to facilitate access to these documents and handling them. In this paper we propose a method for indexing and retrieval of video sequences in a video database of large dimension, based on a weighting technique to calculate the degree of membership of a concept in a video also a structuring of the data of the audio-visual (context / concept / video) and a relevance feedback mechanism.\n    ",
        "submission_date": "2013-08-14T00:00:00",
        "last_modified_date": "2013-08-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1308.3243",
        "title": "Arabic Text Recognition in Video Sequences",
        "authors": [
            "M. Ben Halima",
            "H. Karray",
            "A. M. Alimi"
        ],
        "abstract": "In this paper, we propose a robust approach for text extraction and recognition from Arabic news video sequence. The text included in video sequences is an important needful for indexing and searching system. However, this text is difficult to detect and recognize because of the variability of its size, their low resolution characters and the complexity of the backgrounds. To solve these problems, we propose a system performing in two main tasks: extraction and recognition of text. Our system is tested on a varied database composed of different Arabic news programs and the obtained results are encouraging and show the merits of our approach.\n    ",
        "submission_date": "2013-08-14T00:00:00",
        "last_modified_date": "2013-08-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1308.4338",
        "title": "SAR Image Despeckling Algorithms using Stochastic Distances and Nonlocal Means",
        "authors": [
            "Leonardo Torres",
            "Alejandro C. Frery"
        ],
        "abstract": "This paper presents two approaches for filter design based on stochastic distances for intensity speckle reduction. A window is defined around each pixel, overlapping samples are compared and only those which pass a goodness-of-fit test are used to compute the filtered value. The tests stem from stochastic divergences within the Information Theory framework. The technique is applied to intensity Synthetic Aperture Radar (SAR) data with homogeneous regions using the Gamma model. The first approach uses a Nagao-Matsuyama-type procedure for setting the overlapping samples, and the second uses the nonlocal method. The proposals are compared with the Improved Sigma filter and with anisotropic diffusion for speckled data (SRAD) using a protocol based on Monte Carlo simulation. Among the criteria used to quantify the quality of filters, we employ the equivalent number of looks, and line and edge preservation. Moreover, we also assessed the filters by the Universal Image Quality Index and by the Pearson correlation between edges. Applications to real images are also discussed. The proposed methods show good results.\n    ",
        "submission_date": "2013-08-20T00:00:00",
        "last_modified_date": "2013-08-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1308.4718",
        "title": "Invertibility and Robustness of Phaseless Reconstruction",
        "authors": [
            "Radu Balan",
            "Yang Wang"
        ],
        "abstract": "This paper is concerned with the question of reconstructing a vector in a finite-dimensional real Hilbert space when only the magnitudes of the coefficients of the vector under a redundant linear map are known. We analyze various Lipschitz bounds of the nonlinear analysis map and we establish theoretical performance bounds of any reconstruction algorithm. We show that robust and stable reconstruction requires additional redundancy than the critical threshold.\n    ",
        "submission_date": "2013-08-21T00:00:00",
        "last_modified_date": "2013-08-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1308.5465",
        "title": "Stability of Phase Retrievable Frames",
        "authors": [
            "Radu Balan"
        ],
        "abstract": "In this paper we study the property of phase retrievability by redundant sysems of vectors under perturbations of the frame set. Specifically we show that if a set $\\fc$ of $m$ vectors in the complex Hilbert space of dimension n allows for vector reconstruction from magnitudes of its coefficients, then there is a perturbation bound $\\rho$ so that any frame set within $\\rho$ from $\\fc$ has the same property. In particular this proves the recent construction in \\cite{BH13} is stable under perturbations. By the same token we reduce the critical cardinality conjectured in \\cite{BCMN13a} to proving a stability result for non phase-retrievable frames.\n    ",
        "submission_date": "2013-08-25T00:00:00",
        "last_modified_date": "2013-08-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1308.6487",
        "title": "A New Algorithm of Speckle Filtering using Stochastic Distances",
        "authors": [
            "Leonardo Torres",
            "Tamer Cavalcante",
            "Alejandro C. Frery"
        ],
        "abstract": "This paper presents a new approach for filter design based on stochastic distances and tests between distributions. A window is defined around each pixel, overlapping samples are compared and only those which pass a goodness-of-fit test are used to compute the filtered value. The technique is applied to intensity SAR data with homogeneous regions using the Gamma model. The proposal is compared with the Lee's filter using a protocol based on Monte Carlo. Among the criteria used to quantify the quality of filters, we employ the equivalent number of looks, line and edge preservation. Moreover, we also assessed the filters by the Universal Image Quality Index and the Pearson's correlation on edges regions.\n    ",
        "submission_date": "2013-08-29T00:00:00",
        "last_modified_date": "2013-08-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1309.0270",
        "title": "High-Accuracy Total Variation for Compressed Video Sensing",
        "authors": [
            "Mahdi S. Hosseini",
            "Konstantinos N. Plataniotis"
        ],
        "abstract": "Numerous total variation (TV) regularizers, engaged in image restoration problem, encode the gradients by means of simple $[-1,1]$ FIR filter. Despite its low computational processing, this filter severely deviates signal's high frequency components pertinent to edge/discontinuous information and cause several deficiency issues known as texture and geometric loss. This paper addresses this problem by proposing an alternative model to the TV regularization problem via high order accuracy differential FIR filters to preserve rapid transitions in signal recovery. A numerical encoding scheme is designed to extend the TV model into multidimensional representation (tensorial decomposition). We adopt this design to regulate the spatial and temporal redundancy in compressed video sensing problem to jointly recover frames from under-sampled measurements. We then seek the solution via alternating direction methods of multipliers and find a unique solution to quadratic minimization step with capability of handling different boundary conditions. The resulting algorithm uses much lower sampling rate and highly outperforms alternative state-of-the-art methods. This is evaluated both in terms of restoration accuracy and visual quality of the recovered frames.\n    ",
        "submission_date": "2013-09-01T00:00:00",
        "last_modified_date": "2014-03-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1309.0985",
        "title": "Efficient binary tomographic reconstruction",
        "authors": [
            "Stephane Roux",
            "Hugo Leclerc",
            "Fran\u00e7ois Hild"
        ],
        "abstract": "Tomographic reconstruction of a binary image from few projections is considered. A novel {\\em heuristic} algorithm is proposed, the central element of which is a nonlinear transformation $\\psi(p)=\\log(p/(1-p))$ of the probability $p$ that a pixel of the sought image be 1-valued. It consists of backprojections based on $\\psi(p)$ and iterative corrections. Application of this algorithm to a series of artificial test cases leads to exact binary reconstructions, (i.e recovery of the binary image for each single pixel) from the knowledge of projection data over a few directions. Images up to $10^6$ pixels are reconstructed in a few seconds. A series of test cases is performed for comparison with previous methods, showing a better efficiency and reduced computation times.\n    ",
        "submission_date": "2013-09-04T00:00:00",
        "last_modified_date": "2013-09-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1309.1853",
        "title": "A General Two-Step Approach to Learning-Based Hashing",
        "authors": [
            "Guosheng Lin",
            "Chunhua Shen",
            "David Suter",
            "Anton van den Hengel"
        ],
        "abstract": "Most existing approaches to hashing apply a single form of hash function, and an optimization process which is typically deeply coupled to this specific form. This tight coupling restricts the flexibility of the method to respond to the data, and can result in complex optimization problems that are difficult to solve. Here we propose a flexible yet simple framework that is able to accommodate different types of loss functions and hash functions. This framework allows a number of existing approaches to hashing to be placed in context, and simplifies the development of new problem-specific hashing methods. Our framework decomposes hashing learning problem into two steps: hash bit learning and hash function learning based on the learned bits. The first step can typically be formulated as binary quadratic problems, and the second step can be accomplished by training standard binary classifiers. Both problems have been extensively studied in the literature. Our extensive experiments demonstrate that the proposed framework is effective, flexible and outperforms the state-of-the-art.\n    ",
        "submission_date": "2013-09-07T00:00:00",
        "last_modified_date": "2013-09-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1309.2084",
        "title": "Real-Time and Continuous Hand Gesture Spotting: an Approach Based on Artificial Neural Networks",
        "authors": [
            "Pedro Neto",
            "D\u00e1rio Pereira",
            "Norberto Pires",
            "Paulo Moreira"
        ],
        "abstract": "New and more natural human-robot interfaces are of crucial interest to the evolution of robotics. This paper addresses continuous and real-time hand gesture spotting, i.e., gesture segmentation plus gesture recognition. Gesture patterns are recognized by using artificial neural networks (ANNs) specifically adapted to the process of controlling an industrial robot. Since in continuous gesture recognition the communicative gestures appear intermittently with the noncommunicative, we are proposing a new architecture with two ANNs in series to recognize both kinds of gesture. A data glove is used as interface technology. Experimental results demonstrated that the proposed solution presents high recognition rates (over 99% for a library of ten gestures and over 96% for a library of thirty gestures), low training and learning time and a good capacity to generalize from particular situations.\n    ",
        "submission_date": "2013-09-09T00:00:00",
        "last_modified_date": "2013-09-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1309.2094",
        "title": "The Linearized Bregman Method via Split Feasibility Problems: Analysis and Generalizations",
        "authors": [
            "Dirk A. Lorenz",
            "Frank Sch\u00f6pfer",
            "Stephan Wenger"
        ],
        "abstract": "The linearized Bregman method is a method to calculate sparse solutions to systems of linear equations. We formulate this problem as a split feasibility problem, propose an algorithmic framework based on Bregman projections and prove a general convergence result for this framework. Convergence of the linearized Bregman method will be obtained as a special case. Our approach also allows for several generalizations such as other objective functions, incremental iterations, incorporation of non-gaussian noise models or box constraints.\n    ",
        "submission_date": "2013-09-09T00:00:00",
        "last_modified_date": "2013-09-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1309.2240",
        "title": "Contour Manifolds and Optimal Transport",
        "authors": [
            "Bernhard Schmitzer",
            "Christoph Schn\u00f6rr"
        ],
        "abstract": "Describing shapes by suitable measures in object segmentation, as proposed in [24], allows to combine the advantages of the representations as parametrized contours and indicator functions. The pseudo-Riemannian structure of optimal transport can be used to model shapes in ways similar as with contours, while the Kantorovich functional enables the application of convex optimization methods for global optimality of the segmentation functional.\n",
        "submission_date": "2013-09-09T00:00:00",
        "last_modified_date": "2013-09-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1309.3256",
        "title": "Recovery guarantees for exemplar-based clustering",
        "authors": [
            "Abhinav Nellore",
            "Rachel Ward"
        ],
        "abstract": "For a certain class of distributions, we prove that the linear programming relaxation of $k$-medoids clustering---a variant of $k$-means clustering where means are replaced by exemplars from within the dataset---distinguishes points drawn from nonoverlapping balls with high probability once the number of points drawn and the separation distance between any two balls are sufficiently large. Our results hold in the nontrivial regime where the separation distance is small enough that points drawn from different balls may be closer to each other than points drawn from the same ball; in this case, clustering by thresholding pairwise distances between points can fail. We also exhibit numerical evidence of high-probability recovery in a substantially more permissive regime.\n    ",
        "submission_date": "2013-09-12T00:00:00",
        "last_modified_date": "2014-02-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1309.3842",
        "title": "Estimation of intrinsic volumes from digital grey-scale images",
        "authors": [
            "Anne Marie Svane"
        ],
        "abstract": "Local algorithms are common tools for estimating intrinsic volumes from black-and-white digital images. However, these algorithms are typically biased in the design based setting, even when the resolution tends to infinity. Moreover, images recorded in practice are most often blurred grey-scale images rather than black-and-white. In this paper, an extended definition of local algorithms, applying directly to grey-scale images without thresholding, is suggested. We investigate the asymptotics of these new algorithms when the resolution tends to infinity and apply this to construct estimators for surface area and integrated mean curvature that are asymptotically unbiased in certain natural settings.\n    ",
        "submission_date": "2013-09-16T00:00:00",
        "last_modified_date": "2013-09-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1309.4061",
        "title": "Learning a Loopy Model For Semantic Segmentation Exactly",
        "authors": [
            "Andreas Christian Mueller",
            "Sven Behnke"
        ],
        "abstract": "Learning structured models using maximum margin techniques has become an indispensable tool for com- puter vision researchers, as many computer vision applications can be cast naturally as an image labeling problem. Pixel-based or superpixel-based conditional random fields are particularly popular examples. Typ- ically, neighborhood graphs, which contain a large number of cycles, are used. As exact inference in loopy graphs is NP-hard in general, learning these models without approximations is usually deemed infeasible. In this work we show that, despite the theoretical hardness, it is possible to learn loopy models exactly in practical applications. To this end, we analyze the use of multiple approximate inference techniques together with cutting plane training of structural SVMs. We show that our proposed method yields exact solutions with an optimality guarantees in a computer vision application, for little additional computational cost. We also propose a dynamic caching scheme to accelerate training further, yielding runtimes that are comparable with approximate methods. We hope that this insight can lead to a reconsideration of the tractability of loopy models in computer vision.\n    ",
        "submission_date": "2013-09-16T00:00:00",
        "last_modified_date": "2013-09-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1309.4151",
        "title": "A Non-Local Means Filter for Removing the Poisson Noise",
        "authors": [
            "Qiyu Jin",
            "Ion Grama",
            "Quansheng Liu"
        ],
        "abstract": "A new image denoising algorithm to deal with the Poisson noise model is given, which is based on the idea of Non-Local Mean. By using the \"Oracle\" concept, we establish a theorem to show that the Non-Local Means Filter can effectively deal with Poisson noise with some modification. Under the theoretical result, we construct our new algorithm called Non-Local Means Poisson Filter and demonstrate in theory that the filter converges at the usual optimal rate. The filter is as simple as the classic Non-Local Means and the simulation results show that our filter is very competitive.\n    ",
        "submission_date": "2013-09-17T00:00:00",
        "last_modified_date": "2013-09-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1309.4385",
        "title": "Photon counting compressive depth mapping",
        "authors": [
            "Gregory A. Howland",
            "Daniel J. Lum",
            "Matthew R. Ware",
            "John C. Howell"
        ],
        "abstract": "We demonstrate a compressed sensing, photon counting lidar system based on the single-pixel camera. Our technique recovers both depth and intensity maps from a single under-sampled set of incoherent, linear projections of a scene of interest at ultra-low light levels around 0.5 picowatts. Only two-dimensional reconstructions are required to image a three-dimensional scene. We demonstrate intensity imaging and depth mapping at 256 x 256 pixel transverse resolution with acquisition times as short as 3 seconds. We also show novelty filtering, reconstructing only the difference between two instances of a scene. Finally, we acquire 32 x 32 pixel real-time video for three-dimensional object tracking at 14 frames-per-second.\n    ",
        "submission_date": "2013-09-17T00:00:00",
        "last_modified_date": "2013-09-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1309.5401",
        "title": "Nonmyopic View Planning for Active Object Detection",
        "authors": [
            "Nikolay Atanasov",
            "Bharath Sankaran",
            "Jerome Le Ny",
            "George J. Pappas",
            "Kostas Daniilidis"
        ],
        "abstract": "One of the central problems in computer vision is the detection of semantically important objects and the estimation of their pose. Most of the work in object detection has been based on single image processing and its performance is limited by occlusions and ambiguity in appearance and geometry. This paper proposes an active approach to object detection by controlling the point of view of a mobile depth camera. When an initial static detection phase identifies an object of interest, several hypotheses are made about its class and orientation. The sensor then plans a sequence of views, which balances the amount of energy used to move with the chance of identifying the correct hypothesis. We formulate an active hypothesis testing problem, which includes sensor mobility, and solve it using a point-based approximate POMDP algorithm. The validity of our approach is verified through simulation and real-world experiments with the PR2 robot. The results suggest that our approach outperforms the widely-used greedy view point selection and provides a significant improvement over static object detection.\n    ",
        "submission_date": "2013-09-20T00:00:00",
        "last_modified_date": "2013-09-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1309.5427",
        "title": "Latent Fisher Discriminant Analysis",
        "authors": [
            "Gang Chen"
        ],
        "abstract": "Linear Discriminant Analysis (LDA) is a well-known method for dimensionality reduction and classification. Previous studies have also extended the binary-class case into multi-classes. However, many applications, such as object detection and keyframe extraction cannot provide consistent instance-label pairs, while LDA requires labels on instance level for training. Thus it cannot be directly applied for semi-supervised classification problem. In this paper, we overcome this limitation and propose a latent variable Fisher discriminant analysis model. We relax the instance-level labeling into bag-level, is a kind of semi-supervised (video-level labels of event type are required for semantic frame extraction) and incorporates a data-driven prior over the latent variables. Hence, our method combines the latent variable inference and dimension reduction in an unified bayesian framework. We test our method on MUSK and Corel data sets and yield competitive results compared to the baseline approach. We also demonstrate its capacity on the challenging TRECVID MED11 dataset for semantic keyframe extraction and conduct a human-factors ranking-based experimental evaluation, which clearly demonstrates our proposed method consistently extracts more semantically meaningful keyframes than challenging baselines.\n    ",
        "submission_date": "2013-09-21T00:00:00",
        "last_modified_date": "2013-09-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1309.5655",
        "title": "A new look at reweighted message passing",
        "authors": [
            "Vladimir Kolmogorov"
        ],
        "abstract": "We propose a new family of message passing techniques for MAP estimation in graphical models which we call {\\em Sequential Reweighted Message Passing} (SRMP). Special cases include well-known techniques such as {\\em Min-Sum Diffusion} (MSD) and a faster {\\em Sequential Tree-Reweighted Message Passing} (TRW-S). Importantly, our derivation is simpler than the original derivation of TRW-S, and does not involve a decomposition into trees. This allows easy generalizations. We present such a generalization for the case of higher-order graphical models, and test it on several real-world problems with promising results.\n    ",
        "submission_date": "2013-09-22T00:00:00",
        "last_modified_date": "2017-01-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1309.6487",
        "title": "A Unified Framework for Representation-based Subspace Clustering of Out-of-sample and Large-scale Data",
        "authors": [
            "Xi Peng",
            "Huajin Tang",
            "Lei Zhang",
            "Zhang Yi",
            "Shijie Xiao"
        ],
        "abstract": "Under the framework of spectral clustering, the key of subspace clustering is building a similarity graph which describes the neighborhood relations among data points. Some recent works build the graph using sparse, low-rank, and $\\ell_2$-norm-based representation, and have achieved state-of-the-art performance. However, these methods have suffered from the following two limitations. First, the time complexities of these methods are at least proportional to the cube of the data size, which make those methods inefficient for solving large-scale problems. Second, they cannot cope with out-of-sample data that are not used to construct the similarity graph. To cluster each out-of-sample datum, the methods have to recalculate the similarity graph and the cluster membership of the whole data set. In this paper, we propose a unified framework which makes representation-based subspace clustering algorithms feasible to cluster both out-of-sample and large-scale data. Under our framework, the large-scale problem is tackled by converting it as out-of-sample problem in the manner of \"sampling, clustering, coding, and classifying\". Furthermore, we give an estimation for the error bounds by treating each subspace as a point in a hyperspace. Extensive experimental results on various benchmark data sets show that our methods outperform several recently-proposed scalable methods in clustering large-scale data set.\n    ",
        "submission_date": "2013-09-25T00:00:00",
        "last_modified_date": "2015-10-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1309.7522",
        "title": "An Application of Backpropagation Artificial Neural Network Method for Measuring The Severity of Osteoarthritis",
        "authors": [
            "Dian Pratiwi",
            "Diaz D. Santika",
            "Bens Pardamean"
        ],
        "abstract": "The examination of Osteoarthritis disease through X-ray by rheumatology can be classified into four grade of severity. This paper discusses about the application of artificial neural network backpropagation method for measuring the severity of the disease, where the observed X-ray range from wrist to fingers. The main procedures of system in this paper is divided into three, which are image processing, feature extraction, and artificial neural network process. First, an X-ray image digital (200x150 pixels and greyscale) will be thresholded, then extracted features based on probabilistic values of the color intensity of seven bit quantization result, and statistical textures. That feature values then will be normalizing to interval [0.1, 0.9], and then the result would be processing on backpropagation artificial neural network system as input to determine the severity of disease from an X-ray had input before it. From testing with learning rate 0.3, momentum 0.4, hidden units five pieces and about 132 feature vectors, this system had had a level of accuracy of 100% for learning data, 80% for learning and non-learning data, and 66.6% for non-learning data\n    ",
        "submission_date": "2013-09-29T00:00:00",
        "last_modified_date": "2013-09-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1309.7643",
        "title": "Rotationally Invariant Image Representation for Viewing Direction Classification in Cryo-EM",
        "authors": [
            "Zhizhen Zhao",
            "Amit Singer"
        ],
        "abstract": "We introduce a new rotationally invariant viewing angle classification method for identifying, among a large number of Cryo-EM projection images, similar views without prior knowledge of the molecule. Our rotationally invariant features are based on the bispectrum. Each image is denoised and compressed using steerable principal component analysis (PCA) such that rotating an image is equivalent to phase shifting the expansion coefficients. Thus we are able to extend the theory of bispectrum of 1D periodic signals to 2D images. The randomized PCA algorithm is then used to efficiently reduce the dimensionality of the bispectrum coefficients, enabling fast computation of the similarity between any pair of images. The nearest neighbors provide an initial classification of similar viewing angles. In this way, rotational alignment is only performed for images with their nearest neighbors. The initial nearest neighbor classification and alignment are further improved by a new classification method called vector diffusion maps. Our pipeline for viewing angle classification and alignment is experimentally shown to be faster and more accurate than reference-free alignment with rotationally invariant K-means clustering, MSA/MRA 2D classification, and their modern approximations.\n    ",
        "submission_date": "2013-09-29T00:00:00",
        "last_modified_date": "2014-03-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1309.7959",
        "title": "Exploration and Exploitation in Visuomotor Prediction of Autonomous Agents",
        "authors": [
            "Laurens Bliek"
        ],
        "abstract": "This paper discusses various techniques to let an agent learn how to predict the effects of its own actions on its sensor data autonomously, and their usefulness to apply them to visual sensors. An Extreme Learning Machine is used for visuomotor prediction, while various autonomous control techniques that can aid the prediction process by balancing exploration and exploitation are discussed and tested in a simple system: a camera moving over a 2D greyscale image.\n    ",
        "submission_date": "2013-09-19T00:00:00",
        "last_modified_date": "2013-09-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1310.0322",
        "title": "Optical Flow on Evolving Surfaces with Space and Time Regularisation",
        "authors": [
            "Clemens Kirisits",
            "Lukas F. Lang",
            "Otmar Scherzer"
        ],
        "abstract": "We extend the concept of optical flow with spatiotemporal regularisation to a dynamic non-Euclidean setting. Optical flow is traditionally computed from a sequence of flat images. The purpose of this paper is to introduce variational motion estimation for images that are defined on an evolving surface. Volumetric microscopy images depicting a live zebrafish embryo serve as both biological motivation and test data.\n    ",
        "submission_date": "2013-10-01T00:00:00",
        "last_modified_date": "2014-06-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1310.1221",
        "title": "Spatially Scalable Compressed Image Sensing with Hybrid Transform and Inter-layer Prediction Model",
        "authors": [
            "Diego Valsesia",
            "Enrico Magli"
        ],
        "abstract": "Compressive imaging is an emerging application of compressed sensing, devoted to acquisition, encoding and reconstruction of images using random projections as measurements. In this paper we propose a novel method to provide a scalable encoding of an image acquired by means of compressed sensing techniques. Two bit-streams are generated to provide two distinct quality levels: a low-resolution base layer and full-resolution enhancement layer. In the proposed method we exploit a fast preview of the image at the encoder in order to perform inter-layer prediction and encode the prediction residuals only. The proposed method successfully provides resolution and quality scalability with modest complexity and it provides gains in the quality of the reconstructed images with respect to separate encoding of the quality layers. Remarkably, we also show that the scheme can also provide significant gains with respect to a direct, non-scalable system, thus accomplishing two features at once: scalability and improved reconstruction performance.\n    ",
        "submission_date": "2013-10-04T00:00:00",
        "last_modified_date": "2013-10-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1310.1259",
        "title": "A Novel Progressive Image Scanning and Reconstruction Scheme based on Compressed Sensing and Linear Prediction",
        "authors": [
            "Giulio Coluccia",
            "Enrico Magli"
        ],
        "abstract": "Compressed sensing (CS) is an innovative technique allowing to represent signals through a small number of their linear projections. In this paper we address the application of CS to the scenario of progressive acquisition of 2D visual signals in a line-by-line fashion. This is an important setting which encompasses diverse systems such as flatbed scanners and remote sensing imagers. The use of CS in such setting raises the problem of reconstructing a very high number of samples, as are contained in an image, from their linear projections. Conventional reconstruction algorithms, whose complexity is cubic in the number of samples, are computationally intractable. In this paper we develop an iterative reconstruction algorithm that reconstructs an image by iteratively estimating a row, and correlating adjacent rows by means of linear prediction. We develop suitable predictors and test the proposed algorithm in the context of flatbed scanners and remote sensing imaging systems. We show that this approach can significantly improve the results of separate reconstruction of each row, providing very good reconstruction quality with reasonable complexity.\n    ",
        "submission_date": "2013-10-04T00:00:00",
        "last_modified_date": "2013-10-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1310.1341",
        "title": "Director Field Model of the Primary Visual Cortex for Contour Detection",
        "authors": [
            "Vijay Singh",
            "Martin Tchernookov",
            "Rebecca Butterfield",
            "Ilya Nemenman"
        ],
        "abstract": "We aim to build the simplest possible model capable of detecting long, noisy contours in a cluttered visual scene. For this, we model the neural dynamics in the primate primary visual cortex in terms of a continuous director field that describes the average rate and the average orientational preference of active neurons at a particular point in the cortex. We then use a linear-nonlinear dynamical model with long range connectivity patterns to enforce long-range statistical context present in the analyzed images. The resulting model has substantially fewer degrees of freedom than traditional models, and yet it can distinguish large contiguous objects from the background clutter by suppressing the clutter and by filling-in occluded elements of object contours. This results in high-precision, high-recall detection of large objects in cluttered scenes. Parenthetically, our model has a direct correspondence with the Landau - de Gennes theory of nematic liquid crystal in two dimensions.\n    ",
        "submission_date": "2013-10-04T00:00:00",
        "last_modified_date": "2014-10-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1310.1976",
        "title": "Feature Selection Strategies for Classifying High Dimensional Astronomical Data Sets",
        "authors": [
            "Ciro Donalek",
            "Arun Kumar A.",
            "S.G. Djorgovski",
            "Ashish A. Mahabal",
            "Matthew J. Graham",
            "Thomas J. Fuchs",
            "Michael J. Turmon",
            "N. Sajeeth Philip",
            "Michael Ting-Chang Yang",
            "Giuseppe Longo"
        ],
        "abstract": "The amount of collected data in many scientific fields is increasing, all of them requiring a common task: extract knowledge from massive, multi parametric data sets, as rapidly and efficiently possible. This is especially true in astronomy where synoptic sky surveys are enabling new research frontiers in the time domain astronomy and posing several new object classification challenges in multi dimensional spaces; given the high number of parameters available for each object, feature selection is quickly becoming a crucial task in analyzing astronomical data sets. Using data sets extracted from the ongoing Catalina Real-Time Transient Surveys (CRTS) and the Kepler Mission we illustrate a variety of feature selection strategies used to identify the subsets that give the most information and the results achieved applying these techniques to three major astronomical problems.\n    ",
        "submission_date": "2013-10-08T00:00:00",
        "last_modified_date": "2013-10-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1310.2842",
        "title": "Wavelet methods for shape perception in electro-sensing",
        "authors": [
            "Habib Ammari",
            "St\u00e9phane Mallat",
            "Ir\u00e8ne Waldspurger",
            "Han Wang"
        ],
        "abstract": "This paper aims at presenting a new approach to the electro-sensing problem using wavelets. It provides an efficient algorithm for recognizing the shape of a target from micro-electrical impedance measurements. Stability and resolution capabilities of the proposed algorithm are quantified in numerical simulations.\n    ",
        "submission_date": "2013-10-10T00:00:00",
        "last_modified_date": "2013-10-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1310.2880",
        "title": "Feature Selection with Annealing for Computer Vision and Big Data Learning",
        "authors": [
            "Adrian Barbu",
            "Yiyuan She",
            "Liangjing Ding",
            "Gary Gramajo"
        ],
        "abstract": "Many computer vision and medical imaging problems are faced with learning from large-scale datasets, with millions of observations and features. In this paper we propose a novel efficient learning scheme that tightens a sparsity constraint by gradually removing variables based on a criterion and a schedule. The attractive fact that the problem size keeps dropping throughout the iterations makes it particularly suitable for big data learning. Our approach applies generically to the optimization of any differentiable loss function, and finds applications in regression, classification and ranking. The resultant algorithms build variable screening into estimation and are extremely simple to implement. We provide theoretical guarantees of convergence and selection consistency. In addition, one dimensional piecewise linear response functions are used to account for nonlinearity and a second order prior is imposed on these functions to avoid overfitting. Experiments on real and synthetic data show that the proposed method compares very well with other state of the art methods in regression, classification and ranking while being computationally very efficient and scalable.\n    ",
        "submission_date": "2013-10-10T00:00:00",
        "last_modified_date": "2016-03-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1310.4249",
        "title": "Mapping the stereotyped behaviour of freely-moving fruit flies",
        "authors": [
            "Gordon J. Berman",
            "Daniel M. Choi",
            "William Bialek",
            "Joshua W. Shaevitz"
        ],
        "abstract": "Most animals possess the ability to actuate a vast diversity of movements, ostensibly constrained only by morphology and physics. In practice, however, a frequent assumption in behavioral science is that most of an animal's activities can be described in terms of a small set of stereotyped motifs. Here we introduce a method for mapping the behavioral space of organisms, relying only upon the underlying structure of postural movement data to organize and classify behaviors. We find that six different drosophilid species each perform a mix of non-stereotyped actions and over one hundred hierarchically-organized, stereotyped behaviors. Moreover, we use this approach to compare these species' behavioral spaces, systematically identifying subtle behavioral differences between closely-related species.\n    ",
        "submission_date": "2013-10-16T00:00:00",
        "last_modified_date": "2014-08-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1310.4389",
        "title": "ImageSpirit: Verbal Guided Image Parsing",
        "authors": [
            "Ming-Ming Cheng",
            "Shuai Zheng",
            "Wen-Yan Lin",
            "Jonathan Warrell",
            "Vibhav Vineet",
            "Paul Sturgess",
            "Nigel Crook",
            "Niloy Mitra",
            "Philip Torr"
        ],
        "abstract": "Humans describe images in terms of nouns and adjectives while algorithms operate on images represented as sets of pixels. Bridging this gap between how humans would like to access images versus their typical representation is the goal of image parsing, which involves assigning object and attribute labels to pixel. In this paper we propose treating nouns as object labels and adjectives as visual attribute labels. This allows us to formulate the image parsing problem as one of jointly estimating per-pixel object and attribute labels from a set of training images. We propose an efficient (interactive time) solution. Using the extracted labels as handles, our system empowers a user to verbally refine the results. This enables hands-free parsing of an image into pixel-wise object/attribute labels that correspond to human semantics. Verbally selecting objects of interests enables a novel and natural interaction modality that can possibly be used to interact with new generation devices (e.g. smart phones, Google Glass, living room devices). We demonstrate our system on a large number of real-world images with varying complexity. To help understand the tradeoffs compared to traditional mouse based interactions, results are reported for both a large scale quantitative evaluation and a user study.\n    ",
        "submission_date": "2013-10-16T00:00:00",
        "last_modified_date": "2014-05-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1310.4945",
        "title": "A novel sparsity and clustering regularization",
        "authors": [
            "Xiangrong Zeng",
            "M\u00e1rio A. T. Figueiredo"
        ],
        "abstract": "We propose a novel SPARsity and Clustering (SPARC) regularizer, which is a modified version of the previous octagonal shrinkage and clustering algorithm for regression (OSCAR), where, the proposed regularizer consists of a $K$-sparse constraint and a pair-wise $\\ell_{\\infty}$ norm restricted on the $K$ largest components in magnitude. The proposed regularizer is able to separably enforce $K$-sparsity and encourage the non-zeros to be equal in magnitude. Moreover, it can accurately group the features without shrinking their magnitude. In fact, SPARC is closely related to OSCAR, so that the proximity operator of the former can be efficiently computed based on that of the latter, allowing using proximal splitting algorithms to solve problems with SPARC regularization. Experiments on synthetic data and with benchmark breast cancer data show that SPARC is a competitive group-sparsity inducing regularizer for regression and classification.\n    ",
        "submission_date": "2013-10-18T00:00:00",
        "last_modified_date": "2014-02-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1310.5715",
        "title": "Stochastic Gradient Descent, Weighted Sampling, and the Randomized Kaczmarz algorithm",
        "authors": [
            "Deanna Needell",
            "Nathan Srebro",
            "Rachel Ward"
        ],
        "abstract": "We obtain an improved finite-sample guarantee on the linear convergence of stochastic gradient descent for smooth and strongly convex objectives, improving from a quadratic dependence on the conditioning $(L/\\mu)^2$ (where $L$ is a bound on the smoothness and $\\mu$ on the strong convexity) to a linear dependence on $L/\\mu$. Furthermore, we show how reweighting the sampling distribution (i.e. importance sampling) is necessary in order to further improve convergence, and obtain a linear dependence in the average smoothness, dominating previous results. We also discuss importance sampling for SGD more broadly and show how it can improve convergence also in other scenarios. Our results are based on a connection we make between SGD and the randomized Kaczmarz algorithm, which allows us to transfer ideas between the separate bodies of literature studying each of the two methods. In particular, we recast the randomized Kaczmarz algorithm as an instance of SGD, and apply our results to prove its exponential convergence, but to the solution of a weighted least squares problem rather than the original least squares problem. We then present a modified Kaczmarz algorithm with partially biased sampling which does converge to the original least squares solution with the same exponential convergence rate.\n    ",
        "submission_date": "2013-10-21T00:00:00",
        "last_modified_date": "2015-01-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1310.5781",
        "title": "RANSAC: Identification of Higher-Order Geometric Features and Applications in Humanoid Robot Soccer",
        "authors": [
            "Madison Flannery",
            "Shannon Fenn",
            "David Budden"
        ],
        "abstract": "The ability for an autonomous agent to self-localise is directly proportional to the accuracy and precision with which it can perceive salient features within its local environment. The identification of such features by recognising geometric profile allows robustness against lighting variations, which is necessary in most industrial robotics applications. This paper details a framework by which the random sample consensus (RANSAC) algorithm, often applied to parameter fitting in linear models, can be extended to identify higher-order geometric features. Goalpost identification within humanoid robot soccer is investigated as an application, with the developed system yielding an order-of-magnitude improvement in classification performance relative to a traditional histogramming methodology.\n    ",
        "submission_date": "2013-10-22T00:00:00",
        "last_modified_date": "2013-10-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1310.7217",
        "title": "Compressed Sensing SAR Imaging with Multilook Processing",
        "authors": [
            "Jian Fang",
            "Zongben Xu",
            "Bingchen Zhang",
            "Wen Hong",
            "Yirong Wu"
        ],
        "abstract": "Multilook processing is a widely used speckle reduction approach in synthetic aperture radar (SAR) imaging. Conventionally, it is achieved by incoherently summing of some independent low-resolution images formulated from overlapping subbands of the SAR signal. However, in the context of compressive sensing (CS) SAR imaging, where the samples are collected at sub-Nyquist rate, the data spectrum is highly aliased that hinders the direct application of the existing multilook techniques. In this letter, we propose a new CS-SAR imaging method that can realize multilook processing simultaneously during image reconstruction. The main idea is to replace the SAR observation matrix by the inverse of multilook procedures, which is then combined with random sampling matrix to yield a multilook CS-SAR observation model. Then a joint sparse regularization model, considering pixel dependency of subimages, is derived to form multilook images. The suggested SAR imaging method can not only reconstruct sparse scene efficiently below Nyquist rate, but is also able to achieve a comparable reduction of speckles during reconstruction. Simulation results are finally provided to demonstrate the effectiveness of the proposed method.\n    ",
        "submission_date": "2013-10-27T00:00:00",
        "last_modified_date": "2013-10-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1311.1132",
        "title": "Motion and audio analysis in mobile devices for remote monitoring of physical activities and user authentication",
        "authors": [
            "Hamed Ketabdar",
            "Jalaluddin Qureshi",
            "Pan Hui"
        ],
        "abstract": "In this article we propose the use of accelerometer embedded by default in smartphone as a cost-effective, reliable and efficient way to provide remote physical activity monitoring for the elderly and people requiring healthcare service. Mobile phones are regularly carried by users during their day-to-day work routine, physical movement information can be captured by the mobile phone accelerometer, processed and sent to a remote server for monitoring. The acceleration pattern can deliver information related to the pattern of physical activities the user is engaged in. We further show how this technique can be extended to provide implicit real-time security by analysing unexpected movements captured by the phone accelerometer, and automatically locking the phone in such situation to prevent unauthorised access. This technique is also shown to provide implicit continuous user authentication, by capturing regular user movements such as walking, and requesting for re-authentication whenever it detects a non-regular movement.\n    ",
        "submission_date": "2013-11-05T00:00:00",
        "last_modified_date": "2013-11-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1311.2460",
        "title": "Vision-Guided Robot Hearing",
        "authors": [
            "Xavier Alameda-Pineda",
            "Radu Horaud"
        ],
        "abstract": "Natural human-robot interaction in complex and unpredictable environments is one of the main research lines in robotics. In typical real-world scenarios, humans are at some distance from the robot and the acquired signals are strongly impaired by noise, reverberations and other interfering sources. In this context, the detection and localisation of speakers plays a key role since it is the pillar on which several tasks (e.g.: speech recognition and speaker tracking) rely. We address the problem of how to detect and localize people that are both seen and heard by a humanoid robot. We introduce a hybrid deterministic/probabilistic model. Indeed, the deterministic component allows us to map the visual information into the auditory space. By means of the probabilistic component, the visual features guide the grouping of the auditory features in order to form AV objects. The proposed model and the associated algorithm are implemented in real-time (17 FPS) using a stereoscopic camera pair and two microphones embedded into the head of the humanoid robot NAO. We performed experiments on (i) synthetic data, (ii) a publicly available data set and (iii) data acquired using the robot. The results we obtained validate the approach and encourage us to further investigate how vision can help robot hearing.\n    ",
        "submission_date": "2013-11-06T00:00:00",
        "last_modified_date": "2013-12-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1311.4252",
        "title": "Contour polygonal approximation using shortest path in networks",
        "authors": [
            "Andr\u00e9 Ricardo Backes",
            "Dalcimar Casanova",
            "Odemir Martinez Bruno"
        ],
        "abstract": "Contour polygonal approximation is a simplified representation of a contour by line segments, so that the main characteristics of the contour remain in a small number of line segments. This paper presents a novel method for polygonal approximation based on the Complex Networks theory. We convert each point of the contour into a vertex, so that we model a regular network. Then we transform this network into a Small-World Complex Network by applying some transformations over its edges. By analyzing of network properties, especially the geodesic path, we compute the polygonal approximation. The paper presents the main characteristics of the method, as well as its functionality. We evaluate the proposed method using benchmark contours, and compare its results with other polygonal approximation methods.\n    ",
        "submission_date": "2013-11-18T00:00:00",
        "last_modified_date": "2013-11-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1311.4665",
        "title": "Analysis of Farthest Point Sampling for Approximating Geodesics in a Graph",
        "authors": [
            "Pegah Kamousi",
            "Sylvain Lazard",
            "Anil Maheshwari",
            "Stefanie Wuhrer"
        ],
        "abstract": "A standard way to approximate the distance between any two vertices $p$ and $q$ on a mesh is to compute, in the associated graph, a shortest path from $p$ to $q$ that goes through one of $k$ sources, which are well-chosen vertices. Precomputing the distance between each of the $k$ sources to all vertices of the graph yields an efficient computation of approximate distances between any two vertices. One standard method for choosing $k$ sources, which has been used extensively and successfully for isometry-invariant surface processing, is the so-called Farthest Point Sampling (FPS), which starts with a random vertex as the first source, and iteratively selects the farthest vertex from the already selected sources.\n",
        "submission_date": "2013-11-19T00:00:00",
        "last_modified_date": "2013-11-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1311.4924",
        "title": "Robust Compressed Sensing Under Matrix Uncertainties",
        "authors": [
            "Yipeng Liu"
        ],
        "abstract": "Compressed sensing (CS) shows that a signal having a sparse or compressible representation can be recovered from a small set of linear measurements. In classical CS theory, the sampling matrix and representation matrix are assumed to be known exactly in advance. However, uncertainties exist due to sampling distortion, finite grids of the parameter space of dictionary, etc. In this paper, we take a generalized sparse signal model, which simultaneously considers the sampling and representation matrix uncertainties. Based on the new signal model, a new optimization model for robust sparse signal reconstruction is proposed. This optimization model can be deduced with stochastic robust approximation analysis. Both convex relaxation and greedy algorithms are used to solve the optimization problem. For the convex relaxation method, a sufficient condition for recovery by convex relaxation is given; For the greedy algorithm, it is realized by the introduction of a pre-processing of the sensing matrix and the measurements. In numerical experiments, both simulated data and real-life ECG data based results show that the proposed method has a better performance than the current methods.\n    ",
        "submission_date": "2013-11-20T00:00:00",
        "last_modified_date": "2015-07-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1311.5290",
        "title": "Texture descriptor combining fractal dimension and artificial crawlers",
        "authors": [
            "Wesley Nunes Gon\u00e7alves",
            "Bruno Brandoli Machado",
            "Odemir Martinez Bruno"
        ],
        "abstract": "Texture is an important visual attribute used to describe images. There are many methods available for texture analysis. However, they do not capture the details richness of the image surface. In this paper, we propose a new method to describe textures using the artificial crawler model. This model assumes that each agent can interact with the environment and each other. Since this swarm system alone does not achieve a good discrimination, we developed a new method to increase the discriminatory power of artificial crawlers, together with the fractal dimension theory. Here, we estimated the fractal dimension by the Bouligand-Minkowski method due to its precision in quantifying structural properties of images. We validate our method on two texture datasets and the experimental results reveal that our method leads to highly discriminative textural features. The results indicate that our method can be used in different texture applications.\n    ",
        "submission_date": "2013-11-21T00:00:00",
        "last_modified_date": "2013-11-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1311.6371",
        "title": "On Approximate Inference for Generalized Gaussian Process Models",
        "authors": [
            "Lifeng Shang",
            "Antoni B. Chan"
        ],
        "abstract": "A generalized Gaussian process model (GGPM) is a unifying framework that encompasses many existing Gaussian process (GP) models, such as GP regression, classification, and counting. In the GGPM framework, the observation likelihood of the GP model is itself parameterized using the exponential family distribution (EFD). In this paper, we consider efficient algorithms for approximate inference on GGPMs using the general form of the EFD. A particular GP model and its associated inference algorithms can then be formed by changing the parameters of the EFD, thus greatly simplifying its creation for task-specific output domains. We demonstrate the efficacy of this framework by creating several new GP models for regressing to non-negative reals and to real intervals. We also consider a closed-form Taylor approximation for efficient inference on GGPMs, and elaborate on its connections with other model-specific heuristic closed-form approximations. Finally, we present a comprehensive set of experiments to compare approximate inference algorithms on a wide variety of GGPMs.\n    ",
        "submission_date": "2013-11-25T00:00:00",
        "last_modified_date": "2013-11-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1311.7194",
        "title": "Real-time High Resolution Fusion of Depth Maps on GPU",
        "authors": [
            "Dmitry Trifonov"
        ],
        "abstract": "A system for live high quality surface reconstruction using a single moving depth camera on a commodity hardware is presented. High accuracy and real-time frame rate is achieved by utilizing graphics hardware computing capabilities via OpenCL and by using sparse data structure for volumetric surface representation. Depth sensor pose is estimated by combining serial texture registration algorithm with iterative closest points algorithm (ICP) aligning obtained depth map to the estimated scene model. Aligned surface is then fused into the scene. Kalman filter is used to improve fusion quality. Truncated signed distance function (TSDF) stored as block-based sparse buffer is used to represent surface. Use of sparse data structure greatly increases accuracy of scanned surfaces and maximum scanning area. Traditional GPU implementation of volumetric rendering and fusion algorithms were modified to exploit sparsity to achieve desired performance. Incorporation of texture registration for sensor pose estimation and Kalman filter for measurement integration improved accuracy and robustness of scanning process.\n    ",
        "submission_date": "2013-11-28T00:00:00",
        "last_modified_date": "2013-11-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1311.7295",
        "title": "Glasgow's Stereo Image Database of Garments",
        "authors": [
            "Gerardo Aragon-Camarasa",
            "Susanne B. Oehler",
            "Yuan Liu",
            "Sun Li",
            "Paul Cockshott",
            "J. Paul Siebert"
        ],
        "abstract": "To provide insight into cloth perception and manipulation with an active binocular robotic vision system, we compiled a database of 80 stereo-pair colour images with corresponding horizontal and vertical disparity maps and mask annotations, for 3D garment point cloud rendering has been created and released. The stereo-image garment database is part of research conducted under the EU-FP7 Clothes Perception and Manipulation (CloPeMa) project and belongs to a wider database collection released through CloPeMa (",
        "submission_date": "2013-11-28T00:00:00",
        "last_modified_date": "2013-11-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1311.7401",
        "title": "Shape from Texture using Locally Scaled Point Processes",
        "authors": [
            "Eva-Maria Didden",
            "Thordis Linda Thorarinsdottir",
            "Alex Lenkoski",
            "Christoph Schn\u00f6rr"
        ],
        "abstract": "Shape from texture refers to the extraction of 3D information from 2D images with irregular texture. This paper introduces a statistical framework to learn shape from texture where convex texture elements in a 2D image are represented through a point process. In a first step, the 2D image is preprocessed to generate a probability map corresponding to an estimate of the unnormalized intensity of the latent point process underlying the texture elements. The latent point process is subsequently inferred from the probability map in a non-parametric, model free manner. Finally, the 3D information is extracted from the point pattern by applying a locally scaled point process model where the local scaling function represents the deformation caused by the projection of a 3D surface onto a 2D image.\n    ",
        "submission_date": "2013-11-28T00:00:00",
        "last_modified_date": "2013-11-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1311.7662",
        "title": "The Power of Asymmetry in Binary Hashing",
        "authors": [
            "Behnam Neyshabur",
            "Payman Yadollahpour",
            "Yury Makarychev",
            "Ruslan Salakhutdinov",
            "Nathan Srebro"
        ],
        "abstract": "When approximating binary similarity using the hamming distance between short binary hashes, we show that even if the similarity is symmetric, we can have shorter and more accurate hashes by using two distinct code maps. I.e. by approximating the similarity between $x$ and $x'$ as the hamming distance between $f(x)$ and $g(x')$, for two distinct binary codes $f,g$, rather than as the hamming distance between $f(x)$ and $f(x')$.\n    ",
        "submission_date": "2013-11-29T00:00:00",
        "last_modified_date": "2013-11-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.0809",
        "title": "Automatic White Blood Cell Measuring Aid for Medical Diagnosis",
        "authors": [
            "Pramit Ghosh",
            "Debotosh Bhattacharjee",
            "Mita Nasipuri",
            "Dipak Kumar Basu"
        ],
        "abstract": "Blood related invasive pathological investigations play a major role in diagnosis of diseases. But in India and other third world countries there are no enough pathological infrastructures for medical diagnosis. Moreover, most of the remote places of those countries have neither pathologists nor physicians. Telemedicine partially solves the lack of physicians. But the pathological investigation infrastructure can not be integrated with the telemedicine technology. The objective of this work is to automate the blood related pathological investigation process. Detection of different white blood cells has been automated in this work. This system can be deployed in the remote area as a supporting aid for telemedicine technology and only high school education is sufficient to operate it. The proposed system achieved 97.33 percent accuracy for the samples collected to test this system.\n    ",
        "submission_date": "2013-12-03T00:00:00",
        "last_modified_date": "2013-12-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.0940",
        "title": "Medical Aid for Automatic Detection of Malaria",
        "authors": [
            "Pramit Ghosh",
            "Debotosh Bhattacharjee",
            "Mita Nasipuri",
            "Dipak Kumar Basu"
        ],
        "abstract": "The analysis and counting of blood cells in a microscope image can provide useful information concerning to the health of a person. In particular, morphological analysis of red blood cells deformations can effectively detect important disease like malaria. Blood images, obtained by the microscope, which is coupled with a digital camera, are analyzed by the computer for diagnosis or can be transmitted easily to clinical centers than liquid blood samples. Automatic analysis system for the presence of Plasmodium in microscopic image of blood can greatly help pathologists and doctors that typically inspect blood films manually. Unfortunately, the analysis made by human experts is not rapid and not yet standardized due to the operators capabilities and tiredness. The paper shows how effectively and accurately it is possible to identify the Plasmodium in the blood film. In particular, the paper presents how to enhance the microscopic image and filter out the unnecessary segments followed by the threshold based segmentation and recognize the presence of Plasmodium. The proposed system can be deployed in the remote area as a supporting aid for telemedicine technology and only basic training is sufficient to operate it. This system achieved more than 98 percentage accuracy for the samples collected to test this system.\n    ",
        "submission_date": "2013-12-03T00:00:00",
        "last_modified_date": "2013-12-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.1492",
        "title": "A fast and robust algorithm to count topologically persistent holes in noisy clouds",
        "authors": [
            "Vitaliy Kurlin"
        ],
        "abstract": "Preprocessing a 2D image often produces a noisy cloud of interest points. We study the problem of counting holes in unorganized clouds in the plane. The holes in a given cloud are quantified by the topological persistence of their boundary contours when the cloud is analyzed at all possible scales. We design the algorithm to count holes that are most persistent in the filtration of offsets (neighborhoods) around given points. The input is a cloud of $n$ points in the plane without any user-defined parameters. The algorithm has $O(n\\log n)$ time and $O(n)$ space. The output is the array (number of holes, relative persistence in the filtration). We prove theoretical guarantees when the algorithm finds the correct number of holes (components in the complement) of an unknown shape approximated by a cloud.\n    ",
        "submission_date": "2013-12-05T00:00:00",
        "last_modified_date": "2014-07-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.1494",
        "title": "Approximating persistent homology for a cloud of $n$ points in a subquadratic time",
        "authors": [
            "Vitaliy Kurlin"
        ],
        "abstract": "The Vietoris-Rips filtration for an $n$-point metric space is a sequence of large simplicial complexes adding a topological structure to the otherwise disconnected space. The persistent homology is a key tool in topological data analysis and studies topological features of data that persist over many scales. The fastest algorithm for computing persistent homology of a filtration has time $O(M(u)+u^2\\log^2 u)$, where $u$ is the number of updates (additions or deletions of simplices), $M(u)=O(u^{2.376})$ is the time for multiplication of $u\\times u$ matrices. For a space of $n$ points given by their pairwise distances, we approximate the Vietoris-Rips filtration by a zigzag filtration consisting of $u=o(n)$ updates, which is sublinear in $n$. The constant depends on a given error of approximation and on the doubling dimension of the metric space. Then the persistent homology of this sublinear-size filtration can be computed in time $o(n^2)$, which is subquadratic in $n$.\n    ",
        "submission_date": "2013-12-05T00:00:00",
        "last_modified_date": "2017-09-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.1725",
        "title": "Book embeddings of Reeb graphs",
        "authors": [
            "Vitaliy Kurlin"
        ],
        "abstract": "Let $X$ be a simplicial complex with a piecewise linear function $f:X\\to\\mathbb{R}$. The Reeb graph $Reeb(f,X)$ is the quotient of $X$, where we collapse each connected component of $f^{-1}(t)$ to a single point. Let the nodes of $Reeb(f,X)$ be all homologically critical points where any homology of the corresponding component of the level set $f^{-1}(t)$ changes. Then we can label every arc of $Reeb(f,X)$ with the Betti numbers $(\\beta_1,\\beta_2,\\dots,\\beta_d)$ of the corresponding $d$-dimensional component of a level set. The homology labels give more information about the original complex $X$ than the classical Reeb graph. We describe a canonical embedding of a Reeb graph into a multi-page book (a star cross a line) and give a unique linear code of this book embedding.\n    ",
        "submission_date": "2013-12-05T00:00:00",
        "last_modified_date": "2013-12-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.1743",
        "title": "Dual coordinate solvers for large-scale structural SVMs",
        "authors": [
            "Deva Ramanan"
        ],
        "abstract": "This manuscript describes a method for training linear SVMs (including binary SVMs, SVM regression, and structural SVMs) from large, out-of-core training datasets. Current strategies for large-scale learning fall into one of two camps; batch algorithms which solve the learning problem given a finite datasets, and online algorithms which can process out-of-core datasets. The former typically requires datasets small enough to fit in memory. The latter is often phrased as a stochastic optimization problem; such algorithms enjoy strong theoretical properties but often require manual tuned annealing schedules, and may converge slowly for problems with large output spaces (e.g., structural SVMs). We discuss an algorithm for an \"intermediate\" regime in which the data is too large to fit in memory, but the active constraints (support vectors) are small enough to remain in memory. In this case, one can design rather efficient learning algorithms that are as stable as batch algorithms, but capable of processing out-of-core datasets. We have developed such a MATLAB-based solver and used it to train a collection of recognition systems for articulated pose estimation, facial analysis, 3D object recognition, and action classification, all with publicly-available code. This writeup describes the solver in detail.\n    ",
        "submission_date": "2013-12-06T00:00:00",
        "last_modified_date": "2014-06-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.1909",
        "title": "From Maxout to Channel-Out: Encoding Information on Sparse Pathways",
        "authors": [
            "Qi Wang",
            "Joseph JaJa"
        ],
        "abstract": "Motivated by an important insight from neural science, we propose a new framework for understanding the success of the recently proposed \"maxout\" networks. The framework is based on encoding information on sparse pathways and recognizing the correct pathway at inference time. Elaborating further on this insight, we propose a novel deep network architecture, called \"channel-out\" network, which takes a much better advantage of sparse pathway encoding. In channel-out networks, pathways are not only formed a posteriori, but they are also actively selected according to the inference outputs from the lower layers. From a mathematical perspective, channel-out networks can represent a wider class of piece-wise continuous functions, thereby endowing the network with more expressive power than that of maxout networks. We test our channel-out networks on several well-known image classification benchmarks, setting new state-of-the-art performance on CIFAR-100 and STL-10, which represent some of the \"harder\" image classification benchmarks.\n    ",
        "submission_date": "2013-11-18T00:00:00",
        "last_modified_date": "2013-11-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.2877",
        "title": "Automated Classification of L/R Hand Movement EEG Signals using Advanced Feature Extraction and Machine Learning",
        "authors": [
            "Mohammad H. Alomari",
            "Aya Samaha",
            "Khaled AlKamha"
        ],
        "abstract": "In this paper, we propose an automated computer platform for the purpose of classifying Electroencephalography (EEG) signals associated with left and right hand movements using a hybrid system that uses advanced feature extraction techniques and machine learning algorithms. It is known that EEG represents the brain activity by the electrical voltage fluctuations along the scalp, and Brain-Computer Interface (BCI) is a device that enables the use of the brain neural activity to communicate with others or to control machines, artificial limbs, or robots without direct physical movements. In our research work, we aspired to find the best feature extraction method that enables the differentiation between left and right executed fist movements through various classification algorithms. The EEG dataset used in this research was created and contributed to PhysioNet by the developers of the BCI2000 instrumentation system. Data was preprocessed using the EEGLAB MATLAB toolbox and artifacts removal was done using AAR. Data was epoched on the basis of Event-Related (De) Synchronization (ERD/ERS) and movement-related cortical potentials (MRCP) features. Mu/beta rhythms were isolated for the ERD/ERS analysis and delta rhythms were isolated for the MRCP analysis. The Independent Component Analysis (ICA) spatial filter was applied on related channels for noise reduction and isolation of both artifactually and neutrally generated EEG sources. The final feature vector included the ERD, ERS, and MRCP features in addition to the mean, power and energy of the activations of the resulting independent components of the epoched feature datasets. The datasets were inputted into two machine-learning algorithms: Neural Networks (NNs) and Support Vector Machines (SVMs). Intensive experiments were carried out and optimum classification performances of 89.8 and 97.1 were obtained using NN and SVM, respectively.\n    ",
        "submission_date": "2013-12-10T00:00:00",
        "last_modified_date": "2013-12-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.3522",
        "title": "Sparse Matrix-based Random Projection for Classification",
        "authors": [
            "Weizhi Lu",
            "Weiyu Li",
            "Kidiyo Kpalma",
            "Joseph Ronsin"
        ],
        "abstract": "As a typical dimensionality reduction technique, random projection can be simply implemented with linear projection, while maintaining the pairwise distances of high-dimensional data with high probability. Considering this technique is mainly exploited for the task of classification, this paper is developed to study the construction of random matrix from the viewpoint of feature selection, rather than of traditional distance preservation. This yields a somewhat surprising theoretical result, that is, the sparse random matrix with exactly one nonzero element per column, can present better feature selection performance than other more dense matrices, if the projection dimension is sufficiently large (namely, not much smaller than the number of feature elements); otherwise, it will perform comparably to others. For random projection, this theoretical result implies considerable improvement on both complexity and performance, which is widely confirmed with the classification experiments on both synthetic data and real data.\n    ",
        "submission_date": "2013-12-12T00:00:00",
        "last_modified_date": "2014-10-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.4346",
        "title": "Teleoperation System Using Past Image Records Considering Narrow Communication Band",
        "authors": [
            "Noritaka Sato",
            "Masataka Ito",
            "Yoshifumi Morita",
            "Fumitoshi Matsuno"
        ],
        "abstract": "Teleoperation is necessary when the robot is applied to real missions, for example surveillance, search and rescue. We proposed teleoperation system using past image records (SPIR). SPIR virtually generates the bird's-eye view image by overlaying the CG model of the robot at the corresponding current position on the background image which is captured from the camera mounted on the robot at a past time. The problem for SPIR is that the communication bandwidth is often narrow in some teleoperation tasks. In this case, the candidates of background image of SPIR are few and the position of the robot is often delayed. In this study, we propose zoom function for insufficiency of candidates of the background image and additional interpolation lines for the delay of the position data of the robot. To evaluate proposed system, an outdoor experiments are carried out. The outdoor experiment is conducted on a training course of a driving school.\n    ",
        "submission_date": "2013-12-16T00:00:00",
        "last_modified_date": "2013-12-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.4354",
        "title": "Decomposition of Optical Flow on the Sphere",
        "authors": [
            "Clemens Kirisits",
            "Lukas F. Lang",
            "Otmar Scherzer"
        ],
        "abstract": "We propose a number of variational regularisation methods for the estimation and decomposition of motion fields on the $2$-sphere. While motion estimation is based on the optical flow equation, the presented decomposition models are motivated by recent trends in image analysis. In particular we treat $u+v$ decomposition as well as hierarchical decomposition. Helmholtz decomposition of motion fields is obtained as a natural by-product of the chosen numerical method based on vector spherical harmonics. All models are tested on time-lapse microscopy data depicting fluorescently labelled endodermal cells of a zebrafish embryo.\n    ",
        "submission_date": "2013-12-16T00:00:00",
        "last_modified_date": "2014-03-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.4400",
        "title": "Network In Network",
        "authors": [
            "Min Lin",
            "Qiang Chen",
            "Shuicheng Yan"
        ],
        "abstract": "We propose a novel deep network structure called \"Network In Network\" (NIN) to enhance model discriminability for local patches within the receptive field. The conventional convolutional layer uses linear filters followed by a nonlinear activation function to scan the input. Instead, we build micro neural networks with more complex structures to abstract the data within the receptive field. We instantiate the micro neural network with a multilayer perceptron, which is a potent function approximator. The feature maps are obtained by sliding the micro networks over the input in a similar manner as CNN; they are then fed into the next layer. Deep NIN can be implemented by stacking mutiple of the above described structure. With enhanced local modeling via the micro network, we are able to utilize global average pooling over feature maps in the classification layer, which is easier to interpret and less prone to overfitting than traditional fully connected layers. We demonstrated the state-of-the-art classification performances with NIN on CIFAR-10 and CIFAR-100, and reasonable performances on SVHN and MNIST datasets.\n    ",
        "submission_date": "2013-12-16T00:00:00",
        "last_modified_date": "2014-03-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.5033",
        "title": "Evaluation of Plane Detection with RANSAC According to Density of 3D Point Clouds",
        "authors": [
            "Tomofumi Fujiwara",
            "Tetsushi Kamegawa",
            "Akio Gofuku"
        ],
        "abstract": "We have implemented a method that detects planar regions from 3D scan data using Random Sample Consensus (RANSAC) algorithm to address the issue of a trade-off between the scanning speed and the point density of 3D scanning. However, the limitation of the implemented method has not been clear yet. In this paper, we conducted an additional experiment to evaluate the implemented method by changing its parameter and environments in both high and low point density data. As a result, the number of detected planes in high point density data was different from that in low point density data with the same parameter value.\n    ",
        "submission_date": "2013-12-18T00:00:00",
        "last_modified_date": "2013-12-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.5355",
        "title": "Generative NeuroEvolution for Deep Learning",
        "authors": [
            "Phillip Verbancsics",
            "Josh Harguess"
        ],
        "abstract": "An important goal for the machine learning (ML) community is to create approaches that can learn solutions with human-level capability. One domain where humans have held a significant advantage is visual processing. A significant approach to addressing this gap has been machine learning approaches that are inspired from the natural systems, such as artificial neural networks (ANNs), evolutionary computation (EC), and generative and developmental systems (GDS). Research into deep learning has demonstrated that such architectures can achieve performance competitive with humans on some visual tasks; however, these systems have been primarily trained through supervised and unsupervised learning algorithms. Alternatively, research is showing that evolution may have a significant role in the development of visual systems. Thus this paper investigates the role neuro-evolution (NE) can take in deep learning. In particular, the Hypercube-based NeuroEvolution of Augmenting Topologies is a NE approach that can effectively learn large neural structures by training an indirect encoding that compresses the ANN weight pattern as a function of geometry. The results show that HyperNEAT struggles with performing image classification by itself, but can be effective in training a feature extractor that other ML approaches can learn from. Thus NeuroEvolution combined with other ML methods provides an intriguing area of research that can replicate the processes in nature.\n    ",
        "submission_date": "2013-12-18T00:00:00",
        "last_modified_date": "2013-12-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.5783",
        "title": "Unsupervised Feature Learning by Deep Sparse Coding",
        "authors": [
            "Yunlong He",
            "Koray Kavukcuoglu",
            "Yun Wang",
            "Arthur Szlam",
            "Yanjun Qi"
        ],
        "abstract": "In this paper, we propose a new unsupervised feature learning framework, namely Deep Sparse Coding (DeepSC), that extends sparse coding to a multi-layer architecture for visual object recognition tasks. The main innovation of the framework is that it connects the sparse-encoders from different layers by a sparse-to-dense module. The sparse-to-dense module is a composition of a local spatial pooling step and a low-dimensional embedding process, which takes advantage of the spatial smoothness information in the image. As a result, the new method is able to learn several levels of sparse representation of the image which capture features at a variety of abstraction levels and simultaneously preserve the spatial smoothness between the neighboring image patches. Combining the feature representations from multiple layers, DeepSC achieves the state-of-the-art performance on multiple object recognition tasks.\n    ",
        "submission_date": "2013-12-20T00:00:00",
        "last_modified_date": "2013-12-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.5845",
        "title": "Competitive Learning with Feedforward Supervisory Signal for Pre-trained Multilayered Networks",
        "authors": [
            "Takashi Shinozaki",
            "Yasushi Naruse"
        ],
        "abstract": "We propose a novel learning method for multilayered neural networks which uses feedforward supervisory signal and associates classification of a new input with that of pre-trained input. The proposed method effectively uses rich input information in the earlier layer for robust leaning and revising internal representation in a multilayer neural network.\n    ",
        "submission_date": "2013-12-20T00:00:00",
        "last_modified_date": "2015-02-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.6120",
        "title": "Exact solutions to the nonlinear dynamics of learning in deep linear neural networks",
        "authors": [
            "Andrew M. Saxe",
            "James L. McClelland",
            "Surya Ganguli"
        ],
        "abstract": "Despite the widespread practical success of deep learning methods, our theoretical understanding of the dynamics of learning in deep neural networks remains quite sparse. We attempt to bridge the gap between the theory and practice of deep learning by systematically analyzing learning dynamics for the restricted case of deep linear neural networks. Despite the linearity of their input-output map, such networks have nonlinear gradient descent dynamics on weights that change with the addition of each new hidden layer. We show that deep linear networks exhibit nonlinear learning phenomena similar to those seen in simulations of nonlinear networks, including long plateaus followed by rapid transitions to lower error solutions, and faster convergence from greedy unsupervised pretraining initial conditions than from random initial conditions. We provide an analytical description of these phenomena by finding new exact solutions to the nonlinear dynamics of deep learning. Our theoretical analysis also reveals the surprising finding that as the depth of a network approaches infinity, learning speed can nevertheless remain finite: for a special class of initial conditions on the weights, very deep networks incur only a finite, depth independent, delay in learning speed relative to shallow networks. We show that, under certain conditions on the training data, unsupervised pretraining can find this special class of initial conditions, while scaled random Gaussian initializations cannot. We further exhibit a new class of random orthogonal initial conditions on weights that, like unsupervised pre-training, enjoys depth independent learning times. We further show that these initial conditions also lead to faithful propagation of gradients even in deep nonlinear networks, as long as they operate in a special regime known as the edge of chaos.\n    ",
        "submission_date": "2013-12-20T00:00:00",
        "last_modified_date": "2014-02-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.6158",
        "title": "Deep Belief Networks for Image Denoising",
        "authors": [
            "Mohammad Ali Keyvanrad",
            "Mohammad Pezeshki",
            "Mohammad Ali Homayounpour"
        ],
        "abstract": "Deep Belief Networks which are hierarchical generative models are effective tools for feature representation and extraction. Furthermore, DBNs can be used in numerous aspects of Machine Learning such as image denoising. In this paper, we propose a novel method for image denoising which relies on the DBNs' ability in feature representation. This work is based upon learning of the noise behavior. Generally, features which are extracted using DBNs are presented as the values of the last layer nodes. We train a DBN a way that the network totally distinguishes between nodes presenting noise and nodes presenting image content in the last later of DBN, i.e. the nodes in the last layer of trained DBN are divided into two distinct groups of nodes. After detecting the nodes which are presenting the noise, we are able to make the noise nodes inactive and reconstruct a noiseless image. In section 4 we explore the results of applying this method on the MNIST dataset of handwritten digits which is corrupted with additive white Gaussian noise (AWGN). A reduction of 65.9% in average mean square error (MSE) was achieved when the proposed method was used for the reconstruction of the noisy images.\n    ",
        "submission_date": "2013-12-20T00:00:00",
        "last_modified_date": "2014-01-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.6171",
        "title": "Learning Paired-associate Images with An Unsupervised Deep Learning Architecture",
        "authors": [
            "Ti Wang",
            "Daniel L. Silver"
        ],
        "abstract": "This paper presents an unsupervised multi-modal learning system that learns associative representation from two input modalities, or channels, such that input on one channel will correctly generate the associated response at the other and vice versa. In this way, the system develops a kind of supervised classification model meant to simulate aspects of human associative memory. The system uses a deep learning architecture (DLA) composed of two input/output channels formed from stacked Restricted Boltzmann Machines (RBM) and an associative memory network that combines the two channels. The DLA is trained on pairs of MNIST handwritten digit images to develop hierarchical features and associative representations that are able to reconstruct one image given its paired-associate. Experiments show that the multi-modal learning system generates models that are as accurate as back-propagation networks but with the advantage of a bi-directional network and unsupervised learning from either paired or non-paired training examples.\n    ",
        "submission_date": "2013-12-20T00:00:00",
        "last_modified_date": "2014-01-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.6203",
        "title": "Spectral Networks and Locally Connected Networks on Graphs",
        "authors": [
            "Joan Bruna",
            "Wojciech Zaremba",
            "Arthur Szlam",
            "Yann LeCun"
        ],
        "abstract": "Convolutional Neural Networks are extremely efficient architectures in image and audio recognition tasks, thanks to their ability to exploit the local translational invariance of signal classes over their domain. In this paper we consider possible generalizations of CNNs to signals defined on more general domains without the action of a translation group. In particular, we propose two constructions, one based upon a hierarchical clustering of the domain, and another based on the spectrum of the graph Laplacian. We show through experiments that for low-dimensional graphs it is possible to learn convolutional layers with a number of parameters independent of the input size, resulting in efficient deep architectures.\n    ",
        "submission_date": "2013-12-21T00:00:00",
        "last_modified_date": "2014-05-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.6208",
        "title": "Total variation with overlapping group sparsity for image deblurring under impulse noise",
        "authors": [
            "Gang Liu",
            "Ting-Zhu Huang",
            "Jun Liu",
            "Xiao-Guang Lv"
        ],
        "abstract": "The total variation (TV) regularization method is an effective method for image deblurring in preserving edges. However, the TV based solutions usually have some staircase effects. In this paper, in order to alleviate the staircase effect, we propose a new model for restoring blurred images with impulse noise. The model consists of an $\\ell_1$-fidelity term and a TV with overlapping group sparsity (OGS) regularization term. Moreover, we impose a box constraint to the proposed model for getting more accurate solutions. An efficient and effective algorithm is proposed to solve the model under the framework of the alternating direction method of multipliers (ADMM). We use an inner loop which is nested inside the majorization minimization (MM) iteration for the subproblem of the proposed method. Compared with other methods, numerical results illustrate that the proposed method, can significantly improve the restoration quality, both in avoiding staircase effects and in terms of peak signal-to-noise ratio (PSNR) and relative error (ReE).\n    ",
        "submission_date": "2013-12-21T00:00:00",
        "last_modified_date": "2013-12-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.6813",
        "title": "New explicit thresholding/shrinkage formulas for one class of regularization problems with overlapping group sparsity and their applications",
        "authors": [
            "Gang Liu",
            "Ting-Zhu Huang",
            "Xiao-Guang Lv",
            "Jun Liu"
        ],
        "abstract": "The least-square regression problems or inverse problems have been widely studied in many fields such as compressive sensing, signal processing, and image processing. To solve this kind of ill-posed problems, a regularization term (i.e., regularizer) should be introduced, under the assumption that the solutions have some specific properties, such as sparsity and group sparsity. Widely used regularizers include the $\\ell_1$ norm, total variation (TV) semi-norm, and so on.\n",
        "submission_date": "2013-12-24T00:00:00",
        "last_modified_date": "2014-05-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.6849",
        "title": "Speech Recognition Front End Without Information Loss",
        "authors": [
            "Matthew Ager",
            "Zoran Cvetkovic",
            "Peter Sollich"
        ],
        "abstract": "Speech representation and modelling in high-dimensional spaces of acoustic waveforms, or a linear transformation thereof, is investigated with the aim of improving the robustness of automatic speech recognition to additive noise. The motivation behind this approach is twofold: (i) the information in acoustic waveforms that is usually removed in the process of extracting low-dimensional features might aid robust recognition by virtue of structured redundancy analogous to channel coding, (ii) linear feature domains allow for exact noise adaptation, as opposed to representations that involve non-linear processing which makes noise adaptation challenging. Thus, we develop a generative framework for phoneme modelling in high-dimensional linear feature domains, and use it in phoneme classification and recognition tasks. Results show that classification and recognition in this framework perform better than analogous PLP and MFCC classifiers below 18 dB SNR. A combination of the high-dimensional and MFCC features at the likelihood level performs uniformly better than either of the individual representations across all noise levels.\n    ",
        "submission_date": "2013-12-24T00:00:00",
        "last_modified_date": "2015-03-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.6965",
        "title": "An Unsupervised Approach for Automatic Activity Recognition based on Hidden Markov Model Regression",
        "authors": [
            "Dorra Trabelsi",
            "Samer Mohammed",
            "Faicel Chamroukhi",
            "Latifa Oukhellou",
            "Yacine Amirat"
        ],
        "abstract": "Using supervised machine learning approaches to recognize human activities from on-body wearable accelerometers generally requires a large amount of labelled data. When ground truth information is not available, too expensive, time consuming or difficult to collect, one has to rely on unsupervised approaches. This paper presents a new unsupervised approach for human activity recognition from raw acceleration data measured using inertial wearable sensors. The proposed method is based upon joint segmentation of multidimensional time series using a Hidden Markov Model (HMM) in a multiple regression context. The model is learned in an unsupervised framework using the Expectation-Maximization (EM) algorithm where no activity labels are needed. The proposed method takes into account the sequential appearance of the data. It is therefore adapted for the temporal acceleration data to accurately detect the activities. It allows both segmentation and classification of the human activities. Experimental results are provided to demonstrate the efficiency of the proposed approach with respect to standard supervised and unsupervised classification approaches\n    ",
        "submission_date": "2013-12-25T00:00:00",
        "last_modified_date": "2013-12-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.7167",
        "title": "Near-separable Non-negative Matrix Factorization with $\\ell_1$- and Bregman Loss Functions",
        "authors": [
            "Abhishek Kumar",
            "Vikas Sindhwani"
        ],
        "abstract": "Recently, a family of tractable NMF algorithms have been proposed under the assumption that the data matrix satisfies a separability condition Donoho & Stodden (2003); Arora et al. (2012). Geometrically, this condition reformulates the NMF problem as that of finding the extreme rays of the conical hull of a finite set of vectors. In this paper, we develop several extensions of the conical hull procedures of Kumar et al. (2013) for robust ($\\ell_1$) approximations and Bregman divergences. Our methods inherit all the advantages of Kumar et al. (2013) including scalability and noise-tolerance. We show that on foreground-background separation problems in computer vision, robust near-separable NMFs match the performance of Robust PCA, considered state of the art on these problems, with an order of magnitude faster training time. We also demonstrate applications in exemplar selection settings.\n    ",
        "submission_date": "2013-12-27T00:00:00",
        "last_modified_date": "2013-12-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.7219",
        "title": "Combining persistent homology and invariance groups for shape comparison",
        "authors": [
            "Patrizio Frosini",
            "Grzegorz Jablonski"
        ],
        "abstract": "In many applications concerning the comparison of data expressed by $\\mathbb{R}^m$-valued functions defined on a topological space $X$, the invariance with respect to a given group $G$ of self-homeomorphisms of $X$ is required. While persistent homology is quite efficient in the topological and qualitative comparison of this kind of data when the invariance group $G$ is the group $\\mathrm{Homeo}(X)$ of all self-homeomorphisms of $X$, this theory is not tailored to manage the case in which $G$ is a proper subgroup of $\\mathrm{Homeo}(X)$, and its invariance appears too general for several tasks. This paper proposes a way to adapt persistent homology in order to get invariance just with respect to a given group of self-homeomorphisms of $X$. The main idea consists in a dual approach, based on considering the set of all $G$-invariant non-expanding operators defined on the space of the admissible filtering functions on $X$. Some theoretical results concerning this approach are proven and two experiments are presented. An experiment illustrates the application of the proposed technique to compare 1D-signals, when the invariance is expressed by the group of affinities, the group of orientation-preserving affinities, the group of isometries, the group of translations and the identity group. Another experiment shows how our technique can be used for image comparison.\n    ",
        "submission_date": "2013-12-27T00:00:00",
        "last_modified_date": "2016-01-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.7463",
        "title": "Generalized Ambiguity Decomposition for Understanding Ensemble Diversity",
        "authors": [
            "Kartik Audhkhasi",
            "Abhinav Sethy",
            "Bhuvana Ramabhadran",
            "Shrikanth S. Narayanan"
        ],
        "abstract": "Diversity or complementarity of experts in ensemble pattern recognition and information processing systems is widely-observed by researchers to be crucial for achieving performance improvement upon fusion. Understanding this link between ensemble diversity and fusion performance is thus an important research question. However, prior works have theoretically characterized ensemble diversity and have linked it with ensemble performance in very restricted settings. We present a generalized ambiguity decomposition (GAD) theorem as a broad framework for answering these questions. The GAD theorem applies to a generic convex ensemble of experts for any arbitrary twice-differentiable loss function. It shows that the ensemble performance approximately decomposes into a difference of the average expert performance and the diversity of the ensemble. It thus provides a theoretical explanation for the empirically-observed benefit of fusing outputs from diverse classifiers and regressors. It also provides a loss function-dependent, ensemble-dependent, and data-dependent definition of diversity. We present extensions of this decomposition to common regression and classification loss functions, and report a simulation-based analysis of the diversity term and the accuracy of the decomposition. We finally present experiments on standard pattern recognition data sets which indicate the accuracy of the decomposition for real-world classification and regression problems.\n    ",
        "submission_date": "2013-12-28T00:00:00",
        "last_modified_date": "2013-12-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.7523",
        "title": "Learning Temporal Logical Properties Discriminating ECG models of Cardiac Arrhytmias",
        "authors": [
            "Ezio Bartocci",
            "Luca Bortolussi",
            "Guido Sanguinetti"
        ],
        "abstract": "We present a novel approach to learn the formulae characterising the emergent behaviour of a dynamical system from system observations. At a high level, the approach starts by devising a statistical dynamical model of the system which optimally fits the observations. We then propose general optimisation strategies for selecting high support formulae (under the learnt model of the system) either within a discrete set of formulae of bounded complexity, or a parametric family of formulae. We illustrate and apply the methodology on an in-depth case study of characterising cardiac malfunction from electro-cardiogram data, where our approach enables us to quantitatively determine the diagnostic power of a formula in discriminating between different cardiac conditions.\n    ",
        "submission_date": "2013-12-29T00:00:00",
        "last_modified_date": "2013-12-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1312.7710",
        "title": "Total variation regularization for manifold-valued data",
        "authors": [
            "Andreas Weinmann",
            "Laurent Demaret",
            "Martin Storath"
        ],
        "abstract": "We consider total variation minimization for manifold valued data. We propose a cyclic proximal point algorithm and a parallel proximal point algorithm to minimize TV functionals with $\\ell^p$-type data terms in the manifold case. These algorithms are based on iterative geodesic averaging which makes them easily applicable to a large class of data manifolds. As an application, we consider denoising images which take their values in a manifold. We apply our algorithms to diffusion tensor images, interferometric SAR images as well as sphere and cylinder valued images. For the class of Cartan-Hadamard manifolds (which includes the data space in diffusion tensor imaging) we show the convergence of the proposed TV minimizing algorithms to a global minimizer.\n    ",
        "submission_date": "2013-12-30T00:00:00",
        "last_modified_date": "2013-12-30T00:00:00"
    }
]