[
    {
        "url": "https://arxiv.org/abs/1001.0927",
        "title": "Accelerating Competitive Learning Graph Quantization",
        "authors": [
            "Brijnesh J. Jain",
            "Klaus Obermayer"
        ],
        "abstract": "  Vector quantization(VQ) is a lossy data compression technique from signal processing for which simple competitive learning is one standard method to quantize patterns from the input space. Extending competitive learning VQ to the domain of graphs results in competitive learning for quantizing input graphs. In this contribution, we propose an accelerated version of competitive learning graph quantization (GQ) without trading computational time against solution quality. For this, we lift graphs locally to vectors in order to avoid unnecessary calculations of intractable graph distances. In doing so, the accelerated version of competitive learning GQ gradually turns locally into a competitive learning VQ with increasing number of iterations. Empirical results show a significant speedup by maintaining a comparable solution quality.\n    ",
        "submission_date": "2010-01-06T00:00:00",
        "last_modified_date": "2010-01-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1001.1027",
        "title": "An Unsupervised Algorithm For Learning Lie Group Transformations",
        "authors": [
            "Jascha Sohl-Dickstein",
            "Ching Ming Wang",
            "Bruno A. Olshausen"
        ],
        "abstract": "We present several theoretical contributions which allow Lie groups to be fit to high dimensional datasets. Transformation operators are represented in their eigen-basis, reducing the computational complexity of parameter estimation to that of training a linear transformation model. A transformation specific \"blurring\" operator is introduced that allows inference to escape local minima via a smoothing of the transformation space. A penalty on traversed manifold distance is added which encourages the discovery of sparse, minimal distance, transformations between states. Both learning and inference are demonstrated using these methods for the full set of affine transformations on natural image patches. Transformation operators are then trained on natural video sequences. It is shown that the learned video transformations provide a better description of inter-frame differences than the standard motion model based on rigid translation.\n    ",
        "submission_date": "2010-01-07T00:00:00",
        "last_modified_date": "2017-06-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1001.1221",
        "title": "Boosting k-NN for categorization of natural scenes",
        "authors": [
            "Paolo Piro",
            "Richard Nock",
            "Frank Nielsen",
            "Michel Barlaud"
        ],
        "abstract": "  The k-nearest neighbors (k-NN) classification rule has proven extremely successful in countless many computer vision applications. For example, image categorization often relies on uniform voting among the nearest prototypes in the space of descriptors. In spite of its good properties, the classic k-NN rule suffers from high variance when dealing with sparse prototype datasets in high dimensions. A few techniques have been proposed to improve k-NN classification, which rely on either deforming the nearest neighborhood relationship or modifying the input space. In this paper, we propose a novel boosting algorithm, called UNN (Universal Nearest Neighbors), which induces leveraged k-NN, thus generalizing the classic k-NN rule. We redefine the voting rule as a strong classifier that linearly combines predictions from the k closest prototypes. Weak classifiers are learned by UNN so as to minimize a surrogate risk. A major feature of UNN is the ability to learn which prototypes are the most relevant for a given class, thus allowing one for effective data reduction. Experimental results on the synthetic two-class dataset of Ripley show that such a filtering strategy is able to reject \"noisy\" prototypes. We carried out image categorization experiments on a database containing eight classes of natural scenes. We show that our method outperforms significantly the classic k-NN classification, while enabling significant reduction of the computational cost by means of data filtering.\n    ",
        "submission_date": "2010-01-08T00:00:00",
        "last_modified_date": "2010-01-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1001.1966",
        "title": "A New Method to Extract Dorsal Hand Vein Pattern using Quadratic Inference Function",
        "authors": [
            "Maleika Heenaye Mamode Khan",
            "Naushad Ali Mamode Khan"
        ],
        "abstract": "  Among all biometric, dorsal hand vein pattern is attracting the attention of researchers, of late. Extensive research is being carried out on various techniques in the hope of finding an efficient one which can be applied on dorsal hand vein pattern to improve its accuracy and matching time. One of the crucial step in biometric is the extraction of features. In this paper, we propose a method based on quadratic inference function to the dorsal hand vein features to extract its features. The biometric system developed was tested on a database of 100 images. The false acceptance rate (FAR), false rejection rate (FRR) and the matching time are being computed.\n    ",
        "submission_date": "2010-01-12T00:00:00",
        "last_modified_date": "2010-01-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1001.1968",
        "title": "A Topological derivative based image segmentation for sign language recognition system using isotropic filter",
        "authors": [
            "M. Krishnaveni",
            "Dr. V. Radha"
        ],
        "abstract": "  The need of sign language is increasing radically especially to hearing impaired community. Only few research groups try to automatically recognize sign language from video, colored gloves and etc. Their approach requires a valid segmentation of the data that is used for training and of the data that is used to be recognized. Recognition of a sign language image sequence is challenging because of the variety of hand shapes and hand motions. Here, this paper proposes to apply a combination of image segmentation with restoration using topological derivatives for achieving high recognition accuracy. Image quality measures are conceded here to differentiate the methods both subjectively as well as objectively. Experiments show that the additional use of the restoration before segmenting the postures significantly improves the correct rate of hand detection, and that the discrete derivatives yields a high rate of discrimination between different static hand postures as well as between hand postures and the scene background. Eventually, the research is to contribute to the implementation of automated sign language recognition system mainly established for the welfare purpose.\n    ",
        "submission_date": "2010-01-12T00:00:00",
        "last_modified_date": "2010-01-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1001.1988",
        "title": "An Improved Image Mining Technique For Brain Tumour Classification Using Efficient Classifier",
        "authors": [
            "P. Rajendran",
            "M. Madheswaran"
        ],
        "abstract": "  An improved image mining technique for brain tumor classification using pruned association rule with MARI algorithm is presented in this paper. The method proposed makes use of association rule mining technique to classify the CT scan brain images into three categories namely normal, benign and malign. It combines the low level features extracted from images and high level knowledge from specialists. The developed algorithm can assist the physicians for efficient classification with multiple keywords per image to improve the accuracy. The experimental result on prediagnosed database of brain images showed 96 percent and 93 percent sensitivity and accuracy respectively.\n    ",
        "submission_date": "2010-01-12T00:00:00",
        "last_modified_date": "2010-01-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1001.2605",
        "title": "An Explicit Nonlinear Mapping for Manifold Learning",
        "authors": [
            "Hong Qiao",
            "Peng Zhang",
            "Di Wang",
            "Bo Zhang"
        ],
        "abstract": "  Manifold learning is a hot research topic in the field of computer science and has many applications in the real world. A main drawback of manifold learning methods is, however, that there is no explicit mappings from the input data manifold to the output embedding. This prohibits the application of manifold learning methods in many practical problems such as classification and target detection. Previously, in order to provide explicit mappings for manifold learning methods, many methods have been proposed to get an approximate explicit representation mapping with the assumption that there exists a linear projection between the high-dimensional data samples and their low-dimensional embedding. However, this linearity assumption may be too restrictive. In this paper, an explicit nonlinear mapping is proposed for manifold learning, based on the assumption that there exists a polynomial mapping between the high-dimensional data samples and their low-dimensional representations. As far as we know, this is the first time that an explicit nonlinear mapping for manifold learning is given. In particular, we apply this to the method of Locally Linear Embedding (LLE) and derive an explicit nonlinear manifold learning algorithm, named Neighborhood Preserving Polynomial Embedding (NPPE). Experimental results on both synthetic and real-world data show that the proposed mapping is much more effective in preserving the local neighborhood information and the nonlinear geometry of the high-dimensional data samples than previous work.\n    ",
        "submission_date": "2010-01-15T00:00:00",
        "last_modified_date": "2010-01-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1001.2636",
        "title": "Analytical shape determination of fiber-like objects with Virtual Image Correlation",
        "authors": [
            "Benoit Semin",
            "Marc Louis Maurice Fran\u00e7ois",
            "Harold Auradou"
        ],
        "abstract": "  This paper reports a method allowing for the determination of the shape of deformed fiber-like objects. Compared to existing methods, it provides analytical results including the local slope and curvature which are of first importance, for instance, in beam mechanics. The presented VIC (Virtual Image Correlation) method consists in looking for the best correlation between the image of the fiber-like object and a virtual beam image, using an algorithm close to the Digital Image Correlation method developed in experimental solid mechanics. The computation only involves the part of the image in the vicinity of the fiber: the method is thus insensitive to the picture background and the computational cost remains low. Two examples are reported: the first proves the precision of the method, the second its ability to identify a complex shape with multiple loops.\n    ",
        "submission_date": "2010-01-15T00:00:00",
        "last_modified_date": "2010-01-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1001.3487",
        "title": "Features Based Text Similarity Detection",
        "authors": [
            "Chow Kok Kent",
            "Naomie Salim"
        ],
        "abstract": "  As the Internet help us cross cultural border by providing different information, plagiarism issue is bound to arise. As a result, plagiarism detection becomes more demanding in overcoming this issue. Different plagiarism detection tools have been developed based on various detection techniques. Nowadays, fingerprint matching technique plays an important role in those detection tools. However, in handling some large content articles, there are some weaknesses in fingerprint matching technique especially in space and time consumption issue. In this paper, we propose a new approach to detect plagiarism which integrates the use of fingerprint matching technique with four key features to assist in the detection process. These proposed features are capable to choose the main point or key sentence in the articles to be compared. Those selected sentence will be undergo the fingerprint matching process in order to detect the similarity between the sentences. Hence, time and space usage for the comparison process is reduced without affecting the effectiveness of the plagiarism detection.\n    ",
        "submission_date": "2010-01-20T00:00:00",
        "last_modified_date": "2010-01-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1001.3502",
        "title": "3D Skull Recognition Using 3D Matching Technique",
        "authors": [
            "Hamdan.O.Alanazi",
            "B.B Zaidan",
            "A.A Zaidan"
        ],
        "abstract": "  Biometrics has become a \"hot\" area. Governments are funding research programs focused on biometrics. In this paper the problem of person recognition and verification based on a different biometric application has been addressed. The system is based on the 3DSkull recognition using 3D matching technique, in fact this paper present several bio-metric approaches in order of assign the weak point in term of used the biometric from the authorize person and insure the person who access the data is the real person. The feature of the simulate system shows the capability of using 3D matching system as an efficient way to identify the person through his or her skull by match it with database, this technique grantee fast processing with optimizing the false positive and negative as well .\n    ",
        "submission_date": "2010-01-20T00:00:00",
        "last_modified_date": "2010-01-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1001.3503",
        "title": "Hybrid Medical Image Classification Using Association Rule Mining with Decision Tree Algorithm",
        "authors": [
            "P. Rajendran",
            "M.Madheswaran"
        ],
        "abstract": "  The main focus of image mining in the proposed method is concerned with the classification of brain tumor in the CT scan brain images. The major steps involved in the system are: pre-processing, feature extraction, association rule mining and hybrid classifier. The pre-processing step has been done using the median filtering process and edge features have been extracted using canny edge detection technique. The two image mining approaches with a hybrid manner have been proposed in this paper. The frequent patterns from the CT scan images are generated by frequent pattern tree (FP-Tree) algorithm that mines the association rules. The decision tree method has been used to classify the medical images for diagnosis. This system enhances the classification process to be more accurate. The hybrid method improves the efficiency of the proposed method than the traditional image mining methods. The experimental result on prediagnosed database of brain images showed 97% sensitivity and 95% accuracy respectively. The physicians can make use of this accurate decision tree classification phase for classifying the brain images into normal, benign and malignant for effective medical diagnosis.\n    ",
        "submission_date": "2010-01-20T00:00:00",
        "last_modified_date": "2010-01-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1001.3735",
        "title": "Gradient Based Seeded Region Grow method for CT Angiographic Image Segmentation",
        "authors": [
            "G.N. Harikrishna Rai",
            "T.R. Gopalakrishnan Nair"
        ],
        "abstract": "  Segmentation of medical images using seeded region growing technique is increasingly becoming a popular method because of its ability to involve high-level knowledge of anatomical structures in seed selection process. Region based segmentation of medical images are widely used in varied clinical applications like visualization, bone detection, tumor detection and unsupervised image retrieval in clinical databases. As medical images are mostly fuzzy in nature, segmenting regions based intensity is the most challenging task. In this paper, we discuss about popular seeded region grow methodology used for segmenting anatomical structures in CT Angiography images. We have proposed a gradient based homogeneity criteria to control the region grow process while segmenting CTA images.\n    ",
        "submission_date": "2010-01-21T00:00:00",
        "last_modified_date": "2010-01-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1001.4140",
        "title": "SVM-based Multiview Face Recognition by Generalization of Discriminant Analysis",
        "authors": [
            "Dakshina Ranjan Kisku",
            "Hunny Mehrotra",
            "Jamuna Kanta Sing",
            "Phalguni Gupta"
        ],
        "abstract": "  Identity verification of authentic persons by their multiview faces is a real valued problem in machine vision. Multiview faces are having difficulties due to non-linear representation in the feature space. This paper illustrates the usability of the generalization of LDA in the form of canonical covariate for face recognition to multiview faces. In the proposed work, the Gabor filter bank is used to extract facial features that characterized by spatial frequency, spatial locality and orientation. Gabor face representation captures substantial amount of variations of the face instances that often occurs due to illumination, pose and facial expression changes. Convolution of Gabor filter bank to face images of rotated profile views produce Gabor faces with high dimensional features vectors. Canonical covariate is then used to Gabor faces to reduce the high dimensional feature spaces into low dimensional subspaces. Finally, support vector machines are trained with canonical sub-spaces that contain reduced set of features and perform recognition task. The proposed system is evaluated with UMIST face database. The experiment results demonstrate the efficiency and robustness of the proposed system with high recognition rates.\n    ",
        "submission_date": "2010-01-23T00:00:00",
        "last_modified_date": "2010-01-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1001.4189",
        "title": "Detection and Demarcation of Tumor using Vector Quantization in MRI images",
        "authors": [
            "H. B. Kekre",
            "Tanuja K. Sarode",
            "Saylee M. Gharge"
        ],
        "abstract": "  Segmenting a MRI images into homogeneous texture regions representing disparate tissue types is often a useful preprocessing step in the computer-assisted detection of breast cancer. That is why we proposed new algorithm to detect cancer in mammogram breast cancer images. In this paper we proposed segmentation using vector quantization technique. Here we used Linde Buzo-Gray algorithm (LBG) for segmentation of MRI images. Initially a codebook of size 128 was generated for MRI images. These code vectors were further clustered in 8 clusters using same LBG algorithm. These 8 images were displayed as a result. This approach does not leads to over segmentation or under segmentation. For the comparison purpose we displayed results of watershed segmentation and Entropy using Gray Level Co-occurrence Matrix along with this method.\n    ",
        "submission_date": "2010-01-23T00:00:00",
        "last_modified_date": "2010-01-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1001.4297",
        "title": "Multi-camera Realtime 3D Tracking of Multiple Flying Animals",
        "authors": [
            "Andrew D. Straw",
            "Kristin Branson",
            "Titus R. Neumann",
            "Michael H. Dickinson"
        ],
        "abstract": "  Automated tracking of animal movement allows analyses that would not otherwise be possible by providing great quantities of data. The additional capability of tracking in realtime - with minimal latency - opens up the experimental possibility of manipulating sensory feedback, thus allowing detailed explorations of the neural basis for control of behavior. Here we describe a new system capable of tracking the position and body orientation of animals such as flies and birds. The system operates with less than 40 msec latency and can track multiple animals simultaneously. To achieve these results, a multi target tracking algorithm was developed based on the Extended Kalman Filter and the Nearest Neighbor Standard Filter data association algorithm. In one implementation, an eleven camera system is capable of tracking three flies simultaneously at 60 frames per second using a gigabit network of nine standard Intel Pentium 4 and Core 2 Duo computers. This manuscript presents the rationale and details of the algorithms employed and shows three implementations of the system. An experiment was performed using the tracking system to measure the effect of visual contrast on the flight speed of Drosophila melanogaster. At low contrasts, speed is more variable and faster on average than at high contrasts. Thus, the system is already a useful tool to study the neurobiology and behavior of freely flying animals. If combined with other techniques, such as `virtual reality'-type computer graphics or genetic manipulation, the tracking system would offer a powerful new way to investigate the biology of flying animals.\n    ",
        "submission_date": "2010-01-25T00:00:00",
        "last_modified_date": "2010-01-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1001.5352",
        "title": "Kannada Character Recognition System A Review",
        "authors": [
            "K. Indira",
            "S. Sethu Selvi"
        ],
        "abstract": "  Intensive research has been done on optical character recognition ocr and a large number of articles have been published on this topic during the last few decades. Many commercial OCR systems are now available in the market, but most of these systems work for Roman, Chinese, Japanese and Arabic characters. There are no sufficient number of works on Indian language character recognition especially Kannada script among 12 major scripts in India. This paper presents a review of existing work on printed Kannada script and their results. The characteristics of Kannada script and Kannada Character Recognition System kcr are discussed in detail. Finally fusion at the classifier level is proposed to increase the recognition accuracy.\n    ",
        "submission_date": "2010-01-29T00:00:00",
        "last_modified_date": "2010-01-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1001.5359",
        "title": "Threshold Based Indexing of Commercial Shoe Print to Create Reference and Recovery Images",
        "authors": [
            "S. Rathinavel",
            "S. Arumugam"
        ],
        "abstract": "  One of the important evidence in a crime scene that is normally overlooked but very important evidence is shoe print as the criminal is normally unaware of the mask for this. In this paper we use image processing technique to process reference shoe images to make it index-able for a search from the database the shoe print impressions available in the commercial market. This is achieved first by converting the commercially available image through the process of converting them to gray scale then apply image enhancement and restoration techniques and finally do image segmentation to store the segmented parameter as index in the database storage. We use histogram method for image enhancement, inverse filtering for image restoration and threshold method for indexing. We use global threshold as index of the shoe print. The paper describes this method and simulation results are included to validate the method.\n    ",
        "submission_date": "2010-01-29T00:00:00",
        "last_modified_date": "2010-01-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1002.0382",
        "title": "Face Recognition by Fusion of Local and Global Matching Scores using DS Theory: An Evaluation with Uni-classifier and Multi-classifier Paradigm",
        "authors": [
            "Dakshina Ranjan Kisku",
            "Massimo Tistarelli",
            "Jamuna Kanta Sing",
            "Phalguni Gupta"
        ],
        "abstract": "  Faces are highly deformable objects which may easily change their appearance over time. Not all face areas are subject to the same variability. Therefore decoupling the information from independent areas of the face is of paramount importance to improve the robustness of any face recognition technique. This paper presents a robust face recognition technique based on the extraction and matching of SIFT features related to independent face areas. Both a global and local (as recognition from parts) matching strategy is proposed. The local strategy is based on matching individual salient facial SIFT features as connected to facial landmarks such as the eyes and the mouth. As for the global matching strategy, all SIFT features are combined together to form a single feature. In order to reduce the identification errors, the Dempster-Shafer decision theory is applied to fuse the two matching techniques. The proposed algorithms are evaluated with the ORL and the IITK face databases. The experimental results demonstrate the effectiveness and potential of the proposed face recognition techniques also in the case of partially occluded faces or with missing information.\n    ",
        "submission_date": "2010-02-02T00:00:00",
        "last_modified_date": "2010-02-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1002.0383",
        "title": "Feature Level Clustering of Large Biometric Database",
        "authors": [
            "Hunny Mehrotra",
            "Dakshina Ranjan Kisku",
            "V. Bhawani Radhika",
            "Banshidhar Majhi",
            "Phalguni Gupta"
        ],
        "abstract": "  This paper proposes an efficient technique for partitioning large biometric database during identification. In this technique feature vector which comprises of global and local descriptors extracted from offline signature are used by fuzzy clustering technique to partition the database. As biometric features posses no natural order of sorting, thus it is difficult to index them alphabetically or numerically. Hence, some supervised criteria is required to partition the search space. At the time of identification the fuzziness criterion is introduced to find the nearest clusters for declaring the identity of query sample. The system is tested using bin-miss rate and performs better in comparison to traditional k-means approach.\n    ",
        "submission_date": "2010-02-02T00:00:00",
        "last_modified_date": "2010-02-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1002.0411",
        "title": "Face Identification by SIFT-based Complete Graph Topology",
        "authors": [
            "Dakshina Ranjan Kisku",
            "Ajita Rattani",
            "Enrico Grosso",
            "Massimo Tistarelli"
        ],
        "abstract": "  This paper presents a new face identification system based on Graph Matching Technique on SIFT features extracted from face images. Although SIFT features have been successfully used for general object detection and recognition, only recently they were applied to face recognition. This paper further investigates the performance of identification techniques based on Graph matching topology drawn on SIFT features which are invariant to rotation, scaling and translation. Face projections on images, represented by a graph, can be matched onto new images by maximizing a similarity function taking into account spatial distortions and the similarities of the local features. Two graph based matching techniques have been investigated to deal with false pair assignment and reducing the number of features to find the optimal feature set between database and query face SIFT features. The experimental results, performed on the BANCA database, demonstrate the effectiveness of the proposed system for automatic face identification.\n    ",
        "submission_date": "2010-02-02T00:00:00",
        "last_modified_date": "2010-02-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1002.0412",
        "title": "SIFT-based Ear Recognition by Fusion of Detected Keypoints from Color Similarity Slice Regions",
        "authors": [
            "Dakshina Ranjan Kisku",
            "Hunny Mehrotra",
            "Phalguni Gupta",
            "Jamuna Kanta Sing"
        ],
        "abstract": "  Ear biometric is considered as one of the most reliable and invariant biometrics characteristics in line with iris and fingerprint characteristics. In many cases, ear biometrics can be compared with face biometrics regarding many physiological and texture characteristics. In this paper, a robust and efficient ear recognition system is presented, which uses Scale Invariant Feature Transform (SIFT) as feature descriptor for structural representation of ear images. In order to make it more robust to user authentication, only the regions having color probabilities in a certain ranges are considered for invariant SIFT feature extraction, where the K-L divergence is used for keeping color consistency. Ear skin color model is formed by Gaussian mixture model and clustering the ear color pattern using vector quantization. Finally, K-L divergence is applied to the GMM framework for recording the color similarity in the specified ranges by comparing color similarity between a pair of reference model and probe ear images. After segmentation of ear images in some color slice regions, SIFT keypoints are extracted and an augmented vector of extracted SIFT features are created for matching, which is accomplished between a pair of reference model and probe ear images. The proposed technique has been tested on the IITK Ear database and the experimental results show improvements in recognition accuracy while invariant features are extracted from color slice regions to maintain the robustness of the system.\n    ",
        "submission_date": "2010-02-02T00:00:00",
        "last_modified_date": "2010-02-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1002.0414",
        "title": "Feature Level Fusion of Biometrics Cues: Human Identification with Doddingtons Caricature",
        "authors": [
            "Dakshina Ranjan Kisku",
            "Phalguni Gupta",
            "Jamuna Kanta Sing"
        ],
        "abstract": "  This paper presents a multimodal biometric system of fingerprint and ear biometrics. Scale Invariant Feature Transform (SIFT) descriptor based feature sets extracted from fingerprint and ear are fused. The fused set is encoded by K-medoids partitioning approach with less number of feature points in the set. K-medoids partition the whole dataset into clusters to minimize the error between data points belonging to the clusters and its center. Reduced feature set is used to match between two biometric sets. Matching scores are generated using wolf-lamb user-dependent feature weighting scheme introduced by Doddington. The technique is tested to exhibit its robust performance.\n    ",
        "submission_date": "2010-02-02T00:00:00",
        "last_modified_date": "2010-02-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1002.0416",
        "title": "Fusion of Multiple Matchers using SVM for Offline Signature Identification",
        "authors": [
            "Dakshina Ranjan Kisku",
            "Phalguni Gupta",
            "Jamuna Kanta Sing"
        ],
        "abstract": "  This paper uses Support Vector Machines (SVM) to fuse multiple classifiers for an offline signature system. From the signature images, global and local features are extracted and the signatures are verified with the help of Gaussian empirical rule, Euclidean and Mahalanobis distance based classifiers. SVM is used to fuse matching scores of these matchers. Finally, recognition of query signatures is done by comparing it with all signatures of the database. The proposed system is tested on a signature database contains 5400 offline signatures of 600 individuals and the results are found to be promising.\n    ",
        "submission_date": "2010-02-02T00:00:00",
        "last_modified_date": "2010-02-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1002.1148",
        "title": "A Comparative Study of Removal Noise from Remote Sensing Image",
        "authors": [
            "Salem Saleh Al-amri",
            "N. V. Kalyankar",
            "S.D. Khamitkar"
        ],
        "abstract": "  This paper attempts to undertake the study of three types of noise such as Salt and Pepper (SPN), Random variation Impulse Noise (RVIN), Speckle (SPKN). Different noise densities have been removed between 10% to 60% by using five types of filters as Mean Filter (MF), Adaptive Wiener Filter (AWF), Gaussian Filter (GF), Standard Median Filter (SMF) and Adaptive Median Filter (AMF). The same is applied to the Saturn remote sensing image and they are compared with one another. The comparative study is conducted with the help of Mean Square Errors (MSE) and Peak-Signal to Noise Ratio (PSNR). So as to choose the base method for removal of noise from remote sensing image.\n    ",
        "submission_date": "2010-02-05T00:00:00",
        "last_modified_date": "2010-02-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1002.1285",
        "title": "The Influence of Intensity Standardization on Medical Image Registration",
        "authors": [
            "Ulas Bagci",
            "Jayaram K. Udupa",
            "Li Bai"
        ],
        "abstract": "  Acquisition-to-acquisition signal intensity variations (non-standardness) are inherent in MR images. Standardization is a post processing method for correcting inter-subject intensity variations through transforming all images from the given image gray scale into a standard gray scale wherein similar intensities achieve similar tissue meanings. The lack of a standard image intensity scale in MRI leads to many difficulties in tissue characterizability, image display, and analysis, including image segmentation. This phenomenon has been documented well; however, effects of standardization on medical image registration have not been studied yet. In this paper, we investigate the influence of intensity standardization in registration tasks with systematic and analytic evaluations involving clinical MR images. We conducted nearly 20,000 clinical MR image registration experiments and evaluated the quality of registrations both quantitatively and qualitatively. The evaluations show that intensity variations between images degrades the accuracy of registration performance. The results imply that the accuracy of image registration not only depends on spatial and geometric similarity but also on the similarity of the intensity values for the same tissues in different images.\n    ",
        "submission_date": "2010-02-05T00:00:00",
        "last_modified_date": "2010-02-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1002.1288",
        "title": "Ball-Scale Based Hierarchical Multi-Object Recognition in 3D Medical Images",
        "authors": [
            "Ulas Bagci",
            "Jayaram K. Udupa",
            "Xinjian Chen"
        ],
        "abstract": "  This paper investigates, using prior shape models and the concept of ball scale (b-scale), ways of automatically recognizing objects in 3D images without performing elaborate searches or optimization. That is, the goal is to place the model in a single shot close to the right pose (position, orientation, and scale) in a given image so that the model boundaries fall in the close vicinity of object boundaries in the image. This is achieved via the following set of key ideas: (a) A semi-automatic way of constructing a multi-object shape model assembly. (b) A novel strategy of encoding, via b-scale, the pose relationship between objects in the training images and their intensity patterns captured in b-scale images. (c) A hierarchical mechanism of positioning the model, in a one-shot way, in a given image from a knowledge of the learnt pose relationship and the b-scale image of the given image to be segmented. The evaluation results on a set of 20 routine clinical abdominal female and male CT data sets indicate the following: (1) Incorporating a large number of objects improves the recognition accuracy dramatically. (2) The recognition algorithm can be thought as a hierarchical framework such that quick replacement of the model assembly is defined as coarse recognition and delineation itself is known as finest recognition. (3) Scale yields useful information about the relationship between the model assembly and any given image such that the recognition results in a placement of the model close to the actual pose without doing any elaborate searches or optimization. (4) Effective object recognition can make delineation most accurate.\n    ",
        "submission_date": "2010-02-05T00:00:00",
        "last_modified_date": "2010-02-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1002.2050",
        "title": "Intrinsic dimension estimation of data by principal component analysis",
        "authors": [
            "Mingyu Fan",
            "Nannan Gu",
            "Hong Qiao",
            "Bo Zhang"
        ],
        "abstract": "  Estimating intrinsic dimensionality of data is a classic problem in pattern recognition and statistics. Principal Component Analysis (PCA) is a powerful tool in discovering dimensionality of data sets with a linear structure; it, however, becomes ineffective when data have a nonlinear structure. In this paper, we propose a new PCA-based method to estimate intrinsic dimension of data with nonlinear structures. Our method works by first finding a minimal cover of the data set, then performing PCA locally on each subset in the cover and finally giving the estimation result by checking up the data variance on all small neighborhood regions. The proposed method utilizes the whole data set to estimate its intrinsic dimension and is convenient for incremental learning. In addition, our new PCA procedure can filter out noise in data and converge to a stable estimation with the neighborhood region size increasing. Experiments on synthetic and real world data sets show effectiveness of the proposed method.\n    ",
        "submission_date": "2010-02-10T00:00:00",
        "last_modified_date": "2010-02-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1002.2182",
        "title": "Detection of Microcalcification in Mammograms Using Wavelet Transform and Fuzzy Shell Clustering",
        "authors": [
            "T. Balakumaran",
            "I.L.A. Vennila",
            "C. Gowri Shankar"
        ],
        "abstract": "  Microcalcifications in mammogram have been mainly targeted as a reliable earliest sign of breast cancer and their early detection is vital to improve its prognosis. Since their size is very small and may be easily overlooked by the examining radiologist, computer-based detection output can assist the radiologist to improve the diagnostic accuracy. In this paper, we have proposed an algorithm for detecting microcalcification in mammogram. The proposed microcalcification detection algorithm involves mammogram quality enhancement using multirresolution analysis based on the dyadic wavelet transform and microcalcification detection by fuzzy shell clustering. It may be possible to detect nodular components such as microcalcification accurately by introducing shape information. The effectiveness of the proposed algorithm for microcalcification detection is confirmed by experimental results.\n    ",
        "submission_date": "2010-02-10T00:00:00",
        "last_modified_date": "2010-02-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1002.2408",
        "title": "Automatic diagnosis of retinal diseases from color retinal images",
        "authors": [
            "D. Jayanthi",
            "N. Devi",
            "S. SwarnaParvathi"
        ],
        "abstract": "  Teleophthalmology holds a great potential to improve the quality, access, and affordability in health care. For patients, it can reduce the need for travel and provide the access to a superspecialist. Ophthalmology lends itself easily to telemedicine as it is a largely image based diagnosis. The main goal of the proposed system is to diagnose the type of disease in the retina and to automatically detect and segment retinal diseases without human supervision or interaction. The proposed system will diagnose the disease present in the retina using a neural network based ",
        "submission_date": "2010-02-11T00:00:00",
        "last_modified_date": "2010-02-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1002.2418",
        "title": "Medical Image Compression using Wavelet Decomposition for Prediction Method",
        "authors": [
            "S. M. Ramesh",
            "A. Shanmugam"
        ],
        "abstract": "  In this paper offers a simple and lossless compression method for compression of medical images. Method is based on wavelet decomposition of the medical images followed by the correlation analysis of coefficients. The correlation analyses are the basis of prediction equation for each sub band. Predictor variable selection is performed through coefficient graphic method to avoid multicollinearity problem and to achieve high prediction accuracy and compression rate. The method is applied on MRI and CT images. Results show that the proposed approach gives a high compression rate for MRI and CT images comparing with state of the art methods.\n    ",
        "submission_date": "2010-02-11T00:00:00",
        "last_modified_date": "2010-02-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1002.2523",
        "title": "Feature Level Fusion of Face and Fingerprint Biometrics",
        "authors": [
            "Ajita Rattani",
            "Dakshina Ranjan Kisku",
            "Manuele Bicego",
            "Massimo Tistarelli"
        ],
        "abstract": "  The aim of this paper is to study the fusion at feature extraction level for face and fingerprint biometrics. The proposed approach is based on the fusion of the two traits by extracting independent feature pointsets from the two modalities, and making the two pointsets compatible for concatenation. Moreover, to handle the problem of curse of dimensionality, the feature pointsets are properly reduced in dimension. Different feature reduction techniques are implemented, prior and after the feature pointsets fusion, and the results are duly recorded. The fused feature pointset for the database and the query face and fingerprint images are matched using techniques based on either the point pattern matching, or the Delaunay triangulation. Comparative experiments are conducted on chimeric and real databases, to assess the actual advantage of the fusion performed at the feature extraction level, in comparison to the matching score level.\n    ",
        "submission_date": "2010-02-12T00:00:00",
        "last_modified_date": "2010-02-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1002.2654",
        "title": "Assessment Of The Wind Farm Impact On The Radar",
        "authors": [
            "Evgeny D. Norman"
        ],
        "abstract": "  This study shows the means to evaluate the wind farm impact on the radar. It proposes the set of tools, which can be used to realise this objective. The big part of report covers the study of complex pattern propagation factor as the critical issue of the Advanced Propagation Model (APM). Finally, the reader can find here the implementation of this algorithm - the real scenario in Inverness airport (the United Kingdom), where the ATC radar STAR 2000, developed by Thales Air Systems, operates in the presence of several wind farms. Basically, the project is based on terms of the department \"Strategy Technology & Innovation\", where it has been done. Also you can find here how the radar industry can act with the problem engendered by wind farms. The current strategies in this area are presented, such as a wind turbine production, improvements of air traffic handling procedures and the collaboration between developers of radars and wind turbines. The possible strategy for Thales as a main pioneer was given as well.\n    ",
        "submission_date": "2010-02-13T00:00:00",
        "last_modified_date": "2010-02-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1002.2755",
        "title": "Multibiometrics Belief Fusion",
        "authors": [
            "Dakshina Ranjan Kisku",
            "Jamuna Kanta Sing",
            "Phalguni Gupta"
        ],
        "abstract": "  This paper proposes a multimodal biometric system through Gaussian Mixture Model (GMM) for face and ear biometrics with belief fusion of the estimated scores characterized by Gabor responses and the proposed fusion is accomplished by Dempster-Shafer (DS) decision theory. Face and ear images are convolved with Gabor wavelet filters to extracts spatially enhanced Gabor facial features and Gabor ear features. Further, GMM is applied to the high-dimensional Gabor face and Gabor ear responses separately for quantitive measurements. Expectation Maximization (EM) algorithm is used to estimate density parameters in GMM. This produces two sets of feature vectors which are then fused using Dempster-Shafer theory. Experiments are conducted on multimodal database containing face and ear images of 400 individuals. It is found that use of Gabor wavelet filters along with GMM and DS theory can provide robust and efficient multimodal fusion strategy.\n    ",
        "submission_date": "2010-02-14T00:00:00",
        "last_modified_date": "2010-02-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1002.3344",
        "title": "Iterative exact global histogram specification and SSIM gradient ascent: a proof of convergence, step size and parameter selection",
        "authors": [
            "Alireza Avanaki"
        ],
        "abstract": "  The SSIM-optimized exact global histogram specification (EGHS) is shown to converge in the sense that the first order approximation of the result's quality (i.e., its structural similarity with input) does not decrease in an iteration, when the step size is small. Each iteration is composed of SSIM gradient ascent and basic EGHS with the specified target histogram. Selection of step size and other parameters is also discussed.\n    ",
        "submission_date": "2010-02-17T00:00:00",
        "last_modified_date": "2010-02-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1002.3985",
        "title": "Supervised Learning of Digital image restoration based on Quantization Nearest Neighbor algorithm",
        "authors": [
            "Md. Imran Hossain",
            "Syed Golam Rajib"
        ],
        "abstract": "  In this paper, an algorithm is proposed for Image Restoration. Such algorithm is different from the traditional approaches in this area, by utilizing priors that are learned from similar images. Original images and their degraded versions by the known degradation operators are utilized for designing the Quantization. The code vectors are designed using the blurred images. For each such vector, the high frequency information obtained from the original images is also available. During restoration, the high frequency information of a given degraded image is estimated from its low frequency information based on the artificial noise. For the restoration problem, a number of techniques are designed corresponding to various versions of the blurring function. Given a noisy and blurred image, one of the techniques is chosen based on a similarity measure, therefore providing the identification of the blur. To make the restoration process computationally efficient, the Quantization Nearest Neighborhood approaches are utilized.\n    ",
        "submission_date": "2010-02-21T00:00:00",
        "last_modified_date": "2010-02-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1002.4040",
        "title": "Handwritten Bangla Basic and Compound character recognition using MLP and SVM classifier",
        "authors": [
            "Nibaran Das",
            "Bindaban Das",
            "Ram Sarkar",
            "Subhadip Basu",
            "Mahantapas Kundu",
            "Mita Nasipuri"
        ],
        "abstract": "  A novel approach for recognition of handwritten compound Bangla characters, along with the Basic characters of Bangla alphabet, is presented here. Compared to English like Roman script, one of the major stumbling blocks in Optical Character Recognition (OCR) of handwritten Bangla script is the large number of complex shaped character classes of Bangla alphabet. In addition to 50 basic character classes, there are nearly 160 complex shaped compound character classes in Bangla alphabet. Dealing with such a large varieties of handwritten characters with a suitably designed feature set is a challenging problem. Uncertainty and imprecision are inherent in handwritten script. Moreover, such a large varieties of complex shaped characters, some of which have close resemblance, makes the problem of OCR of handwritten Bangla characters more difficult. Considering the complexity of the problem, the present approach makes an attempt to identify compound character classes from most frequently to less frequently occurred ones, i.e., in order of importance. This is to develop a frame work for incrementally increasing the number of learned classes of compound characters from more frequently occurred ones to less frequently occurred ones along with Basic characters. On experimentation, the technique is observed produce an average recognition rate of 79.25 after three fold cross validation of data with future scope of improvement and extension.\n    ",
        "submission_date": "2010-02-22T00:00:00",
        "last_modified_date": "2010-02-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1002.4317",
        "title": "CLD-shaped Brushstrokes in Non-Photorealistic Rendering",
        "authors": [
            "Amelia Carolina Sparavigna",
            "Roberto Marazzato"
        ],
        "abstract": "  Rendering techniques based on a random grid can be improved by adapting brushstrokes to the shape of different areas of the original picture. In this paper, the concept of Coherence Length Diagram is applied to determine the adaptive brushstrokes, in order to simulate an impressionist painting. Some examples are provided to instance the proposed algorithm.\n    ",
        "submission_date": "2010-02-23T00:00:00",
        "last_modified_date": "2010-02-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1003.0487",
        "title": "Scalable Large-Margin Mahalanobis Distance Metric Learning",
        "authors": [
            "Chunhua Shen",
            "Junae Kim",
            "Lei Wang"
        ],
        "abstract": "  For many machine learning algorithms such as $k$-Nearest Neighbor ($k$-NN) classifiers and $ k $-means clustering, often their success heavily depends on the metric used to calculate distances between different data points.\n",
        "submission_date": "2010-03-02T00:00:00",
        "last_modified_date": "2010-03-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1003.0642",
        "title": "Text Region Extraction from Business Card Images for Mobile Devices",
        "authors": [
            "Ayatullah Faruk Mollah",
            "Subhadip Basu",
            "Nibaran Das",
            "Ram Sarkar",
            "Mita Nasipuri",
            "Mahantapas Kundu"
        ],
        "abstract": "  Designing a Business Card Reader (BCR) for mobile devices is a challenge to the researchers because of huge deformation in acquired images, multiplicity in nature of the business cards and most importantly the computational constraints of the mobile devices. This paper presents a text extraction method designed in our work towards developing a BCR for mobile devices. At first, the background of a camera captured image is eliminated at a coarse level. Then, various rule based techniques are applied on the Connected Components (CC) to filter out the noises and picture regions. The CCs identified as text are then binarized using an adaptive but light-weight binarization technique. Experiments show that the text extraction accuracy is around 98% for a wide range of resolutions with varying computation time and memory requirements. The optimum performance is achieved for the images of resolution 1024x768 pixels with text extraction accuracy of 98.54% and, space and time requirements as 1.1 MB and 0.16 seconds respectively.\n    ",
        "submission_date": "2010-03-02T00:00:00",
        "last_modified_date": "2010-03-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1003.0645",
        "title": "Binarizing Business Card Images for Mobile Devices",
        "authors": [
            "Ayatullah Faruk Mollah",
            "Subhadip Basu",
            "Nibaran Das",
            "Ram Sarkar",
            "Mita Nasipuri",
            "Mahantapas Kundu"
        ],
        "abstract": "  Business card images are of multiple natures as these often contain graphics, pictures and texts of various fonts and sizes both in background and foreground. So, the conventional binarization techniques designed for document images can not be directly applied on mobile devices. In this paper, we have presented a fast binarization technique for camera captured business card images. A card image is split into small blocks. Some of these blocks are classified as part of the background based on intensity variance. Then the non-text regions are eliminated and the text ones are skew corrected and binarized using a simple yet adaptive technique. Experiment shows that the technique is fast, efficient and applicable for the mobile devices.\n    ",
        "submission_date": "2010-03-02T00:00:00",
        "last_modified_date": "2010-03-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1003.0776",
        "title": "Properties of the Discrete Pulse Transform for Multi-Dimensional Arrays",
        "authors": [
            "Roumen Anguelov",
            "Inger Fabris-Rotelli"
        ],
        "abstract": "  This report presents properties of the Discrete Pulse Transform on multi-dimensional arrays introduced by the authors two or so years ago. The main result given here in Lemma 2.1 is also formulated in a paper to appear in IEEE Transactions on Image Processing. However, the proof, being too technical, was omitted there and hence it appears in full in this publication.\n    ",
        "submission_date": "2010-03-03T00:00:00",
        "last_modified_date": "2010-03-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1003.1072",
        "title": "An Offline Technique for Localization of License Plates for Indian Commercial Vehicles",
        "authors": [
            "Satadal Saha",
            "Subhadip Basu",
            "Mita Nasipuri",
            "Dipak Kumar Basu"
        ],
        "abstract": "Automatic License Plate Recognition (ALPR) is a challenging area of research due to its importance to variety of commercial applications. The overall problem may be subdivided into two key modules, firstly, localization of license plates from vehicle images, and secondly, optical character recognition of extracted license plates. In the current work, we have concentrated on the first part of the problem, i.e., localization of license plate regions from Indian commercial vehicles as a significant step towards development of a complete ALPR system for Indian vehicles. The technique is based on color based segmentation of vehicle images and identification of potential license plate regions. True license plates are finally localized based on four spatial and horizontal contrast features. The technique successfully localizes the actual license plates in 73.4% images.\n    ",
        "submission_date": "2010-03-04T00:00:00",
        "last_modified_date": "2015-01-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1003.1511",
        "title": "Clinical gait data analysis based on Spatio-Temporal features",
        "authors": [
            "Rohit Katiyar",
            "Dr. Vinay Kumar Pathak"
        ],
        "abstract": "Analysing human gait has found considerable interest in recent computer vision research. So far, however, contributions to this topic exclusively dealt with the tasks of person identification or activity recognition. In this paper, we consider a different application for gait analysis and examine its use as a means of deducing the physical well-being of people. The proposed method is based on transforming the joint motion trajectories using wavelets to extract spatio-temporal features which are then fed as input to a vector quantiser; a self-organising map for classification of walking patterns of individuals with and without pathology. We show that our proposed algorithm is successful in extracting features that successfully discriminate between individuals with and without locomotion impairment.\n    ",
        "submission_date": "2010-03-07T00:00:00",
        "last_modified_date": "2010-03-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1003.1803",
        "title": "Nonlinear Filter Based Image Denoising Using AMF Approach",
        "authors": [
            "T. K. Thivakaran",
            "RM. Chandrasekaran"
        ],
        "abstract": "This paper proposes a new technique based on nonlinear Adaptive Median filter (AMF) for image restoration. Image denoising is a common procedure in digital image processing aiming at the removal of noise, which may corrupt an image during its acquisition or transmission, while retaining its quality. This procedure is traditionally performed in the spatial or frequency domain by filtering. The aim of image enhancement is to reconstruct the true image from the corrupted image. The process of image acquisition frequently leads to degradation and the quality of the digitized image becomes inferior to the original image. Filtering is a technique for enhancing the image. Linear filter is the filtering in which the value of an output pixel is a linear combination of neighborhood values, which can produce blur in the image. Thus a variety of smoothing techniques have been developed that are non linear. Median filter is the one of the most popular non-linear filter. When considering a small neighborhood it is highly efficient but for large window and in case of high noise it gives rise to more blurring to image. The Centre Weighted Median (CWM) filter has got a better average performance over the median filter [8]. However the original pixel corrupted and noise reduction is substantial under high noise condition. Hence this technique has also blurring affect on the image. To illustrate the superiority of the proposed approach by overcoming the existing problem, the proposed new scheme (AMF) Adaptive Median Filter has been simulated along with the standard ones and various performance measures have been compared.\n    ",
        "submission_date": "2010-03-09T00:00:00",
        "last_modified_date": "2010-03-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1003.1819",
        "title": "Facial Gesture Recognition Using Correlation And Mahalanobis Distance",
        "authors": [
            "Supriya Kapoor",
            "Shruti Khanna",
            "Rahul Bhatia"
        ],
        "abstract": "Augmenting human computer interaction with automated analysis and synthesis of facial expressions is a goal towards which much research effort has been devoted recently. Facial gesture recognition is one of the important component of natural human-machine interfaces; it may also be used in behavioural science, security systems and in clinical practice. Although humans recognise facial expressions virtually without effort or delay, reliable expression recognition by machine is still a challenge. The face expression recognition problem is challenging because different individuals display the same expression differently. This paper presents an overview of gesture recognition in real time using the concepts of correlation and Mahalanobis ",
        "submission_date": "2010-03-09T00:00:00",
        "last_modified_date": "2010-03-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1003.1826",
        "title": "A GA based Window Selection Methodology to Enhance Window based Multi wavelet transformation and thresholding aided CT image denoising technique",
        "authors": [
            "Syed Amjad Ali",
            "Srinivasan Vathsal",
            "K. Lal kishore"
        ],
        "abstract": "Image denoising is getting more significance, especially in Computed Tomography (CT), which is an important and most common modality in medical imaging. This is mainly due to that the effectiveness of clinical diagnosis using CT image lies on the image quality. The denoising technique for CT images using window-based Multi-wavelet transformation and thresholding shows the effectiveness in denoising, however, a drawback exists in selecting the closer windows in the process of window-based multi-wavelet transformation and thresholding. Generally, the windows of the duplicate noisy image that are closer to each window of original noisy image are obtained by the checking them sequentially. This leads to the possibility of missing out very closer windows and so enhancement is required in the aforesaid process of the denoising technique. In this paper, we propose a GA-based window selection methodology to include the denoising technique. With the aid of the GA-based window selection methodology, the windows of the duplicate noisy image that are very closer to every window of the original noisy image are extracted in an effective manner. By incorporating the proposed GA-based window selection methodology, the denoising the CT image is performed effectively. Eventually, a comparison is made between the denoising technique with and without the proposed GA-based window selection methodology.\n    ",
        "submission_date": "2010-03-09T00:00:00",
        "last_modified_date": "2010-03-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1003.1827",
        "title": "Investigation and Assessment of Disorder of Ultrasound B-mode Images",
        "authors": [
            "Vidhi Rawat",
            "Alok Jain",
            "Vibhakar Shrimali"
        ],
        "abstract": "Digital image plays a vital role in the early detection of cancers, such as prostate cancer, breast cancer, lungs cancer, cervical cancer. Ultrasound imaging method is also suitable for early detection of the abnormality of fetus. The accurate detection of region of interest in ultrasound image is crucial. Since the result of reflection, refraction and deflection of ultrasound waves from different types of tissues with different acoustic impedance. Usually, the contrast in ultrasound image is very low and weak edges make the image difficult to identify the fetus region in the ultrasound image. So the analysis of ultrasound image is more challenging one. We try to develop a new algorithmic approach to solve the problem of non clarity and find disorder of it. Generally there is no common enhancement approach for noise reduction. This paper proposes different filtering techniques based on statistical methods for the removal of various noise. The quality of the enhanced images is measured by the statistical quantity measures: Signal-to-Noise Ratio (SNR), Peak Signal-to-Noise Ratio (PSNR), and Root Mean Square Error (RMSE).\n    ",
        "submission_date": "2010-03-09T00:00:00",
        "last_modified_date": "2010-03-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1003.1891",
        "title": "Handwritten Arabic Numeral Recognition using a Multi Layer Perceptron",
        "authors": [
            "Nibaran Das",
            "Ayatullah Faruk Mollah",
            "Sudip Saha",
            "Syed Sahidul Haque"
        ],
        "abstract": "Handwritten numeral recognition is in general a benchmark problem of Pattern Recognition and Artificial Intelligence. Compared to the problem of printed numeral recognition, the problem of handwritten numeral recognition is compounded due to variations in shapes and sizes of handwritten characters. Considering all these, the problem of handwritten numeral recognition is addressed under the present work in respect to handwritten Arabic numerals. Arabic is spoken throughout the Arab World and the fifth most popular language in the world slightly before Portuguese and Bengali. For the present work, we have developed a feature set of 88 features is designed to represent samples of handwritten Arabic numerals for this work. It includes 72 shadow and 16 octant features. A Multi Layer Perceptron (MLP) based classifier is used here for recognition handwritten Arabic digits represented with the said feature set. On experimentation with a database of 3000 samples, the technique yields an average recognition rate of 94.93% evaluated after three-fold cross validation of results. It is useful for applications related to OCR of handwritten Arabic Digit and can also be extended to include OCR of handwritten characters of Arabic alphabet.\n    ",
        "submission_date": "2010-03-09T00:00:00",
        "last_modified_date": "2010-03-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1003.1894",
        "title": "A comparative study of different feature sets for recognition of handwritten Arabic numerals using a Multi Layer Perceptron",
        "authors": [
            "Nibaran Das",
            "Ayatullah Faruk Mollah",
            "Ram Sarkar",
            "Subhadip Basu"
        ],
        "abstract": "The work presents a comparative assessment of seven different feature sets for recognition of handwritten Arabic numerals using a Multi Layer Perceptron (MLP) based classifier. The seven feature sets employed here consist of shadow features, octant centroids, longest runs, angular distances, effective spans, dynamic centers of gravity, and some of their combinations. On experimentation with a database of 3000 samples, the maximum recognition rate of 95.80% is observed with both of two separate combinations of features. One of these combinations consists of shadow and centriod features, i. e. 88 features in all, and the other shadow, centroid and longest run features, i. e. 124 features in all. Out of these two, the former combination having a smaller number of features is finally considered effective for applications related to Optical Character Recognition (OCR) of handwritten Arabic numerals. The work can also be extended to include OCR of handwritten characters of Arabic alphabet.\n    ",
        "submission_date": "2010-03-09T00:00:00",
        "last_modified_date": "2010-03-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1003.2022",
        "title": "Fast space-variant elliptical filtering using box splines",
        "authors": [
            "Kunal Narayan Chaudhury",
            "Arrate Munoz-Barrutia",
            "Michael Unser"
        ],
        "abstract": "The efficient realization of linear space-variant (non-convolution) filters is a challenging computational problem in image processing. In this paper, we demonstrate that it is possible to filter an image with a Gaussian-like elliptic window of varying size, elongation and orientation using a fixed number of computations per pixel. The associated algorithm, which is based on a family of smooth compactly supported piecewise polynomials, the radially-uniform box splines, is realized using pre-integration and local finite-differences. The radially-uniform box splines are constructed through the repeated convolution of a fixed number of box distributions, which have been suitably scaled and distributed radially in an uniform fashion. The attractive features of these box splines are their asymptotic behavior, their simple covariance structure, and their quasi-separability. They converge to Gaussians with the increase of their order, and are used to approximate anisotropic Gaussians of varying covariance simply by controlling the scales of the constituent box distributions. Based on the second feature, we develop a technique for continuously controlling the size, elongation and orientation of these Gaussian-like functions. Finally, the quasi-separable structure, along with a certain scaling property of box distributions, is used to efficiently realize the associated space-variant elliptical filtering, which requires O(1) computations per pixel irrespective of the shape and size of the filter.\n    ",
        "submission_date": "2010-03-10T00:00:00",
        "last_modified_date": "2011-09-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1003.3266",
        "title": "Pattern recognition using inverse resonance filtration",
        "authors": [
            "Olga Sofina",
            "Yuriy Bunyak",
            "Roman Kvetnyy"
        ],
        "abstract": "An approach to textures pattern recognition based on inverse resonance filtration (IRF) is considered. A set of principal resonance harmonics of textured image signal fluctuations eigen harmonic decomposition (EHD) is used for the IRF design. It was shown that EHD is invariant to textured image linear shift. The recognition of texture is made by transfer of its signal into unstructured signal which simple statistical parameters can be used for texture pattern recognition. Anomalous variations of this signal point on foreign objects. Two methods of 2D EHD parameters estimation are considered with the account of texture signal breaks presence. The first method is based on the linear symmetry model that is not sensitive to signal phase jumps. The condition of characteristic polynomial symmetry provides the model stationarity and periodicity. Second method is based on the eigenvalues problem of matrices pencil projection into principal vectors space of singular values decomposition (SVD) of 2D correlation matrix. Two methods of classification of retrieval from textured image foreign objects are offered.\n    ",
        "submission_date": "2010-03-16T00:00:00",
        "last_modified_date": "2010-03-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1003.3654",
        "title": "Sliding window approach based Text Binarisation from Complex Textual images",
        "authors": [
            "Chitrakala Gopalan",
            "D.Manjula"
        ],
        "abstract": "Text binarisation process classifies individual pixels as text or background in the textual images. Binarization is necessary to bridge the gap between localization and recognition by OCR. This paper presents Sliding window method to binarise text from textual images with textured background. Suitable preprocessing techniques are applied first to increase the contrast of the image and blur the background noises due to textured background.  Then Edges are detected by iterative thresholding. Subsequently formed edge boxes are analyzed to remove unwanted edges due to complex background and binarised by sliding window approach based character size uniformity check algorithm. The proposed method has been applied on localized region from heterogeneous textual images and compared with Otsu, Niblack methods and shown encouraging performance of the proposed method.\n    ",
        "submission_date": "2010-03-18T00:00:00",
        "last_modified_date": "2010-03-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1003.3984",
        "title": "On MMSE and MAP Denoising Under Sparse Representation Modeling Over a Unitary Dictionary",
        "authors": [
            "Javier Turek",
            "Irad Yavneh",
            "Matan Protter",
            "Michael Elad"
        ],
        "abstract": "Among the many ways to model signals, a recent approach that draws considerable attention is sparse representation modeling. In this model, the signal is assumed to be generated as a random linear combination of a few atoms from a pre-specified dictionary. In this work we analyze two Bayesian denoising algorithms -- the Maximum-Aposteriori Probability (MAP) and the Minimum-Mean-Squared-Error (MMSE) estimators, under the assumption that the dictionary is unitary. It is well known that both these estimators lead to a scalar shrinkage on the transformed coefficients, albeit with a different response curve. In this work we start by deriving closed-form expressions for these shrinkage curves and then analyze their performance. Upper bounds on the MAP and the MMSE estimation errors are derived. We tie these to the error obtained by a so-called oracle estimator, where the support is given, establishing a worst-case gain-factor between the MAP/MMSE estimation errors and the oracle's performance. These denoising algorithms are demonstrated on synthetic signals and on true data (images).\n    ",
        "submission_date": "2010-03-21T00:00:00",
        "last_modified_date": "2010-03-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1003.3985",
        "title": "The Projected GSURE for Automatic Parameter Tuning in Iterative Shrinkage Methods",
        "authors": [
            "Raja Giryes",
            "Michael Elad",
            "Yonina C Eldar"
        ],
        "abstract": "Linear inverse problems are very common in signal and image processing. Many algorithms that aim at solving such problems include unknown parameters that need tuning. In this work we focus on optimally selecting such parameters in iterative shrinkage methods for image deblurring and image zooming. Our work uses the projected Generalized Stein Unbiased Risk Estimator (GSURE) for determining the threshold value lambda and the iterations number K in these algorithms. The proposed parameter selection is shown to handle any degradation operator, including ill-posed and even rectangular ones. This is achieved by using GSURE on the projected expected error. We further propose an efficient greedy parameter setting scheme, that tunes the parameter while iterating without impairing the resulting deblurring performance. Finally, we provide extensive comparisons to conventional methods for parameter selection, showing the superiority of the use of the projected GSURE.\n    ",
        "submission_date": "2010-03-21T00:00:00",
        "last_modified_date": "2010-03-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1003.4021",
        "title": "System-theoretic approach to image interest point detection",
        "authors": [
            "Vitaly Pimenov"
        ],
        "abstract": "Interest point detection is a common task in various computer vision applications. Although a big variety of detector are developed so far computational efficiency of interest point based image analysis remains to be the problem. Current paper proposes a system-theoretic approach to interest point detection. Starting from the analysis of interdependency between detector and descriptor it is shown that given a descriptor it is possible to introduce to notion of detector redundancy. Furthermore for each detector it is possible to construct its irredundant and equivalent modification. Modified detector possesses lower computational complexity and is preferable. It is also shown that several known approaches to reduce computational complexity of image registration can be generalized in terms of proposed theory.\n    ",
        "submission_date": "2010-03-21T00:00:00",
        "last_modified_date": "2010-03-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1003.4053",
        "title": "A Comprehensive Review of Image Enhancement Techniques",
        "authors": [
            "Raman Maini",
            "Himanshu Aggarwal"
        ],
        "abstract": "Principle objective of Image enhancement is to process an image so that result is more suitable than original image for specific application. Digital image enhancement techniques provide a multitude of choices for improving the visual quality of images. Appropriate choice of such techniques is greatly influenced by the imaging modality, task at hand and viewing conditions. This paper will provide an overview of underlying concepts, along with algorithms commonly used for image enhancement. The paper focuses on spatial domain techniques for image enhancement, with particular reference to point processing methods and histogram processing.\n    ",
        "submission_date": "2010-03-22T00:00:00",
        "last_modified_date": "2010-03-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1003.4087",
        "title": "Land-cover Classification and Mapping for Eastern Himalayan State Sikkim",
        "authors": [
            "Ratika Pradhan",
            "Mohan P. Pradhan",
            "Ashish Bhusan",
            "Ronak K. Pradhan",
            "M. K. Ghose"
        ],
        "abstract": "Area of classifying satellite imagery has become a challenging task in current era where there is tremendous growth in settlement i.e. construction of buildings, roads, bridges, dam etc. This paper suggests an improvised k-means and Artificial Neural Network (ANN) classifier for land-cover mapping of Eastern Himalayan state Sikkim. The improvised k-means algorithm shows satisfactory results compared to existing methods that includes k-Nearest Neighbor and maximum likelihood classifier. The strength of the Artificial Neural Network (ANN) classifier lies in the fact that they are fast and have good recognition rate and it's capability of self-learning compared to other classification algorithms has made it widely accepted. Classifier based on ANN shows satisfactory and accurate result in comparison with the classical method.\n    ",
        "submission_date": "2010-03-22T00:00:00",
        "last_modified_date": "2010-03-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1003.4287",
        "title": "Towards automated high-throughput screening of C. elegans on agar",
        "authors": [
            "Mayank Kabra",
            "Annie L. Conery",
            "Eyleen J. O'Rourke",
            "Xin Xie",
            "Vebjorn Ljosa",
            "Thouis R. Jones",
            "Frederick M. Ausubel",
            "Gary Ruvkun",
            "Anne E. Carpenter",
            "Yoav Freund"
        ],
        "abstract": "High-throughput screening (HTS) using model organisms is a promising method to identify a small number of genes or drugs potentially relevant to human biology or disease. In HTS experiments, robots and computers do a significant portion of the experimental work. However, one remaining major bottleneck is the manual analysis of experimental results, which is commonly in the form of microscopy images. This manual inspection is labor intensive, slow and subjective. Here we report our progress towards applying computer vision and machine learning methods to analyze HTS experiments that use Caenorhabditis elegans (C. elegans) worms grown on agar. Our main contribution is a robust segmentation algorithm for separating the worms from the background using brightfield images. We also show that by combining the output of this segmentation algorithm with an algorithm to detect the fluorescent dye, Nile Red, we can reliably distinguish different fluorescence-based phenotypes even though the visual differences are subtle. The accuracy of our method is similar to that of expert human analysts. This new capability is a significant step towards fully automated HTS experiments using C. elegans.\n    ",
        "submission_date": "2010-03-22T00:00:00",
        "last_modified_date": "2010-03-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1003.5249",
        "title": "Active Testing for Face Detection and Localization",
        "authors": [
            "Raphael Sznitman",
            "Bruno Jedynak"
        ],
        "abstract": "We provide a novel search technique, which uses a hierarchical model and a mutual information gain heuristic to efficiently prune the search space when localizing faces in images. We show exponential gains in computation over traditional sliding window approaches, while keeping similar performance levels.\n    ",
        "submission_date": "2010-03-27T00:00:00",
        "last_modified_date": "2010-03-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1003.5320",
        "title": "The Video Genome",
        "authors": [
            "Alexander M. Bronstein",
            "Michael M. Bronstein",
            "Ron Kimmel"
        ],
        "abstract": "Fast evolution of Internet technologies has led to an explosive growth of video data available in the public domain and created unprecedented challenges in the analysis, organization, management, and control of such content. The problems encountered in video analysis such as identifying a video in a large database (e.g. detecting pirated content in YouTube), putting together video fragments, finding similarities and common ancestry between different versions of a video, have analogous counterpart problems in genetic research and analysis of DNA and protein sequences. In this paper, we exploit the analogy between genetic sequences and videos and propose an approach to video analysis motivated by genomic research. Representing video information as video DNA sequences and applying bioinformatic algorithms allows to search, match, and compare videos in  large-scale databases. We show an application for content-based metadata mapping between versions of annotated video.\n    ",
        "submission_date": "2010-03-27T00:00:00",
        "last_modified_date": "2010-03-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1003.5435",
        "title": "Image Compression and Watermarking scheme using Scalar Quantization",
        "authors": [
            "Kilari Veera Swamy",
            "B.Chandra Mohan",
            "Y.V.Bhaskar Reddy",
            "S.Srinivas Kumar"
        ],
        "abstract": "This paper presents a new compression technique and image watermarking algorithm based on Contourlet Transform (CT). For image compression, an energy based quantization is used. Scalar quantization is explored for image watermarking. Double filter bank structure is used in CT. The Laplacian Pyramid (LP) is used to capture the point discontinuities, and then followed by a Directional Filter Bank (DFB) to link point discontinuities. The coefficients of down sampled low pass version of LP decomposed image are re-ordered in a pre-determined manner and prediction algorithm is used to reduce entropy (bits/pixel). In addition, the coefficients of CT are quantized based on the energy in the particular band. The superiority of proposed algorithm to JPEG is observed in terms of reduced blocking artifacts. The results are also compared with wavelet transform (WT). Superiority of CT to WT is observed when the image contains more contours. The watermark image is embedded in the low pass image of contourlet decomposition. The watermark can be extracted with minimum error. In terms of PSNR, the visual quality of the watermarked image is exceptional. The proposed algorithm is robust to many image attacks and suitable for copyright protection applications.\n    ",
        "submission_date": "2010-03-29T00:00:00",
        "last_modified_date": "2010-03-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1003.5821",
        "title": "Tuning CLD Maps",
        "authors": [
            "Roberto Marazzato",
            "Amelia Carolina Sparavigna"
        ],
        "abstract": "The Coherence Length Diagram and the related maps have been shown to represent a useful tool for image analysis. Setting threshold parameters is one of the most important issues when dealing with such applications, as they affect both the computability, which is outlined by the support map, and the appearance of the coherence length diagram itself and of defect maps. A coupled optimization analysis, returning a range for the basic (saturation) threshold, and a histogram based method, yielding suitable values for a desired map appearance, are proposed for an effective control of the analysis process.\n    ",
        "submission_date": "2010-03-30T00:00:00",
        "last_modified_date": "2010-03-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1003.5861",
        "title": "Robust multi-camera view face recognition",
        "authors": [
            "Dakshina Ranjan Kisku",
            "Hunny Mehrotra",
            "Phalguni Gupta",
            "Jamuna Kanta Sing"
        ],
        "abstract": "This paper presents multi-appearance fusion of Principal Component Analysis (PCA) and generalization of Linear Discriminant Analysis (LDA) for multi-camera view offline face recognition (verification) system. The generalization of LDA has been extended to establish correlations between the face classes in the transformed representation and this is called canonical covariate. The proposed system uses Gabor filter banks for characterization of facial features by spatial frequency, spatial locality and orientation to make compensate to the variations of face instances occurred due to illumination, pose and facial expression changes. Convolution of Gabor filter bank to face images produces Gabor face representations with high dimensional feature vectors. PCA and canonical covariate are then applied on the Gabor face representations to reduce the high dimensional feature spaces into low dimensional Gabor eigenfaces and Gabor canonical faces. Reduced eigenface vector and canonical face vector are fused together using weighted mean fusion rule. Finally, support vector machines (SVM) have trained with augmented fused set of features and perform the recognition task. The system has been evaluated with UMIST face database consisting of multiview faces. The experimental results demonstrate the efficiency and robustness of the proposed system for multi-view face images with high recognition rates. Complexity analysis of the proposed system is also presented at the end of the experimental results.\n    ",
        "submission_date": "2010-03-30T00:00:00",
        "last_modified_date": "2010-03-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1003.5865",
        "title": "Offline Signature Identification by Fusion of Multiple Classifiers using Statistical Learning Theory",
        "authors": [
            "Dakshina Ranjan Kisku",
            "Phalguni Gupta",
            "Jamuna Kanta Sing"
        ],
        "abstract": "This paper uses Support Vector Machines (SVM) to fuse multiple classifiers for an offline signature system. From the signature images, global and local features are extracted and the signatures are verified with the help of Gaussian empirical rule, Euclidean and Mahalanobis distance based classifiers. SVM is used to fuse matching scores of these matchers. Finally, recognition of query signatures is done by comparing it with all signatures of the database. The proposed system is tested on a signature database contains 5400 offline signatures of 600 individuals and the results are found to be promising.\n    ",
        "submission_date": "2010-03-30T00:00:00",
        "last_modified_date": "2010-03-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1003.5886",
        "title": "Development of a multi-user handwriting recognition system using Tesseract open source OCR engine",
        "authors": [
            "Sandip Rakshit",
            "Subhadip Basu"
        ],
        "abstract": "The objective of the paper is to recognize handwritten samples of lower case Roman script using Tesseract open source Optical Character Recognition (OCR) engine under Apache License 2.0. Handwritten data samples containing isolated and free-flow text were collected from different users. Tesseract is trained with user-specific data samples of both the categories of document pages to generate separate user-models representing a unique language-set. Each such language-set recognizes isolated and free-flow handwritten test samples collected from the designated user. On a three user model, the system is trained with 1844, 1535 and 1113 isolated handwritten character samples collected from three different users and the performance is tested on 1133, 1186 and 1204 character samples, collected form the test sets of the three users respectively. The user specific character level accuracies were obtained as 87.92%, 81.53% and 65.71% respectively. The overall character-level accuracy of the system is observed as 78.39%. The system fails to segment 10.96% characters and erroneously classifies 10.65% characters on the overall dataset.\n    ",
        "submission_date": "2010-03-30T00:00:00",
        "last_modified_date": "2010-03-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1003.5891",
        "title": "Recognition of Handwritten Roman Script Using Tesseract Open source OCR Engine",
        "authors": [
            "Sandip Rakshit",
            "Subhadip Basu"
        ],
        "abstract": "In the present work, we have used Tesseract 2.01 open source Optical Character Recognition (OCR) Engine under Apache License 2.0 for recognition of handwriting samples of lower case Roman script. Handwritten isolated and free-flow text samples were collected from multiple users. Tesseract is trained to recognize user-specific handwriting samples of both the categories of document pages. On a single user model, the system is trained with 1844 isolated handwritten characters and the performance is tested on 1133 characters, taken form the test set. The overall character-level accuracy of the system is observed as 83.5%. The system fails to segment 5.56% characters and erroneously classifies 10.94% characters.\n    ",
        "submission_date": "2010-03-30T00:00:00",
        "last_modified_date": "2010-03-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1003.5893",
        "title": "Recognition of Handwritten Textual Annotations using Tesseract Open Source OCR Engine for information Just In Time (iJIT)",
        "authors": [
            "Sandip Rakshit",
            "Subhadip Basu",
            "Hisashi Ikeda"
        ],
        "abstract": "Objective of the current work is to develop an Optical Character Recognition (OCR) engine for information Just In Time (iJIT) system that can be used for recognition of handwritten textual annotations of lower case Roman script. Tesseract open source OCR engine under Apache License 2.0 is used to develop user-specific handwriting recognition models, viz., the language sets, for the said system, where each user is identified by a unique identification tag associated with the digital pen. To generate the language set for any user, Tesseract is trained with labeled handwritten data samples of isolated and free-flow texts of Roman script, collected exclusively from that user. The designed system is tested on five different language sets with free- flow handwritten annotations as test samples. The system could successfully segment and subsequently recognize 87.92%, 81.53%, 92.88%, 86.75% and 90.80% handwritten characters in the test samples of five different users.\n    ",
        "submission_date": "2010-03-30T00:00:00",
        "last_modified_date": "2010-03-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1003.5897",
        "title": "Development of a Multi-User Recognition Engine for Handwritten Bangla Basic Characters and Digits",
        "authors": [
            "Sandip Rakshit",
            "Debkumar Ghosal",
            "Tanmoy Das",
            "Subhrajit Dutta",
            "Subhadip Basu"
        ],
        "abstract": "The objective of the paper is to recognize handwritten samples of basic Bangla characters using Tesseract open source Optical Character Recognition (OCR) engine under Apache License 2.0. Handwritten data samples containing isolated Bangla basic characters and digits were collected from different users. Tesseract is trained with user-specific data samples of document pages to generate separate user-models representing a unique language-set. Each such language-set recognizes isolated basic Bangla handwritten test samples collected from the designated users. On a three user model, the system is trained with 919, 928 and 648 isolated handwritten character and digit samples and the performance is tested on 1527, 14116 and 1279 character and digit  samples, collected form the test datasets of the three users respectively. The user specific character/digit recognition accuracies were obtained as 90.66%, 91.66% and 96.87% respectively. The overall basic character-level and digit level accuracy of the system is observed as 92.15% and 97.37%. The system fails to segment 12.33% characters and 15.96% digits and also erroneously classifies 7.85% characters and 2.63% on the overall dataset.\n    ",
        "submission_date": "2010-03-30T00:00:00",
        "last_modified_date": "2010-03-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1003.5898",
        "title": "Recognition of handwritten Roman Numerals using Tesseract open source OCR engine",
        "authors": [
            "Sandip Rakshit",
            "Amitava Kundu",
            "Mrinmoy Maity",
            "Subhajit Mandal",
            "Satwika Sarkar",
            "Subhadip Basu"
        ],
        "abstract": "The objective of the paper is to recognize handwritten samples of Roman numerals using Tesseract open source Optical Character Recognition (OCR) engine. Tesseract is trained with data samples of different persons to generate one user-independent language model, representing the handwritten Roman digit-set. The system is trained with 1226   digit samples collected form the different users. The performance is tested on two different datasets, one consisting of samples collected from the known users (those who prepared the training data samples) and the other consisting of handwritten data samples of  unknown users. The overall recognition accuracy is obtained as 92.1% and 86.59% on these test datasets respectively.\n    ",
        "submission_date": "2010-03-30T00:00:00",
        "last_modified_date": "2010-03-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1003.6052",
        "title": "Development of an automated Red Light Violation Detection System (RLVDS) for Indian vehicles",
        "authors": [
            "Satadal Saha",
            "Subhadip Basu",
            "Mita Nasipuri",
            "Dipak Kumar Basu"
        ],
        "abstract": "Integrated Traffic Management Systems (ITMS) are now implemented in different cities in India to primarily address the concerns of road-safety and security. An automated Red Light Violation Detection System (RLVDS) is an integral part of the ITMS. In our present work we have designed and developed a complete system for generating the list of all stop-line violating vehicle images automatically from video snapshots of road-side surveillance cameras. The system first generates adaptive background images for each camera view, subtracts captured images from the corresponding background images and analyses potential occlusions over the stop-line in a traffic signal. Considering round-the-clock operations in a real-life test environment, the developed system could successfully track 92% images of vehicles with violations on the stop-line in a \"Red\" traffic signal.\n    ",
        "submission_date": "2010-03-31T00:00:00",
        "last_modified_date": "2015-01-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1003.6059",
        "title": "A novel scheme for binarization of vehicle images using hierarchical histogram equalization technique",
        "authors": [
            "Satadal Saha",
            "Subhadip Basu",
            "Mita Nasipuri",
            "Dipak Kumar Basu"
        ],
        "abstract": "Automatic License Plate Recognition system is a challenging area of research now-a-days and binarization is an integral and most important part of it. In case of a real life scenario, most of existing methods fail to properly binarize the image of a vehicle in a congested road, captured through a CCD camera. In the current work we have applied histogram equalization technique over the complete image and also over different hierarchy of image partitioning. A novel scheme is formulated for giving the membership value to each pixel for each hierarchy of histogram equalization. Then the image is binarized depending on the net membership value of each pixel. The technique is exhaustively evaluated on the vehicle image dataset as well as the license plate dataset, giving satisfactory performances.\n    ",
        "submission_date": "2010-03-31T00:00:00",
        "last_modified_date": "2015-01-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1004.0085",
        "title": "A stochastic model of human visual attention with a dynamic Bayesian network",
        "authors": [
            "Akisato kimura",
            "Derek Pang",
            "Tatsuto Takeuchi",
            "Kouji Miyazato",
            "Junji Yamato",
            "Kunio Kashino"
        ],
        "abstract": "Recent studies in the field of human vision science suggest that the human responses to the stimuli on a visual display are non-deterministic. People may attend to different locations on the same visual input at the same time. Based on this knowledge, we propose a new stochastic model of visual attention by introducing a dynamic Bayesian network to predict the likelihood of where humans typically focus on a video scene. The proposed model is composed of a dynamic Bayesian network with 4 layers. Our model provides a framework that simulates and combines the visual saliency response and the cognitive state of a person to estimate the most probable attended regions. Sample-based inference with Markov chain Monte-Carlo based particle filter and stream processing with multi-core processors enable us to estimate human visual attention in near real time. Experimental results have demonstrated that our model performs significantly better in predicting human visual attention compared to the previous deterministic models.\n    ",
        "submission_date": "2010-04-01T00:00:00",
        "last_modified_date": "2010-04-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1004.0378",
        "title": "Facial Expression Representation and Recognition Using 2DHLDA, Gabor Wavelets, and Ensemble Learning",
        "authors": [
            "Mahmoud Khademi",
            "Mohammad H. Kiapour",
            "Mehran Safayani",
            "Mohammad T. Manzuri",
            "M. Shojaei"
        ],
        "abstract": "In this paper, a novel method for representation and recognition of the facial expressions in two-dimensional image sequences is presented. We apply a variation of two-dimensional heteroscedastic linear discriminant analysis (2DHLDA) algorithm, as an efficient dimensionality reduction technique, to Gabor representation of the input sequence. 2DHLDA is an extension of the two-dimensional linear discriminant analysis (2DLDA) approach and it removes the equal within-class covariance. By applying 2DHLDA in two directions, we eliminate the correlations between both image columns and image rows. Then, we perform a one-dimensional LDA on the new features. This combined method can alleviate the small sample size problem and instability encountered by HLDA. Also, employing both geometric and appearance features and using an ensemble learning scheme based on data fusion, we create a classifier which can efficiently classify the facial expressions. The proposed method is robust to illumination changes and it can properly represent temporal information as well as subtle changes in facial muscles. We provide experiments on Cohn-Kanade database that show the superiority of the proposed method. KEYWORDS: two-dimensional heteroscedastic linear discriminant analysis (2DHLDA), subspace learning, facial expression analysis, Gabor wavelets, ensemble learning.\n    ",
        "submission_date": "2010-04-02T00:00:00",
        "last_modified_date": "2012-07-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1004.0393",
        "title": "Object-image correspondence for curves under finite and affine cameras",
        "authors": [
            "Joseph M. Burdis",
            "Irina A. Kogan"
        ],
        "abstract": "We provide criteria for deciding whether a given planar curve is an image of a given spatial curve, obtained by a central or a parallel projection with unknown parameters. These criteria reduce the projection problem to a certain modification of the equivalence problem of planar curves under affine and projective transformations. The latter problem can be addressed using Cartan's moving frame method. This leads to a novel algorithmic solution of the projection problem for curves. The computational advantage of the algorithms presented here, in comparison to algorithms based on a straightforward solution, lies in a significant reduction of a number of real parameters that has to be eliminated in order to establish existence or non-existence of a projection that maps a given spatial curve to a given planar curve. The same approach can be used to decide whether a given finite set of ordered points on a plane is an image of a given finite set of ordered points in R^3. The motivation comes from the problem of establishing a correspondence between an object and an image, taken by a camera with unknown position and parameters.\n    ",
        "submission_date": "2010-04-02T00:00:00",
        "last_modified_date": "2011-02-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1004.0512",
        "title": "Analysis, Interpretation, and Recognition of Facial Action Units and Expressions Using Neuro-Fuzzy Modeling",
        "authors": [
            "Mahmoud Khademi",
            "Mohammad Hadi Kiapour",
            "Mohammad T. Manzuri-Shalmani",
            "Ali A. Kiaei"
        ],
        "abstract": "In this paper an accurate real-time sequence-based system for representation, recognition, interpretation, and analysis of the facial action units (AUs) and expressions is presented. Our system has the following characteristics: 1) employing adaptive-network-based fuzzy inference systems (ANFIS) and temporal information, we developed a classification scheme based on neuro-fuzzy modeling of the AU intensity, which is robust to intensity variations, 2) using both geometric and appearance-based features, and applying efficient dimension reduction techniques, our system is robust to illumination changes and it can represent the subtle changes as well as temporal information involved in formation of the facial expressions, and 3) by continuous values of intensity and employing top-down hierarchical rule-based classifiers, we can develop accurate human-interpretable AU-to-expression converters. Extensive experiments on Cohn-Kanade database show the superiority of the proposed method, in comparison with support vector machines, hidden Markov models, and neural network classifiers. Keywords: biased discriminant analysis (BDA), classifier design and evaluation, facial action units (AUs), hybrid learning, neuro-fuzzy modeling.\n    ",
        "submission_date": "2010-04-04T00:00:00",
        "last_modified_date": "2010-04-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1004.0515",
        "title": "Recognizing Combinations of Facial Action Units with Different Intensity Using a Mixture of Hidden Markov Models and Neural Network",
        "authors": [
            "Mahmoud Khademi",
            "Mohammad T. Manzuri-Shalmani",
            "Mohammad H. Kiapour",
            "Ali A. Kiaei"
        ],
        "abstract": "Facial Action Coding System consists of 44 action units (AUs) and more than 7000 combinations. Hidden Markov models (HMMs) classifier has been used successfully to recognize facial action units (AUs) and expressions due to its ability to deal with AU dynamics. However, a separate HMM is necessary for each single AU and each AU combination. Since combinations of AU numbering in thousands, a more efficient method will be needed. In this paper an accurate real-time sequence-based system for representation and recognition of facial AUs is presented. Our system has the following characteristics: 1) employing a mixture of HMMs and neural network, we develop a novel accurate classifier, which can deal with AU dynamics, recognize subtle changes, and it is also robust to intensity variations, 2) although we use an HMM for each single AU only, by employing a neural network we can recognize each single and combination AU, and 3) using both geometric and appearance-based features, and applying efficient dimension reduction techniques, our system is robust to illumination changes and it can represent the temporal information involved in formation of the facial expressions. Extensive experiments on Cohn-Kanade database show the superiority of the proposed method, in comparison with other classifiers. Keywords: classifier design and evaluation, data fusion, facial action units (AUs), hidden Markov models (HMMs), neural network (NN).\n    ",
        "submission_date": "2010-04-04T00:00:00",
        "last_modified_date": "2010-04-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1004.0517",
        "title": "Multilinear Biased Discriminant Analysis: A Novel Method for Facial Action Unit Representation",
        "authors": [
            "Mahmoud Khademi",
            "Mehran Safayani",
            "Mohammad T. Manzuri-Shalmani"
        ],
        "abstract": "In this paper a novel efficient method for representation of facial action units by encoding an image sequence as a fourth-order tensor is presented. The multilinear tensor-based extension of the biased discriminant analysis (BDA) algorithm, called multilinear biased discriminant analysis (MBDA), is first proposed. Then, we apply the MBDA and two-dimensional BDA (2DBDA) algorithms, as the dimensionality reduction techniques, to Gabor representations and the geometric features of the input image sequence respectively. The proposed scheme can deal with the asymmetry between positive and negative samples as well as curse of dimensionality dilemma. Extensive experiments on Cohn-Kanade database show the superiority of the proposed method for representation of the subtle changes and the temporal information involved in formation of the facial expressions. As an accurate tool, this representation can be applied to many areas such as recognition of spontaneous and deliberate facial expressions, multi modal/media human computer interaction and lie detection efforts.\n    ",
        "submission_date": "2010-04-04T00:00:00",
        "last_modified_date": "2010-04-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1004.0755",
        "title": "Extended Two-Dimensional PCA for Efficient Face Representation and Recognition",
        "authors": [
            "Mehran Safayani",
            "Mohammad T. Manzuri-Shalmani",
            "Mahmoud Khademi"
        ],
        "abstract": "In this paper a novel method called Extended Two-Dimensional PCA (E2DPCA) is proposed which is an extension to the original 2DPCA. We state that the covariance matrix of 2DPCA is equivalent to the average of the main diagonal of the covariance matrix of PCA. This implies that 2DPCA eliminates some covariance information that can be useful for recognition. E2DPCA instead of just using the main diagonal considers a radius of r diagonals around it and expands the averaging so as to include the covariance information within those diagonals. The parameter r unifies PCA and 2DPCA. r = 1 produces the covariance of 2DPCA, r = n that of PCA. Hence, by controlling r it is possible to control the trade-offs between recognition accuracy and energy compression (fewer coefficients), and between training and recognition complexity. Experiments on ORL face database show improvement in both recognition accuracy and recognition time over the original 2DPCA.\n    ",
        "submission_date": "2010-04-06T00:00:00",
        "last_modified_date": "2010-04-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1004.1215",
        "title": "Regularized Richardson-Lucy Algorithm for Sparse Reconstruction of Poissonian Images",
        "authors": [
            "Elad Shaked",
            "Oleg Michailovich"
        ],
        "abstract": "Restoration of digital images from their degraded measurements has always been a problem of great theoretical and practical importance in numerous applications of imaging sciences. A specific solution to the problem of image restoration is generally determined by the nature of degradation phenomenon as well as by the statistical properties of measurement noises. The present study is concerned with the case in which the images of interest are corrupted by convolutional blurs and Poisson noises. To deal with such problems, there exists a range of solution methods which are based on the principles originating from the fixed-point algorithm of Richardson and Lucy (RL). In this paper, we provide conceptual and experimental proof that such methods tend to converge to sparse solutions, which makes them applicable only to those images which can be represented by a relatively small number of non-zero samples in the spatial domain. Unfortunately, the set of such images is relatively small, which restricts the applicability of RL-type methods. On the other hand, virtually all practical images admit sparse representations in the domain of a properly designed linear transform. To take advantage of this fact, it is therefore tempting to modify the RL algorithm so as to make it recover  representation coefficients, rather than the values of their associated image. Such modification is introduced in this paper. Apart from the generality of its assumptions, the proposed method is also superior to many established reconstruction approaches in terms of estimation accuracy and computational complexity. This and other conclusions of this study are validated through a series of numerical experiments.\n    ",
        "submission_date": "2010-04-08T00:00:00",
        "last_modified_date": "2010-04-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1004.1227",
        "title": "Signature Recognition using Multi Scale Fourier Descriptor And Wavelet Transform",
        "authors": [
            "Ismail A. Ismail",
            "Mohammed A. Ramadan",
            "Talaat S. El danaf",
            "Ahmed H. Samak"
        ],
        "abstract": "This paper present a novel off-line signature recognition method based on multi scale Fourier Descriptor and wavelet transform . The main steps of constructing a signature recognition system are discussed and experiments on real data sets show that the average error rate can reach 1%. Finally we compare 8 distance measures between feature vectors with respect to the recognition performance.\n",
        "submission_date": "2010-04-08T00:00:00",
        "last_modified_date": "2010-04-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1004.1679",
        "title": "A Robust Fuzzy Clustering Technique with Spatial Neighborhood Information for Effective Medical Image Segmentation",
        "authors": [
            "S. Zulaikha Beevi",
            "M. Mohammed Sathik",
            "K. Senthamaraikannan"
        ],
        "abstract": "Medical image segmentation demands an efficient and robust segmentation algorithm against noise. The conventional fuzzy c-means algorithm is an efficient clustering algorithm that is used in medical image segmentation. But FCM is highly vulnerable to noise since it uses only intensity values for clustering the images. This paper aims to develop a novel and efficient fuzzy spatial c-means clustering algorithm which is robust to noise. The proposed clustering algorithm uses fuzzy spatial information to calculate membership value. The input image is clustered using proposed ISFCM algorithm. A comparative study has been made between the conventional FCM and proposed ISFCM. The proposed approach is found to be outperforming the conventional FCM.\n    ",
        "submission_date": "2010-04-10T00:00:00",
        "last_modified_date": "2010-04-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1004.1686",
        "title": "New Clustering Algorithm for Vector Quantization using Rotation of Error Vector",
        "authors": [
            "H. B. Kekre",
            "Tanuja K. Sarode"
        ],
        "abstract": "The paper presents new clustering algorithm. The proposed algorithm gives less distortion as compared to well known Linde Buzo Gray (LBG) algorithm and Kekre's Proportionate Error (KPE) Algorithm. Constant error is added every time to split the clusters in LBG, resulting in formation of cluster in one direction which is 1350 in 2-dimensional case. Because of this reason clustering is inefficient resulting in high MSE in LBG. To overcome this drawback of LBG proportionate error is added to change the cluster orientation in KPE. Though the cluster orientation in KPE is changed its variation is limited to +/- 450 over 1350. The proposed algorithm takes care of this problem by introducing new orientation every time to split the clusters. The proposed method reduces PSNR by 2db to 5db for codebook size 128 to 1024 with respect to LBG.\n    ",
        "submission_date": "2010-04-10T00:00:00",
        "last_modified_date": "2010-04-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1004.1768",
        "title": "A New Approach to Lung Image Segmentation using Fuzzy Possibilistic C-Means Algorithm",
        "authors": [
            "M. Gomathi",
            "P.Thangaraj"
        ],
        "abstract": "Image segmentation is a vital part of image processing. Segmentation has its application widespread in the field of medical images in order to diagnose curious diseases. The same medical images can be segmented manually. But the accuracy of image segmentation using the segmentation algorithms is more when compared with the manual segmentation. In the field of medical diagnosis an extensive diversity of imaging techniques is presently available, such as radiography, computed tomography (CT) and magnetic resonance imaging (MRI). Medical image segmentation is an essential step for most consequent image analysis tasks. Although the original FCM algorithm yields good results for segmenting noise free images, it fails to segment images corrupted by noise, outliers and other imaging artifact. This paper presents an image segmentation approach using Modified Fuzzy C-Means (FCM) algorithm and Fuzzy Possibilistic c-means algorithm (FPCM). This approach is a generalized version of standard Fuzzy CMeans Clustering (FCM) algorithm. The limitation of the conventional FCM technique is eliminated in modifying the standard technique. The Modified FCM algorithm is formulated by modifying the distance measurement of the standard FCM algorithm to permit the labeling of a pixel to be influenced by other pixels and to restrain the noise effect during segmentation. Instead of having one term in the objective function, a second term is included, forcing the membership to be as high as possible without a maximum limit constraint of one. Experiments are conducted on real images to investigate the performance of the proposed modified FCM technique in segmenting the medical images. Standard FCM, Modified FCM, Fuzzy Possibilistic CMeans algorithm (FPCM) are compared to explore the accuracy of our proposed approach.\n    ",
        "submission_date": "2010-04-11T00:00:00",
        "last_modified_date": "2010-04-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1004.1886",
        "title": "Feature Level Fusion of Face and Palmprint Biometrics by Isomorphic Graph-based Improved K-Medoids Partitioning",
        "authors": [
            "Dakshina Ranjan Kisku",
            "Phalguni Gupta",
            "Jamuna Kanta Sing"
        ],
        "abstract": "This paper presents a feature level fusion approach which uses the improved K-medoids clustering algorithm and isomorphic graph for face and palmprint biometrics. Partitioning around medoids (PAM) algorithm is used to partition the set of n invariant feature points of the face and palmprint images into k clusters. By partitioning the face and palmprint images with scale invariant features SIFT points, a number of clusters is formed on both the images. Then on each cluster, an isomorphic graph is drawn. In the next step, the most probable pair of graphs is searched using iterative relaxation algorithm from all possible isomorphic graphs for a pair of corresponding face and palmprint images. Finally, graphs are fused by pairing the isomorphic graphs into augmented groups in terms of addition of invariant SIFT points and in terms of combining pair of keypoint descriptors by concatenation rule. Experimental results obtained from the extensive evaluation show that the proposed feature level fusion with the improved K-medoids partitioning algorithm increases the performance of the system with utmost level of accuracy.\n    ",
        "submission_date": "2010-04-12T00:00:00",
        "last_modified_date": "2010-04-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1004.1887",
        "title": "Maximized Posteriori Attributes Selection from Facial Salient Landmarks for Face Recognition",
        "authors": [
            "Phalguni Gupta",
            "Dakshina Ranjan Kisku",
            "Jamuna Kanta Sing",
            "Massimo Tistarelli"
        ],
        "abstract": "This paper presents a robust and dynamic face recognition technique based on the extraction and matching of devised probabilistic graphs drawn on SIFT features related to independent face areas. The face matching strategy is based on matching individual salient facial graph characterized by SIFT features as connected to facial landmarks such as the eyes and the mouth. In order to reduce the face matching errors, the Dempster-Shafer decision theory is applied to fuse the individual matching scores obtained from each pair of salient facial features. The proposed algorithm is evaluated with the ORL and the IITK face databases. The experimental results demonstrate the effectiveness and potential of the proposed face recognition technique also in case of partially occluded faces.\n    ",
        "submission_date": "2010-04-12T00:00:00",
        "last_modified_date": "2010-04-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1004.3257",
        "title": "Offline Handwriting Recognition using Genetic Algorithm",
        "authors": [
            "Rahul Kala",
            "Harsh Vazirani",
            "Anupam Shukla",
            "Ritu Tiwari"
        ],
        "abstract": "Handwriting Recognition enables a person to scribble something on a piece of paper and then convert it into text. If we look into the practical reality there are enumerable styles in which a character may be written. These styles can be self combined to generate more styles. Even if a small child knows the basic styles a character can be written, he would be able to recognize characters written in styles intermediate between them or formed by their mixture. This motivates the use of Genetic Algorithms for the problem. In order to prove this, we made a pool of images of characters. We converted them to graphs. The graph of every character was intermixed to generate styles intermediate between the styles of parent character. Character recognition involved the matching of the graph generated from the unknown character image with the graphs generated by mixing. Using this method we received an accuracy of 98.44%.\n    ",
        "submission_date": "2010-04-19T00:00:00",
        "last_modified_date": "2010-04-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1004.3276",
        "title": "Color Image Compression Based On Wavelet Packet Best Tree",
        "authors": [
            "G. K. Kharate",
            "V. H. Patil"
        ],
        "abstract": "In Image Compression, the researchers' aim is to reduce the number of bits required to represent an image by removing the spatial and spectral redundancies. Recently discrete wavelet transform and wavelet packet has emerged as popular techniques for image compression. The wavelet transform is one of the major processing components of image compression. The result of the compression changes as per the basis and tap of the wavelet used. It is proposed that proper selection of mother wavelet on the basis of nature of images, improve the quality as well as compression ratio remarkably. We suggest the novel technique, which is based on wavelet packet best tree based on Threshold Entropy with enhanced run-length encoding. This method reduces the time complexity of wavelet packets decomposition as complete tree is not decomposed. Our algorithm selects the sub-bands, which include significant information based on threshold entropy. The enhanced run length encoding technique is suggested provides better results than RLE. The result when compared with JPEG-2000 proves to be better.\n    ",
        "submission_date": "2010-04-19T00:00:00",
        "last_modified_date": "2010-04-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1004.3549",
        "title": "Signature Region of Interest using Auto cropping",
        "authors": [
            "Bassam Al-Mahadeen",
            "Mokhled S. AlTarawneh",
            "Islam H. AlTarawneh"
        ],
        "abstract": "A new approach for signature region of interest pre-processing was presented. It used new auto cropping preparation on the basis of the image content, where the intensity value of pixel is the source of cropping. This approach provides both the possibility of improving the performance of security systems based on signature images, and also the ability to use only the region of interest of the used image to suit layout design of biometric systems. Underlying the approach is a novel segmentation method which identifies the exact region of foreground of signature for feature extraction usage. Evaluation results of this approach shows encouraging prospects by eliminating the need for false region isolating, reduces the time cost associated with signature false points detection, and addresses enhancement issues. A further contribution of this paper is an automated cropping stage in bio-secure based systems.\n    ",
        "submission_date": "2010-04-20T00:00:00",
        "last_modified_date": "2010-04-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1004.3629",
        "title": "Simultaneous Bayesian inference of motion velocity fields and probabilistic models in successive video-frames described by spatio-temporal MRFs",
        "authors": [
            "Yuya Inagaki",
            "Jun-ichi Inoue"
        ],
        "abstract": "We numerically investigate a mean-field Bayesian approach with the assistance of the Markov chain Monte Carlo method to estimate motion velocity fields  and probabilistic models simultaneously in consecutive digital images described by spatio-temporal Markov random fields. Preliminary to construction of  our procedure, we find that mean-field variables in the iteration diverge due to improper normalization factor of regularization terms appearing in the posterior. To avoid this difficulty, we rescale the regularization term by introducing a scaling factor and optimizing it by means of minimization of the mean-square error. We confirm that the optimal scaling factor stabilizes the mean-field iterative process of the motion velocity estimation. We next attempt to estimate the optimal values of hyper-parameters including the regularization term, which define our probabilistic model macroscopically, by using the Boltzmann-machine type learning algorithm based on gradient descent of marginal likelihood (type-II likelihood) with respect to the hyper-parameters. In our framework, one can estimate both the probabilistic model (hyper-parameters) and motion velocity fields simultaneously.  We find that our motion estimation is much better than the result obtained by Zhang and Hanouer (1995) in which the hyper-parameters are set to some ad-hoc values without any theoretical justification.\n    ",
        "submission_date": "2010-04-21T00:00:00",
        "last_modified_date": "2010-04-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1004.3708",
        "title": "Parcellation of fMRI Datasets with ICA and PLS-A Data Driven Approach",
        "authors": [
            "Yongnan Ji",
            "Pierre-Yves Herve",
            "Uwe Aickelin",
            "Alain Pitiot"
        ],
        "abstract": "Inter-subject parcellation of functional Magnetic Resonance Imaging (fMRI) data based on a standard General Linear Model (GLM)and spectral clustering was recently proposed as a means to alleviate the issues associated with spatial normalization in fMRI. However, for all its appeal, a GLM-based parcellation approach introduces its own biases, in the form of a priori knowledge about the shape of Hemodynamic Response Function (HRF) and task-related signal changes, or about the subject behaviour during the task. In this paper, we introduce a data-driven version of the spectral clustering parcellation, based on Independent Component Analysis (ICA) and Partial Least Squares (PLS) instead of the GLM. First, a number of independent components are automatically selected. Seed voxels are then obtained from the associated ICA maps and we compute the PLS latent variables between the fMRI signal of the seed voxels (which covers regional variations of the HRF) and the principal components of the signal across all voxels. Finally, we parcellate all subjects data with a spectral clustering of the PLS latent variables. We present results of the application of the proposed method on both single-subject and multi-subject fMRI datasets. Preliminary experimental results, evaluated with intra-parcel variance of GLM t-values and PLS derived t-values, indicate that this data-driven approach offers improvement in terms of parcellation accuracy over GLM based techniques.\n    ",
        "submission_date": "2010-04-21T00:00:00",
        "last_modified_date": "2010-04-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1004.3980",
        "title": "Hashing Image Patches for Zooming",
        "authors": [
            "Mithun Das Gupta"
        ],
        "abstract": "In this paper we present a Bayesian image zooming/super-resolution algorithm based on a patch based representation. We work on a patch based model with overlap and employ a Locally Linear Embedding (LLE) based approach as our data fidelity term in the Bayesian inference. The image prior imposes continuity constraints across the overlapping patches. We apply an error back-projection technique, with an approximate cross bilateral filter. The problem of nearest neighbor search is handled by a variant of the locality sensitive hashing (LSH) scheme. The novelty of our work lies in the speed up achieved by the hashing scheme and the robustness and inherent modularity and parallel structure achieved by the LLE setup. The ill-posedness of the image reconstruction problem is handled by the introduction of regularization priors which encode the knowledge present in vast collections of natural images. We present comparative results for both run-time as well as visual image quality based measurements.\n    ",
        "submission_date": "2010-04-22T00:00:00",
        "last_modified_date": "2010-04-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1004.4373",
        "title": "Spatially-Adaptive Reconstruction in Computed Tomography Based on Statistical Learning",
        "authors": [
            "Joseph Shtok",
            "Michael Zibulevsky",
            "Michael Elad"
        ],
        "abstract": "We propose a direct reconstruction algorithm for Computed Tomography, based on a local fusion of a few preliminary image estimates by means of a non-linear fusion rule. One such rule is based on a signal denoising technique which is spatially adaptive to the unknown local smoothness. Another, more powerful fusion rule, is based on a neural network trained off-line with a high-quality training set of images. Two types of linear reconstruction algorithms for the preliminary images are employed for two different reconstruction tasks. For an entire image reconstruction from full projection data, the proposed scheme uses a sequence of Filtered Back-Projection algorithms with a gradually growing cut-off frequency. To recover a Region Of Interest only from local projections, statistically-trained linear reconstruction algorithms are employed. Numerical experiments display the improvement in reconstruction quality when compared to linear reconstruction algorithms.\n    ",
        "submission_date": "2010-04-25T00:00:00",
        "last_modified_date": "2010-04-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1004.4448",
        "title": "Deblured Gaussian Blurred Images",
        "authors": [
            "Salem Saleh Al-amri",
            "N.V. Kalyankar",
            "Khamitkar S.D"
        ],
        "abstract": "This paper attempts to undertake the study of Restored Gaussian Blurred Images. by using four types of techniques of deblurring image as Wiener filter, Regularized filter, Lucy Richardson deconvlutin algorithm and Blind deconvlution algorithm with an information of the Point Spread Function (PSF) corrupted blurred image with Different values of Size and Alfa and then corrupted by Gaussian noise. The same is applied to the remote sensing image and they are compared with one another, So as to choose the base technique for restored or deblurring ",
        "submission_date": "2010-04-26T00:00:00",
        "last_modified_date": "2010-04-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1004.4467",
        "title": "An Efficient Watermarking Algorithm to Improve Payload and Robustness without Affecting Image Perceptual Quality",
        "authors": [
            "Er. Deepak Aggarwal",
            "Er. Sandeep Kaur",
            "Er. Anantdeep"
        ],
        "abstract": "Capacity, Robustness, & Perceptual quality of watermark data are very important issues to be considered. A lot of research is going on to increase these parameters for watermarking of the digital images, as there is always a tradeoff among them. . In this paper an efficient watermarking algorithm to improve payload and robustness without affecting perceptual quality of image data based on DWT is discussed. The aim of the paper is to employ the nested watermarks in wavelet domain which increases the capacity and ultimately the robustness against attacks and selection of different scaling factor values for LL & HH bands and during embedding not to create the visible artifacts in the original image and therefore the original and watermarked image is similar.\n    ",
        "submission_date": "2010-04-26T00:00:00",
        "last_modified_date": "2010-04-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1004.4793",
        "title": "Logical methods of object recognition on satellite images using spatial constraints",
        "authors": [
            "R.K. Fedorov"
        ],
        "abstract": "A logical approach to object recognition on image is proposed. The main idea of the approach is to perform the object recognition as a logical inference on a set of rules describing an object shape.\n    ",
        "submission_date": "2010-04-27T00:00:00",
        "last_modified_date": "2010-04-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1004.5351",
        "title": "Isometric Embeddings in Imaging and Vision: Facts and Fiction",
        "authors": [
            "Emil Saucan"
        ],
        "abstract": "We explore the practicability of Nash's Embedding Theorem in vision and imaging sciences. In particular, we investigate the relevance of a result of Burago and Zalgaller regarding the existence of isometric embeddings of polyhedral surfaces in $\\mathbb{R}^3$ and we show that their proof does not  extended directly to higher dimensions.\n    ",
        "submission_date": "2010-04-29T00:00:00",
        "last_modified_date": "2010-05-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1004.5424",
        "title": "Graphic Symbol Recognition using Graph Based Signature and Bayesian Network Classifier",
        "authors": [
            "Muhammad Muzzamil Luqman",
            "Thierry Brouard",
            "Jean-Yves Ramel"
        ],
        "abstract": "We present a new approach for recognition of complex graphic symbols in technical documents. Graphic symbol recognition is a well known challenge in the field of document image analysis and is at heart of most graphic recognition systems. Our method uses structural approach for symbol representation and statistical classifier for symbol recognition. In our system we represent symbols by their graph based signatures: a graphic symbol is vectorized and is converted to an attributed relational graph, which is used for computing a feature vector for the symbol. This signature corresponds to geometry and topology of the symbol. We learn a Bayesian network to encode joint probability distribution of symbol signatures and use it in a supervised learning scenario for graphic symbol recognition. We have evaluated our method on synthetically deformed and degraded images of pre-segmented 2D architectural and electronic symbols from GREC databases and have obtained encouraging recognition rates.\n    ",
        "submission_date": "2010-04-30T00:00:00",
        "last_modified_date": "2010-04-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1004.5427",
        "title": "Employing fuzzy intervals and loop-based methodology for designing structural signature: an application to symbol recognition",
        "authors": [
            "Muhammad Muzzamil Luqman",
            "Mathieu Delalandre",
            "Thierry Brouard",
            "Jean-Yves Ramel",
            "Josep Llad\u00f3s"
        ],
        "abstract": "Motivation of our work is to present a new methodology for symbol recognition. We support structural methods for representing visual associations in graphic documents. The proposed method employs a structural approach for symbol representation and a statistical classifier for recognition. We vectorize a graphic symbol, encode its topological and geometrical information by an ARG and compute a signature from this structural graph. To address the sensitivity of structural representations to deformations and degradations, we use data adapted fuzzy intervals while computing structural signature. The joint probability distribution of signatures is encoded by a Bayesian network. This network in fact serves as a mechanism for pruning irrelevant features and choosing a subset of interesting features from structural signatures, for underlying symbol set. Finally we deploy the Bayesian network in supervised learning scenario for recognizing query symbols. We have evaluated the robustness of our method against noise, on synthetically deformed and degraded images of pre-segmented 2D architectural and electronic symbols from GREC databases and have obtained encouraging recognition rates. A second set of experimentation was carried out for evaluating the performance of our method against context noise i.e. symbols cropped from complete documents. The results support the use of our signature by a symbol spotting system.\n    ",
        "submission_date": "2010-04-30T00:00:00",
        "last_modified_date": "2010-04-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1005.0858",
        "title": "Randomized hybrid linear modeling by local best-fit flats",
        "authors": [
            "Teng Zhang",
            "Arthur Szlam",
            "Yi Wang",
            "Gilad Lerman"
        ],
        "abstract": "The hybrid linear modeling problem is to identify a set of d-dimensional affine sets in a D-dimensional Euclidean space. It arises, for example, in object tracking and structure from motion. The hybrid linear model can be considered as the second simplest (behind linear) manifold model of data. In this paper we will present a very simple geometric method for hybrid linear modeling based on selecting a set of local best fit flats that minimize a global l1 error measure. The size of the local neighborhoods is determined automatically by the Jones' l2 beta numbers; it is proven under certain geometric conditions that good local neighborhoods exist and are found by our method. We also demonstrate how to use this algorithm for fast determination of the number of affine subspaces. We give extensive experimental evidence demonstrating the state of the art accuracy and speed of the algorithm on synthetic and real hybrid linear data.\n    ",
        "submission_date": "2010-05-05T00:00:00",
        "last_modified_date": "2010-05-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1005.0907",
        "title": "Multistage Hybrid Arabic/Indian Numeral OCR System",
        "authors": [
            "Yasser M. Alginaih",
            "Abdul Ahad Siddiqi"
        ],
        "abstract": "The use of OCR in postal services is not yet universal and there are still many countries that process mail sorting manually. Automated Arabic/Indian numeral Optical Character Recognition (OCR) systems for Postal services are being used in some countries, but still there are errors during the mail sorting process, thus causing a reduction in efficiency. The need to investigate fast and efficient recognition algorithms/systems is important so as to correctly read the postal codes from mail addresses and to eliminate any errors during the mail sorting stage. The objective of this study is to recognize printed numerical postal codes from mail addresses. The proposed system is a multistage hybrid system which consists of three different feature extraction methods, i.e., binary, zoning, and fuzzy features, and three different classifiers, i.e., Hamming Nets, Euclidean Distance, and Fuzzy Neural Network Classifiers. The proposed system, systematically compares the performance of each of these methods, and ensures that the numerals are recognized correctly. Comprehensive results provide a very high recognition rate, outperforming the other known developed methods in literature.\n    ",
        "submission_date": "2010-05-06T00:00:00",
        "last_modified_date": "2010-05-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1005.0945",
        "title": "An Efficient Vein Pattern-based Recognition System",
        "authors": [
            "Mohit Soni",
            "Sandesh Gupta",
            "M.S. Rao",
            "Phalguni Gupta"
        ],
        "abstract": "This paper presents an efficient human recognition system based on vein pattern from the palma dorsa. A new absorption based technique has been proposed to collect good quality images with the help of a low cost camera and light source. The system automatically detects the region of interest from the image and does the necessary preprocessing to extract features. A Euclidean Distance based matching technique has been used for making the decision. It has been tested on a data set of 1750 image samples collected from 341 individuals. The accuracy of the verification system is found to be 99.26% with false rejection rate (FRR) of 0.03%.\n    ",
        "submission_date": "2010-05-06T00:00:00",
        "last_modified_date": "2010-05-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1005.1471",
        "title": "Classification via Incoherent Subspaces",
        "authors": [
            "Karin Schnass",
            "Pierre Vandergheynst"
        ],
        "abstract": "This article presents a new classification framework that can extract individual features per class. The scheme is based on a model of incoherent subspaces, each one associated to one class, and a model on how the elements in a class are represented in this subspace. After the theoretical analysis an alternate projection algorithm to find such a collection is developed. The classification performance and speed of the proposed method is tested on the AR and YaleB databases and compared to that of Fisher's LDA and a recent approach based on on $\\ell_1$ minimisation. Finally connections of the presented scheme to already existing work are discussed and possible ways of extensions are pointed out.\n    ",
        "submission_date": "2010-05-10T00:00:00",
        "last_modified_date": "2010-05-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1005.2715",
        "title": "On the Subspace of Image Gradient Orientations",
        "authors": [
            "Georgios Tzimiropoulos",
            "Stefanos Zafeiriou"
        ],
        "abstract": "We introduce the notion of Principal Component Analysis (PCA) of image gradient orientations. As image data is typically noisy, but noise is substantially different from Gaussian, traditional PCA of pixel intensities very often fails to estimate reliably the low-dimensional subspace of a given data population. We show that replacing intensities with gradient orientations and the $\\ell_2$ norm with a cosine-based distance measure offers, to some extend, a remedy to this problem. Our scheme requires the eigen-decomposition of a covariance matrix and is as computationally efficient as standard $\\ell_2$ PCA. We demonstrate some of its favorable properties on robust subspace estimation.\n    ",
        "submission_date": "2010-05-16T00:00:00",
        "last_modified_date": "2010-05-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1005.4020",
        "title": "Image Segmentation by Using Threshold Techniques",
        "authors": [
            "Salem Saleh Al-amri",
            "N.V. Kalyankar",
            "Khamitkar S.D."
        ],
        "abstract": "This paper attempts to undertake the study of segmentation image techniques by using five threshold methods as Mean method, P-tile method, Histogram Dependent Technique (HDT), Edge Maximization Technique (EMT) and visual Technique and they are compared with one another so as to choose the best technique for threshold segmentation techniques image. These techniques applied on three satellite images to choose base guesses for threshold segmentation image.\n    ",
        "submission_date": "2010-05-21T00:00:00",
        "last_modified_date": "2010-05-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1005.4032",
        "title": "Combining Multiple Feature Extraction Techniques for Handwritten Devnagari Character Recognition",
        "authors": [
            "Sandhya Arora",
            "Debotosh Bhattacharjee",
            "Mita Nasipuri",
            "Dipak Kumar Basu",
            "Mahantapas Kundu"
        ],
        "abstract": "In this paper we present an OCR for Handwritten Devnagari Characters. Basic symbols are recognized by neural classifier. We have used four feature extraction techniques namely, intersection, shadow feature, chain code histogram and straight line fitting features. Shadow features are computed globally for character image while intersection features, chain code histogram features and line fitting features are computed by dividing the character image into different segments. Weighted majority voting technique is used for combining the classification decision obtained from four Multi Layer Perceptron(MLP) based classifier. On experimentation with a dataset of 4900 samples the overall recognition rate observed is 92.80% as we considered top five choices results. This method is compared with other recent methods for Handwritten Devnagari Character Recognition and it has been observed that this approach has better success rate than other methods.\n    ",
        "submission_date": "2010-05-21T00:00:00",
        "last_modified_date": "2010-05-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1005.4034",
        "title": "Face Synthesis (FASY) System for Generation of a Face Image from Human Description",
        "authors": [
            "Santanu Halder",
            "Debotosh Bhattacharjee",
            "Mita Nasipuri",
            "Dipak Kumar Basu",
            "Mahantapas Kundu"
        ],
        "abstract": "This paper aims at generating a new face based on the human like description using a new concept. The FASY (FAce SYnthesis) System is a Face Database Retrieval and new Face generation System that is under development. One of its main features is the generation of the requested face when it is not found in the existing database, which allows a continuous growing of the database also.\n    ",
        "submission_date": "2010-05-21T00:00:00",
        "last_modified_date": "2010-05-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1005.4035",
        "title": "Classification of Polar-Thermal Eigenfaces using Multilayer Perceptron for Human Face Recognition",
        "authors": [
            "Mrinal Kanti Bhowmik",
            "Debotosh Bhattacharjee",
            "Mita Nasipuri",
            "Dipak Kumar Basu",
            "Mahantapas Kundu"
        ],
        "abstract": "This paper presents a novel approach to handle the challenges of face recognition. In this work thermal face images are considered, which minimizes the affect of illumination changes and occlusion due to moustache, beards, adornments etc. The proposed approach registers the training and testing thermal face images in polar coordinate, which is capable to handle complicacies introduced by scaling and rotation. Polar images are projected into eigenspace and finally classified using a multi-layer perceptron. In the experiments we have used Object Tracking and Classification Beyond Visible Spectrum (OTCBVS) database benchmark thermal face images. Experimental results show that the proposed approach significantly improves the verification and identification performance and the success rate is 97.05%.\n    ",
        "submission_date": "2010-05-21T00:00:00",
        "last_modified_date": "2010-05-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1005.4044",
        "title": "Reduction of Feature Vectors Using Rough Set Theory for Human Face Recognition",
        "authors": [
            "Debotosh Bhattacharjee",
            "Dipak Kumar Basu",
            "Mita Nasipuri",
            "M. Kundu"
        ],
        "abstract": "In this paper we describe a procedure to reduce the size of the input feature vector. A complex pattern recognition problem like face recognition involves huge dimension of input feature vector. To reduce that dimension here we have used eigenspace projection (also called as Principal Component Analysis), which is basically transformation of space. To reduce further we have applied feature selection method to select indispensable features, which will remain in the final feature vectors. Features those are not selected are removed from the final feature vector considering them as redundant or superfluous. For selection of features we have used the concept of reduct and core from rough set theory. This method has shown very good performance. It is worth to mention that in some cases the recognition rate increases with the decrease in the feature vector dimension.\n    ",
        "submission_date": "2010-05-21T00:00:00",
        "last_modified_date": "2010-05-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1005.4103",
        "title": "LACBoost and FisherBoost: Optimally Building Cascade Classifiers",
        "authors": [
            "Chunhua Shen",
            "Peng Wang",
            "Hanxi Li"
        ],
        "abstract": "Object detection is one of the key tasks in computer vision. The cascade framework of Viola and Jones has become the de facto standard. A classifier in each node of the cascade is required to achieve extremely high detection rates, instead of low overall classification error. Although there are a few reported methods addressing this requirement in the context of object detection, there is no a principled feature selection method that explicitly takes into account this asymmetric node learning objective. We provide such a boosting algorithm in this work. It is inspired by the linear asymmetric classifier (LAC) of Wu et al. in that our boosting algorithm optimizes a similar cost function. The new totally-corrective boosting algorithm is implemented by the column generation technique in convex optimization. Experimental results on face detection suggest that our proposed boosting algorithms can improve the state-of-the-art methods in detection performance.\n    ",
        "submission_date": "2010-05-22T00:00:00",
        "last_modified_date": "2010-05-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1005.4118",
        "title": "Incremental Training of a Detector Using Online Sparse Eigen-decomposition",
        "authors": [
            "Sakrapee Paisitkriangkrai",
            "Chunhua Shen",
            "Jian Zhang"
        ],
        "abstract": "The ability to efficiently and accurately detect objects plays a very crucial role for many computer vision tasks. Recently, offline object detectors have shown a tremendous success. However, one major drawback of offline techniques is that a complete set of training data has to be collected beforehand. In addition, once learned, an offline detector can not make use of newly arriving data. To alleviate these drawbacks, online learning has been adopted with the  following objectives: (1) the technique should be computationally and storage efficient; (2) the updated classifier must maintain its high classification accuracy. In this paper, we propose an effective and efficient framework for learning an adaptive online greedy sparse linear discriminant analysis (GSLDA) model. Unlike many existing online boosting detectors, which usually apply exponential or logistic loss, our online algorithm makes use of LDA's learning criterion that not only aims to maximize the class-separation criterion but also incorporates the asymmetrical property of training data distributions. We provide a better alternative for online boosting algorithms in the context of training a visual object detector. We demonstrate the robustness and efficiency of our methods on handwriting digit and face data sets. Our results confirm that object detection tasks benefit significantly when trained in an online manner.\n    ",
        "submission_date": "2010-05-22T00:00:00",
        "last_modified_date": "2010-05-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1005.4216",
        "title": "Classification of LULC Change Detection using Remotely Sensed Data for Coimbatore City, Tamilnadu, India",
        "authors": [
            "Y.Babykalpana",
            "K.ThanushKodi"
        ],
        "abstract": "Maps are used to describe far-off places . It is an aid for navigation and military strategies. Mapping of the lands are important and the mapping work is based on (i). Natural resource management & development (ii). Information technology ,(iii). Environmental development ,(iv). Facility management and (v). e-governance. The Landuse / Landcover system espoused by almost all Organisations and scientists, engineers and remote sensing community who are involved in mapping of earth surface features, is a system which is derived from the united States Geological Survey (USGS) LULC classification system. The application of RS and GIS involves influential of homogeneous zones, drift analysis of land use integration of new area changes or change detection etc.,National Remote Sensing Agency(NRSA) Govt. of India has devised a generalized LULC classification system respect to the Indian conditions based on the various categories of Earth surface features , resolution of available satellite data, capabilities of sensors and present and future applications. The profusion information of the earth surface offered by the high resolution satellite images for remote sensing applications. Using change detection methodologies to extract the target changes in the areas from high resolution images and rapidly updates geodatabase information ",
        "submission_date": "2010-05-23T00:00:00",
        "last_modified_date": "2010-05-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1005.4292",
        "title": "Application Of Fuzzy System In Segmentation Of MRI Brain Tumor",
        "authors": [
            "Mrigank Rajya",
            "Sonal Rewri",
            "Swati Sheoran"
        ],
        "abstract": "Segmentation of images holds an important position in the area of image processing. It becomes more important whi le typically dealing with medical images where presurgery and post surgery decisions are required for the purpose of initiating and speeding up the recovery process. Segmentation of 3-D tumor structures from magnetic resonance images (MRI) is a very challenging problem due to the variability of tumor geometry and intensity patterns. Level set evolution combining global smoothness with the flexibility of topology changes offers significant advantages over the conventional statistical classification followed by mathematical morphology. Level set evolution with constant propagation needs to be initialized either completely inside or outside the tumor and can leak through weak or missing boundary parts. Replacing the constant propagation term by a statistical force overcomes these limitations and results in a convergence to a stable solution. Using MR images presenting tumors, probabilities for background and tumor regions are calculated from a pre- and post-contrast difference image and mixture modeling fit of the histogram. The whole image is used for initialization of the level set evolution to segment the tumor boundaries.\n    ",
        "submission_date": "2010-05-24T00:00:00",
        "last_modified_date": "2010-05-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1005.5181",
        "title": "Compression Rate Method for Empirical Science and Application to Computer Vision",
        "authors": [
            "Daniel Burfoot"
        ],
        "abstract": "This philosophical paper proposes a modified version of the scientific method, in which large databases are used instead of experimental observations as the necessary empirical ingredient. This change in the source of the empirical data allows the scientific method to be applied to several aspects of physical reality that previously resisted systematic interrogation. Under the new method, scientific theories are compared by instantiating them as compression programs, and examining the codelengths they achieve on a database of measurements related to a phenomenon of interest. Because of the impossibility of compressing random data, \"real world\" data can only be compressed by discovering and exploiting the empirical structure it exhibits. The method also provides a new way of thinking about two longstanding issues in the philosophy of science: the problem of induction and the problem of demarcation.\n",
        "submission_date": "2010-05-27T00:00:00",
        "last_modified_date": "2010-05-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1005.5437",
        "title": "Content Based Image Retrieval Using Exact Legendre Moments and Support Vector Machine",
        "authors": [
            "Ch.Srinivasa Rao",
            "S.Srinivas Kumar",
            "B.Chandra Mohan"
        ],
        "abstract": "Content Based Image Retrieval (CBIR) systems based on shape using invariant image moments, viz., Moment Invariants (MI) and Zernike Moments (ZM) are available in the literature. MI and ZM are good at representing the shape features of an image. However, non-orthogonality of MI and poor reconstruction of ZM restrict their application in CBIR. Therefore, an efficient and orthogonal moment based CBIR system is needed. Legendre Moments (LM) are orthogonal, computationally faster, and can represent image shape features compactly. CBIR system using Exact Legendre Moments (ELM) for gray scale images is proposed in this work. Superiority of the proposed CBIR system is observed over other moment based methods, viz., MI and ZM in terms of retrieval efficiency and retrieval time. Further, the classification efficiency is improved by employing Support Vector Machine (SVM) classifier. Improved retrieval results are obtained over existing CBIR algorithm based on Stacked Euler Vector (SERVE) combined with Modified Moment Invariants (MMI).\n    ",
        "submission_date": "2010-05-29T00:00:00",
        "last_modified_date": "2010-05-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1005.5439",
        "title": "Detection of Bleeding in Wireless Capsule Endoscopy Images Using Range Ratio Color",
        "authors": [
            "Amer A. Al-Rahayfeh",
            "Abdelshakour A. Abuzneid"
        ],
        "abstract": "Wireless Capsule Endoscopy (WCE) is device to detect abnormalities in colon,esophagus,small intestinal and stomach, to distinguish bleeding in WCE images from non bleeding is a hard job by human reviewing and very time consuming. Consequently, automation for classifying bleeding frames not only will expedite the process but will reduce the burden on the doctors. Using the purity of the red color we can detect the Bleeding areas in WCE images. But, we could find various intensity of red color values in different parts of the small intestinal,so it is not enough to depend on the red color feature alone. We select RGB(Red,Green,Blue) because it takes raw level values and it is easy to use. In this paper we will put range ratio color for each of R,G,and B. Therefore, we divide each image into multiple pixels and apply the range ratio color condition for each pixel. Then we count the number of the pixels that achieved our condition. If the number of pixels grater than zero, then the frame is classified as a bleeding type. Otherwise, it is a non-bleeding. Our experimental results show that this method could achieve a very high accuracy in detecting bleeding images for the different parts of the small intestinal\n    ",
        "submission_date": "2010-05-29T00:00:00",
        "last_modified_date": "2010-05-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1006.1187",
        "title": "Biometric Authentication using Nonparametric Methods",
        "authors": [
            "S. V. Sheela",
            "K. R. Radhika"
        ],
        "abstract": "The physiological and behavioral trait is employed to develop biometric authentication systems. The proposed work deals with the authentication of iris and signature based on minimum variance criteria. The iris patterns are preprocessed based on area of the connected components. The segmented image used for authentication consists of the region with large variations in the gray level values. The image region is split into quadtree components. The components with minimum variance are determined from the training samples. Hu moments are applied on the components. The summation of moment values corresponding to minimum variance components are provided as input vector to k-means and fuzzy kmeans classifiers. The best performance was obtained for MMU database consisting of 45 subjects. The number of subjects with zero False Rejection Rate [FRR] was 44 and number of subjects with zero False Acceptance Rate [FAR] was 45. This paper addresses the computational load reduction in off-line signature verification based on minimal features using k-means, fuzzy k-means, k-nn, fuzzy k-nn and novel average-max approaches. FRR of 8.13% and FAR of 10% was achieved using k-nn classifier. The signature is a biometric, where variations in a genuine case, is a natural expectation. In the genuine signature, certain parts of signature vary from one instance to another. The system aims to provide simple, fast and robust system using less number of features when compared to state of art works.\n    ",
        "submission_date": "2010-06-07T00:00:00",
        "last_modified_date": "2010-06-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1006.2368",
        "title": "L2-optimal image interpolation and its applications to medical imaging",
        "authors": [
            "Oleg Pianykh"
        ],
        "abstract": "Digital medical images are always displayed scaled to fit particular view. Interpolation is responsible for this scaling, and if not done properly, can significantly degrade diagnostic image quality. However, theoretically-optimal interpolation algorithms may also be the most time-consuming and impractical. We propose a new approach, adapted to the needs of digital medical imaging, to combine high interpolation speed and superior L2-optimal image quality.\n    ",
        "submission_date": "2010-06-11T00:00:00",
        "last_modified_date": "2010-06-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1006.2700",
        "title": "Image Segmentation Using Weak Shape Priors",
        "authors": [
            "Robert Sheng Xu",
            "Oleg Michailovich",
            "Magdy Salama"
        ],
        "abstract": "The problem of image segmentation is known to become particularly challenging in the case of partial occlusion of the object(s) of interest, background clutter, and the presence of strong noise. To overcome this problem, the present paper introduces a novel approach segmentation through the use of \"weak\" shape priors. Specifically, in the proposed method, an segmenting active contour is constrained to converge to a configuration at which its geometric parameters attain their empirical probability densities closely matching the corresponding model densities that are learned based on training samples. It is shown through numerical experiments that the proposed shape modeling can be regarded as \"weak\" in the sense that it minimally influences the segmentation, which is allowed to be dominated by data-related forces. On the other hand, the priors provide sufficient constraints to regularize the convergence of segmentation, while requiring substantially smaller training sets to yield less biased results as compared to the case of PCA-based regularization methods. The main advantages of the proposed technique over some existing alternatives is demonstrated in a series of experiments.\n    ",
        "submission_date": "2010-06-14T00:00:00",
        "last_modified_date": "2010-06-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1006.2734",
        "title": "Penalized K-Nearest-Neighbor-Graph Based Metrics for Clustering",
        "authors": [
            "Ariel E. Baya",
            "Pablo M. Granitto"
        ],
        "abstract": "A difficult problem in clustering is how to handle data with a manifold structure, i.e. data that is not shaped in the form of compact clouds of points, forming arbitrary shapes or paths embedded in a high-dimensional space. In this work we introduce the Penalized k-Nearest-Neighbor-Graph (PKNNG) based metric, a new tool for evaluating distances in such cases. The new metric can be used in combination with most clustering algorithms. The PKNNG metric is based on a two-step procedure: first it constructs the k-Nearest-Neighbor-Graph of the dataset of interest using a low k-value and then it adds edges with an exponentially penalized weight for connecting the sub-graphs produced by the first step. We discuss several possible schemes for connecting the different sub-graphs. We use three artificial datasets in four different embedding situations to evaluate the behavior of the new metric, including a comparison among different clustering methods. We also evaluate the new metric in a real world application, clustering the MNIST digits dataset. In all cases the PKNNG metric shows promising clustering results.\n    ",
        "submission_date": "2010-06-14T00:00:00",
        "last_modified_date": "2010-06-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1006.2804",
        "title": "An Effective Fingerprint Verification Technique",
        "authors": [
            "Minakshi Gogoi",
            "D K Bhattacharyya"
        ],
        "abstract": "This paper presents an effective method for fingerprint verification based on a data mining technique called minutiae clustering and a graph-theoretic approach to analyze the process of fingerprint comparison to give a feature space representation of minutiae and to produce a lower bound on the number of detectably distinct fingerprints. The method also proving the invariance of each individual fingerprint by using both the topological behavior of the minutiae graph and also using a distance measure called Hausdorff ",
        "submission_date": "2010-06-14T00:00:00",
        "last_modified_date": "2010-06-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1006.3056",
        "title": "Solving Inverse Problems with Piecewise Linear Estimators: From Gaussian Mixture Models to Structured Sparsity",
        "authors": [
            "Guoshen Yu",
            "Guillermo Sapiro",
            "St\u00e9phane Mallat"
        ],
        "abstract": "A general framework for solving image inverse problems is introduced in this paper. The approach is based on Gaussian mixture models, estimated via a computationally efficient MAP-EM algorithm. A dual mathematical interpretation of the proposed framework with structured sparse estimation is described, which shows that the resulting piecewise linear estimate stabilizes the estimation when compared to traditional sparse inverse problem techniques. This interpretation also suggests an effective dictionary motivated initialization for the MAP-EM algorithm. We demonstrate that in a number of image inverse problems, including inpainting, zooming, and deblurring, the same algorithm produces either equal, often significantly better, or very small margin worse results than the best published ones, at a lower computational cost.\n    ",
        "submission_date": "2010-06-15T00:00:00",
        "last_modified_date": "2010-06-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1006.3506",
        "title": "Action Recognition in Videos: from Motion Capture Labs to the Web",
        "authors": [
            "Ana Paula Brand\u00e3o Lopes",
            "Eduardo Alves do Valle Jr.",
            "Jussara Marques de Almeida",
            "Arnaldo Albuquerque de Ara\u00fajo"
        ],
        "abstract": "This paper presents a survey of human action recognition approaches based on visual data recorded from a single video camera. We propose an organizing framework which puts in evidence the evolution of the area, with techniques moving from heavily constrained motion capture scenarios towards more challenging, realistic, \"in the wild\" videos. The proposed organization is based on the representation used as input for the recognition task, emphasizing the hypothesis assumed and thus, the constraints imposed on the type of video that each technique is able to address. Expliciting the hypothesis and constraints makes the framework particularly useful to select a method, given an application. Another advantage of the proposed organization is that it allows categorizing newest approaches seamlessly with traditional ones, while providing an insightful perspective of the evolution of the action recognition task up to now. That perspective is the basis for the discussion in the end of the paper, where we also present the main open issues in the area.\n    ",
        "submission_date": "2010-06-17T00:00:00",
        "last_modified_date": "2010-06-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1006.3679",
        "title": "Segmentation of Natural Images by Texture and Boundary Compression",
        "authors": [
            "Hossein Mobahi",
            "Shankar R. Rao",
            "Allen Y. Yang",
            "Shankar S. Sastry",
            "Yi Ma"
        ],
        "abstract": "We present a novel algorithm for segmentation of natural images that harnesses the principle of minimum description length (MDL). Our method is based on observations that a homogeneously textured region of a natural image can be well modeled by a Gaussian distribution and the region boundary can be effectively coded by an adaptive chain code. The optimal segmentation of an image is the one that gives the shortest coding length for encoding all textures and boundaries in the image, and is obtained via an agglomerative clustering process applied to a hierarchy of decreasing window sizes as multi-scale texture features. The optimal segmentation also provides an accurate estimate of the overall coding length and hence the true entropy of the image. We test our algorithm on the publicly available Berkeley Segmentation Dataset. It achieves state-of-the-art segmentation results compared to other existing methods.\n    ",
        "submission_date": "2010-06-18T00:00:00",
        "last_modified_date": "2010-06-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1006.4175",
        "title": "Optimization of Weighted Curvature for Image Segmentation",
        "authors": [
            "Noha El-Zehiry",
            "Leo Grady"
        ],
        "abstract": "Minimization of boundary curvature is a classic regularization technique for image segmentation in the presence of noisy image data. Techniques for minimizing curvature have historically been derived from descent methods which could be trapped in a local minimum and therefore required a good initialization. Recently, combinatorial optimization techniques have been applied to the optimization of curvature which provide a solution that achieves nearly a global optimum. However, when applied to image segmentation these methods required a meaningful data term. Unfortunately, for many images, particularly medical images, it is difficult to find a meaningful data term. Therefore, we propose to remove the data term completely and instead weight the curvature locally, while still achieving a global optimum.\n    ",
        "submission_date": "2010-06-21T00:00:00",
        "last_modified_date": "2010-06-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1006.4588",
        "title": "Efficient Region-Based Image Querying",
        "authors": [
            "S. Sadek",
            "A. Al-Hamadi",
            "B. Michaelis",
            "U. Sayed"
        ],
        "abstract": "Retrieving images from large and varied repositories using visual contents has been one of major research items, but a challenging task in the image management community. In this paper we present an efficient approach for region-based image classification and retrieval using a fast multi-level neural network model. The advantages of this neural model in image classification and retrieval domain will be highlighted. The proposed approach accomplishes its goal in three main steps. First, with the help of a mean-shift based segmentation algorithm, significant regions of the image are isolated. Secondly, color and texture features of each region are extracted by using color moments and 2D wavelets decomposition technique. Thirdly the multi-level neural classifier is trained in order to classify each region in a given image into one of five predefined categories, i.e., \"Sky\", \"Building\", \"SandnRock\", \"Grass\" and \"Water\". Simulation results show that the proposed method is promising in terms of classification and retrieval accuracy results. These results compare favorably with the best published results obtained by other state-of-the-art image retrieval techniques.\n    ",
        "submission_date": "2010-06-23T00:00:00",
        "last_modified_date": "2010-06-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1006.4910",
        "title": "Kalman Filters and Homography: Utilizing the Matrix $A$",
        "authors": [
            "Burak Bayramli"
        ],
        "abstract": "Many problems in Computer Vision can be reduced to either working around a known transform, or given a model for the transform computing the inverse problem of the transform itself. We will look at two ways of working with the matrix $A$ and see how transforms are at the root of image processing and vision problems.\n    ",
        "submission_date": "2010-06-25T00:00:00",
        "last_modified_date": "2022-12-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1006.5902",
        "title": "Performance Comparison of SVM and ANN for Handwritten Devnagari Character Recognition",
        "authors": [
            "Sandhya Arora",
            "Debotosh Bhattacharjee",
            "Mita Nasipuri",
            "L. Malik",
            "M. Kundu",
            "D. K. Basu"
        ],
        "abstract": "Classification methods based on learning from examples have been widely applied to character recognition from the 1990s and have brought forth significant improvements of recognition accuracies. This class of methods includes statistical methods, artificial neural networks, support vector machines (SVM), multiple classifier combination, etc. In this paper, we discuss the characteristics of the some classification methods that have been successfully applied to handwritten Devnagari character recognition and results of SVM and ANNs classification method, applied on Handwritten Devnagari characters. After preprocessing the character image, we extracted shadow features, chain code histogram features, view based features and longest run features. These features are then fed to Neural classifier and in support vector machine for classification. In neural classifier, we explored three ways of combining decisions of four MLP's designed for four different features.\n    ",
        "submission_date": "2010-06-30T00:00:00",
        "last_modified_date": "2010-06-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1006.5908",
        "title": "Recognition of Non-Compound Handwritten Devnagari Characters using a Combination of MLP and Minimum Edit Distance",
        "authors": [
            "Sandhya Arora",
            "Debotosh Bhattacharjee",
            "Mita Nasipuri",
            "D. K. Basu",
            "M. Kundu"
        ],
        "abstract": "This paper deals with a new method for recognition of offline Handwritten non-compound Devnagari Characters in two stages. It uses two well known and established pattern recognition techniques: one using neural networks and the other one using minimum edit distance. Each of these techniques is applied on different sets of characters for recognition. In the first stage, two sets of features are computed and two classifiers are applied to get higher recognition accuracy. Two MLP's are used separately to recognize the characters. For one of the MLP's the characters are represented with their shadow features and for the other chain code histogram feature is used. The decision of both MLP's is combined using weighted majority scheme. Top three results produced by combined MLP's in the first stage are used to calculate the relative difference values. In the second stage, based on these relative differences character set is divided into two. First set consists of the characters with distinct shapes and second set consists of confused characters, which appear very similar in shapes. Characters of distinct shapes of first set are classified using MLP. Confused characters in second set are classified using minimum edit distance method. Method of minimum edit distance makes use of corner detected in a character image using modified Harris corner detection technique. Experiment on this method is carried out on a database of 7154 samples. The overall recognition is found to be 90.74%.\n    ",
        "submission_date": "2010-06-30T00:00:00",
        "last_modified_date": "2010-06-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1006.5911",
        "title": "Application of Statistical Features in Handwritten Devnagari Character Recognition",
        "authors": [
            "S. Arora",
            "Debotosh Bhattacharjee",
            "M. Nasipuri",
            "D.K. Basu",
            "M.Kundu"
        ],
        "abstract": "In this paper a scheme for offline Handwritten Devnagari Character Recognition is proposed, which uses different feature extraction methodologies and recognition algorithms. The proposed system assumes no constraints in writing style or size. First the character is preprocessed and features namely : Chain code histogram and moment invariant features are extracted and fed to Multilayer Perceptrons as a preliminary recognition step. Finally the results of both MLP's are combined using weighted majority scheme. The proposed system is tested on 1500 handwritten devnagari character database collected from different people. It is observed that the proposed system achieves recognition rates 98.03% for top 5 results and 89.46% for top 1 result.\n    ",
        "submission_date": "2010-06-30T00:00:00",
        "last_modified_date": "2010-06-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1006.5913",
        "title": "Multiple Classifier Combination for Off-line Handwritten Devnagari Character Recognition",
        "authors": [
            "Sandhya Arora",
            "Debotosh Bhattacharjee",
            "Mita Nasipuri",
            "Dipak Kumar Basu",
            "Mahantapas Kundu"
        ],
        "abstract": "This work presents the application of weighted majority voting technique for combination of classification decision obtained from three Multi_Layer Perceptron(MLP) based classifiers for Recognition of Handwritten Devnagari characters using three different feature sets. The features used are intersection, shadow feature and chain code histogram features. Shadow features are computed globally for character image while intersection features and chain code histogram features are computed by dividing the character image into different segments. On experimentation with a dataset of 4900 samples the overall recognition rate observed is 92.16% as we considered top five choices results. This method is compared with other recent methods for Handwritten Devnagari Character Recognition and it has been observed that this approach has better success rate than other methods.\n    ",
        "submission_date": "2010-06-30T00:00:00",
        "last_modified_date": "2010-06-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1006.5920",
        "title": "A Two Stage Classification Approach for Handwritten Devanagari Characters",
        "authors": [
            "Sandhya Arora",
            "Debotosh Bhattacharjee",
            "Mita Nasipuri",
            "Latesh Malik"
        ],
        "abstract": "The paper presents a two stage classification approach for handwritten devanagari characters The first stage is using structural properties like shirorekha, spine in character and second stage exploits some intersection features of characters which are fed to a feedforward neural network. Simple histogram based method does not work for finding shirorekha, vertical bar (Spine) in handwritten devnagari characters. So we designed a differential distance based technique to find a near straight line for shirorekha and spine. This approach has been tested for 50000 samples and we got 89.12% success\n    ",
        "submission_date": "2010-06-30T00:00:00",
        "last_modified_date": "2010-06-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1006.5924",
        "title": "A novel approach for handwritten Devnagari character recognition",
        "authors": [
            "Sandhya Arora",
            "Latesh Malik",
            "Debotosh Bhattacharjee",
            "Mita Nasipuri"
        ],
        "abstract": "In this paper a method for recognition of handwritten devanagari characters is described. Here, feature vector is constituted by accumulated directional gradient changes in different segments, number of intersections points for the character, type of spine present and type of shirorekha present in the character. One Multi-layer Perceptron with conjugate-gradient training is used to classify these feature vectors. This method is applied to a database with 1000 sample characters and the recognition rate obtained is 88.12%\n    ",
        "submission_date": "2010-06-30T00:00:00",
        "last_modified_date": "2010-06-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1006.5927",
        "title": "Classification Of Gradient Change Features Using MLP For Handwritten Character Recognition",
        "authors": [
            "Sandhya Arora",
            "Latesh Malik",
            "Debotosh Bhattacharjee",
            "Mita Nasipuri"
        ],
        "abstract": "A novel, generic scheme for off-line handwritten English alphabets character images is proposed. The advantage of the technique is that it can be applied in a generic manner to different applications and is expected to perform better in uncertain and noisy environments. The recognition scheme is using a multilayer perceptron(MLP) neural networks. The system was trained and tested on a database of 300 samples of handwritten characters. For improved generalization and to avoid overtraining, the whole available dataset has been divided into two subsets: training set and test set. We achieved 99.10% and 94.15% correct recognition rates on training and test sets respectively. The purposed scheme is robust with respect to various writing styles and size as well as presence of considerable noise.\n    ",
        "submission_date": "2010-06-30T00:00:00",
        "last_modified_date": "2010-06-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1006.5942",
        "title": "FPGA Based Assembling of Facial Components for Human Face Construction",
        "authors": [
            "Santanu Halder",
            "Debotosh Bhattacharjee",
            "Mita Nasipuri",
            "Dipak Kumar Basu",
            "Mahantapas Kundu"
        ],
        "abstract": "This paper aims at VLSI realization for generation of a new face from textual description. The FASY (FAce SYnthesis) System is a Face Database Retrieval and new Face generation System that is under development. One of its main features is the generation of the requested face when it is not found in the existing database. The new face generation system works in three steps - searching phase, assembling phase and tuning phase. In this paper the tuning phase using hardware description language and its implementation in a Field Programmable Gate Array (FPGA) device is presented.\n    ",
        "submission_date": "2010-06-30T00:00:00",
        "last_modified_date": "2010-06-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1006.5945",
        "title": "Fuzzy Classification of Facial Component Parameters",
        "authors": [
            "S. Halder",
            "Debotosh Bhattacharjee",
            "M. Nasipuri",
            "D. K. Basu",
            "M. Kundu"
        ],
        "abstract": "This paper presents a novel type-2 Fuzzy logic System to define the Shape of a facial component with the crisp output. This work is the part of our main research effort to design a system (called FASY) which offers a novel face construction approach based on the textual description and also extracts and analyzes the facial components from a face image by an efficient technique. The Fuzzy model, designed in this paper, takes crisp value of width and height of a facial component and produces the crisp value of Shape for different facial components. This method is designed using Matlab 6.5 and Visual Basic 6.0 and tested with the facial components extracted from 200 male and female face images of different ages from different face databases.\n    ",
        "submission_date": "2010-06-30T00:00:00",
        "last_modified_date": "2010-07-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1007.0085",
        "title": "Survey of Nearest Neighbor Techniques",
        "authors": [
            "Nitin Bhatia",
            "Vandana"
        ],
        "abstract": "The nearest neighbor (NN) technique is very simple, highly efficient and effective in the field of pattern recognition, text categorization, object recognition etc. Its simplicity is its main advantage, but the disadvantages can't be ignored even. The memory requirement and computation complexity also matter. Many techniques are developed to overcome these limitations. NN techniques are broadly classified into structure less and structure based techniques. In this paper, we present the survey of such techniques. Weighted kNN, Model based kNN, Condensed NN, Reduced NN, Generalized NN are structure less techniques whereas k-d tree, ball tree, Principal Axis Tree, Nearest Feature Line, Tunable NN, Orthogonal Search Tree are structure based algorithms developed on the basis of kNN. The structure less method overcome memory limitation and structure based techniques reduce the computational complexity.\n    ",
        "submission_date": "2010-07-01T00:00:00",
        "last_modified_date": "2010-07-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1007.0313",
        "title": "Repairing People Trajectories Based on Point Clustering",
        "authors": [
            "Duc Phu Chau",
            "Francois Bremond",
            "Etienne Corvee",
            "Monique Thonnat"
        ],
        "abstract": "This paper presents a method for improving any object tracking algorithm based on machine learning. During the training phase, important trajectory features are extracted which are then used to calculate a confidence value of trajectory. The positions at which objects are usually lost and found are clustered in order to construct the set of 'lost zones' and 'found zones' in the scene. Using these zones, we construct a triplet set of zones i.e. three zones: In/Out zone (zone where an object can enter or exit the scene), 'lost zone' and 'found zone'. Thanks to these triplets, during the testing phase, we can repair the erroneous trajectories according to which triplet they are most likely to belong to. The advantage of our approach over the existing state of the art approaches is that (i) this method does not depend on a predefined contextual scene, (ii) we exploit the semantic of the scene and (iii) we have proposed a method to filter out noisy trajectories based on their confidence value.\n    ",
        "submission_date": "2010-07-02T00:00:00",
        "last_modified_date": "2010-07-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1007.0547",
        "title": "A Fast Decision Technique for Hierarchical Hough Transform for Line Detection",
        "authors": [
            "Chandan Singh",
            "Nitin Bhatia"
        ],
        "abstract": "Many techniques have been proposed to speedup the performance of classic Hough Transform. These techniques are primarily based on converting the voting procedure to a hierarchy based voting method. These methods use approximate decision-making process. In this paper, we propose a fast decision making process that enhances the speed and reduces the space requirements. Experimental results demonstrate that the proposed algorithm is much faster than a similar Fast Hough Transform.\n    ",
        "submission_date": "2010-07-04T00:00:00",
        "last_modified_date": "2010-07-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1007.0618",
        "title": "Face Synthesis (FASY) System for Determining the Characteristics of a Face Image",
        "authors": [
            "Santanu Halder",
            "Debotosh Bhattacharjee",
            "Mita Nasipuri",
            "Dipak Kumar Basu",
            "Mahantapas Kundu"
        ],
        "abstract": "This paper aims at determining the characteristics of a face image by extracting its components. The FASY (FAce SYnthesis) System is a Face Database Retrieval and new Face generation System that is under development. One of its main features is the generation of the requested face when it is not found in the existing database, which allows a continuous growing of the database also. To generate the new face image, we need to store the face components in the database. So we have designed a new technique to extract the face components by a sophisticated method. After extraction of the facial feature points we have analyzed the components to determine their characteristics. After extraction and analysis we have stored the components along with their characteristics into the face database for later use during the face construction.\n    ",
        "submission_date": "2010-07-05T00:00:00",
        "last_modified_date": "2010-07-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1007.0620",
        "title": "Quotient Based Multiresolution Image Fusion of Thermal and Visual Images Using Daubechies Wavelet Transform for Human Face Recognition",
        "authors": [
            "Mrinal Kanti Bhowmik",
            "Debotosh Bhattacharjee",
            "Mita Nasipuri",
            "Dipak Kumar Basu",
            "Mahantapas Kundu"
        ],
        "abstract": "This paper investigates the multiresolution level-1 and level-2 Quotient based Fusion of thermal and visual images. In the proposed system, the method-1 namely \"Decompose then Quotient Fuse Level-1\" and the method-2 namely \"Decompose-Reconstruct then Quotient Fuse Level-2\" both work on wavelet transformations of the visual and thermal face images. The wavelet transform is well-suited to manage different image resolution and allows the image decomposition in different kinds of coefficients, while preserving the image information without any loss. This approach is based on a definition of an illumination invariant signature image which enables an analytic generation of the image space with varying illumination. The quotient fused images are passed through Principal Component Analysis (PCA) for dimension reduction and then those images are classified using a multi-layer perceptron (MLP). The performances of both the methods have been evaluated using OTCBVS and IRIS databases. All the different classes have been tested separately, among them the maximum recognition result is 100%.\n    ",
        "submission_date": "2010-07-05T00:00:00",
        "last_modified_date": "2010-07-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1007.0621",
        "title": "Fusion of Daubechies Wavelet Coefficients for Human Face Recognition",
        "authors": [
            "Mrinal Kanti Bhowmik",
            "Debotosh Bhattacharjee",
            "Mita Nasipuri",
            "Dipak Kumar Basu",
            "Mahantapas Kundu"
        ],
        "abstract": "In this paper fusion of visual and thermal images in wavelet transformed domain has been presented. Here, Daubechies wavelet transform, called as D2, coefficients from visual and corresponding coefficients computed in the same manner from thermal images are combined to get fused coefficients. After decomposition up to fifth level (Level 5) fusion of coefficients is done. Inverse Daubechies wavelet transform of those coefficients gives us fused face images. The main advantage of using wavelet transform is that it is well-suited to manage different image resolution and allows the image decomposition in different kinds of coefficients, while preserving the image information. Fused images thus found are passed through Principal Component Analysis (PCA) for reduction of dimensions and then those reduced fused images are classified using a multi-layer perceptron. For experiments IRIS Thermal/Visual Face Database was used. Experimental results show that the performance of the approach presented here achieves maximum success rate of 100% in many cases.\n    ",
        "submission_date": "2010-07-05T00:00:00",
        "last_modified_date": "2010-07-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1007.0626",
        "title": "Fusion of Wavelet Coefficients from Visual and Thermal Face Images for Human Face Recognition - A Comparative Study",
        "authors": [
            "M. K. Bhowmik",
            "Debotosh Bhattacharjee",
            "M. Nasipuri",
            "D. K. Basu",
            "M. Kundu"
        ],
        "abstract": "In this paper we present a comparative study on fusion of visual and thermal images using different wavelet transformations. Here, coefficients of discrete wavelet transforms from both visual and thermal images are computed separately and combined. Next, inverse discrete wavelet transformation is taken in order to obtain fused face image. Both Haar and Daubechies (db2) wavelet transforms have been used to compare recognition results. For experiments IRIS Thermal/Visual Face Database was used. Experimental results using Haar and Daubechies wavelets show that the performance of the approach presented here achieves maximum success rate of 100% in many cases.\n    ",
        "submission_date": "2010-07-05T00:00:00",
        "last_modified_date": "2010-07-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1007.0627",
        "title": "A Parallel Framework for Multilayer Perceptron for Human Face Recognition",
        "authors": [
            "M.K. Bhowmik",
            "Debotosh Bhattacharjee",
            "M. Nasipuri",
            "D. K. Basu",
            "M. Kundu"
        ],
        "abstract": "Artificial neural networks have already shown their success in face recognition and similar complex pattern recognition tasks. However, a major disadvantage of the technique is that it is extremely slow during training for larger classes and hence not suitable for real-time complex problems such as pattern recognition. This is an attempt to develop a parallel framework for the training algorithm of a perceptron. In this paper, two general architectures for a Multilayer Perceptron (MLP) have been demonstrated. The first architecture is All-Class-in-One-Network (ACON) where all the classes are placed in a single network and the second one is One-Class-in-One-Network (OCON) where an individual single network is responsible for each and every class. Capabilities of these two architectures were compared and verified in solving human face recognition, which is a complex pattern recognition task where several factors affect the recognition performance like pose variations, facial expression changes, occlusions, and most importantly illumination changes. Both the structures were implemented and tested for face recognition purpose and experimental results show that the OCON structure performs better than the generally used ACON ones in term of training convergence speed of the network. Unlike the conventional sequential approach of training the neural networks, the OCON technique may be implemented by training all the classes of the face images simultaneously.\n    ",
        "submission_date": "2010-07-05T00:00:00",
        "last_modified_date": "2010-07-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1007.0628",
        "title": "Image Pixel Fusion for Human Face Recognition",
        "authors": [
            "Mrinal Kanti Bhowmik",
            "Debotosh Bhattacharjee",
            "Mita Nasipuri",
            "Dipak Kumar Basu",
            "Mahantapas Kundu"
        ],
        "abstract": "In this paper we present a technique for fusion of optical and thermal face images based on image pixel fusion approach. Out of several factors, which affect face recognition performance in case of visual images, illumination changes are a significant factor that needs to be addressed. Thermal images are better in handling illumination conditions but not very consistent in capturing texture details of the faces. Other factors like sunglasses, beard, moustache etc also play active role in adding complicacies to the recognition process. Fusion of thermal and visual images is a solution to overcome the drawbacks present in the individual thermal and visual face images. Here fused images are projected into an eigenspace and the projected images are classified using a radial basis function (RBF) neural network and also by a multi-layer perceptron (MLP). In the experiments Object Tracking and Classification Beyond Visible Spectrum (OTCBVS) database benchmark for thermal and visual face images have been used. Comparison of experimental results show that the proposed approach performs significantly well in recognizing face images with a success rate of 96% and 95.07% for RBF Neural Network and MLP respectively.\n    ",
        "submission_date": "2010-07-05T00:00:00",
        "last_modified_date": "2010-07-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1007.0631",
        "title": "Classification of Fused Images using Radial Basis Function Neural Network for Human Face Recognition",
        "authors": [
            "M.K. Bhowmik",
            "Debotosh Bhattacharjee",
            "M. Nasipuri",
            "D. K. Basu",
            "M. Kundu"
        ],
        "abstract": "Here an efficient fusion technique for automatic face recognition has been presented. Fusion of visual and thermal images has been done to take the advantages of thermal images as well as visual images. By employing fusion a new image can be obtained, which provides the most detailed, reliable, and discriminating information. In this method fused images are generated using visual and thermal face images in the first step. In the second step, fused images are projected into eigenspace and finally classified using a radial basis function neural network. In the experiments Object Tracking and Classification Beyond Visible Spectrum (OTCBVS) database benchmark for thermal and visual face images have been used. Experimental results show that the proposed approach performs well in recognizing unknown individuals with a maximum success rate of 96%.\n    ",
        "submission_date": "2010-07-05T00:00:00",
        "last_modified_date": "2010-07-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1007.0633",
        "title": "Classification of fused face images using multilayer perceptron neural network",
        "authors": [
            "Debotosh Bhattacharjee",
            "Mrinal Kanti Bhowmik",
            "Mita Nasipuri",
            "Dipak Kumar Basu",
            "Mahantapas Kundu"
        ],
        "abstract": "This paper presents a concept of image pixel fusion of visual and thermal faces, which can significantly improve the overall performance of a face recognition system. Several factors affect face recognition performance including pose variations, facial expression changes, occlusions, and most importantly illumination changes. So, image pixel fusion of thermal and visual images is a solution to overcome the drawbacks present in the individual thermal and visual face images. Fused images are projected into eigenspace and finally classified using a multi-layer perceptron. In the experiments we have used Object Tracking and Classification Beyond Visible Spectrum (OTCBVS) database benchmark thermal and visual face images. Experimental results show that the proposed approach significantly improves the verification and identification performance and the success rate is 95.07%. The main objective of employing fusion is to produce a fused image that provides the most detailed and reliable information. Fusion of multiple images together produces a more efficient representation of the image.\n    ",
        "submission_date": "2010-07-05T00:00:00",
        "last_modified_date": "2010-07-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1007.0636",
        "title": "Classification of Log-Polar-Visual Eigenfaces using Multilayer Perceptron",
        "authors": [
            "Mrinal Kanti Bhowmik",
            "Debotosh Bhattacharjee",
            "Mita Nasipuri",
            "Mahantapas Kundu",
            "Dipak Kumar Basu"
        ],
        "abstract": "In this paper we present a simple novel approach to tackle the challenges of scaling and rotation of face images in face recognition. The proposed approach registers the training and testing visual face images by log-polar transformation, which is capable to handle complicacies introduced by scaling and rotation. Log-polar images are projected into eigenspace and finally classified using an improved multi-layer perceptron. In the experiments we have used ORL face database and Object Tracking and Classification Beyond Visible Spectrum (OTCBVS) database for visual face images. Experimental results show that the proposed approach significantly improves the recognition performances from visual to log-polar-visual face images. In case of ORL face database, recognition rate for visual face images is 89.5% and that is increased to 97.5% for log-polar-visual face images whereas for OTCBVS face database recognition rate for visual images is 87.84% and 96.36% for log-polar-visual face images.\n    ",
        "submission_date": "2010-07-05T00:00:00",
        "last_modified_date": "2010-07-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1007.0638",
        "title": "Human Face Recognition using Line Features",
        "authors": [
            "Mrinal Kanti Bhowmik",
            "Debotosh Bhattacharjee",
            "Mita Nasipuri",
            "Dipak Kumar Basu",
            "Mahantapas Kundu"
        ],
        "abstract": "In this work we investigate a novel approach to handle the challenges of face recognition, which includes rotation, scale, occlusion, illumination etc. Here, we have used thermal face images as those are capable to minimize the affect of illumination changes and occlusion due to moustache, beards, adornments etc. The proposed approach registers the training and testing thermal face images in polar coordinate, which is capable to handle complicacies introduced by scaling and rotation. Line features are extracted from thermal polar images and feature vectors are constructed using these line. Feature vectors thus obtained passes through principal component analysis (PCA) for the dimensionality reduction of feature vectors. Finally, the images projected into eigenspace are classified using a multi-layer perceptron. In the experiments we have used Object Tracking and Classification Beyond Visible Spectrum (OTCBVS) database. Experimental results show that the proposed approach significantly improves the verification and identification performance and the success rate is 99.25%.\n    ",
        "submission_date": "2010-07-05T00:00:00",
        "last_modified_date": "2010-07-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1007.1016",
        "title": "Bilateral filters: what they can and cannot do",
        "authors": [
            "Oleg S. Pianykh"
        ],
        "abstract": "Nonlinear bilateral filters (BF) deliver a fine blend of computational simplicity and blur-free denoising. However, little is known about their nature, noise-suppressing properties, and optimal choices of filter parameters. Our study is meant to fill this gap-explaining the underlying mechanism of bilateral filtering and providing the methodology for optimal filter selection. Practical application to CT image denoising is discussed to illustrate our results.\n    ",
        "submission_date": "2010-07-06T00:00:00",
        "last_modified_date": "2010-07-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1007.1048",
        "title": "Registration of Brain Images using Fast Walsh Hadamard Transform",
        "authors": [
            "D.Sasikala",
            "R.Neelaveni"
        ],
        "abstract": "A lot of image registration techniques have been developed with great significance for data analysis in medicine, astrophotography, satellite imaging and few other areas. This work proposes a method for medical image registration using Fast Walsh Hadamard transform. This algorithm registers images of the same or different modalities. Each image bit is lengthened in terms of Fast Walsh Hadamard basis functions. Each basis function is a notion of determining various aspects of local structure, e.g., horizontal edge, corner, etc. These coefficients are normalized and used as numerals in a chosen number system which allows one to form a unique number for each type of local structure. The experimental results show that Fast Walsh Hadamard transform accomplished better results than the conventional Walsh transform in the time domain. Also Fast Walsh Hadamard transform is more reliable in medical image registration consuming less time.\n    ",
        "submission_date": "2010-07-07T00:00:00",
        "last_modified_date": "2010-07-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1007.1398",
        "title": "Multi-environment model estimation for motility analysis of Caenorhabditis Elegans",
        "authors": [
            "Raphael Sznitman",
            "Manaswi Gupta",
            "Gregory D. Hager",
            "Paulo E. Arratia",
            "Josue Sznitman"
        ],
        "abstract": "The nematode Caenorhabditis elegans is a well-known model organism used to investigate fundamental questions in biology. Motility assays of this small roundworm are designed to study the relationships between genes and behavior. Commonly, motility analysis is used to classify nematode movements and characterize them quantitatively. Over the past years, C. elegans' motility has been studied across a wide range of environments, including crawling on substrates, swimming in fluids, and locomoting through microfluidic substrates. However, each environment often requires customized image processing tools relying on heuristic parameter tuning. In the present study, we propose a novel Multi-Environment Model Estimation (MEME) framework for automated image segmentation that is versatile across various environments. The MEME platform is constructed around the concept of Mixture of Gaussian (MOG) models, where statistical models for both the background environment and the nematode appearance are explicitly learned and used to accurately segment a target nematode. Our method is designed to simplify the burden often imposed on users; here, only a single image which includes a nematode in its environment must be provided for model learning. In addition, our platform enables the extraction of nematode `skeletons' for straightforward motility quantification. We test our algorithm on various locomotive environments and compare performances with an intensity-based thresholding method. Overall, MEME outperforms the threshold-based approach for the overwhelming majority of cases examined. Ultimately, MEME provides researchers with an attractive platform for C. elegans' segmentation and `skeletonizing' across a wide range of motility assays.\n    ",
        "submission_date": "2010-07-08T00:00:00",
        "last_modified_date": "2010-07-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1007.1432",
        "title": "Improved RANSAC performance using simple, iterative minimal-set solvers",
        "authors": [
            "Edward Rosten",
            "Gerhard Reitmayr",
            "Tom Drummond"
        ],
        "abstract": "RANSAC is a popular technique for estimating model parameters in the presence of outliers. The best speed is achieved when the minimum possible number of points is used to estimate hypotheses for the model. Many useful problems can be represented using polynomial constraints (for instance, the determinant of a fundamental matrix must be zero) and so have a number of solutions which are consistent with a minimal set. A considerable amount of effort has been expended on finding the constraints of such problems, and these often require the solution of systems of polynomial equations. We show that better performance can be achieved by using a simple optimization based approach on minimal sets. For a given minimal set, the optimization approach is not guaranteed to converge to the correct solution. However, when used within RANSAC the greater speed and numerical stability results in better performance overall, and much simpler algorithms. We also show that by selecting more than the minimal number of points and using robust optimization can yield better results for very noisy by reducing the number of trials required. The increased speed of our method demonstrated with experiments on essential matrix estimation.\n    ",
        "submission_date": "2010-07-08T00:00:00",
        "last_modified_date": "2010-07-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1007.1708",
        "title": "A Study on the Effectiveness of Different Patch Size and Shape for Eyes and Mouth Detection",
        "authors": [
            "Lim Huey Charn",
            "Liyana Nuraini Rasid",
            "Shahrel A. Suandi"
        ],
        "abstract": "Template matching is one of the simplest methods used for eyes and mouth detection. However, it can be modified and extended to become a powerful tool. Since the patch itself plays a significant role in optimizing detection performance, a study on the influence of patch size and shape is carried out. The optimum patch size and shape is determined using the proposed method. Usually, template matching is also combined with other methods in order to improve detection accuracy. Thus, in this paper, the effectiveness of two image processing methods i.e. grayscale and Haar wavelet transform, when used with template matching are analyzed.\n    ",
        "submission_date": "2010-07-10T00:00:00",
        "last_modified_date": "2010-07-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1007.2442",
        "title": "Neural Network Based Reconstruction of a 3D Object from a 2D Wireframe",
        "authors": [
            "Kyle Johnson",
            "Clayton Chang",
            "Hod Lipson"
        ],
        "abstract": "We propose a new approach for constructing a 3D representation from a 2D wireframe drawing. A drawing is simply a parallel projection of a 3D object onto a 2D surface; humans are able to recreate mental 3D models from 2D representations very easily, yet the process is very difficult to emulate computationally. We hypothesize that our ability to perform this construction relies on the angles in the 2D scene, among other geometric properties. Being able to reproduce this reconstruction process automatically would allow for efficient and robust 3D sketch interfaces. Our research focuses on the relationship between 2D geometry observable in the sketch and 3D geometry derived from a potential 3D construction. We present a fully automated system that constructs 3D representations from 2D wireframes using a neural network in conjunction with a genetic search algorithm.\n    ",
        "submission_date": "2010-07-14T00:00:00",
        "last_modified_date": "2010-07-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1007.2958",
        "title": "A Machine Learning Approach to Recovery of Scene Geometry from Images",
        "authors": [
            "Hoang Trinh"
        ],
        "abstract": "Recovering the 3D structure of the scene from images yields useful information for tasks such as shape and scene recognition, object detection, or motion planning and object grasping in robotics. In this thesis, we introduce a general machine learning approach called unsupervised CRF learning based on maximizing the conditional likelihood. We apply our approach to computer vision systems that recover the 3-D scene geometry from images. We focus on recovering 3D geometry from single images, stereo pairs and video sequences. Building these systems requires algorithms for doing inference as well as learning the parameters of conditional Markov random fields (MRF). Our system is trained unsupervisedly without using ground-truth labeled data. We employ a slanted-plane stereo vision model in which we use a fixed over-segmentation to segment the left image into coherent regions called superpixels, then assign a disparity plane for each superpixel. Plane parameters are estimated by solving an MRF labelling problem, through minimizing an energy fuction. We demonstrate the use of our unsupervised CRF learning algorithm for a parameterized slanted-plane stereo vision model involving shape from texture cues. Our stereo model with texture cues, only by unsupervised training, outperforms the results in related work on the same stereo dataset. In this thesis, we also formulate structure and motion estimation as an energy minimization problem, in which the model is an extension of our slanted-plane stereo vision model that also handles surface velocity. Velocity estimation is achieved by solving an MRF labeling problem using Loopy BP. Performance analysis is done using our novel evaluation metrics based on the notion of view prediction error. Experiments on road-driving stereo sequences show encouraging results.\n    ",
        "submission_date": "2010-07-17T00:00:00",
        "last_modified_date": "2010-07-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1007.3753",
        "title": "Fast L1-Minimization Algorithms For Robust Face Recognition",
        "authors": [
            "Allen Y. Yang",
            "Zihan Zhou",
            "Arvind Ganesh",
            "S. Shankar Sastry",
            "Yi Ma"
        ],
        "abstract": "L1-minimization refers to finding the minimum L1-norm solution to an underdetermined linear system b=Ax. Under certain conditions as described in compressive sensing theory, the minimum L1-norm solution is also the sparsest solution. In this paper, our study addresses the speed and scalability of its algorithms. In particular, we focus on the numerical implementation of a sparsity-based classification framework in robust face recognition, where sparse representation is sought to recover human identities from very high-dimensional facial images that may be corrupted by illumination, facial disguise, and pose variation. Although the underlying numerical problem is a linear program, traditional algorithms are known to suffer poor scalability for large-scale applications. We investigate a new solution based on a classical convex optimization framework, known as Augmented Lagrangian Methods (ALM). The new convex solvers provide a viable solution to real-world, time-critical applications such as face recognition. We conduct extensive experiments to validate and compare the performance of the ALM algorithms against several popular L1-minimization solvers, including interior-point method, Homotopy, FISTA, SESOP-PCD, approximate message passing (AMP) and TFOCS. To aid peer evaluation, the code for all the algorithms has been made publicly available.\n    ",
        "submission_date": "2010-07-21T00:00:00",
        "last_modified_date": "2012-08-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1007.3772",
        "title": "Video Event Recognition for Surveillance Applications (VERSA)",
        "authors": [
            "Stephen O'Hara"
        ],
        "abstract": "VERSA provides a general-purpose framework for defining and recognizing events in live or recorded surveillance video streams. The approach for event recognition in VERSA is using a declarative logic language to define the spatial and temporal relationships that characterize a given event or activity. Doing so requires the definition of certain fundamental spatial and temporal relationships and a high-level syntax for specifying frame templates and query parameters. Although the handling of uncertainty in the current VERSA implementation is simplistic, the language and architecture is amenable to extending using Fuzzy Logic or similar approaches. VERSA's high-level architecture is designed to work in XML-based, services- oriented environments. VERSA can be thought of as subscribing to the XML annotations streamed by a lower-level video analytics service that provides basic entity detection, labeling, and tracking. One or many VERSA Event Monitors could thus analyze video streams and provide alerts when certain events are detected.\n    ",
        "submission_date": "2010-07-21T00:00:00",
        "last_modified_date": "2010-07-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1007.3881",
        "title": "Orthogonal multifilters image processing of astronomical images from scanned photographic plates",
        "authors": [
            "Vasil Kolev"
        ],
        "abstract": "In this paper orthogonal multifilters for astronomical image processing are presented. We obtained new orthogonal multifilters based on the orthogonal wavelet of Haar and Daubechies. Recently, multiwavelets have been introduced as a more powerful multiscale analysis tool. It adds several degrees of freedom in multifilter design and makes it possible to have several useful properties such as symmetry, orthogonality, short support, and a higher number of vanishing moments simultaneously. Multifilter decomposition of scanned photographic plates with astronomical images is made.\n    ",
        "submission_date": "2010-07-22T00:00:00",
        "last_modified_date": "2021-08-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1007.3926",
        "title": "Ear Identification by Fusion of Segmented Slice Regions using Invariant Features: An Experimental Manifold with Dual Fusion Approach",
        "authors": [
            "Dakshina Ranjan Kisku",
            "Phalguni Gupta",
            "Jamuna Kanta Sing"
        ],
        "abstract": "This paper proposes a robust ear identification system which is developed by fusing SIFT features of color segmented slice regions of an ear. The proposed ear identification method makes use of Gaussian mixture model (GMM) to build ear model with mixture of Gaussian using vector quantization algorithm and K-L divergence is applied to the GMM framework for recording the color similarity in the specified ranges by comparing color similarity between a pair of reference ear and probe ear. SIFT features are then detected and extracted from each color slice region as a part of invariant feature extraction. The extracted keypoints are then fused separately by the two fusion approaches, namely concatenation and the Dempster-Shafer theory. Finally, the fusion approaches generate two independent augmented feature vectors which are used for identification of individuals separately. The proposed identification technique is tested on IIT Kanpur ear database of 400 individuals and is found to achieve 98.25% accuracy for identification while top 5 matched criteria is set for each subject.\n    ",
        "submission_date": "2010-07-21T00:00:00",
        "last_modified_date": "2010-07-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1007.4531",
        "title": "Competitive Analysis of Minimum-Cut Maximum Flow Algorithms in Vision Problems",
        "authors": [
            "Barak Fishbain",
            "Dorit S. Hochbaum",
            "Stefan Mueller"
        ],
        "abstract": "Rapid advances in image acquisition and storage technology underline the need for algorithms that are capable of solving large scale image processing and computer-vision problems. The minimum cut problem plays an important role in processing many of these imaging problems such as, image and video segmentation, stereo vision, multi-view reconstruction and surface fitting. While several min-cut/max-flow algorithms can be found in the literature, their performance in practice has been studied primarily outside the scope of computer vision. We present here the results of a comprehensive computational study, in terms of execution times and memory utilization, of four recently published algorithms, which optimally solve the {\\em s-t} cut and maximum flow problems: (i) Goldberg's and Tarjan's {\\em Push-Relabel}; (ii) Hochbaum's {\\em pseudoflow}; (iii) Boykov's and Kolmogorov's {\\em augmenting paths}; and (iv) Goldberg's {\\em partial augment-relabel}. Our results demonstrate that the {\\em Hochbaum's pseudoflow} algorithm, is faster and utilizes less memory than the other algorithms on all problem instances investigated.\n    ",
        "submission_date": "2010-07-26T00:00:00",
        "last_modified_date": "2010-10-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1007.5129",
        "title": "An Efficient Automatic Mass Classification Method In Digitized Mammograms Using Artificial Neural Network",
        "authors": [
            "Mohammed J. Islam",
            "Majid Ahmadi",
            "Maher A. Sid-Ahmed"
        ],
        "abstract": "In this paper we present an efficient computer aided mass classification method in digitized mammograms using Artificial Neural Network (ANN), which performs benign-malignant classification on region of interest (ROI) that contains mass. One of the major mammographic characteristics for mass classification is texture. ANN exploits this important factor to classify the mass into benign or malignant. The statistical textural features used in characterizing the masses are mean, standard deviation, entropy, skewness, kurtosis and uniformity. The main aim of the method is to increase the effectiveness and efficiency of the classification process in an objective manner to reduce the numbers of false-positive of malignancies. Three layers artificial neural network (ANN) with seven features was proposed for classifying the marked regions into benign and malignant and 90.91% sensitivity and 83.87% specificity is achieved that is very much promising compare to the radiologist's sensitivity 75%.\n    ",
        "submission_date": "2010-07-29T00:00:00",
        "last_modified_date": "2010-07-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1008.0502",
        "title": "Fully automatic extraction of salient objects from videos in near real-time",
        "authors": [
            "Akamine Kazuma",
            "Ken Fukuchi",
            "Akisato Kimura",
            "Shigeru Takagi"
        ],
        "abstract": "Automatic video segmentation plays an important role in a wide range of computer vision and image processing applications. Recently, various methods have been proposed for this purpose. The problem is that most of these methods are far from real-time processing even for low-resolution videos due to the complex procedures. To this end, we propose a new and quite fast method for automatic video segmentation with the help of 1) efficient optimization of Markov random fields with polynomial time of number of pixels by introducing graph cuts, 2) automatic, computationally efficient but stable derivation of segmentation priors using visual saliency and sequential update mechanism, and 3) an implementation strategy in the principle of stream processing with graphics processor units (GPUs). Test results indicates that our method extracts appropriate regions from videos as precisely as and much faster than previous semi-automatic methods even though any supervisions have not been incorporated.\n    ",
        "submission_date": "2010-08-03T00:00:00",
        "last_modified_date": "2010-08-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1008.0548",
        "title": "Image sequence interpolation using optimal control",
        "authors": [
            "Kanglin Chen",
            "Dirk A. Lorenz"
        ],
        "abstract": "The problem of the generation of an intermediate image between two given images in an image sequence is considered. The problem is formulated as an optimal control problem governed by a transport equation. This approach bears similarities with the Horn \\& Schunck method for optical flow calculation but in fact the model is quite different. The images are modelled in $BV$ and an analysis of solutions of transport equations with values in $BV$ is included. Moreover, the existence of optimal controls is proven and necessary conditions are derived. Finally, two algorithms are given and numerical results are compared with existing methods. The new method is competitive with state-of-the-art methods and even outperforms several existing methods.\n    ",
        "submission_date": "2010-08-03T00:00:00",
        "last_modified_date": "2010-08-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1008.1150",
        "title": "Modeling the growth of fingerprints improves matching for adolescents",
        "authors": [
            "Carsten Gottschlich",
            "Thomas Hotz",
            "Robert Lorenz",
            "Stefanie Bernhardt",
            "Michael Hantschel",
            "Axel Munk"
        ],
        "abstract": "We study the effect of growth on the fingerprints of adolescents, based on which we suggest a simple method to adjust for growth when trying to recover a juvenile's fingerprint in a database years later. Based on longitudinal data sets in juveniles' criminal records, we show that growth essentially leads to an isotropic rescaling, so that we can use the strong correlation between growth in stature and limbs to model the growth of fingerprints proportional to stature growth as documented in growth charts. The proposed rescaling leads to a 72% reduction of the distances between corresponding minutiae for the data set analyzed. These findings were corroborated by several verification tests. In an identification test on a database containing 3.25 million right index fingers at the Federal Criminal Police Office of Germany, the identification error rate of 20.8% was reduced to 2.1% by rescaling. The presented method is of striking simplicity and can easily be integrated into existing automated fingerprint identification systems.\n    ",
        "submission_date": "2010-08-06T00:00:00",
        "last_modified_date": "2010-08-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1008.1695",
        "title": "Biometric Authentication using Nonparametric Methods",
        "authors": [
            "S. V. Sheela",
            "K. R. Radhika"
        ],
        "abstract": "The physiological and behavioral trait is employed to develop biometric authentication systems. The proposed work deals with the authentication of iris and signature based on minimum variance criteria. The iris patterns are preprocessed based on area of the connected components. The segmented image used for authentication consists of the region with large variations in the gray level values. The image region is split into quadtree components. The components with minimum variance are determined from the training samples. Hu moments are applied on the components. The summation of moment values corresponding to minimum variance components are provided as input vector to k-means and fuzzy k-means classifiers. The best performance was obtained for MMU database consisting of 45 subjects. The number of subjects with zero False Rejection Rate [FRR] was 44 and number of subjects with zero False Acceptance Rate [FAR] was 45. This paper addresses the computational load reduction in off-line signature verification based on minimal features using k-means, fuzzy k-means, k-nn, fuzzy k-nn and novel average-max approaches. FRR of 8.13% and FAR of 10% was achieved using k-nn classifier. The signature is a biometric, where variations in a genuine case, is a natural expectation. In the genuine signature, certain parts of signature vary from one instance to another. The system aims to provide simple, fast and robust system using less number of features when compared to state of art works.\n    ",
        "submission_date": "2010-08-10T00:00:00",
        "last_modified_date": "2010-08-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1008.2579",
        "title": "Homotopy Perturbation Method for Image Restoration and Denoising",
        "authors": [
            "Keyvan Yahya",
            "Jafar Biazar",
            "Hossein Azari",
            "Pouyan Rafiei Fard"
        ],
        "abstract": "The famous Perona-Malik (P-M) equation which was at first introduced for image restoration has been solved via various numerical methods. In this paper we will solve it for the first time via applying a new numerical method called Homotopy Perturbation Method (HMP) and the correspondent approximated solutions will be obtained for the P-M equation with regards to relevant error analysis. Through implementation of our algorithm we will access some effective results which are deserved to be considered as worthy as the other solutions issued by the other methods.\n    ",
        "submission_date": "2010-08-16T00:00:00",
        "last_modified_date": "2010-08-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1008.3346",
        "title": "A Miniature-Based Image Retrieval System",
        "authors": [
            "Md. Saiful Islam",
            "Md. Haider Ali"
        ],
        "abstract": "Due to the rapid development of World Wide Web (WWW) and imaging technology, more and more images are available in the Internet and stored in databases. Searching the related images by the querying image is becoming tedious and difficult. Most of the images on the web are compressed by methods based on discrete cosine transform (DCT) including Joint Photographic Experts Group(JPEG) and H.261. This paper presents an efficient content-based image indexing technique for searching similar images using discrete cosine transform features. Experimental results demonstrate its superiority with the existing techniques.\n    ",
        "submission_date": "2010-08-19T00:00:00",
        "last_modified_date": "2010-08-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1008.3742",
        "title": "Optimally Training a Cascade Classifier",
        "authors": [
            "Chunhua Shen",
            "Peng Wang",
            "Anton van den Hengel"
        ],
        "abstract": "Cascade classifiers are widely used in real-time object detection. Different from conventional classifiers that are designed for a low overall classification error rate, a classifier in each node of the cascade is required to achieve an extremely high detection rate and moderate false positive rate. Although there are a few reported methods addressing this requirement in the context of object detection, there is no a principled feature selection method that explicitly takes into account this asymmetric node learning objective. We provide such an algorithm here. We show a special case of the biased minimax probability machine has the same formulation as the linear asymmetric classifier (LAC) of \\cite{wu2005linear}. We then design a new boosting algorithm that directly optimizes the cost function of LAC. The resulting totally-corrective boosting algorithm is implemented by the column generation technique in convex optimization. Experimental results on object detection verify the effectiveness of the proposed boosting algorithm as a node classifier in cascade object detection, and show performance better than that of the current state-of-the-art.\n    ",
        "submission_date": "2010-08-23T00:00:00",
        "last_modified_date": "2010-08-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1008.3798",
        "title": "Proliferating cell nuclear antigen (PCNA) allows the automatic identification of follicles in microscopic images of human ovarian tissue",
        "authors": [
            "Thomas W Kelsey",
            "Benedicta Caserta",
            "Luis Castillo",
            "W Hamish B Wallace",
            "Francisco C\u00f3ppola Gonz\u00e1lvez"
        ],
        "abstract": "Human ovarian reserve is defined by the population of nongrowing follicles (NGFs) in the ovary. Direct estimation of ovarian reserve involves the identification of NGFs in prepared ovarian tissue. Previous studies involving human tissue have used hematoxylin and eosin (HE) stain, with NGF populations estimated by human examination either of tissue under a microscope, or of images taken of this tissue.\nIn this study we replaced HE with proliferating cell nuclear antigen (PCNA), and automated the identification and enumeration of NGFs that appear in the resulting microscopic images. We compared the automated estimates to those obtained by human experts, with the \"gold standard\" taken to be the average of the conservative and liberal estimates by three human experts.\nThe automated estimates were within 10% of the \"gold standard\", for images at both 100x and 200x magnifications. Automated analysis took longer than human analysis for several hundred images, not allowing for breaks from analysis needed by humans.\nOur results both replicate and improve on those of previous studies involving rodent ovaries, and demonstrate the viability of large-scale studies of human ovarian reserve using a combination of immunohistochemistry and computational image analysis techniques.\n    ",
        "submission_date": "2010-08-23T00:00:00",
        "last_modified_date": "2010-08-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1008.4206",
        "title": "Comparative Study of Statistical Skin Detection Algorithms for Sub-Continental Human Images",
        "authors": [
            "Mirza Rehenuma Tabassum",
            "Alim Ul Gias",
            "Md. Mostafa Kamal",
            "Hossain Muhammad Muctadir",
            "Muhammad Ibrahim",
            "Asif Khan Shakir",
            "Asif Imran",
            "Saiful Islamm",
            "Md. Golam Rabbani",
            "Shah Mostafa Khaled",
            "Md. Saiful Islam",
            "Zerina Begum"
        ],
        "abstract": "Object detection has been a focus of research in human-computer interaction. Skin area detection has been a key to different recognitions like face recognition, human motion detection, pornographic and nude image prediction, etc. Most of the research done in the fields of skin detection has been trained and tested on human images of African, Mongolian and Anglo-Saxon ethnic origins. Although there are several intensity invariant approaches to skin detection, the skin color of Indian sub-continentals have not been focused separately. The approach of this research is to make a comparative study between three image segmentation approaches using Indian sub-continental human images, to optimize the detection criteria, and to find some efficient parameters to detect the skin area from these images. The experiments observed that HSV color model based approach to Indian sub-continental skin detection is more suitable with considerable success rate of 91.1% true positives and 88.1% true negatives.\n    ",
        "submission_date": "2010-08-25T00:00:00",
        "last_modified_date": "2010-08-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1009.0623",
        "title": "Weighted Attribute Fusion Model for Face Recognition",
        "authors": [
            "S. Sakthivel",
            "R. Lakshmipathi"
        ],
        "abstract": "Recognizing a face based on its attributes is an easy task for a human to perform as it is a cognitive process. In recent years, Face Recognition is achieved with different kinds of facial features which were used separately or in a combined manner. Currently, Feature fusion methods and parallel methods are the facial features used and performed by integrating multiple feature sets at different levels. However, this integration and the combinational methods do not guarantee better result. Hence to achieve better results, the feature fusion model with multiple weighted facial attribute set is selected. For this feature model, face images from predefined data set has been taken from Olivetti Research Laboratory (ORL) and applied on different methods like Principal Component Analysis (PCA) based Eigen feature extraction technique, Discrete Cosine Transformation (DCT) based feature extraction technique, Histogram Based Feature Extraction technique and Simple Intensity based features. The extracted feature set obtained from these methods were compared and tested for accuracy. In this work we have developed a model which will use the above set of feature extraction techniques with different levels of weights to attain better accuracy. The results show that the selection of optimum weight for a particular feature will lead to improvement in recognition rate.\n    ",
        "submission_date": "2010-09-03T00:00:00",
        "last_modified_date": "2010-09-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1009.0854",
        "title": "Fast Color Space Transformations Using Minimax Approximations",
        "authors": [
            "M. Emre Celebi",
            "Hassan Kingravi",
            "Fatih Celiker"
        ],
        "abstract": "Color space transformations are frequently used in image processing, graphics, and visualization applications. In many cases, these transformations are complex nonlinear functions, which prohibits their use in time-critical applications. In this paper, we present a new approach called Minimax Approximations for Color-space Transformations (MACT).We demonstrate MACT on three commonly used color space transformations. Extensive experiments on a large and diverse image set and comparisons with well-known multidimensional lookup table interpolation methods show that MACT achieves an excellent balance among four criteria: ease of implementation, memory usage, accuracy, and computational speed.\n    ",
        "submission_date": "2010-09-04T00:00:00",
        "last_modified_date": "2010-09-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1009.0892",
        "title": "Effective Pedestrian Detection Using Center-symmetric Local Binary/Trinary Patterns",
        "authors": [
            "Yongbin Zheng",
            "Chunhua Shen",
            "Richard Hartley",
            "Xinsheng Huang"
        ],
        "abstract": "Accurately detecting pedestrians in images plays a critically important role in many computer vision applications. Extraction of effective features is the key to this task. Promising features should be discriminative, robust to various variations and easy to compute. In this work, we present novel features, termed dense center-symmetric local binary patterns (CS-LBP) and pyramid center-symmetric local binary/ternary patterns (CS-LBP/LTP), for pedestrian detection. The standard LBP proposed by Ojala et al. \\cite{c4} mainly captures the texture information. The proposed CS-LBP feature, in contrast, captures the gradient information and some texture information. Moreover, the proposed dense CS-LBP and the pyramid CS-LBP/LTP are easy to implement and computationally efficient, which is desirable for real-time applications. Experiments on the INRIA pedestrian dataset show that the dense CS-LBP feature with linear supporct vector machines (SVMs) is comparable with the histograms of oriented gradients (HOG) feature with linear SVMs, and the pyramid CS-LBP/LTP features outperform both HOG features with linear SVMs and the start-of-the-art pyramid HOG (PHOG) feature with the histogram intersection kernel SVMs. We also demonstrate that the combination of our pyramid CS-LBP feature and the PHOG feature could significantly improve the detection performance-producing state-of-the-art accuracy on the INRIA pedestrian dataset.\n    ",
        "submission_date": "2010-09-05T00:00:00",
        "last_modified_date": "2010-09-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1009.0957",
        "title": "Distance Measures for Reduced Ordering Based Vector Filters",
        "authors": [
            "M. Emre Celebi"
        ],
        "abstract": "Reduced ordering based vector filters have proved successful in removing long-tailed noise from color images while preserving edges and fine image details. These filters commonly utilize variants of the Minkowski distance to order the color vectors with the aim of distinguishing between noisy and noise-free vectors. In this paper, we review various alternative distance measures and evaluate their performance on a large and diverse set of images using several effectiveness and efficiency criteria. The results demonstrate that there are in fact strong alternatives to the popular Minkowski metrics.\n    ",
        "submission_date": "2010-09-05T00:00:00",
        "last_modified_date": "2010-09-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1009.0958",
        "title": "Real-Time Implementation of Order-Statistics Based Directional Filters",
        "authors": [
            "M. Emre Celebi"
        ],
        "abstract": "Vector filters based on order-statistics have proved successful in removing impulsive noise from color images while preserving edges and fine image details. Among these filters, the ones that involve the cosine distance function (directional filters) have particularly high computational requirements, which limits their use in time critical applications. In this paper, we introduce two methods to speed up these filters. Experiments on a diverse set of color images show that the proposed methods provide substantial computational gains without significant loss of accuracy.\n    ",
        "submission_date": "2010-09-05T00:00:00",
        "last_modified_date": "2010-09-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1009.0959",
        "title": "Cost-Effective Implementation of Order-Statistics Based Vector Filters Using Minimax Approximations",
        "authors": [
            "M. Emre Celebi",
            "Hassan A. Kingravi",
            "Rastislav Lukac",
            "Fatih Celiker"
        ],
        "abstract": "Vector operators based on robust order statistics have proved successful in digital multichannel imaging applications, particularly color image filtering and enhancement, in dealing with impulsive noise while preserving edges and fine image details. These operators often have very high computational requirements which limits their use in time-critical applications. This paper introduces techniques to speed up vector filters using the minimax approximation theory. Extensive experiments on a large and diverse set of color images show that proposed approximations achieve an excellent balance among ease of implementation, accuracy, and computational speed.\n    ",
        "submission_date": "2010-09-06T00:00:00",
        "last_modified_date": "2010-09-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1009.0961",
        "title": "A Fast Switching Filter for Impulsive Noise Removal from Color Images",
        "authors": [
            "M. Emre Celebi",
            "Hassan A. Kingravi",
            "Bakhtiyar Uddin",
            "Y. Alp Aslandogan"
        ],
        "abstract": "In this paper, we present a fast switching filter for impulsive noise removal from color images. The filter exploits the HSL color space, and is based on the peer group concept, which allows for the fast detection of noise in a neighborhood without resorting to pairwise distance computations between each pixel. Experiments on large set of diverse images demonstrate that the proposed approach is not only extremely fast, but also gives excellent results in comparison to various state-of-the-art filters.\n    ",
        "submission_date": "2010-09-06T00:00:00",
        "last_modified_date": "2010-09-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1009.0962",
        "title": "Nonlinear Vector Filtering for Impulsive Noise Removal from Color Images",
        "authors": [
            "M. Emre Celebi",
            "Hassan A. Kingravi",
            "Y. Alp Aslandogan"
        ],
        "abstract": "In this paper, a comprehensive survey of 48 filters for impulsive noise removal from color images is presented. The filters are formulated using a uniform notation and categorized into 8 families. The performance of these filters is compared on a large set of images that cover a variety of domains using three effectiveness and one efficiency criteria. In order to ensure a fair efficiency comparison, a fast and accurate approximation for the inverse cosine function is introduced. In addition, commonly used distance measures (Minkowski, angular, and directional-distance) are analyzed and evaluated. Finally, suggestions are provided on how to choose a filter given certain requirements.\n    ",
        "submission_date": "2010-09-06T00:00:00",
        "last_modified_date": "2010-09-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1009.1013",
        "title": "Automatic Detection of Blue-White Veil and Related Structures in Dermoscopy Images",
        "authors": [
            "M. Emre Celebi",
            "Hitoshi Iyatomi",
            "William V. Stoecker",
            "Randy H. Moss",
            "Harold S. Rabinovitz",
            "Giuseppe Argenziano",
            "H. Peter Soyer"
        ],
        "abstract": "  Dermoscopy is a non-invasive skin imaging technique, which permits visualization of features of pigmented melanocytic neoplasms that are not discernable by examination with the naked eye. One of the most important features for the diagnosis of melanoma in dermoscopy images is the blue-white veil (irregular, structureless areas of confluent blue pigmentation with an overlying white \"ground-glass\" film). In this article, we present a machine learning approach to the detection of blue-white veil and related structures in dermoscopy images. The method involves contextual pixel classification using a decision tree classifier. The percentage of blue-white areas detected in a lesion combined with a simple shape descriptor yielded a sensitivity of 69.35% and a specificity of 89.97% on a set of 545 dermoscopy images. The sensitivity rises to 78.20% for detection of blue veil in those cases where it is a primary feature for melanoma recognition.\n    ",
        "submission_date": "2010-09-06T00:00:00",
        "last_modified_date": "2010-09-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1009.1020",
        "title": "An Improved Objective Evaluation Measure for Border Detection in Dermoscopy Images",
        "authors": [
            "M. Emre Celebi",
            "Gerald Schaefer",
            "Hitoshi Iyatomi",
            "William V. Stoecker",
            "Joseph M. Malters",
            "James M. Grichnik"
        ],
        "abstract": "Background: Dermoscopy is one of the major imaging modalities used in the diagnosis of melanoma and other pigmented skin lesions. Due to the difficulty and subjectivity of human interpretation, dermoscopy image analysis has become an important research area. One of the most important steps in dermoscopy image analysis is the automated detection of lesion borders. Although numerous methods have been developed for the detection of lesion borders, very few studies were comprehensive in the evaluation of their results. Methods: In this paper, we evaluate five recent border detection methods on a set of 90 dermoscopy images using three sets of dermatologist-drawn borders as the ground-truth. In contrast to previous work, we utilize an objective measure, the Normalized Probabilistic Rand Index, which takes into account the variations in the ground-truth images. Conclusion: The results demonstrate that the differences between four of the evaluated border detection methods are in fact smaller than those predicted by the commonly used XOR measure.\n    ",
        "submission_date": "2010-09-06T00:00:00",
        "last_modified_date": "2010-09-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1009.1362",
        "title": "Approximate Lesion Localization in Dermoscopy Images",
        "authors": [
            "M. Emre Celebi",
            "Hitoshi Iyatomi",
            "Gerald Schaefer",
            "William V. Stoecker"
        ],
        "abstract": "Background: Dermoscopy is one of the major imaging modalities used in the diagnosis of melanoma and other pigmented skin lesions. Due to the difficulty and subjectivity of human interpretation, automated analysis of dermoscopy images has become an important research area. Border detection is often the first step in this analysis. Methods: In this article, we present an approximate lesion localization method that serves as a preprocessing step for detecting borders in dermoscopy images. In this method, first the black frame around the image is removed using an iterative algorithm. The approximate location of the lesion is then determined using an ensemble of thresholding algorithms. Results: The method is tested on a set of 428 dermoscopy images. The localization error is quantified by a metric that uses dermatologist determined borders as the ground truth. Conclusion: The results demonstrate that the method presented here achieves both fast and accurate localization of lesions in dermoscopy images.\n    ",
        "submission_date": "2010-09-06T00:00:00",
        "last_modified_date": "2010-09-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1009.1983",
        "title": "Evolutionary Computational Method of Facial Expression Analysis for Content-based Video Retrieval using 2-Dimensional Cellular Automata",
        "authors": [
            "P. Geetha",
            "Vasumathi Narayanan"
        ],
        "abstract": "In this paper, Deterministic Cellular Automata (DCA) based video shot classification and retrieval is proposed. The deterministic 2D Cellular automata model captures the human facial expressions, both spontaneous and posed. The determinism stems from the fact that the facial muscle actions are standardized by the encodings of Facial Action Coding System (FACS) and Action Units (AUs). Based on these encodings, we generate the set of evolutionary update rules of the DCA for each facial expression. We consider a Person-Independent Facial Expression Space (PIFES) to analyze the facial expressions based on Partitioned 2D-Cellular Automata which capture the dynamics of facial expressions and classify the shots based on it. Target video shot is retrieved by comparing the similar expression is obtained for the query frame's face with respect to the key faces expressions in the database video. Consecutive key face expressions in the database that are highly similar to the query frame's face, then the key faces are used to generate the set of retrieved video shots from the database. A concrete example of its application which realizes an affective interaction between the computer and the user is proposed. In the affective interaction, the computer can recognize the facial expression of any given video shot. This interaction endows the computer with certain ability to adapt to the user's feedback.\n    ",
        "submission_date": "2010-09-10T00:00:00",
        "last_modified_date": "2010-09-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1009.3029",
        "title": "Invariant Spectral Hashing of Image Saliency Graph",
        "authors": [
            "Maxime Taquet",
            "Laurent Jacques",
            "Christophe De Vleeschouwer",
            "Benoit Macq"
        ],
        "abstract": "Image hashing is the process of associating a short vector of bits to an image. The resulting summaries are useful in many applications including image indexing, image authentication and pattern recognition. These hashes need to be invariant under transformations of the image that result in similar visual content, but should drastically differ for conceptually distinct contents. This paper proposes an image hashing method that is invariant under rotation, scaling and translation of the image. The gist of our approach relies on the geometric characterization of salient point distribution in the image. This is achieved by the definition of a \"saliency graph\" connecting these points jointly with an image intensity function on the graph nodes. An invariant hash is then obtained by considering the spectrum of this function in the eigenvector basis of the Laplacian graph, that is, its graph Fourier transform. Interestingly, this spectrum is invariant under any relabeling of the graph nodes. The graph reveals geometric information of the image, making the hash robust to image transformation, yet distinct for different visual content. The efficiency of the proposed method is assessed on a set of MRI 2-D slices and on a database of faces.\n    ",
        "submission_date": "2010-09-15T00:00:00",
        "last_modified_date": "2010-09-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1009.3078",
        "title": "Asymmetric Totally-corrective Boosting for Real-time Object Detection",
        "authors": [
            "Peng Wang",
            "Chunhua Shen",
            "Nick Barnes",
            "Hong Zheng",
            "Zhang Ren"
        ],
        "abstract": "Real-time object detection is one of the core problems in computer vision. The cascade boosting framework proposed by Viola and Jones has become the standard for this problem. In this framework, the learning goal for each node is asymmetric, which is required to achieve a high detection rate and a moderate false positive rate. We develop new boosting algorithms to address this asymmetric learning problem. We show that our methods explicitly optimize asymmetric loss objectives in a totally corrective fashion. The methods are totally corrective in the sense that the coefficients of all selected weak classifiers are updated at each iteration. In contract, conventional boosting like AdaBoost is stage-wise in that only the current weak classifier's coefficient is updated. At the heart of the totally corrective boosting is the column generation technique. Experiments on face detection show that our methods outperform the state-of-the-art asymmetric boosting methods.\n    ",
        "submission_date": "2010-09-16T00:00:00",
        "last_modified_date": "2010-09-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1009.3802",
        "title": "Robust Low-Rank Subspace Segmentation with Semidefinite Guarantees",
        "authors": [
            "Yuzhao Ni",
            "Ju Sun",
            "Xiaotong Yuan",
            "Shuicheng Yan",
            "Loong-Fah Cheong"
        ],
        "abstract": "Recently there is a line of research work proposing to employ Spectral Clustering (SC) to segment (group){Throughout the paper, we use segmentation, clustering, and grouping, and their verb forms, interchangeably.} high-dimensional structural data such as those (approximately) lying on subspaces {We follow {liu2010robust} and use the term \"subspace\" to denote both linear subspaces and affine subspaces. There is a trivial conversion between linear subspaces and affine subspaces as mentioned therein.} or low-dimensional manifolds. By learning the affinity matrix in the form of sparse reconstruction, techniques proposed in this vein often considerably boost the performance in subspace settings where traditional SC can fail. Despite the success, there are fundamental problems that have been left unsolved: the spectrum property of the learned affinity matrix cannot be gauged in advance, and there is often one ugly symmetrization step that post-processes the affinity for SC input. Hence we advocate to enforce the symmetric positive semidefinite constraint explicitly during learning (Low-Rank Representation with Positive SemiDefinite constraint, or LRR-PSD), and show that factually it can be solved in an exquisite scheme efficiently instead of general-purpose SDP solvers that usually scale up poorly. We provide rigorous mathematical derivations to show that, in its canonical form, LRR-PSD is equivalent to the recently proposed Low-Rank Representation (LRR) scheme {liu2010robust}, and hence offer theoretic and practical insights to both LRR-PSD and LRR, inviting future research. As per the computational cost, our proposal is at most comparable to that of LRR, if not less. We validate our theoretic analysis and optimization scheme by experiments on both synthetic and real data sets.\n    ",
        "submission_date": "2010-09-20T00:00:00",
        "last_modified_date": "2010-10-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1009.4004",
        "title": "A family of statistical symmetric divergences based on Jensen's inequality",
        "authors": [
            "Frank Nielsen"
        ],
        "abstract": "We introduce a novel parametric family of symmetric information-theoretic distances based on Jensen's inequality for a convex functional generator. In particular, this family unifies the celebrated Jeffreys divergence with the Jensen-Shannon divergence when the Shannon entropy generator is chosen. We then design a generic algorithm to compute the unique centroid defined as the minimum average divergence. This yields a smooth family of centroids linking the Jeffreys to the Jensen-Shannon centroid. Finally, we report on our experimental results.\n    ",
        "submission_date": "2010-09-21T00:00:00",
        "last_modified_date": "2011-12-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1009.4581",
        "title": "3D-Mesh denoising using an improved vertex based anisotropic diffusion",
        "authors": [
            "Mohammed EL Hassouni",
            "Driss Aboutajdine"
        ],
        "abstract": "This paper deals with an improvement of vertex based nonlinear diffusion for mesh denoising. This method directly filters the position of the vertices using Laplace, reduced centered Gaussian and Rayleigh probability density functions as diffusivities. The use of these PDFs improves the performance of a vertex-based diffusion method which are adapted to the underlying mesh structure. We also compare the proposed method to other mesh denoising methods such as Laplacian flow, mean, median, min and the adaptive MMSE filtering. To evaluate these methods of filtering, we use two error metrics. The first is based on the vertices and the second is based on the normals. Experimental results demonstrate the effectiveness of our proposed method in comparison with the existing methods.\n    ",
        "submission_date": "2010-09-23T00:00:00",
        "last_modified_date": "2010-09-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1009.4739",
        "title": "Balancing clusters to reduce response time variability in large scale image search",
        "authors": [
            "Romain Tavenard",
            "Laurent Amsaleg",
            "Herv\u00e9 J\u00e9gou"
        ],
        "abstract": "Many algorithms for approximate nearest neighbor search in high-dimensional spaces partition the data into clusters. At query time, in order to avoid exhaustive search, an index selects the few (or a single) clusters nearest to the query point. Clusters are often produced by the well-known $k$-means approach since it has several desirable properties. On the downside, it tends to produce clusters having quite different cardinalities. Imbalanced clusters negatively impact both the variance and the expectation of query response times. This paper proposes to modify $k$-means centroids to produce clusters with more comparable sizes without sacrificing the desirable properties. Experiments with a large scale collection of image descriptors show that our algorithm significantly reduces the variance of response times without seriously impacting the search quality.\n    ",
        "submission_date": "2010-09-21T00:00:00",
        "last_modified_date": "2010-09-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1009.4757",
        "title": "Modeling Instantaneous Changes In Natural Scenes",
        "authors": [
            "Vikram Dhillon"
        ],
        "abstract": "This project aims to create 3d model of the natural world and model changes in it instantaneously. A framework for modeling instantaneous changes natural scenes in real time using Lagrangian Particle Framework and a fluid-particle grid approach is presented. This project is presented in the form of a proof-based system where we show that the design is very much possible but currently we only have selective scripts that accomplish the given job, a complete software however is still under work. This research can be divided into 3 distinct sections: the first one discusses a multi-camera rig that can measure ego-motion accurately up to 88%, how this device becomes the backbone of our framework, and some improvements devised to optimize a know framework for depth maps and 3d structure estimation from a single still image called make3d. The second part discusses the fluid-particle framework to model natural scenes, presents some algorithms that we are using to accomplish this task and we show how an application of our framework can extend make3d to model natural scenes in real time. This part of the research constructs a bridge between computer vision and computer graphics so that now ideas, answers and intuitions that arose in the domain of computer graphics can now be applied to computer vision and natural modeling. The final part of this research improves upon what might become the first general purpose vision system using deep belief architectures and provides another framework to improve the lower bound on training images for boosting by using a variation of Restricted Boltzmann machines (RBM). We also discuss other applications that might arise from our work in these areas.\n    ",
        "submission_date": "2010-09-24T00:00:00",
        "last_modified_date": "2010-11-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1009.4823",
        "title": "Image Segmentation by Discounted Cumulative Ranking on Maximal Cliques",
        "authors": [
            "Joao Carreira",
            "Adrian Ion",
            "Cristian Sminchisescu"
        ],
        "abstract": "We propose a mid-level image segmentation framework that combines multiple figure-ground hypothesis (FG) constrained at different locations and scales, into interpretations that tile the entire image. The problem is cast as optimization over sets of maximal cliques sampled from the graph connecting non-overlapping, putative figure-ground segment hypotheses. Potential functions over cliques combine unary Gestalt-based figure quality scores and pairwise compatibilities among spatially neighboring segments, constrained by T-junctions and the boundary interface statistics resulting from projections of real 3d scenes. Learning the model parameters is formulated as rank optimization, alternating between sampling image tilings and optimizing their potential function parameters. State of the art results are reported on both the Berkeley and the VOC2009 segmentation dataset, where a 28% improvement was achieved.\n    ",
        "submission_date": "2010-09-24T00:00:00",
        "last_modified_date": "2010-09-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1009.4974",
        "title": "Rotation Invariant Face Detection Using Wavelet, PCA and Radial Basis Function Networks",
        "authors": [
            "S. M. Kamruzzaman",
            "Firoz Ahmed Siddiqi",
            "Md. Saiful Islam",
            "Md. Emdadul Haque",
            "Mohammad Shamsul Alam"
        ],
        "abstract": "This paper introduces a novel method for human face detection with its orientation by using wavelet, principle component analysis (PCA) and redial basis networks. The input image is analyzed by two-dimensional wavelet and a two-dimensional stationary wavelet. The common goals concern are the image clearance and simplification, which are parts of de-noising or compression. We applied an effective procedure to reduce the dimension of the input vectors using PCA. Radial Basis Function (RBF) neural network is then used as a function approximation network to detect where either the input image is contained a face or not and if there is a face exists then tell about its orientation. We will show how RBF can perform well then back-propagation algorithm and give some solution for better regularization of the RBF (GRNN) network. Compared with traditional RBF networks, the proposed network demonstrates better capability of approximation to underlying functions, faster learning speed, better size of network, and high robustness to outliers.\n    ",
        "submission_date": "2010-09-25T00:00:00",
        "last_modified_date": "2010-09-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1009.5249",
        "title": "Defining and Generating Axial Lines from Street Center Lines for better Understanding of Urban Morphologies",
        "authors": [
            "Xintao Liu",
            "Bin Jiang"
        ],
        "abstract": "Axial lines are defined as the longest visibility lines for representing individual linear spaces in urban environments. The least number of axial lines that cover the free space of an urban environment or the space between buildings constitute what is often called an axial map. This is a fundamental tool in space syntax, a theory developed by Bill Hillier and his colleagues for characterizing the underlying urban morphologies. For a long time, generating axial lines with help of some graphic software has been a tedious manual process that is criticized for being time consuming, subjective, or even arbitrary. In this paper, we redefine axial lines as the least number of individual straight line segments mutually intersected along natural streets that are generated from street center lines using the Gestalt principle of good continuity. Based on this new definition, we develop an automatic solution to generating the newly defined axial lines from street center lines. We apply this solution to six typical street networks (three from North America and three from Europe), and generate a new set of axial lines for analyzing the urban morphologies. Through a comparison study between the new axial lines and the conventional or old axial lines, and between the new axial lines and natural streets, we demonstrate with empirical evidence that the newly defined axial lines are a better alternative in capturing the underlying urban structure.\n",
        "submission_date": "2010-09-27T00:00:00",
        "last_modified_date": "2011-04-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1009.5758",
        "title": "Face Detection with Effective Feature Extraction",
        "authors": [
            "Sakrapee Paisitkriangkrai",
            "Chunhua Shen",
            "Jian Zhang"
        ],
        "abstract": "There is an abundant literature on face detection due to its important role in many vision applications. Since Viola and Jones proposed the first real-time AdaBoost based face detector, Haar-like features have been adopted as the method of choice for frontal face detection. In this work, we show that simple features other than Haar-like features can also be applied for training an effective face detector. Since, single feature is not discriminative enough to separate faces from difficult non-faces, we further improve the generalization performance of our simple features by introducing feature co-occurrences. We demonstrate that our proposed features yield a performance improvement compared to Haar-like features. In addition, our findings indicate that features play a crucial role in the ability of the system to generalize.\n    ",
        "submission_date": "2010-09-29T00:00:00",
        "last_modified_date": "2010-09-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1010.0012",
        "title": "An Embarrassingly Simple Speed-Up of Belief Propagation with Robust Potentials",
        "authors": [
            "James M. Coughlan",
            "Huiying Shen"
        ],
        "abstract": "We present an exact method of greatly speeding up belief propagation (BP) for a wide variety of potential functions in pairwise MRFs and other graphical models. Specifically, our technique applies whenever the pairwise potentials have been {\\em truncated} to a constant value for most pairs of states, as is commonly done in MRF models with robust potentials (such as stereo) that impose an upper bound on the penalty assigned to discontinuities; for each of the $M$ possible states in one node, only a smaller number $m$ of compatible states in a neighboring node are assigned milder penalties. The computational complexity of our method is $O(mM)$, compared with $O(M^2)$ for standard BP, and we emphasize that the method is {\\em exact}, in contrast with related techniques such as pruning; moreover, the method is very simple and easy to implement. Unlike some previous work on speeding up BP, our method applies both to sum-product and max-product BP, which makes it useful in any applications where marginal probabilities are required, such as maximum likelihood estimation. We demonstrate the technique on a stereo MRF example, confirming that the technique speeds up BP without altering the solution.\n    ",
        "submission_date": "2010-09-30T00:00:00",
        "last_modified_date": "2010-09-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1010.0301",
        "title": "A Microwave Imaging and Enhancement Technique from Noisy Synthetic Data",
        "authors": [
            "Anjan Kumar Kundu",
            "Bijoy Bandopadhyay",
            "Sugata Sanyal"
        ],
        "abstract": "An inverse iterative algorithm for microwave imaging based on moment method solution is presented here. The iterative scheme has been developed on constrained optimization technique and is certain to converge. Different mesh size for the model has been used here to overcome the Inverse Crime. The synthetic data at the receivers is contaminated with different percentage of noise. The ill-posedness of the problem is solved by Levenberg-Marquardt method. The algorithm is applied to synthetic data and the reconstructed image is then further enhanced through the Image enhancement technique\n    ",
        "submission_date": "2010-10-02T00:00:00",
        "last_modified_date": "2010-10-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1010.0417",
        "title": "Visual-hint Boundary to Segment Algorithm for Image Segmentation",
        "authors": [
            "Yu Su",
            "Margaret H. Dunham"
        ],
        "abstract": "Image segmentation has been a very active research topic in image analysis area. Currently, most of the image segmentation algorithms are designed based on the idea that images are partitioned into a set of regions preserving homogeneous intra-regions and inhomogeneous inter-regions. However, human visual intuition does not always follow this pattern. A new image segmentation method named Visual-Hint Boundary to Segment (VHBS) is introduced, which is more consistent with human perceptions. VHBS abides by two visual hint rules based on human perceptions: (i) the global scale boundaries tend to be the real boundaries of the objects; (ii) two adjacent regions with quite different colors or textures tend to result in the real boundaries between them. It has been demonstrated by experiments that, compared with traditional image segmentation method, VHBS has better performance and also preserves higher computational efficiency.\n    ",
        "submission_date": "2010-10-03T00:00:00",
        "last_modified_date": "2010-10-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1010.0422",
        "title": "Convolutional Matching Pursuit and Dictionary Training",
        "authors": [
            "Arthur Szlam",
            "Koray Kavukcuoglu",
            "Yann LeCun"
        ],
        "abstract": "Matching pursuit and K-SVD is demonstrated in the translation invariant setting\n    ",
        "submission_date": "2010-10-03T00:00:00",
        "last_modified_date": "2010-10-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1010.0608",
        "title": "Real-time Robust Principal Components' Pursuit",
        "authors": [
            "Chenlu Qiu",
            "Namrata Vaswani"
        ],
        "abstract": "In the recent work of Candes et al, the problem of recovering low rank matrix corrupted by i.i.d. sparse outliers is studied and a very elegant solution, principal component pursuit, is proposed. It is motivated as a tool for video surveillance applications with the background image sequence forming the low rank part and the moving objects/persons/abnormalities forming the sparse part. Each image frame is treated as a column vector of the data matrix made up of a low rank matrix and a sparse corruption matrix. Principal component pursuit solves the problem under the assumptions that the singular vectors of the low rank matrix are spread out and the sparsity pattern of the sparse matrix is uniformly random. However, in practice, usually the sparsity pattern and the signal values of the sparse part (moving persons/objects) change in a correlated fashion over time, for e.g., the object moves slowly and/or with roughly constant velocity. This will often result in a low rank sparse matrix.\n",
        "submission_date": "2010-10-04T00:00:00",
        "last_modified_date": "2011-02-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1010.1496",
        "title": "Profile Based Sub-Image Search in Image Databases",
        "authors": [
            "Vishwakarma Singh",
            "Ambuj K. Singh"
        ],
        "abstract": "Sub-image search with high accuracy in natural images still remains a challenging problem. This paper proposes a new feature vector called profile for a keypoint in a bag of visual words model of an image. The profile of a keypoint captures the spatial geometry of all the other keypoints in an image with respect to itself, and is very effective in discriminating true matches from false matches. Sub-image search using profiles is a single-phase process requiring no geometric validation, yields high precision on natural images, and works well on small visual codebook. The proposed search technique differs from traditional methods that first generate a set of candidates disregarding spatial information and then verify them geometrically. Conventional methods also use large codebooks. We achieve a precision of 81% on a combined data set of synthetic and real natural images using a codebook size of 500 for top-10 queries; that is 31% higher than the conventional candidate generation approach.\n    ",
        "submission_date": "2010-10-07T00:00:00",
        "last_modified_date": "2010-10-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1010.2733",
        "title": "Combinatorial Continuous Maximal Flows",
        "authors": [
            "Camille Couprie",
            "Leo Grady",
            "Hugues Talbot",
            "Laurent Najman"
        ],
        "abstract": "Maximum flow (and minimum cut) algorithms have had a strong impact on computer vision. In particular, graph cuts algorithms provide a mechanism for the discrete optimization of an energy functional which has been used in a variety of applications such as image segmentation, stereo, image stitching and texture synthesis. Algorithms based on the classical formulation of max-flow defined on a graph are known to exhibit metrication artefacts in the solution. Therefore, a recent trend has been to instead employ a spatially continuous maximum flow (or the dual min-cut problem) in these same applications to produce solutions with no metrication errors. However, known fast continuous max-flow algorithms have no stopping criteria or have not been proved to converge. In this work, we revisit the continuous max-flow problem and show that the analogous discrete formulation is different from the classical max-flow problem. We then apply an appropriate combinatorial optimization technique to this combinatorial continuous max-flow CCMF problem to find a null-divergence solution that exhibits no metrication artefacts and may be solved exactly by a fast, efficient algorithm with provable convergence. Finally, by exhibiting the dual problem of our CCMF formulation, we clarify the fact, already proved by Nozawa in the continuous setting, that the max-flow and the total variation problems are not always equivalent.\n    ",
        "submission_date": "2010-10-13T00:00:00",
        "last_modified_date": "2011-12-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1010.3460",
        "title": "Hybrid Linear Modeling via Local Best-fit Flats",
        "authors": [
            "Teng Zhang",
            "Arthur Szlam",
            "Yi Wang",
            "Gilad Lerman"
        ],
        "abstract": "We present a simple and fast geometric method for modeling data by a union of affine subspaces. The method begins by forming a collection of local best-fit affine subspaces, i.e., subspaces approximating the data in local neighborhoods. The correct sizes of the local neighborhoods are determined automatically by the Jones' $\\beta_2$ numbers (we prove under certain geometric conditions that our method finds the optimal local neighborhoods). The collection of subspaces is further processed by a greedy selection procedure or a spectral method to generate the final model. We discuss applications to tracking-based motion segmentation and clustering of faces under different illuminating conditions. We give extensive experimental evidence demonstrating the state of the art accuracy and speed of the suggested algorithms on these problems and also on synthetic hybrid linear data as well as the MNIST handwritten digits data; and we demonstrate how to use our algorithms for fast determination of the number of affine subspaces.\n    ",
        "submission_date": "2010-10-17T00:00:00",
        "last_modified_date": "2012-05-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1010.3467",
        "title": "Fast Inference in Sparse Coding Algorithms with Applications to Object Recognition",
        "authors": [
            "Koray Kavukcuoglu",
            "Marc'Aurelio Ranzato",
            "Yann LeCun"
        ],
        "abstract": "Adaptive sparse coding methods learn a possibly overcomplete set of basis functions, such that natural image patches can be reconstructed by linearly combining a small subset of these bases. The applicability of these methods to visual object recognition tasks has been limited because of the prohibitive cost of the optimization algorithms required to compute the sparse representation. In this work we propose a simple and efficient algorithm to learn basis functions. After training, this model also provides a fast and smooth approximator to the optimal representation, achieving even better accuracy than exact sparse coding algorithms on visual object recognition tasks.\n    ",
        "submission_date": "2010-10-18T00:00:00",
        "last_modified_date": "2010-10-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1010.3867",
        "title": "Joint interpretation of on-board vision and static GPS cartography for determination of correct speed limit",
        "authors": [
            "Alexandre Bargeton",
            "Fabien Moutarde",
            "Fawzi Nashashibi",
            "Anne-Sophie Puthon"
        ],
        "abstract": "We present here a first prototype of a \"Speed Limit Support\" Advance Driving Assistance System (ADAS) producing permanent reliable information on the current speed limit applicable to the vehicle. Such a module can be used either for information of the driver, or could even serve for automatic setting of the maximum speed of a smart Adaptive Cruise Control (ACC). Our system is based on a joint interpretation of cartographic information (for static reference information) with on-board vision, used for traffic sign detection and recognition (including supplementary sub-signs) and visual road lines localization (for detection of lane changes). The visual traffic sign detection part is quite robust (90% global correct detection and recognition for main speed signs, and 80% for exit-lane sub-signs detection). Our approach for joint interpretation with cartography is original, and logic-based rather than probability-based, which allows correct behaviour even in cases, which do happen, when both vision and cartography may provide the same erroneous information.\n    ",
        "submission_date": "2010-10-19T00:00:00",
        "last_modified_date": "2010-10-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1010.3935",
        "title": "3-D Rigid Models from Partial Views - Global Factorization",
        "authors": [
            "Pedro M. Q. Aguiar",
            "Rui F. C. Guerreiro",
            "Bruno B. Gon\u00e7alves"
        ],
        "abstract": "The so-called factorization methods recover 3-D rigid structure from motion by factorizing an observation matrix that collects 2-D projections of features. These methods became popular due to their robustness - they use a large number of views, which constrains adequately the solution - and computational simplicity - the large number of unknowns is computed through an SVD, avoiding non-linear optimization. However, they require that all the entries of the observation matrix are known. This is unlikely to happen in practice, due to self-occlusion and limited field of view. Also, when processing long videos, regions that become occluded often appear again later. Current factorization methods process these as new regions, leading to less accurate estimates of 3-D structure. In this paper, we propose a global factorization method that infers complete 3-D models directly from the 2-D projections in the entire set of available video frames. Our method decides whether a region that has become visible is a region that was seen before, or a previously unseen region, in a global way, i.e., by seeking the simplest rigid object that describes well the entire set of observations. This global approach increases significantly the accuracy of the estimates of the 3-D shape of the scene and the 3-D motion of the camera. Experiments with artificial and real videos illustrate the good performance of our method.\n    ",
        "submission_date": "2010-10-19T00:00:00",
        "last_modified_date": "2010-10-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1010.3947",
        "title": "Maximum Likelihood Mosaics",
        "authors": [
            "Bernardo Esteves Pires",
            "Pedro M. Q. Aguiar"
        ],
        "abstract": "The majority of the approaches to the automatic recovery of a panoramic image from a set of partial views are suboptimal in the sense that the input images are aligned, or registered, pair by pair, e.g., consecutive frames of a video clip. These approaches lead to propagation errors that may be very severe, particularly when dealing with videos that show the same region at disjoint time intervals. Although some authors have proposed a post-processing step to reduce the registration errors in these situations, there have not been attempts to compute the optimal solution, i.e., the registrations leading to the panorama that best matches the entire set of partial views}. This is our goal. In this paper, we use a generative model for the partial views of the panorama and develop an algorithm to compute in an efficient way the Maximum Likelihood estimate of all the unknowns involved: the parameters describing the alignment of all the images and the panorama itself.\n    ",
        "submission_date": "2010-10-19T00:00:00",
        "last_modified_date": "2010-10-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1010.4021",
        "title": "ANSIG - An Analytic Signature for Arbitrary 2D Shapes (or Bags of Unlabeled Points)",
        "authors": [
            "Jos\u00e9 J. Rodrigues",
            "Jo\u00e3o M. F. Xavier",
            "Pedro M. Q. Aguiar"
        ],
        "abstract": "In image analysis, many tasks require representing two-dimensional (2D) shape, often specified by a set of 2D points, for comparison purposes. The challenge of the representation is that it must not only capture the characteristics of the shape but also be invariant to relevant transformations. Invariance to geometric transformations, such as translation, rotation, and scale, has received attention in the past, usually under the assumption that the points are previously labeled, i.e., that the shape is characterized by an ordered set of landmarks. However, in many practical scenarios, the points describing the shape are obtained from automatic processes, e.g., edge or corner detection, thus without labels or natural ordering. Obviously, the combinatorial problem of computing the correspondences between the points of two shapes in the presence of the aforementioned geometrical distortions becomes a quagmire when the number of points is large. We circumvent this problem by representing shapes in a way that is invariant to the permutation of the landmarks, i.e., we represent bags of unlabeled 2D points. Within our framework, a shape is mapped to an analytic function on the complex plane, leading to what we call its analytic signature (ANSIG). To store an ANSIG, it suffices to sample it along a closed contour in the complex plane. We show that the ANSIG is a maximal invariant with respect to the permutation group, i.e., that different shapes have different ANSIGs and shapes that differ by a permutation (or re-labeling) of the landmarks have the same ANSIG. We further show how easy it is to factor out geometric transformations when comparing shapes using the ANSIG representation. Finally, we illustrate these capabilities with shape-based image classification experiments.\n    ",
        "submission_date": "2010-10-19T00:00:00",
        "last_modified_date": "2010-10-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1010.4203",
        "title": "Revisiting Complex Moments For 2D Shape Representation and Image Normalization",
        "authors": [
            "Jo\u00e3o B. F. P. Crespo",
            "Pedro M. Q. Aguiar"
        ],
        "abstract": "When comparing 2D shapes, a key issue is their normalization. Translation and scale are easily taken care of by removing the mean and normalizing the energy. However, defining and computing the orientation of a 2D shape is not so simple. In fact, although for elongated shapes the principal axis can be used to define one of two possible orientations, there is no such tool for general shapes. As we show in the paper, previous approaches fail to compute the orientation of even noiseless observations of simple shapes. We address this problem. In the paper, we show how to uniquely define the orientation of an arbitrary 2D shape, in terms of what we call its Principal Moments. We show that a small subset of these moments suffice to represent the underlying 2D shape and propose a new method to efficiently compute the shape orientation: Principal Moment Analysis. Finally, we discuss how this method can further be applied to normalize grey-level images. Besides the theoretical proof of correctness, we describe experiments demonstrating robustness to noise and illustrating the method with real images.\n    ",
        "submission_date": "2010-10-18T00:00:00",
        "last_modified_date": "2010-10-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1010.4314",
        "title": "Statistical Compressive Sensing of Gaussian Mixture Models",
        "authors": [
            "Guoshen Yu",
            "Guillermo Sapiro"
        ],
        "abstract": "A new framework of compressive sensing (CS), namely statistical compressive sensing (SCS), that aims at efficiently sampling a collection of signals that follow a statistical distribution and achieving accurate reconstruction on average, is introduced. For signals following a Gaussian distribution, with Gaussian or Bernoulli sensing matrices of O(k) measurements, considerably smaller than the O(k log(N/k)) required by conventional CS, where N is the signal dimension, and with an optimal decoder implemented with linear filtering, significantly faster than the pursuit decoders applied in conventional CS, the error of SCS is shown tightly upper bounded by a constant times the k-best term approximation error, with overwhelming probability. The failure probability is also significantly smaller than that of conventional CS. Stronger yet simpler results further show that for any sensing matrix, the error of Gaussian SCS is upper bounded by a constant times the k-best term approximation with probability one, and the bound constant can be efficiently calculated. For signals following Gaussian mixture models, SCS with a piecewise linear decoder is introduced and shown to produce for real images better results than conventional CS based on sparse models.\n    ",
        "submission_date": "2010-10-20T00:00:00",
        "last_modified_date": "2010-10-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1010.4893",
        "title": "Collaborative Sources Identification in Mixed Signals via Hierarchical Sparse Modeling",
        "authors": [
            "Pablo Sprechmann",
            "Ignacio Ramirez",
            "Pablo Cancela",
            "Guillermo Sapiro"
        ],
        "abstract": "A collaborative framework for detecting the different sources in mixed signals is presented in this paper. The approach is based on C-HiLasso, a convex collaborative hierarchical sparse model, and proceeds as follows. First, we build a structured dictionary for mixed signals by concatenating a set of sub-dictionaries, each one of them learned to sparsely model one of a set of possible classes. Then, the coding of the mixed signal is performed by efficiently solving a convex optimization problem that combines standard sparsity with group and collaborative sparsity. The present sources are identified by looking at the sub-dictionaries automatically selected in the coding. The collaborative filtering in C-HiLasso takes advantage of the temporal/spatial redundancy in the mixed signals, letting collections of samples collaborate in identifying the classes, while allowing individual samples to have different internal sparse representations. This collaboration is critical to further stabilize the sparse representation of signals, in particular the class/sub-dictionary selection. The internal sparsity inside the sub-dictionaries, as naturally incorporated by the hierarchical aspects of C-HiLasso, is critical to make the model consistent with the essence of the sub-dictionaries that have been trained for sparse representation of each individual class. We present applications from speaker and instrument identification and texture separation. In the case of audio signals, we use sparse modeling to describe the short-term power spectrum envelopes of harmonic sounds. The proposed pitch independent method automatically detects the number of sources on a recording.\n    ",
        "submission_date": "2010-10-23T00:00:00",
        "last_modified_date": "2010-10-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1010.4951",
        "title": "Local Component Analysis for Nonparametric Bayes Classifier",
        "authors": [
            "Mahmoud Khademi",
            "Mohammad T. Manzuri-Shalmani",
            "Meharn safayani"
        ],
        "abstract": "The decision boundaries of Bayes classifier are optimal because they lead to maximum probability of correct decision. It means if we knew the prior probabilities and the class-conditional densities, we could design a classifier which gives the lowest probability of error. However, in classification based on nonparametric density estimation methods such as Parzen windows, the decision regions depend on the choice of parameters such as window width. Moreover, these methods suffer from curse of dimensionality of the feature space and small sample size problem which severely restricts their practical applications. In this paper, we address these problems by introducing a novel dimension reduction and classification method based on local component analysis. In this method, by adopting an iterative cross-validation algorithm, we simultaneously estimate the optimal transformation matrices (for dimension reduction) and classifier parameters based on local information. The proposed method can classify the data with complicated boundary and also alleviate the course of dimensionality dilemma. Experiments on real data show the superiority of the proposed algorithm in term of classification accuracies for pattern classification applications like age, facial expression and character recognition. Keywords: Bayes classifier, curse of dimensionality dilemma, Parzen window, pattern classification, subspace learning.\n    ",
        "submission_date": "2010-10-24T00:00:00",
        "last_modified_date": "2012-07-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1010.5610",
        "title": "Selective Image Super-Resolution",
        "authors": [
            "Ju Sun",
            "Qiang Chen",
            "Shuicheng Yan",
            "Loong-Fah Cheong"
        ],
        "abstract": "In this paper we propose a vision system that performs image Super Resolution (SR) with selectivity. Conventional SR techniques, either by multi-image fusion or example-based construction, have failed to capitalize on the intrinsic structural and semantic context in the image, and performed \"blind\" resolution recovery to the entire image area. By comparison, we advocate example-based selective SR whereby selectivity is exemplified in three aspects: region selectivity (SR only at object regions), source selectivity (object SR with trained object dictionaries), and refinement selectivity (object boundaries refinement using matting). The proposed system takes over-segmented low-resolution images as inputs, assimilates recent learning techniques of sparse coding (SC) and grouped multi-task lasso (GMTL), and leads eventually to a framework for joint figure-ground separation and interest object SR. The efficiency of our framework is manifested in our experiments with subsets of the VOC2009 and MSRC datasets. We also demonstrate several interesting vision applications that can build on our system.\n    ",
        "submission_date": "2010-10-27T00:00:00",
        "last_modified_date": "2010-10-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1011.0093",
        "title": "Fast Color Quantization Using Weighted Sort-Means Clustering",
        "authors": [
            "M. Emre Celebi"
        ],
        "abstract": "Color quantization is an important operation with numerous applications in graphics and image processing. Most quantization methods are essentially based on data clustering algorithms. However, despite its popularity as a general purpose clustering algorithm, k-means has not received much respect in the color quantization literature because of its high computational requirements and sensitivity to initialization. In this paper, a fast color quantization method based on k-means is presented. The method involves several modifications to the conventional (batch) k-means algorithm including data reduction, sample weighting, and the use of triangle inequality to speed up the nearest neighbor search. Experiments on a diverse set of images demonstrate that, with the proposed modifications, k-means becomes very competitive with state-of-the-art color quantization methods in terms of both effectiveness and efficiency.\n    ",
        "submission_date": "2010-10-30T00:00:00",
        "last_modified_date": "2010-10-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1011.0596",
        "title": "Multiple View Reconstruction of Calibrated Images using Singular Value Decomposition",
        "authors": [
            "Ayan Chaudhury",
            "Abhishek Gupta",
            "Sumita Manna",
            "Subhadeep Mukherjee",
            "Amlan Chakrabarti"
        ],
        "abstract": "Calibration in a multi camera network has widely been studied for over several years starting from the earlier days of photogrammetry. Many authors have presented several calibration algorithms with their relative advantages and disadvantages. In a stereovision system, multiple view reconstruction is a challenging task. However, the total computational procedure in detail has not been presented before. Here in this work, we are dealing with the problem that, when a world coordinate point is fixed in space, image coordinates of that 3D point vary for different camera positions and orientations. In computer vision aspect, this situation is undesirable. That is, the system has to be designed in such a way that image coordinate of the world coordinate point will be fixed irrespective of the position & orientation of the cameras. We have done it in an elegant fashion. Firstly, camera parameters are calculated in its local coordinate system. Then, we use global coordinate data to transfer all local coordinate data of stereo cameras into same global coordinate system, so that we can register everything into this global coordinate system. After all the transformations, when the image coordinate of the world coordinate point is calculated, it gives same coordinate value for all camera positions & orientations. That is, the whole system is calibrated.\n    ",
        "submission_date": "2010-11-02T00:00:00",
        "last_modified_date": "2010-11-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1011.0640",
        "title": "Lesion Border Detection in Dermoscopy Images",
        "authors": [
            "M. Emre Celebi",
            "Hitoshi Iyatomi",
            "Gerald Schaefer",
            "William V. Stoecker"
        ],
        "abstract": "  Background: Dermoscopy is one of the major imaging modalities used in the diagnosis of melanoma and other pigmented skin lesions. Due to the difficulty and subjectivity of human interpretation, computerized analysis of dermoscopy images has become an important research area. One of the most important steps in dermoscopy image analysis is the automated detection of lesion borders. Methods: In this article, we present a systematic overview of the recent border detection methods in the literature paying particular attention to computational issues and evaluation aspects. Conclusion: Common problems with the existing approaches include the acquisition, size, and diagnostic distribution of the test image set, the evaluation of the results, and the inadequate description of the employed methods. Border determination by dermatologists appears to depend upon higher-level knowledge, therefore it is likely that the incorporation of domain knowledge in automated methods will enable them to perform better, especially in sets of images with a variety of diagnoses.\n    ",
        "submission_date": "2010-10-30T00:00:00",
        "last_modified_date": "2010-10-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1011.1035",
        "title": "Featureless 2D-3D Pose Estimation by Minimising an Illumination-Invariant Loss",
        "authors": [
            "Srimal Jayawardena",
            "Marcus Hutter",
            "Nathan Brewer"
        ],
        "abstract": "The problem of identifying the 3D pose of a known object from a given 2D image has important applications in Computer Vision ranging from robotic vision to image analysis. Our proposed method of registering a 3D model of a known object on a given 2D photo of the object has numerous advantages over existing methods: It does neither require prior training nor learning, nor knowledge of the camera parameters, nor explicit point correspondences or matching features between image and model. Unlike techniques that estimate a partial 3D pose (as in an overhead view of traffic or machine parts on a conveyor belt), our method estimates the complete 3D pose of the object, and works on a single static image from a given view, and under varying and unknown lighting conditions. For this purpose we derive a novel illumination-invariant distance measure between 2D photo and projected 3D model, which is then minimised to find the best pose parameters. Results for vehicle pose detection are presented.\n    ",
        "submission_date": "2010-11-03T00:00:00",
        "last_modified_date": "2010-11-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1011.2272",
        "title": "Single Frame Image super Resolution using Learned Directionlets",
        "authors": [
            "A.P. Reji",
            "Thomas Tessamma"
        ],
        "abstract": "In this paper, a new directionally adaptive, learning based, single image super resolution method using multiple direction wavelet transform, called Directionlets is presented. This method uses directionlets to effectively capture directional features and to extract edge information along different directions of a set of available high resolution images .This information is used as the training set for super resolving a low resolution input image and the Directionlet coefficients at finer scales of its high-resolution image are learned locally from this training set and the inverse Directionlet transform recovers the super-resolved high resolution image. The simulation results showed that the proposed approach outperforms standard interpolation techniques like Cubic spline interpolation as well as standard Wavelet-based learning, both visually and in terms of the mean squared error (mse) values. This method gives good result with aliased images also.\n    ",
        "submission_date": "2010-11-10T00:00:00",
        "last_modified_date": "2010-11-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1011.3019",
        "title": "Bounded Multivariate Surfaces On Monovariate Internal Functions",
        "authors": [
            "Shriprakash Sinha",
            "Gert J. ter Horst"
        ],
        "abstract": "Combining the properties of monovariate internal functions as proposed in Kolmogorov superimposition theorem, in tandem with the bounds wielded by the multivariate formulation of Chebyshev inequality, a hybrid model is presented, that decomposes images into homogeneous probabilistically bounded multivariate surfaces. Given an image, the model shows a novel way of working on reduced image representation while processing and capturing the interaction among the multidimensional information that describes the content of the same. Further, it tackles the practical issues of preventing leakage by bounding the growth of surface and reducing the problem sample size. The model if used, also sheds light on how the Chebyshev parameter relates to the number of pixels and the dimensionality of the feature space that associates with a pixel. Initial segmentation results on the Berkeley image segmentation benchmark indicate the effectiveness of the proposed decomposition algorithm.\n    ",
        "submission_date": "2010-11-12T00:00:00",
        "last_modified_date": "2010-11-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1011.3023",
        "title": "Classification with Scattering Operators",
        "authors": [
            "Joan Bruna",
            "St\u00e9phane Mallat"
        ],
        "abstract": "A scattering vector is a local descriptor including multiscale and multi-direction co-occurrence information. It is computed with a cascade of wavelet decompositions and complex modulus. This scattering representation is locally translation invariant and linearizes deformations. A supervised classification algorithm is computed with a PCA model selection on scattering vectors. State of the art results are obtained for handwritten digit recognition and texture classification.\n    ",
        "submission_date": "2010-11-12T00:00:00",
        "last_modified_date": "2013-11-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1011.3174",
        "title": "Tensor-SIFT based Earth Mover's Distance for Contour Tracking",
        "authors": [
            "Peihua Li"
        ],
        "abstract": "Contour tracking in adverse environments is a challenging problem due to cluttered background, illumination variation, occlusion, and noise, among others. This paper presents a robust contour tracking method by contributing to some of the key issues involved, including (a) a region functional formulation and its optimization; (b) design of a robust and effective feature; and (c) development of an integrated tracking algorithm. First, we formulate a region functional based on robust Earth Mover's distance (EMD) with kernel density for distribution modeling, and propose a two-phase method for its optimization. In the first phase, letting the candidate contour be fixed, we express EMD as the transportation problem and solve it by the simplex algorithm. Next, using the theory of shape derivative, we make a perturbation analysis of the contour around the best solution to the transportation problem. This leads to a partial differential equation (PDE) that governs the contour evolution. Second, we design a novel and effective feature for tracking applications. We propose a dimensionality reduction method by tensor decomposition, achieving a low-dimensional description of SIFT features called Tensor-SIFT for characterizing local image region properties. Applicable to both color and gray-level images, Tensor-SIFT is very distinctive, insensitive to illumination changes, and noise. Finally, we develop an integrated algorithm that combines various techniques of the simplex algorithm, narrow-band level set and fast marching algorithms. Particularly, we introduce an inter-frame initialization method and a stopping criterion for the termination of PDE iteration. Experiments in challenging image sequences show that the proposed work has promising performance.\n    ",
        "submission_date": "2010-11-14T00:00:00",
        "last_modified_date": "2010-11-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1011.3177",
        "title": "The Data Replication Method for the Classification with Reject Option",
        "authors": [
            "Ricardo Sousa",
            "Jaime S. Cardoso"
        ],
        "abstract": "Classification is one of the most important tasks of machine learning. Although the most well studied model is the two-class problem, in many scenarios there is the opportunity to label critical items for manual revision, instead of trying to automatically classify every item. In this paper we adapt a paradigm initially proposed for the classification of ordinal data to address the classification problem with reject option. The technique reduces the problem of classifying with reject option to the standard two-class problem. The introduced method is then mapped into support vector machines and neural networks. Finally, the framework is extended to multiclass ordinal data with reject option. An experimental study with synthetic and real data sets, verifies the usefulness of the proposed approach.\n    ",
        "submission_date": "2010-11-14T00:00:00",
        "last_modified_date": "2011-07-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1011.3189",
        "title": "Warping Peirce Quincuncial Panoramas",
        "authors": [
            "Chamberlain Fong",
            "Brian K. Vogel"
        ],
        "abstract": "The Peirce quincuncial projection is a mapping of the surface of a sphere to the interior of a square. It is a conformal map except for four points on the equator. These points of non-conformality cause significant artifacts in photographic applications. In this paper, we propose an algorithm and user-interface to mitigate these artifacts. Moreover, in order to facilitate an interactive user-interface, we present a fast algorithm for calculating the Peirce quincuncial projection of spherical imagery. We then promote the Peirce quincuncial projection as a viable alternative to the more popular stereographic projection in some scenarios.\n    ",
        "submission_date": "2010-11-14T00:00:00",
        "last_modified_date": "2015-09-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1011.4058",
        "title": "Modeling Image Structure with Factorized Phase-Coupled Boltzmann Machines",
        "authors": [
            "Charles F. Cadieu",
            "Kilian Koepsell"
        ],
        "abstract": "We describe a model for capturing the statistical structure of local amplitude and local spatial phase in natural images. The model is based on a recently developed, factorized third-order Boltzmann machine that was shown to be effective at capturing higher-order structure in images by modeling dependencies among squared filter outputs (Ranzato and Hinton, 2010). Here, we extend this model to $L_p$-spherically symmetric subspaces. In order to model local amplitude and phase structure in images, we focus on the case of two dimensional subspaces, and the $L_2$-norm. When trained on natural images the model learns subspaces resembling quadrature-pair Gabor filters. We then introduce an additional set of hidden units that model the dependencies among subspace phases. These hidden units form a combinatorial mixture of phase coupling distributions, concentrated in the sum and difference of phase pairs. When adapted to natural images, these distributions capture local spatial phase structure in natural images.\n    ",
        "submission_date": "2010-11-17T00:00:00",
        "last_modified_date": "2010-11-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1011.4321",
        "title": "A Fuzzy Clustering Model for Fuzzy Data with Outliers",
        "authors": [
            "M.H.Fazel Zarandi",
            "Zahra S. Razaee"
        ],
        "abstract": "In this paper a fuzzy clustering model for fuzzy data with outliers is proposed. The model is based on Wasserstein distance between interval valued data which is generalized to fuzzy data. In addition, Keller's approach is used to identify outliers and reduce their influences. We have also defined a transformation to change our distance to the Euclidean distance. With the help of this approach, the problem of fuzzy clustering of fuzzy data is reduced to fuzzy clustering of crisp data. In order to show the performance of the proposed clustering algorithm, two simulation experiments are discussed.\n    ",
        "submission_date": "2010-11-18T00:00:00",
        "last_modified_date": "2010-11-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1011.4615",
        "title": "Generalized Tree-Based Wavelet Transform",
        "authors": [
            "Idan Ram",
            "Michael Elad",
            "Israel Cohen"
        ],
        "abstract": "In this paper we propose a new wavelet transform applicable to functions defined on graphs, high dimensional data and networks. The proposed method generalizes the Haar-like transform proposed in [1], and it is defined via a hierarchical tree, which is assumed to capture the geometry and structure of the input data. It is applied to the data using a modified version of the common one-dimensional (1D) wavelet filtering and decimation scheme, which can employ different wavelet filters. In each level of this wavelet decomposition scheme, a permutation derived from the tree is applied to the approximation coefficients, before they are filtered. We propose a tree construction method that results in an efficient representation of the input function in the transform domain. We show that the proposed transform is more efficient than both the 1D and two-dimensional (2D) separable wavelet transforms in representing images. We also explore the application of the proposed transform to image denoising, and show that combined with a subimage averaging scheme, it achieves denoising results which are similar to those obtained with the K-SVD algorithm.\n    ",
        "submission_date": "2010-11-20T00:00:00",
        "last_modified_date": "2011-02-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1011.5694",
        "title": "Formulation Of A N-Degree Polynomial For Depth Estimation using a Single Image",
        "authors": [
            "Kaushik K Tiwari"
        ],
        "abstract": "The depth of a visible surface of a scene is the distance between the surface and the sensor. Recovering depth information from two-dimensional images of a scene is an important task in computer vision that can assist numerous applications such as object recognition, scene interpretation, obstacle avoidance, inspection and assembly. Various passive depth computation techniques have been developed for computer vision applications. They can be classified into two groups. The first group operates using just one image. The second group requires more than one image which can be acquired using either multiple cameras or a camera whose parameters and positioning can be changed. This project is aimed to find the real depth of the object from the camera which had been used to click the photograph. An n-degree polynomial was formulated, which maps the pixel depth of an image to the real depth. In order to find the coefficients of the polynomial, an experiment was carried out for a particular lens and thus, these coefficients are a unique feature of a particular camera. The procedure explained in this report is a monocular approach for estimation of depth of a scene. The idea involves mapping the Pixel Depth of the object photographed in the image with the Real Depth of the object from the camera lens with an interpolation function. In order to find the parameters of the interpolation function, a set of lines with predefined distance from camera is used, and then the distance of each line from the bottom edge of the picture (as the origin line) is calculated.\n    ",
        "submission_date": "2010-11-26T00:00:00",
        "last_modified_date": "2010-11-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1011.5962",
        "title": "Edge Preserving Image Denoising in Reproducing Kernel Hilbert Spaces",
        "authors": [
            "Pantelis Bouboulis",
            "Sergios Theodoridis"
        ],
        "abstract": "The goal of this paper is the development of a novel approach for the problem of Noise Removal, based on the theory of Reproducing Kernels Hilbert Spaces (RKHS). The problem is cast as an optimization task in a RKHS, by taking advantage of the celebrated semiparametric Representer Theorem. Examples verify that in the presence of gaussian noise the proposed method performs relatively well compared to wavelet based technics and outperforms them significantly in the presence of impulse or mixed noise.\n",
        "submission_date": "2010-11-27T00:00:00",
        "last_modified_date": "2010-11-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1011.6656",
        "title": "Learning sparse representations of depth",
        "authors": [
            "Ivana Tosic",
            "Bruno A. Olshausen",
            "Benjamin J. Culpepper"
        ],
        "abstract": "This paper introduces a new method for learning and inferring sparse representations of depth (disparity) maps. The proposed algorithm relaxes the usual assumption of the stationary noise model in sparse coding. This enables learning from data corrupted with spatially varying noise or uncertainty, typically obtained by laser range scanners or structured light depth cameras. Sparse representations are learned from the Middlebury database disparity maps and then exploited in a two-layer graphical model for inferring depth from stereo, by including a sparsity prior on the learned features. Since they capture higher-order dependencies in the depth structure, these priors can complement smoothness priors commonly used in depth inference based on Markov Random Field (MRF) models. Inference on the proposed graph is achieved using an alternating iterative optimization technique, where the first layer is solved using an existing MRF-based stereo matching algorithm, then held fixed as the second layer is solved using the proposed non-stationary sparse coding algorithm. This leads to a general method for improving solutions of state of the art MRF-based depth estimation algorithms. Our experimental results first show that depth inference using learned representations leads to state of the art denoising of depth maps obtained from laser range scanners and a time of flight camera. Furthermore, we show that adding sparse priors improves the results of two depth estimation methods: the classical graph cut algorithm by Boykov et al. and the more recent algorithm of Woodford et al.\n    ",
        "submission_date": "2010-11-30T00:00:00",
        "last_modified_date": "2011-04-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1012.0223",
        "title": "An Effective Method of Image Retrieval using Image Mining Techniques",
        "authors": [
            "A. Kannan",
            "V. Mohan",
            "N. Anbazhagan"
        ],
        "abstract": "The present research scholars are having keen interest in doing their research activities in the area of Data mining all over the world. Especially, [13]Mining Image data is the one of the essential features in this present scenario since image data plays vital role in every aspect of the system such as business for marketing, hospital for surgery, engineering for construction, Web for publication and so on. The other area in the Image mining system is the Content-Based Image Retrieval (CBIR) which performs retrieval based on the similarity defined in terms of extracted features with more objectiveness. The drawback in CBIR is the features of the query image alone are considered. Hence, a new technique called Image retrieval based on optimum clusters is proposed for improving user interaction with image retrieval systems by fully exploiting the similarity information. The index is created by describing the images according to their color characteristics, with compact feature vectors, that represent typical color distributions [12].\n    ",
        "submission_date": "2010-12-01T00:00:00",
        "last_modified_date": "2010-12-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1012.1184",
        "title": "Image Deblurring and Super-resolution by Adaptive Sparse Domain Selection and Adaptive Regularization",
        "authors": [
            "Weisheng Dong",
            "Lei Zhang",
            "Guangming Shi",
            "Xiaolin Wu"
        ],
        "abstract": "As a powerful statistical image modeling technique, sparse representation has been successfully used in various image restoration applications. The success of sparse representation owes to the development of l1-norm optimization techniques, and the fact that natural images are intrinsically sparse in some domain. The image restoration quality largely depends on whether the employed sparse domain can represent well the underlying image. Considering that the contents can vary significantly across different images or different patches in a single image, we propose to learn various sets of bases from a pre-collected dataset of example image patches, and then for a given patch to be processed, one set of bases are adaptively selected to characterize the local sparse domain. We further introduce two adaptive regularization terms into the sparse representation framework. First, a set of autoregressive (AR) models are learned from the dataset of example image patches. The best fitted AR models to a given patch are adaptively selected to regularize the image local structures. Second, the image non-local self-similarity is introduced as another regularization term. In addition, the sparsity regularization parameter is adaptively estimated for better image restoration performance. Extensive experiments on image deblurring and super-resolution validate that by using adaptive sparse domain selection and adaptive regularization, the proposed method achieves much better results than many state-of-the-art algorithms in terms of both PSNR and visual perception.\n    ",
        "submission_date": "2010-12-06T00:00:00",
        "last_modified_date": "2010-12-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1012.1193",
        "title": "Automatic Image Segmentation by Dynamic Region Merging",
        "authors": [
            "Bo Peng",
            "Lei Zhang",
            "David Zhang"
        ],
        "abstract": "This paper addresses the automatic image segmentation problem in a region merging style. With an initially over-segmented image, in which the many regions (or super-pixels) with homogeneous color are detected, image segmentation is performed by iteratively merging the regions according to a statistical test. There are two essential issues in a region merging algorithm: order of merging and the stopping criterion. In the proposed algorithm, these two issues are solved by a novel predicate, which is defined by the sequential probability ratio test (SPRT) and the maximum likelihood criterion. Starting from an over-segmented image, neighboring regions are progressively merged if there is an evidence for merging according to this predicate. We show that the merging order follows the principle of dynamic programming. This formulates image segmentation as an inference problem, where the final segmentation is established based on the observed image. We also prove that the produced segmentation satisfies certain global properties. In addition, a faster algorithm is developed to accelerate the region merging process, which maintains a nearest neighbor graph in each iteration. Experiments on real natural images are conducted to demonstrate the performance of the proposed dynamic region merging algorithm.\n    ",
        "submission_date": "2010-12-06T00:00:00",
        "last_modified_date": "2010-12-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1012.2138",
        "title": "Sparse motion segmentation using multiple six-point consistencies",
        "authors": [
            "Vasileios Zografos",
            "Klas Nordberg",
            "Liam Ellis"
        ],
        "abstract": "We present a method for segmenting an arbitrary number of moving objects in image sequences using the geometry of 6 points in 2D to infer motion consistency. The method has been evaluated on the Hopkins 155 database and surpasses current state-of-the-art methods such as SSC, both in terms of overall performance on two and three motions but also in terms of maximum errors. The method works by finding initial clusters in the spatial domain, and then classifying each remaining point as belonging to the cluster that minimizes a motion consistency score. In contrast to most other motion segmentation methods that are based on an affine camera model, the proposed method is fully projective.\n    ",
        "submission_date": "2010-12-09T00:00:00",
        "last_modified_date": "2010-12-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1012.2491",
        "title": "Affine Invariant, Model-Based Object Recognition Using Robust Metrics and Bayesian Statistics",
        "authors": [
            "Vasileios Zografos",
            "Bernard Buxton"
        ],
        "abstract": "We revisit the problem of model-based object recognition for intensity images and attempt to address some of the shortcomings of existing Bayesian methods, such as unsuitable priors and the treatment of residuals with a non-robust error norm. We do so by using a refor- mulation of the Huber metric and carefully chosen prior distributions. Our proposed method is invariant to 2-dimensional affine transforma- tions and, because it is relatively easy to train and use, it is suited for general object matching problems.\n    ",
        "submission_date": "2010-12-11T00:00:00",
        "last_modified_date": "2010-12-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1012.2603",
        "title": "Real-time Visual Tracking Using Sparse Representation",
        "authors": [
            "Hanxi Li",
            "Chunhua Shen",
            "Qinfeng Shi"
        ],
        "abstract": "The $\\ell_1$ tracker obtains robustness by seeking a sparse representation of the tracking object via $\\ell_1$ norm minimization \\cite{Xue_ICCV_09_Track}. However, the high computational complexity involved in the $ \\ell_1 $ tracker restricts its further applications in real time processing scenario. Hence we propose a Real Time Compressed Sensing Tracking (RTCST) by exploiting the signal recovery power of Compressed Sensing (CS). Dimensionality reduction and a customized Orthogonal Matching Pursuit (OMP) algorithm are adopted to accelerate the CS tracking. As a result, our algorithm achieves a real-time speed that is up to $6,000$ times faster than that of the $\\ell_1$ tracker. Meanwhile, RTCST still produces competitive (sometimes even superior) tracking accuracy comparing to the existing $\\ell_1$ tracker. Furthermore, for a stationary camera, a further refined tracker is designed by integrating a CS-based background model (CSBM). This CSBM-equipped tracker coined as RTCST-B, outperforms most state-of-the-arts with respect to both accuracy and robustness. Finally, our experimental results on various video sequences, which are verified by a new metric---Tracking Success Probability (TSP), show the excellence of the proposed algorithms.\n    ",
        "submission_date": "2010-12-12T00:00:00",
        "last_modified_date": "2010-12-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1012.3216",
        "title": "TILT: Transform Invariant Low-rank Textures",
        "authors": [
            "Zhengdong Zhang",
            "Arvind Ganesh",
            "Xiao Liang",
            "Yi Ma"
        ],
        "abstract": "In this paper, we show how to efficiently and effectively extract a class of \"low-rank textures\" in a 3D scene from 2D images despite significant corruptions and warping. The low-rank textures capture geometrically meaningful structures in an image, which encompass conventional local features such as edges and corners as well as all kinds of regular, symmetric patterns ubiquitous in urban environments and man-made objects. Our approach to finding these low-rank textures leverages the recent breakthroughs in convex optimization that enable robust recovery of a high-dimensional low-rank matrix despite gross sparse errors. In the case of planar regions with significant affine or projective deformation, our method can accurately recover both the intrinsic low-rank texture and the precise domain transformation, and hence the 3D geometry and appearance of the planar regions. Extensive experimental results demonstrate that this new technique works effectively for many regular and near-regular patterns or objects that are approximately low-rank, such as symmetrical patterns, building facades, printed texts, and human faces.\n    ",
        "submission_date": "2010-12-15T00:00:00",
        "last_modified_date": "2010-12-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1012.3802",
        "title": "Detecting Image Forgeries using Geometric Cues",
        "authors": [
            "Lin Wu",
            "Yang Wang"
        ],
        "abstract": "This chapter presents a framework for detecting fake regions by using various methods including watermarking technique and blind approaches. In particular, we describe current categories on blind approaches which can be divided into five: pixel-based techniques, format-based techniques, camera-based techniques, physically-based techniques and geometric-based techniques. Then we take a second look on the geometric-based techniques and further categorize them in detail. In the following section, the state-of-the-art methods involved in the geometric technique are elaborated.\n    ",
        "submission_date": "2010-12-17T00:00:00",
        "last_modified_date": "2010-12-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1012.3951",
        "title": "Diffusion-geometric maximally stable component detection in deformable shapes",
        "authors": [
            "Roee Litman",
            "Alex M. Bronstein",
            "Michael M. Bronstein"
        ],
        "abstract": "Maximally stable component detection is a very popular method for feature analysis in images, mainly due to its low computation cost and high repeatability. With the recent advance of feature-based methods in geometric shape analysis, there is significant interest in finding analogous approaches in the 3D world. In this paper, we formulate a diffusion-geometric framework for stable component detection in non-rigid 3D shapes, which can be used for geometric feature detection and description. A quantitative evaluation of our method on the SHREC'10 feature detection benchmark shows its potential as a source of high-quality features.\n    ",
        "submission_date": "2010-12-17T00:00:00",
        "last_modified_date": "2010-12-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1012.5208",
        "title": "Texture feature extraction in the spatial-frequency domain for content-based image retrieval",
        "authors": [
            "Nadia Baaziz",
            "Omar Abahmane",
            "Rokia Missaoui"
        ],
        "abstract": "The advent of large scale multimedia databases has led to great challenges in content-based image retrieval (CBIR). Even though CBIR is considered an emerging field of research, however it constitutes a strong background for new methodologies and systems implementations. Therefore, many research contributions are focusing on techniques enabling higher image retrieval accuracy while preserving low level of computational complexity. Image retrieval based on texture features is receiving special attention because of the omnipresence of this visual feature in most real-world images. This paper highlights the state-of-the-art and current progress relevant to texture-based image retrieval and spatial-frequency image representations. In particular, it gives an overview of statistical methodologies and techniques employed for texture feature extraction using most popular spatial-frequency image transforms, namely discrete wavelets, Gabor wavelets, dual-tree complex wavelet and contourlets. Indications are also given about used similarity measurement functions and most important achieved results.\n    ",
        "submission_date": "2010-12-23T00:00:00",
        "last_modified_date": "2010-12-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1012.5933",
        "title": "Affine-invariant diffusion geometry for the analysis of deformable 3D shapes",
        "authors": [
            "Dan Raviv",
            "Alexander M. Bronstein",
            "Michael M. Bronstein",
            "Ron Kimmel",
            "Nir Sochen"
        ],
        "abstract": "We introduce an (equi-)affine invariant diffusion geometry by which surfaces that go through squeeze and shear transformations can still be properly analyzed. The definition of an affine invariant metric enables us to construct an invariant Laplacian from which local and global geometric structures are extracted. Applications of the proposed framework demonstrate its power in generalizing and enriching the existing set of tools for shape analysis.\n    ",
        "submission_date": "2010-12-29T00:00:00",
        "last_modified_date": "2010-12-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1012.5936",
        "title": "Affine-invariant geodesic geometry of deformable 3D shapes",
        "authors": [
            "Dan Raviv",
            "Alexander M. Bronstein",
            "Michael M. Bronstein",
            "Ron Kimmel",
            "Nir Sochen"
        ],
        "abstract": "Natural objects can be subject to various transformations yet still preserve properties that we refer to as invariants. Here, we use definitions of affine invariant arclength for surfaces in R^3 in order to extend the set of existing non-rigid shape analysis tools. In fact, we show that by re-defining the surface metric as its equi-affine version, the surface with its modified metric tensor can be treated as a canonical Euclidean object on which most classical Euclidean processing and analysis tools can be applied. The new definition of a metric is used to extend the fast marching method technique for computing geodesic distances on surfaces, where now, the distances are defined with respect to an affine invariant arclength. Applications of the proposed framework demonstrate its invariance, efficiency, and accuracy in shape analysis.\n    ",
        "submission_date": "2010-12-29T00:00:00",
        "last_modified_date": "2010-12-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1001.0591",
        "title": "Comparing Distributions and Shapes using the Kernel Distance",
        "authors": [
            "Sarang Joshi",
            "Raj Varma Kommaraju",
            "Jeff M. Phillips",
            "Suresh Venkatasubramanian"
        ],
        "abstract": "Starting with a similarity function between objects, it is possible to define a distance metric on pairs of objects, and more generally on probability distributions over them. These distance metrics have a deep basis in functional analysis, measure theory and geometric measure theory, and have a rich structure that includes an isometric embedding into a (possibly infinite dimensional) Hilbert space. They have recently been applied to numerous problems in machine learning and shape analysis.\n",
        "submission_date": "2010-01-04T00:00:00",
        "last_modified_date": "2011-03-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1001.1020",
        "title": "An Empirical Evaluation of Four Algorithms for Multi-Class Classification: Mart, ABC-Mart, Robust LogitBoost, and ABC-LogitBoost",
        "authors": [
            "Ping Li"
        ],
        "abstract": "  This empirical study is mainly devoted to comparing four tree-based boosting algorithms: mart, abc-mart, robust logitboost, and abc-logitboost, for multi-class classification on a variety of publicly available datasets. Some of those datasets have been thoroughly tested in prior studies using a broad range of classification algorithms including SVM, neural nets, and deep learning.\n",
        "submission_date": "2010-01-07T00:00:00",
        "last_modified_date": "2010-01-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1001.1972",
        "title": "A New Image Steganography Based On First Component Alteration Technique",
        "authors": [
            "Amanpreet Kaur",
            "Renu Dhir",
            "Geeta Sikka"
        ],
        "abstract": "  In this paper, A new image steganography scheme is proposed which is a kind of spatial domain technique. In order to hide secret data in cover-image, the first component alteration technique is used. Techniques used so far focuses only on the two or four bits of a pixel in a image (at the most five bits at the edge of an image) which results in less peak to signal noise ratio and high root mean square error. In this technique, 8 bits of blue components of pixels are replaced with secret data bits. Proposed scheme can embed more data than previous schemes and shows better image quality. To prove this scheme, several experiments are performed, and are compared the experimental results with the related previous works.\n    ",
        "submission_date": "2010-01-12T00:00:00",
        "last_modified_date": "2010-01-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1002.1727",
        "title": "An Improved DC Recovery Method from AC Coefficients of DCT-Transformed Images",
        "authors": [
            "Shujun Li",
            "Junaid Jameel Ahmad",
            "Dietmar Saupe",
            "C.-C. Jay Kuo"
        ],
        "abstract": "Motivated by the work of Uehara et al. [1], an improved method to recover DC coefficients from AC coefficients of DCT-transformed images is investigated in this work, which finds applications in cryptanalysis of selective multimedia encryption. The proposed under/over-flow rate minimization (FRM) method employs an optimization process to get a statistically more accurate estimation of unknown DC coefficients, thus achieving a better recovery performance. It was shown by experimental results based on 200 test images that the proposed DC recovery method significantly improves the quality of most recovered images in terms of the PSNR values and several state-of-the-art objective image quality assessment (IQA) metrics such as SSIM and MS-SSIM.\n    ",
        "submission_date": "2010-02-08T00:00:00",
        "last_modified_date": "2010-06-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1002.2184",
        "title": "The Fast Haar Wavelet Transform for Signal & Image Processing",
        "authors": [
            "V. Ashok",
            "T. Balakumaran",
            "C. Gowrishankar",
            "I.L.A. Vennila",
            "A. Nirmal kumar"
        ],
        "abstract": "  A method for the design of Fast Haar wavelet for signal processing and image processing has been proposed. In the proposed work, the analysis bank and synthesis bank of Haar wavelet is modified by using polyphase structure. Finally, the Fast Haar wavelet was designed and it satisfies alias free and perfect reconstruction condition. Computational time and computational complexity is reduced in Fast Haar wavelet transform.\n    ",
        "submission_date": "2010-02-10T00:00:00",
        "last_modified_date": "2010-02-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1002.2191",
        "title": "Vision Based Game Development Using Human Computer Interaction",
        "authors": [
            "S. Sumathi",
            "S. K. Srivatsa",
            "M. Uma Maheswari"
        ],
        "abstract": "  A Human Computer Interface (HCI) System for playing games is designed here for more natural communication with the machines. The system presented here is a vision-based system for detection of long voluntary eye blinks and interpretation of blink patterns for communication between man and machine. This system replaces the mouse with the human face as a new way to interact with the computer. Facial features (nose tip and eyes) are detected and tracked in realtime to use their actions as mouse events. The coordinates and movement of the nose tip in the live video feed are translated to become the coordinates and movement of the mouse pointer on the application. The left or right eye blinks fire left or right mouse click events. The system works with inexpensive USB cameras and runs at a frame rate of 30 frames per second.\n    ",
        "submission_date": "2010-02-10T00:00:00",
        "last_modified_date": "2010-02-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1002.2959",
        "title": "Geometric approach to sampling and communication",
        "authors": [
            "Emil Saucan",
            "Eli Appleboim",
            "Yehoshua Y. Zeevi"
        ],
        "abstract": "  Relationships that exist between the classical, Shannon-type, and geometric-based approaches to sampling are investigated. Some aspects of coding and communication through a Gaussian channel are considered. In particular, a constructive method to determine the quantizing dimension in Zador's theorem is provided. A geometric version of Shannon's Second Theorem is introduced. Applications to Pulse Code Modulation and Vector Quantization of Images are addressed.\n    ",
        "submission_date": "2010-02-15T00:00:00",
        "last_modified_date": "2010-02-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1002.4046",
        "title": "Supervised Classification Performance of Multispectral Images",
        "authors": [
            "K. Perumal",
            "R. Bhaskaran"
        ],
        "abstract": "  Nowadays government and private agencies use remote sensing imagery for a wide range of applications from military applications to farm development. The images may be a panchromatic, multispectral, hyperspectral or even ultraspectral of terra bytes. Remote sensing image classification is one amongst the most significant application worlds for remote sensing. A few number of image classification algorithms have proved good precision in classifying remote sensing data. But, of late, due to the increasing spatiotemporal dimensions of the remote sensing data, traditional classification algorithms have exposed weaknesses necessitating further research in the field of remote sensing image classification. So an efficient classifier is needed to classify the remote sensing images to extract information. We are experimenting with both supervised and unsupervised classification. Here we compare the different classification methods and their performances. It is found that Mahalanobis classifier performed the best in our classification.\n    ",
        "submission_date": "2010-02-22T00:00:00",
        "last_modified_date": "2010-02-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1003.0529",
        "title": "A Unified Algorithmic Framework for Multi-Dimensional Scaling",
        "authors": [
            "Arvind Agarwal",
            "Jeff M. Phillips",
            "Suresh Venkatasubramanian"
        ],
        "abstract": "  In this paper, we propose a unified algorithmic framework for solving many known variants of \\mds. Our algorithm is a simple iterative scheme with guaranteed convergence, and is \\emph{modular}; by changing the internals of a single subroutine in the algorithm, we can switch cost functions and target spaces easily. In addition to the formal guarantees of convergence, our algorithms are accurate; in most cases, they converge to better quality solutions than existing methods, in comparable time. We expect that this framework will be useful for a number of \\mds variants that have not yet been studied.\n",
        "submission_date": "2010-03-02T00:00:00",
        "last_modified_date": "2010-03-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1003.0723",
        "title": "Securing Interactive Sessions Using Mobile Device through Visual Channel and Visual Inspection",
        "authors": [
            "Chengfang Fang",
            "Ee-Chien Chang"
        ],
        "abstract": "Communication channel established from a display to a device's camera is known as visual channel, and it is helpful in securing key exchange protocol. In this paper, we study how visual channel can be exploited by a network terminal and mobile device to jointly verify information in an interactive session, and how such information can be jointly presented in a user-friendly manner, taking into account that the mobile device can only capture and display a small region, and the user may only want to authenticate selective regions-of-interests. Motivated by applications in Kiosk computing and multi-factor authentication, we consider three security models: (1) the mobile device is trusted, (2) at most one of the terminal or the mobile device is dishonest, and (3) both the terminal and device are dishonest but they do not collude or communicate. We give two protocols and investigate them under the abovementioned models. We point out a form of replay attack that renders some other straightforward implementations cumbersome to use. To enhance user-friendliness, we propose a solution using visual cues embedded into the 2D barcodes and incorporate the framework of \"augmented reality\" for easy verifications through visual inspection. We give a proof-of-concept implementation to show that our scheme is feasible in practice.\n    ",
        "submission_date": "2010-03-03T00:00:00",
        "last_modified_date": "2010-07-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1003.1458",
        "title": "Secured Cryptographic Key Generation From Multimodal Biometrics: Feature Level Fusion of Fingerprint and Iris",
        "authors": [
            "A. Jagadeesan",
            "K.Duraiswamy"
        ],
        "abstract": "Human users have a tough time remembering long cryptographic keys. Hence, researchers, for so long, have been examining ways to utilize biometric features of the user instead of a memorable password or passphrase, in an effort to generate strong and repeatable cryptographic keys. Our objective is to incorporate the volatility of the user's biometric features into the generated key, so as to make the key unguessable to an attacker lacking significant knowledge of the user's biometrics. We go one step further trying to incorporate multiple biometric modalities into cryptographic key generation so as to provide better security. In this article, we propose an efficient approach based on multimodal biometrics (Iris and fingerprint) for generation of secure cryptographic key. The proposed approach is composed of three modules namely, 1) Feature extraction, 2) Multimodal biometric template generation and 3) Cryptographic key generation. Initially, the features, minutiae points and texture properties are extracted from the fingerprint and iris images respectively. Subsequently, the extracted features are fused together at the feature level to construct the multi-biometric template. Finally, a 256-bit secure cryptographic key is generated from the multi-biometric template. For experimentation, we have employed the fingerprint images obtained from publicly available sources and the iris images from CASIA Iris Database. The experimental results demonstrate the effectiveness of the proposed approach.\n    ",
        "submission_date": "2010-03-07T00:00:00",
        "last_modified_date": "2010-03-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1003.4781",
        "title": "Large Margin Boltzmann Machines and Large Margin Sigmoid Belief Networks",
        "authors": [
            "Xu Miao",
            "Rajesh P.N. Rao"
        ],
        "abstract": "Current statistical models for structured prediction make simplifying assumptions about the underlying output graph structure, such as assuming a low-order Markov chain, because exact inference becomes intractable as the tree-width of the underlying graph increases. Approximate inference algorithms, on the other hand, force one to trade off representational power with computational efficiency. In this paper, we propose two new types of probabilistic graphical models, large margin Boltzmann machines (LMBMs) and large margin sigmoid belief networks (LMSBNs), for structured prediction. LMSBNs in particular  allow a very fast inference algorithm for arbitrary graph structures that runs in polynomial time with a high probability. This probability is data-distribution dependent and is maximized in learning. The new approach overcomes the representation-efficiency trade-off in previous models and allows fast structured prediction with complicated graph structures. We present results from applying a fully connected model to multi-label scene classification and demonstrate that the proposed approach can yield significant performance gains over current state-of-the-art methods.\n    ",
        "submission_date": "2010-03-25T00:00:00",
        "last_modified_date": "2010-03-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1004.0258",
        "title": "Trends and Techniques in Visual Gaze Analysis",
        "authors": [
            "Sophie Stellmach",
            "Lennart E. Nacke",
            "Raimund Dachselt",
            "Craig A. Lindley"
        ],
        "abstract": "Visualizing gaze data is an effective way for the quick interpretation of eye tracking results. This paper presents a study investigation benefits and limitations of visual gaze analysis among eye tracking professionals and researchers. The results were used to create a tool for visual gaze analysis within a Master's project.\n    ",
        "submission_date": "2010-04-01T00:00:00",
        "last_modified_date": "2010-04-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1004.1789",
        "title": "SAR Image Segmentation using Vector Quantization Technique on Entropy Images",
        "authors": [
            "H. B. Kekre",
            "Saylee Gharge",
            "Tanuja K. Sarode"
        ],
        "abstract": "The development and application of various remote sensing platforms result in the production of huge amounts of satellite image data. Therefore, there is an increasing need for effective querying and browsing in these image databases. In order to take advantage and make good use of satellite images data, we must be able to extract meaningful information from the imagery. Hence we proposed a new algorithm for SAR image segmentation. In this paper we propose segmentation using vector quantization technique on entropy image. Initially, we obtain entropy image and in second step we use Kekre's Fast Codebook Generation (KFCG) algorithm for segmentation of the entropy image. Thereafter, a codebook of size 128 was generated for the Entropy image. These code vectors were further clustered in 8 clusters using same KFCG algorithm and converted into 8 images. These 8 images were displayed as a result. This approach does not lead to over segmentation or under segmentation. We compared these results with well known Gray Level Co-occurrence Matrix. The proposed algorithm gives better segmentation with less complexity.\n    ",
        "submission_date": "2010-04-11T00:00:00",
        "last_modified_date": "2010-04-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1004.4965",
        "title": "Many-to-Many Graph Matching: a Continuous Relaxation Approach",
        "authors": [
            "Mikhail Zaslavskiy",
            "Francis Bach",
            "Jean-Philippe Vert"
        ],
        "abstract": "Graphs provide an efficient tool for object representation in various computer vision applications. Once graph-based representations are constructed, an important question is how to compare graphs. This problem is often formulated as a graph matching problem where one seeks a mapping between vertices of two graphs which optimally aligns their structure. In the classical formulation of graph matching, only one-to-one correspondences between vertices are considered. However, in many applications, graphs cannot be matched perfectly and it is more interesting to consider many-to-many correspondences where clusters of vertices in one graph are matched to clusters of vertices in the other graph. In this paper, we formulate the many-to-many graph matching problem as a discrete optimization problem and propose an approximate algorithm based on a continuous relaxation of the combinatorial problem. We compare our method with other existing methods on several benchmark computer vision datasets.\n    ",
        "submission_date": "2010-04-28T00:00:00",
        "last_modified_date": "2010-04-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1004.5305",
        "title": "Compressed Sensing with off-axis frequency-shifting holography",
        "authors": [
            "Marcio Marim",
            "Michael Atlan",
            "Elsa Angelini",
            "Jean-Christophe Olivo-Marin"
        ],
        "abstract": "This work reveals an experimental microscopy acquisition scheme successfully combining Compressed Sensing (CS) and digital holography in off-axis and frequency-shifting conditions. CS is a recent data acquisition theory involving signal reconstruction from randomly undersampled measurements, exploiting the fact that most images present some compact structure and redundancy. We propose a genuine CS-based imaging scheme for sparse gradient images, acquiring a diffraction map of the optical field with holographic microscopy and recovering the signal from as little as 7% of random measurements. We report experimental results demonstrating how CS can lead to an elegant and effective way to reconstruct images, opening the door for new microscopy applications.\n    ",
        "submission_date": "2010-04-29T00:00:00",
        "last_modified_date": "2010-04-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1004.5538",
        "title": "Bayesian estimation of regularization and PSF parameters for Wiener-Hunt deconvolution",
        "authors": [
            "Francois Orieux",
            "Jean-Francois Giovannelli",
            "Thomas Rodet"
        ],
        "abstract": "This paper tackles the problem of image deconvolution with joint estimation of PSF parameters and hyperparameters. Within a Bayesian framework, the solution is inferred via a global a posteriori law for unknown parameters and object. The estimate is chosen as the posterior mean, numerically calculated by means of a Monte-Carlo Markov chain algorithm. The estimates are efficiently computed in the Fourier domain and the effectiveness of the method is shown on simulated examples.  Results show precise estimates for PSF parameters and hyperparameters as well as precise image estimates including restoration of high-frequencies and spatial details, within a global and coherent approach.\n    ",
        "submission_date": "2010-04-30T00:00:00",
        "last_modified_date": "2010-04-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1005.0069",
        "title": "Perturbation Resilience and Superiorization of Iterative Algorithms",
        "authors": [
            "Y. Censor",
            "R. Davidi",
            "G.T. Herman"
        ],
        "abstract": "Iterative algorithms aimed at solving some problems are discussed. For certain problems, such as finding a common point in the intersection of a finite number of convex sets, there often exist iterative algorithms that impose very little demand on computer resources. For other problems, such as finding that point in the intersection at which the value of a given function is optimal, algorithms tend to need more computer memory and longer execution time. A methodology is presented whose aim is to produce automatically for an iterative algorithm of the first kind a \"superiorized version\" of it that retains its computational efficiency but nevertheless goes a long way towards solving an optimization problem. This is possible to do if the original algorithm is \"perturbation resilient,\" which is shown to be the case for various projection algorithms for solving the consistent convex feasibility problem. The superiorized versions of such algorithms use perturbations that drive the process in the direction of the optimizer of the given function. After presenting these intuitive ideas in a precise mathematical form, they are illustrated in image reconstruction from projections for two different projection algorithms superiorized for the function whose value is the total variation of the image.\n    ",
        "submission_date": "2010-05-01T00:00:00",
        "last_modified_date": "2010-05-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1005.0527",
        "title": "Detecting the Most Unusual Part of Two and Three-dimensional Digital Images",
        "authors": [
            "Kostadin Koroutchev",
            "Elka Korutcheva"
        ],
        "abstract": "The purpose of this paper is to introduce an algorithm that can detect the most unusual part of a digital image in probabilistic setting. The most unusual part of a given shape is defined as a part of the image that has the maximal distance to all non intersecting shapes with the same form. The method is tested on two and three-dimensional images and has shown very good results without any predefined model. A version of the method independent of the contrast of the image is considered and is found to be useful for finding the most unusual part (and the most similar part) of the image conditioned on  given image. The results can be used to scan large image databases, as for example medical databases.\n    ",
        "submission_date": "2010-05-03T00:00:00",
        "last_modified_date": "2010-05-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1005.2638",
        "title": "Hierarchical Clustering for Finding Symmetries and Other Patterns in Massive, High Dimensional Datasets",
        "authors": [
            "Fionn Murtagh",
            "Pedro Contreras"
        ],
        "abstract": "Data analysis and data mining are concerned with unsupervised pattern finding and structure determination in data sets.  \"Structure\" can be understood as symmetry and a range of symmetries are expressed by hierarchy.  Such symmetries directly point to invariants, that pinpoint intrinsic properties of the data and of the background empirical domain of interest.  We review many aspects of hierarchy here, including ultrametric topology, generalized ultrametric, linkages with lattices and other discrete algebraic structures and with p-adic number representations.  By focusing on symmetries in data we have a powerful means of structuring and analyzing massive, high dimensional data stores.  We illustrate the powerfulness of hierarchical clustering in case studies in chemistry and finance, and we provide pointers to other published case studies.\n    ",
        "submission_date": "2010-05-14T00:00:00",
        "last_modified_date": "2010-05-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1006.1346",
        "title": "C-HiLasso: A Collaborative Hierarchical Sparse Modeling Framework",
        "authors": [
            "Pablo Sprechmann",
            "Ignacio Ram\u00edrez",
            "Guillermo Sapiro",
            "Yonina Eldar"
        ],
        "abstract": "Sparse modeling is a powerful framework for data analysis and processing. Traditionally, encoding in this framework is performed by solving an L1-regularized linear regression problem, commonly referred to as Lasso or Basis Pursuit. In this work we combine the sparsity-inducing property of the Lasso model at the individual feature level, with the block-sparsity property of the Group Lasso model, where sparse groups of features are jointly encoded, obtaining a sparsity pattern hierarchically structured. This results in the Hierarchical Lasso (HiLasso), which shows important practical modeling advantages. We then extend this approach to the collaborative case, where a set of simultaneously coded signals share the same sparsity pattern at the higher (group) level, but not necessarily at the lower (inside the group) level, obtaining the collaborative HiLasso model (C-HiLasso). Such signals then share the same active groups, or classes, but not necessarily the same active set. This model is very well suited for applications such as source identification and separation. An efficient optimization procedure, which guarantees convergence to the global optimum, is developed for these new models. The underlying presentation of the new framework and optimization approach is complemented with experimental examples and theoretical results regarding recovery guarantees for the proposed models.\n    ",
        "submission_date": "2010-06-07T00:00:00",
        "last_modified_date": "2011-03-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1006.3275",
        "title": "Normalized Information Distance is Not Semicomputable",
        "authors": [
            "Sebastiaan A. Terwijn",
            "Leen Torenvliet",
            "Paul M.B. Vitanyi"
        ],
        "abstract": "Normalized information distance (NID) uses the theoretical notion of Kolmogorov complexity, which for practical purposes is approximated by the length of the compressed version of the file involved, using a real-world compression program. This practical application is called 'normalized compression distance' and it is trivially computable. It is a parameter-free similarity measure based on compression, and is used in pattern recognition, data mining, phylogeny, clustering, and classification. The complexity properties of its theoretical precursor, the NID, have been open. We show that the NID is neither upper semicomputable nor lower semicomputable.\n    ",
        "submission_date": "2010-06-16T00:00:00",
        "last_modified_date": "2010-06-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1006.3403",
        "title": "Image processing of a spectrogram produced by Spectrometer Airglow Temperature Imager",
        "authors": [
            "Atanas Marinov Atanassov"
        ],
        "abstract": "The Spectral Airglow Temperature Imager is an instrument, specially designed for investigation of the wave processes in the Mesosphere-Lower Thermosphere. In order to determine the kinematics parameters of a wave, the values of a physical quantity in different space points and their changes in the time should be known. An approach for image processing of registered spectrograms is proposed. A detailed description is made of the steps of this approach, related to recovering CCD pixel values, influenced by cosmic particles, dark image correction and filter parameters determination.\n    ",
        "submission_date": "2010-06-17T00:00:00",
        "last_modified_date": "2010-06-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1006.3468",
        "title": "Algorithm for Sector Spectra Calculation from Images Registered by the Spectral Airglow Temperature Imager",
        "authors": [
            "Atanas Marinov Atanassov"
        ],
        "abstract": "The Spectral Airglow Temperature Imager is an instrument, specially designed for investigation of the wave processes in the Mesosphere-Lower Thermosphere. In order to determine the kinematic parameters of a wave, the values of a physical quantity in different space points and their changes in the time should be known. As a result of the possibilities of the SATI instrument for space scanning, different parts of the images (sectors of spectrograms) correspond to the respective mesopause areas (where the radiation is generated). Algorithms for sector spectra calculation are proposed. In contrast to the original algorithms where twelve sectors with angles of 30 degrees are only determined now sectors with arbitrary orientation and angles are calculated. An algorithm is presented for sector calculation based on pixel division into sub pixels. A comparative results are shown.\n    ",
        "submission_date": "2010-06-17T00:00:00",
        "last_modified_date": "2011-07-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1006.4330",
        "title": "Large gaps imputation in remote sensed imagery of the environment",
        "authors": [
            "Valeria Rulloni",
            "Oscar Bustos",
            "Ana Georgina Flesia"
        ],
        "abstract": "Imputation of missing data in large regions of satellite imagery is necessary when the acquired image has been damaged by shadows due to clouds, or information gaps produced by sensor failure.\n",
        "submission_date": "2010-06-22T00:00:00",
        "last_modified_date": "2010-06-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1006.4801",
        "title": "Noise Invalidation Denoising",
        "authors": [
            "Soosan Beheshti",
            "Masoud Hashemi",
            "Xiao-Ping Zhang",
            "Nima Nikvand"
        ],
        "abstract": "A denoising technique based on noise invalidation is proposed. The adaptive approach derives a noise signature from the noise order statistics and utilizes the signature to denoise the data. The novelty of this approach is in presenting a general-purpose denoising in the sense that it does not need to employ any particular assumption on the structure of the noise-free signal, such as data smoothness or sparsity of the coefficients. An advantage of the method is in denoising the corrupted data in any complete basis transformation (orthogonal or non-orthogonal). Experimental results show that the proposed method, called Noise Invalidation Denoising (NIDe), outperforms existing denoising approaches in terms of Mean Square Error (MSE).\n    ",
        "submission_date": "2010-06-24T00:00:00",
        "last_modified_date": "2010-06-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1006.5739",
        "title": "Polyharmonic Daubechies type wavelets in Image Processing and Astronomy, II",
        "authors": [
            "Ognyan Kounchev",
            "Damyan Kalaglarsky",
            "Milcho Tsvetkov"
        ],
        "abstract": "We consider the application of the polyharmonic subdivision wavelets (of Daubechies type) to Image Processing, in particular to Astronomical Images. The results show an essential advantage over some standard multivariate wavelets and a potential for better compression.\n    ",
        "submission_date": "2010-06-29T00:00:00",
        "last_modified_date": "2010-06-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1007.0210",
        "title": "Uncertainty of visual measurement and efficient allocation of sensory resources",
        "authors": [
            "Sergei Gepshtein",
            "Ivan Tyukin"
        ],
        "abstract": "We review the reasoning underlying two approaches to combination of sensory uncertainties. First approach is noncommittal, making no assumptions about properties of uncertainty or parameters of stimulation. Then we explain the relationship between this approach and the one commonly used in modeling \"higher level\" aspects of sensory systems, such as in visual cue integration, where assumptions are made about properties of stimulation. The two approaches follow similar logic, except in one case maximal uncertainty is minimized, and in the other minimal certainty is maximized. Then we demonstrate how optimal solutions are found to the problem of resource allocation under uncertainty.\n    ",
        "submission_date": "2010-07-01T00:00:00",
        "last_modified_date": "2014-05-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1008.4662",
        "title": "Automated Acanthamoeba polyphaga detection and computation of Salmonella typhimurium concentration in spatio-temporal images",
        "authors": [
            "George D Tsibidis",
            "Nigel J Burroughs",
            "William Gaze",
            "Elizabeth M H Wellington"
        ],
        "abstract": "Interactions between bacteria and protozoa is an increasing area of interest, however there are a few systems that allow extensive observation of the interactions. We examined a surface system consisting of non nutrient agar with a uniform bacterial lawn that extended over the agar surface, and a spatially localised central population of amoebae. The amoeba fed on bacteria and migrated over the plate. Automated image analysis techniques were used to locate and count amoebae, cysts and bacteria coverage in a series of spatial images. Most algorithms were based on intensity thresholding, or a modification of this idea with probabilistic models. Our strategy was two tiered, we performed an automated analysis for object classification and bacteria counting followed by user intervention/reclassification using custom written Graphical User Interfaces.\n    ",
        "submission_date": "2010-08-27T00:00:00",
        "last_modified_date": "2010-09-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1008.4870",
        "title": "On Euclidean Norm Approximations",
        "authors": [
            "M. Emre Celebi",
            "Fatih Celiker",
            "Hassan A. Kingravi"
        ],
        "abstract": "Euclidean norm calculations arise frequently in scientific and engineering applications. Several approximations for this norm with differing complexity and accuracy have been proposed in the literature. Earlier approaches were based on minimizing the maximum error. Recently, Seol and Cheun proposed an approximation based on minimizing the average error. In this paper, we first examine these approximations in detail, show that they fit into a single mathematical formulation, and compare their average and maximum errors. We then show that the maximum errors given by Seol and Cheun are significantly optimistic.\n    ",
        "submission_date": "2010-08-28T00:00:00",
        "last_modified_date": "2010-08-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1008.5372",
        "title": "Penalty Decomposition Methods for $L0$-Norm Minimization",
        "authors": [
            "Zhaosong Lu",
            "Yong Zhang"
        ],
        "abstract": "In this paper we consider general l0-norm minimization problems, that is, the problems with l0-norm appearing in either objective function or constraint. In particular, we first reformulate the l0-norm constrained problem as an equivalent rank minimization problem and then apply the penalty decomposition (PD) method proposed in [33] to solve the latter problem. By utilizing the special structures, we then transform all matrix operations of this method to vector operations and obtain a PD method that only involves vector operations. Under some suitable assumptions, we establish that any accumulation point of the sequence generated by the PD method satisfies a first-order optimality condition that is generally stronger than one natural optimality condition. We further extend the PD method to solve the problem with the l0-norm appearing in objective function. Finally, we test the performance of our PD methods by applying them to compressed sensing, sparse logistic regression and sparse inverse covariance selection. The computational results demonstrate that our methods generally outperform the existing methods in terms of solution quality and/or speed.\n    ",
        "submission_date": "2010-08-31T00:00:00",
        "last_modified_date": "2012-05-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1009.0051",
        "title": "Variational Iteration Method for Image Restoration",
        "authors": [
            "Keyvan Yahya",
            "Jafar Biazar",
            "Hossein Azari",
            "Pouyan Rafiei Fard"
        ],
        "abstract": "The famous Perona-Malik (P-M) equation which was at first introduced for image restoration has been solved via various numerical methods. In this paper we will solve it for the first time via applying a new numerical method called the Variational Iteration Method (VIM) and the correspondent approximated solutions will be obtained for the P-M equation with regards to relevant error analysis. Through implementation of our algorithm we will access some effective results which are deserved to be considered as worthy as the other solutions issued by the other methods.\n    ",
        "submission_date": "2010-08-31T00:00:00",
        "last_modified_date": "2010-09-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1009.3589",
        "title": "Deep Self-Taught Learning for Handwritten Character Recognition",
        "authors": [
            "Fr\u00e9d\u00e9ric Bastien",
            "Yoshua Bengio",
            "Arnaud Bergeron",
            "Nicolas Boulanger-Lewandowski",
            "Thomas Breuel",
            "Youssouf Chherawala",
            "Moustapha Cisse",
            "Myriam C\u00f4t\u00e9",
            "Dumitru Erhan",
            "Jeremy Eustache",
            "Xavier Glorot",
            "Xavier Muller",
            "Sylvain Pannetier Lebeuf",
            "Razvan Pascanu",
            "Salah Rifai",
            "Francois Savard",
            "Guillaume Sicard"
        ],
        "abstract": "Recent theoretical and empirical work in statistical machine learning has demonstrated the importance of learning algorithms for deep architectures, i.e., function classes obtained by composing multiple non-linear transformations. Self-taught learning (exploiting unlabeled examples or examples from other distributions) has already been applied to deep learners, but mostly to show the advantage of unlabeled examples. Here we explore the advantage brought by {\\em out-of-distribution examples}. For this purpose we developed a powerful generator of stochastic variations and noise processes for character images, including not only affine transformations but also slant, local elastic deformations, changes in thickness, background images, grey level changes, contrast, occlusion, and various types of noise. The out-of-distribution examples are obtained from these highly distorted images or by including examples of object classes different from those in the target test set. We show that {\\em deep learners benefit more from out-of-distribution examples than a corresponding shallow learner}, at least in the area of handwritten character recognition. In fact, we show that they beat previously published results and reach human-level performance on both handwritten digit classification and 62-class handwritten character recognition.\n    ",
        "submission_date": "2010-09-18T00:00:00",
        "last_modified_date": "2010-09-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1009.5750",
        "title": "Use of multiple singular value decompositions to analyze complex intracellular calcium ion signals",
        "authors": [
            "Josue G. Martinez",
            "Jianhua Z. Huang",
            "Robert C. Burghardt",
            "Rola Barhoumi",
            "Raymond J. Carroll"
        ],
        "abstract": "We compare calcium ion signaling ($\\mathrm {Ca}^{2+}$) between two exposures; the data are present as movies, or, more prosaically, time series of images. This paper describes novel uses of singular value decompositions (SVD) and weighted versions of them (WSVD) to extract the signals from such movies, in a way that is semi-automatic and tuned closely to the actual data and their many complexities. These complexities include the following. First, the images themselves are of no interest: all interest focuses on the behavior of individual cells across time, and thus, the cells need to be segmented in an automated manner. Second, the cells themselves have 100$+$ pixels, so that they form 100$+$ curves measured over time, so that data compression is required to extract the features of these curves. Third, some of the pixels in some of the cells are subject to image saturation due to bit depth limits, and this saturation needs to be accounted for if one is to normalize the images in a reasonably unbiased manner. Finally, the $\\mathrm {Ca}^{2+}$ signals have oscillations or waves that vary with time and these signals need to be extracted. Thus, our aim is to show how to use multiple weighted and standard singular value decompositions to detect, extract and clarify the $\\mathrm {Ca}^{2+}$ signals. Our signal extraction methods then lead to simple although finely focused statistical methods to compare $\\mathrm {Ca}^{2+}$ signals across experimental conditions.\n    ",
        "submission_date": "2010-09-28T00:00:00",
        "last_modified_date": "2010-09-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1009.6215",
        "title": "How to Extract the Geometry and Topology from Very Large 3D Segmentations",
        "authors": [
            "Bjoern Andres",
            "Ullrich Koethe",
            "Thorben Kroeger",
            "Fred A. Hamprecht"
        ],
        "abstract": "Segmentation is often an essential intermediate step in image analysis. A volume segmentation characterizes the underlying volume image in terms of geometric information--segments, faces between segments, curves in which several faces meet--as well as a topology on these objects. Existing algorithms encode this information in designated data structures, but require that these data structures fit entirely in Random Access Memory (RAM). Today, 3D images with several billion voxels are acquired, e.g. in structural neurobiology. Since these large volumes can no longer be processed with existing methods, we present a new algorithm which performs geometry and topology extraction with a runtime linear in the number of voxels and log-linear in the number of faces and curves. The parallelizable algorithm proceeds in a block-wise fashion and constructs a consistent representation of the entire volume image on the hard drive, making the structure of very large volume segmentations accessible to image analysis. The parallelized C++ source code, free command line tools and MATLAB mex files are avilable from ",
        "submission_date": "2010-09-30T00:00:00",
        "last_modified_date": "2010-09-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1010.2955",
        "title": "Robust Recovery of Subspace Structures by Low-Rank Representation",
        "authors": [
            "Guangcan Liu",
            "Zhouchen Lin",
            "Shuicheng Yan",
            "Ju Sun",
            "Yong Yu",
            "Yi Ma"
        ],
        "abstract": "In this work we address the subspace recovery problem. Given a set of data samples (vectors) approximately drawn from a union of multiple subspaces, our goal is to segment the samples into their respective subspaces and correct the possible errors as well. To this end, we propose a novel method termed Low-Rank Representation (LRR), which seeks the lowest-rank representation among all the candidates that can represent the data samples as linear combinations of the bases in a given dictionary. It is shown that LRR well solves the subspace recovery problem: when the data is clean, we prove that LRR exactly captures the true subspace structures; for the data contaminated by outliers, we prove that under certain conditions LRR can exactly recover the row space of the original data and detect the outlier as well; for the data corrupted by arbitrary errors, LRR can also approximately recover the row space with theoretical guarantees. Since the subspace membership is provably determined by the row space, these further imply that LRR can perform robust subspace segmentation and error correction, in an efficient way.\n    ",
        "submission_date": "2010-10-14T00:00:00",
        "last_modified_date": "2012-05-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1010.4059",
        "title": "Multiplierless Modules for Forward and Backward Integer Wavelet Transform",
        "authors": [
            "Vasil Kolev"
        ],
        "abstract": "This article is about the architecture of a lossless wavelet filter bank with reprogrammable logic. It is based on second generation of wavelets with a reduced of number of operations. A new basic structure for parallel architecture and modules to forward and backward integer discrete wavelet transform is proposed.\n    ",
        "submission_date": "2010-10-19T00:00:00",
        "last_modified_date": "2021-08-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1011.0997",
        "title": "Performance Analysis of Spectral Clustering on Compressed, Incomplete and Inaccurate Measurements",
        "authors": [
            "Blake Hunter",
            "Thomas Strohmer"
        ],
        "abstract": "Spectral clustering is one of the most widely used techniques for extracting the underlying global structure of a data set. Compressed sensing and matrix completion have emerged as prevailing methods for efficiently recovering sparse and partially observed signals respectively. We combine the distance preserving measurements of compressed sensing and matrix completion with the power of robust spectral clustering. Our analysis provides rigorous bounds on how small errors in the affinity matrix can affect the spectral coordinates and clusterability. This work generalizes the current perturbation results of two-class spectral clustering to incorporate multi-class clustering with k eigenvectors. We thoroughly track how small perturbation from using compressed sensing and matrix completion affect the affinity matrix and in succession the spectral coordinates. These perturbation results for multi-class clustering require an eigengap between the kth and (k+1)th eigenvalues of the affinity matrix, which naturally occurs in data with k well-defined clusters. Our theoretical guarantees are complemented with numerical results along with a number of examples of the unsupervised organization and clustering of image data.\n    ",
        "submission_date": "2010-11-03T00:00:00",
        "last_modified_date": "2010-11-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1011.1876",
        "title": "Statistical mechanics of digital halftoning",
        "authors": [
            "Jun-ichi Inoue",
            "Yohei Saika",
            "Masato Okada"
        ],
        "abstract": "We consider the problem of digital halftoning from the view point of statistical mechanics. The digital halftoning is a sort of image processing, namely, representing each grayscale in terms of black and white binary dots. The digital halftoning is achieved by making use of the threshold mask, namely, for each pixel, the halftoned binary pixel is determined as black if the original grayscale pixel is greater than or equal to the mask value and is determined as white vice versa. To determine the optimal value of the mask on each pixel for a given original grayscale image, we first assume that the human-eyes might recognize the black and white binary halftoned image as the corresponding grayscale one by linear filters. The Hamiltonian is constructed as a distance between the original and the recognized images which is written in terms of the threshold mask. We are confirmed that the system described by the Hamiltonian is regarded as a kind of antiferromagnetic Ising model with quenched disorders. By searching the ground state of the Hamiltonian, we obtain the optimal threshold mask and the resulting halftoned binary dots simultaneously. From the power-spectrum analysis, we find that the binary dots image is physiologically plausible from the view point of human-eyes modulation properties. We also propose a theoretical framework to investigate statistical performance of inverse digital halftoning, that is, the inverse process of halftoning. From the Bayesian inference view point, we rigorously show that the Bayes-optimal inverse-halftoning is achieved on a specific condition which is very similar to the so-called Nishimori line in the research field of spin glasses.\n    ",
        "submission_date": "2010-11-08T00:00:00",
        "last_modified_date": "2010-11-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1011.2292",
        "title": "Image Segmentation with Multidimensional Refinement Indicators",
        "authors": [
            "Hend Ben Ameur",
            "Guy Chavent",
            "Francois Cl\u00e9ment",
            "Pierre Weis"
        ],
        "abstract": "We transpose an optimal control technique to the image segmentation problem. The idea is to consider image segmentation as a parameter estimation problem. The parameter to estimate is the color of the pixels of the image. We use the adaptive parameterization technique which builds iteratively an optimal representation of the parameter into uniform regions that form a partition of the domain, hence corresponding to a segmentation of the image. We minimize an error function during the iterations, and the partition of the image into regions is optimally driven by the gradient of this error. The resulting segmentation algorithm inherits desirable properties from its optimal control origin: soundness, robustness, and flexibility.\n    ",
        "submission_date": "2010-11-10T00:00:00",
        "last_modified_date": "2011-05-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1011.4829",
        "title": "Closed-Form Solutions to A Category of Nuclear Norm Minimization Problems",
        "authors": [
            "Guangcan Liu",
            "Ju Sun",
            "Shuicheng Yan"
        ],
        "abstract": "It is an efficient and effective strategy to utilize the nuclear norm approximation to learn low-rank matrices, which arise frequently in machine learning and computer vision. So the exploration of nuclear norm minimization problems is gaining much attention recently. In this paper we shall prove that the following Low-Rank Representation (LRR) \\cite{icml_2010_lrr,lrr_extention} problem: {eqnarray*} \\min_{Z} \\norm{Z}_*, & {s.t.,} & X=AZ, {eqnarray*} has a unique and closed-form solution, where $X$ and $A$ are given matrices. The proof is based on proving a lemma that allows us to get closed-form solutions to a category of nuclear norm minimization problems.\n    ",
        "submission_date": "2010-11-22T00:00:00",
        "last_modified_date": "2010-11-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1012.0084",
        "title": "Survey on Various Gesture Recognition Techniques for Interfacing Machines Based on Ambient Intelligence",
        "authors": [
            "Harshith C",
            "Karthik R. Shastry",
            "Manoj Ravindran",
            "M.V.V.N.S. Srikanth",
            "Naveen Lakshmikhanth"
        ],
        "abstract": "Gesture recognition is mainly apprehensive on analyzing the functionality of human wits. The main goal of gesture recognition is to create a system which can recognize specific human gestures and use them to convey information or for device control. Hand gestures provide a separate complementary modality to speech for expressing ones ideas. Information associated with hand gestures in a conversation is degree,discourse structure, spatial and temporal structure. The approaches present can be mainly divided into Data-Glove Based and Vision Based approaches. An important face feature point is the nose tip. Since nose is the highest protruding point from the face. Besides that, it is not affected by facial ",
        "submission_date": "2010-12-01T00:00:00",
        "last_modified_date": "2010-12-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1012.3656",
        "title": "Adaptive Cluster Expansion (ACE): A Multilayer Network for Estimating Probability Density Functions",
        "authors": [
            "Stephen Luttrell"
        ],
        "abstract": "We derive an adaptive hierarchical method of estimating high dimensional probability density functions. We call this method of density estimation the \"adaptive cluster expansion\" or ACE for short. We present an application of this approach, based on a multilayer topographic mapping network, that adaptively estimates the joint probability density function of the pixel values of an image, and presents this result as a \"probability image\". We apply this to the problem of identifying statistically anomalous regions in otherwise statistically homogeneous images.\n    ",
        "submission_date": "2010-12-16T00:00:00",
        "last_modified_date": "2010-12-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1012.3705",
        "title": "Stochastic Vector Quantisers",
        "authors": [
            "Stephen Luttrell"
        ],
        "abstract": "In this paper a stochastic generalisation of the standard Linde-Buzo-Gray (LBG) approach to vector quantiser (VQ) design is presented, in which the encoder is implemented as the sampling of a vector of code indices from a probability distribution derived from the input vector, and the decoder is implemented as a superposition of reconstruction vectors, and the stochastic VQ is optimised using a minimum mean Euclidean reconstruction distortion criterion, as in the LBG case. Numerical simulations are used to demonstrate how this leads to self-organisation of the stochastic VQ, where different stochastically sampled code indices become associated with different input subspaces. This property may be used to automate the process of splitting high-dimensional input vectors into low-dimensional blocks before encoding them.\n    ",
        "submission_date": "2010-12-16T00:00:00",
        "last_modified_date": "2010-12-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1012.3724",
        "title": "The Development of Dominance Stripes and Orientation Maps in a Self-Organising Visual Cortex Network (VICON)",
        "authors": [
            "Stephen Luttrell"
        ],
        "abstract": "A self-organising neural network is presented that is based on a rigorous Bayesian analysis of the information contained in individual neural firing events. This leads to a visual cortex network (VICON) that has many of the properties emerge when a mammalian visual cortex is exposed to data arriving from two imaging sensors (i.e. the two retinae), such as dominance stripes and orientation maps.\n    ",
        "submission_date": "2010-12-16T00:00:00",
        "last_modified_date": "2010-12-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1012.4116",
        "title": "lp-Recovery of the Most Significant Subspace among Multiple Subspaces with Outliers",
        "authors": [
            "Gilad Lerman",
            "Teng Zhang"
        ],
        "abstract": "We assume data sampled from a mixture of d-dimensional linear subspaces with spherically symmetric distributions within each subspace and an additional outlier component with spherically symmetric distribution within the ambient space (for simplicity we may assume that all distributions are uniform on their corresponding unit spheres). We also assume mixture weights for the different components. We say that one of the underlying subspaces of the model is most significant if its mixture weight is higher than the sum of the mixture weights of all other subspaces. We study the recovery of the most significant subspace by minimizing the lp-averaged distances of data points from d-dimensional subspaces, where p>0. Unlike other lp minimization problems, this minimization is non-convex for all p>0 and thus requires different methods for its analysis. We show that if 0<p<=1, then for any fraction of outliers the most significant subspace can be recovered by lp minimization with overwhelming probability (which depends on the generating distribution and its parameters). We show that when adding small noise around the underlying subspaces the most significant subspace can be nearly recovered by lp minimization for any 0<p<=1 with an error proportional to the noise level. On the other hand, if p>1 and there is more than one underlying subspace, then with overwhelming probability the most significant subspace cannot be recovered or nearly recovered. This last result does not require spherically symmetric outliers.\n    ",
        "submission_date": "2010-12-18T00:00:00",
        "last_modified_date": "2014-01-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1012.4126",
        "title": "Self-Organising Stochastic Encoders",
        "authors": [
            "Stephen Luttrell"
        ],
        "abstract": "The processing of mega-dimensional data, such as images, scales linearly with image size only if fixed size processing windows are used. It would be very useful to be able to automate the process of sizing and interconnecting the processing windows. A stochastic encoder that is an extension of the standard Linde-Buzo-Gray vector quantiser, called a stochastic vector quantiser (SVQ), includes this required behaviour amongst its emergent properties, because it automatically splits the input space into statistically independent subspaces, which it then separately encodes. Various optimal SVQs have been obtained, both analytically and numerically. Analytic solutions which demonstrate how the input space is split into independent subspaces may be obtained when an SVQ is used to encode data that lives on a 2-torus (e.g. the superposition of a pair of uncorrelated sinusoids). Many numerical solutions have also been obtained, using both SVQs and chains of linked SVQs: (1) images of multiple independent targets (encoders for single targets emerge), (2) images of multiple correlated targets (various types of encoder for single and multiple targets emerge), (3) superpositions of various waveforms (encoders for the separate waveforms emerge - this is a type of independent component analysis (ICA)), (4) maternal and foetal ECGs (another example of ICA), (5) images of textures (orientation maps and dominance stripes emerge). Overall, SVQs exhibit a rich variety of self-organising behaviour, which effectively discovers the internal structure of the training data. This should have an immediate impact on \"intelligent\" computation, because it reduces the need for expert human intervention in the design of data processing algorithms.\n    ",
        "submission_date": "2010-12-18T00:00:00",
        "last_modified_date": "2010-12-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1012.4173",
        "title": "A Self-Organising Neural Network for Processing Data from Multiple Sensors",
        "authors": [
            "S P Luttrell"
        ],
        "abstract": "This paper shows how a folded Markov chain network can be applied to the problem of processing data from multiple sensors, with an emphasis on the special case of 2 sensors. It is necessary to design the network so that it can transform a high dimensional input vector into a posterior probability, for which purpose the partitioned mixture distribution network is ideally suited. The underlying theory is presented in detail, and a simple numerical simulation is given that shows the emergence of ocular dominance stripes.\n    ",
        "submission_date": "2010-12-19T00:00:00",
        "last_modified_date": "2010-12-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1012.4521",
        "title": "Characterizing Structure Through Shape Matching and Applications to Self Assembly",
        "authors": [
            "Aaron S. Keys",
            "Christopher R. Iacovella",
            "Sharon C. Glotzer"
        ],
        "abstract": "Structural quantities such as order parameters and correlation functions are often employed to gain insight into the physical behavior and properties of condensed matter systems. While standard quantities for characterizing structure exist, often they are insufficient for treating problems in the emerging field of nano and microscale self-assembly, where the structures encountered may be complex and unusual. The computer science field of \"shape matching\" offers a robust solution to this problem by defining diverse methods for quantifying the similarity between arbitrarily complex shapes. Most order parameters and correlation functions used in condensed matter apply a specific measure of structural similarity within the context of a broader scheme. By substituting shape matching quantities for traditional quantities, we retain the essence of the broader scheme, but extend its applicability to more complex structures. Here we review some standard shape matching techniques and discuss how they might be used to create highly flexible structural metrics for diverse systems such as self-assembled matter. We provide three proof-of-concept example problems applying shape matching methods to identifying local and global structures, and tracking structural transitions in complex assembled systems. The shape matching methods reviewed here are applicable to a wide range of condensed matter systems, both simulated and experimental, provided particle positions are known or can be accurately imaged.\n    ",
        "submission_date": "2010-12-21T00:00:00",
        "last_modified_date": "2010-12-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1012.4527",
        "title": "Harmonic Order Parameters for Characterizing Complex Particle Morphologies",
        "authors": [
            "Aaron S. Keys",
            "Christopher R. Iacovella",
            "Sharon C. Glotzer"
        ],
        "abstract": "Order parameters based on spherical harmonics and Fourier coefficients already play a significant role in condensed matter research in the context of systems of spherical or point particles. Here, we extend these types of order parameter to more complex shapes, such as those encountered in nanoscale self-assembly applications. To do so, we build on a powerful set of techniques that originate in the computer science field of \"shape matching.\" We demonstrate how shape matching techniques can be applied to identify unknown structures and create highly-specialized \\textit{ad hoc} order parameters. Additionally, we investigate the special symmetry properties of harmonic descriptors, and demonstrate how they can be exploited to provide optimal solutions to certain classes of problems. Our techniques can be applied to particle systems in general, both simulated and experimental, provided the particle positions are known.\n    ",
        "submission_date": "2010-12-21T00:00:00",
        "last_modified_date": "2010-12-21T00:00:00"
    }
]