[
    {
        "url": "https://arxiv.org/abs/cs/0401004",
        "title": "Cyborg Systems as Platforms for Computer-Vision Algorithm-Development for Astrobiology",
        "authors": [
            "Patrick C. McGuire",
            "J.A. Rodriguez-Manfredi",
            "E. Sebastian-Martinez",
            "J. Gomez-Elvira",
            "E. Diaz-Martinez",
            "J. Ormo",
            "K. Neuffer",
            "A. Giaquinta",
            "F. Camps-Martinez",
            "A. Lepinette-Malvitte",
            "J. Perez-Mercader",
            "H. Ritter",
            "M. Oesker",
            "J. Ontrup",
            "J. Walter"
        ],
        "abstract": "  Employing the allegorical imagery from the film \"The Matrix\", we motivate and discuss our `Cyborg Astrobiologist' research program. In this research program, we are using a wearable computer and video camcorder in order to test and train a computer-vision system to be a field-geologist and field-astrobiologist.\n    ",
        "submission_date": "2004-01-02T00:00:00",
        "last_modified_date": "2004-05-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/cs/0401017",
        "title": "Better Foreground Segmentation Through Graph Cuts",
        "authors": [
            "Nicholas R. Howe",
            "Alexandra Deschamps"
        ],
        "abstract": "  For many tracking and surveillance applications, background subtraction provides an effective means of segmenting objects moving in front of a static background. Researchers have traditionally used combinations of morphological operations to remove the noise inherent in the background-subtracted result. Such techniques can effectively isolate foreground objects, but tend to lose fidelity around the borders of the segmentation, especially for noisy input. This paper explores the use of a minimum graph cut algorithm to segment the foreground, resulting in qualitatively and quantitiatively cleaner segmentations. Experiments on both artificial and real data show that the graph-based method reduces the error around segmented foreground objects. A MATLAB code implementation is available at ",
        "submission_date": "2004-01-21T00:00:00",
        "last_modified_date": "2004-07-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/cs/0401018",
        "title": "Factor Temporal Prognosis of Tick-Borne Encephalitis Foci Functioning on the South of Russian Far East",
        "authors": [
            "E.I. Bolotin",
            "G.Sh. Tsitsiashvili",
            "I.V. Golycheva"
        ],
        "abstract": "  A method of temporal factor prognosis of TE (tick-borne encephalitis) infection has been developed. The high precision of the prognosis results for a number of geographical regions of Primorsky Krai has been achieved. The method can be applied not only to epidemiological research but also to others.\n    ",
        "submission_date": "2004-01-22T00:00:00",
        "last_modified_date": "2004-01-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/cs/0402020",
        "title": "Geometrical Complexity of Classification Problems",
        "authors": [
            "Tin Kam Ho"
        ],
        "abstract": "  Despite encouraging recent progresses in ensemble approaches, classification methods seem to have reached a plateau in development. Further advances depend on a better understanding of geometrical and topological characteristics of point sets in high-dimensional spaces, the preservation of such characteristics under feature transformations and sampling processes, and their interaction with geometrical models used in classifiers. We discuss an attempt to measure such properties from data sets and relate them to classifier accuracies.\n    ",
        "submission_date": "2004-02-11T00:00:00",
        "last_modified_date": "2004-02-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/cs/0402021",
        "title": "A Numerical Example on the Principles of Stochastic Discrimination",
        "authors": [
            "Tin Kam Ho"
        ],
        "abstract": "  Studies on ensemble methods for classification suffer from the difficulty of modeling the complementary strengths of the components. Kleinberg's theory of stochastic discrimination (SD) addresses this rigorously via mathematical notions of enrichment, uniformity, and projectability of an ensemble. We explain these concepts via a very simple numerical example that captures the basic principles of the SD theory and method. We focus on a fundamental symmetry in point set covering that is the key observation leading to the foundation of the theory. We believe a better understanding of the SD method will lead to developments of better tools for analyzing other ensemble methods.\n    ",
        "submission_date": "2004-02-11T00:00:00",
        "last_modified_date": "2004-02-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/cs/0404046",
        "title": "Visualising the structure of architectural open spaces based on shape analysis",
        "authors": [
            "Sanjay Rana",
            "Mike Batty"
        ],
        "abstract": "  This paper proposes the application of some well known two-dimensional geometrical shape descriptors for the visualisation of the structure of architectural open spaces. The paper demonstrates the use of visibility measures such as distance to obstacles and amount of visible space to calculate shape descriptors such as convexity and skeleton of the open space. The aim of the paper is to indicate a simple, objective and quantifiable approach to understand the structure of open spaces otherwise impossible due to the complex construction of built structures.\n    ",
        "submission_date": "2004-04-22T00:00:00",
        "last_modified_date": "2004-04-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/cs/0405029",
        "title": "A New Computational Framework For 2D Shape-Enclosing Contours",
        "authors": [
            "B. R. Schlei"
        ],
        "abstract": "In this paper, a new framework for one-dimensional contour extraction from discrete two-dimensional data sets is presented. Contour extraction is important in many scientific fields such as digital image processing, computer vision, pattern recognition, etc. This novel framework includes (but is not limited to) algorithms for dilated contour extraction, contour displacement, shape skeleton extraction, contour continuation, shape feature based contour refinement and contour simplification. Many of the new techniques depend strongly on the application of a Delaunay tessellation. In order to demonstrate the versatility of this novel toolbox approach, the contour extraction techniques presented here are applied to scientific problems in material science, biology and heavy ion physics.\n    ",
        "submission_date": "2004-05-07T00:00:00",
        "last_modified_date": "2010-11-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/cs/0405093",
        "title": "Computerized Face Detection and Recognition",
        "authors": [
            "Vytautas Perlibakas"
        ],
        "abstract": "  This publication presents methods for face detection, analysis and recognition: fast normalized cross-correlation (fast correlation coefficient) between multiple templates based face pre-detection method, method for detection of exact face contour based on snakes and Generalized Gradient Vector Flow field, method for combining recognition algorithms based on Cumulative Match Characteristics in order to increase recognition speed and accuracy, and face recognition method based on Principal Component Analysis of the Wavelet Packet Decomposition allowing to use PCA - based recognition method with large number of training images. For all the methods are presented experimental results and comparisons of speed and accuracy with large face databases.\n    ",
        "submission_date": "2004-05-25T00:00:00",
        "last_modified_date": "2004-10-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/cs/0405095",
        "title": "Blind Detection and Compensation of Camera Lens Geometric Distortions",
        "authors": [
            "Lili Ma",
            "YangQuan Chen",
            "Kevin L. Moore"
        ],
        "abstract": "  This paper presents a blind detection and compensation technique for camera lens geometric distortions. The lens distortion introduces higher-order correlations in the frequency domain and in turn it can be detected using higher-order spectral analysis tools without assuming any specific calibration target. The existing blind lens distortion removal method only considered a single-coefficient radial distortion model. In this paper, two coefficients are considered to model approximately the geometric distortion. All the models considered have analytical closed-form inverse formulae.\n    ",
        "submission_date": "2004-05-25T00:00:00",
        "last_modified_date": "2004-05-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/cs/0406008",
        "title": "Image compression by rectangular wavelet transform",
        "authors": [
            "Vyacheslav Zavadsky"
        ],
        "abstract": "  We study image compression by a separable wavelet basis $\\big\\{\\psi(2^{k_1}x-i)\\psi(2^{k_2}y-j),$ $\\phi(x-i)\\psi(2^{k_2}y-j),$ $\\psi(2^{k_1}(x-i)\\phi(y-j),$ $\\phi(x-i)\\phi(y-i)\\big\\},$ where $k_1, k_2 \\in \\mathbb{Z}_+$; $i,j\\in\\mathbb{Z}$; and $\\phi,\\psi$ are elements of a standard biorthogonal wavelet basis in $L_2(\\mathbb{R})$. Because $k_1\\ne k_2$, the supports of the basis elements are rectangles, and the corresponding transform is known as the {\\em rectangular wavelet transform}. We prove that if one-dimensional wavelet basis has $M$ dual vanishing moments then the rate of approximation by $N$ coefficients of rectangular wavelet transform is $\\mathcal{O}(N^{-M}\\log^C N)$ for functions with mixed derivative of order $M$ in each direction.\n",
        "submission_date": "2004-06-04T00:00:00",
        "last_modified_date": "2004-06-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/cs/0406047",
        "title": "Self-organizing neural networks in classification and image recognition",
        "authors": [
            "G.A. Ososkov",
            "S.G. Dmitrievskiy",
            "A.V. Stadnik"
        ],
        "abstract": "  Self-organizing neural networks are used for brick finding in OPERA experiment. Self-organizing neural networks and wavelet analysis used for recognition and extraction of car numbers from images.\n    ",
        "submission_date": "2004-06-24T00:00:00",
        "last_modified_date": "2004-06-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/cs/0407047",
        "title": "Channel-Independent and Sensor-Independent Stimulus Representations",
        "authors": [
            "David N. Levin"
        ],
        "abstract": "  This paper shows how a machine, which observes stimuli through an uncharacterized, uncalibrated channel and sensor, can glean machine-independent information (i.e., channel- and sensor-independent information) about the stimuli. First, we demonstrate that a machine defines a specific coordinate system on the stimulus state space, with the nature of that coordinate system depending on the device's channel and sensor. Thus, machines with different channels and sensors \"see\" the same stimulus trajectory through state space, but in different machine-specific coordinate systems. For a large variety of physical stimuli, statistical properties of that trajectory endow the stimulus configuration space with differential geometric structure (a metric and parallel transfer procedure), which can then be used to represent relative stimulus configurations in a coordinate-system-independent manner (and, therefore, in a channel- and sensor-independent manner). The resulting description is an \"inner\" property of the stimulus time series in the sense that it does not depend on extrinsic factors like the observer's choice of a coordinate system in which the stimulus is viewed (i.e., the observer's choice of channel and sensor). This methodology is illustrated with analytic examples and with a numerically simulated experiment. In an intelligent sensory device, this kind of representation \"engine\" could function as a \"front-end\" that passes channel/sensor-independent stimulus representations to a pattern recognition module. After a pattern recognizer has been trained in one of these devices, it could be used without change in other devices having different channels and sensors.\n    ",
        "submission_date": "2004-07-19T00:00:00",
        "last_modified_date": "2005-09-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/cs/0408012",
        "title": "Three-Dimensional Face Orientation and Gaze Detection from a Single Image",
        "authors": [
            "J.Y. Kaminski",
            "M. Teicher",
            "D. Knaan",
            "A. Shavit"
        ],
        "abstract": "  Gaze detection and head orientation are an important part of many advanced human-machine interaction applications. Many systems have been proposed for gaze detection. Typically, they require some form of user cooperation and calibration. Additionally, they may require multiple cameras and/or restricted head positions. We present a new approach for inference of both face orientation and gaze direction from a single image with no restrictions on the head position. Our algorithm is based on a face and eye model, deduced from anthropometric data. This approach allows us to use a single camera and requires no cooperation from the user. Using a single image avoids the complexities associated with of a multi-camera system. Evaluation tests show that our system is accurate, fast and can be used in a variety of applications, including ones where the user is unaware of the system.\n    ",
        "submission_date": "2004-08-04T00:00:00",
        "last_modified_date": "2004-08-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/cs/0409031",
        "title": "Field Geology with a Wearable Computer: First Results of the Cyborg Astrobiologist System",
        "authors": [
            "Patrick C. McGuire",
            "Javier Gomez-Elvira",
            "Jose Antonio Rodriguez-Manfredi",
            "Eduardo Sebastian-Martinez",
            "Jens Ormo",
            "Enrique Diaz-Martinez",
            "Helge Ritter",
            "Markus Oesker",
            "Robert Haschke",
            "Joerg Ontrup"
        ],
        "abstract": "  We present results from the first geological field tests of the `Cyborg Astrobiologist', which is a wearable computer and video camcorder system that we are using to test and train a computer-vision system towards having some of the autonomous decision-making capabilities of a field-geologist. The Cyborg Astrobiologist platform has thus far been used for testing and development of these algorithms and systems: robotic acquisition of quasi-mosaics of images, real-time image segmentation, and real-time determination of interesting points in the image mosaics. The hardware and software systems function reliably, and the computer-vision algorithms are adequate for the first field tests. In addition to the proof-of-concept aspect of these field tests, the main result of these field tests is the enumeration of those issues that we can improve in the future, including: dealing with structural shadow and microtexture, and also, controlling the camera's zoom lens in an intelligent manner. Nonetheless, despite these and other technical inadequacies, this Cyborg Astrobiologist system, consisting of a camera-equipped wearable-computer and its computer-vision algorithms, has demonstrated its ability of finding genuinely interesting points in real-time in the geological scenery, and then gathering more information about these interest points in an automated manner.\n    ",
        "submission_date": "2004-09-15T00:00:00",
        "last_modified_date": "2004-09-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/cs/0410017",
        "title": "Automated Pattern Detection--An Algorithm for Constructing Optimally Synchronizing Multi-Regular Language Filters",
        "authors": [
            "Carl S. McTague",
            "James P. Crutchfield"
        ],
        "abstract": "  In the computational-mechanics structural analysis of one-dimensional cellular automata the following automata-theoretic analogue of the \\emph{change-point problem} from time series analysis arises: \\emph{Given a string $\\sigma$ and a collection $\\{\\mc{D}_i\\}$ of finite automata, identify the regions of $\\sigma$ that belong to each $\\mc{D}_i$ and, in particular, the boundaries separating them.} We present two methods for solving this \\emph{multi-regular language filtering problem}. The first, although providing the ideal solution, requires a stack, has a worst-case compute time that grows quadratically in $\\sigma$'s length and conditions its output at any point on arbitrarily long windows of future input. The second method is to algorithmically construct a transducer that approximates the first algorithm. In contrast to the stack-based algorithm, however, the transducer requires only a finite amount of memory, runs in linear time, and gives immediate output for each letter read; it is, moreover, the best possible finite-state approximation with these three features.\n    ",
        "submission_date": "2004-10-07T00:00:00",
        "last_modified_date": "2004-10-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/cs/0410071",
        "title": "The Cyborg Astrobiologist: First Field Experience",
        "authors": [
            "Patrick C. McGuire",
            "Jens Ormo",
            "Enrique Diaz-Martinez",
            "Jose Antonio Rodriguez-Manfredi",
            "Javier Gomez-Elvira",
            "Helge Ritter",
            "Markus Oesker",
            "Joerg Ontrup"
        ],
        "abstract": "  We present results from the first geological field tests of the `Cyborg Astrobiologist', which is a wearable computer and video camcorder system that we are using to test and train a computer-vision system towards having some of the autonomous decision-making capabilities of a field-geologist and field-astrobiologist. The Cyborg Astrobiologist platform has thus far been used for testing and development of these algorithms and systems: robotic acquisition of quasi-mosaics of images, real-time image segmentation, and real-time determination of interesting points in the image mosaics. The hardware and software systems function reliably, and the computer-vision algorithms are adequate for the first field tests. In addition to the proof-of-concept aspect of these field tests, the main result of these field tests is the enumeration of those issues that we can improve in the future, including: first, detection and accounting for shadows caused by 3D jagged edges in the outcrop; second, reincorporation of more sophisticated texture-analysis algorithms into the system; third, creation of hardware and software capabilities to control the camera's zoom lens in an intelligent manner; and fourth, development of algorithms for interpretation of complex geological scenery. Nonetheless, despite these technical inadequacies, this Cyborg Astrobiologist system, consisting of a camera-equipped wearable-computer and its computer-vision algorithms, has demonstrated its ability of finding genuinely interesting points in real-time in the geological scenery, and then gathering more information about these interest points in an automated manner.\n    ",
        "submission_date": "2004-10-27T00:00:00",
        "last_modified_date": "2004-10-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/cs/0412088",
        "title": "On Image Filtering, Noise and Morphological Size Intensity Diagrams",
        "authors": [
            "Vitorino Ramos",
            "Fernando Muge"
        ],
        "abstract": "  In the absence of a pure noise-free image it is hard to define what noise is, in any original noisy image, and as a consequence also where it is, and in what amount. In fact, the definition of noise depends largely on our own aim in the whole image analysis process, and (perhaps more important) in our self-perception of noise. For instance, when we perceive noise as disconnected and small it is normal to use MM-ASF filters to treat it. There is two evidences of this. First, in many instances there is no ideal and pure noise-free image to compare our filtering process (nothing but our self-perception of its pure image); second, and related with this first point, MM transformations that we chose are only based on our self - and perhaps - fuzzy notion. The present proposal combines the results of two MM filtering transformations (FT1, FT2) and makes use of some measures and quantitative relations on their Size/Intensity Diagrams to find the most appropriate noise removal process. Results can also be used for finding the most appropriate stop criteria, and the right sequence of MM operators combination on Alternating Sequential Filters (ASF), if these measures are applied, for instance, on a Genetic Algorithm's target function.\n    ",
        "submission_date": "2004-12-17T00:00:00",
        "last_modified_date": "2004-12-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/cs/0404042",
        "title": "Extraction of topological features from communication network topological patterns using self-organizing feature maps",
        "authors": [
            "W. Ali",
            "R.J. Mondragon",
            "F. Alavi"
        ],
        "abstract": "  Different classes of communication network topologies and their representation in the form of adjacency matrix and its eigenvalues are presented. A self-organizing feature map neural network is used to map different classes of communication network topological patterns. The neural network simulation results are reported.\n    ",
        "submission_date": "2004-04-21T00:00:00",
        "last_modified_date": "2004-04-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/cs/0406017",
        "title": "Using Self-Organising Mappings to Learn the Structure of Data Manifolds",
        "authors": [
            "Stephen Luttrell"
        ],
        "abstract": "  In this paper it is shown how to map a data manifold into a simpler form by progressively discarding small degrees of freedom. This is the key to self-organising data fusion, where the raw data is embedded in a very high-dimensional space (e.g. the pixel values of one or more images), and the requirement is to isolate the important degrees of freedom which lie on a low-dimensional manifold. A useful advantage of the approach used in this paper is that the computations are arranged as a feed-forward processing chain, where all the details of the processing in each stage of the chain are learnt by self-organisation. This approach is demonstrated using hierarchically correlated data, which causes the processing chain to split the data into separate processing channels, and then to progressively merge these channels wherever they are correlated with each other. This is the key to self-organising data fusion.\n    ",
        "submission_date": "2004-06-08T00:00:00",
        "last_modified_date": "2004-08-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/cs/0406043",
        "title": "The Computational Complexity of Orientation Search Problems in Cryo-Electron Microscopy",
        "authors": [
            "Taneli Mielik\u00e4inen",
            "Janne Ravantti",
            "Esko Ukkonen"
        ],
        "abstract": "  In this report we study the problem of determining three-dimensional orientations for noisy projections of randomly oriented identical particles. The problem is of central importance in the tomographic reconstruction of the density map of macromolecular complexes from electron microscope images and it has been studied intensively for more than 30 years.\n",
        "submission_date": "2004-06-23T00:00:00",
        "last_modified_date": "2004-06-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/cs/0408049",
        "title": "Using Stochastic Encoders to Discover Structure in Data",
        "authors": [
            "Stephen Luttrell"
        ],
        "abstract": "  In this paper a stochastic generalisation of the standard Linde-Buzo-Gray (LBG) approach to vector quantiser (VQ) design is presented, in which the encoder is implemented as the sampling of a vector of code indices from a probability distribution derived from the input vector, and the decoder is implemented as a superposition of reconstruction vectors. This stochastic VQ (SVQ) is optimised using a minimum mean Euclidean reconstruction distortion criterion, as in the LBG case. Numerical simulations are used to demonstrate how this leads to self-organisation of the SVQ, where different stochastically sampled code indices become associated with different input subspaces.\n    ",
        "submission_date": "2004-08-21T00:00:00",
        "last_modified_date": "2004-08-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/cs/0408050",
        "title": "Invariant Stochastic Encoders",
        "authors": [
            "Stephen Luttrell"
        ],
        "abstract": "  The theory of stochastic vector quantisers (SVQ) has been extended to allow the quantiser to develop invariances, so that only \"large\" degrees of freedom in the input vector are represented in the code. This has been applied to the problem of encoding data vectors which are a superposition of a \"large\" jammer and a \"small\" signal, so that only the jammer is represented in the code. This allows the jammer to be subtracted from the total input vector (i.e. the jammer is nulled), leaving a residual that contains only the underlying signal. The main advantage of this approach to jammer nulling is that little prior knowledge of the jammer is assumed, because these properties are automatically discovered by the SVQ as it is trained on examples of input vectors.\n    ",
        "submission_date": "2004-08-21T00:00:00",
        "last_modified_date": "2004-08-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/cs/0409003",
        "title": "ScheduleNanny: Using GPS to Learn the User's Significant Locations, Travel Times and Schedule",
        "authors": [
            "Parth Bhawalkar",
            "Victor Bigio",
            "Adam Davis",
            "Karthik Narayanaswami",
            "Femi Olumoko"
        ],
        "abstract": "  As computing technology becomes more pervasive, personal devices such as the PDA, cell-phone, and notebook should use context to determine how to act. Location is one form of context that can be used in many ways. We present a multiple-device system that collects and clusters GPS data into significant locations. These locations are then used to determine travel times and a probabilistic model of the user's schedule, which is used to intelligently alert the user. We evaluate our system and suggest how it should be integrated with a variety of applications.\n    ",
        "submission_date": "2004-09-02T00:00:00",
        "last_modified_date": "2004-09-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/cs/0410020",
        "title": "Adaptive Cluster Expansion (ACE): A Hierarchical Bayesian Network",
        "authors": [
            "Stephen Luttrell"
        ],
        "abstract": "  Using the maximum entropy method, we derive the \"adaptive cluster expansion\" (ACE), which can be trained to estimate probability density functions in high dimensional spaces. The main advantage of ACE over other Bayesian networks is its ability to capture high order statistics after short training times, which it achieves by making use of a hierarchical vector quantisation of the input data. We derive a scheme for representing the state of an ACE network as a \"probability image\", which allows us to identify statistically anomalous regions in an otherwise statistically homogeneous image, for instance. Finally, we present some probability images that we obtained after training ACE on some Brodatz texture images - these demonstrate the ability of ACE to detect subtle textural anomalies.\n    ",
        "submission_date": "2004-10-10T00:00:00",
        "last_modified_date": "2004-10-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/cs/0410036",
        "title": "Self-Organised Factorial Encoding of a Toroidal Manifold",
        "authors": [
            "Stephen Luttrell"
        ],
        "abstract": "  It is shown analytically how a neural network can be used optimally to encode input data that is derived from a toroidal manifold. The case of a 2-layer network is considered, where the output is assumed to be a set of discrete neural firing events. The network objective function measures the average Euclidean error that occurs when the network attempts to reconstruct its input from its output. This optimisation problem is solved analytically for a toroidal input manifold, and two types of solution are obtained: a joint encoder in which the network acts as a soft vector quantiser, and a factorial encoder in which the network acts as a pair of soft vector quantisers (one for each of the circular subspaces of the torus). The factorial encoder is favoured for small network sizes when the number of observed firing events is large. Such self-organised factorial encoding may be used to restrict the size of network that is required to perform a given encoding task, and will decompose an input manifold into its constituent submanifolds.\n    ",
        "submission_date": "2004-10-15T00:00:00",
        "last_modified_date": "2005-09-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/cs/0410042",
        "title": "Neural Architectures for Robot Intelligence",
        "authors": [
            "H. Ritter",
            "J.J. Steil",
            "C. Noelker",
            "F. Roethling",
            "P.C. McGuire"
        ],
        "abstract": "  We argue that the direct experimental approaches to elucidate the architecture of higher brains may benefit from insights gained from exploring the possibilities and limits of artificial control architectures for robot systems. We present some of our recent work that has been motivated by that view and that is centered around the study of various aspects of hand actions since these are intimately linked with many higher cognitive abilities. As examples, we report on the development of a modular system for the recognition of continuous hand postures based on neural nets, the use of vision and tactile sensing for guiding prehensile movements of a multifingered hand, and the recognition and use of hand gestures for robot teaching.\n",
        "submission_date": "2004-10-18T00:00:00",
        "last_modified_date": "2004-10-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/cs/0412066",
        "title": "From Feature Extraction to Classification: A multidisciplinary Approach applied to Portuguese Granites",
        "authors": [
            "Vitorino Ramos",
            "Pedro Pina",
            "Fernando Muge"
        ],
        "abstract": "  The purpose of this paper is to present a complete methodology based on a multidisciplinary approach, that goes from the extraction of features till the classification of a set of different portuguese granites. The set of tools to extract the features that characterise polished surfaces of the granites is mainly based on mathematical morphology. The classification methodology is based on a genetic algorithm capable of search the input feature space used by the nearest neighbour rule classifier. Results show that is adequate to perform feature reduction and simultaneous improve the recognition rate. Moreover, the present methodology represents a robust strategy to understand the proper nature of the images treated, and their discriminant features. KEYWORDS: Portuguese grey granites, feature extraction, mathematical morphology, feature reduction, genetic algorithms, nearest neighbour rule classifiers (k-NNR).\n    ",
        "submission_date": "2004-12-17T00:00:00",
        "last_modified_date": "2004-12-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/cs/0412069",
        "title": "Swarming around Shellfish Larvae",
        "authors": [
            "Vitorino Ramos",
            "Jonathan Campbell",
            "John Slater",
            "John Gillespie",
            "Ivan F. Bendezu",
            "Fionn Murtagh"
        ],
        "abstract": "  The collection of wild larvae seed as a source of raw material is a major sub industry of shellfish aquaculture. To predict when, where and in what quantities wild seed will be available, it is necessary to track the appearance and growth of planktonic larvae. One of the most difficult groups to identify, particularly at the species level are the Bivalvia. This difficulty arises from the fact that fundamentally all bivalve larvae have a similar shape and colour. Identification based on gross morphological appearance is limited by the time-consuming nature of the microscopic examination and by the limited availability of expertise in this field. Molecular and immunological methods are also being studied. We describe the application of computational pattern recognition methods to the automated identification and size analysis of scallop larvae. For identification, the shape features used are binary invariant moments; that is, the features are invariant to shift (position within the image), scale (induced either by growth or differential image magnification) and rotation. Images of a sample of scallop and non-scallop larvae covering a range of maturities have been analysed. In order to overcome the automatic identification, as well as to allow the system to receive new unknown samples at any moment, a self-organized and unsupervised ant-like clustering algorithm based on Swarm Intelligence is proposed, followed by simple k-NNR nearest neighbour classification on the final map. Results achieve a full recognition rate of 100% under several situations (k =1 or 3).\n    ",
        "submission_date": "2004-12-17T00:00:00",
        "last_modified_date": "2004-12-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/cs/0412070",
        "title": "Less is More - Genetic Optimisation of Nearest Neighbour Classifiers",
        "authors": [
            "Vitorino Ramos",
            "Fernando Muge"
        ],
        "abstract": "  The present paper deals with optimisation of Nearest Neighbour rule Classifiers via Genetic Algorithms. The methodology consists on implement a Genetic Algorithm capable of search the input feature space used by the NNR classifier. Results show that is adequate to perform feature reduction and simultaneous improve the Recognition Rate. Some practical examples prove that is possible to Recognise Portuguese Granites in 100%, with only 3 morphological features (from an original set of 117 features), which is well suited for real time applications. Moreover, the present method represents a robust strategy to understand the proper nature of the images treated, and their discriminant features. KEYWORDS: Feature Reduction, Genetic Algorithms, Nearest Neighbour Rule Classifiers (k-NNR).\n    ",
        "submission_date": "2004-12-17T00:00:00",
        "last_modified_date": "2004-12-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/cs/0412076",
        "title": "Clustering Techniques for Marbles Classification",
        "authors": [
            "J.R. Caldas-Pinto",
            "Pedro Pina",
            "Vitorino Ramos",
            "Mario Ramalho"
        ],
        "abstract": "  Automatic marbles classification based on their visual appearance is an important industrial issue. However, there is no definitive solution to the problem mainly due to the presence of randomly distributed high number of different colours and its subjective evaluation by the human expert. In this paper we present a study of segmentation techniques, we evaluate they overall performance using a training set and standard quality measures and finally we apply different clustering techniques to automatically classify the marbles. KEYWORDS: Segmentation, Clustering, Quadtrees, Learning Vector Quantization (LVQ), Simulated Annealing (SA).\n    ",
        "submission_date": "2004-12-17T00:00:00",
        "last_modified_date": "2004-12-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/cs/0412083",
        "title": "Line and Word Matching in Old Documents",
        "authors": [
            "A. Marcolino",
            "Vitorino Ramos",
            "Mario Ramalho",
            "J.R. Caldas Pinto"
        ],
        "abstract": "  This paper is concerned with the problem of establishing an index based on word matching. It is assumed that the book was digitised as better as possible and some pre-processing techniques were already applied as line orientation correction and some noise removal. However two main factor are responsible for being not possible to apply ordinary optical character recognition techniques (OCR): the presence of antique fonts and the degraded state of many characters due to unrecoverable original time degradation. In this paper we make a short introduction to word segmentation that involves finding the lines that characterise a word. After we discuss different approaches for word matching and how they can be combined to obtain an ordered list for candidate words for the matching. This discussion will be illustrated by examples.\n    ",
        "submission_date": "2004-12-17T00:00:00",
        "last_modified_date": "2004-12-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/cs/0412086",
        "title": "Artificial Ant Colonies in Digital Image Habitats - A Mass Behaviour Effect Study on Pattern Recognition",
        "authors": [
            "Vitorino Ramos",
            "Filipe Almeida"
        ],
        "abstract": "  Some recent studies have pointed that, the self-organization of neurons into brain-like structures, and the self-organization of ants into a swarm are similar in many respects. If possible to implement, these features could lead to important developments in pattern recognition systems, where perceptive capabilities can emerge and evolve from the interaction of many simple local rules. The principle of the method is inspired by the work of Chialvo and Millonas who developed the first numerical simulation in which swarm cognitive map formation could be explained. From this point, an extended model is presented in order to deal with digital image habitats, in which artificial ants could be able to react to the environment and perceive it. Evolution of pheromone fields point that artificial ant colonies could react and adapt appropriately to any type of digital habitat. KEYWORDS: Swarm Intelligence, Self-Organization, Stigmergy, Artificial Ant Systems, Pattern Recognition and Perception, Image Segmentation, Gestalt Perception Theory, Distributed Computation.\n    ",
        "submission_date": "2004-12-17T00:00:00",
        "last_modified_date": "2004-12-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/cs/0412087",
        "title": "Image Colour Segmentation by Genetic Algorithms",
        "authors": [
            "Vitorino Ramos",
            "Fernando Muge"
        ],
        "abstract": "  Segmentation of a colour image composed of different kinds of texture regions can be a hard problem, namely to compute for an exact texture fields and a decision of the optimum number of segmentation areas in an image when it contains similar and/or unstationary texture fields. In this work, a method is described for evolving adaptive procedures for these problems. In many real world applications data clustering constitutes a fundamental issue whenever behavioural or feature domains can be mapped into topological domains. We formulate the segmentation problem upon such images as an optimisation problem and adopt evolutionary strategy of Genetic Algorithms for the clustering of small regions in colour feature space. The present approach uses k-Means unsupervised clustering methods into Genetic Algorithms, namely for guiding this last Evolutionary Algorithm in his search for finding the optimal or sub-optimal data partition, task that as we know, requires a non-trivial search because of its intrinsic NP-complete nature. To solve this task, the appropriate genetic coding is also discussed, since this is a key aspect in the implementation. Our purpose is to demonstrate the efficiency of Genetic Algorithms to automatic and unsupervised texture segmentation. Some examples in Colour Maps, Ornamental Stones and in Human Skin Mark segmentation are presented and overall results discussed. KEYWORDS: Genetic Algorithms, Colour Image Segmentation, Classification, Clustering.\n    ",
        "submission_date": "2004-12-17T00:00:00",
        "last_modified_date": "2004-12-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/cs/0412110",
        "title": "Q-valued neural network as a system of fast identification and pattern recognition",
        "authors": [
            "D.I.Alieva",
            "B.V.Kryzhanovsky",
            "V.M.Kryzhanovsky",
            "A.B.Fonarev"
        ],
        "abstract": "  An effective neural network algorithm of the perceptron type is proposed. The algorithm allows us to identify strongly distorted input vector reliably. It is shown that its reliability and processing speed are orders of magnitude higher than that of full connected neural networks. The processing speed of our algorithm exceeds the one of the stack fast-access retrieval algorithm that is modified for working when there are noises in the input channel.\n    ",
        "submission_date": "2004-12-24T00:00:00",
        "last_modified_date": "2004-12-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/q-bio/0411030",
        "title": "Statistical Mechanics Characterization of Neuronal Mosaics",
        "authors": [
            "Luciano da Fontoura Costa",
            "Fernando Rocha",
            "Silene Maria Araujo de Lima"
        ],
        "abstract": "  The spatial distribution of neuronal cells is an important requirement for achieving proper neuronal function in several parts of the nervous system of most animals. For instance, specific distribution of photoreceptors and related neuronal cells, particularly the ganglion cells, in mammal's retina is required in order to properly sample the projected scene. This work presents how two concepts from the areas of statistical mechanics and complex systems, namely the \\emph{lacunarity} and the \\emph{multiscale entropy} (i.e. the entropy calculated over progressively diffused representations of the cell mosaic), have allowed effective characterization of the spatial distribution of retinal cells.\n    ",
        "submission_date": "2004-11-14T00:00:00",
        "last_modified_date": "2004-11-14T00:00:00"
    }
]