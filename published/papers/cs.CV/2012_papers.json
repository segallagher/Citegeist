[
    {
        "url": "https://arxiv.org/abs/1201.0566",
        "title": "Learning joint intensity-depth sparse representations",
        "authors": [
            "Ivana Tosic",
            "Sarah Drewes"
        ],
        "abstract": "This paper presents a method for learning overcomplete dictionaries composed of two modalities that describe a 3D scene: image intensity and scene depth. We propose a novel Joint Basis Pursuit (JBP) algorithm that finds related sparse features in two modalities using conic programming and integrate it into a two-step dictionary learning algorithm. JBP differs from related convex algorithms because it finds joint sparsity models with different atoms and different coefficient values for intensity and depth. This is crucial for recovering generative models where the same sparse underlying causes (3D features) give rise to different signals (intensity and depth). We give a theoretical bound for the sparse coefficient recovery error obtained by JBP, and show experimentally that JBP is far superior to the state of the art Group Lasso algorithm. When applied to the Middlebury depth-intensity database, our learning algorithm converges to a set of related features, such as pairs of depth and intensity edges or image textures and depth slants. Finally, we show that the learned dictionary and JBP achieve the state of the art depth inpainting performance on time-of-flight 3D data.\n    ",
        "submission_date": "2012-01-03T00:00:00",
        "last_modified_date": "2013-09-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1201.1216",
        "title": "Probabilistic Motion Estimation Based on Temporal Coherence",
        "authors": [
            "Pierre-Yves Burgi",
            "Alan L. Yuille",
            "Norberto M. Grzywacz"
        ],
        "abstract": "We develop a theory for the temporal integration of visual motion motivated by psychophysical experiments. The theory proposes that input data are temporally grouped and used to predict and estimate the motion flows in the image sequence. This temporal grouping can be considered a generalization of the data association techniques used by engineers to study motion sequences. Our temporal-grouping theory is expressed in terms of the Bayesian generalization of standard Kalman filtering. To implement the theory we derive a parallel network which shares some properties of cortical networks. Computer simulations of this network demonstrate that our theory qualitatively accounts for psychophysical experiments on motion occlusion and motion outliers.\n    ",
        "submission_date": "2012-01-05T00:00:00",
        "last_modified_date": "2012-01-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1201.1221",
        "title": "Information Distance: New Developments",
        "authors": [
            "P. M. B. Vitanyi"
        ],
        "abstract": "In pattern recognition, learning, and data mining one obtains information from information-carrying objects. This involves an objective definition of the information in a single object, the information to go from one object to another object in a pair of objects, the information to go from one object to any other object in a multiple of objects, and the shared information between objects. This is called \"information distance.\" We survey a selection of new developments in information distance.\n    ",
        "submission_date": "2012-01-05T00:00:00",
        "last_modified_date": "2012-01-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1201.1417",
        "title": "Picture Collage with Genetic Algorithm and Stereo vision",
        "authors": [
            "Hesam Ekhtiyar",
            "Mahdi Sheida",
            "Mahmood Amintoosi"
        ],
        "abstract": "In this paper, a salient region extraction method for creating picture collage based on stereo vision is proposed. Picture collage is a kind of visual image summary to arrange all input images on a given canvas, allowing overlay, to maximize visible visual information. The salient regions of each image are firstly extracted and represented as a depth map. The output picture collage shows as many visible salient regions (without being overlaid by others) from all images as possible. A very efficient Genetic algorithm is used here for the optimization. The experimental results showed the superior performance of the proposed method.\n    ",
        "submission_date": "2011-11-29T00:00:00",
        "last_modified_date": "2011-11-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1201.1422",
        "title": "Minutiae Extraction from Fingerprint Images - a Review",
        "authors": [
            "Roli Bansal",
            "Priti Sehgal",
            "Punam Bedi"
        ],
        "abstract": "Fingerprints are the oldest and most widely used form of biometric identification. Everyone is known to have unique, immutable fingerprints. As most Automatic Fingerprint Recognition Systems are based on local ridge features known as minutiae, marking minutiae accurately and rejecting false ones is very important. However, fingerprint images get degraded and corrupted due to variations in skin and impression conditions. Thus, image enhancement techniques are employed prior to minutiae extraction. A critical step in automatic fingerprint matching is to reliably extract minutiae from the input fingerprint images. This paper presents a review of a large number of techniques present in the literature for extracting fingerprint minutiae. The techniques are broadly classified as those working on binarized images and those that work on gray scale images directly.\n    ",
        "submission_date": "2011-11-29T00:00:00",
        "last_modified_date": "2011-11-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1201.1571",
        "title": "A United Image Force for Deformable Models and Direct Transforming Geometric Active Contorus to Snakes by Level Sets",
        "authors": [
            "Hongyu Lu",
            "Yutian Wang",
            "Shanglian Bao"
        ],
        "abstract": "A uniform distribution of the image force field around the object fasts the convergence speed of the segmentation process. However, to achieve this aim, it causes the force constructed from the heat diffusion model unable to indicate the object boundaries accurately. The image force based on electrostatic field model can perform an exact shape recovery. First, this study introduces a fusion scheme of these two image forces, which is capable of extracting the object boundary with high precision and fast speed. Until now, there is no satisfied analysis about the relationship between Snakes and Geometric Active Contours (GAC). The second contribution of this study addresses that the GAC model can be deduced directly from Snakes model. It proves that each term in GAC and Snakes is correspondent and has similar function. However, the two models are expressed using different mathematics. Further, since losing the ability of rotating the contour, adoption of level sets can limits the usage of GAC in some circumstances.\n    ",
        "submission_date": "2012-01-07T00:00:00",
        "last_modified_date": "2012-05-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1201.2050",
        "title": "Adaptive Noise Reduction Scheme for Salt and Pepper",
        "authors": [
            "Tina Gebreyohannes",
            "Dong-Yoon Kim"
        ],
        "abstract": "In this paper, a new adaptive noise reduction scheme for images corrupted by impulse noise is presented. The proposed scheme efficiently identifies and reduces salt and pepper noise. MAG (Mean Absolute Gradient) is used to identify pixels which are most likely corrupted by salt and pepper noise that are candidates for further median based noise reduction processing. Directional filtering is then applied after noise reduction to achieve a good tradeoff between detail preservation and noise removal. The proposed scheme can remove salt and pepper noise with noise density as high as 90% and produce better result in terms of qualitative and quantitative measures of images.\n    ",
        "submission_date": "2012-01-10T00:00:00",
        "last_modified_date": "2012-01-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1201.2605",
        "title": "Autonomous Cleaning of Corrupted Scanned Documents - A Generative Modeling Approach",
        "authors": [
            "Zhenwen Dai",
            "J\u00f6rg L\u00fccke"
        ],
        "abstract": "We study the task of cleaning scanned text documents that are strongly corrupted by dirt such as manual line strokes, spilled ink etc. We aim at autonomously removing dirt from a single letter-size page based only on the information the page contains. Our approach, therefore, has to learn character representations without supervision and requires a mechanism to distinguish learned representations from irregular patterns. To learn character representations, we use a probabilistic generative model parameterizing pattern features, feature variances, the features' planar arrangements, and pattern frequencies. The latent variables of the model describe pattern class, pattern position, and the presence or absence of individual pattern features. The model parameters are optimized using a novel variational EM approximation. After learning, the parameters represent, independently of their absolute position, planar feature arrangements and their variances. A quality measure defined based on the learned representation then allows for an autonomous discrimination between regular character patterns and the irregular patterns making up the dirt. The irregular patterns can thus be removed to clean the document. For a full Latin alphabet we found that a single page does not contain sufficiently many character examples. However, even if heavily corrupted by dirt, we show that a page containing a lower number of character types can efficiently and autonomously be cleaned solely based on the structural regularity of the characters it contains. In different examples using characters from different alphabets, we demonstrate generality of the approach and discuss its implications for future developments.\n    ",
        "submission_date": "2012-01-12T00:00:00",
        "last_modified_date": "2012-07-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1201.2843",
        "title": "Nonparametric Sparse Representation",
        "authors": [
            "Mahmoud Ramezani Mayiami",
            "Babak Seyfe"
        ],
        "abstract": "This paper suggests a nonparametric scheme to find the sparse solution of the underdetermined system of linear equations in the presence of unknown impulsive or non-Gaussian noise. This approach is robust against any variations of the noise model and its parameters. It is based on minimization of rank pseudo norm of the residual signal and l_1-norm of the signal of interest, simultaneously. We use the steepest descent method to find the sparse solution via an iterative algorithm. Simulation results show that our proposed method outperforms the existence methods like OMP, BP, Lasso, and BCS whenever the observation vector is contaminated with measurement or environmental non-Gaussian noise with unknown parameters. Furthermore, for low SNR condition, the proposed method has better performance in the presence of Gaussian noise.\n    ",
        "submission_date": "2012-01-13T00:00:00",
        "last_modified_date": "2012-01-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1201.2905",
        "title": "NegCut: Automatic Image Segmentation based on MRF-MAP",
        "authors": [
            "Zhao Qiyang"
        ],
        "abstract": "Solving the Maximum a Posteriori on Markov Random Field, MRF-MAP, is a prevailing method in recent interactive image segmentation tools. Although mathematically explicit in its computational targets, and impressive for the segmentation quality, MRF-MAP is hard to accomplish without the interactive information from users. So it is rarely adopted in the automatic style up to today. In this paper, we present an automatic image segmentation algorithm, NegCut, based on the approximation to MRF-MAP. First we prove MRF-MAP is NP-hard when the probabilistic models are unknown, and then present an approximation function in the form of minimum cuts on graphs with negative weights. Finally, the binary segmentation is taken from the largest eigenvector of the target matrix, with a tuned version of the Lanczos eigensolver. It is shown competitive at the segmentation quality in our experiments.\n    ",
        "submission_date": "2012-01-13T00:00:00",
        "last_modified_date": "2012-01-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1201.2995",
        "title": "G-Lets: Signal Processing Using Transformation Groups",
        "authors": [
            "B.Rajathilagam",
            "Murali Rangarajan",
            "K.P.Soman"
        ],
        "abstract": "We present an algorithm using transformation groups and their irreducible representations to generate an orthogonal basis for a signal in the vector space of the signal. It is shown that multiresolution analysis can be done with amplitudes using a transformation group. G-lets is thus not a single transform, but a group of linear transformations related by group theory. The algorithm also specifies that a multiresolution and multiscale analysis for each resolution is possible in terms of frequencies. Separation of low and high frequency components of each amplitude resolution is facilitated by G-lets. Using conjugacy classes of the transformation group, more than one set of basis may be generated, giving a different perspective of the signal through each basis. Applications for this algorithm include edge detection, feature extraction, denoising, face recognition, compression, and more. We analyze this algorithm using dihedral groups as an example. We demonstrate the results with an ECG signal and the standard `Lena' image.\n    ",
        "submission_date": "2012-01-14T00:00:00",
        "last_modified_date": "2012-01-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1201.3109",
        "title": "Automatic system for counting cells with elliptical shape",
        "authors": [
            "Wesley Nunes Gon\u00e7alves",
            "Odemir Martinez Bruno"
        ],
        "abstract": "This paper presents a new method for automatic quantification of ellipse-like cells in images, an important and challenging problem that has been studied by the computer vision community. The proposed method can be described by two main steps. Initially, image segmentation based on the k-means algorithm is performed to separate different types of cells from the background. Then, a robust and efficient strategy is performed on the blob contour for touching cells splitting. Due to the contour processing, the method achieves excellent results of detection compared to manual detection performed by specialists.\n    ",
        "submission_date": "2012-01-15T00:00:00",
        "last_modified_date": "2012-01-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1201.3116",
        "title": "Enhancing Volumetric Bouligand-Minkowski Fractal Descriptors by using Functional Data Analysis",
        "authors": [
            "Jo\u00e3o Batista Florindo",
            "M\u00e1rio de Castro",
            "Odemir Martinez Bruno"
        ],
        "abstract": "This work proposes and study the concept of Functional Data Analysis transform, applying it to the performance improving of volumetric Bouligand-Minkowski fractal descriptors. The proposed transform consists essentially in changing the descriptors originally defined in the space of the calculus of fractal dimension into the space of coefficients used in the functional data representation of these descriptors. The transformed decriptors are used here in texture classification problems. The enhancement provided by the FDA transform is measured by comparing the transformed to the original descriptors in terms of the correctness rate in the classification of well known datasets.\n    ",
        "submission_date": "2012-01-15T00:00:00",
        "last_modified_date": "2012-01-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1201.3153",
        "title": "Fractal and Multi-Scale Fractal Dimension analysis: a comparative study of Bouligand-Minkowski method",
        "authors": [
            "Andr\u00e9 Ricardo Backes",
            "Odemir Martinez Bruno"
        ],
        "abstract": "Shape is one of the most important visual attributes to characterize objects, playing a important role in pattern recognition. There are various approaches to extract relevant information of a shape. An approach widely used in shape analysis is the complexity, and Fractal Dimension and Multi-Scale Fractal Dimension are both well-known methodologies to estimate it. This papers presents a comparative study between Fractal Dimension and Multi-Scale Fractal Dimension in a shape analysis context. Through experimental comparison using a shape database previously classified, both methods are compared. Different parameters configuration of each method are considered and a discussion about the results of each method is also presented.\n    ",
        "submission_date": "2012-01-16T00:00:00",
        "last_modified_date": "2012-01-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1201.3233",
        "title": "Variations of images to increase their visibility",
        "authors": [
            "Amelia Carolina Sparavigna"
        ],
        "abstract": "The calculus of variations applied to the image processing requires some numerical models able to perform the variations of images and the extremization of appropriate actions. To produce the variations of images, there are several possibilities based on the brightness maps. Before a numerical model, I propose an experimental approach, based on a tool of Gimp, GNU Image Manipulation Program, in order to visualize how the image variations can be. After the discussion of this tool, which is able to strongly increase the visibility of images, the variations and a possible functional for the visibility are proposed in the framework of a numerical model. The visibility functional is analogous to the fringe visibility of the optical interference.\n    ",
        "submission_date": "2012-01-16T00:00:00",
        "last_modified_date": "2012-01-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1201.3337",
        "title": "A New Color Feature Extraction Method Based on Dynamic Color Distribution Entropy of Neighborhoods",
        "authors": [
            "Fatemeh Alamdar",
            "MohammadReza Keyvanpour"
        ],
        "abstract": "One of the important requirements in image retrieval, indexing, classification, clustering and etc. is extracting efficient features from images. The color feature is one of the most widely used visual features. Use of color histogram is the most common way for representing color feature. One of disadvantage of the color histogram is that it does not take the color spatial distribution into consideration. In this paper dynamic color distribution entropy of neighborhoods method based on color distribution entropy is presented, which effectively describes the spatial information of colors. The image retrieval results in compare to improved color distribution entropy show the acceptable efficiency of this approach.\n    ",
        "submission_date": "2012-01-08T00:00:00",
        "last_modified_date": "2012-01-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1201.3612",
        "title": "Spatiotemporal Gabor filters: a new method for dynamic texture recognition",
        "authors": [
            "Wesley Nunes Gon\u00e7alves",
            "Bruno Brandoli Machado",
            "Odemir Martinez Bruno"
        ],
        "abstract": "This paper presents a new method for dynamic texture recognition based on spatiotemporal Gabor filters. Dynamic textures have emerged as a new field of investigation that extends the concept of self-similarity of texture image to the spatiotemporal domain. To model a dynamic texture, we convolve the sequence of images to a bank of spatiotemporal Gabor filters. For each response, a feature vector is built by calculating the energy statistic. As far as the authors know, this paper is the first to report an effective method for dynamic texture recognition using spatiotemporal Gabor filters. We evaluate the proposed method on two challenging databases and the experimental results indicate that the proposed method is a robust approach for dynamic texture recognition.\n    ",
        "submission_date": "2012-01-17T00:00:00",
        "last_modified_date": "2012-01-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1201.3674",
        "title": "On the Lagrangian Biduality of Sparsity Minimization Problems",
        "authors": [
            "Dheeraj Singaraju",
            "Ehsan Elhamifar",
            "Roberto Tron",
            "Allen Y. Yang",
            "S. Shankar Sastry"
        ],
        "abstract": "Recent results in Compressive Sensing have shown that, under certain conditions, the solution to an underdetermined system of linear equations with sparsity-based regularization can be accurately recovered by solving convex relaxations of the original problem. In this work, we present a novel primal-dual analysis on a class of sparsity minimization problems. We show that the Lagrangian bidual (i.e., the Lagrangian dual of the Lagrangian dual) of the sparsity minimization problems can be used to derive interesting convex relaxations: the bidual of the $\\ell_0$-minimization problem is the $\\ell_1$-minimization problem; and the bidual of the $\\ell_{0,1}$-minimization problem for enforcing group sparsity on structured data is the $\\ell_{1,\\infty}$-minimization problem. The analysis provides a means to compute per-instance non-trivial lower bounds on the (group) sparsity of the desired solutions. In a real-world application, the bidual relaxation improves the performance of a sparsity-based classification framework applied to robust face recognition.\n    ",
        "submission_date": "2012-01-18T00:00:00",
        "last_modified_date": "2012-01-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1201.3720",
        "title": "A Multimodal Biometric System Using Linear Discriminant Analysis For Improved Performance",
        "authors": [
            "Aamir Khan",
            "Muhammad Farhan",
            "Aasim Khurshid",
            "Adeel Akram"
        ],
        "abstract": "Essentially a biometric system is a pattern recognition system which recognizes a user by determining the authenticity of a specific anatomical or behavioral characteristic possessed by the user. With the ever increasing integration of computers and Internet into daily life style, it has become necessary to protect sensitive and personal data. This paper proposes a multimodal biometric system which incorporates more than one biometric trait to attain higher security and to handle failure to enroll situations for some users. This paper is aimed at investigating a multimodal biometric identity system using Linear Discriminant Analysis as backbone to both facial and speech recognition and implementing such system in real-time using SignalWAVE.\n    ",
        "submission_date": "2012-01-18T00:00:00",
        "last_modified_date": "2012-01-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1201.3803",
        "title": "Image Labeling and Segmentation using Hierarchical Conditional Random Field Model",
        "authors": [
            "Manoj K. Vairalkar",
            "Sonali. Nimbhorkar"
        ],
        "abstract": "The use of hierarchical Conditional Random Field model deal with the problem of labeling images . At the time of labeling a new image, selection of the nearest cluster and using the related CRF model to label this image. When one give input image, one first use the CRF model to get initial pixel labels then finding the cluster with most similar images. Then at last relabeling the input image by the CRF model associated with this cluster. This paper presents a approach to label and segment specific image having correct information.\n    ",
        "submission_date": "2012-01-16T00:00:00",
        "last_modified_date": "2012-01-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1201.3821",
        "title": "A PCA-Based Super-Resolution Algorithm for Short Image Sequences",
        "authors": [
            "Carlos Miravet",
            "Francisco B. Rodr\u00edguez"
        ],
        "abstract": "In this paper, we present a novel, learning-based, two-step super-resolution (SR) algorithm well suited to solve the specially demanding problem of obtaining SR estimates from short image sequences. The first step, devoted to increase the sampling rate of the incoming images, is performed by fitting linear combinations of functions generated from principal components (PC) to reproduce locally the sparse projected image data, and using these models to estimate image values at nodes of the high-resolution grid. PCs were obtained from local image patches sampled at sub-pixel level, which were generated in turn from a database of high-resolution images by application of a physically realistic observation model. Continuity between local image models is enforced by minimizing an adequate functional in the space of model coefficients. The second step, dealing with restoration, is performed by a linear filter with coefficients learned to restore residual interpolation artifacts in addition to low-resolution blurring, providing an effective coupling between both steps of the method. Results on a demanding five-image scanned sequence of graphics and text are presented, showing the excellent performance of the proposed method compared to several state-of-the-art two-step and Bayesian Maximum a Posteriori SR algorithms.\n    ",
        "submission_date": "2012-01-18T00:00:00",
        "last_modified_date": "2012-01-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1201.3972",
        "title": "A Novel Approach to Fast Image Filtering Algorithm of Infrared Images based on Intro Sort Algorithm",
        "authors": [
            "Kapil Kumar Gupta",
            "Rizwan Beg",
            "Jitendra Kumar Niranjan"
        ],
        "abstract": "In this study we investigate the fast image filtering algorithm based on Intro sort algorithm and fast noise reduction of infrared images. Main feature of the proposed approach is that no prior knowledge of noise required. It is developed based on Stefan- Boltzmann law and the Fourier law. We also investigate the fast noise reduction approach that has advantage of less computation load. In addition, it can retain edges, details, text information even if the size of the window increases. Intro sort algorithm begins with Quick sort and switches to heap sort when the recursion depth exceeds a level based on the number of elements being sorted. This approach has the advantage of fast noise reduction by reducing the comparison time. It also significantly speed up the noise reduction process and can apply to real-time image processing. This approach will extend the Infrared images applications for medicine and video conferencing.\n    ",
        "submission_date": "2012-01-19T00:00:00",
        "last_modified_date": "2012-01-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1201.4139",
        "title": "Image decomposition with anisotropic diffusion applied to leaf-texture analysis",
        "authors": [
            "Bruno Brandoli Machado",
            "Wesley Nunes Gon\u00e7alves",
            "Odemir Martinez Bruno"
        ],
        "abstract": "Texture analysis is an important field of investigation that has received a great deal of interest from computer vision community. In this paper, we propose a novel approach for texture modeling based on partial differential equation (PDE). Each image $f$ is decomposed into a family of derived sub-images. $f$ is split into the $u$ component, obtained with anisotropic diffusion, and the $v$ component which is calculated by the difference between the original image and the $u$ component. After enhancing the texture attribute $v$ of the image, Gabor features are computed as descriptors. We validate the proposed approach on two texture datasets with high variability. We also evaluate our approach on an important real-world application: leaf-texture analysis. Experimental results indicate that our approach can be used to produce higher classification rates and can be successfully employed for different texture applications.\n    ",
        "submission_date": "2012-01-19T00:00:00",
        "last_modified_date": "2012-01-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1201.4895",
        "title": "Compressive Acquisition of Dynamic Scenes",
        "authors": [
            "Aswin C Sankaranarayanan",
            "Pavan K Turaga",
            "Rama Chellappa",
            "Richard G Baraniuk"
        ],
        "abstract": "Compressive sensing (CS) is a new approach for the acquisition and recovery of sparse signals and images that enables sampling rates significantly below the classical Nyquist rate. Despite significant progress in the theory and methods of CS, little headway has been made in compressive video acquisition and recovery. Video CS is complicated by the ephemeral nature of dynamic events, which makes direct extensions of standard CS imaging architectures and signal models difficult. In this paper, we develop a new framework for video CS for dynamic textured scenes that models the evolution of the scene as a linear dynamical system (LDS). This reduces the video recovery problem to first estimating the model parameters of the LDS from compressive measurements, and then reconstructing the image frames. We exploit the low-dimensional dynamic parameters (the state sequence) and high-dimensional static parameters (the observation matrix) of the LDS to devise a novel compressive measurement strategy that measures only the dynamic part of the scene at each instant and accumulates measurements over time to estimate the static parameters. This enables us to lower the compressive measurement rate considerably. We validate our approach with a range of experiments involving both video recovery, sensing hyper-spectral data, and classification of dynamic scenes from compressive data. Together, these applications demonstrate the effectiveness of the approach.\n    ",
        "submission_date": "2012-01-23T00:00:00",
        "last_modified_date": "2013-06-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1201.5227",
        "title": "A New Local Adaptive Thresholding Technique in Binarization",
        "authors": [
            "T. Romen Singh",
            "Sudipta Roy",
            "O. Imocha Singh",
            "Tejmani Sinam",
            "Kh. Manglem Singh"
        ],
        "abstract": "Image binarization is the process of separation of pixel values into two groups, white as background and black as foreground. Thresholding plays a major in binarization of images. Thresholding can be categorized into global thresholding and local thresholding. In images with uniform contrast distribution of background and foreground like document images, global thresholding is more appropriate. In degraded document images, where considerable background noise or variation in contrast and illumination exists, there exists many pixels that cannot be easily classified as foreground or background. In such cases, binarization with local thresholding is more appropriate. This paper describes a locally adaptive thresholding technique that removes background by using local mean and mean deviation. Normally the local mean computational time depends on the window size. Our technique uses integral sum image as a prior processing to calculate local mean. It does not involve calculations of standard deviations as in other local adaptive techniques. This along with the fact that calculations of mean is independent of window size speed up the process as compared to other local thresholding techniques.\n    ",
        "submission_date": "2012-01-25T00:00:00",
        "last_modified_date": "2012-01-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1201.5404",
        "title": "Task-Driven Adaptive Statistical Compressive Sensing of Gaussian Mixture Models",
        "authors": [
            "Julio M. Duarte-Carvajalino",
            "Guoshen Yu",
            "Lawrence Carin",
            "Guillermo Sapiro"
        ],
        "abstract": "A framework for adaptive and non-adaptive statistical compressive sensing is developed, where a statistical model replaces the standard sparsity model of classical compressive sensing. We propose within this framework optimal task-specific sensing protocols specifically and jointly designed for classification and reconstruction. A two-step adaptive sensing paradigm is developed, where online sensing is applied to detect the signal class in the first step, followed by a reconstruction step adapted to the detected class and the observed samples. The approach is based on information theory, here tailored for Gaussian mixture models (GMMs), where an information-theoretic objective relationship between the sensed signals and a representation of the specific task of interest is maximized. Experimental results using synthetic signals, Landsat satellite attributes, and natural images of different sizes and with different noise levels show the improvements achieved using the proposed framework when compared to more standard sensing protocols. The underlying formulation can be applied beyond GMMs, at the price of higher mathematical and computational complexity.\n    ",
        "submission_date": "2012-01-25T00:00:00",
        "last_modified_date": "2012-01-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1201.5938",
        "title": "Comparing Methods for segmentation of Microcalcification Clusters in Digitized Mammograms",
        "authors": [
            "Hajar Moradmand",
            "Saeed Setayeshi",
            "Hossein Khazaei Targhi"
        ],
        "abstract": "The appearance of microcalcifications in mammograms is one of the early signs of breast cancer. So, early detection of microcalcification clusters (MCCs) in mammograms can be helpful for cancer diagnosis and better treatment of breast cancer. In this paper a computer method has been proposed to support radiologists in detection MCCs in digital mammography. First, in order to facilitate and improve the detection step, mammogram images have been enhanced with wavelet transformation and morphology operation. Then for segmentation of suspicious MCCs, two methods have been investigated. The considered methods are: adaptive threshold and watershed segmentation. Finally, the detected MCCs areas in different algorithms will be compared to find out which segmentation method is more appropriate for extracting MCCs in mammograms.\n    ",
        "submission_date": "2012-01-28T00:00:00",
        "last_modified_date": "2012-01-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1201.5946",
        "title": "Feature selection using nearest attributes",
        "authors": [
            "Alex Pappachen James",
            "Sima Dimitrijev"
        ],
        "abstract": "Feature selection is an important problem in high-dimensional data analysis and classification. Conventional feature selection approaches focus on detecting the features based on a redundancy criterion using learning and feature searching schemes. In contrast, we present an approach that identifies the need to select features based on their discriminatory ability among classes. Area of overlap between inter-class and intra-class distances resulting from feature to feature comparison of an attribute is used as a measure of discriminatory ability of the feature. A set of nearest attributes in a pattern having the lowest area of overlap within a degree of tolerance defined by a selection threshold is selected to represent the best available discriminable features. State of the art recognition results are reported for pattern classification problems by using the proposed feature selection scheme with the nearest neighbour classifier. These results are reported with benchmark databases having high dimensional feature vectors in the problems involving images and micro array data.\n    ",
        "submission_date": "2012-01-28T00:00:00",
        "last_modified_date": "2012-01-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1201.5947",
        "title": "Examplers based image fusion features for face recognition",
        "authors": [
            "Alex Pappachen James",
            "Sima Dimitrijev"
        ],
        "abstract": "Examplers of a face are formed from multiple gallery images of a person and are used in the process of classification of a test image. We incorporate such examplers in forming a biologically inspired local binary decisions on similarity based face recognition method. As opposed to single model approaches such as face averages the exampler based approach results in higher recognition accu- racies and stability. Using multiple training samples per person, the method shows the following recognition accuracies: 99.0% on AR, 99.5% on FERET, 99.5% on ORL, 99.3% on EYALE, 100.0% on YALE and 100.0% on CALTECH face databases. In addition to face recognition, the method also detects the natural variability in the face images which can find application in automatic tagging of face images.\n    ",
        "submission_date": "2012-01-28T00:00:00",
        "last_modified_date": "2012-01-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1202.0216",
        "title": "The watershed concept and its use in segmentation : a brief history",
        "authors": [
            "Fernand Meyer"
        ],
        "abstract": "The watershed is one of the most used tools in image segmentation. We present how its concept is born and developed over time. Its implementation as an algorithm or a hardwired device evolved together with the technology which allowed it. We present also how it is used in practice, first together with markers, and later introduced in a multiscale framework, in order to produce not a unique partition but a complete hierarchy.\n    ",
        "submission_date": "2012-02-01T00:00:00",
        "last_modified_date": "2012-02-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1202.0492",
        "title": "Resolving Implementation Ambiguity and Improving SURF",
        "authors": [
            "Peter Abeles"
        ],
        "abstract": "Speeded Up Robust Features (SURF) has emerged as one of the more popular feature descriptors and detectors in recent years. Performance and algorithmic details vary widely between implementations due to SURF's complexity and ambiguities found in its description. To resolve these ambiguities, a set of general techniques for feature stability is defined based on the smoothness rule. Additional improvements to SURF are proposed for speed and stability. To illustrate the importance of these implementation details, a performance study of popular SURF implementations is done. By utilizing all the suggested improvements, it is possible to create a SURF implementation that is several times faster and more stable.\n    ",
        "submission_date": "2012-02-02T00:00:00",
        "last_modified_date": "2012-03-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1202.0549",
        "title": "Comparing Background Subtraction Algorithms and Method of Car Counting",
        "authors": [
            "Gautam S. Thakur",
            "Mohsen Ali",
            "Pan Hui",
            "Ahmed Helmy"
        ],
        "abstract": "In this paper, we compare various image background subtraction algorithms with the ground truth of cars counted. We have given a sample of thousand images, which are the snap shots of current traffic as records at various intersections and highways. We have also counted an approximate number of cars that are visible in these images. In order to ascertain the accuracy of algorithms to be used for the processing of million images, we compare them on many metrics that includes (i) Scalability (ii) Accuracy (iii) Processing time.\n    ",
        "submission_date": "2012-01-29T00:00:00",
        "last_modified_date": "2012-01-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1202.0609",
        "title": "Wavelet-based deconvolution of ultrasonic signals in nondestructive evaluation",
        "authors": [
            "Roberto Henry Herrera",
            "Rub\u00e9n Orozco",
            "Manuel Rodr\u00edguez"
        ],
        "abstract": "In this paper, the inverse problem of reconstructing reflectivity function of a medium is examined within a blind deconvolution framework. The ultrasound pulse is estimated using higher-order statistics, and Wiener filter is used to obtain the ultrasonic reflectivity function through wavelet-based models. A new approach to the parameter estimation of the inverse filtering step is proposed in the nondestructive evaluation field, which is based on the theory of Fourier-Wavelet regularized deconvolution (ForWaRD). This new approach can be viewed as a solution to the open problem of adaptation of the ForWaRD framework to perform the convolution kernel estimation and deconvolution interdependently. The results indicate stable solutions of the estimated pulse and an improvement in the radio-frequency (RF) signal taking into account its signal-to-noise ratio (SNR) and axial resolution. Simulations and experiments showed that the proposed approach can provide robust and optimal estimates of the reflectivity function.\n    ",
        "submission_date": "2012-02-03T00:00:00",
        "last_modified_date": "2012-02-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1202.1444",
        "title": "Fully Automatic Expression-Invariant Face Correspondence",
        "authors": [
            "Augusto Salazar",
            "Stefanie Wuhrer",
            "Chang Shu",
            "Flavio Prieto"
        ],
        "abstract": "We consider the problem of computing accurate point-to-point correspondences among a set of human face scans with varying expressions. Our fully automatic approach does not require any manually placed markers on the scan. Instead, the approach learns the locations of a set of landmarks present in a database and uses this knowledge to automatically predict the locations of these landmarks on a newly available scan. The predicted landmarks are then used to compute point-to-point correspondences between a template model and the newly available scan. To accurately fit the expression of the template to the expression of the scan, we use as template a blendshape model. Our algorithm was tested on a database of human faces of different ethnic groups with strongly varying expressions. Experimental results show that the obtained point-to-point correspondence is both highly accurate and consistent for most of the tested 3D face models.\n    ",
        "submission_date": "2012-02-07T00:00:00",
        "last_modified_date": "2013-01-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1202.1585",
        "title": "Robust seed selection algorithm for k-means type algorithms",
        "authors": [
            "K. Karteeka Pavan",
            "Allam Appa Rao",
            "A.V. Dattatreya Rao",
            "G.R.Sridhar"
        ],
        "abstract": "Selection of initial seeds greatly affects the quality of the clusters and in k-means type algorithms. Most of the seed selection methods result different results in different independent runs. We propose a single, optimal, outlier insensitive seed selection algorithm for k-means type algorithms as extension to k-means++. The experimental results on synthetic, real and on microarray data sets demonstrated that effectiveness of the new algorithm in producing the clustering results\n    ",
        "submission_date": "2012-02-08T00:00:00",
        "last_modified_date": "2012-02-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1202.1587",
        "title": "Automatic Clustering with Single Optimal Solution",
        "authors": [
            "K. Karteeka Pavan",
            "Allam Appa Rao",
            "A. V. Dattatreya Rao"
        ],
        "abstract": "Determining optimal number of clusters in a dataset is a challenging task. Though some methods are available, there is no algorithm that produces unique clustering solution. The paper proposes an Automatic Merging for Single Optimal Solution (AMSOS) which aims to generate unique and nearly optimal clusters for the given datasets automatically. The AMSOS is iteratively merges the closest clusters automatically by validating with cluster validity measure to find single and nearly optimal clusters for the given data set. Experiments on both synthetic and real data have proved that the proposed algorithm finds single and nearly optimal clustering structure in terms of number of clusters, compactness and separation.\n    ",
        "submission_date": "2012-02-08T00:00:00",
        "last_modified_date": "2012-02-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1202.1685",
        "title": "Combined Haar-Hilbert and Log-Gabor Based Iris Encoders",
        "authors": [
            "Valentina E. Balas",
            "Iulia M. Motoc",
            "Alina Barbulescu"
        ],
        "abstract": "This chapter shows that combining Haar-Hilbert and Log-Gabor improves iris recognition performance leading to a less ambiguous biometric decision landscape in which the overlap between the experimental intra- and interclass score distributions diminishes or even vanishes. Haar-Hilbert, Log-Gabor and combined Haar-Hilbert and Log-Gabor encoders are tested here both for single and dual iris approach. The experimental results confirm that the best performance is obtained for the dual iris approach when the iris code is generated using the combined Haar-Hilbert and Log-Gabor encoder, and when the matching score fuses the information from both Haar-Hilbert and Log-Gabor channels of the combined encoder.\n    ",
        "submission_date": "2012-02-08T00:00:00",
        "last_modified_date": "2012-02-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1202.1943",
        "title": "3D Model Assisted Image Segmentation",
        "authors": [
            "Srimal Jayawardena",
            "Di Yang",
            "Marcus Hutter"
        ],
        "abstract": "The problem of segmenting a given image into coherent regions is important in Computer Vision and many industrial applications require segmenting a known object into its components. Examples include identifying individual parts of a component for process control work in a manufacturing plant and identifying parts of a car from a photo for automatic damage detection. Unfortunately most of an object's parts of interest in such applications share the same pixel characteristics, having similar colour and texture. This makes segmenting the object into its components a non-trivial task for conventional image segmentation algorithms. In this paper, we propose a \"Model Assisted Segmentation\" method to tackle this problem. A 3D model of the object is registered over the given image by optimising a novel gradient based loss function. This registration obtains the full 3D pose from an image of the object. The image can have an arbitrary view of the object and is not limited to a particular set of views. The segmentation is subsequently performed using a level-set based method, using the projected contours of the registered 3D model as initialisation curves. The method is fully automatic and requires no user interaction. Also, the system does not require any prior training. We present our results on photographs of a real car.\n    ",
        "submission_date": "2012-02-09T00:00:00",
        "last_modified_date": "2012-02-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1202.1990",
        "title": "Non-parametric convolution based image-segmentation of ill-posed objects applying context window approach",
        "authors": [
            "Upendra Kumar",
            "Tapobrata Lahiri",
            "Manoj Kumar Pal"
        ],
        "abstract": "Context-dependence in human cognition process is a well-established fact. Following this, we introduced the image segmentation method that can use context to classify a pixel on the basis of its membership to a particular object-class of the concerned image. In the broad methodological steps, each pixel was defined by its context window (CW) surrounding it the size of which was fixed heuristically. CW texture defined by the intensities of its pixels was convoluted with weights optimized through a non-parametric function supported by a backpropagation network. Result of convolution was used to classify them. The training data points (i.e., pixels) were carefully chosen to include all variety of contexts of types, i) points within the object, ii) points near the edge but inside the objects, iii) points at the border of the objects, iv) points near the edge but outside the objects, v) points near or at the edge of the image frame. Moreover the training data points were selected from all the images within image-dataset. CW texture information for 1000 pixels from face area and background area of images were captured, out of which 700 CWs were used as training input data, and remaining 300 for testing. Our work gives the first time foundation of quantitative enumeration of efficiency of image-segmentation which is extendable to segment out more than 2 objects within an image.\n    ",
        "submission_date": "2012-02-09T00:00:00",
        "last_modified_date": "2012-02-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1202.2160",
        "title": "Scene Parsing with Multiscale Feature Learning, Purity Trees, and Optimal Covers",
        "authors": [
            "Cl\u00e9ment Farabet",
            "Camille Couprie",
            "Laurent Najman",
            "Yann LeCun"
        ],
        "abstract": "Scene parsing, or semantic segmentation, consists in labeling each pixel in an image with the category of the object it belongs to. It is a challenging task that involves the simultaneous detection, segmentation and recognition of all the objects in the image.\n",
        "submission_date": "2012-02-10T00:00:00",
        "last_modified_date": "2012-07-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1202.2350",
        "title": "Streaming an image through the eye: The retina seen as a dithered scalable image coder",
        "authors": [
            "Khaled Masmoudi",
            "Marc Antonini",
            "Pierre Kornprobst"
        ],
        "abstract": "We propose the design of an original scalable image coder/decoder that is inspired from the mammalians retina. Our coder accounts for the time-dependent and also nondeterministic behavior of the actual retina. The present work brings two main contributions: As a first step, (i) we design a deterministic image coder mimicking most of the retinal processing stages and then (ii) we introduce a retinal noise in the coding process, that we model here as a dither signal, to gain interesting perceptual features. Regarding our first contribution, our main source of inspiration will be the biologically plausible model of the retina called Virtual Retina. The main novelty of this coder is to show that the time-dependent behavior of the retina cells could ensure, in an implicit way, scalability and bit allocation. Regarding our second contribution, we reconsider the inner layers of the retina. We emit a possible interpretation for the non-determinism observed by neurophysiologists in their output. For this sake, we model the retinal noise that occurs in these layers by a dither signal. The dithering process that we propose adds several interesting features to our image coder. The dither noise whitens the reconstruction error and decorrelates it from the input stimuli. Furthermore, integrating the dither noise in our coder allows a faster recognition of the fine details of the image during the decoding process. Our present paper goal is twofold. First, we aim at mimicking as closely as possible the retina for the design of a novel image coder while keeping encouraging performances. Second, we bring a new insight concerning the non-deterministic behavior of the retina.\n    ",
        "submission_date": "2012-02-10T00:00:00",
        "last_modified_date": "2012-02-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1202.2368",
        "title": "An evaluation of local shape descriptors for 3D shape retrieval",
        "authors": [
            "Sarah Tang",
            "Afzal Godil"
        ],
        "abstract": "As the usage of 3D models increases, so does the importance of developing accurate 3D shape retrieval algorithms. A common approach is to calculate a shape descriptor for each object, which can then be compared to determine two objects' similarity. However, these descriptors are often evaluated independently and on different datasets, making them difficult to compare. Using the SHREC 2011 Shape Retrieval Contest of Non-rigid 3D Watertight Meshes dataset, we systematically evaluate a collection of local shape descriptors. We apply each descriptor to the bag-of-words paradigm and assess the effects of varying the dictionary's size and the number of sample points. In addition, several salient point detection methods are used to choose sample points; these methods are compared to each other and to random selection. Finally, information from two local descriptors is combined in two ways and changes in performance are investigated. This paper presents results of these experiment\n    ",
        "submission_date": "2012-02-10T00:00:00",
        "last_modified_date": "2012-02-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1202.2449",
        "title": "Efficient Web-based Facial Recognition System Employing 2DHOG",
        "authors": [
            "Moataz M. Abdelwahab",
            "Salah A. Aly",
            "Islam Yousry"
        ],
        "abstract": "In this paper, a system for facial recognition to identify missing and found people in Hajj and Umrah is described as a web portal. Explicitly, we present a novel algorithm for recognition and classifications of facial images based on applying 2DPCA to a 2D representation of the Histogram of oriented gradients (2D-HOG) which maintains the spatial relation between pixels of the input images. This algorithm allows a compact representation of the images which reduces the computational complexity and the storage requirments, while maintaining the highest reported recognition accuracy. This promotes this method for usage with very large datasets. Large dataset was collected for people in Hajj. Experimental results employing ORL, UMIST, JAFFE, and HAJJ datasets confirm these excellent properties.\n    ",
        "submission_date": "2012-02-11T00:00:00",
        "last_modified_date": "2012-02-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1202.2528",
        "title": "Using Covariance Matrices as Feature Descriptors for Vehicle Detection from a Fixed Camera",
        "authors": [
            "Kevin Mader",
            "Gil Reese"
        ],
        "abstract": "A method is developed to distinguish between cars and trucks present in a video feed of a highway. The method builds upon previously done work using covariance matrices as an accurate descriptor for regions. Background subtraction and other similar proven image processing techniques are used to identify the regions where the vehicles are most likely to be, and a distance metric comparing the vehicle inside the region to a fixed library of vehicles is used to determine the class of vehicle.\n    ",
        "submission_date": "2012-02-12T00:00:00",
        "last_modified_date": "2012-02-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1202.2745",
        "title": "Multi-column Deep Neural Networks for Image Classification",
        "authors": [
            "Dan Cire\u015fan",
            "Ueli Meier",
            "Juergen Schmidhuber"
        ],
        "abstract": "Traditional methods of computer vision and machine learning cannot match human performance on tasks such as the recognition of handwritten digits or traffic signs. Our biologically plausible deep artificial neural network architectures can. Small (often minimal) receptive fields of convolutional winner-take-all neurons yield large network depth, resulting in roughly as many sparsely connected neural layers as found in mammals between retina and visual cortex. Only winner neurons are trained. Several deep neural columns become experts on inputs preprocessed in different ways; their predictions are averaged. Graphics cards allow for fast training. On the very competitive MNIST handwriting benchmark, our method is the first to achieve near-human performance. On a traffic sign recognition benchmark it outperforms humans by a factor of two. We also improve the state-of-the-art on a plethora of common image classification benchmarks.\n    ",
        "submission_date": "2012-02-13T00:00:00",
        "last_modified_date": "2012-02-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1202.3021",
        "title": "No-reference image quality assessment through the von Mises distribution",
        "authors": [
            "Salvador Gabarda",
            "Gabriel Cristobal"
        ],
        "abstract": "An innovative way of calculating the von Mises distribution (VMD) of image entropy is introduced in this paper. The VMD's concentration parameter and some fitness parameter that will be later defined, have been analyzed in the experimental part for determining their suitability as a image quality assessment measure in some particular distortions such as Gaussian blur or additive Gaussian noise. To achieve such measure, the local R\u00e9nyi entropy is calculated in four equally spaced orientations and used to determine the parameters of the von Mises distribution of the image entropy. Considering contextual images, experimental results after applying this model show that the best-in-focus noise-free images are associated with the highest values for the von Mises distribution concentration parameter and the highest approximation of image data to the von Mises distribution model. Our defined von Misses fitness parameter experimentally appears also as a suitable no-reference image quality assessment indicator for no-contextual images.\n    ",
        "submission_date": "2012-02-14T00:00:00",
        "last_modified_date": "2012-02-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1202.3046",
        "title": "Segmentation of Offline Handwritten Bengali Script",
        "authors": [
            "Subhadip Basu",
            "Chitrita Chaudhuri",
            "Mahantapas Kundu",
            "Mita Nasipuri",
            "Dipak K. Basu"
        ],
        "abstract": "Character segmentation has long been one of the most critical areas of optical character recognition process. Through this operation, an image of a sequence of characters, which may be connected in some cases, is decomposed into sub-images of individual alphabetic symbols. In this paper, segmentation of cursive handwritten script of world's fourth popular language, Bengali, is considered. Unlike English script, Bengali handwritten characters and its components often encircle the main character, making the conventional segmentation methodologies inapplicable. Experimental results, using the proposed segmentation technique, on sample cursive handwritten data containing 218 ideal segmentation points show a success rate of 97.7%. Further feature-analysis on these segments may lead to actual recognition of handwritten cursive Bengali script.\n    ",
        "submission_date": "2012-02-14T00:00:00",
        "last_modified_date": "2012-02-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1202.3684",
        "title": "Generalized Boundaries from Multiple Image Interpretations",
        "authors": [
            "Marius Leordeanu",
            "Rahul Sukthankar",
            "Cristian Sminchisescu"
        ],
        "abstract": "Boundary detection is essential for a variety of computer vision tasks such as segmentation and recognition. In this paper we propose a unified formulation and a novel algorithm that are applicable to the detection of different types of boundaries, such as intensity edges, occlusion boundaries or object category specific boundaries. Our formulation leads to a simple method with state-of-the-art performance and significantly lower computational cost than existing methods. We evaluate our algorithm on different types of boundaries, from low-level boundaries extracted in natural images, to occlusion boundaries obtained using motion cues and RGB-D cameras, to boundaries from soft-segmentation. We also propose a novel method for figure/ground soft-segmentation that can be used in conjunction with our boundary detection method and improve its accuracy at almost no extra computational cost.\n    ",
        "submission_date": "2012-02-16T00:00:00",
        "last_modified_date": "2012-02-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1202.3884",
        "title": "A feature extraction technique based on character geometry for character recognition",
        "authors": [
            "Dinesh Dileep Gaurav",
            "Renu Ramesh"
        ],
        "abstract": "This paper describes a geometry based technique for feature extraction applicable to segmentation-based word recognition systems. The proposed system extracts the geometric features of the character contour. This features are based on the basic line types that forms the character skeleton. The system gives a feature vector as its output. The feature vectors so generated from a training set, were then used to train a pattern recognition engine based on Neural Networks so that the system can be benchmarked.\n    ",
        "submission_date": "2012-02-17T00:00:00",
        "last_modified_date": "2012-02-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1202.4002",
        "title": "Generalized Principal Component Analysis (GPCA)",
        "authors": [
            "Rene Vidal",
            "Yi Ma",
            "Shankar Sastry"
        ],
        "abstract": "This paper presents an algebro-geometric solution to the problem of segmenting an unknown number of subspaces of unknown and varying dimensions from sample data points. We represent the subspaces with a set of homogeneous polynomials whose degree is the number of subspaces and whose derivatives at a data point give normal vectors to the subspace passing through the point. When the number of subspaces is known, we show that these polynomials can be estimated linearly from data; hence, subspace segmentation is reduced to classifying one point per subspace. We select these points optimally from the data set by minimizing certain distance function, thus dealing automatically with moderate noise in the data. A basis for the complement of each subspace is then recovered by applying standard PCA to the collection of derivatives (normal vectors). Extensions of GPCA that deal with data in a high- dimensional space and with an unknown number of subspaces are also presented. Our experiments on low-dimensional data show that GPCA outperforms existing algebraic algorithms based on polynomial factorization and provides a good initialization to iterative techniques such as K-subspaces and Expectation Maximization. We also present applications of GPCA to computer vision problems such as face clustering, temporal video segmentation, and 3D motion segmentation from point correspondences in multiple affine views.\n    ",
        "submission_date": "2012-02-17T00:00:00",
        "last_modified_date": "2012-02-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1202.4107",
        "title": "Unsupervised Threshold for Automatic Extraction of Dolphin Dorsal Fin Outlines from Digital Photographs in DARWIN (Digital Analysis and Recognition of Whale Images on a Network)",
        "authors": [
            "Scott A. Hale"
        ],
        "abstract": "At least two software packages---DARWIN, Eckerd College, and FinScan, Texas A&M---exist to facilitate the identification of cetaceans---whales, dolphins, porpoises---based upon the naturally occurring features along the edges of their dorsal fins. Such identification is useful for biological studies of population, social interaction, migration, etc. The process whereby fin outlines are extracted in current fin-recognition software packages is manually intensive and represents a major user input bottleneck: it is both time consuming and visually fatiguing. This research aims to develop automated methods (employing unsupervised thresholding and morphological processing techniques) to extract cetacean dorsal fin outlines from digital photographs thereby reducing manual user input. Ideally, automatic outline generation will improve the overall user experience and improve the ability of the software to correctly identify cetaceans. Various transformations from color to gray space were examined to determine which produced a grayscale image in which a suitable threshold could be easily identified. To assist with unsupervised thresholding, a new metric was developed to evaluate the jaggedness of figures (\"pixelarity\") in an image after thresholding. The metric indicates how cleanly a threshold segments background and foreground elements and hence provides a good measure of the quality of a given threshold. This research results in successful extractions in roughly 93% of images, and significantly reduces user-input time.\n    ",
        "submission_date": "2012-02-18T00:00:00",
        "last_modified_date": "2012-02-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1202.4207",
        "title": "Regularized Robust Coding for Face Recognition",
        "authors": [
            "Meng Yang",
            "Lei Zhang",
            "Jian Yang",
            "David Zhang"
        ],
        "abstract": "Recently the sparse representation based classification (SRC) has been proposed for robust face recognition (FR). In SRC, the testing image is coded as a sparse linear combination of the training samples, and the representation fidelity is measured by the l2-norm or l1-norm of the coding residual. Such a sparse coding model assumes that the coding residual follows Gaussian or Laplacian distribution, which may not be effective enough to describe the coding residual in practical FR systems. Meanwhile, the sparsity constraint on the coding coefficients makes SRC's computational cost very high. In this paper, we propose a new face coding model, namely regularized robust coding (RRC), which could robustly regress a given signal with regularized regression coefficients. By assuming that the coding residual and the coding coefficient are respectively independent and identically distributed, the RRC seeks for a maximum a posterior solution of the coding problem. An iteratively reweighted regularized robust coding (IR3C) algorithm is proposed to solve the RRC model efficiently. Extensive experiments on representative face databases demonstrate that the RRC is much more effective and efficient than state-of-the-art sparse representation based methods in dealing with face occlusion, corruption, lighting and expression changes, etc.\n    ",
        "submission_date": "2012-02-20T00:00:00",
        "last_modified_date": "2012-02-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1202.4237",
        "title": "A Simple Unsupervised Color Image Segmentation Method based on MRF-MAP",
        "authors": [
            "Qiyang Zhao"
        ],
        "abstract": "Color image segmentation is an important topic in the image processing field. MRF-MAP is often adopted in the unsupervised segmentation methods, but their performance are far behind recent interactive segmentation tools supervised by user inputs. Furthermore, the existing related unsupervised methods also suffer from the low efficiency, and high risk of being trapped in the local optima, because MRF-MAP is currently solved by iterative frameworks with inaccurate initial color distribution models. To address these problems, the letter designs an efficient method to calculate the energy functions approximately in the non-iteration style, and proposes a new binary segmentation algorithm based on the slightly tuned Lanczos eigensolver. The experiments demonstrate that the new algorithm achieves competitive performance compared with two state-of-art segmentation methods.\n    ",
        "submission_date": "2012-02-20T00:00:00",
        "last_modified_date": "2012-02-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1202.4495",
        "title": "Stochastic-Based Pattern Recognition Analysis",
        "authors": [
            "V. Canals",
            "A. Morro",
            "J.L. Rossell\u00f3"
        ],
        "abstract": "In this work we review the basic principles of stochastic logic and propose its application to probabilistic-based pattern-recognition analysis. The proposed technique is intrinsically a parallel comparison of input data to various pre-stored categories using Bayesian techniques. We design smart pulse-based stochastic-logic blocks to provide an efficient pattern recognition analysis. The proposed rchitecture is applied to a specific navigation problem. The resulting system is orders of magnitude faster than processor-based solutions.\n    ",
        "submission_date": "2012-02-20T00:00:00",
        "last_modified_date": "2012-02-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1202.6384",
        "title": "Fast approximations to structured sparse coding and applications to object classification",
        "authors": [
            "Arthur Szlam",
            "Karol Gregor",
            "Yann LeCun"
        ],
        "abstract": "We describe a method for fast approximation of sparse coding. The input space is subdivided by a binary decision tree, and we simultaneously learn a dictionary and assignment of allowed dictionary elements for each leaf of the tree. We store a lookup table with the assignments and the pseudoinverses for each node, allowing for very fast inference. We give an algorithm for learning the tree, the dictionary and the dictionary element assignment, and In the process of describing this algorithm, we discuss the more general problem of learning the groups in group structured sparse modelling. We show that our method creates good sparse representations by using it in the object recognition framework of \\cite{lazebnik06,yang-cvpr-09}. Implementing our own fast version of the SIFT descriptor the whole system runs at 20 frames per second on $321 \\times 481$ sized images on a laptop with a quad-core cpu, while sacrificing very little accuracy on the Caltech 101 and 15 scenes benchmarks.\n    ",
        "submission_date": "2012-02-28T00:00:00",
        "last_modified_date": "2012-02-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1202.6429",
        "title": "Stable image reconstruction using total variation minimization",
        "authors": [
            "Deanna Needell",
            "Rachel Ward"
        ],
        "abstract": "This article presents near-optimal guarantees for accurate and robust image recovery from under-sampled noisy measurements using total variation minimization. In particular, we show that from O(slog(N)) nonadaptive linear measurements, an image can be reconstructed to within the best s-term approximation of its gradient up to a logarithmic factor, and this factor can be removed by taking slightly more measurements. Along the way, we prove a strengthened Sobolev inequality for functions lying in the null space of suitably incoherent matrices.\n    ",
        "submission_date": "2012-02-29T00:00:00",
        "last_modified_date": "2013-03-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1202.6586",
        "title": "Filling-Based Techniques Applied to Object Projection Feature Estimation",
        "authors": [
            "Luis Quesada",
            "Alejandro J. Le\u00f3n"
        ],
        "abstract": "3D motion tracking is a critical task in many computer vision applications. Unsupervised markerless 3D motion tracking systems determine the most relevant object in the screen and then track it by continuously estimating its projection features (center and area) from the edge image and a point inside the relevant object projection (namely, inner point), until the tracking fails. Existing object projection feature estimation techniques are based on ray-casting from the inner point. These techniques present three main drawbacks: when the inner point is surrounded by edges, rays may not reach other relevant areas; as a consequence of that issue, the estimated features may greatly vary depending on the position of the inner point relative to the object projection; and finally, increasing the number of rays being casted and the ray-casting iterations (which would make the results more accurate and stable) increases the processing time to the point the tracking cannot be performed on the fly. In this paper, we analyze an intuitive filling-based object projection feature estimation technique that solves the aforementioned problems but is too sensitive to edge miscalculations. Then, we propose a less computing-intensive modification to that technique that would not be affected by the existing techniques issues and would be no more sensitive to edge miscalculations than ray-casting-based techniques.\n    ",
        "submission_date": "2012-02-29T00:00:00",
        "last_modified_date": "2012-02-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1203.0076",
        "title": "Using Barriers to Reduce the Sensitivity to Edge Miscalculations of Casting-Based Object Projection Feature Estimation",
        "authors": [
            "Luis Quesada"
        ],
        "abstract": "3D motion tracking is a critical task in many computer vision applications. Unsupervised markerless 3D motion tracking systems determine the most relevant object in the screen and then track it by continuously estimating its projection features (center and area) from the edge image and a point inside the relevant object projection (namely, inner point), until the tracking fails. Existing reliable object projection feature estimation techniques are based on ray-casting or grid-filling from the inner point. These techniques assume the edge image to be accurate. However, in real case scenarios, edge miscalculations may arise from low contrast between the target object and its surroundings or motion blur caused by low frame rates or fast moving target objects. In this paper, we propose a barrier extension to casting-based techniques that mitigates the effect of edge miscalculations.\n    ",
        "submission_date": "2012-03-01T00:00:00",
        "last_modified_date": "2012-03-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1203.0265",
        "title": "Image Fusion and Re-Modified SPIHT for Fused Image",
        "authors": [
            "S. Chitra",
            "J. B. Bhattacharjee",
            "B. Thilakavathi"
        ],
        "abstract": "This paper presents the Discrete Wavelet based fusion techniques for combining perceptually important image features. SPIHT (Set Partitioning in Hierarchical Trees) algorithm is an efficient method for lossy and lossless coding of fused image. This paper presents some modifications on the SPIHT algorithm. It is based on the idea of insignificant correlation of wavelet coefficient among the medium and high frequency sub bands. In RE-MSPIHT algorithm, wavelet coefficients are scaled prior to SPIHT coding based on the sub band importance, with the goal of minimizing the MSE.\n    ",
        "submission_date": "2012-02-29T00:00:00",
        "last_modified_date": "2012-02-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1203.0488",
        "title": "Multi-Level Feature Descriptor for Robust Texture Classification via Locality-Constrained Collaborative Strategy",
        "authors": [
            "Shu Kong",
            "Donghui Wang"
        ],
        "abstract": "This paper introduces a simple but highly efficient ensemble for robust texture classification, which can effectively deal with translation, scale and changes of significant viewpoint problems. The proposed method first inherits the spirit of spatial pyramid matching model (SPM), which is popular for encoding spatial distribution of local features, but in a flexible way, partitioning the original image into different levels and incorporating different overlapping patterns of each level. This flexible setup helps capture the informative features and produces sufficient local feature codes by some well-chosen aggregation statistics or pooling operations within each partitioned region, even when only a few sample images are available for training. Then each texture image is represented by several orderless feature codes and thereby all the training data form a reliable feature pond. Finally, to take full advantage of this feature pond, we develop a collaborative representation-based strategy with locality constraint (LC-CRC) for the final classification, and experimental results on three well-known public texture datasets demonstrate the proposed approach is very competitive and even outperforms several state-of-the-art methods. Particularly, when only a few samples of each category are available for training, our approach still achieves very high classification performance.\n    ",
        "submission_date": "2012-03-02T00:00:00",
        "last_modified_date": "2012-03-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1203.0744",
        "title": "A Report on Multilinear PCA Plus Multilinear LDA to Deal with Tensorial Data: Visual Classification as An Example",
        "authors": [
            "Shu Kong",
            "Donghui Wang"
        ],
        "abstract": "In practical applications, we often have to deal with high order data, such as a grayscale image and a video sequence are intrinsically 2nd-order tensor and 3rd-order tensor, respectively. For doing clustering or classification of these high order data, it is a conventional way to vectorize these data before hand, as PCA or FDA does, which often induce the curse of dimensionality problem. For this reason, experts have developed many methods to deal with the tensorial data, such as multilinear PCA, multilinear LDA, and so on. In this paper, we still address the problem of high order data representation and recognition, and propose to study the result of merging multilinear PCA and multilinear LDA into one scenario, we name it \\textbf{GDA} for the abbreviation of Generalized Discriminant Analysis. To evaluate GDA, we perform a series of experiments, and the experimental results demonstrate our GDA outperforms a selection of competing methods such (2D)$^2$PCA, (2D)$^2$LDA, and MDA.\n    ",
        "submission_date": "2012-03-04T00:00:00",
        "last_modified_date": "2012-03-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1203.0781",
        "title": "Posterior Mean Super-Resolution with a Compound Gaussian Markov Random Field Prior",
        "authors": [
            "Takayuki Katsuki",
            "Masato Inoue"
        ],
        "abstract": "This manuscript proposes a posterior mean (PM) super-resolution (SR) method with a compound Gaussian Markov random field (MRF) prior. SR is a technique to estimate a spatially high-resolution image from observed multiple low-resolution images. A compound Gaussian MRF model provides a preferable prior for natural images that preserves edges. PM is the optimal estimator for the objective function of peak signal-to-noise ratio (PSNR). This estimator is numerically determined by using variational Bayes (VB). We then solve the conjugate prior problem on VB and the exponential-order calculation cost problem of a compound Gaussian MRF prior with simple Taylor approximations. In experiments, the proposed method roughly overcomes existing methods.\n    ",
        "submission_date": "2012-03-04T00:00:00",
        "last_modified_date": "2012-03-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1203.0856",
        "title": "Online Discriminative Dictionary Learning for Image Classification Based on Block-Coordinate Descent Method",
        "authors": [
            "Shu Kong",
            "Donghui Wang"
        ],
        "abstract": "Previous researches have demonstrated that the framework of dictionary learning with sparse coding, in which signals are decomposed as linear combinations of a few atoms of a learned dictionary, is well adept to reconstruction issues. This framework has also been used for discrimination tasks such as image classification. To achieve better performances of classification, experts develop several methods to learn a discriminative dictionary in a supervised manner. However, another issue is that when the data become extremely large in scale, these methods will be no longer effective as they are all batch-oriented approaches. For this reason, we propose a novel online algorithm for discriminative dictionary learning, dubbed \\textbf{ODDL} in this paper. First, we introduce a linear classifier into the conventional dictionary learning formulation and derive a discriminative dictionary learning problem. Then, we exploit an online algorithm to solve the derived problem. Unlike the most existing approaches which update dictionary and classifier alternately via iteratively solving sub-problems, our approach directly explores them jointly. Meanwhile, it can largely shorten the runtime for training and is also particularly suitable for large-scale classification issues. To evaluate the performance of the proposed ODDL approach in image recognition, we conduct some experiments on three well-known benchmarks, and the experimental results demonstrate ODDL is fairly promising for image classification tasks.\n    ",
        "submission_date": "2012-03-05T00:00:00",
        "last_modified_date": "2012-03-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1203.0876",
        "title": "An MLP based Approach for Recognition of Handwritten `Bangla' Numerals",
        "authors": [
            "Subhadip Basu",
            "Nibaran Das",
            "Ram Sarkar",
            "Mahantapas Kundu",
            "Mita Nasipuri",
            "Dipak Kumar Basu"
        ],
        "abstract": "The work presented here involves the design of a Multi Layer Perceptron (MLP) based pattern classifier for recognition of handwritten Bangla digits using a 76 element feature vector. Bangla is the second most popular script and language in the Indian subcontinent and the fifth most popular language in the world. The feature set developed for representing handwritten Bangla numerals here includes 24 shadow features, 16 centroid features and 36 longest-run features. On experimentation with a database of 6000 samples, the technique yields an average recognition rate of 96.67% evaluated after three-fold cross validation of results. It is useful for applications related to OCR of handwritten Bangla Digit and can also be extended to include OCR of handwritten characters of Bangla alphabet.\n    ",
        "submission_date": "2012-03-05T00:00:00",
        "last_modified_date": "2012-03-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1203.0882",
        "title": "Handwritten Bangla Alphabet Recognition using an MLP Based Classifier",
        "authors": [
            "Subhadip Basu",
            "Nibaran Das",
            "Ram Sarkar",
            "Mahantapas Kundu",
            "Mita Nasipuri",
            "Dipak Kumar Basu"
        ],
        "abstract": "The work presented here involves the design of a Multi Layer Perceptron (MLP) based classifier for recognition of handwritten Bangla alphabet using a 76 element feature set Bangla is the second most popular script and language in the Indian subcontinent and the fifth most popular language in the world. The feature set developed for representing handwritten characters of Bangla alphabet includes 24 shadow features, 16 centroid features and 36 longest-run features. Recognition performances of the MLP designed to work with this feature set are experimentally observed as 86.46% and 75.05% on the samples of the training and the test sets respectively. The work has useful application in the development of a complete OCR system for handwritten Bangla text.\n    ",
        "submission_date": "2012-03-05T00:00:00",
        "last_modified_date": "2012-03-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1203.0905",
        "title": "Autocalibration with the Minimum Number of Cameras with Known Pixel Shape",
        "authors": [
            "Jos\u00e9 I. Ronda",
            "Antonio Vald\u00e9s",
            "Guillermo Gallego"
        ],
        "abstract": "In 3D reconstruction, the recovery of the calibration parameters of the cameras is paramount since it provides metric information about the observed scene, e.g., measures of angles and ratios of distances. Autocalibration enables the estimation of the camera parameters without using a calibration device, but by enforcing simple constraints on the camera parameters. In the absence of information about the internal camera parameters such as the focal length and the principal point, the knowledge of the camera pixel shape is usually the only available constraint. Given a projective reconstruction of a rigid scene, we address the problem of the autocalibration of a minimal set of cameras with known pixel shape and otherwise arbitrarily varying intrinsic and extrinsic parameters. We propose an algorithm that only requires 5 cameras (the theoretical minimum), thus halving the number of cameras required by previous algorithms based on the same constraint. To this purpose, we introduce as our basic geometric tool the six-line conic variety (SLCV), consisting in the set of planes intersecting six given lines of 3D space in points of a conic. We show that the set of solutions of the Euclidean upgrading problem for three cameras with known pixel shape can be parameterized in a computationally efficient way. This parameterization is then used to solve autocalibration from five or more cameras, reducing the three-dimensional search space to a two-dimensional one. We provide experiments with real images showing the good performance of the technique.\n    ",
        "submission_date": "2012-03-05T00:00:00",
        "last_modified_date": "2014-01-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1203.1005",
        "title": "Sparse Subspace Clustering: Algorithm, Theory, and Applications",
        "authors": [
            "Ehsan Elhamifar",
            "Rene Vidal"
        ],
        "abstract": "In many real-world problems, we are dealing with collections of high-dimensional data, such as images, videos, text and web documents, DNA microarray data, and more. Often, high-dimensional data lie close to low-dimensional structures corresponding to several classes or categories the data belongs to. In this paper, we propose and study an algorithm, called Sparse Subspace Clustering (SSC), to cluster data points that lie in a union of low-dimensional subspaces. The key idea is that, among infinitely many possible representations of a data point in terms of other points, a sparse representation corresponds to selecting a few points from the same subspace. This motivates solving a sparse optimization program whose solution is used in a spectral clustering framework to infer the clustering of data into subspaces. Since solving the sparse optimization program is in general NP-hard, we consider a convex relaxation and show that, under appropriate conditions on the arrangement of subspaces and the distribution of data, the proposed minimization program succeeds in recovering the desired sparse representations. The proposed algorithm can be solved efficiently and can handle data points near the intersections of subspaces. Another key advantage of the proposed algorithm with respect to the state of the art is that it can deal with data nuisances, such as noise, sparse outlying entries, and missing entries, directly by incorporating the model of the data into the sparse optimization program. We demonstrate the effectiveness of the proposed algorithm through experiments on synthetic data as well as the two real-world problems of motion segmentation and face clustering.\n    ",
        "submission_date": "2012-03-05T00:00:00",
        "last_modified_date": "2013-02-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1203.1483",
        "title": "Learning Random Kernel Approximations for Object Recognition",
        "authors": [
            "Eduard Gabriel B\u0103z\u0103van",
            "Fuxin Li",
            "Cristian Sminchisescu"
        ],
        "abstract": "Approximations based on random Fourier features have recently emerged as an efficient and formally consistent methodology to design large-scale kernel machines. By expressing the kernel as a Fourier expansion, features are generated based on a finite set of random basis projections, sampled from the Fourier transform of the kernel, with inner products that are Monte Carlo approximations of the original kernel. Based on the observation that different kernel-induced Fourier sampling distributions correspond to different kernel parameters, we show that an optimization process in the Fourier domain can be used to identify the different frequency bands that are useful for prediction on training data. Moreover, the application of group Lasso to random feature vectors corresponding to a linear combination of multiple kernels, leads to efficient and scalable reformulations of the standard multiple kernel learning model \\cite{Varma09}. In this paper we develop the linear Fourier approximation methodology for both single and multiple gradient-based kernel learning and show that it produces fast and accurate predictors on a complex dataset such as the Visual Object Challenge 2011 (VOC2011).\n    ",
        "submission_date": "2012-03-07T00:00:00",
        "last_modified_date": "2012-03-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1203.1513",
        "title": "Invariant Scattering Convolution Networks",
        "authors": [
            "Joan Bruna",
            "St\u00e9phane Mallat"
        ],
        "abstract": "A wavelet scattering network computes a translation invariant image representation, which is stable to deformations and preserves high frequency information for classification. It cascades wavelet transform convolutions with non-linear modulus and averaging operators. The first network layer outputs SIFT-type descriptors whereas the next layers provide complementary invariant information which improves classification. The mathematical analysis of wavelet scattering networks explains important properties of deep convolution networks for classification.\n",
        "submission_date": "2012-03-05T00:00:00",
        "last_modified_date": "2012-03-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1203.1765",
        "title": "A comparative evaluation of two algorithms of detection of masses on mammograms",
        "authors": [
            "Guillaume Kom",
            "Alain Tiedeu",
            "Martin Kom",
            "John Ngundam"
        ],
        "abstract": " In this paper, we implement and carry out the comparison of two methods of computer-aided-detection of masses on mammograms. The two algorithms basically consist of 3 steps each: segmentation, binarization and noise suppression using different techniques for each step. A database of 60 images was used to compare the performance of the two algorithms in terms of general detection efficiency, conservation of size and shape of detected masses.\n    ",
        "submission_date": "2012-03-08T00:00:00",
        "last_modified_date": "2012-03-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1203.1823",
        "title": "Enhancement Techniques for Local Content Preservation and Contrast Improvement in Images",
        "authors": [
            "Chelsy Sapna Josephus",
            "S. Remya"
        ],
        "abstract": "There are several images that do not have uniform brightness which pose a challenging problem for image enhancement systems. As histogram equalization has been successfully used to correct for uniform brightness problems, a histogram equalization method that utilizes human visual system based thresholding(human vision thresholding) as well as logarithmic processing techniques were introduced later . But these methods are not good for preserving the local content of the image which is a major factor for various images like medical and aerial images. Therefore new method is proposed here. This method is referred as \"Human vision thresholding with enhancement technique for dark blurred images for local content preservation\". It uses human vision thresholding together with an existing enhancement method for dark blurred images. Furthermore a comparative study with another method for local content preservation is done which is further extended to make it suitable for contrast improvement. Experimental results shows that the proposed methods outperforms the former existing methods in preserving the local content for standard images, medical and aerial images.\n    ",
        "submission_date": "2012-03-08T00:00:00",
        "last_modified_date": "2012-03-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1203.1985",
        "title": "Substructure and Boundary Modeling for Continuous Action Recognition",
        "authors": [
            "Zhaowen Wang",
            "Jinjun Wang",
            "Jing Xiao",
            "Kai-Hsiang Lin",
            "Thomas Huang"
        ],
        "abstract": "This paper introduces a probabilistic graphical model for continuous action recognition with two novel components: substructure transition model and discriminative boundary model. The first component encodes the sparse and global temporal transition prior between action primitives in state-space model to handle the large spatial-temporal variations within an action class. The second component enforces the action duration constraint in a discriminative way to locate the transition boundaries between actions more accurately. The two components are integrated into a unified graphical structure to enable effective training and inference. Our comprehensive experimental results on both public and in-house datasets show that, with the capability to incorporate additional information that had not been explicitly or efficiently modeled by previous methods, our proposed algorithm achieved significantly improved performance for continuous action recognition.\n    ",
        "submission_date": "2012-03-09T00:00:00",
        "last_modified_date": "2012-03-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1203.2210",
        "title": "Fixed-Rank Representation for Unsupervised Visual Learning",
        "authors": [
            "Risheng Liu",
            "Zhouchen Lin",
            "Fernando De la Torre",
            "Zhixun Su"
        ],
        "abstract": "Subspace clustering and feature extraction are two of the most commonly used unsupervised learning techniques in computer vision and pattern recognition. State-of-the-art techniques for subspace clustering make use of recent advances in sparsity and rank minimization. However, existing techniques are computationally expensive and may result in degenerate solutions that degrade clustering performance in the case of insufficient data sampling. To partially solve these problems, and inspired by existing work on matrix factorization, this paper proposes fixed-rank representation (FRR) as a unified framework for unsupervised visual learning. FRR is able to reveal the structure of multiple subspaces in closed-form when the data is noiseless. Furthermore, we prove that under some suitable conditions, even with insufficient observations, FRR can still reveal the true subspace memberships. To achieve robustness to outliers and noise, a sparse regularizer is introduced into the FRR framework. Beyond subspace clustering, FRR can be used for unsupervised feature extraction. As a non-trivial byproduct, a fast numerical solver is developed for FRR. Experimental results on both synthetic data and real applications validate our theoretical analysis and demonstrate the benefits of FRR for unsupervised visual learning.\n    ",
        "submission_date": "2012-03-09T00:00:00",
        "last_modified_date": "2012-04-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1203.2386",
        "title": "On-Board Visual Tracking with Unmanned Aircraft System (UAS)",
        "authors": [
            "Ashraf Qadir",
            "Jeremiah Neubert",
            "William Semke"
        ],
        "abstract": "This paper presents the development of a real time tracking algorithm that runs on a 1.2 GHz PC/104 computer on-board a small UAV. The algorithm uses zero mean normalized cross correlation to detect and locate an object in the image. A kalman filter is used to make the tracking algorithm computationally efficient. Object position in an image frame is predicted using the motion model and a search window, centered at the predicted position is generated. Object position is updated with the measurement from object detection. The detected position is sent to the motion controller to move the gimbal so that the object stays at the center of the image frame. Detection and tracking is autonomously carried out on the payload computer and the system is able to work in two different methods. The first method starts detecting and tracking using a stored image patch. The second method allows the operator on the ground to select the interest object for the UAV to track. The system is capable of re-detecting an object, in the event of tracking failure. Performance of the tracking system was verified both in the lab and on the field by mounting the payload on a vehicle and simulating a flight. Tests show that the system can detect and track a diverse set of objects in real time. Flight testing of the system will be conducted at the next available opportunity.\n    ",
        "submission_date": "2012-03-11T00:00:00",
        "last_modified_date": "2012-03-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1203.2404",
        "title": "Video Object Tracking and Analysis for Computer Assisted Surgery",
        "authors": [
            "Nobert Thomas Pallath",
            "Tessamma Thomas"
        ],
        "abstract": "Pedicle screw insertion technique has made revolution in the surgical treatment of spinal fractures and spinal disorders. Although X- ray fluoroscopy based navigation is popular, there is risk of prolonged exposure to X- ray radiation. Systems that have lower radiation risk are generally quite expensive. The position and orientation of the drill is clinically very important in pedicle screw fixation. In this paper, the position and orientation of the marker on the drill is determined using pattern recognition based methods, using geometric features, obtained from the input video sequence taken from CCD camera. A search is then performed on the video frames after preprocessing, to obtain the exact position and orientation of the drill. Animated graphics, showing the instantaneous position and orientation of the drill is then overlaid on the processed video for real time drill control and navigation.\n    ",
        "submission_date": "2012-03-12T00:00:00",
        "last_modified_date": "2012-03-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1203.2514",
        "title": "Enhancement of Images using Morphological Transformation",
        "authors": [
            "K. Sreedhar",
            "B. Panlal"
        ],
        "abstract": "This paper deals with enhancement of images with poor contrast and detection of background. Proposes a frame work which is used to detect the background in images characterized by poor contrast. Image enhancement has been carried out by the two methods based on the Weber's law notion. The first method employs information from image background analysis by blocks, while the second transformation method utilizes the opening operation, closing operation, which is employed to define the multi-background gray scale images. The complete image processing is done using MATLAB simulation model. Finally, this paper is organized as follows as Morphological transformation and Weber's law. Image background approximation to the background by means of block analysis in conjunction with transformations that enhance images with poor lighting. The multibackground notion is introduced by means of the opening by reconstruction shows a comparison among several techniques to improve contrast in images. Finally, conclusions are presented.\n    ",
        "submission_date": "2012-03-09T00:00:00",
        "last_modified_date": "2012-03-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1203.2839",
        "title": "Square-Cut: A Segmentation Algorithm on the Basis of a Rectangle Shape",
        "authors": [
            "Jan Egger",
            "Tina Kapur",
            "Thomas Dukatz",
            "Malgorzata Kolodziej",
            "Dzenan Zukic",
            "Bernd Freisleben",
            "Christopher Nimsky"
        ],
        "abstract": "We present a rectangle-based segmentation algorithm that sets up a graph and performs a graph cut to separate an object from the background. However, graph-based algorithms distribute the graph's nodes uniformly and equidistantly on the image. Then, a smoothness term is added to force the cut to prefer a particular shape. This strategy does not allow the cut to prefer a certain structure, especially when areas of the object are indistinguishable from the background. We solve this problem by referring to a rectangle shape of the object when sampling the graph nodes, i.e., the nodes are distributed nonuniformly and non-equidistantly on the image. This strategy can be useful, when areas of the object are indistinguishable from the background. For evaluation, we focus on vertebrae images from Magnetic Resonance Imaging (MRI) datasets to support the time consuming manual slice-by-slice segmentation performed by physicians. The ground truth of the vertebrae boundaries were manually extracted by two clinical experts (neurological surgeons) with several years of experience in spine surgery and afterwards compared with the automatic segmentation results of the proposed scheme yielding an average Dice Similarity Coefficient (DSC) of 90.97\\pm62.2%.\n    ",
        "submission_date": "2012-03-13T00:00:00",
        "last_modified_date": "2012-03-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1203.3114",
        "title": "Integrated three-dimensional reconstruction using reflectance fields",
        "authors": [
            "Maria-Luisa Sosas",
            "Miguel-Octavio Arias"
        ],
        "abstract": "A method to obtain three-dimensional data of real-world objects by integrating their material properties is presented. The material properties are defined by capturing the Reflectance Fields of the real-world objects. It is shown, unlike conventional reconstruction methods, the method is able to use the reflectance information to recover surface depth for objects having a non-Lambertian surface reflectance. It is, for recovering 3D data of objects exhibiting an anisotropic BRDF with an error less than 0.3%.\n    ",
        "submission_date": "2012-03-14T00:00:00",
        "last_modified_date": "2012-03-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1203.3170",
        "title": "Single Reduct Generation Based on Relative Indiscernibility of Rough Set Theory",
        "authors": [
            "Shampa Sengupta",
            "Asit Kr. Das"
        ],
        "abstract": "In real world everything is an object which represents particular classes. Every object can be fully described by its attributes. Any real world dataset contains large number of attributes and objects. Classifiers give poor performance when these huge datasets are given as input to it for proper classification. So from these huge dataset most useful attributes need to be extracted that contribute the maximum to the decision. In the paper, attribute set is reduced by generating reducts using the indiscernibility relation of Rough Set Theory (RST). The method measures similarity among the attributes using relative indiscernibility relation and computes attribute similarity set. Then the set is minimized and an attribute similarity table is constructed from which attribute similar to maximum number of attributes is selected so that the resultant minimum set of selected attributes (called reduct) cover all attributes of the attribute similarity table. The method has been applied on glass dataset collected from the UCI repository and the classification accuracy is calculated by various classifiers. The result shows the efficiency of the proposed method.\n    ",
        "submission_date": "2012-03-14T00:00:00",
        "last_modified_date": "2012-03-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1203.3230",
        "title": "Reconstruction error in a motion capture system",
        "authors": [
            "Andrea Masiero",
            "Angelo Cenedese"
        ],
        "abstract": "Marker-based motion capture (MoCap) systems can be composed by several dozens of cameras with the purpose of reconstructing the trajectories of hundreds of targets. With a large amount of cameras it becomes interesting to determine the optimal reconstruction strategy. For such aim it is of fundamental importance to understand the information provided by different camera measurements and how they are combined, i.e. how the reconstruction error changes by considering different cameras. In this work, first, an approximation of the reconstruction error variance is derived. The results obtained in some simulations suggest that the proposed strategy allows to obtain a good approximation of the real error variance with significant reduction of the computational time.\n    ",
        "submission_date": "2012-03-14T00:00:00",
        "last_modified_date": "2012-03-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1203.3270",
        "title": "Extraction of Facial Feature Points Using Cumulative Histogram",
        "authors": [
            "Sushil Kumar Paul",
            "Mohammad Shorif Uddin",
            "Saida Bouakaz"
        ],
        "abstract": "This paper proposes a novel adaptive algorithm to extract facial feature points automatically such as eyebrows corners, eyes corners, nostrils, nose tip, and mouth corners in frontal view faces, which is based on cumulative histogram approach by varying different threshold values. At first, the method adopts the Viola-Jones face detector to detect the location of face and also crops the face region in an image. From the concept of the human face structure, the six relevant regions such as right eyebrow, left eyebrow, right eye, left eye, nose, and mouth areas are cropped in a face image. Then the histogram of each cropped relevant region is computed and its cumulative histogram value is employed by varying different threshold values to create a new filtering image in an adaptive way. The connected component of interested area for each relevant filtering image is indicated our respective feature region. A simple linear search algorithm for eyebrows, eyes and mouth filtering images and contour algorithm for nose filtering image are applied to extract our desired corner points automatically. The method was tested on a large BioID frontal face database in different illuminations, expressions and lighting conditions and the experimental results have achieved average success rates of 95.27%.\n    ",
        "submission_date": "2012-03-15T00:00:00",
        "last_modified_date": "2012-03-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1203.4204",
        "title": "Clustering Using Isoperimetric Number of Trees",
        "authors": [
            "Amir Daneshgar",
            "Ramin Javadi",
            "Basir Shariat Razavi"
        ],
        "abstract": "In this paper we propose a graph-based data clustering algorithm which is based on exact clustering of a minimum spanning tree in terms of a minimum isoperimetry criteria. We show that our basic clustering algorithm runs in $O(n \\log n)$ and with post-processing in $O(n^2)$ (worst case) time where $n$ is the size of the data set. We also show that our generalized graph model which also allows the use of potentials at vertices can be used to extract a more detailed pack of information as the {\\it outlier profile} of the data set. In this direction we show that our approach can be used to define the concept of an outlier-set in a precise way and we propose approximation algorithms for finding such sets. We also provide a comparative performance analysis of our algorithm with other related ones and we show that the new clustering algorithm (without the outlier extraction procedure) behaves quite effectively even on hard benchmarks and handmade examples.\n    ",
        "submission_date": "2012-03-19T00:00:00",
        "last_modified_date": "2012-03-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1203.4355",
        "title": "Real-time Image-based 6-DOF Localization in Large-Scale Environments",
        "authors": [
            "Hyon Lim",
            "Sudipta Sinha",
            "Michael Cohen",
            "Matt Uyttendaele"
        ],
        "abstract": "We present a real-time approach for image-based localization within large scenes that have been reconstructed offline using structure from motion (Sfm). From monocular video, our method continuously computes a precise 6-DOF camera pose, by efficiently tracking natural features and matching them to 3D points in the Sfm point cloud. Our main contribution lies in efficiently interleaving a fast keypoint tracker that uses inexpensive binary feature descriptors with a new approach for direct 2D-to-3D matching. The 2D-to-3D matching avoids the need for online extraction of scale-invariant features. Instead, offline we construct an indexed database containing multiple DAISY descriptors per 3D point extracted at multiple scales. The key to the efficiency of our method lies in invoking DAISY descriptor extraction and matching sparingly during localization, and in distributing this computation over a window of successive frames. This enables the algorithm to run in real-time, without fluctuations in the latency over long durations. We evaluate the method in large indoor and outdoor scenes. Our algorithm runs at over 30 Hz on a laptop and at 12 Hz on a low-power, mobile computer suitable for onboard computation on a quadrotor micro aerial vehicle.\n    ",
        "submission_date": "2012-03-20T00:00:00",
        "last_modified_date": "2012-03-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1203.4855",
        "title": "Texture Classification Approach Based on Combination of Edge & Co-occurrence and Local Binary Pattern",
        "authors": [
            "Shervan Fekri Ershad"
        ],
        "abstract": "Texture classification is one of the problems which has been paid much attention on by computer scientists since late 90s. If texture classification is done correctly and accurately, it can be used in many cases such as Pattern recognition, object tracking, and shape recognition. So far, there have been so many methods offered to solve this problem. Near all these methods have tried to extract and define features to separate different labels of textures really well. This article has offered an approach which has an overall process on the images of textures based on Local binary pattern and Gray Level Co-occurrence matrix and then by edge detection, and finally, extracting the statistical features from the images would classify them. Although, this approach is a general one and is could be used in different applications, the method has been tested on the stone texture and the results have been compared with some of the previous approaches to prove the quality of proposed approach.\n    ",
        "submission_date": "2012-03-21T00:00:00",
        "last_modified_date": "2012-03-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1203.4874",
        "title": "A Co-Prime Blur Scheme for Data Security in Video Surveillance",
        "authors": [
            "Christopher Thorpe",
            "Feng Li",
            "Zijia Li",
            "Zhan Yu",
            "David Saunders",
            "Jingyi Yu"
        ],
        "abstract": "This paper presents a novel Coprime Blurred Pair (CBP) model for visual data-hiding for security in camera surveillance. While most previous approaches have focused on completely encrypting the video stream, we introduce a spatial encryption scheme by blurring the image/video contents to create a CBP. Our goal is to obscure detail in public video streams by blurring while allowing behavior to be recognized and to quickly deblur the stream so that details are available if behavior is recognized as suspicious. We create a CBP by blurring the same latent image with two unknown kernels. The two kernels are coprime when mapped to bivariate polynomials in the z domain. To deblur the CBP we first use the coprime constraint to approximate the kernels and sample the bivariate CBP polynomials in one dimension on the unit circle. At each sample point, we factor the 1D polynomial pair and compose the results into a 2D kernel matrix. Finally, we compute the inverse Fast Fourier Transform (FFT) of the kernel matrices to recover the coprime kernels and then the latent video stream. It is therefore only possible to deblur the video stream if a user has access to both streams. To improve the practicability of our algorithm, we implement our algorithm using a graphics processing unit (GPU) to decrypt the blurred video streams in real-time, and extensive experimental results demonstrate that our new scheme can effectively protect sensitive identity information in surveillance videos and faithfully reconstruct the unblurred video stream when two blurred sequences are available.\n    ",
        "submission_date": "2012-03-22T00:00:00",
        "last_modified_date": "2012-03-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1203.5078",
        "title": "Kernel Density Feature Points Estimator for Content-Based Image Retrieval",
        "authors": [
            "Tranos Zuva",
            "Oludayo O. Olugbara",
            "Sunday O. Ojo",
            "Seleman M. Ngwira"
        ],
        "abstract": "Research is taking place to find effective algorithms for content-based image representation and description. There is a substantial amount of algorithms available that use visual features (color, shape, texture). Shape feature has attracted much attention from researchers that there are many shape representation and description algorithms in literature. These shape image representation and description algorithms are usually not application independent or robust, making them undesirable for generic shape description. This paper presents an object shape representation using Kernel Density Feature Points Estimator (KDFPE). In this method, the density of feature points within defined rings around the centroid of the image is obtained. The KDFPE is then applied to the vector of the image. KDFPE is invariant to translation, scale and rotation. This method of image representation shows improved retrieval rate when compared to Density Histogram Feature Points (DHFP) method. Analytic analysis is done to justify our method, which was compared with the DHFP to prove its robustness.\n    ",
        "submission_date": "2012-03-22T00:00:00",
        "last_modified_date": "2012-03-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1203.5128",
        "title": "Acceleration of the shiftable O(1) algorithm for bilateral filtering and non-local means",
        "authors": [
            "Kunal N. Chaudhury"
        ],
        "abstract": "A direct implementation of the bilateral filter [1] requires O(\\sigma_s^2) operations per pixel, where \\sigma_s is the (effective) width of the spatial kernel. A fast implementation of the bilateral filter was recently proposed in [2] that required O(1) operations per pixel with respect to \\sigma_s. This was done by using trigonometric functions for the range kernel of the bilateral filter, and by exploiting their so-called shiftability property. In particular, a fast implementation of the Gaussian bilateral filter was realized by approximating the Gaussian range kernel using raised cosines. Later, it was demonstrated in [3] that this idea could be extended to a larger class of filters, including the popular non-local means filter [4]. As already observed in [2], a flip side of this approach was that the run time depended on the width \\sigma_r of the range kernel. For an image with (local) intensity variations in the range [0,T], the run time scaled as O(T^2/\\sigma^2_r) with \\sigma_r. This made it difficult to implement narrow range kernels, particularly for images with large dynamic range. We discuss this problem in this note, and propose some simple steps to accelerate the implementation in general, and for small \\sigma_r in particular.\n",
        "submission_date": "2012-03-22T00:00:00",
        "last_modified_date": "2012-08-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1203.6329",
        "title": "Analysis of Magnification in Depth from Defocus",
        "authors": [
            "Arnav Bhavsar"
        ],
        "abstract": "In depth from defocus (DFD), when images are captured with different camera parameters, a relative magnification is induced between them. Image warping is a simpler solution to account for magnification than seemingly more accurate optical approaches. This work is an investigation into the effects of magnification on the accuracy of DFD. We comment on issues regarding scaling effect on relative blur computation. We statistically analyze accountability of scale factor, commenting on the bias and efficiency of the estimator that does not consider scale. We also discuss the effect of interpolation errors on blur estimation in a warping based solution to handle magnification and carry out experimental analysis to comment on the blur estimation accuracy.\n    ",
        "submission_date": "2012-03-28T00:00:00",
        "last_modified_date": "2012-11-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1203.6722",
        "title": "Face Expression Recognition and Analysis: The State of the Art",
        "authors": [
            "Vinay Bettadapura"
        ],
        "abstract": "The automatic recognition of facial expressions has been an active research topic since the early nineties. There have been several advances in the past few years in terms of face detection and tracking, feature extraction mechanisms and the techniques used for expression classification. This paper surveys some of the published work since 2001 till date. The paper presents a time-line view of the advances made in this field, the applications of automatic face expression recognizers, the characteristics of an ideal system, the databases that have been used and the advances made in terms of their standardization and a detailed summary of the state of the art. The paper also discusses facial parameterization using FACS Action Units (AUs) and MPEG-4 Facial Animation Parameters (FAPs) and the recent advances in face detection, tracking and feature extraction methods. Notes have also been presented on emotions, expressions and facial features, discussion on the six prototypic expressions and the recent studies on expression classifiers. The paper ends with a note on the challenges and the future work. This paper has been written in a tutorial style with the intention of helping students and researchers who are new to this field.\n    ",
        "submission_date": "2012-03-30T00:00:00",
        "last_modified_date": "2012-03-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1204.0357",
        "title": "Skull-stripping for Tumor-bearing Brain Images",
        "authors": [
            "Stefan Bauer",
            "Lutz-P. Nolte",
            "Mauricio Reyes"
        ],
        "abstract": "Skull-stripping separates the skull region of the head from the soft brain tissues. In many cases of brain image analysis, this is an essential preprocessing step in order to improve the final result. This is true for both registration and segmentation tasks. In fact, skull-stripping of magnetic resonance images (MRI) is a well-studied problem with numerous publications in recent years. Many different algorithms have been proposed, a summary and comparison of which can be found in [Fennema-Notestine, 2006]. Despite the abundance of approaches, we discovered that the algorithms which had been suggested so far, perform poorly when dealing with tumor-bearing brain images. This is mostly due to additional difficulties in separating the brain from the skull in this case, especially when the lesion is located very close to the skull border. Additionally, images acquired according to standard clinical protocols, often exhibit anisotropic resolution and only partial coverage, which further complicates the task. Therefore, we developed a method which is dedicated to skull-stripping for clinically acquired tumor-bearing brain images.\n    ",
        "submission_date": "2012-04-02T00:00:00",
        "last_modified_date": "2012-04-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1204.0767",
        "title": "Efficient Fruit Defect Detection and Glare removal Algorithm by anisotropic diffusion and 2D Gabor filter",
        "authors": [
            "Vini Katyal",
            "Deepesh Srivastava"
        ],
        "abstract": "This paper focuses on fruit defect detection and glare removal using morphological operations, Glare removal can be considered as an important preprocessing step as uneven lighting may introduce it in images, which hamper the results produced through segmentation by Gabor filters .The problem of glare in images is very pronounced sometimes due to the unusual reflectance from the camera sensor or stray light entering, this method counteracts this problem and makes the defect detection much more pronounced. Anisotropic diffusion is used for further smoothening of the images and removing the high energy regions in an image for better defect detection and makes the defects more retrievable. Our algorithm is robust and scalable the employability of a particular mask for glare removal has been checked and proved useful for ",
        "submission_date": "2012-04-03T00:00:00",
        "last_modified_date": "2012-04-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1204.1177",
        "title": "Principal Component Analysis-Linear Discriminant Analysis Feature Extractor for Pattern Recognition",
        "authors": [
            "Aamir Khan",
            "Hasan Farooq"
        ],
        "abstract": "Robustness of embedded biometric systems is of prime importance with the emergence of fourth generation communication devices and advancement in security systems This paper presents the realization of such technologies which demands reliable and error-free biometric identity verification systems. High dimensional patterns are not permitted due to eigen-decomposition in high dimensional image space and degeneration of scattering matrices in small size sample. Generalization, dimensionality reduction and maximizing the margins are controlled by minimizing weight vectors. Results show good pattern by multimodal biometric system proposed in this paper. This paper is aimed at investigating a biometric identity system using Principal Component Analysis and Lindear Discriminant Analysis with K-Nearest Neighbor and implementing such system in real-time using SignalWAVE.\n    ",
        "submission_date": "2012-04-05T00:00:00",
        "last_modified_date": "2012-04-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1204.1198",
        "title": "A Complete Workflow for Development of Bangla OCR",
        "authors": [
            "Farjana Yeasmin Omee",
            "Shiam Shabbir Himel",
            "Md. Abu Naser Bikas"
        ],
        "abstract": "Developing a Bangla OCR requires bunch of algorithm and methods. There were many effort went on for developing a Bangla OCR. But all of them failed to provide an error free Bangla OCR. Each of them has some lacking. We discussed about the problem scope of currently existing Bangla OCR's. In this paper, we present the basic steps required for developing a Bangla OCR and a complete workflow for development of a Bangla OCR with mentioning all the possible algorithms required.\n    ",
        "submission_date": "2012-04-05T00:00:00",
        "last_modified_date": "2012-04-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1204.1393",
        "title": "Continuous Markov Random Fields for Robust Stereo Estimation",
        "authors": [
            "Koichiro Yamaguchi",
            "Tamir Hazan",
            "David McAllester",
            "Raquel Urtasun"
        ],
        "abstract": "In this paper we present a novel slanted-plane MRF model which reasons jointly about occlusion boundaries as well as depth. We formulate the problem as the one of inference in a hybrid MRF composed of both continuous (i.e., slanted 3D planes) and discrete (i.e., occlusion boundaries) random variables. This allows us to define potentials encoding the ownership of the pixels that compose the boundary between segments, as well as potentials encoding which junctions are physically possible. Our approach outperforms the state-of-the-art on Middlebury high resolution imagery as well as in the more challenging KITTI dataset, while being more efficient than existing slanted plane MRF-based methods, taking on average 2 minutes to perform inference on high resolution imagery.\n    ",
        "submission_date": "2012-04-06T00:00:00",
        "last_modified_date": "2012-04-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1204.1611",
        "title": "Vision-based Human Gender Recognition: A Survey",
        "authors": [
            "Choon Boon Ng",
            "Yong Haur Tay",
            "Bok Min Goi"
        ],
        "abstract": "Gender is an important demographic attribute of people. This paper provides a survey of human gender recognition in computer vision. A review of approaches exploiting information from face and whole body (either from a still image or gait sequence) is presented. We highlight the challenges faced and survey the representative methods of these approaches. Based on the results, good performance have been achieved for datasets captured under controlled environments, but there is still much work that can be done to improve the robustness of gender recognition under real-life environments.\n    ",
        "submission_date": "2012-04-07T00:00:00",
        "last_modified_date": "2012-04-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1204.1615",
        "title": "Discrimination between Arabic and Latin from bilingual documents",
        "authors": [
            "Sofiene Haboubi",
            "Samia Maddouri",
            "Hamid Amiri"
        ],
        "abstract": "2011 International Conference on Communications, Computing and Control Applications (CCCA)\n    ",
        "submission_date": "2012-04-07T00:00:00",
        "last_modified_date": "2012-04-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1204.1629",
        "title": "Image segmentation by adaptive distance based on EM algorithm",
        "authors": [
            "Mohamed Ali Mahjoub",
            "karim kalti"
        ],
        "abstract": "This paper introduces a Bayesian image segmentation algorithm based on finite mixtures. An EM algorithm is developed to estimate parameters of the Gaussian mixtures. The finite mixture is a flexible and powerful probabilistic modeling tool. It can be used to provide a model-based clustering in the field of pattern recognition. However, the application of finite mixtures to image segmentation presents some difficulties; especially it's sensible to noise. In this paper we propose a variant of this method which aims to resolve this problem. Our approach proceeds by the characterization of pixels by two features: the first one describes the intrinsic properties of the pixel and the second characterizes the neighborhood of pixel. Then the classification is made on the base on adaptive distance which privileges the one or the other features according to the spatial position of the pixel in the image. The obtained results have shown a significant improvement of our approach compared to the standard version of EM algorithm.\n    ",
        "submission_date": "2012-04-07T00:00:00",
        "last_modified_date": "2012-04-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1204.1631",
        "title": "New approach using Bayesian Network to improve content based image classification systems",
        "authors": [
            "Khlifia jayech",
            "mohamed ali mahjoub"
        ],
        "abstract": "This paper proposes a new approach based on augmented naive Bayes for image classification. Initially, each image is cutting in a whole of blocks. For each block, we compute a vector of descriptors. Then, we propose to carry out a classification of the vectors of descriptors to build a vector of labels for each image. Finally, we propose three variants of Bayesian Networks such as Naive Bayesian Network (NB), Tree Augmented Naive Bayes (TAN) and Forest Augmented Naive Bayes (FAN) to classify the image using the vector of labels. The results showed a marked improvement over the FAN, NB and TAN.\n    ",
        "submission_date": "2012-04-07T00:00:00",
        "last_modified_date": "2012-04-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1204.1634",
        "title": "Automatic liver segmentation method in CT images",
        "authors": [
            "Oussema zayane",
            "besma jouini",
            "Mohamed Ali Mahjoub"
        ],
        "abstract": "The aim of this work is to develop a method for automatic segmentation of the liver based on a priori knowledge of the image, such as location and shape of the liver.\n    ",
        "submission_date": "2012-04-07T00:00:00",
        "last_modified_date": "2012-04-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1204.1678",
        "title": "A New Approach for Arabic Handwritten Postal Addresses Recognition",
        "authors": [
            "Moncef Charfi",
            "Monji Kherallah",
            "Abdelkarim El Baati",
            "Adel M. Alimi"
        ],
        "abstract": "In this paper, we propose an automatic analysis system for the Arabic handwriting postal addresses recognition, by using the beta elliptical model. Our system is divided into different steps: analysis, pre-processing and classification. The first operation is the filtering of image. In the second, we remove the border print, stamps and graphics. After locating the address on the envelope, the address segmentation allows the extraction of postal code and city name separately. The pre-processing system and the modeling approach are based on two basic steps. The first step is the extraction of the temporal order in the image of the handwritten trajectory. The second step is based on the use of Beta-Elliptical model for the representation of handwritten script. The recognition system is based on Graph-matching algorithm. Our modeling and recognition approaches were validated by using the postal code and city names extracted from the Tunisian postal envelopes data. The recognition rate obtained is about 98%.\n    ",
        "submission_date": "2012-04-07T00:00:00",
        "last_modified_date": "2012-04-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1204.1679",
        "title": "Clustering and Bayesian network for image of faces classification",
        "authors": [
            "Khlifia Jayech",
            "Mohamed Ali Mahjoub"
        ],
        "abstract": "In a content based image classification system, target images are sorted by feature similarities with respect to the query (CBIR). In this paper, we propose to use new approach combining distance tangent, k-means algorithm and Bayesian network for image classification. First, we use the technique of tangent distance to calculate several tangent spaces representing the same image. The objective is to reduce the error in the classification phase. Second, we cut the image in a whole of blocks. For each block, we compute a vector of descriptors. Then, we use K-means to cluster the low-level features including color and texture information to build a vector of labels for each image. Finally, we apply five variants of Bayesian networks classifiers (Na\u00efve Bayes, Global Tree Augmented Na\u00efve Bayes (GTAN), Global Forest Augmented Na\u00efve Bayes (GFAN), Tree Augmented Na\u00efve Bayes for each class (TAN), and Forest Augmented Na\u00efve Bayes for each class (FAN) to classify the image of faces using the vector of labels. In order to validate the feasibility and effectively, we compare the results of GFAN to FAN and to the others classifiers (NB, GTAN, TAN). The results demonstrate FAN outperforms than GFAN, NB, GTAN and TAN in the overall classification accuracy.\n    ",
        "submission_date": "2012-04-07T00:00:00",
        "last_modified_date": "2012-04-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1204.1704",
        "title": "Multi-Level Coding Efficiency with Improved Quality for Image Compression based on AMBTC",
        "authors": [
            "K.Somasundaram",
            "S.Vimala"
        ],
        "abstract": "In this paper, we have proposed an extended version of Absolute Moment Block Truncation Coding (AMBTC) to compress images. Generally the elements of a bitplane used in the variants of Block Truncation Coding (BTC) are of size 1 bit. But it has been extended to two bits in the proposed method. Number of statistical moments preserved to reconstruct the compressed has also been raised from 2 to 4. Hence, the quality of the reconstructed images has been improved significantly from 33.62 to 38.12 with the increase in bpp by 1. The increased bpp (3) is further reduced to 1.75in multiple levels: in one level, by dropping 4 elements of the bitplane in such a away that the pixel values of the dropped elements can easily be interpolated with out much of loss in the quality, in level two, eight elements are dropped and reconstructed later and in level three, the size of the statistical moments is reduced. The experiments were carried over standard images of varying intensities. In all the cases, the proposed method outperforms the existing AMBTC technique in terms of both PSNR and bpp.\n    ",
        "submission_date": "2012-04-08T00:00:00",
        "last_modified_date": "2012-04-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1204.1811",
        "title": "Skin-color based videos categorization",
        "authors": [
            "Rehanullah Khan",
            "Asad Maqsood",
            "Zeeshan Khan",
            "Muhammad Ishaq",
            "Arsalan Arif"
        ],
        "abstract": "On dedicated websites, people can upload videos and share it with the rest of the world. Currently these videos are cat- egorized manually by the help of the user community. In this paper, we propose a combination of color spaces with the Bayesian network approach for robust detection of skin color followed by an automated video categorization. Exper- imental results show that our method can achieve satisfactory performance for categorizing videos based on skin color.\n    ",
        "submission_date": "2012-04-09T00:00:00",
        "last_modified_date": "2012-04-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1204.2062",
        "title": "SVD-EBP Algorithm for Iris Pattern Recognition",
        "authors": [
            "Babasaheb G. Patil",
            "Shaila Subbaraman"
        ],
        "abstract": "This paper proposes a neural network approach based on Error Back Propagation (EBP) for classification of different eye images. To reduce the complexity of layered neural network the dimensions of input vectors are optimized using Singular Value Decomposition (SVD). The main of this work is to provide for best method for feature extraction and classification. The details of this combined system named as SVD-EBP system, and results thereof are presented in this paper.\n",
        "submission_date": "2012-04-10T00:00:00",
        "last_modified_date": "2012-04-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1204.2073",
        "title": "Automatic facial feature extraction and expression recognition based on neural network",
        "authors": [
            "S.P. Khandait",
            "R.C. Thool",
            "P.D. Khandait"
        ],
        "abstract": "In this paper, an approach to the problem of automatic facial feature extraction from a still frontal posed image and classification and recognition of facial expression and hence emotion and mood of a person is presented. Feed forward back propagation neural network is used as a classifier for classifying the expressions of supplied face into seven basic categories like surprise, neutral, sad, disgust, fear, happy and angry. For face portion segmentation and localization, morphological image processing operations are used. Permanent facial features like eyebrows, eyes, mouth and nose are extracted using SUSAN edge detection operator, facial geometry, edge projection analysis. Experiments are carried out on JAFFE facial expression database and gives better performance in terms of 100% accuracy for training set and 95.26% accuracy for test set.\n    ",
        "submission_date": "2012-04-10T00:00:00",
        "last_modified_date": "2012-04-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1204.2114",
        "title": "Image-based Vehicle Classification System",
        "authors": [
            "Jun Yee Ng",
            "Yong Haur Tay"
        ],
        "abstract": "Electronic toll collection (ETC) system has been a common trend used for toll collection on toll road nowadays. The implementation of electronic toll collection allows vehicles to travel at low or full speed during the toll payment, which help to avoid the traffic delay at toll road. One of the major components of an electronic toll collection is the automatic vehicle detection and classification (AVDC) system which is important to classify the vehicle so that the toll is charged according to the vehicle classes. Vision-based vehicle classification system is one type of vehicle classification system which adopt camera as the input sensing device for the system. This type of system has advantage over the rest for it is cost efficient as low cost camera is used. The implementation of vision-based vehicle classification system requires lower initial investment cost and very suitable for the toll collection trend migration in Malaysia from single ETC system to full-scale multi-lane free flow (MLFF). This project includes the development of an image-based vehicle classification system as an effort to seek for a robust vision-based vehicle classification system. The techniques used in the system include scale-invariant feature transform (SIFT) technique, Canny's edge detector, K-means clustering as well as Euclidean distance matching. In this project, a unique way to image description as matching medium is proposed. This distinctiveness of method is analogous to the human DNA concept which is highly unique. The system is evaluated on open datasets and return promising results.\n    ",
        "submission_date": "2012-04-10T00:00:00",
        "last_modified_date": "2012-04-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1204.2134",
        "title": "The steepest watershed: from graphs to images",
        "authors": [
            "Fernand Meyer"
        ],
        "abstract": "The watershed is a powerful tool for segmenting objects whose contours appear as crest lines on a gradient image. The watershed transform associates to a topographic surface a partition into catchment basins, defined as attraction zones of a drop of water falling on the relief and following a line of steepest descent. Unfortunately, catchment basins may overlap and do not form a partition. Moreover, current watershed algorithms, being shortsighted, do not correctly estimate the steepness of the downwards trajectories and overestimate the overlapping zones of catchment basins. An arbitrary division of these zones between adjacent catchment basin results in a poor localization of the contours. We propose an algorithm without myopia, which considers the total length of a trajectory for estimating its steepness. We first consider topographic surfaces defined on node weighted graphs. The graphs are pruned in order to eliminate all downwards trajectories which are not the steepest. An iterative algorithm with simple neighborhood operations performs the pruning and constructs the catchment basins. The algorithm is then adapted to gray tone images. The graph structure itself is encoded as an image thanks to the fixed neighborhood structure of grids. A pair of adaptative erosions and dilations prune the graph and extend the catchment basins. As a result one obtains a precise detection of the catchment basins and a graph of the steepest trajectories. A last iterative algorithm allows to follow selected downwards trajectories in order to detect particular structures such as rivers or thalweg lines of the topographic surface.\n    ",
        "submission_date": "2012-04-10T00:00:00",
        "last_modified_date": "2012-04-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1204.2294",
        "title": "Ubiquitous WLAN/Camera Positioning using Inverse Intensity Chromaticity Space-based Feature Detection and Matching: A Preliminary Result",
        "authors": [
            "Wan Mohd Yaakob Wan Bejuri",
            "Mohd Murtadha Mohamad",
            "Maimunah Sapri",
            "Mohd Adly Rosly"
        ],
        "abstract": "This paper present our new intensity chromaticity space-based feature detection and matching algorithm. This approach utilizes hybridization of wireless local area network and camera internal sensor which to receive signal strength from a access point and the same time retrieve interest point information from hallways. This information is combined by model fitting approach in order to find the absolute of user target position. No conventional searching algorithm is required, thus it is expected reducing the computational complexity. Finally we present pre-experimental results to illustrate the performance of the localization system for an indoor environment set-up.\n    ",
        "submission_date": "2012-04-10T00:00:00",
        "last_modified_date": "2012-04-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1204.2336",
        "title": "Feature Extraction Methods for Color Image Similarity",
        "authors": [
            "R. Venkata Ramana Chary",
            "D. Rajya Lakshmi",
            "K. V. N. Sunitha"
        ],
        "abstract": "Many User interactive systems are proposed all methods are trying to implement as a user friendly and various approaches proposed but most of the systems not reached to the use specifications like user friendly systems with user interest, all proposed method implemented basic techniques some are improved methods also propose but not reaching to the user specifications. In this proposed paper we concentrated on image retrieval system with in early days many user interactive systems performed with basic concepts but such systems are not reaching to the user specifications and not attracted to the user so a lot of research interest in recent years with new specifications, recent approaches have user is interested in friendly interacted methods are expecting, many are concentrated for improvement in all methods. In this proposed system we focus on the retrieval of images within a large image collection based on color projections and different mathematical approaches are introduced and applied for retrieval of images. before Appling proposed methods images are sub grouping using threshold values, in this paper R G B color combinations considered for retrieval of images, in proposed methods are implemented and results are included, through results it is observed that we obtaining efficient results comparatively previous and existing.\n    ",
        "submission_date": "2012-04-11T00:00:00",
        "last_modified_date": "2012-04-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1204.2358",
        "title": "Collaborative Representation based Classification for Face Recognition",
        "authors": [
            "Lei Zhang",
            "Meng Yang",
            "Xiangchu Feng",
            "Yi Ma",
            "David Zhang"
        ],
        "abstract": "By coding a query sample as a sparse linear combination of all training samples and then classifying it by evaluating which class leads to the minimal coding residual, sparse representation based classification (SRC) leads to interesting results for robust face recognition. It is widely believed that the l1- norm sparsity constraint on coding coefficients plays a key role in the success of SRC, while its use of all training samples to collaboratively represent the query sample is rather ignored. In this paper we discuss how SRC works, and show that the collaborative representation mechanism used in SRC is much more crucial to its success of face classification. The SRC is a special case of collaborative representation based classification (CRC), which has various instantiations by applying different norms to the coding residual and coding coefficient. More specifically, the l1 or l2 norm characterization of coding residual is related to the robustness of CRC to outlier facial pixels, while the l1 or l2 norm characterization of coding coefficient is related to the degree of discrimination of facial features. Extensive experiments were conducted to verify the face recognition accuracy and efficiency of CRC with different instantiations.\n    ",
        "submission_date": "2012-04-11T00:00:00",
        "last_modified_date": "2014-03-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1204.2741",
        "title": "Simultaneous Object Detection, Tracking, and Event Recognition",
        "authors": [
            "Andrei Barbu",
            "Aaron Michaux",
            "Siddharth Narayanaswamy",
            "Jeffrey Mark Siskind"
        ],
        "abstract": "The common internal structure and algorithmic organization of object detection, detection-based tracking, and event recognition facilitates a general approach to integrating these three components. This supports multidirectional information flow between these components allowing object detection to influence tracking and event recognition and event recognition to influence tracking and object detection. The performance of the combination can exceed the performance of the components in isolation. This can be done with linear asymptotic complexity.\n    ",
        "submission_date": "2012-04-12T00:00:00",
        "last_modified_date": "2012-04-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1204.2742",
        "title": "Video In Sentences Out",
        "authors": [
            "Andrei Barbu",
            "Alexander Bridge",
            "Zachary Burchill",
            "Dan Coroian",
            "Sven Dickinson",
            "Sanja Fidler",
            "Aaron Michaux",
            "Sam Mussman",
            "Siddharth Narayanaswamy",
            "Dhaval Salvi",
            "Lara Schmidt",
            "Jiangnan Shangguan",
            "Jeffrey Mark Siskind",
            "Jarrell Waggoner",
            "Song Wang",
            "Jinlian Wei",
            "Yifan Yin",
            "Zhiqi Zhang"
        ],
        "abstract": "We present a system that produces sentential descriptions of video: who did what to whom, and where and how they did it. Action class is rendered as a verb, participant objects as noun phrases, properties of those objects as adjectival modifiers in those noun phrases,spatial relations between those participants as prepositional phrases, and characteristics of the event as prepositional-phrase adjuncts and adverbial modifiers. Extracting the information needed to render these linguistic entities requires an approach to event recognition that recovers object tracks, the track-to-role assignments, and changing body posture.\n    ",
        "submission_date": "2012-04-12T00:00:00",
        "last_modified_date": "2012-04-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1204.2801",
        "title": "Seeing Unseeability to See the Unseeable",
        "authors": [
            "Siddharth Narayanaswamy",
            "Andrei Barbu",
            "Jeffrey Mark Siskind"
        ],
        "abstract": "We present a framework that allows an observer to determine occluded portions of a structure by finding the maximum-likelihood estimate of those occluded portions consistent with visible image evidence and a consistency model. Doing this requires determining which portions of the structure are occluded in the first place. Since each process relies on the other, we determine a solution to both problems in tandem. We extend our framework to determine confidence of one's assessment of which portions of an observed structure are occluded, and the estimate of that occluded structure, by determining the sensitivity of one's assessment to potential new observations. We further extend our framework to determine a robotic action whose execution would allow a new observation that would maximally increase one's confidence.\n    ",
        "submission_date": "2012-04-12T00:00:00",
        "last_modified_date": "2012-04-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1204.2837",
        "title": "Watersheds, waterfalls, on edge or node weighted graphs",
        "authors": [
            "Fernand Meyer"
        ],
        "abstract": "We present an algebraic approach to the watershed adapted to edge or node weighted graphs. Starting with the flooding adjunction, we introduce the flooding graphs, for which node and edge weights may be deduced one from the other. Each node weighted or edge weighted graph may be transformed in a flooding graph, showing that there is no superiority in using one or the other, both being equivalent. We then introduce pruning operators extract subgraphs of increasing steepness. For an increasing steepness, the number of never ascending paths becomes smaller and smaller. This reduces the watershed zone, where catchment basins overlap. A last pruning operator called scissor associates to each node outside the regional minima one and only one edge. The catchment basins of this new graph do not overlap and form a watershed partition. Again, with an increasing steepness, the number of distinct watershed partitions contained in a graph becomes smaller and smaller. Ultimately, for natural image, an infinite steepness leads to a unique solution, as it is not likely that two absolutely identical non ascending paths of infinite steepness connect a node with two distinct minima. It happens that non ascending paths of a given steepness are the geodesics of lexicographic distance functions of a given depth. This permits to extract the watershed partitions as skeletons by zone of influence of the minima for such lexicographic distances. The waterfall hierarchy is obtained by a sequence of operations. The first constructs the minimum spanning forest which spans an initial watershed partition. The contraction of the trees into one node produces a reduced graph which may be submitted to the same treatment. The process is iterated until only one region remains. The union of the edges of all forests produced constitutes a minimum spanning tree of the initial graph.\n    ",
        "submission_date": "2012-04-12T00:00:00",
        "last_modified_date": "2012-04-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1204.2912",
        "title": "Non-sparse Linear Representations for Visual Tracking with Online Reservoir Metric Learning",
        "authors": [
            "Xi Li",
            "Chunhua Shen",
            "Qinfeng Shi",
            "Anthony Dick",
            "Anton van den Hengel"
        ],
        "abstract": "Most sparse linear representation-based trackers need to solve a computationally expensive L1-regularized optimization problem. To address this problem, we propose a visual tracker based on non-sparse linear representations, which admit an efficient closed-form solution without sacrificing accuracy. Moreover, in order to capture the correlation information between different feature dimensions, we learn a Mahalanobis distance metric in an online fashion and incorporate the learned metric into the optimization problem for obtaining the linear representation. We show that online metric learning using proximity comparison significantly improves the robustness of the tracking, especially on those sequences exhibiting drastic appearance changes. Furthermore, in order to prevent the unbounded growth in the number of training samples for the metric learning, we design a time-weighted reservoir sampling method to maintain and update limited-sized foreground and background sample buffers for balancing sample diversity and adaptability. Experimental results on challenging videos demonstrate the effectiveness and robustness of the proposed tracker.\n    ",
        "submission_date": "2012-04-13T00:00:00",
        "last_modified_date": "2012-04-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1204.2994",
        "title": "Image Restoration with Signal-dependent Camera Noise",
        "authors": [
            "Ayan Chakrabarti",
            "Todd Zickler"
        ],
        "abstract": "This article describes a fast iterative algorithm for image denoising and deconvolution with signal-dependent observation noise. We use an optimization strategy based on variable splitting that adapts traditional Gaussian noise-based restoration algorithms to account for the observed image being corrupted by mixed Poisson-Gaussian noise and quantization errors.\n    ",
        "submission_date": "2012-04-13T00:00:00",
        "last_modified_date": "2012-04-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1204.3616",
        "title": "Large-Scale Automatic Labeling of Video Events with Verbs Based on Event-Participant Interaction",
        "authors": [
            "Andrei Barbu",
            "Alexander Bridge",
            "Dan Coroian",
            "Sven Dickinson",
            "Sam Mussman",
            "Siddharth Narayanaswamy",
            "Dhaval Salvi",
            "Lara Schmidt",
            "Jiangnan Shangguan",
            "Jeffrey Mark Siskind",
            "Jarrell Waggoner",
            "Song Wang",
            "Jinlian Wei",
            "Yifan Yin",
            "Zhiqi Zhang"
        ],
        "abstract": "We present an approach to labeling short video clips with English verbs as event descriptions. A key distinguishing aspect of this work is that it labels videos with verbs that describe the spatiotemporal interaction between event participants, humans and objects interacting with each other, abstracting away all object-class information and fine-grained image characteristics, and relying solely on the coarse-grained motion of the event participants. We apply our approach to a large set of 22 distinct verb classes and a corpus of 2,584 videos, yielding two surprising outcomes. First, a classification accuracy of greater than 70% on a 1-out-of-22 labeling task and greater than 85% on a variety of 1-out-of-10 subsets of this labeling task is independent of the choice of which of two different time-series classifiers we employ. Second, we achieve this level of accuracy using a highly impoverished intermediate representation consisting solely of the bounding boxes of one or two event participants as a function of time. This indicates that successful event recognition depends more on the choice of appropriate features that characterize the linguistic invariants of the event classes than on the particular classifier algorithms.\n    ",
        "submission_date": "2012-04-16T00:00:00",
        "last_modified_date": "2012-04-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1204.3618",
        "title": "Compensating Interpolation Distortion by Using New Optimized Modular Method",
        "authors": [
            "Mohammad Tofighi",
            "Ali Ayremlou",
            "Farokh Marvasti"
        ],
        "abstract": "A modular method was suggested before to recover a band limited signal from the sample and hold and linearly interpolated (or, in general, an nth-order-hold) version of the regular samples. In this paper a novel approach for compensating the distortion of any interpolation based on modular method has been proposed. In this method the performance of the modular method is optimized by adding only some simply calculated coefficients. This approach causes drastic improvement in terms of signal-to-noise ratios with fewer modules compared to the classical modular method. Simulation results clearly confirm the improvement of the proposed method and also its superior robustness against additive noise.\n    ",
        "submission_date": "2012-04-13T00:00:00",
        "last_modified_date": "2012-04-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1204.3968",
        "title": "Convolutional Neural Networks Applied to House Numbers Digit Classification",
        "authors": [
            "Pierre Sermanet",
            "Soumith Chintala",
            "Yann LeCun"
        ],
        "abstract": "We classify digits of real-world house numbers using convolutional neural networks (ConvNets). ConvNets are hierarchical feature learning neural networks whose structure is biologically inspired. Unlike many popular vision approaches that are hand-designed, ConvNets can automatically learn a unique set of features optimized for a given task. We augmented the traditional ConvNet architecture by learning multi-stage features and by using Lp pooling and establish a new state-of-the-art of 94.85% accuracy on the SVHN dataset (45.2% error improvement). Furthermore, we analyze the benefits of different pooling methods and multi-stage features in ConvNets. The source code and a tutorial are available at ",
        "submission_date": "2012-04-18T00:00:00",
        "last_modified_date": "2012-04-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1204.4257",
        "title": "Speech Recognition: Increasing Efficiency of Support Vector Machines",
        "authors": [
            "Aamir Khan",
            "Muhammad Farhan",
            "Asar Ali"
        ],
        "abstract": "With the advancement of communication and security technologies, it has become crucial to have robustness of embedded biometric systems. This paper presents the realization of such technologies which demands reliable and error-free biometric identity verification systems. High dimensional patterns are not permitted due to eigen-decomposition in high dimensional feature space and degeneration of scattering matrices in small size sample. Generalization, dimensionality reduction and maximizing the margins are controlled by minimizing weight vectors. Results show good pattern by multimodal biometric system proposed in this paper. This paper is aimed at investigating a biometric identity system using Support Vector Machines(SVMs) and Lindear Discriminant Analysis(LDA) with MFCCs and implementing such system in real-time using SignalWAVE.\n    ",
        "submission_date": "2012-04-19T00:00:00",
        "last_modified_date": "2012-04-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1204.4476",
        "title": "Dynamic Template Tracking and Recognition",
        "authors": [
            "Rizwan Chaudhry",
            "Gregory Hager",
            "Rene Vidal"
        ],
        "abstract": "In this paper we address the problem of tracking non-rigid objects whose local appearance and motion changes as a function of time. This class of objects includes dynamic textures such as steam, fire, smoke, water, etc., as well as articulated objects such as humans performing various actions. We model the temporal evolution of the object's appearance/motion using a Linear Dynamical System (LDS). We learn such models from sample videos and use them as dynamic templates for tracking objects in novel videos. We pose the problem of tracking a dynamic non-rigid object in the current frame as a maximum a-posteriori estimate of the location of the object and the latent state of the dynamical system, given the current image features and the best estimate of the state in the previous frame. The advantage of our approach is that we can specify a-priori the type of texture to be tracked in the scene by using previously trained models for the dynamics of these textures. Our framework naturally generalizes common tracking methods such as SSD and kernel-based tracking from static templates to dynamic templates. We test our algorithm on synthetic as well as real examples of dynamic textures and show that our simple dynamics-based trackers perform at par if not better than the state-of-the-art. Since our approach is general and applicable to any image feature, we also apply it to the problem of human action tracking and build action-specific optical flow trackers that perform better than the state-of-the-art when tracking a human performing a particular action. Finally, since our approach is generative, we can use a-priori trained trackers for different texture or action classes to simultaneously track and recognize the texture or action in the video.\n    ",
        "submission_date": "2012-04-19T00:00:00",
        "last_modified_date": "2012-04-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1204.4758",
        "title": "Morphological Filtering in Shape Spaces: Applications using Tree-Based Image Representations",
        "authors": [
            "Yongchao Xu",
            "Thierry G\u00e9raud",
            "Laurent Najman"
        ],
        "abstract": "Connected operators are filtering tools that act by merging elementary regions of an image. A popular strategy is based on tree-based image representations: for example, one can compute an attribute on each node of the tree and keep only the nodes for which the attribute is sufficiently strong. This operation can be seen as a thresholding of the tree, seen as a graph whose nodes are weighted by the attribute. Rather than being satisfied with a mere thresholding, we propose to expand on this idea, and to apply connected filters on this latest graph. Consequently, the filtering is done not in the space of the image, but on the space of shapes build from the image. Such a processing is a generalization of the existing tree-based connected operators. Indeed, the framework includes classical existing connected operators by attributes. It also allows us to propose a class of novel connected operators from the leveling family, based on shape attributes. Finally, we also propose a novel class of self-dual connected operators that we call morphological shapings.\n    ",
        "submission_date": "2012-04-20T00:00:00",
        "last_modified_date": "2012-07-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1204.4867",
        "title": "A Unified Multiscale Framework for Discrete Energy Minimization",
        "authors": [
            "Shai Bagon",
            "Meirav Galun"
        ],
        "abstract": "Discrete energy minimization is a ubiquitous task in computer vision, yet is NP-hard in most cases. In this work we propose a multiscale framework for coping with the NP-hardness of discrete optimization. Our approach utilizes algebraic multiscale principles to efficiently explore the discrete solution space, yielding improved results on challenging, non-submodular energies for which current methods provide unsatisfactory approximations. In contrast to popular multiscale methods in computer vision, that builds an image pyramid, our framework acts directly on the energy to construct an energy pyramid. Deriving a multiscale scheme from the energy itself makes our framework application independent and widely applicable. Our framework gives rise to two complementary energy coarsening strategies: one in which coarser scales involve fewer variables, and a more revolutionary one in which the coarser scales involve fewer discrete labels. We empirically evaluated our unified framework on a variety of both non-submodular and submodular energies, including energies from Middlebury benchmark.\n    ",
        "submission_date": "2012-04-22T00:00:00",
        "last_modified_date": "2012-04-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1204.5416",
        "title": "A New Approach of Improving CFA Image for Digital Camera's",
        "authors": [
            "Manoj Kumar",
            "Vikas Kaushik",
            "Pradeep Singla"
        ],
        "abstract": "This paper work directly towards the improving the quality of the image for the digital cameras and other visual capturing products. In this Paper, the authors clearly defines the problems occurs in the CFA image. A different methodology for removing the noise is discuses in the paper for color correction and color balancing of the image. At the same time, the authors also proposed a new methodology of providing denoisiing process before the demosaickingfor the improving the image quality of CFA which is much efficient then the other previous defined. The demosaicking process for producing the colors in the image in a best way is also discuss.\n    ",
        "submission_date": "2012-04-24T00:00:00",
        "last_modified_date": "2012-04-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1204.5431",
        "title": "Robust Head Pose Estimation Using Contourlet Transform",
        "authors": [
            "Mohammad Tofighi",
            "Hashem Kalbkhani",
            "Mahrokh G. Shayesteh",
            "Mehdi Ghasemzadeh"
        ],
        "abstract": "Estimating pose of the head is an important preprocessing step in many pattern recognition and computer vision systems such as face recognition. Since the performance of the face recognition systems is greatly affected by the poses of the face, how to estimate the accurate pose of the face in human face image is still a challenging problem. In this paper, we represent a novel method for head pose estimation. To enhance the efficiency of the estimation we use contourlet transform for feature extraction. Contourlet transform is multi-resolution, multi-direction transform. In order to reduce the feature space dimension and obtain appropriate features we use LDA (Linear Discriminant Analysis) and PCA (Principal Component Analysis) to remove ineffcient features. Then, we apply different classifiers such as k-nearest neighborhood (knn) and minimum distance. We use the public available FERET database to evaluate the performance of proposed method. Simulation results indicate the superior robustness of the proposed method.\n    ",
        "submission_date": "2012-04-24T00:00:00",
        "last_modified_date": "2012-05-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1204.6326",
        "title": "Background subtraction based on Local Shape",
        "authors": [
            "Jean-Philippe Jodoin",
            "Guillaume-Alexandre Bilodeau",
            "Nicolas Saunier"
        ],
        "abstract": "We present a novel approach to background subtraction that is based on the local shape of small image regions. In our approach, an image region centered on a pixel is mod-eled using the local self-similarity descriptor. We aim at obtaining a reliable change detection based on local shape change in an image when foreground objects are moving. The method first builds a background model and compares the local self-similarities between the background model and the subsequent frames to distinguish background and foreground objects. Post-processing is then used to refine the boundaries of moving objects. Results show that this approach is promising as the foregrounds obtained are com-plete, although they often include shadows.\n    ",
        "submission_date": "2012-04-27T00:00:00",
        "last_modified_date": "2012-05-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1204.6385",
        "title": "A 3D Segmentation Method for Retinal Optical Coherence Tomography Volume Data",
        "authors": [
            "Yankui Sun",
            "Tian Zhang"
        ],
        "abstract": "With the introduction of spectral-domain optical coherence tomography (OCT), much larger image datasets are routinely acquired compared to what was possible using the previous generation of time-domain OCT. Thus, the need for 3-D segmentation methods for processing such data is becoming increasingly important. We present a new 3D segmentation method for retinal OCT volume data, which generates an enhanced volume data by using pixel intensity, boundary position information, intensity changes on both sides of the border simultaneously, and preliminary discrete boundary points are found from all A-Scans and then the smoothed boundary surface can be obtained after removing a small quantity of error points. Our experiments show that this method is efficient, accurate and robust.\n    ",
        "submission_date": "2012-04-28T00:00:00",
        "last_modified_date": "2012-04-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1204.6458",
        "title": "Active Contour with A Tangential Component",
        "authors": [
            "Junyan Wang",
            "Kap Luk Chan"
        ],
        "abstract": "Conventional edge-based active contours often require the normal component of an edge indicator function on the optimal contours to approximate zero, while the tangential component can still be significant. In real images, the full gradients of the edge indicator function along the object boundaries are often small. Hence, the curve evolution of edge-based active contours can terminate early before converging to the object boundaries with a careless contour initialization. We propose a novel Geodesic Snakes (GeoSnakes) active contour that requires the full gradients of the edge indicator to vanish at the optimal solution. Besides, the conventional curve evolution approach for minimizing active contour energy cannot fully solve the Euler-Lagrange (EL) equation of our GeoSnakes active contour, causing a Pseudo Stationary Phenomenon (PSP). To address the PSP problem, we propose an auxiliary curve evolution equation, named the equilibrium flow (EF) equation. Based on the EF and the conventional curve evolution, we obtain a solution to the full EL equation of GeoSnakes active contour. Experimental results validate the proposed geometrical interpretation of the early termination problem, and they also show that the proposed method overcomes the problem.\n    ",
        "submission_date": "2012-04-29T00:00:00",
        "last_modified_date": "2012-04-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1204.6563",
        "title": "Parametric annealing: a stochastic search method for human pose tracking",
        "authors": [
            "Prabhu Kaliamoorthi",
            "Ramakrishna Kakarala"
        ],
        "abstract": "Model based methods to marker-free motion capture have a very high computational overhead that make them unattractive. In this paper we describe a method that improves on existing global optimization techniques to tracking articulated objects. Our method improves on the state-of-the-art Annealed Particle Filter (APF) by reusing samples across annealing layers and by using an adaptive parametric density for diffusion. We compare the proposed method with APF on a scalable problem and study how the two methods scale with the dimensionality, multi-modality and the range of search. Then we perform sensitivity analysis on the parameters of our algorithm and show that it tolerates a wide range of parameter settings. We also show results on tracking human pose from the widely-used Human Eva I dataset. Our results show that the proposed method reduces the tracking error despite using less than 50% of the computational resources as APF. The tracked output also shows a significant qualitative improvement over APF as demonstrated through image and video results.\n    ",
        "submission_date": "2012-04-30T00:00:00",
        "last_modified_date": "2012-05-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1204.6653",
        "title": "Elimination of Glass Artifacts and Object Segmentation",
        "authors": [
            "Vini Katyal",
            "Aviral",
            "Deepesh Srivastava"
        ],
        "abstract": "Many images nowadays are captured from behind the glasses and may have certain stains discrepancy because of glass and must be processed to make differentiation between the glass and objects behind it. This research paper proposes an algorithm to remove the damaged or corrupted part of the image and make it consistent with other part of the image and to segment objects behind the glass. The damaged part is removed using total variation inpainting method and segmentation is done using kmeans clustering, anisotropic diffusion and watershed transformation. The final output is obtained by interpolation. This algorithm can be useful to applications in which some part of the images are corrupted due to data transmission or needs to segment objects from an image for further processing.\n    ",
        "submission_date": "2012-04-30T00:00:00",
        "last_modified_date": "2012-04-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1204.6725",
        "title": "OCT Segmentation Survey and Summary Reviews and a Novel 3D Segmentation Algorithm and a Proof of Concept Implementation",
        "authors": [
            "Serguei A. Mokhov",
            "Yankui Sun"
        ],
        "abstract": "We overview the existing OCT work, especially the practical aspects of it. We create a novel algorithm for 3D OCT segmentation with the goals of speed and/or accuracy while remaining flexible in the design and implementation for future extensions and improvements. The document at this point is a running draft being iteratively \"developed\" as a progress report as the work and survey advance. It contains the review and summarization of select OCT works, the design and implementation of the OCTMARF experimentation application and some results.\n    ",
        "submission_date": "2012-04-30T00:00:00",
        "last_modified_date": "2012-06-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1205.1644",
        "title": "DBC based Face Recognition using DWT",
        "authors": [
            "H S Jagadeesh",
            "K Suresh Babu",
            "K B Raja"
        ],
        "abstract": "The applications using face biometric has proved its reliability in last decade. In this paper, we propose DBC based Face Recognition using DWT (DBC- FR) model. The Poly-U Near Infra Red (NIR) database images are scanned and cropped to get only the face part in pre-processing. The face part is resized to 100*100 and DWT is applied to derive LL, LH, HL and HH subbands. The LL subband of size 50*50 is converted into 100 cells with 5*5 dimention of each cell. The Directional Binary Code (DBC) is applied on each 5*5 cell to derive 100 features. The Euclidian distance measure is used to compare the features of test image and database images. The proposed algorithm render better percentage recognition rate compared to the existing algorithm.\n    ",
        "submission_date": "2012-05-08T00:00:00",
        "last_modified_date": "2012-05-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1205.1648",
        "title": "A novel statistical fusion rule for image fusion and its comparison in non subsampled contourlet transform domain and wavelet domain",
        "authors": [
            "Manu V T",
            "Philomina Simon"
        ],
        "abstract": "Image fusion produces a single fused image from a set of input images. A new method for image fusion is proposed based on Weighted Average Merging Method (WAMM) in the NonSubsampled Contourlet Transform (NSCT) domain. A performance analysis on various statistical fusion rules are also analysed both in NSCT and Wavelet domain. Analysis has been made on medical images, remote sensing images and multi focus images. Experimental results shows that the proposed method, WAMM obtained better results in NSCT domain than the wavelet domain as it preserves more edges and keeps the visual quality intact in the fused image.\n    ",
        "submission_date": "2012-05-08T00:00:00",
        "last_modified_date": "2012-05-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1205.2031",
        "title": "M-FISH Karyotyping - A New Approach Based on Watershed Transform",
        "authors": [
            "K. S. Sreejini",
            "A. Lijiya",
            "V. K. Govindan"
        ],
        "abstract": "Karyotyping is a process in which chromosomes in a dividing cell are properly stained, identified and displayed in a standard format, which helps geneticist to study and diagnose genetic factors behind various genetic diseases and for studying cancer. M-FISH (Multiplex Fluorescent In-Situ Hybridization) provides color karyotyping. In this paper, an automated method for M-FISH chromosome segmentation based on watershed transform followed by naive Bayes classification of each region using the features, mean and standard deviation, is presented. Also, a post processing step is added to re-classify the small chromosome segments to the neighboring larger segment for reducing the chances of misclassification. The approach provided improved accuracy when compared to the pixel-by-pixel approach. The approach was tested on 40 images from the dataset and achieved an accuracy of 84.21 %.\n    ",
        "submission_date": "2012-05-09T00:00:00",
        "last_modified_date": "2012-05-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1205.2164",
        "title": "Discrimination of English to other Indian languages (Kannada and Hindi) for OCR system",
        "authors": [
            "Ankit Kumar",
            "Tushar Patnaik",
            "Vivek Kr Verma"
        ],
        "abstract": "India is a multilingual multi-script country. In every state of India there are two languages one is state local language and the other is English. For example in Andhra Pradesh, a state in India, the document may contain text words in English and Telugu script. For Optical Character Recognition (OCR) of such a bilingual document, it is necessary to identify the script before feeding the text words to the OCRs of individual scripts. In this paper, we are introducing a simple and efficient technique of script identification for Kannada, English and Hindi text words of a printed document. The proposed approach is based on the horizontal and vertical projection profile for the discrimination of the three scripts. The feature extraction is done based on the horizontal projection profile of each text words. We analysed 700 different words of Kannada, English and Hindi in order to extract the discrimination features and for the development of knowledge base. We use the horizontal projection profile of each text word and based on the horizontal projection profile we extract the appropriate features. The proposed system is tested on 100 different document images containing more than 1000 text words of each script and a classification rate of 98.25%, 99.25% and 98.87% is achieved for Kannada, English and Hindi respectively.\n    ",
        "submission_date": "2012-05-10T00:00:00",
        "last_modified_date": "2012-05-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1205.2345",
        "title": "Hajj and Umrah Event Recognition Datasets",
        "authors": [
            "Hossam Zawbaa",
            "Salah A. Aly"
        ],
        "abstract": "In this note, new Hajj and Umrah Event Recognition datasets (HUER) are presented. The demonstrated datasets are based on videos and images taken during 2011-2012 Hajj and Umrah seasons. HUER is the first collection of datasets covering the six types of Hajj and Umrah ritual events (rotating in Tawaf around Kabaa, performing Sa'y between Safa and Marwa, standing on the mount of Arafat, staying overnight in Muzdalifah, staying two or three days in Mina, and throwing Jamarat). The HUER datasets also contain video and image databases for nine types of human actions during Hajj and Umrah (walking, drinking from Zamzam water, sleeping, smiling, eating, praying, sitting, shaving hairs and ablutions, reading the holy Quran and making duaa). The spatial resolutions are 1280 x 720 pixels for images and 640 x 480 pixels for videos and have lengths of 20 seconds in average with 30 frame per second rates.\n    ",
        "submission_date": "2012-05-10T00:00:00",
        "last_modified_date": "2012-05-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1205.2663",
        "title": "Are visual dictionaries generalizable?",
        "authors": [
            "Otavio A. B. Penatti",
            "Eduardo Valle",
            "Ricardo da S. Torres"
        ],
        "abstract": "Mid-level features based on visual dictionaries are today a cornerstone of systems for classification and retrieval of images. Those state-of-the-art representations depend crucially on the choice of a codebook (visual dictionary), which is usually derived from the dataset. In general-purpose, dynamic image collections (e.g., the Web), one cannot have the entire collection in order to extract a representative dictionary. However, based on the hypothesis that the dictionary reflects only the diversity of low-level appearances and does not capture semantics, we argue that a dictionary based on a small subset of the data, or even on an entirely different dataset, is able to produce a good representation, provided that the chosen images span a diverse enough portion of the low-level feature space. Our experiments confirm that hypothesis, opening the opportunity to greatly alleviate the burden in generating the codebook, and confirming the feasibility of employing visual dictionaries in large-scale dynamic environments.\n    ",
        "submission_date": "2012-05-11T00:00:00",
        "last_modified_date": "2012-05-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1205.3137",
        "title": "Unsupervised Discovery of Mid-Level Discriminative Patches",
        "authors": [
            "Saurabh Singh",
            "Abhinav Gupta",
            "Alexei A. Efros"
        ],
        "abstract": "The goal of this paper is to discover a set of discriminative patches which can serve as a fully unsupervised mid-level visual representation. The desired patches need to satisfy two requirements: 1) to be representative, they need to occur frequently enough in the visual world; 2) to be discriminative, they need to be different enough from the rest of the visual world. The patches could correspond to parts, objects, \"visual phrases\", etc. but are not restricted to be any one of them. We pose this as an unsupervised discriminative clustering problem on a huge dataset of image patches. We use an iterative procedure which alternates between clustering and training discriminative classifiers, while applying careful cross-validation at each step to prevent overfitting. The paper experimentally demonstrates the effectiveness of discriminative patches as an unsupervised mid-level visual representation, suggesting that it could be used in place of visual words for many tasks. Furthermore, discriminative patches can also be used in a supervised regime, such as scene classification, where they demonstrate state-of-the-art performance on the MIT Indoor-67 dataset.\n    ",
        "submission_date": "2012-05-14T00:00:00",
        "last_modified_date": "2012-08-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1205.3766",
        "title": "Efficient Topology-Controlled Sampling of Implicit Shapes",
        "authors": [
            "Jason Chang",
            "John W. Fisher III"
        ],
        "abstract": "Sampling from distributions of implicitly defined shapes enables analysis of various energy functionals used for image segmentation. Recent work describes a computationally efficient Metropolis-Hastings method for accomplishing this task. Here, we extend that framework so that samples are accepted at every iteration of the sampler, achieving an order of magnitude speed up in convergence. Additionally, we show how to incorporate topological constraints.\n    ",
        "submission_date": "2012-05-16T00:00:00",
        "last_modified_date": "2012-05-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1205.3999",
        "title": "Optimal Weights Mixed Filter for Removing Mixture of Gaussian and Impulse Noises",
        "authors": [
            "Qiyu Jin",
            "Ion Grama",
            "Quansheng Liu"
        ],
        "abstract": "According to the character of Gaussian, we modify the Rank-Ordered Absolute Differences (ROAD) to Rank-Ordered Absolute Differences of mixture of Gaussian and impulse noises (ROADG). It will be more effective to detect impulse noise when the impulse is mixed with Gaussian noise. Combining rightly the ROADG with Optimal Weights Filter (OWF), we obtain a new method to deal with the mixed noise, called Optimal Weights Mixed Filter (OWMF). The simulation results show that the method is effective to remove the mixed noise.\n    ",
        "submission_date": "2012-05-17T00:00:00",
        "last_modified_date": "2012-05-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1205.4336",
        "title": "Fuzzy - Rough Feature Selection With \u03a0- Membership Function For Mammogram Classification",
        "authors": [
            "K.Thangavel",
            "R.Roselin"
        ],
        "abstract": "Breast cancer is the second leading cause for death among women and it is diagnosed with the help of mammograms. Oncologists are miserably failed in identifying the micro calcification at the early stage with the help of the mammogram visually. In order to improve the performance of the breast cancer screening, most of the researchers have proposed Computer Aided Diagnosis using image processing. In this study mammograms are preprocessed and features are extracted, then the abnormality is identified through the classification. If all the extracted features are used, most of the cases are misidentified. Hence feature selection procedure is sought. In this paper, Fuzzy-Rough feature selection with {\\pi} membership function is proposed. The selected features are used to classify the abnormalities with help of Ant-Miner and Weka tools. The experimental analysis shows that the proposed method improves the mammograms classification accuracy.\n    ",
        "submission_date": "2012-05-19T00:00:00",
        "last_modified_date": "2012-05-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1205.4377",
        "title": "Multi-Stage Classifier Design",
        "authors": [
            "Kirill Trapeznikov",
            "Venkatesh Saligrama",
            "David Castanon"
        ],
        "abstract": "In many classification systems, sensing modalities have different acquisition costs. It is often {\\it unnecessary} to use every modality to classify a majority of examples. We study a multi-stage system in a prediction time cost reduction setting, where the full data is available for training, but for a test example, measurements in a new modality can be acquired at each stage for an additional cost. We seek decision rules to reduce the average measurement acquisition cost. We formulate an empirical risk minimization problem (ERM) for a multi-stage reject classifier, wherein the stage $k$ classifier either classifies a sample using only the measurements acquired so far or rejects it to the next stage where more attributes can be acquired for a cost. To solve the ERM problem, we show that the optimal reject classifier at each stage is a combination of two binary classifiers, one biased towards positive examples and the other biased towards negative examples. We use this parameterization to construct stage-by-stage global surrogate risk, develop an iterative algorithm in the boosting framework and present convergence and generalization results. We test our work on synthetic, medical and explosives detection datasets. Our results demonstrate that substantial cost reduction without a significant sacrifice in accuracy is achievable.\n    ",
        "submission_date": "2012-05-20T00:00:00",
        "last_modified_date": "2013-01-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1205.4450",
        "title": "Spectral Graph Cut from a Filtering Point of View",
        "authors": [
            "Chengxi Ye",
            "Yuxu Lin",
            "Mingli Song",
            "Chun Chen",
            "David W. Jacobs"
        ],
        "abstract": "Spectral graph theory is well known and widely used in computer vision. In this paper, we analyze image segmentation algorithms that are based on spectral graph theory, e.g., normalized cut, and show that there is a natural connection between spectural graph theory based image segmentationand and edge preserving filtering. Based on this connection we show that the normalized cut algorithm is equivalent to repeated iterations of bilateral filtering. Then, using this equivalence we present and implement a fast normalized cut algorithm for image segmentation. Experiments show that our implementation can solve the original optimization problem in the normalized cut algorithm 10 to 100 times faster. Furthermore, we present a new algorithm called conditioned normalized cut for image segmentation that can easily incorporate color image patches and demonstrate how this segmentation problem can be solved with edge preserving filtering.\n    ",
        "submission_date": "2012-05-20T00:00:00",
        "last_modified_date": "2016-11-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1205.4463",
        "title": "Pilgrims Face Recognition Dataset -- HUFRD",
        "authors": [
            "Salah A. Aly"
        ],
        "abstract": "In this work, we define a new pilgrims face recognition dataset, called HUFRD dataset. The new developed dataset presents various pilgrims' images taken from outside the Holy Masjid El-Harram in Makkah during the 2011-2012 Hajj and Umrah seasons. Such dataset will be used to test our developed facial recognition and detection algorithms, as well as assess in the missing and found recognition system \\cite{crowdsensing}.\n    ",
        "submission_date": "2012-05-20T00:00:00",
        "last_modified_date": "2012-12-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1205.4831",
        "title": "Gray Level Co-Occurrence Matrices: Generalisation and Some New Features",
        "authors": [
            "Bino Sebastian V",
            "A. Unnikrishnan",
            "Kannan Balakrishnan"
        ],
        "abstract": "Gray Level Co-occurrence Matrices (GLCM) are one of the earliest techniques used for image texture analysis. In this paper we defined a new feature called trace extracted from the GLCM and its implications in texture analysis are discussed in the context of Content Based Image Retrieval (CBIR). The theoretical extension of GLCM to n-dimensional gray scale images are also discussed. The results indicate that trace features outperform Haralick features when applied to CBIR.\n    ",
        "submission_date": "2012-05-22T00:00:00",
        "last_modified_date": "2012-05-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1205.5097",
        "title": "Neural Network Approach for Eye Detection",
        "authors": [
            "Vijayalaxmi",
            "P. Sudhakara Rao",
            "S. Sreehari"
        ],
        "abstract": "Driving support systems, such as car navigation systems are becoming common and they support driver in several aspects. Non-intrusive method of detecting Fatigue and drowsiness based on eye-blink count and eye directed instruction controlhelps the driver to prevent from collision caused by drowsy driving. Eye detection and tracking under various conditions such as illumination, background, face alignment and facial expression makes the problem ",
        "submission_date": "2012-05-23T00:00:00",
        "last_modified_date": "2012-05-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1205.5351",
        "title": "Linearized Alternating Direction Method with Adaptive Penalty and Warm Starts for Fast Solving Transform Invariant Low-Rank Textures",
        "authors": [
            "Xiang Ren",
            "Zhouchen Lin"
        ],
        "abstract": "Transform Invariant Low-rank Textures (TILT) is a novel and powerful tool that can effectively rectify a rich class of low-rank textures in 3D scenes from 2D images despite significant deformation and corruption. The existing algorithm for solving TILT is based on the alternating direction method (ADM). It suffers from high computational cost and is not theoretically guaranteed to converge to a correct solution. In this paper, we propose a novel algorithm to speed up solving TILT, with guaranteed convergence. Our method is based on the recently proposed linearized alternating direction method with adaptive penalty (LADMAP). To further reduce computation, warm starts are also introduced to initialize the variables better and cut the cost on singular value decomposition. Extensive experimental results on both synthetic and real data demonstrate that this new algorithm works much more efficiently and robustly than the existing algorithm. It could be at least five times faster than the previous method.\n    ",
        "submission_date": "2012-05-24T00:00:00",
        "last_modified_date": "2013-01-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1205.5425",
        "title": "Locally Orderless Registration",
        "authors": [
            "Sune Darkner",
            "Jon Sporring"
        ],
        "abstract": "Image registration is an important tool for medical image analysis and is used to bring images into the same reference frame by warping the coordinate field of one image, such that some similarity measure is minimized. We study similarity in image registration in the context of Locally Orderless Images (LOI), which is the natural way to study density estimates and reveals the 3 fundamental scales: the measurement scale, the intensity scale, and the integration scale.\n",
        "submission_date": "2012-05-24T00:00:00",
        "last_modified_date": "2012-05-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1205.6352",
        "title": "Generalized sequential tree-reweighted message passing",
        "authors": [
            "Vladimir Kolmogorov",
            "Thomas Schoenemann"
        ],
        "abstract": "This paper addresses the problem of approximate MAP-MRF inference in general graphical models. Following [36], we consider a family of linear programming relaxations of the problem where each relaxation is specified by a set of nested pairs of factors for which the marginalization constraint needs to be enforced. We develop a generalization of the TRW-S algorithm [9] for this problem, where we use a decomposition into junction chains, monotonic w.r.t. some ordering on the nodes. This generalizes the monotonic chains in [9] in a natural way. We also show how to deal with nested factors in an efficient way. Experiments show an improvement over min-sum diffusion, MPLP and subgradient ascent algorithms on a number of computer vision and natural language processing problems.\n    ",
        "submission_date": "2012-05-29T00:00:00",
        "last_modified_date": "2012-09-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1205.6391",
        "title": "A Brief Summary of Dictionary Learning Based Approach for Classification",
        "authors": [
            "Kong Shu",
            "Wang Donghui"
        ],
        "abstract": "This note presents some representative methods which are based on dictionary learning (DL) for classification. We do not review the sophisticated methods or frameworks that involve DL for classification, such as online DL and spatial pyramid matching (SPM), but rather, we concentrate on the direct DL-based classification methods. Here, the \"so-called direct DL-based method\" is the approach directly deals with DL framework by adding some meaningful penalty terms. By listing some representative methods, we can roughly divide them into two categories, i.e. (1) directly making the dictionary discriminative and (2) forcing the sparse coefficients discriminative to push the discrimination power of the dictionary. From this taxonomy, we can expect some extensions of them as future researches.\n    ",
        "submission_date": "2012-05-29T00:00:00",
        "last_modified_date": "2012-05-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1205.6544",
        "title": "A Brief Summary of Dictionary Learning Based Approach for Classification (revised)",
        "authors": [
            "Shu Kong",
            "Donghui Wang"
        ],
        "abstract": "This note presents some representative methods which are based on dictionary learning (DL) for classification. We do not review the sophisticated methods or frameworks that involve DL for classification, such as online DL and spatial pyramid matching (SPM), but rather, we concentrate on the direct DL-based classification methods. Here, the \"so-called direct DL-based method\" is the approach directly deals with DL framework by adding some meaningful penalty terms. By listing some representative methods, we can roughly divide them into two categories, i.e. (1) directly making the dictionary discriminative and (2) forcing the sparse coefficients discriminative to push the discrimination power of the dictionary. From this taxonomy, we can expect some extensions of them as future researches.\n    ",
        "submission_date": "2012-05-30T00:00:00",
        "last_modified_date": "2012-05-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1205.6572",
        "title": "An Unsupervised Dynamic Image Segmentation using Fuzzy Hopfield Neural Network based Genetic Algorithm",
        "authors": [
            "Amiya Halder",
            "Soumajit Pramanik"
        ],
        "abstract": "This paper proposes a Genetic Algorithm based segmentation method that can automatically segment gray-scale images. The proposed method mainly consists of spatial unsupervised grayscale image segmentation that divides an image into regions. The aim of this algorithm is to produce precise segmentation of images using intensity information along with neighborhood relationships. In this paper, Fuzzy Hopfield Neural Network (FHNN) clustering helps in generating the population of Genetic algorithm which there by automatically segments the image. This technique is a powerful method for image segmentation and works for both single and multiple-feature data with spatial information. Validity index has been utilized for introducing a robust technique for finding the optimum number of components in an image. Experimental results shown that the algorithm generates good quality segmented image.\n    ",
        "submission_date": "2012-05-30T00:00:00",
        "last_modified_date": "2012-05-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1205.6605",
        "title": "Template-Cut: A Pattern-Based Segmentation Paradigm",
        "authors": [
            "Jan Egger",
            "Bernd Freisleben",
            "Christopher Nimsky",
            "Tina Kapur"
        ],
        "abstract": "We present a scale-invariant, template-based segmentation paradigm that sets up a graph and performs a graph cut to separate an object from the background. Typically graph-based schemes distribute the nodes of the graph uniformly and equidistantly on the image, and use a regularizer to bias the cut towards a particular shape. The strategy of uniform and equidistant nodes does not allow the cut to prefer more complex structures, especially when areas of the object are indistinguishable from the background. We propose a solution by introducing the concept of a \"template shape\" of the target object in which the nodes are sampled non-uniformly and non-equidistantly on the image. We evaluate it on 2D-images where the object's textures and backgrounds are similar, and large areas of the object have the same gray level appearance as the background. We also evaluate it in 3D on 60 brain tumor datasets for neurosurgical planning purposes.\n    ",
        "submission_date": "2012-05-30T00:00:00",
        "last_modified_date": "2012-05-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1205.6745",
        "title": "Fingerprint Gender Classification using Wavelet Transform and Singular Value Decomposition",
        "authors": [
            "P Gnanasivam",
            "Dr. S Muttan"
        ],
        "abstract": "A novel method of gender Classification from fingerprint is proposed based on discrete wavelet transform (DWT) and singular value decomposition (SVD). The classification is achieved by extracting the energy computed from all the sub-bands of DWT combined with the spatial features of non-zero singular values obtained from the SVD of fingerprint images. K nearest neighbor (KNN) used as a classifier. This method is experimented with the internal database of 3570 fingerprints finger prints in which 1980 were male fingerprints and 1590 were female fingerprints. Finger-wise gender classification is achieved which is 94.32% for the left hand little fingers of female persons and 95.46% for the left hand index finger of male persons. Gender classification for any finger of male persons tested is attained as 91.67% and 84.69% for female persons respectively. Overall classification rate is 88.28% has been achieved.\n    ",
        "submission_date": "2012-05-30T00:00:00",
        "last_modified_date": "2012-05-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1206.0238",
        "title": "Rapid Feature Extraction for Optical Character Recognition",
        "authors": [
            "M. Zahid Hossain",
            "M. Ashraful Amin",
            "Hong Yan"
        ],
        "abstract": "Feature extraction is one of the fundamental problems of character recognition. The performance of character recognition system is depends on proper feature extraction and correct classifier selection. In this article, a rapid feature extraction method is proposed and named as Celled Projection (CP) that compute the projection of each section formed through partitioning an image. The recognition performance of the proposed method is compared with other widely used feature extraction methods that are intensively studied for many different scripts in literature. The experiments have been conducted using Bangla handwritten numerals along with three different well known classifiers which demonstrate comparable results including 94.12% recognition accuracy using celled projection.\n    ",
        "submission_date": "2012-06-01T00:00:00",
        "last_modified_date": "2012-06-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1206.0285",
        "title": "Image Filtering using All Neighbor Directional Weighted Pixels: Optimization using Particle Swarm Optimization",
        "authors": [
            "J. K. Mandal",
            "Somnath Mukhopadhyay"
        ],
        "abstract": "In this paper a novel approach for de noising images corrupted by random valued impulses has been proposed. Noise suppression is done in two steps. The detection of noisy pixels is done using all neighbor directional weighted pixels (ANDWP) in the 5 x 5 window. The filtering scheme is based on minimum variance of the four directional pixels. In this approach, relatively recent category of stochastic global optimization technique i.e., particle swarm optimization (PSO) has also been used for searching the parameters of detection and filtering operators required for optimal performance. Results obtained shows better de noising and preservation of fine details for highly corrupted images.\n    ",
        "submission_date": "2012-02-19T00:00:00",
        "last_modified_date": "2012-02-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1206.0338",
        "title": "Poisson noise reduction with non-local PCA",
        "authors": [
            "Joseph Salmon",
            "Zachary Harmany",
            "Charles-Alban Deledalle",
            "Rebecca Willett"
        ],
        "abstract": "Photon-limited imaging arises when the number of photons collected by a sensor array is small relative to the number of detector elements. Photon limitations are an important concern for many applications such as spectral imaging, night vision, nuclear medicine, and astronomy. Typically a Poisson distribution is used to model these observations, and the inherent heteroscedasticity of the data combined with standard noise removal methods yields significant artifacts. This paper introduces a novel denoising algorithm for photon-limited images which combines elements of dictionary learning and sparse patch-based representations of images. The method employs both an adaptation of Principal Component Analysis (PCA) for Poisson noise and recently developed sparsity-regularized convex optimization algorithms for photon-limited images. A comprehensive empirical evaluation of the proposed method helps characterize the performance of this approach relative to other state-of-the-art denoising methods. The results reveal that, despite its conceptual simplicity, Poisson PCA-based denoising appears to be highly competitive in very low light regimes.\n    ",
        "submission_date": "2012-06-02T00:00:00",
        "last_modified_date": "2014-04-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1206.1515",
        "title": "Optimizing Face Recognition Using PCA",
        "authors": [
            "Manal Abdullah",
            "Majda Wazzan",
            "Sahar Bo-saeed"
        ],
        "abstract": "Principle Component Analysis PCA is a classical feature extraction and data representation technique widely used in pattern recognition. It is one of the most successful techniques in face recognition. But it has drawback of high computational especially for big size database. This paper conducts a study to optimize the time complexity of PCA (eigenfaces) that does not affects the recognition performance. The authors minimize the participated eigenvectors which consequently decreases the computational time. A comparison is done to compare the differences between the recognition time in the original algorithm and in the enhanced algorithm. The performance of the original and the enhanced proposed algorithm is tested on face94 face database. Experimental results show that the recognition time is reduced by 35% by applying our proposed enhanced algorithm. DET Curves are used to illustrate the experimental results.\n    ",
        "submission_date": "2012-06-07T00:00:00",
        "last_modified_date": "2012-06-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1206.1518",
        "title": "Off-Line Arabic Handwriting Character Recognition Using Word Segmentation",
        "authors": [
            "Manal A. Abdullah",
            "Lulwah M. Al-Harigy",
            "Hanadi H. Al-Fraidi"
        ],
        "abstract": "The ultimate aim of handwriting recognition is to make computers able to read and/or authenticate human written texts, with a performance comparable to or even better than that of humans. Reading means that the computer is given a piece of handwriting and it provides the electronic transcription of that (e.g. in ASCII format). Two types of handwriting: on-line and offline. The most important purpose of off-line handwriting recognition is in protection systems and authentication. Arabic Handwriting scripts are much more complicated in comparison to Latin scripts. This paper introduces a simple and novel methodology to authenticate Arabic handwriting characters. Reaching our aim, we built our own character database. The research methodology depends on two stages: The first is character extraction where preprocessing the word and then apply segmentation process to obtain the character. The second is the character recognition by matching the characters comprising the word with the letters in the database. Our results ensure character recognition with 81%. We eliminate FAR by using similarity percent between 45-55%. Our research is coded using MATLAB.\n    ",
        "submission_date": "2012-06-07T00:00:00",
        "last_modified_date": "2012-06-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1206.1552",
        "title": "Performance Analysis of Unsymmetrical trimmed median as detector on image noises and its Fpga implementation",
        "authors": [
            "K. Vasanth",
            "V. Jawahar Senthil Kumar"
        ],
        "abstract": "This Paper Analyze the performance of Unsymmetrical trimmed median, which is used as detector for the detection of impulse noise, Gaussian noise and mixed noise is proposed. The proposed algorithm uses a fixed 3x3 window for the increasing noise densities. The pixels in the current window are arranged in sorting order using a improved snake like sorting algorithm with reduced comparator. The processed pixel is checked for the occurrence of outliers, if the absolute difference between processed pixels is greater than fixed threshold. Under high noise densities the processed pixel is also noisy hence the median is checked using the above procedure. if found true then the pixel is considered as noisy hence the corrupted pixel is replaced by the median of the current processing window. If median is also noisy then replace the corrupted pixel with unsymmetrical trimmed median else if the pixel is termed uncorrupted and left unaltered. The proposed algorithm (PA) is tested on varying detail images for various noises. The proposed algorithm effectively removes the high density fixed value impulse noise, low density random valued impulse noise, low density Gaussian noise and lower proportion of mixed noise. The proposed algorithm is targeted on Xc3e5000-5fg900 FPGA using Xilinx 7.1 compiler version which requires less number of slices, optimum speed and low power when compared to the other median finding architectures.\n    ",
        "submission_date": "2012-06-07T00:00:00",
        "last_modified_date": "2012-06-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1206.2058",
        "title": "Dimension Reduction by Mutual Information Discriminant Analysis",
        "authors": [
            "Ali Shadvar"
        ],
        "abstract": "In the past few decades, researchers have proposed many discriminant analysis (DA) algorithms for the study of high-dimensional data in a variety of problems. Most DA algorithms for feature extraction are based on transformations that simultaneously maximize the between-class scatter and minimize the withinclass scatter matrices. This paper presents a novel DA algorithm for feature extraction using mutual information (MI). However, it is not always easy to obtain an accurate estimation for high-dimensional MI. In this paper, we propose an efficient method for feature extraction that is based on one-dimensional MI estimations. We will refer to this algorithm as mutual information discriminant analysis (MIDA). The performance of this proposed method was evaluated using UCI databases. The results indicate that MIDA provides robust performance over different data sets with different characteristics and that MIDA always performs better than, or at least comparable to, the best performing algorithms.\n    ",
        "submission_date": "2012-06-10T00:00:00",
        "last_modified_date": "2012-06-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1206.2068",
        "title": "Revolvable Indoor Panoramas Using a Rectified Azimuthal Projection",
        "authors": [
            "Chamberlain Fong"
        ],
        "abstract": "We present an algorithm for converting an indoor spherical panorama into a photograph with a simulated overhead view. The resulting image will have an extremely wide field of view covering up to 4{\\pi} steradians of the spherical panorama. We argue that our method complements the stereographic projection commonly used in the \"little planet\" effect. The stereographic projection works well in creating little planets of outdoor scenes; whereas our method is a well-suited counterpart for indoor scenes. The main innovation of our method is the introduction of a novel azimuthal map projection that can smoothly blend between the stereographic projection and the Lambert azimuthal equal-area projection. Our projection has an adjustable parameter that allows one to control and compromise between distortions in shape and distortions in size within the projected panorama. This extra control parameter gives our projection the ability to produce superior results over the stereographic projection.\n    ",
        "submission_date": "2012-06-10T00:00:00",
        "last_modified_date": "2016-05-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1206.2437",
        "title": "A Novel Windowing Technique for Efficient Computation of MFCC for Speaker Recognition",
        "authors": [
            "Md. Sahidullah",
            "Goutam Saha"
        ],
        "abstract": "In this paper, we propose a novel family of windowing technique to compute Mel Frequency Cepstral Coefficient (MFCC) for automatic speaker recognition from speech. The proposed method is based on fundamental property of discrete time Fourier transform (DTFT) related to differentiation in frequency domain. Classical windowing scheme such as Hamming window is modified to obtain derivatives of discrete time Fourier transform coefficients. It has been mathematically shown that the slope and phase of power spectrum are inherently incorporated in newly computed cepstrum. Speaker recognition systems based on our proposed family of window functions are shown to attain substantial and consistent performance improvement over baseline single tapered Hamming window as well as recently proposed multitaper windowing technique.\n    ",
        "submission_date": "2012-06-12T00:00:00",
        "last_modified_date": "2012-06-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1206.2627",
        "title": "Image Similarity Using Sparse Representation and Compression Distance",
        "authors": [
            "Tanaya Guha",
            "Rabab K. Ward"
        ],
        "abstract": "A new line of research uses compression methods to measure the similarity between signals. Two signals are considered similar if one can be compressed significantly when the information of the other is known. The existing compression-based similarity methods, although successful in the discrete one dimensional domain, do not work well in the context of images. This paper proposes a sparse representation-based approach to encode the information content of an image using information from the other image, and uses the compactness (sparsity) of the representation as a measure of its compressibility (how much can the image be compressed) with respect to the other image. The more sparse the representation of an image, the better it can be compressed and the more it is similar to the other image. The efficacy of the proposed measure is demonstrated through the high accuracies achieved in image clustering, retrieval and classification.\n    ",
        "submission_date": "2012-06-12T00:00:00",
        "last_modified_date": "2013-05-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1206.2807",
        "title": "An efficient hierarchical graph based image segmentation",
        "authors": [
            "Silvio Jamil F. Guimar\u00e3es",
            "Jean Cousty",
            "Yukiko Kenmochi",
            "Laurent Najman"
        ],
        "abstract": "Hierarchical image segmentation provides region-oriented scalespace, i.e., a set of image segmentations at different detail levels in which the segmentations at finer levels are nested with respect to those at coarser levels. Most image segmentation algorithms, such as region merging algorithms, rely on a criterion for merging that does not lead to a hierarchy, and for which the tuning of the parameters can be difficult. In this work, we propose a hierarchical graph based image segmentation relying on a criterion popularized by Felzenzwalb and Huttenlocher. We illustrate with both real and synthetic images, showing efficiency, ease of use, and robustness of our method.\n    ",
        "submission_date": "2012-06-13T00:00:00",
        "last_modified_date": "2012-06-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1206.3559",
        "title": "Real time facial expression recognition using a novel method",
        "authors": [
            "Saumil Srivastava"
        ],
        "abstract": "This paper discusses a novel method for Facial Expression Recognition System which performs facial expression analysis in a near real time from a live web cam feed. Primary objectives were to get results in a near real time with light invariant, person independent and pose invariant way. The system is composed of two different entities trainer and evaluator. Each frame of video feed is passed through a series of steps including haar classifiers, skin detection, feature extraction, feature points tracking, creating a learned Support Vector Machine model to classify emotions to achieve a tradeoff between accuracy and result rate. A processing time of 100-120 ms per 10 frames was achieved with accuracy of around 60%. We measure our accuracy in terms of variety of interaction and classification scenarios. We conclude by discussing relevance of our work to human computer interaction and exploring further measures that can be taken.\n    ",
        "submission_date": "2012-05-08T00:00:00",
        "last_modified_date": "2012-05-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1206.3594",
        "title": "Blind PSF estimation and methods of deconvolution optimization",
        "authors": [
            "Yu.A.Bunyak",
            "O.Yu.Sofina",
            "R.N.Kvetnyy"
        ],
        "abstract": "We have shown that the left side null space of the autoregression (AR) matrix operator is the lexicographical presentation of the point spread function (PSF) on condition the AR parameters are common for original and blurred images. The method of inverse PSF evaluation with regularization functional as the function of surface area is offered. The inverse PSF was used for primary image estimation. Two methods of original image estimate optimization were designed basing on maximum entropy generalization of sought and blurred images conditional probability density and regularization. The first method uses balanced variations of convolution and deconvolution transforms to obtaining iterative schema of image optimization. The variations balance was defined by dynamic regularization basing on condition of iteration process convergence. The regularization has dynamic character because depends on current and previous image estimate variations. The second method implements the regularization of deconvolution optimization in curved space with metric defined on image estimate surface. It is basing on target functional invariance to fluctuations of optimal argument value. The given iterative schemas have faster convergence in comparison with known ones, so they can be used for reconstruction of high resolution images series in real time.\n    ",
        "submission_date": "2012-06-15T00:00:00",
        "last_modified_date": "2012-06-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1206.3633",
        "title": "Feature Based Fuzzy Rule Base Design for Image Extraction",
        "authors": [
            "Koushik Mondal",
            "Paramartha Dutta",
            "Siddhartha Bhattacharyya"
        ],
        "abstract": "In the recent advancement of multimedia technologies, it becomes a major concern of detecting visual attention regions in the field of image processing. The popularity of the terminal devices in a heterogeneous environment of the multimedia technology gives us enough scope for the betterment of image visualization. Although there exist numerous methods, feature based image extraction becomes a popular one in the field of image processing. The objective of image segmentation is the domain-independent partition of the image into a set of regions, which are visually distinct and uniform with respect to some property, such as grey level, texture or colour. Segmentation and subsequent extraction can be considered the first step and key issue in object recognition, scene understanding and image analysis. Its application area encompasses mobile devices, industrial quality control, medical appliances, robot navigation, geophysical exploration, military applications, etc. In all these areas, the quality of the final results depends largely on the quality of the preprocessing work. Most of the times, acquiring spurious-free preprocessing data requires a lot of application cum mathematical intensive background works. We propose a feature based fuzzy rule guided novel technique that is functionally devoid of any external intervention during execution. Experimental results suggest that this approach is an efficient one in comparison to different other techniques extensively addressed in literature. In order to justify the supremacy of performance of our proposed technique in respect of its competitors, we take recourse to effective metrics like Mean Squared Error (MSE), Mean Absolute Error (MAE) and Peak Signal to Noise Ratio (PSNR).\n    ",
        "submission_date": "2012-06-16T00:00:00",
        "last_modified_date": "2012-06-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1206.3714",
        "title": "How important are Deformable Parts in the Deformable Parts Model?",
        "authors": [
            "Santosh K. Divvala",
            "Alexei A. Efros",
            "Martial Hebert"
        ],
        "abstract": "The main stated contribution of the Deformable Parts Model (DPM) detector of Felzenszwalb et al. (over the Histogram-of-Oriented-Gradients approach of Dalal and Triggs) is the use of deformable parts. A secondary contribution is the latent discriminative learning. Tertiary is the use of multiple components. A common belief in the vision community (including ours, before this study) is that their ordering of contributions reflects the performance of detector in practice. However, what we have experimentally found is that the ordering of importance might actually be the reverse. First, we show that by increasing the number of components, and switching the initialization step from their aspect-ratio, left-right flipping heuristics to appearance-based clustering, considerable improvement in performance is obtained. But more intriguingly, we show that with these new components, the part deformations can now be completely switched off, yet obtaining results that are almost on par with the original DPM detector. Finally, we also show initial results for using multiple components on a different problem -- scene classification, suggesting that this idea might have wider applications in addition to object detection.\n    ",
        "submission_date": "2012-06-16T00:00:00",
        "last_modified_date": "2012-06-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1206.4042",
        "title": "The Stability of Convergence of Curve Evolutions in Vector Fields",
        "authors": [
            "Junyan Wang",
            "Kap Luk Chan"
        ],
        "abstract": "Curve evolution is often used to solve computer vision problems. If the curve evolution fails to converge, we would not be able to solve the targeted problem in a lifetime. This paper studies the theoretical aspect of the convergence of a type of general curve evolutions. We establish a theory for analyzing and improving the stability of the convergence of the general curve evolutions. Based on this theory, we ascertain that the convergence of a known curve evolution is marginal stable. We propose a way of modifying the original curve evolution equation to improve the stability of the convergence according to our theory. Numerical experiments show that the modification improves the convergence of the curve evolution, which validates our theory.\n    ",
        "submission_date": "2012-06-17T00:00:00",
        "last_modified_date": "2012-06-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1206.4391",
        "title": "Gray Image extraction using Fuzzy Logic",
        "authors": [
            "Koushik Mondal",
            "Paramartha Dutta",
            "Siddhartha Bhattacharyya"
        ],
        "abstract": "Fuzzy systems concern fundamental methodology to represent and process uncertainty and imprecision in the linguistic information. The fuzzy systems that use fuzzy rules to represent the domain knowledge of the problem are known as Fuzzy Rule Base Systems (FRBS). On the other hand image segmentation and subsequent extraction from a noise-affected background, with the help of various soft computing methods, are relatively new and quite popular due to various reasons. These methods include various Artificial Neural Network (ANN) models (primarily supervised in nature), Genetic Algorithm (GA) based techniques, intensity histogram based methods etc. providing an extraction solution working in unsupervised mode happens to be even more interesting problem. Literature suggests that effort in this respect appears to be quite rudimentary. In the present article, we propose a fuzzy rule guided novel technique that is functional devoid of any external intervention during execution. Experimental results suggest that this approach is an efficient one in comparison to different other techniques extensively addressed in literature. In order to justify the supremacy of performance of our proposed technique in respect of its competitors, we take recourse to effective metrics like Mean Squared Error (MSE), Mean Absolute Error (MAE), Peak Signal to Noise Ratio (PSNR).\n    ",
        "submission_date": "2012-06-20T00:00:00",
        "last_modified_date": "2012-06-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1206.4609",
        "title": "On multi-view feature learning",
        "authors": [
            "Roland Memisevic"
        ],
        "abstract": "Sparse coding is a common approach to learning local features for object recognition. Recently, there has been an increasing interest in learning features from spatio-temporal, binocular, or other multi-observation data, where the goal is to encode the relationship between images rather than the content of a single image. We provide an analysis of multi-view feature learning, which shows that hidden variables encode transformations by detecting rotation angles in the eigenspaces shared among multiple image warps. Our analysis helps explain recent experimental results showing that transformation-specific features emerge when training complex cell models on videos. Our analysis also shows that transformation-invariant features can emerge as a by-product of learning representations of transformations.\n    ",
        "submission_date": "2012-06-18T00:00:00",
        "last_modified_date": "2012-06-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1206.4866",
        "title": "Portraits of Julius Caesar: a proposal for 3D analysis",
        "authors": [
            "Amelia Carolina Sparavigna"
        ],
        "abstract": "Here I suggest the use of a 3D scanning and rendering to create some virtual copies of ancient artifacts to study and compare them. In particular, this approach could be interesting for some roman marble busts, two of which are portraits of Julius Caesar, and the third is a realistic portrait of a man recently found at Arles, France. The comparison of some images indicates that a three-dimensional visualization is necessary.\n    ",
        "submission_date": "2012-06-21T00:00:00",
        "last_modified_date": "2012-06-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1206.4880",
        "title": "Dynamic Domain Classification for Fractal Image Compression",
        "authors": [
            "K. Revathy",
            "M. Jayamohan"
        ],
        "abstract": "Fractal image compression is attractive except for its high encoding time requirements. The image is encoded as a set of contractive affine transformations. The image is partitioned into non-overlapping range blocks, and a best matching domain block larger than the range block is identified. There are many attempts on improving the encoding time by reducing the size of search pool for range-domain matching. But these methods are attempting to prepare a static domain pool that remains unchanged throughout the encoding process. This paper proposes dynamic preparation of separate domain pool for each range block. This will result in significant reduction in the encoding time. The domain pool for a particular range block can be selected based upon a parametric value. Here we use classification based on local fractal dimension.\n    ",
        "submission_date": "2012-05-20T00:00:00",
        "last_modified_date": "2012-05-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1206.5065",
        "title": "A generic framework for video understanding applied to group behavior recognition",
        "authors": [
            "Sofia Zaidenberg",
            "Bernard Boulay",
            "Fran\u00e7ois Bremond"
        ],
        "abstract": "This paper presents an approach to detect and track groups of people in video-surveillance applications, and to automatically recognize their behavior. This method keeps track of individuals moving together by maintaining a spacial and temporal group coherence. First, people are individually detected and tracked. Second, their trajectories are analyzed over a temporal window and clustered using the Mean-Shift algorithm. A coherence value describes how well a set of people can be described as a group. Furthermore, we propose a formal event description language. The group events recognition approach is successfully validated on 4 camera views from 3 datasets: an airport, a subway, a shopping center corridor and an entrance hall.\n    ",
        "submission_date": "2012-06-22T00:00:00",
        "last_modified_date": "2012-06-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1206.5157",
        "title": "Leaf vein segmentation using Odd Gabor filters and morphological operations",
        "authors": [
            "Vini Katyal",
            "Aviral"
        ],
        "abstract": "Leaf vein forms the basis of leaf characterization and classification. Different species have different leaf vein patterns. It is seen that leaf vein segmentation will help in maintaining a record of all the leaves according to their specific pattern of veins thus provide an effective way to retrieve and store information regarding various plant species in database as well as provide an effective means to characterize plants on the basis of leaf vein structure which is unique for every species. The algorithm proposes a new way of segmentation of leaf veins with the use of Odd Gabor filters and the use of morphological operations for producing a better output. The Odd Gabor filter gives an efficient output and is robust and scalable as compared with the existing techniques as it detects the fine fiber like veins present in leaves much more efficiently.\n    ",
        "submission_date": "2012-06-22T00:00:00",
        "last_modified_date": "2012-06-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1206.6437",
        "title": "Large Scale Variational Bayesian Inference for Structured Scale Mixture Models",
        "authors": [
            "Young Jun Ko",
            "Matthias Seeger"
        ],
        "abstract": "Natural image statistics exhibit hierarchical dependencies across multiple scales. Representing such prior knowledge in non-factorial latent tree models can boost performance of image denoising, inpainting, deconvolution or reconstruction substantially, beyond standard factorial \"sparse\" methodology. We derive a large scale approximate Bayesian inference algorithm for linear models with non-factorial (latent tree-structured) scale mixture priors. Experimental results on a range of denoising and inpainting problems demonstrate substantially improved performance compared to MAP estimation or to inference with factorial priors.\n    ",
        "submission_date": "2012-06-27T00:00:00",
        "last_modified_date": "2012-06-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1206.6445",
        "title": "Deep Lambertian Networks",
        "authors": [
            "Yichuan Tang",
            "Ruslan Salakhutdinov",
            "Geoffrey Hinton"
        ],
        "abstract": "Visual perception is a challenging problem in part due to illumination variations. A possible solution is to first estimate an illumination invariant representation before using it for recognition. The object albedo and surface normals are examples of such representations. In this paper, we introduce a multilayer generative model where the latent variables include the albedo, surface normals, and the light source. Combining Deep Belief Nets with the Lambertian reflectance assumption, our model can learn good priors over the albedo from 2D images. Illumination variations can be explained by changing only the lighting latent variable in our model. By transferring learned knowledge from similar objects, albedo and surface normals estimation from a single image is possible in our model. Experiments demonstrate that our model is able to generalize as well as improve over standard baselines in one-shot face recognition.\n    ",
        "submission_date": "2012-06-27T00:00:00",
        "last_modified_date": "2012-06-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1206.6482",
        "title": "Modeling Images using Transformed Indian Buffet Processes",
        "authors": [
            "Ke Zhai",
            "Yuening Hu",
            "Sinead Williamson",
            "Jordan Boyd-Graber"
        ],
        "abstract": "Latent feature models are attractive for image modeling, since images generally contain multiple objects. However, many latent feature models ignore that objects can appear at different locations or require pre-segmentation of images. While the transformed Indian buffet process (tIBP) provides a method for modeling transformation-invariant features in unsegmented binary images, its current form is inappropriate for real images because of its computational cost and modeling assumptions. We combine the tIBP with likelihoods appropriate for real images and develop an efficient inference, using the cross-correlation between images and features, that is theoretically and empirically faster than existing inference techniques. Our method discovers reasonable components and achieve effective image reconstruction in natural images.\n    ",
        "submission_date": "2012-06-27T00:00:00",
        "last_modified_date": "2012-06-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1206.6514",
        "title": "Investigation of Color Constancy for Ubiquitous Wireless LAN/Camera Positioning: An Initial Outcome",
        "authors": [
            "Wan Mohd Yaakob Wan Bejuri",
            "Mohd Murtadha Mohamad",
            "Maimunah Sapri",
            "Mohd Adly Rosly"
        ],
        "abstract": "This paper present our color constancy investigation in the hybridization of Wireless LAN and Camera positioning in the mobile phone. Five typical color constancy schemes are analyzed in different location environment. The results can be used to combine with RF signals from Wireless LAN positioning by using model fitting approach in order to establish absolute positioning output. There is no conventional searching algorithm required, thus it is expected to reduce the complexity of computation. Finally we present our preliminary results to illustrate the indoor positioning algorithm performance evaluation for an indoor environment set-up.\n    ",
        "submission_date": "2012-06-27T00:00:00",
        "last_modified_date": "2012-06-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1206.6872",
        "title": "A Self-Supervised Terrain Roughness Estimator for Off-Road Autonomous Driving",
        "authors": [
            "David Stavens",
            "Sebastian Thrun"
        ],
        "abstract": "We present a machine learning approach for estimating the second derivative of a drivable surface, its roughness. Robot perception generally focuses on the first derivative, obstacle detection. However, the second derivative is also important due to its direct relation (with speed) to the shock the vehicle experiences. Knowing the second derivative allows a vehicle to slow down in advance of rough terrain. Estimating the second derivative is challenging due to uncertainty. For example, at range, laser readings may be so sparse that significant information about the surface is missing. Also, a high degree of precision is required in projecting laser readings. This precision may be unavailable due to latency or error in the pose estimation. We model these sources of error as a multivariate polynomial. Its coefficients are learned using the shock data as ground truth -- the accelerometers are used to train the lasers. The resulting classifier operates on individual laser readings from a road surface described by a 3D point cloud. The classifier identifies sections of road where the second derivative is likely to be large. Thus, the vehicle can slow down in advance, reducing the shock it experiences. The algorithm is an evolution of one we used in the 2005 DARPA Grand Challenge. We analyze it using data from that route.\n    ",
        "submission_date": "2012-06-27T00:00:00",
        "last_modified_date": "2012-06-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1206.6878",
        "title": "Efficient Selection of Disambiguating Actions for Stereo Vision",
        "authors": [
            "Monika Schaeffer",
            "Ron Parr"
        ],
        "abstract": "In many domains that involve the use of sensors, such as robotics or sensor networks, there are opportunities to use some form of active sensing to disambiguate data from noisy or unreliable sensors. These disambiguating actions typically take time and expend energy. One way to choose the next disambiguating action is to select the action with the greatest expected entropy reduction, or information gain. In this work, we consider active sensing in aid of stereo vision for robotics. Stereo vision is a powerful sensing technique for mobile robots, but it can fail in scenes that lack strong texture. In such cases, a structured light source, such as vertical laser line can be used for disambiguation. By treating the stereo matching problem as a specially structured HMM-like graphical model, we demonstrate that for a scan line with n columns and maximum stereo disparity d, the entropy minimizing aim point for the laser can be selected in O(nd) time - cost no greater than the stereo algorithm itself. In contrast, a typical HMM formulation would suggest at least O(nd^2) time for the entropy calculation alone.\n    ",
        "submission_date": "2012-06-27T00:00:00",
        "last_modified_date": "2012-06-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1207.0151",
        "title": "Differentiable Pooling for Hierarchical Feature Learning",
        "authors": [
            "Matthew D. Zeiler",
            "Rob Fergus"
        ],
        "abstract": "We introduce a parametric form of pooling, based on a Gaussian, which can be optimized alongside the features in a single global objective function. By contrast, existing pooling schemes are based on heuristics (e.g. local maximum) and have no clear link to the cost function of the model. Furthermore, the variables of the Gaussian explicitly store location information, distinct from the appearance captured by the features, thus providing a what/where decomposition of the input signal. Although the differentiable pooling scheme can be incorporated in a wide range of hierarchical models, we demonstrate it in the context of a Deconvolutional Network model (Zeiler et al. ICCV 2011). We also explore a number of secondary issues within this model and present detailed experiments on MNIST digits.\n    ",
        "submission_date": "2012-06-30T00:00:00",
        "last_modified_date": "2012-06-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1207.0805",
        "title": "Anatomical Structure Segmentation in Liver MRI Images",
        "authors": [
            "G.Geethu Lakshmi"
        ],
        "abstract": "Segmentation of medical images is a challenging task owing to their complexity. A standard segmentation problem within Magnetic Resonance Imaging (MRI) is the task of labeling voxels according to their tissue type. Image segmentation provides volumetric quantification of liver area and thus helps in the diagnosis of disorders, such as Hepatitis, Cirrhosis, Jaundice, Hemochromatosis ",
        "submission_date": "2012-07-03T00:00:00",
        "last_modified_date": "2013-03-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1207.1114",
        "title": "A Fast Projected Fixed-Point Algorithm for Large Graph Matching",
        "authors": [
            "Yao Lu",
            "Kaizhu Huang",
            "Cheng-Lin Liu"
        ],
        "abstract": "We propose a fast approximate algorithm for large graph matching. A new projected fixed-point method is defined and a new doubly stochastic projection is adopted to derive the algorithm. Previous graph matching algorithms suffer from high computational complexity and therefore do not have good scalability with respect to graph size. For matching two weighted graphs of $n$ nodes, our algorithm has time complexity only $O(n^3)$ per iteration and space complexity $O(n^2)$. In addition to its scalability, our algorithm is easy to implement, robust, and able to match undirected weighted attributed graphs of different sizes. While the convergence rate of previous iterative graph matching algorithms is unknown, our algorithm is theoretically guaranteed to converge at a linear rate. Extensive experiments on large synthetic and real graphs (more than 1,000 nodes) were conducted to evaluate the performance of various algorithms. Results show that in most cases our proposed algorithm achieves better performance than previous state-of-the-art algorithms in terms of both speed and accuracy in large graph matching. In particular, with high accuracy, our algorithm takes only a few seconds (in a PC) to match two graphs of 1,000 nodes.\n    ",
        "submission_date": "2012-07-03T00:00:00",
        "last_modified_date": "2012-08-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1207.1522",
        "title": "Multimodal similarity-preserving hashing",
        "authors": [
            "Jonathan Masci",
            "Michael M. Bronstein",
            "Alexander A. Bronstein",
            "J\u00fcrgen Schmidhuber"
        ],
        "abstract": "We introduce an efficient computational framework for hashing data belonging to multiple modalities into a single representation space where they become mutually comparable. The proposed approach is based on a novel coupled siamese neural network architecture and allows unified treatment of intra- and inter-modality similarity learning. Unlike existing cross-modality similarity learning approaches, our hashing functions are not limited to binarized linear projections and can assume arbitrarily complex forms. We show experimentally that our method significantly outperforms state-of-the-art hashing approaches on multimedia retrieval tasks.\n    ",
        "submission_date": "2012-07-06T00:00:00",
        "last_modified_date": "2012-07-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1207.1551",
        "title": "An Innovative Skin Detection Approach Using Color Based Image Retrieval Technique",
        "authors": [
            "Shervan Fekri-Ershad",
            "Mohammad Saberi",
            "Farshad Tajeripour"
        ],
        "abstract": "From The late 90th, \"Skin Detection\" becomes one of the major problems in image processing. If \"Skin Detection\" will be done in high accuracy, it can be used in many cases as face recognition, Human Tracking and etc. Until now so many methods were presented for solving this problem. In most of these methods, color space was used to extract feature vector for classifying pixels, but the most of them have not good accuracy in detecting types of skin. The proposed approach in this paper is based on \"Color based image retrieval\" (CBIR) technique. In this method, first by means of CBIR method and image tiling and considering the relation between pixel and its neighbors, a feature vector would be defined and then with using a training step, detecting the skin in the test stage. The result shows that the presenting approach, in addition to its high accuracy in detecting type of skin, has no sensitivity to illumination intensity and moving face orientation.\n    ",
        "submission_date": "2012-07-06T00:00:00",
        "last_modified_date": "2012-07-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1207.1649",
        "title": "Analysis of Multi-Scale Fractal Dimension to Classify Human Motion",
        "authors": [
            "N\u00fabia Rosa da Silva",
            "Odemir Martinez Bruno"
        ],
        "abstract": "In recent years there has been considerable interest in human action recognition. Several approaches have been developed in order to enhance the automatic video analysis. Although some developments have been achieved by the computer vision community, the properly classification of human motion is still a hard and challenging task. The objective of this study is to investigate the use of 3D multi-scale fractal dimension to recognize motion patterns in videos. In order to develop a robust strategy for human motion classification, we proposed a method where the Fourier transform is used to calculate the derivative in which all data points are deemed. Our results shown that different accuracy rates can be found for different databases. We believe that in specific applications our results are the first step to develop an automatic monitoring system, which can be applied in security systems, traffic monitoring, biology, physical therapy, cardiovascular disease among many others.\n    ",
        "submission_date": "2012-07-06T00:00:00",
        "last_modified_date": "2012-07-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1207.1765",
        "title": "Object Recognition with Multi-Scale Pyramidal Pooling Networks",
        "authors": [
            "Jonathan Masci",
            "Ueli Meier",
            "Gabriel Fricout",
            "J\u00fcrgen Schmidhuber"
        ],
        "abstract": "We present a Multi-Scale Pyramidal Pooling Network, featuring a novel pyramidal pooling layer at multiple scales and a novel encoding layer. Thanks to the former the network does not require all images of a given classification task to be of equal size. The encoding layer improves generalisation performance in comparison to similar neural network architectures, especially when training data is scarce. We evaluate and compare our system to convolutional neural networks and state-of-the-art computer vision methods on various benchmark datasets. We also present results on industrial steel defect classification, where existing architectures are not applicable because of the constraint on equally sized input images. The proposed architecture can be seen as a fully supervised hierarchical bag-of-features extension that is trained online and can be fine-tuned for any given task.\n    ",
        "submission_date": "2012-07-07T00:00:00",
        "last_modified_date": "2012-07-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1207.1922",
        "title": "Spatial And Spectral Quality Evaluation Based On Edges Regions Of Satellite Image Fusion",
        "authors": [
            "Firouz Abdullah Al-Wassai",
            "N. V. Kalyankar",
            "Ali A. Al-Zaky"
        ],
        "abstract": "The Quality of image fusion is an essential determinant of the value of processing images fusion for many applications. Spatial and spectral qualities are the two important indexes that used to evaluate the quality of any fused image. However, the jury is still out of fused image's benefits if it compared with its original images. In addition, there is a lack of measures for assessing the objective quality of the spatial resolution for the fusion methods. Therefore, an objective quality of the spatial resolution assessment for fusion images is required. Most important details of the image are in edges regions, but most standards of image estimation do not depend upon specifying the edges in the image and measuring their edges. However, they depend upon the general estimation or estimating the uniform region, so this study deals with new method proposed to estimate the spatial resolution by Contrast Statistical Analysis (CSA) depending upon calculating the contrast of the edge, non edge regions and the rate for the edges regions. Specifying the edges in the image is made by using Soble operator with different threshold values. In addition, estimating the color distortion added by image fusion based on Histogram Analysis of the edge brightness values of all RGB-color bands and Lcomponent.\n    ",
        "submission_date": "2012-07-08T00:00:00",
        "last_modified_date": "2012-07-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1207.2346",
        "title": "Cups Products in Z2-Cohomology of 3D Polyhedral Complexes",
        "authors": [
            "Rocio Gonalez-Diaz",
            "Javier Lamar",
            "Ronald Umble"
        ],
        "abstract": "Let $I=(\\mathbb{Z}^3,26,6,B)$ be a 3D digital image, let $Q(I)$ be the associated cubical complex and let $\\partial Q(I)$ be the subcomplex of $Q(I)$ whose maximal cells are the quadrangles of $Q(I)$ shared by a voxel of $B$ in the foreground -- the object under study -- and by a voxel of $\\mathbb{Z}^3\\smallsetminus B$ in the background -- the ambient space. We show how to simplify the combinatorial structure of $\\partial Q(I)$ and obtain a 3D polyhedral complex $P(I)$ homeomorphic to $\\partial Q(I)$ but with fewer cells. We introduce an algorithm that computes cup products on $H^*(P(I);\\mathbb{Z}_2)$ directly from the combinatorics. The computational method introduced here can be effectively applied to any polyhedral complex embedded in $\\mathbb{R}^3$.\n    ",
        "submission_date": "2012-07-10T00:00:00",
        "last_modified_date": "2013-07-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1207.2426",
        "title": "A Multi-Agents Architecture to Learn Vision Operators and their Parameters",
        "authors": [
            "Issam Qaffou",
            "Mohammed Sadgal",
            "Abdelaziz Elfazziki"
        ],
        "abstract": "In a vision system, every task needs that the operators to apply should be \u00ab well chosen \u00bb and their parameters should be also \u00ab well adjusted \u00bb. The diversity of operators and the multitude of their parameters constitute a big challenge for users. As it is very difficult to make the \u00ab right \u00bb choice, lack of a specific rule, many disadvantages appear and affect the computation time and especially the quality of results. In this paper we present a multi-agent architecture to learn the best operators to apply and their best parameters for a class of images. Our architecture consists of three types of agents: User Agent, Operator Agent and Parameter Agent. The User Agent determines the phases of treatment, a library of operators and the possible values of their parameters. The Operator Agent constructs all possible combinations of operators and the Parameter Agent, the core of the architecture, adjusts the parameters of each combination by treating a large number of images. Through the reinforcement learning mechanism, our architecture does not consider only the system opportunities but also the user preferences.\n    ",
        "submission_date": "2012-07-10T00:00:00",
        "last_modified_date": "2012-07-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1207.2488",
        "title": "Kernelized Supervised Dictionary Learning",
        "authors": [
            "Mehrdad J. Gangeh",
            "Ali Ghodsi",
            "Mohamed S. Kamel"
        ],
        "abstract": "In this paper, we propose supervised dictionary learning (SDL) by incorporating information on class labels into the learning of the dictionary. To this end, we propose to learn the dictionary in a space where the dependency between the signals and their corresponding labels is maximized. To maximize this dependency, the recently introduced Hilbert Schmidt independence criterion (HSIC) is used. One of the main advantages of this novel approach for SDL is that it can be easily kernelized by incorporating a kernel, particularly a data-derived kernel such as normalized compression distance, into the formulation. The learned dictionary is compact and the proposed approach is fast. We show that it outperforms other unsupervised and supervised dictionary learning approaches in the literature, using real-world data.\n    ",
        "submission_date": "2012-07-10T00:00:00",
        "last_modified_date": "2013-11-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1207.2537",
        "title": "Face Recognition Algorithms based on Transformed Shape Features",
        "authors": [
            "Sambhunath Biswas",
            "Amrita Biswas"
        ],
        "abstract": "Human face recognition is, indeed, a challenging task, especially under the illumination and pose variations. We examine in the present paper effectiveness of two simple algorithms using coiflet packet and Radon transforms to recognize human faces from some databases of still gray level images, under the environment of illumination and pose variations. Both the algorithms convert 2-D gray level training face images into their respective depth maps or physical shape which are subsequently transformed by Coiflet packet and Radon transforms to compute energy for feature extraction. Experiments show that such transformed shape features are robust to illumination and pose variations. With the features extracted, training classes are optimally separated through linear discriminant analysis (LDA), while classification for test face images is made through a k-NN classifier, based on L1 norm and Mahalanobis distance measures. Proposed algorithms are then tested on face images that differ in illumination,expression or pose separately, obtained from three databases,namely, ORL, Yale and Essex-Grimace databases. Results, so obtained, are compared with two different existing ",
        "submission_date": "2012-07-11T00:00:00",
        "last_modified_date": "2012-07-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1207.2597",
        "title": "Automated Training and Maintenance through Kinect",
        "authors": [
            "Saket Warade",
            "Jagannath Aghav",
            "Petitpierre Claude",
            "Sandeep Udayagiri"
        ],
        "abstract": "In this paper, we have worked on reducing burden on mechanic involving complex automobile maintenance activities that are performed in centralised workshops. We have presented a system prototype that combines Augmented Reality with Kinect. With the use of Kinect, very high quality sensors are available at considerably low costs, thus reducing overall expenditure for system design. The system can be operated either in Speech mode or in Gesture mode. The system can be controlled by various audio commands if user opts for Speech mode. The same controlling can also be done by using a set of Gestures in Gesture mode.\n",
        "submission_date": "2012-07-11T00:00:00",
        "last_modified_date": "2012-07-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1207.2600",
        "title": "Efficient Prediction of DNA-Binding Proteins Using Machine Learning",
        "authors": [
            "Sokyna Qatawneh",
            "Afaf Alneaimi",
            "Thamer Rawashdeh",
            "Mmohammad Muhairat",
            "Rami Qahwaji",
            "Stan Ipson"
        ],
        "abstract": "DNA-binding proteins are a class of proteins which have a specific or general affinity to DNA and include three important components: transcription factors; nucleases, and histones. DNA-binding proteins also perform important roles in many types of cellular activities. In this paper we describe machine learning systems for the prediction of DNA- binding proteins where a Support Vector Machine and a Cascade Correlation Neural Network are optimized and then compared to determine the learning algorithm that achieves the best prediction performance. The information used for classification is derived from characteristics that include overall charge, patch size and amino acids composition. In total 121 DNA- binding proteins and 238 non-binding proteins are used to build and evaluate the system. For SVM using the ANOVA Kernel with Jack-knife evaluation, an accuracy of 86.7% has been achieved with 91.1% for sensitivity and 85.3% for specificity. For CCNN optimized over the entire dataset with Jack knife evaluation we report an accuracy of 75.4%, while the values of specificity and sensitivity achieved were 72.3% and 82.6%, respectively.\n    ",
        "submission_date": "2012-07-11T00:00:00",
        "last_modified_date": "2012-07-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1207.2602",
        "title": "A Novel Approach Coloured Object Tracker with Adaptive Model and Bandwidth using Mean Shift Algorithm",
        "authors": [
            "Seyed Amir Mohammadi",
            "Mohammad Reza Mahzoun"
        ],
        "abstract": "The traditional color-based mean-shift tracking algorithm is popular among tracking methods due to its simple and efficient procedure, however, the lack of dynamism in its target model makes it unsuitable for tracking objects which have changes in their sizes and shapes. In this paper, we propose a fast novel threephase colored object tracker algorithm based on mean shift idea while utilizing adaptive model. The proposed method can improve the mentioned weaknesses of the original mean-shift algorithm. The experimental results show that the new method is feasible, robust and has acceptable speed in comparison with other algorithms.15 page,\n    ",
        "submission_date": "2012-07-11T00:00:00",
        "last_modified_date": "2021-10-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1207.2641",
        "title": "Camera identification by grouping images from database, based on shared noise patterns",
        "authors": [
            "Teun Baar",
            "Wiger van Houten",
            "Zeno Geradts"
        ],
        "abstract": "Previous research showed that camera specific noise patterns, so-called PRNU-patterns, are extracted from images and related images could be found. In this particular research the focus is on grouping images from a database, based on a shared noise pattern as an identification method for cameras. Using the method as described in this article, groups of images, created using the same camera, could be linked from a large database of images. Using MATLAB programming, relevant image noise patterns are extracted from images much quicker than common methods by the use of faster noise extraction filters and improvements to reduce the calculation costs. Relating noise patterns, with a correlation above a certain threshold value, can quickly be matched. Hereby, from a database of images, groups of relating images could be linked and the method could be used to scan a large number of images for suspect noise patterns.\n    ",
        "submission_date": "2012-07-11T00:00:00",
        "last_modified_date": "2012-07-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1207.2922",
        "title": "ROI Segmentation for Feature Extraction from Human Facial Images",
        "authors": [
            "Surbhi",
            "Vishal Arora"
        ],
        "abstract": "Human Computer Interaction (HCI) is the biggest goal of computer vision researchers. Features form the different facial images are able to provide a very deep knowledge about the activities performed by the different facial movements. In this paper we presented a technique for feature extraction from various regions of interest with the help of Skin color segmentation technique, Thresholding, knowledge based technique for face recognition.\n    ",
        "submission_date": "2012-07-12T00:00:00",
        "last_modified_date": "2012-07-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1207.3056",
        "title": "Non-Local Euclidean Medians",
        "authors": [
            "Kunal N. Chaudhury",
            "Amit Singer"
        ],
        "abstract": "In this letter, we note that the denoising performance of Non-Local Means (NLM) at large noise levels can be improved by replacing the mean by the Euclidean median. We call this new denoising algorithm the Non-Local Euclidean Medians (NLEM). At the heart of NLEM is the observation that the median is more robust to outliers than the mean. In particular, we provide a simple geometric insight that explains why NLEM performs better than NLM in the vicinity of edges, particularly at large noise levels. NLEM can be efficiently implemented using iteratively reweighted least squares, and its computational complexity is comparable to that of NLM. We provide some preliminary results to study the proposed algorithm and to compare it with NLM.\n    ",
        "submission_date": "2012-07-12T00:00:00",
        "last_modified_date": "2012-08-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1207.3071",
        "title": "Supervised Texture Classification Using a Novel Compression-Based Similarity Measure",
        "authors": [
            "Mehrdad J. Gangeh",
            "Ali Ghodsi",
            "Mohamed S. Kamel"
        ],
        "abstract": "Supervised pixel-based texture classification is usually performed in the feature space. We propose to perform this task in (dis)similarity space by introducing a new compression-based (dis)similarity measure. The proposed measure utilizes two dimensional MPEG-1 encoder, which takes into consideration the spatial locality and connectivity of pixels in the images. The proposed formulation has been carefully designed based on MPEG encoder functionality. To this end, by design, it solely uses P-frame coding to find the (dis)similarity among patches/images. We show that the proposed measure works properly on both small and large patch sizes. Experimental results show that the proposed approach significantly improves the performance of supervised pixel-based texture classification on Brodatz and outdoor images compared to other compression-based dissimilarity measures as well as approaches performed in feature space. It also improves the computation speed by about 40% compared to its rivals.\n    ",
        "submission_date": "2012-07-12T00:00:00",
        "last_modified_date": "2013-11-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1207.3127",
        "title": "Tracking Tetrahymena Pyriformis Cells using Decision Trees",
        "authors": [
            "Quan Wang",
            "Yan Ou",
            "A. Agung Julius",
            "Kim L. Boyer",
            "Min Jun Kim"
        ],
        "abstract": "Matching cells over time has long been the most difficult step in cell tracking. In this paper, we approach this problem by recasting it as a classification problem. We construct a feature set for each cell, and compute a feature difference vector between a cell in the current frame and a cell in a previous frame. Then we determine whether the two cells represent the same cell over time by training decision trees as our binary classifiers. With the output of decision trees, we are able to formulate an assignment problem for our cell association task and solve it using a modified version of the Hungarian algorithm.\n    ",
        "submission_date": "2012-07-13T00:00:00",
        "last_modified_date": "2012-07-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1207.3142",
        "title": "Color Constancy based on Image Similarity via Bilayer Sparse Coding",
        "authors": [
            "Bing Li",
            "Weihua Xiong",
            "Weiming Hu"
        ],
        "abstract": "Computational color constancy is a very important topic in computer vision and has attracted many researchers' attention. Recently, lots of research has shown the effects of high level visual content information for illumination estimation. However, all of these existing methods are essentially combinational strategies in which image's content analysis is only used to guide the combination or selection from a variety of individual illumination estimation methods. In this paper, we propose a novel bilayer sparse coding model for illumination estimation that considers image similarity in terms of both low level color distribution and high level image scene content simultaneously. For the purpose, the image's scene content information is integrated with its color distribution to obtain optimal illumination estimation model. The experimental results on two real-world image sets show that our algorithm is superior to other prevailing illumination estimation methods, even better than combinational methods.\n    ",
        "submission_date": "2012-07-13T00:00:00",
        "last_modified_date": "2012-11-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1207.3370",
        "title": "Deconvolution of vibroacoustic images using a simulation model based on a three dimensional point spread function",
        "authors": [
            "Talita Perciano",
            "Matthew Urban",
            "Nelson D. A. Mascarenhas",
            "Mostafa Fatemi",
            "Alejandro C. Frery",
            "Glauber T. Silva"
        ],
        "abstract": "Vibro-acoustography (VA) is a medical imaging method based on the difference-frequency generation produced by the mixture of two focused ultrasound beams. VA has been applied to different problems in medical imaging such as imaging bones, microcalcifications in the breast, mass lesions, and calcified arteries. The obtained images may have a resolution of 0.7--0.8 mm. Current VA systems based on confocal or linear array transducers generate C-scan images at the beam focal plane. Images on the axial plane are also possible, however the system resolution along depth worsens when compared to the lateral one. Typical axial resolution is about 1.0 cm. Furthermore, the elevation resolution of linear array systems is larger than that in lateral direction. This asymmetry degrades C-scan images obtained using linear arrays. The purpose of this article is to study VA image restoration based on a 3D point spread function (PSF) using classical deconvolution algorithms: Wiener, constrained least-squares (CLSs), and geometric mean filters. To assess the filters' performance, we use an image quality index that accounts for correlation loss, luminance and contrast distortion. Results for simulated VA images show that the quality index achieved with the Wiener filter is 0.9 (1 indicates perfect restoration). This filter yielded the best result in comparison with the other ones. Moreover, the deconvolution algorithms were applied to an experimental VA image of a phantom composed of three stretched 0.5 mm wires. Experiments were performed using transducer driven at two frequencies, 3075 kHz and 3125 kHz, which resulted in the difference-frequency of 50 kHz. Restorations with the theoretical line spread function (LSF) did not recover sufficient information to identify the wires in the images. However, using an estimated LSF the obtained results displayed enough information to spot the wires in the images.\n    ",
        "submission_date": "2012-07-13T00:00:00",
        "last_modified_date": "2012-07-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1207.3389",
        "title": "Incremental Learning of 3D-DCT Compact Representations for Robust Visual Tracking",
        "authors": [
            "Xi Li",
            "Anthony Dick",
            "Chunhua Shen",
            "Anton van den Hengel",
            "Hanzi Wang"
        ],
        "abstract": "Visual tracking usually requires an object appearance model that is robust to changing illumination, pose and other factors encountered in video. In this paper, we construct an appearance model using the 3D discrete cosine transform (3D-DCT). The 3D-DCT is based on a set of cosine basis functions, which are determined by the dimensions of the 3D signal and thus independent of the input video data. In addition, the 3D-DCT can generate a compact energy spectrum whose high-frequency coefficients are sparse if the appearance samples are similar. By discarding these high-frequency coefficients, we simultaneously obtain a compact 3D-DCT based object representation and a signal reconstruction-based similarity measure (reflecting the information loss from signal reconstruction). To efficiently update the object representation, we propose an incremental 3D-DCT algorithm, which decomposes the 3D-DCT into successive operations of the 2D discrete cosine transform (2D-DCT) and 1D discrete cosine transform (1D-DCT) on the input video data.\n    ",
        "submission_date": "2012-07-14T00:00:00",
        "last_modified_date": "2012-07-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1207.3510",
        "title": "HMRF-EM-image: Implementation of the Hidden Markov Random Field Model and its Expectation-Maximization Algorithm",
        "authors": [
            "Quan Wang"
        ],
        "abstract": "In this project, we study the hidden Markov random field (HMRF) model and its expectation-maximization (EM) algorithm. We implement a MATLAB toolbox named HMRF-EM-image for 2D image segmentation using the HMRF-EM framework. This toolbox also implements edge-prior-preserving image segmentation, and can be easily reconfigured for other problems, such as 3D image segmentation.\n    ",
        "submission_date": "2012-07-15T00:00:00",
        "last_modified_date": "2012-12-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1207.3538",
        "title": "Kernel Principal Component Analysis and its Applications in Face Recognition and Active Shape Models",
        "authors": [
            "Quan Wang"
        ],
        "abstract": "Principal component analysis (PCA) is a popular tool for linear dimensionality reduction and feature extraction. Kernel PCA is the nonlinear form of PCA, which better exploits the complicated spatial structure of high-dimensional features. In this paper, we first review the basic ideas of PCA and kernel PCA. Then we focus on the reconstruction of pre-images for kernel PCA. We also give an introduction on how PCA is used in active shape models (ASMs), and discuss how kernel PCA can be applied to improve traditional ASMs. Then we show some experimental results to compare the performance of kernel PCA and standard PCA for classification problems. We also implement the kernel PCA-based ASMs, and use it to construct human face models.\n    ",
        "submission_date": "2012-07-15T00:00:00",
        "last_modified_date": "2014-08-31T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1207.3554",
        "title": "Designing various component analysis at will",
        "authors": [
            "Akisato Kimura",
            "Masashi Sugiyama",
            "Sakano Hitoshi",
            "Hirokazu Kameoka"
        ],
        "abstract": "This paper provides a generic framework of component analysis (CA) methods introducing a new expression for scatter matrices and Gram matrices, called Generalized Pairwise Expression (GPE). This expression is quite compact but highly powerful: The framework includes not only (1) the standard CA methods but also (2) several regularization techniques, (3) weighted extensions, (4) some clustering methods, and (5) their semi-supervised extensions. This paper also presents quite a simple methodology for designing a desired CA method from the proposed framework: Adopting the known GPEs as templates, and generating a new method by combining these templates appropriately.\n    ",
        "submission_date": "2012-07-16T00:00:00",
        "last_modified_date": "2012-10-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1207.3576",
        "title": "Hierarchical Approach for Total Variation Digital Image Inpainting",
        "authors": [
            "S. Padmavathi",
            "N. Archana",
            "K. P. Soman"
        ],
        "abstract": "The art of recovering an image from damage in an undetectable form is known as inpainting. The manual work of inpainting is most often a very time consuming process. Due to digitalization of this technique, it is automatic and faster. In this paper, after the user selects the regions to be reconstructed, the algorithm automatically reconstruct the lost regions with the help of the information surrounding them. The existing methods perform very well when the region to be reconstructed is very small, but fails in proper reconstruction as the area increases. This paper describes a Hierarchical method by which the area to be inpainted is reduced in multiple levels and Total Variation(TV) method is used to inpaint in each level. This algorithm gives better performance when compared with other existing algorithms such as nearest neighbor interpolation, Inpainting through Blurring and Sobolev Inpainting.\n    ",
        "submission_date": "2012-07-16T00:00:00",
        "last_modified_date": "2013-07-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1207.3607",
        "title": "Fusing image representations for classification using support vector machines",
        "authors": [
            "Can Demirkesen",
            "Hocine Cherifi"
        ],
        "abstract": "In order to improve classification accuracy different image representations are usually combined. This can be done by using two different fusing schemes. In feature level fusion schemes, image representations are combined before the classification process. In classifier fusion, the decisions taken separately based on individual representations are fused to make a decision. In this paper the main methods derived for both strategies are evaluated. Our experimental results show that classifier fusion performs better. Specifically Bayes belief integration is the best performing strategy for image classification task.\n    ",
        "submission_date": "2012-07-16T00:00:00",
        "last_modified_date": "2012-07-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1207.3809",
        "title": "Image Labeling on a Network: Using Social-Network Metadata for Image Classification",
        "authors": [
            "Julian McAuley",
            "Jure Leskovec"
        ],
        "abstract": "Large-scale image retrieval benchmarks invariably consist of images from the Web. Many of these benchmarks are derived from online photo sharing networks, like Flickr, which in addition to hosting images also provide a highly interactive social community. Such communities generate rich metadata that can naturally be harnessed for image classification and retrieval. Here we study four popular benchmark datasets, extending them with social-network metadata, such as the groups to which each image belongs, the comment thread associated with the image, who uploaded it, their location, and their network of friends. Since these types of data are inherently relational, we propose a model that explicitly accounts for the interdependencies between images sharing common properties. We model the task as a binary labeling problem on a network, and use structured learning techniques to learn model parameters. We find that social-network metadata are useful in a variety of classification tasks, in many cases outperforming methods based on image content.\n    ",
        "submission_date": "2012-07-16T00:00:00",
        "last_modified_date": "2012-07-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1207.3944",
        "title": "Polarimetric SAR Image Segmentation with B-Splines and a New Statistical Model",
        "authors": [
            "Alejandro C. Frery",
            "Julio Jacobo-Berlles",
            "Juliana Gambini",
            "Marta Mejail"
        ],
        "abstract": "We present an approach for polarimetric Synthetic Aperture Radar (SAR) image region boundary detection based on the use of B-Spline active contours and a new model for polarimetric SAR data: the GHP distribution. In order to detect the boundary of a region, initial B-Spline curves are specified, either automatically or manually, and the proposed algorithm uses a deformable contours technique to find the boundary. In doing this, the parameters of the polarimetric GHP model for the data are estimated, in order to find the transition points between the region being segmented and the surrounding area. This is a local algorithm since it works only on the region to be segmented. Results of its performance are presented.\n    ",
        "submission_date": "2012-07-17T00:00:00",
        "last_modified_date": "2012-07-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1207.4089",
        "title": "A Two-Stage Combined Classifier in Scale Space Texture Classification",
        "authors": [
            "Mehrdad J. Gangeh",
            "Robert P. W. Duin",
            "Bart M. ter Haar Romeny",
            "Mohamed S. Kamel"
        ],
        "abstract": "Textures often show multiscale properties and hence multiscale techniques are considered useful for texture analysis. Scale-space theory as a biologically motivated approach may be used to construct multiscale textures. In this paper various ways are studied to combine features on different scales for texture classification of small image patches. We use the N-jet of derivatives up to the second order at different scales to generate distinct pattern representations (DPR) of feature subsets. Each feature subset in the DPR is given to a base classifier (BC) of a two-stage combined classifier. The decisions made by these BCs are combined in two stages over scales and derivatives. Various combining systems and their significances and differences are discussed. The learning curves are used to evaluate the performances. We found for small sample sizes combining classifiers performs significantly better than combining feature spaces (CFS). It is also shown that combining classifiers performs better than the support vector machine on CFS in multiscale texture classification.\n    ",
        "submission_date": "2012-07-17T00:00:00",
        "last_modified_date": "2012-07-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1207.4129",
        "title": "Recovering Articulated Object Models from 3D Range Data",
        "authors": [
            "Dragomir Anguelov",
            "Daphne Koller",
            "Hoi-Cheung Pang",
            "Praveen Srinivasan",
            "Sebastian Thrun"
        ],
        "abstract": "We address the problem of unsupervised learning of complex articulated object models from 3D range data. We describe an algorithm whose input is a set of meshes corresponding to different configurations of an articulated object. The algorithm automatically recovers a decomposition of the object into approximately rigid parts, the location of the parts in the different object instances, and the articulated object skeleton linking the parts. Our algorithm first registers allthe meshes using an unsupervised non-rigid technique described in a companion paper. It then segments the meshes using a graphical model that captures the spatial contiguity of parts. The segmentation is done using the EM algorithm, iterating between finding a decomposition of the object into rigid parts, and finding the location of the parts in the object instances. Although the graphical model is densely connected, the object decomposition step can be performed optimally and efficiently, allowing us to identify a large number of object parts while avoiding local maxima. We demonstrate the algorithm on real world datasets, recovering a 15-part articulated model of a human puppet from just 7 different puppet configurations, as well as a 4 part model of a fiexing arm where significant non-rigid deformation was present.\n    ",
        "submission_date": "2012-07-11T00:00:00",
        "last_modified_date": "2012-07-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1207.4179",
        "title": "Probabilistic index maps for modeling natural signals",
        "authors": [
            "Nebojsa Jojic",
            "Yaron Caspi",
            "Manuel Reyes-Gomez"
        ],
        "abstract": "One of the major problems in modeling natural signals is that signals with very similar structure may locally have completely different measurements, e.g., images taken under different illumination conditions, or the speech signal captured in different environments. While there have been many successful attempts to address these problems in application-specific settings, we believe that underlying a large set of problems in signal representation is a representational deficiency of intensity-derived local measurements that are the basis of most efficient models. We argue that interesting structure in signals is better captured when the signal is de- fined as a matrix whose entries are discrete indices to a separate palette of possible measurements. In order to model the variability in signal structure, we define a signal class not by a single index map, but by a probability distribution over the index maps, which can be estimated from the data, and which we call probabilistic index maps. The existing algorithm can be adapted to work with this representation. Furthermore, the probabilistic index map representation leads to algorithms with computational costs proportional to either the size of the palette or the log of the size of the palette, making the cost of significantly increased invariance to non-structural changes quite bearable. We illustrate the benefits of the probabilistic index map representation in several applications in computer vision and speech processing.\n    ",
        "submission_date": "2012-07-12T00:00:00",
        "last_modified_date": "2012-07-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1207.4308",
        "title": "Assessment of SAR Image Filtering using Adaptive Stack Filters",
        "authors": [
            "Maria E. Buemi",
            "Marta Mejail",
            "Julio Jacobo",
            "Alejandro C. Frery",
            "Heitor S. Ramos"
        ],
        "abstract": "Stack filters are a special case of non-linear filters. They have a good performance for filtering images with different types of noise while preserving edges and details. A stack filter decomposes an input image into several binary images according to a set of thresholds. Each binary image is then filtered by a Boolean function, which characterizes the filter. Adaptive stack filters can be designed to be optimal; they are computed from a pair of images consisting of an ideal noiseless image and its noisy version. In this work we study the performance of adaptive stack filters when they are applied to Synthetic Aperture Radar (SAR) images. This is done by evaluating the quality of the filtered images through the use of suitable image quality indexes and by measuring the classification accuracy of the resulting images.\n    ",
        "submission_date": "2012-07-18T00:00:00",
        "last_modified_date": "2012-07-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1207.4417",
        "title": "Penalty Constraints and Kernelization of M-Estimation Based Fuzzy C-Means",
        "authors": [
            "Jingwei Liu",
            "Meizhi Xu"
        ],
        "abstract": "A framework of M-estimation based fuzzy C-means clustering (MFCM) algorithm is proposed with iterative reweighted least squares (IRLS) algorithm, and penalty constraint and kernelization extensions of MFCM algorithms are also developed. Introducing penalty information to the object functions of MFCM algorithms, the spatially constrained fuzzy C-means (SFCM) is extended to penalty constraints MFCM algorithms(abbr. pMFCM).Substituting the Euclidean distance with kernel method, the MFCM and pMFCM algorithms are extended to kernelized MFCM (abbr. KMFCM) and kernelized pMFCM (",
        "submission_date": "2012-07-18T00:00:00",
        "last_modified_date": "2013-01-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1207.5007",
        "title": "Multisegmentation through wavelets: Comparing the efficacy of Daubechies vs Coiflets",
        "authors": [
            "Madhur Srivastava",
            "Yashwant Yashu",
            "Satish K. Singh",
            "Prasanta K. Panigrahi"
        ],
        "abstract": "In this paper, we carry out a comparative study of the efficacy of wavelets belonging to Daubechies and Coiflet family in achieving image segmentation through a fast statistical ",
        "submission_date": "2012-07-20T00:00:00",
        "last_modified_date": "2012-07-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1207.5064",
        "title": "A Novel Metric Approach Evaluation For The Spatial Enhancement Of Pan-Sharpened Images",
        "authors": [
            "Firouz Abdullah Al-Wassai",
            "Dr. N.V. Kalyankar"
        ],
        "abstract": "Various and different methods can be used to produce high-resolution multispectral images from high-resolution panchromatic image (PAN) and low-resolution multispectral images (MS), mostly on the pixel level. The Quality of image fusion is an essential determinant of the value of processing images fusion for many applications. Spatial and spectral qualities are the two important indexes that used to evaluate the quality of any fused image. However, the jury is still out of fused image's benefits if it compared with its original images. In addition, there is a lack of measures for assessing the objective quality of the spatial resolution for the fusion methods. So, an objective quality of the spatial resolution assessment for fusion images is required. Therefore, this paper describes a new approach proposed to estimate the spatial resolution improve by High Past Division Index (HPDI) upon calculating the spatial-frequency of the edge regions of the image and it deals with a comparison of various analytical techniques for evaluating the Spatial quality, and estimating the colour distortion added by image fusion including: MG, SG, FCC, SD, En, SNR, CC and NRMSE. In addition, this paper devotes to concentrate on the comparison of various image fusion techniques based on pixel and feature fusion technique.\n    ",
        "submission_date": "2012-07-20T00:00:00",
        "last_modified_date": "2012-07-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1207.5113",
        "title": "Piecewise Linear Patch Reconstruction for Segmentation and Description of Non-smooth Image Structures",
        "authors": [
            "Junyan Wang",
            "Kap Luk Chan"
        ],
        "abstract": "In this paper, we propose a unified energy minimization model for the segmentation of non-smooth image structures. The energy of piecewise linear patch reconstruction is considered as an objective measure of the quality of the segmentation of non-smooth structures. The segmentation is achieved by minimizing the single energy without any separate process of feature extraction. We also prove that the error of segmentation is bounded by the proposed energy functional, meaning that minimizing the proposed energy leads to reducing the error of segmentation. As a by-product, our method produces a dictionary of optimized orthonormal descriptors for each segmented region. The unique feature of our method is that it achieves the simultaneous segmentation and description for non-smooth image structures under the same optimization framework. The experiments validate our theoretical claims and show the clear superior performance of our methods over other related methods for segmentation of various image textures. We show that our model can be coupled with the piecewise smooth model to handle both smooth and non-smooth structures, and we demonstrate that the proposed model is capable of coping with multiple different regions through the one-against-all strategy.\n    ",
        "submission_date": "2012-07-21T00:00:00",
        "last_modified_date": "2012-07-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1207.5774",
        "title": "A New Training Algorithm for Kanerva's Sparse Distributed Memory",
        "authors": [
            "Lou Marvin Caraig"
        ],
        "abstract": "The Sparse Distributed Memory proposed by Pentii Kanerva (SDM in short) was thought to be a model of human long term memory. The architecture of the SDM permits to store binary patterns and to retrieve them using partially matching patterns. However Kanerva's model is especially efficient only in handling random data. The purpose of this article is to introduce a new approach of training Kanerva's SDM that can handle efficiently non-random data, and to provide it the capability to recognize inverted patterns. This approach uses a signal model which is different from the one proposed for different purposes by Hely, Willshaw and Hayes in [4]. This article additionally suggests a different way of creating hard locations in the memory despite the Kanerva's static model.\n    ",
        "submission_date": "2012-07-22T00:00:00",
        "last_modified_date": "2012-07-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1207.6774",
        "title": "A Survey Of Activity Recognition And Understanding The Behavior In Video Survelliance",
        "authors": [
            "A. R. Revathi",
            "Dhananjay Kumar"
        ],
        "abstract": "This paper presents a review of human activity recognition and behaviour understanding in video sequence. The key objective of this paper is to provide a general review on the overall process of a surveillance system used in the current trend. Visual surveillance system is directed on automatic identification of events of interest, especially on tracking and classification of moving objects. The processing step of the video surveillance system includes the following stages: Surrounding model, object representation, object tracking, activity recognition and behaviour understanding. It describes techniques that use to define a general set of activities that are applicable to a wide range of scenes and environments in video sequence.\n    ",
        "submission_date": "2012-07-29T00:00:00",
        "last_modified_date": "2012-07-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1207.7244",
        "title": "Visual Vocabulary Learning and Its Application to 3D and Mobile Visual Search",
        "authors": [
            "Liujuan Cao"
        ],
        "abstract": "In this technical report, we review related works and recent trends in visual vocabulary based web image search, object recognition, mobile visual search, and 3D object retrieval. Especial focuses would be also given for the recent trends in supervised/unsupervised vocabulary optimization, compact descriptor for visual search, as well as in multi-view based 3D object representation.\n    ",
        "submission_date": "2012-06-29T00:00:00",
        "last_modified_date": "2012-06-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1208.0378",
        "title": "Fast Planar Correlation Clustering for Image Segmentation",
        "authors": [
            "Julian Yarkony",
            "Alexander T. Ihler",
            "Charless C. Fowlkes"
        ],
        "abstract": "We describe a new optimization scheme for finding high-quality correlation clusterings in planar graphs that uses weighted perfect matching as a subroutine. Our method provides lower-bounds on the energy of the optimal correlation clustering that are typically fast to compute and tight in practice. We demonstrate our algorithm on the problem of image segmentation where this approach outperforms existing global optimization techniques in minimizing the objective and is competitive with the state of the art in producing high-quality segmentations.\n    ",
        "submission_date": "2012-08-02T00:00:00",
        "last_modified_date": "2012-08-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1208.0432",
        "title": "Efficient Point-to-Subspace Query in $\\ell^1$ with Application to Robust Object Instance Recognition",
        "authors": [
            "Ju Sun",
            "Yuqian Zhang",
            "John Wright"
        ],
        "abstract": "Motivated by vision tasks such as robust face and object recognition, we consider the following general problem: given a collection of low-dimensional linear subspaces in a high-dimensional ambient (image) space, and a query point (image), efficiently determine the nearest subspace to the query in $\\ell^1$ distance. In contrast to the naive exhaustive search which entails large-scale linear programs, we show that the computational burden can be cut down significantly by a simple two-stage algorithm: (1) projecting the query and data-base subspaces into lower-dimensional space by random Cauchy matrix, and solving small-scale distance evaluations (linear programs) in the projection space to locate candidate nearest; (2) with few candidates upon independent repetition of (1), getting back to the high-dimensional space and performing exhaustive search. To preserve the identity of the nearest subspace with nontrivial probability, the projection dimension typically is low-order polynomial of the subspace dimension multiplied by logarithm of number of the subspaces (Theorem 2.1). The reduced dimensionality and hence complexity renders the proposed algorithm particularly relevant to vision application such as robust face and object instance recognition that we investigate empirically.\n    ",
        "submission_date": "2012-08-02T00:00:00",
        "last_modified_date": "2014-03-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1208.0967",
        "title": "Human Activity Learning using Object Affordances from RGB-D Videos",
        "authors": [
            "Hema Swetha Koppula",
            "Rudhir Gupta",
            "Ashutosh Saxena"
        ],
        "abstract": "Human activities comprise several sub-activities performed in a sequence and involve interactions with various objects. This makes reasoning about the object affordances a central task for activity recognition. In this work, we consider the problem of jointly labeling the object affordances and human activities from RGB-D videos. We frame the problem as a Markov Random Field where the nodes represent objects and sub-activities, and the edges represent the relationships between object affordances, their relations with sub-activities, and their evolution over time. We formulate the learning problem using a structural SVM approach, where labeling over various alternate temporal segmentations are considered as latent variables. We tested our method on a dataset comprising 120 activity videos collected from four subjects, and obtained an end-to-end precision of 81.8% and recall of 80.0% for labeling the activities.\n    ",
        "submission_date": "2012-08-04T00:00:00",
        "last_modified_date": "2012-08-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1208.1670",
        "title": "Performance Measurement and Method Analysis (PMMA) for Fingerprint Reconstruction",
        "authors": [
            "Josphineleela Ramakrishnan",
            "Ramakrishnan Malaisamy"
        ],
        "abstract": "Fingerprint reconstruction is one of the most well-known and publicized biometrics. Because of their uniqueness and consistency over time, fingerprints have been used for identification over a century, more recently becoming automated due to advancements in computed capabilities. Fingerprint reconstruction is popular because of the inherent ease of acquisition, the numerous sources (e.g. ten fingers) available for collection, and their established use and collections by law enforcement and immigration. Fingerprints have always been the most practical and positive means of identification. Offenders, being well aware of this, have been coming up with ways to escape identification by that means. Erasing left over fingerprints, using gloves, fingerprint forgery; are certain examples of methods tried by them, over the years. Failing to prevent themselves, they moved to an extent of mutilating their finger skin pattern, to remain unidentified. This article is based upon obliteration of finger ridge patterns and discusses some known cases in relation to the same, in chronological order; highlighting the reasons why offenders go to an extent of performing such act. The paper gives an overview of different methods and performance measurement of the fingerprint reconstruction.\n    ",
        "submission_date": "2012-08-08T00:00:00",
        "last_modified_date": "2012-08-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1208.1672",
        "title": "An Efficient Automatic Attendance System Using Fingerprint Reconstruction Technique",
        "authors": [
            "Josphineleela Ramakrishnan",
            "M. Ramakrishnan"
        ],
        "abstract": "Biometric time and attendance system is one of the most successful applications of biometric technology. One of the main advantage of a biometric time and attendance system is it avoids \"buddy-punching\". Buddy punching was a major loophole which will be exploiting in the traditional time attendance systems. Fingerprint recognition is an established field today, but still identifying individual from a set of enrolled fingerprints is a time taking process. Most fingerprint-based biometric systems store the minutiae template of a user in the database. It has been traditionally assumed that the minutiae template of a user does not reveal any information about the original fingerprint. This belief has now been shown to be false; several algorithms have been proposed that can reconstruct fingerprint images from minutiae templates. In this paper, a novel fingerprint reconstruction algorithm is proposed to reconstruct the phase image, which is then converted into the grayscale image. The proposed reconstruction algorithm reconstructs the phase image from minutiae. The proposed reconstruction algorithm is used to automate the whole process of taking attendance, manually which is a laborious and troublesome work and waste a lot of time, with its managing and maintaining the records for a period of time is also a burdensome task. The proposed reconstruction algorithm has been evaluated with respect to the success rates of type-I attack (match the reconstructed fingerprint against the original fingerprint) and type-II attack (match the reconstructed fingerprint against different impressions of the original fingerprint) using a commercial fingerprint recognition system. Given the reconstructed image from our algorithm, we show that both types of attacks can be effectively launched against a fingerprint recognition system.\n    ",
        "submission_date": "2012-08-08T00:00:00",
        "last_modified_date": "2012-08-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1208.1880",
        "title": "Stereo Acoustic Perception based on Real Time Video Acquisition for Navigational Assistance",
        "authors": [
            "Supreeth K. Rao",
            "Arpitha Prasad B.",
            "Anushree R. Shetty",
            "Chinmai",
            "R. Bhakthavathsalam",
            "Rajeshwari Hegde"
        ],
        "abstract": "A smart navigation system (an Electronic Travel Aid) based on an object detection mechanism has been designed to detect the presence of obstacles that immediately impede the path, by means of real time video processing. The algorithm can be used for any general purpose navigational aid. This paper is discussed, keeping in mind the navigation of the visually impaired, and is not limited to the same. A video camera feeds images of the surroundings to a Da- Vinci Digital Media Processor, DM642, which works on the video, frame by frame. The processor carries out image processing techniques whose result contains information about the object in terms of image pixels. The algorithm aims to select the object which, among all others, poses maximum threat to the navigation. A database containing a total of three sounds is constructed. Hence, each image translates to a beep, where every beep informs the navigator of the obstacles directly in front of him. This paper implements an algorithm that is more efficient as compared to its predecessors.\n    ",
        "submission_date": "2012-08-09T00:00:00",
        "last_modified_date": "2012-08-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1208.2128",
        "title": "Brain tumor MRI image classification with feature selection and extraction using linear discriminant analysis",
        "authors": [
            "V. P. Gladis Pushpa Rathi",
            "S. Palani"
        ],
        "abstract": "Feature extraction is a method of capturing visual content of an image. The feature extraction is the process to represent raw image in its reduced form to facilitate decision making such as pattern classification. We have tried to address the problem of classification MRI brain images by creating a robust and more accurate classifier which can act as an expert assistant to medical practitioners. The objective of this paper is to present a novel method of feature selection and extraction. This approach combines the Intensity, Texture, shape based features and classifies the tumor as white matter, Gray matter, CSF, abnormal and normal area. The experiment is performed on 140 tumor contained brain MR images from the Internet Brain Segmentation Repository. The proposed technique has been carried out over a larger database as compare to any previous work and is more robust and effective. PCA and Linear Discriminant Analysis (LDA) were applied on the training sets. The Support Vector Machine (SVM) classifier served as a comparison of nonlinear techniques Vs linear ones. PCA and LDA methods are used to reduce the number of features used. The feature selection using the proposed technique is more beneficial as it analyses the data according to grouping class variable and gives reduced feature set with high classification accuracy.\n    ",
        "submission_date": "2012-08-10T00:00:00",
        "last_modified_date": "2012-08-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1208.2655",
        "title": "Stable Segmentation of Digital Image",
        "authors": [
            "M. Kharinov"
        ],
        "abstract": "In the paper the optimal image segmentation by means of piecewise constant approximations is considered. The optimality is defined by a minimum value of the total squared error or by equivalent value of standard deviation of the approximation from the image. The optimal approximations are defined independently on the method of their obtaining and might be generated in different algorithms. We investigate the computation of the optimal approximation on the grounds of stability with respect to a given set of modifications. To obtain the optimal approximation the Mumford-Shuh model is generalized and developed, which in the computational part is combined with the Otsu method in multi-thresholding version. The proposed solution is proved analytically and experimentally on the example of the standard image.\n    ",
        "submission_date": "2012-08-13T00:00:00",
        "last_modified_date": "2012-08-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1208.3133",
        "title": "Color Image Compression Algorithm Based on the DCT Blocks",
        "authors": [
            "Walaa M. Abd-Elhafiez",
            "Wajeb Gharibi"
        ],
        "abstract": "This paper presents the performance of different blockbased discrete cosine transform (DCT) algorithms for compressing color image. In this RGB component of color image are converted to YCbCr before DCT transform is applied. Y is luminance component;Cb and Cr are chrominance components of the image. The modification of the image data is done based on the classification of image blocks to edge blocks and non-edge blocks, then the edge block of the image is compressed with low compression and the nonedge blocks is compressed with high compression. The analysis results have indicated that the performance of the suggested method is much better, where the constructed images are less distorted and compressed with higher factor.\n    ",
        "submission_date": "2012-08-15T00:00:00",
        "last_modified_date": "2012-08-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1208.3512",
        "title": "Contour Completion Around a Fixation Point",
        "authors": [
            "Toshiro Kubota"
        ],
        "abstract": "The paper presents two edge grouping algorithms for finding a closed contour starting from a particular edge point and enclosing a fixation point. Both algorithms search a shortest simple cycle in \\textit{an angularly ordered graph} derived from an edge image where a vertex is an end point of a contour fragment and an undirected arc is drawn between a pair of end-points whose visual angle from the fixation point is less than a threshold value, which is set to $\\pi/2$ in our experiments. The first algorithm restricts the search space by disregarding arcs that cross the line extending from the fixation point to the starting point. The second algorithm improves the solution of the first algorithm in a greedy manner. The algorithms were tested with a large number of natural images with manually placed fixation and starting points. The results are promising.\n    ",
        "submission_date": "2012-08-16T00:00:00",
        "last_modified_date": "2012-08-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1208.3665",
        "title": "An Evaluation of Popular Copy-Move Forgery Detection Approaches",
        "authors": [
            "Vincent Christlein",
            "Christian Riess",
            "Johannes Jordan",
            "Corinna Riess",
            "Elli Angelopoulou"
        ],
        "abstract": "A copy-move forgery is created by copying and pasting content within the same image, and potentially post-processing it. In recent years, the detection of copy-move forgeries has become one of the most actively researched topics in blind image forensics. A considerable number of different algorithms have been proposed focusing on different types of postprocessed copies. In this paper, we aim to answer which copy-move forgery detection algorithms and processing steps (e.g., matching, filtering, outlier detection, affine transformation estimation) perform best in various postprocessing scenarios. The focus of our analysis is to evaluate the performance of previously proposed feature sets. We achieve this by casting existing algorithms in a common pipeline. In this paper, we examined the 15 most prominent feature sets. We analyzed the detection performance on a per-image basis and on a per-pixel basis. We created a challenging real-world copy-move dataset, and a software framework for systematic image manipulation. Experiments show, that the keypoint-based features SIFT and SURF, as well as the block-based DCT, DWT, KPCA, PCA and Zernike features perform very well. These feature sets exhibit the best robustness against various noise sources and downsampling, while reliably identifying the copied regions.\n    ",
        "submission_date": "2012-08-17T00:00:00",
        "last_modified_date": "2012-11-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1208.3670",
        "title": "A Survey of Recent View-based 3D Model Retrieval Methods",
        "authors": [
            "Qiong Liu"
        ],
        "abstract": "Extensive research efforts have been dedicated to 3D model retrieval in recent decades. Recently, view-based methods have attracted much research attention due to the high discriminative property of multi-views for 3D object representation. In this report, we summarize the view-based 3D model methods and provide the further research trends. This paper focuses on the scheme for matching between multiple views of 3D models and the application of bag-of-visual-words method in 3D model retrieval. For matching between multiple views, the many-to-many matching, probabilistic matching and semisupervised learning methods are introduced. For bag-of-visual-words application in 3D model retrieval, we first briefly review the bag-of-visual-words works on multimedia and computer vision tasks, where the visual dictionary has been detailed introduced. Then a series of 3D model retrieval methods by using bag-of-visual-words description are surveyed in this paper. At last, we summarize the further research content in view-based 3D model retrieval.\n    ",
        "submission_date": "2012-08-08T00:00:00",
        "last_modified_date": "2012-08-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1208.3687",
        "title": "Information-theoretic Dictionary Learning for Image Classification",
        "authors": [
            "Qiang Qiu",
            "Vishal M. Patel",
            "Rama Chellappa"
        ],
        "abstract": "We present a two-stage approach for learning dictionaries for object classification tasks based on the principle of information maximization. The proposed method seeks a dictionary that is compact, discriminative, and generative. In the first stage, dictionary atoms are selected from an initial dictionary by maximizing the mutual information measure on dictionary compactness, discrimination and reconstruction. In the second stage, the selected dictionary atoms are updated for improved reconstructive and discriminative power using a simple gradient ascent algorithm on mutual information. Experiments using real datasets demonstrate the effectiveness of our approach for image classification tasks.\n    ",
        "submission_date": "2012-08-17T00:00:00",
        "last_modified_date": "2012-08-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1208.3716",
        "title": "Improved Total Variation based Image Compressive Sensing Recovery by Nonlocal Regularization",
        "authors": [
            "Jian Zhang",
            "Shaohui Liu",
            "Debin Zhao",
            "Ruiqin Xiong",
            "Siwei Ma"
        ],
        "abstract": "Recently, total variation (TV) based minimization algorithms have achieved great success in compressive sensing (CS) recovery for natural images due to its virtue of preserving edges. However, the use of TV is not able to recover the fine details and textures, and often suffers from undesirable staircase artifact. To reduce these effects, this letter presents an improved TV based image CS recovery algorithm by introducing a new nonlocal regularization constraint into CS optimization problem. The nonlocal regularization is built on the well known nonlocal means (NLM) filtering and takes advantage of self-similarity in images, which helps to suppress the staircase effect and restore the fine details. Furthermore, an efficient augmented Lagrangian based algorithm is developed to solve the above combined TV and nonlocal regularization constrained problem. Experimental results demonstrate that the proposed algorithm achieves significant performance improvements over the state-of-the-art TV based algorithm in both PSNR and visual perception.\n    ",
        "submission_date": "2012-08-18T00:00:00",
        "last_modified_date": "2012-12-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1208.3723",
        "title": "Image Super-Resolution via Dual-Dictionary Learning And Sparse Representation",
        "authors": [
            "Jian Zhang",
            "Chen Zhao",
            "Ruiqin Xiong",
            "Siwei Ma",
            "Debin Zhao"
        ],
        "abstract": "Learning-based image super-resolution aims to reconstruct high-frequency (HF) details from the prior model trained by a set of high- and low-resolution image patches. In this paper, HF to be estimated is considered as a combination of two components: main high-frequency (MHF) and residual high-frequency (RHF), and we propose a novel image super-resolution method via dual-dictionary learning and sparse representation, which consists of the main dictionary learning and the residual dictionary learning, to recover MHF and RHF respectively. Extensive experimental results on test images validate that by employing the proposed two-layer progressive scheme, more image details can be recovered and much better results can be achieved than the state-of-the-art algorithms in terms of both PSNR and visual perception.\n    ",
        "submission_date": "2012-08-18T00:00:00",
        "last_modified_date": "2012-08-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1208.3822",
        "title": "Joint-ViVo: Selecting and Weighting Visual Words Jointly for Bag-of-Features based Tissue Classification in Medical Images",
        "authors": [
            "Jingyan Wang"
        ],
        "abstract": "Automatically classifying the tissues types of Region of Interest (ROI) in medical imaging has been an important application in Computer-Aided Diagnosis (CAD), such as classification of breast parenchymal tissue in the mammogram, classify lung disease patterns in High-Resolution Computed Tomography (HRCT) etc. Recently, bag-of-features method has shown its power in this field, treating each ROI as a set of local features. In this paper, we investigate using the bag-of-features strategy to classify the tissue types in medical imaging applications. Two important issues are considered here: the visual vocabulary learning and weighting. Although there are already plenty of algorithms to deal with them, all of them treat them independently, namely, the vocabulary learned first and then the histogram weighted. Inspired by Auto-Context who learns the features and classifier jointly, we try to develop a novel algorithm that learns the vocabulary and weights jointly. The new algorithm, called Joint-ViVo, works in an iterative way. In each iteration, we first learn the weights for each visual word by maximizing the margin of ROI triplets, and then select the most discriminate visual words based on the learned weights for the next iteration. We test our algorithm on three tissue classification tasks: identifying brain tissue type in magnetic resonance imaging (MRI), classifying lung tissue in HRCT images, and classifying breast tissue density in mammograms. The results show that Joint-ViVo can perform effectively for classifying tissues.\n    ",
        "submission_date": "2012-08-19T00:00:00",
        "last_modified_date": "2013-04-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1208.3839",
        "title": "Discriminative Sparse Coding on Multi-Manifold for Data Representation and Classification",
        "authors": [
            "Jing-Yan Wang"
        ],
        "abstract": "Sparse coding has been popularly used as an effective data representation method in various applications, such as computer vision, medical imaging and bioinformatics, etc. However, the conventional sparse coding algorithms and its manifold regularized variants (graph sparse coding and Laplacian sparse coding), learn the codebook and codes in a unsupervised manner and neglect the class information available in the training set. To address this problem, in this paper we propose a novel discriminative sparse coding method based on multi-manifold, by learning discriminative class-conditional codebooks and sparse codes from both data feature space and class labels. First, the entire training set is partitioned into multiple manifolds according to the class labels. Then, we formulate the sparse coding as a manifold-manifold matching problem and learn class-conditional codebooks and codes to maximize the manifold margins of different classes. Lastly, we present a data point-manifold matching error based strategy to classify the unlabeled data point. Experimental results on somatic mutations identification and breast tumors classification in ultrasonic images tasks demonstrate the efficacy of the proposed data representation-classification approach.\n    ",
        "submission_date": "2012-08-19T00:00:00",
        "last_modified_date": "2013-04-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1208.3901",
        "title": "Trace transform based method for color image domain identification",
        "authors": [
            "Igor G. Olaizola",
            "Marco Quartulli",
            "Julian Florez",
            "Basilio Sierra"
        ],
        "abstract": "Context categorization is a fundamental pre-requisite for multi-domain multimedia content analysis applications in order to manage contextual information in an efficient manner. In this paper, we introduce a new color image context categorization method (DITEC) based on the trace transform. The problem of dimensionality reduction of the obtained trace transform signal is addressed through statistical descriptors that keep the underlying information. These extracted features offer a highly discriminant behavior for content categorization. The theoretical properties of the method are analyzed and validated experimentally through two different datasets.\n    ",
        "submission_date": "2012-08-19T00:00:00",
        "last_modified_date": "2019-03-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1208.4316",
        "title": "An Online Character Recognition System to Convert Grantha Script to Malayalam",
        "authors": [
            "Sreeraj.M",
            "Sumam Mary Idicula"
        ],
        "abstract": "This paper presents a novel approach to recognize Grantha, an ancient script in South India and converting it to Malayalam, a prevalent language in South India using online character recognition mechanism. The motivation behind this work owes its credit to (i) developing a mechanism to recognize Grantha script in this modern world and (ii) affirming the strong connection among Grantha and Malayalam. A framework for the recognition of Grantha script using online character recognition is designed and implemented. The features extracted from the Grantha script comprises mainly of time-domain features based on writing direction and curvature. The recognized characters are mapped to corresponding Malayalam characters. The framework was tested on a bed of medium length manuscripts containing 9-12 sample lines and printed pages of a book titled Soundarya Lahari writtenin Grantha by Sri Adi Shankara to recognize the words and sentences. The manuscript recognition rates with the system are for Grantha as 92.11%, Old Malayalam 90.82% and for new Malayalam script 89.56%. The recognition rates of pages of the printed book are for Grantha as 96.16%, Old Malayalam script 95.22% and new Malayalam script as 92.32% respectively. These results show the efficiency of the developed system.\n    ",
        "submission_date": "2012-08-21T00:00:00",
        "last_modified_date": "2012-08-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1208.4384",
        "title": "Iterative graph cuts for image segmentation with a nonlinear statistical shape prior",
        "authors": [
            "Joshua C. Chang",
            "Tom Chou"
        ],
        "abstract": "Shape-based regularization has proven to be a useful method for delineating objects within noisy images where one has prior knowledge of the shape of the targeted object. When a collection of possible shapes is available, the specification of a shape prior using kernel density estimation is a natural technique. Unfortunately, energy functionals arising from kernel density estimation are of a form that makes them impossible to directly minimize using efficient optimization algorithms such as graph cuts. Our main contribution is to show how one may recast the energy functional into a form that is minimizable iteratively and efficiently using graph cuts.\n    ",
        "submission_date": "2012-08-21T00:00:00",
        "last_modified_date": "2013-02-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1208.4391",
        "title": "Shape Tracking With Occlusions via Coarse-To-Fine Region-Based Sobolev Descent",
        "authors": [
            "Yanchao Yang",
            "Ganesh Sundaramoorthi"
        ],
        "abstract": "We present a method to track the precise shape of an object in video based on new modeling and optimization on a new Riemannian manifold of parameterized regions.\n",
        "submission_date": "2012-08-21T00:00:00",
        "last_modified_date": "2013-12-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1208.4398",
        "title": "A Unified Approach for Modeling and Recognition of Individual Actions and Group Activities",
        "authors": [
            "Qiang Qiu",
            "Rama Chellappa"
        ],
        "abstract": "Recognizing group activities is challenging due to the difficulties in isolating individual entities, finding the respective roles played by the individuals and representing the complex interactions among the participants. Individual actions and group activities in videos can be represented in a common framework as they share the following common feature: both are composed of a set of low-level features describing motions, e.g., optical flow for each pixel or a trajectory for each feature point, according to a set of composition constraints in both temporal and spatial dimensions. In this paper, we present a unified model to assess the similarity between two given individual or group activities. Our approach avoids explicit extraction of individual actors, identifying and representing the inter-person interactions. With the proposed approach, retrieval from a video database can be performed through Query-by-Example; and activities can be recognized by querying videos containing known activities. The suggested video matching process can be performed in an unsupervised manner. We demonstrate the performance of our approach by recognizing a set of human actions and football plays.\n    ",
        "submission_date": "2012-08-21T00:00:00",
        "last_modified_date": "2012-08-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1208.4842",
        "title": "The Segmentation Fusion Method On10 Multi-Sensors",
        "authors": [
            "Firouz Abdullah Al-Wassai",
            "N. V. Kalyankar"
        ],
        "abstract": "The most significant problem may be undesirable effects for the spectral signatures of fused images as well as the benefits of using fused images mostly compared to their source images were acquired at the same time by one sensor. They may or may not be suitable for the fusion of other images. It becomes therefore increasingly important to investigate techniques that allow multi-sensor, multi-date image fusion to make final conclusions can be drawn on the most suitable method of fusion. So, In this study we present a new method Segmentation Fusion method (SF) for remotely sensed images is presented by considering the physical characteristics of sensors, which uses a feature level processing paradigm. In a particularly, attempts to test the proposed method performance on 10 multi-sensor images and comparing it with different fusion techniques for estimating the quality and degree of information improvement quantitatively by using various spatial and spectral metrics.\n    ",
        "submission_date": "2012-08-23T00:00:00",
        "last_modified_date": "2012-08-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1208.5016",
        "title": "WESD - Weighted Spectral Distance for Measuring Shape Dissimilarity",
        "authors": [
            "Ender Konukoglu",
            "Ben Glocker",
            "Antonio Criminisi",
            "Kilian M. Pohl"
        ],
        "abstract": "This article presents a new distance for measuring shape dissimilarity between objects. Recent publications introduced the use of eigenvalues of the Laplace operator as compact shape descriptors. Here, we revisit the eigenvalues to define a proper distance, called Weighted Spectral Distance (WESD), for quantifying shape dissimilarity. The definition of WESD is derived through analysing the heat-trace. This analysis provides the proposed distance an intuitive meaning and mathematically links it to the intrinsic geometry of objects. We analyse the resulting distance definition, present and prove its important theoretical properties. Some of these properties include: i) WESD is defined over the entire sequence of eigenvalues yet it is guaranteed to converge, ii) it is a pseudometric, iii) it is accurately approximated with a finite number of eigenvalues, and iv) it can be mapped to the [0,1) interval. Lastly, experiments conducted on synthetic and real objects are presented. These experiments highlight the practical benefits of WESD for applications in vision and medical image analysis.\n    ",
        "submission_date": "2012-08-24T00:00:00",
        "last_modified_date": "2012-08-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1208.5092",
        "title": "Graph Degree Linkage: Agglomerative Clustering on a Directed Graph",
        "authors": [
            "Wei Zhang",
            "Xiaogang Wang",
            "Deli Zhao",
            "Xiaoou Tang"
        ],
        "abstract": "This paper proposes a simple but effective graph-based agglomerative algorithm, for clustering high-dimensional data. We explore the different roles of two fundamental concepts in graph theory, indegree and outdegree, in the context of clustering. The average indegree reflects the density near a sample, and the average outdegree characterizes the local geometry around a sample. Based on such insights, we define the affinity measure of clusters via the product of average indegree and average outdegree. The product-based affinity makes our algorithm robust to noise. The algorithm has three main advantages: good performance, easy implementation, and high computational efficiency. We test the algorithm on two fundamental computer vision problems: image clustering and object matching. Extensive experiments demonstrate that it outperforms the state-of-the-arts in both applications.\n    ",
        "submission_date": "2012-08-25T00:00:00",
        "last_modified_date": "2012-08-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1208.5365",
        "title": "A Missing and Found Recognition System for Hajj and Umrah",
        "authors": [
            "Salah A. Aly"
        ],
        "abstract": "This note describes an integrated recognition system for identifying missing and found objects as well as missing, dead, and found people during Hajj and Umrah seasons in the two Holy cities of Makkah and Madina in the Kingdom of Saudi Arabia. It is assumed that the total estimated number of pilgrims will reach 20 millions during the next decade. The ultimate goal of this system is to integrate facial recognition and object identification solutions into the Hajj and Umrah rituals. The missing and found computerized system is part of the CrowdSensing system for Hajj and Umrah crowd estimation, management and safety.\n    ",
        "submission_date": "2012-08-27T00:00:00",
        "last_modified_date": "2012-08-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1208.5451",
        "title": "Are You Imitating Me? Unsupervised Sparse Modeling for Group Activity Analysis from a Single Video",
        "authors": [
            "Zhongwei Tang",
            "Alexey Castrodad",
            "Mariano Tepper",
            "Guillermo Sapiro"
        ],
        "abstract": "A framework for unsupervised group activity analysis from a single video is here presented. Our working hypothesis is that human actions lie on a union of low-dimensional subspaces, and thus can be efficiently modeled as sparse linear combinations of atoms from a learned dictionary representing the action's primitives. Contrary to prior art, and with the primary goal of spatio-temporal action grouping, in this work only one single video segment is available for both unsupervised learning and analysis without any prior training information. After extracting simple features at a single spatio-temporal scale, we learn a dictionary for each individual in the video during each short time lapse. These dictionaries allow us to compare the individuals' actions by producing an affinity matrix which contains sufficient discriminative information about the actions in the scene leading to grouping with simple and efficient tools. With diverse publicly available real videos, we demonstrate the effectiveness of the proposed framework and its robustness to cluttered backgrounds, changes of human appearance, and action variability.\n    ",
        "submission_date": "2012-08-27T00:00:00",
        "last_modified_date": "2012-08-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1208.5842",
        "title": "Tenacious tagging of images via Mellin monomials",
        "authors": [
            "Kieran G. Larkin",
            "Peter A. Fletcher",
            "Stephen J. Hardy"
        ],
        "abstract": "We describe a method for attaching persistent metadata to an image. The method can be interpreted as a template-based blind watermarking scheme, robust to common editing operations, namely: cropping, rotation, scaling, stretching, shearing, compression, printing, scanning, noise, and color removal. Robustness is achieved through the reciprocity of the embedding and detection invariants. The embedded patterns are real onedimensional Mellin monomial patterns distributed over two-dimensions. The embedded patterns are scale invariant and can be directly embedded in an image by simple pixel addition. Detection achieves rotation and general affine invariance by signal projection using implicit Radon transformation. Embedded signals contract to one-dimension in the two-dimensional Fourier polar domain. The real signals are detected by correlation with complex Mellin monomial templates. Using a unique template of 4 chirp patterns we detect the affine signature with exquisite sensitivity and moderate security. The practical implementation achieves efficiencies through fast Fourier transform (FFT) correspondences such as the projection-slice theorem, the FFT correlation relation, and fast resampling via the chirp-z transform. The overall method utilizes orthodox spread spectrum patterns for the payload and performs well in terms of the classic robustness-capacity-visibility performance triangle. Tags are entirely imperceptible with a mean SSIM greater than 0.988 in all cases tested. Watermarked images survive almost all Stirmark attacks. The method is ideal for attaching metadata robustly to both digital and analogue images.\n    ",
        "submission_date": "2012-08-29T00:00:00",
        "last_modified_date": "2014-06-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1208.6137",
        "title": "Benchmarking recognition results on word image datasets",
        "authors": [
            "Deepak Kumar",
            "M N Anil Prasad",
            "A G Ramakrishnan"
        ],
        "abstract": "We have benchmarked the maximum obtainable recognition accuracy on various word image datasets using manual segmentation and a currently available commercial OCR. We have developed a Matlab program, with graphical user interface, for semi-automated pixel level segmentation of word images. We discuss the advantages of pixel level annotation. We have covered five databases adding up to over 3600 word images. These word images have been cropped from camera captured scene, born-digital and street view images. We recognize the segmented word image using the trial version of Nuance Omnipage OCR. We also discuss, how the degradations introduced during acquisition or inaccuracies introduced during creation of word images affect the recognition of the word present in the image. Word images for different kinds of degradations and correction for slant and curvy nature of words are also discussed. The word recognition rates obtained on ICDAR 2003, Sign evaluation, Street view, Born-digital and ICDAR 2011 datasets are 83.9%, 89.3%, 79.6%, 88.5% and 86.7% respectively.\n    ",
        "submission_date": "2012-08-30T00:00:00",
        "last_modified_date": "2012-08-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1208.6335",
        "title": "Comparative Study and Optimization of Feature-Extraction Techniques for Content based Image Retrieval",
        "authors": [
            "Aman Chadha",
            "Sushmit Mallik",
            "Ravdeep Johar"
        ],
        "abstract": "The aim of a Content-Based Image Retrieval (CBIR) system, also known as Query by Image Content (QBIC), is to help users to retrieve relevant images based on their contents. CBIR technologies provide a method to find images in large databases by using unique descriptors from a trained image. The image descriptors include texture, color, intensity and shape of the object inside an image. Several feature-extraction techniques viz., Average RGB, Color Moments, Co-occurrence, Local Color Histogram, Global Color Histogram and Geometric Moment have been critically compared in this paper. However, individually these techniques result in poor performance. So, combinations of these techniques have also been evaluated and results for the most efficient combination of techniques have been presented and optimized for each class of image query. We also propose an improvement in image retrieval performance by introducing the idea of Query modification through image cropping. It enables the user to identify a region of interest and modify the initial query to refine and personalize the image retrieval results.\n    ",
        "submission_date": "2012-08-30T00:00:00",
        "last_modified_date": "2020-07-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1208.6516",
        "title": "A two-stage denoising filter: the preprocessed Yaroslavsky filter",
        "authors": [
            "Joseph Salmon",
            "Rebecca Willett",
            "Ery Arias-Castro"
        ],
        "abstract": "This paper describes a simple image noise removal method which combines a preprocessing step with the Yaroslavsky filter for strong numerical, visual, and theoretical performance on a broad class of images. The framework developed is a two-stage approach. In the first stage the image is filtered with a classical denoising method (e.g., wavelet or curvelet thresholding). In the second stage a modification of the Yaroslavsky filter is performed on the original noisy image, where the weights of the filters are governed by pixel similarities in the denoised image from the first stage. Similar prefiltering ideas have proved effective previously in the literature, and this paper provides theoretical guarantees and important insight into why prefiltering can be effective. Empirically, this simple approach achieves very good performance for cartoon images, and can be computed much more quickly than current patch-based denoising algorithms.\n    ",
        "submission_date": "2012-08-31T00:00:00",
        "last_modified_date": "2012-08-31T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1208.6523",
        "title": "Combinatorial Gradient Fields for 2D Images with Empirically Convergent Separatrices",
        "authors": [
            "Jan Reininghaus",
            "David G\u00fcnther",
            "Ingrid Hotz",
            "Tino Weinkauf",
            "Hans Peter Seidel"
        ],
        "abstract": "This paper proposes an efficient probabilistic method that computes combinatorial gradient fields for two dimensional image data. In contrast to existing algorithms, this approach yields a geometric Morse-Smale complex that converges almost surely to its continuous counterpart when the image resolution is increased. This approach is motivated using basic ideas from probability theory and builds upon an algorithm from discrete Morse theory with a strong mathematical foundation. While a formal proof is only hinted at, we do provide a thorough numerical evaluation of our method and compare it to established algorithms.\n    ",
        "submission_date": "2012-08-31T00:00:00",
        "last_modified_date": "2012-08-31T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1209.0053",
        "title": "A Session Based Blind Watermarking Technique within the NROI of Retinal Fundus Images for Authentication Using DWT, Spread Spectrum and Harris Corner Detection",
        "authors": [
            "Nilanjan Dey",
            "Moumita Pal",
            "Achintya Das"
        ],
        "abstract": "Digital Retinal Fundus Images helps to detect various ophthalmic diseases by detecting morphological changes in optical cup, optical disc and macula. Present work proposes a method for the authentication of medical images based on Discrete Wavelet Transformation (DWT) and Spread Spectrum. Proper selection of the Non Region of Interest (NROI) for watermarking is crucial, as the area under concern has to be the least required portion conveying any medical information. Proposed method discusses both the selection of least impact area and the blind watermarking technique. Watermark is embedded within the High-High (HH) sub band. During embedding, watermarked image is dispersed within the band using a pseudo random sequence and a Session key. Watermarked image is extracted using the session key and the size of the image. In this approach the generated watermarked image having an acceptable level of imperceptibility and distortion is compared to the Original retinal image based on Peak Signal to Noise Ratio (PSNR) and correlation value.\n    ",
        "submission_date": "2012-09-01T00:00:00",
        "last_modified_date": "2012-09-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1209.0654",
        "title": "Compressive Optical Deflectometric Tomography: A Constrained Total-Variation Minimization Approach",
        "authors": [
            "Adriana Gonzalez",
            "Laurent Jacques",
            "Christophe De Vleeschouwer",
            "Philippe Antoine"
        ],
        "abstract": "Optical Deflectometric Tomography (ODT) provides an accurate characterization of transparent materials whose complex surfaces present a real challenge for manufacture and control. In ODT, the refractive index map (RIM) of a transparent object is reconstructed by measuring light deflection under multiple orientations. We show that this imaging modality can be made \"compressive\", i.e., a correct RIM reconstruction is achievable with far less observations than required by traditional Filtered Back Projection (FBP) methods. Assuming a cartoon-shape RIM model, this reconstruction is driven by minimizing the map Total-Variation under a fidelity constraint with the available observations. Moreover, two other realistic assumptions are added to improve the stability of our approach: the map positivity and a frontier condition. Numerically, our method relies on an accurate ODT sensing model and on a primal-dual minimization scheme, including easily the sensing operator and the proposed RIM constraints. We conclude this paper by demonstrating the power of our method on synthetic and experimental data under various compressive scenarios. In particular, the compressiveness of the stabilized ODT problem is demonstrated by observing a typical gain of 20 dB compared to FBP at only 5% of 360 incident light angles for moderately noisy sensing.\n    ",
        "submission_date": "2012-09-04T00:00:00",
        "last_modified_date": "2013-10-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1209.0841",
        "title": "Constructing the L2-Graph for Robust Subspace Learning and Subspace Clustering",
        "authors": [
            "Xi Peng",
            "Zhiding Yu",
            "Huajin Tang",
            "Zhang Yi"
        ],
        "abstract": "Under the framework of graph-based learning, the key to robust subspace clustering and subspace learning is to obtain a good similarity graph that eliminates the effects of errors and retains only connections between the data points from the same subspace (i.e., intra-subspace data points). Recent works achieve good performance by modeling errors into their objective functions to remove the errors from the inputs. However, these approaches face the limitations that the structure of errors should be known prior and a complex convex problem must be solved. In this paper, we present a novel method to eliminate the effects of the errors from the projection space (representation) rather than from the input space. We first prove that $\\ell_1$-, $\\ell_2$-, $\\ell_{\\infty}$-, and nuclear-norm based linear projection spaces share the property of Intra-subspace Projection Dominance (IPD), i.e., the coefficients over intra-subspace data points are larger than those over inter-subspace data points. Based on this property, we introduce a method to construct a sparse similarity graph, called L2-Graph. The subspace clustering and subspace learning algorithms are developed upon L2-Graph. Experiments show that L2-Graph algorithms outperform the state-of-the-art methods for feature extraction, image clustering, and motion segmentation in terms of accuracy, robustness, and time efficiency.\n    ",
        "submission_date": "2012-09-05T00:00:00",
        "last_modified_date": "2015-01-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1209.1181",
        "title": "FCM Based Blood Vessel Segmentation Method for Retinal Images",
        "authors": [
            "Nilanjan Dey",
            "Anamitra Bardhan Roy",
            "Moumita Pal",
            "Achintya Das"
        ],
        "abstract": "Segmentation of blood vessels in retinal images provides early diagnosis of diseases like glaucoma, diabetic retinopathy and macular degeneration. Among these diseases occurrence of Glaucoma is most frequent and has serious ocular consequences that can even lead to blindness, if it is not detected early. The clinical criteria for the diagnosis of glaucoma include intraocular pressure measurement, optic nerve head evaluation, retinal nerve fiber layer and visual field defects. This form of blood vessel segmentation helps in early detection for ophthalmic diseases, and potentially reduces the risk of blindness. The low-contrast images at the retina owing to narrow blood vessels of the retina are difficult to extract. These low contrast images are, however useful in revealing certain systemic diseases. Motivated by the goals of improving detection of such vessels, this present work proposes an algorithm for segmentation of blood vessels and compares the results between expert ophthalmologist hand-drawn ground-truths and segmented image(i.e. the output of the present work).Sensitivity, specificity, positive predictive value (PPV), positive likelihood ratio (PLR) and accuracy are used to evaluate overall ",
        "submission_date": "2012-09-06T00:00:00",
        "last_modified_date": "2012-09-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1209.1224",
        "title": "Wavelet Based Normal and Abnormal Heart Sound Identification using Spectrogram Analysis",
        "authors": [
            "Nilanjan Dey",
            "Achintya Das",
            "Sheli Sinha Chaudhuri"
        ],
        "abstract": "The present work proposes a computer-aided normal and abnormal heart sound identification based on Discrete Wavelet Transform (DWT), it being useful for tele-diagnosis of heart diseases. Due to the presence of Cumulative Frequency components in the spectrogram, DWT is applied on the spectro-gram up to n level to extract the features from the individual approximation components. One dimensional feature vector is obtained by evaluating the Row Mean of the approximation components of these spectrograms. For this present approach, the set of spectrograms has been considered as the database, rather than raw sound samples. Minimum Euclidean distance is computed between feature vector of the test sample and the feature vectors of the stored samples to identify the heart sound. By applying this algorithm, almost 82% of accuracy was achieved.\n    ",
        "submission_date": "2012-09-06T00:00:00",
        "last_modified_date": "2012-09-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1209.1558",
        "title": "A Comparative Study between Moravec and Harris Corner Detection of Noisy Images Using Adaptive Wavelet Thresholding Technique",
        "authors": [
            "Nilanjan Dey",
            "Pradipti Nandi",
            "Nilanjana Barman",
            "Debolina Das",
            "Subhabrata Chakraborty"
        ],
        "abstract": "In this paper a comparative study between Moravec and Harris Corner Detection has been done for obtaining features required to track and recognize objects within a noisy image. Corner detection of noisy images is a challenging task in image processing. Natural images often get corrupted by noise during acquisition and transmission. As Corner detection of these noisy images does not provide desired results, hence de-noising is required. Adaptive wavelet thresholding approach is applied for the same.\n    ",
        "submission_date": "2012-09-07T00:00:00",
        "last_modified_date": "2012-09-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1209.1563",
        "title": "Wavelet Based QRS Complex Detection of ECG Signal",
        "authors": [
            "Sayantan Mukhopadhyay",
            "Shouvik Biswas",
            "Anamitra Bardhan Roy",
            "Nilanjan Dey"
        ],
        "abstract": "The Electrocardiogram (ECG) is a sensitive diagnostic tool that is used to detect various cardiovascular diseases by measuring and recording the electrical activity of the heart in exquisite detail. A wide range of heart condition is determined by thorough examination of the features of the ECG report. Automatic extraction of time plane features is important for identification of vital cardiac diseases. This paper presents a multi-resolution wavelet transform based system for detection 'P', 'Q', 'R', 'S', 'T' peaks complex from original ECG signal. 'R-R' time lapse is an important minutia of the ECG signal that corresponds to the heartbeat of the concerned person. Abrupt increase in height of the 'R' wave or changes in the measurement of the 'R-R' denote various anomalies of human heart. Similarly 'P-P', 'Q-Q', 'S-S', 'T-T' also corresponds to different anomalies of heart and their peak amplitude also envisages other cardiac diseases. In this proposed method the 'PQRST' peaks are marked and stored over the entire signal and the time interval between two consecutive 'R' peaks and other peaks interval are measured to detect anomalies in behavior of heart, if any. The peaks are achieved by the composition of Daubeheissub bands wavelet of original ECG signal. The accuracy of the 'PQRST' complex detection and interval measurement is achieved up to 100% with high exactitude by processing and thresholding the original ECG signal.\n    ",
        "submission_date": "2012-09-07T00:00:00",
        "last_modified_date": "2012-09-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1209.1759",
        "title": "Difference of Normals as a Multi-Scale Operator in Unorganized Point Clouds",
        "authors": [
            "Yani Ioannou",
            "Babak Taati",
            "Robin Harrap",
            "Michael Greenspan"
        ],
        "abstract": "A novel multi-scale operator for unorganized 3D point clouds is introduced. The Difference of Normals (DoN) provides a computationally efficient, multi-scale approach to processing large unorganized 3D point clouds. The application of DoN in the multi-scale filtering of two different real-world outdoor urban LIDAR scene datasets is quantitatively and qualitatively demonstrated. In both datasets the DoN operator is shown to segment large 3D point clouds into scale-salient clusters, such as cars, people, and lamp posts towards applications in semi-automatic annotation, and as a pre-processing step in automatic object recognition. The application of the operator to segmentation is evaluated on a large public dataset of outdoor LIDAR scenes with ground truth annotations.\n    ",
        "submission_date": "2012-09-08T00:00:00",
        "last_modified_date": "2012-09-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1209.1788",
        "title": "On the Use of Lee's Protocol for Speckle-Reducing Techniques",
        "authors": [
            "Elsa E. Moschetti",
            "M. Gabriela Palacio",
            "Mery Picco",
            "Oscar H. Bustos",
            "Alejandro C. Frery"
        ],
        "abstract": "This paper presents two new MAP (Maximum a Posteriori) filters for speckle noise reduction and a Monte Carlo procedure for the assessment of their performance. In order to quantitatively evaluate the results obtained using these new filters, with respect to classical ones, a Monte Carlo extension of Lee's protocol is proposed. This extension of the protocol shows that its original version leads to inconsistencies that hamper its use as a general procedure for filter assessment. Some solutions for these inconsistencies are proposed, and a consistent comparison of speckle-reducing filters is provided.\n    ",
        "submission_date": "2012-09-09T00:00:00",
        "last_modified_date": "2012-09-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1209.2082",
        "title": "Blind Image Deblurring by Spectral Properties of Convolution Operators",
        "authors": [
            "Guangcan Liu",
            "Shiyu Chang",
            "Yi Ma"
        ],
        "abstract": "In this paper, we study the problem of recovering a sharp version of a given blurry image when the blur kernel is unknown. Previous methods often introduce an image-independent regularizer (such as Gaussian or sparse priors) on the desired blur kernel. We shall show that the blurry image itself encodes rich information about the blur kernel. Such information can be found through analyzing and comparing how the spectrum of an image as a convolution operator changes before and after blurring. Our analysis leads to an effective convex regularizer on the blur kernel which depends only on the given blurry image. We show that the minimizer of this regularizer guarantees to give good approximation to the blur kernel if the original image is sharp enough. By combining this powerful regularizer with conventional image deblurring techniques, we show how we could significantly improve the deblurring results through simulations and experiments on real images. In addition, our analysis and experiments help explaining a widely accepted doctrine; that is, the edges are good features for deblurring.\n    ",
        "submission_date": "2012-09-10T00:00:00",
        "last_modified_date": "2014-04-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1209.2295",
        "title": "Multimodal diffusion geometry by joint diagonalization of Laplacians",
        "authors": [
            "Davide Eynard",
            "Klaus Glashoff",
            "Michael M. Bronstein",
            "Alexander M. Bronstein"
        ],
        "abstract": "We construct an extension of diffusion geometry to multiple modalities through joint approximate diagonalization of Laplacian matrices. This naturally extends classical data analysis tools based on spectral geometry, such as diffusion maps and spectral clustering. We provide several synthetic and real examples of manifold learning, retrieval, and clustering demonstrating that the joint diffusion geometry frequently better captures the inherent structure of multi-modal data. We also show that many previous attempts to construct multimodal spectral clustering can be seen as particular cases of joint approximate diagonalization of the Laplacians.\n    ",
        "submission_date": "2012-09-11T00:00:00",
        "last_modified_date": "2012-09-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1209.2515",
        "title": "Wavelet Based Image Coding Schemes : A Recent Survey",
        "authors": [
            "V. J. Rehna",
            "M. K. Jeya Kumar"
        ],
        "abstract": "A variety of new and powerful algorithms have been developed for image compression over the years. Among them the wavelet-based image compression schemes have gained much popularity due to their overlapping nature which reduces the blocking artifacts that are common phenomena in JPEG compression and multiresolution character which leads to superior energy compaction with high quality reconstructed images. This paper provides a detailed survey on some of the popular wavelet coding techniques such as the Embedded Zerotree Wavelet (EZW) coding, Set Partitioning in Hierarchical Tree (SPIHT) coding, the Set Partitioned Embedded Block (SPECK) Coder, and the Embedded Block Coding with Optimized Truncation (EBCOT) algorithm. Other wavelet-based coding techniques like the Wavelet Difference Reduction (WDR) and the Adaptive Scanned Wavelet Difference Reduction (ASWDR) algorithms, the Space Frequency Quantization (SFQ) algorithm, the Embedded Predictive Wavelet Image Coder (EPWIC), Compression with Reversible Embedded Wavelet (CREW), the Stack-Run (SR) coding and the recent Geometric Wavelet (GW) coding are also discussed. Based on the review, recommendations and discussions are presented for algorithm development and implementation.\n    ",
        "submission_date": "2012-09-12T00:00:00",
        "last_modified_date": "2012-09-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1209.2696",
        "title": "Visual Tracking with Similarity Matching Ratio",
        "authors": [
            "Aysegul Dundar",
            "Jonghoon Jin",
            "Eugenio Culurciello"
        ],
        "abstract": "This paper presents a novel approach to visual tracking: Similarity Matching Ratio (SMR). The traditional approach of tracking is minimizing some measures of the difference between the template and a patch from the frame. This approach is vulnerable to outliers and drastic appearance changes and an extensive study is focusing on making the approach more tolerant to them. However, this often results in longer, corrective algo- rithms which do not solve the original problem. This paper proposes a novel approach to the definition of the tracking problems, SMR, which turns the differences into a probability measure. Only pixel differences below a threshold count towards deciding the match, the rest are ignored. This approach makes the SMR tracker robust to outliers and points that dramaticaly change appearance. The SMR tracker is tested on challenging video sequences and achieved state-of-the-art performance.\n    ",
        "submission_date": "2012-09-12T00:00:00",
        "last_modified_date": "2012-09-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1209.2816",
        "title": "Hirarchical Digital Image Inpainting Using Wavelets",
        "authors": [
            "S. Padmavathi",
            "B. Priyalakshmi. Dr. K. P. Soman"
        ],
        "abstract": "Inpainting is the technique of reconstructing unknown or damaged portions of an image in a visually plausible way. Inpainting algorithm automatically fills the damaged region in an image using the information available in undamaged region. Propagation of structure and texture information becomes a challenge as the size of damaged area increases. In this paper, a hierarchical inpainting algorithm using wavelets is proposed. The hierarchical method tries to keep the mask size smaller while wavelets help in handling the high pass structure information and low pass texture information separately. The performance of the proposed algorithm is tested using different factors. The results of our algorithm are compared with existing methods such as interpolation, diffusion and exemplar techniques.\n    ",
        "submission_date": "2012-09-13T00:00:00",
        "last_modified_date": "2012-09-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1209.2903",
        "title": "A Novel Approach of Harris Corner Detection of Noisy Images using Adaptive Wavelet Thresholding Technique",
        "authors": [
            "Nilanjan Dey",
            "Pradipti Nandi",
            "Nilanjana Barman"
        ],
        "abstract": "In this paper we propose a method of corner detection for obtaining features which is required to track and recognize objects within a noisy image. Corner detection of noisy images is a challenging task in image processing. Natural images often get corrupted by noise during acquisition and transmission. Though Corner detection of these noisy images does not provide desired results, hence de-noising is required. Adaptive wavelet thresholding approach is applied for the same.\n    ",
        "submission_date": "2012-09-13T00:00:00",
        "last_modified_date": "2012-09-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1209.3113",
        "title": "Detection and Classification of Viewer Age Range Smart Signs at TV Broadcast",
        "authors": [
            "Baran Tander",
            "Atilla \u00d6zmen",
            "Murat Ba\u015fkan"
        ],
        "abstract": "In this paper, the identification and classification of Viewer Age Range Smart Signs, designed by the Radio and Television Supreme Council of Turkey, to give age range information for the TV viewers, are realized. Therefore, the automatic detection at the broadcast will be possible, enabling the manufacturing of TV receivers which are sensible to these signs. The most important step at this process is the pattern recognition. Since the symbols that must be identified are circular, various circle detection techniques can be employed. In our study, first, two different circle segmentation methods for still images are analyzed, their advantages and drawbacks are discussed. A popular neural network structure called Multilayer Perceptron is employed for the classification. Afterwards, the same procedures are carried out for streaming video. All of the steps depicted above are realized on a standard PC.\n    ",
        "submission_date": "2012-09-14T00:00:00",
        "last_modified_date": "2012-09-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1209.3433",
        "title": "A Hajj And Umrah Location Classification System For Video Crowded Scenes",
        "authors": [
            "Hossam M. Zawbaa",
            "Salah A. Aly",
            "Adnan A. Gutub"
        ],
        "abstract": "In this paper, a new automatic system for classifying ritual locations in diverse Hajj and Umrah video scenes is investigated. This challenging subject has mostly been ignored in the past due to several problems one of which is the lack of realistic annotated video datasets. HUER Dataset is defined to model six different Hajj and Umrah ritual locations[26].\n",
        "submission_date": "2012-09-15T00:00:00",
        "last_modified_date": "2012-09-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1209.4317",
        "title": "Image Super-Resolution via Sparse Bayesian Modeling of Natural Images",
        "authors": [
            "Haichao Zhang",
            "David Wipf",
            "Yanning Zhang"
        ],
        "abstract": "Image super-resolution (SR) is one of the long-standing and active topics in image processing community. A large body of works for image super resolution formulate the problem with Bayesian modeling techniques and then obtain its Maximum-A-Posteriori (MAP) solution, which actually boils down to a regularized regression task over separable regularization term. Although straightforward, this approach cannot exploit the full potential offered by the probabilistic modeling, as only the posterior mode is sought. Also, the separable property of the regularization term can not capture any correlations between the sparse coefficients, which sacrifices much on its modeling accuracy. We propose a Bayesian image SR algorithm via sparse modeling of natural images. The sparsity property of the latent high resolution image is exploited by introducing latent variables into the high-order Markov Random Field (MRF) which capture the content adaptive variance by pixel-wise adaptation. The high-resolution image is estimated via Empirical Bayesian estimation scheme, which is substantially faster than our previous approach based on Markov Chain Monte Carlo sampling [1]. It is shown that the actual cost function for the proposed approach actually incorporates a non-factorial regularization term over the sparse coefficients. Experimental results indicate that the proposed method can generate competitive or better results than \\emph{state-of-the-art} SR algorithms.\n    ",
        "submission_date": "2012-09-19T00:00:00",
        "last_modified_date": "2012-09-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1209.4419",
        "title": "Head Frontal-View Identification Using Extended LLE",
        "authors": [
            "Chao Wang"
        ],
        "abstract": "Automatic head frontal-view identification is challenging due to appearance variations caused by pose changes, especially without any training samples. In this paper, we present an unsupervised algorithm for identifying frontal view among multiple facial images under various yaw poses (derived from the same person). Our approach is based on Locally Linear Embedding (LLE), with the assumption that with yaw pose being the only variable, the facial images should lie in a smooth and low dimensional manifold. We horizontally flip the facial images and present two K-nearest neighbor protocols for the original images and the flipped images, respectively. In the proposed extended LLE, for any facial image (original or flipped one), we search (1) the Ko nearest neighbors among the original facial images and (2) the Kf nearest neighbors among the flipped facial images to construct the same neighborhood graph. The extended LLE eliminates the differences (because of background, face position and scale in the whole image and some asymmetry of left-right face) between the original facial image and the flipped facial image at the same yaw pose so that the flipped facial images can be used effectively. Our approach does not need any training samples as prior information. The experimental results show that the frontal view of head can be identified reliably around the lowest point of the pose manifold for multiple facial images, especially the cropped facial images (little background and centered face).\n    ",
        "submission_date": "2012-09-20T00:00:00",
        "last_modified_date": "2012-09-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1209.4420",
        "title": "An Efficient Color Face Verification Based on 2-Directional 2-Dimensional Feature Extraction",
        "authors": [
            "Lan-Ting LI"
        ],
        "abstract": "A novel and uniform framework for face verification is presented in this paper. First of all, a 2-directional 2-dimensional feature extraction method is adopted to extract client-specific template - 2D discrimant projection matrix. Then the face skin color information is utilized as an additive feature to enhance decision making strategy that makes use of not only 2D grey feature but also 2D skin color feature. A fusion decision of both is applied to experiment the performance on the XM2VTS database according to Lausanne protocol. Experimental results show that the framework achieves high verification accuracy and verification speed.\n    ",
        "submission_date": "2012-09-20T00:00:00",
        "last_modified_date": "2012-09-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1209.5039",
        "title": "Creation of Digital Test Form for Prepress Department",
        "authors": [
            "Jaswinder Singh Dilawari",
            "Ravinder Khanna"
        ],
        "abstract": "The main problem in colour management in prepress department is lack of availability of literature on colour management and knowledge gap between prepress department and press department. So a digital test from has been created by Adobe Photoshop to analyse the ICC profile and to create a new profile and this analysed data is used to study about various grey scale of RGB and CMYK images. That helps in conversion of image from RGB to CMYK in prepress department.\n    ",
        "submission_date": "2012-09-23T00:00:00",
        "last_modified_date": "2012-09-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1209.5040",
        "title": "Image Classification and Optimized Image Reproduction",
        "authors": [
            "Jaswinder Singh Dilawari",
            "Ravinder Khanna"
        ],
        "abstract": "By taking into account the properties and limitations of the human visual system, images can be more efficiently compressed, colors more accurately reproduced, prints better rendered. To show all these advantages in this paper new adapted color charts have been created based on technical and visual image category analysis. A number of tests have been carried out using extreme images with their key information strictly in dark and light areas. It was shown that the image categorization using the adapted color charts improves the analysis of relevant image information with regard to both the image gradation and the detail reproduction. The images with key information in hi-key areas were also test printed using the adapted color charts.\n    ",
        "submission_date": "2012-09-23T00:00:00",
        "last_modified_date": "2012-09-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1209.5041",
        "title": "An Implementation of Computer Graphics as Prepress Image Enhancement Process",
        "authors": [
            "Jaswinder Singh Dilawari",
            "Ravinder Khanna"
        ],
        "abstract": "The production of a printed product involves three stages: prepress, the printing process (press) itself, and finishing (post press). There are various types of equipments (printers, scanners) and various qualities image are present in the market. These give different color rendering each time during reproduction. So, a color key tool has been developed keeping Color Management Scheme (CMS) in mind so that during reproduction no color rendering takes place irrespective of use of any device and resolution level has also been improved.\n    ",
        "submission_date": "2012-09-23T00:00:00",
        "last_modified_date": "2012-09-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1209.5111",
        "title": "Making a Science of Model Search",
        "authors": [
            "J. Bergstra",
            "D. Yamins",
            "D. D. Cox"
        ],
        "abstract": "Many computer vision algorithms depend on a variety of parameter choices and settings that are typically hand-tuned in the course of evaluating the algorithm. While such parameter tuning is often presented as being incidental to the algorithm, correctly setting these parameter choices is frequently critical to evaluating a method's full potential. Compounding matters, these parameters often must be re-tuned when the algorithm is applied to a new problem domain, and the tuning process itself often depends on personal experience and intuition in ways that are hard to describe. Since the performance of a given technique depends on both the fundamental quality of the algorithm and the details of its tuning, it can be difficult to determine whether a given technique is genuinely better, or simply better tuned.\n",
        "submission_date": "2012-09-23T00:00:00",
        "last_modified_date": "2012-09-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1209.5245",
        "title": "Spike Timing Dependent Competitive Learning in Recurrent Self Organizing Pulsed Neural Networks Case Study: Phoneme and Word Recognition",
        "authors": [
            "Tarek Behi",
            "Najet Arous",
            "Noureddine Ellouze"
        ],
        "abstract": "Synaptic plasticity seems to be a capital aspect of the dynamics of neural networks. It is about the physiological modifications of the synapse, which have like consequence a variation of the value of the synaptic weight. The information encoding is based on the precise timing of single spike events that is based on the relative timing of the pre- and post-synaptic spikes, local synapse competitions within a single neuron and global competition via lateral connections. In order to classify temporal sequences, we present in this paper how to use a local hebbian learning, spike-timing dependent plasticity for unsupervised competitive learning, preserving self-organizing maps of spiking neurons. In fact we present three variants of self-organizing maps (SOM) with spike-timing dependent Hebbian learning rule, the Leaky Integrators Neurons (LIN), the Spiking_SOM and the recurrent Spiking_SOM (RSSOM) models. The case study of the proposed SOM variants is phoneme classification and word recognition in continuous speech and speaker independent.\n    ",
        "submission_date": "2012-09-24T00:00:00",
        "last_modified_date": "2012-09-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1209.5417",
        "title": "Model based neuro-fuzzy ASR on Texas processor",
        "authors": [
            "Hesam Ekhtiyar",
            "Mehdi Sheida",
            "Somaye Sobati Moghadam"
        ],
        "abstract": "In this paper an algorithm for recognizing speech has been proposed. The recognized speech is used to execute related commands which use the MFCC and two kind of classifiers, first one uses MLP and second one uses fuzzy inference system as a classifier. The experimental results demonstrate the high gain and efficiency of the proposed algorithm. We have implemented this system based on graphical design and tested on a fix point digital signal processor (DSP) of 600 MHz, with reference DM6437-EVM of Texas instrument.\n    ",
        "submission_date": "2012-09-24T00:00:00",
        "last_modified_date": "2012-09-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1209.5494",
        "title": "Segmentation of Breast Regions in Mammogram Based on Density: A Review",
        "authors": [
            "Nafiza Saidin",
            "Harsa Amylia Mat Sakim",
            "Umi Kalthum Ngah",
            "Ibrahim Lutfi Shuaib"
        ],
        "abstract": "The focus of this paper is to review approaches for segmentation of breast regions in mammograms according to breast density. Studies based on density have been undertaken because of the relationship between breast cancer and density. Breast cancer usually occurs in the fibroglandular area of breast tissue, which appears bright on mammograms and is described as breast density. Most of the studies are focused on the classification methods for glandular tissue detection. Others highlighted on the segmentation methods for fibroglandular tissue, while few researchers performed segmentation of the breast anatomical regions based on density. There have also been works on the segmentation of other specific parts of breast regions such as either detection of nipple position, skin-air interface or pectoral muscles. The problems on the evaluation performance of the segmentation results in relation to ground truth are also discussed in this paper.\n    ",
        "submission_date": "2012-09-25T00:00:00",
        "last_modified_date": "2012-09-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1209.5756",
        "title": "Environmental Sounds Spectrogram Classification using Log-Gabor Filters and Multiclass Support Vector Machines",
        "authors": [
            "Sameh Souli",
            "Zied Lachiri"
        ],
        "abstract": "This paper presents novel approaches for efficient feature extraction using environmental sound magnitude spectrogram. We propose approach based on the visual domain. This approach included three methods. The first method is based on extraction for each spectrogram a single log-Gabor filter followed by mutual information procedure. In the second method, the spectrogram is passed by the same steps of the first method but with an averaged bank of 12 log-Gabor filter. The third method consists of spectrogram segmentation into three patches, and after that for each spectrogram patch we applied the second method. The classification results prove that the second method is the most efficient in our environmental sound classification system.\n    ",
        "submission_date": "2012-09-25T00:00:00",
        "last_modified_date": "2012-09-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1209.6037",
        "title": "Reproduction of Images by Gamut Mapping and Creation of New Test Charts in Prepress Process",
        "authors": [
            "Jaswinder Singh Dilawari",
            "Ravinder Khanna"
        ],
        "abstract": "With the advent of digital images the problem of keeping picture visualization uniformity arises because each printing or scanning device has its own color chart. So, universal color profiles are made by ICC to bring uniformity in various types of devices. Keeping that color profile in mind various new color charts are created and calibrated with the help of standard IT8 test charts available in the market. The main objective to color reproduction is to produce the identical picture at device output. For that principles for gamut mapping has been designed\n    ",
        "submission_date": "2012-09-26T00:00:00",
        "last_modified_date": "2012-09-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1209.6151",
        "title": "Face Alignment Using Active Shape Model And Support Vector Machine",
        "authors": [
            "Thai Hoang Le",
            "Truong Nhat Vo"
        ],
        "abstract": "The Active Shape Model (ASM) is one of the most popular local texture models for face alignment. It applies in many fields such as locating facial features in the image, face synthesis, etc. However, the experimental results show that the accuracy of the classical ASM for some applications is not high. This paper suggests some improvements on the classical ASM to increase the performance of the model in the application: face alignment. Four of our major improvements include: i) building a model combining Sobel filter and the 2-D profile in searching face in image; ii) applying Canny algorithm for the enhancement edge on image; iii) Support Vector Machine (SVM) is used to classify landmarks on face, in order to determine exactly location of these landmarks support for ASM; iv)automatically adjust 2-D profile in the multi-level model based on the size of the input image. The experimental results on Caltech face database and Technical University of Denmark database (imm_face) show that our proposed improvement leads to far better performance.\n    ",
        "submission_date": "2012-09-27T00:00:00",
        "last_modified_date": "2012-09-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1209.6189",
        "title": "The Biometric Menagerie - A Fuzzy and Inconsistent Concept",
        "authors": [
            "Nicolaie Popescu-Bodorin",
            "Valentina E. Balas",
            "Iulia M. Motoc"
        ],
        "abstract": "This paper proves that in iris recognition, the concepts of sheep, goats, lambs and wolves - as proposed by Doddington and Yager in the so-called Biometric Menagerie, are at most fuzzy and at least not quite well defined. They depend not only on the users or on their biometric templates, but also on the parameters that calibrate the iris recognition system. This paper shows that, in the case of iris recognition, the extensions of these concepts have very unsharp and unstable (non-stationary) boundaries. The membership of a user to these categories is more often expressed as a degree (as a fuzzy value) rather than as a crisp value. Moreover, they are defined by fuzzy Sugeno rules instead of classical (crisp) definitions. For these reasons, we said that the Biometric Menagerie proposed by Doddington and Yager could be at most a fuzzy concept of biometry, but even this status is conditioned by improving its definition. All of these facts are confirmed experimentally in a series of 12 exhaustive iris recognition tests undertaken for University of Bath Iris Image Database while using three different iris code dimensions (256x16, 128x8 and 64x4), two different iris texture encoders (Log-Gabor and Haar-Hilbert) and two different types of safety models.\n    ",
        "submission_date": "2012-09-27T00:00:00",
        "last_modified_date": "2012-09-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1209.6190",
        "title": "Noise Influence on the Fuzzy-Linguistic Partitioning of Iris Code Space",
        "authors": [
            "Iulia M. Motoc",
            "Cristina M. Noaica",
            "Robert Badea",
            "Claudiu G. Ghica"
        ],
        "abstract": "This paper analyses the set of iris codes stored or used in an iris recognition system as an f-granular space. The f-granulation is given by identifying in the iris code space the extensions of the fuzzy concepts wolves, goats, lambs and sheep (previously introduced by Doddington as 'animals' of the biometric menagerie) - which together form a partitioning of the iris code space. The main question here is how objective (stable / stationary) this partitioning is when the iris segments are subject to noisy acquisition. In order to prove that the f-granulation of iris code space with respect to the fuzzy concepts that define the biometric menagerie is unstable in noisy conditions (is sensitive to noise), three types of noise (localvar, motion blur, salt and pepper) have been alternatively added to the iris segments extracted from University of Bath Iris Image Database. The results of 180 exhaustive (all-to-all) iris recognition tests are presented and commented here.\n    ",
        "submission_date": "2012-09-27T00:00:00",
        "last_modified_date": "2012-09-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1209.6204",
        "title": "Reclassification formula that provides to surpass K-means method",
        "authors": [
            "M. Kharinov"
        ],
        "abstract": "The paper presents a formula for the reclassification of multidimensional data points (columns of real numbers, \"objects\", \"vectors\", etc.). This formula describes the change in the total squared error caused by reclassification of data points from one cluster into another and prompts the way to calculate the sequence of optimal partitions, which are characterized by a minimum value of the total squared error E (weighted sum of within-class variance, within-cluster sum of squares WCSS etc.), i.e. the sum of squared distances from each data point to its cluster center. At that source data points are treated with repetitions allowed, and resulting clusters from different partitions, in general case, overlap each other. The final partitions are characterized by \"equilibrium\" stability with respect to the reclassification of the data points, where the term \"stability\" means that any prescribed reclassification of data points does not increase the total squared error E. It is important that conventional K-means method, in general case, provides generation of instable partitions with overstated values of the total squared error E. The proposed method, based on the formula of reclassification, is more efficient than K-means method owing to converting of any partition into stable one, as well as involving into the process of reclassification of certain sets of data points, in contrast to the classification of individual data points according to K-means method.\n    ",
        "submission_date": "2012-09-27T00:00:00",
        "last_modified_date": "2012-09-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1209.6491",
        "title": "Review of Statistical Shape Spaces for 3D Data with Comparative Analysis for Human Faces",
        "authors": [
            "Alan Brunton",
            "Augusto Salazar",
            "Timo Bolkart",
            "Stefanie Wuhrer"
        ],
        "abstract": "With systems for acquiring 3D surface data being evermore commonplace, it has become important to reliably extract specific shapes from the acquired data. In the presence of noise and occlusions, this can be done through the use of statistical shape models, which are learned from databases of clean examples of the shape in question. In this paper, we review, analyze and compare different statistical models: from those that analyze the variation in geometry globally to those that analyze the variation in geometry locally. We first review how different types of models have been used in the literature, then proceed to define the models and analyze them theoretically, in terms of both their statistical and computational aspects. We then perform extensive experimental comparison on the task of model fitting, and give intuition about which type of model is better for a few applications. Due to the wide availability of databases of high-quality data, we use the human face as the specific shape we wish to extract from corrupted data.\n    ",
        "submission_date": "2012-09-28T00:00:00",
        "last_modified_date": "2014-05-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1209.6525",
        "title": "A Complete System for Candidate Polyps Detection in Virtual Colonoscopy",
        "authors": [
            "Marcelo Fiori",
            "Pablo Mus\u00e9",
            "Guillermo Sapiro"
        ],
        "abstract": "Computer tomographic colonography, combined with computer-aided detection, is a promising emerging technique for colonic polyp analysis. We present a complete pipeline for polyp detection, starting with a simple colon segmentation technique that enhances polyps, followed by an adaptive-scale candidate polyp delineation and classification based on new texture and geometric features that consider both the information in the candidate polyp location and its immediate surrounding area. The proposed system is tested with ground truth data, including flat and small polyps which are hard to detect even with optical colonoscopy. For polyps larger than 6mm in size we achieve 100% sensitivity with just 0.9 false positives per case, and for polyps larger than 3mm in size we achieve 93% sensitivity with 2.8 false positives per case.\n    ",
        "submission_date": "2012-09-28T00:00:00",
        "last_modified_date": "2012-09-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1210.0026",
        "title": "Coupled quasi-harmonic bases",
        "authors": [
            "A. Kovnatsky",
            "M.M.Bronstein",
            "A.M.Bronstein",
            "K. Glashoff",
            "R. Kimmel"
        ],
        "abstract": "The use of Laplacian eigenbases has been shown to be fruitful in many computer graphics applications. Today, state-of-the-art approaches to shape analysis, synthesis, and correspondence rely on these natural harmonic bases that allow using classical tools from harmonic analysis on manifolds. However, many applications involving multiple shapes are obstacled by the fact that Laplacian eigenbases computed independently on different shapes are often incompatible with each other. In this paper, we propose the construction of common approximate eigenbases for multiple shapes using approximate joint diagonalization algorithms. We illustrate the benefits of the proposed approach on tasks from shape editing, pose transfer, correspondence, and similarity.\n    ",
        "submission_date": "2012-09-28T00:00:00",
        "last_modified_date": "2012-09-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1210.0052",
        "title": "Dimensionality Reduction and Classification feature using Mutual Information applied to Hyperspectral Images : A Filter strategy based algorithm",
        "authors": [
            "ELkebir Sarhrouni",
            "Ahmed Hammouch",
            "Driss Aboutajdine"
        ],
        "abstract": "Hyperspectral images (HIS) classification is a high technical remote sensing tool. The goal is to reproduce a thematic map that will be compared with a reference ground truth map (GT), constructed by expecting the region. The HIS contains more than a hundred bidirectional measures, called bands (or simply images), of the same region. They are taken at juxtaposed frequencies. Unfortunately, some bands contain redundant information, others are affected by the noise, and the high dimensionality of features made the accuracy of classification lower. The problematic is how to find the good bands to classify the pixels of regions. Some methods use Mutual Information (MI) and threshold, to select relevant bands, without treatment of redundancy. Others control and eliminate redundancy by selecting the band top ranking the MI, and if its neighbors have sensibly the same MI with the GT, they will be considered redundant and so discarded. This is the most inconvenient of this method, because this avoids the advantage of hyperspectral images: some precious information can be discarded. In this paper we'll accept the useful redundancy. A band contains useful redundancy if it contributes to produce an estimated reference map that has higher MI with the ",
        "submission_date": "2012-09-28T00:00:00",
        "last_modified_date": "2012-09-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1210.0115",
        "title": "Demosaicing and Superresolution for Color Filter Array via Residual Image Reconstruction and Sparse Representation",
        "authors": [
            "Guangling Sun"
        ],
        "abstract": "A framework of demosaicing and superresolution for color filter array (CFA) via residual image reconstruction and sparse representation is ",
        "submission_date": "2012-09-29T00:00:00",
        "last_modified_date": "2013-07-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1210.0153",
        "title": "A Low Cost Vision Based Hybrid Fiducial Mark Tracking Technique for Mobile Industrial Robots",
        "authors": [
            "Mohammed Y Aalsalem",
            "Wazir Zada Khan",
            "Quratul Ain Arshad"
        ],
        "abstract": "The field of robotic vision is developing rapidly. Robots can react intelligently and provide assistance to user activities through sentient computing. Since industrial applications pose complex requirements that cannot be handled by humans, an efficient low cost and robust technique is required for the tracking of mobile industrial robots. The existing sensor based techniques for mobile robot tracking are expensive and complex to deploy, configure and maintain. Also some of them demand dedicated and often expensive hardware. This paper presents a low cost vision based technique called Hybrid Fiducial Mark Tracking (HFMT) technique for tracking mobile industrial robot. HFMT technique requires off-the-shelf hardware (CCD cameras) and printable 2-D circular marks used as fiducials for tracking a mobile industrial robot on a pre-defined path. This proposed technique allows the robot to track on a predefined path by using fiducials for the detection of Right and Left turns on the path and White Strip for tracking the path. The HFMT technique is implemented and tested on an indoor mobile robot at our laboratory. Experimental results from robot navigating in real environments have confirmed that our approach is simple and robust and can be adopted in any hostile industrial environment where humans are unable to work.\n    ",
        "submission_date": "2012-09-29T00:00:00",
        "last_modified_date": "2012-09-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1210.0310",
        "title": "Intra-Retinal Layer Segmentation of 3D Optical Coherence Tomography Using Coarse Grained Diffusion Map",
        "authors": [
            "Raheleh Kafieh",
            "Hossein Rabbani",
            "Michael D. Abramoff",
            "Milan Sonka"
        ],
        "abstract": "Optical coherence tomography (OCT) is a powerful and noninvasive method for retinal imaging. In this paper, we introduce a fast segmentation method based on a new variant of spectral graph theory named diffusion maps. The research is performed on spectral domain (SD) OCT images depicting macular and optic nerve head appearance. The presented approach does not require edge-based image information and relies on regional image texture. Consequently, the proposed method demonstrates robustness in situations of low image contrast or poor layer-to-layer image gradients. Diffusion mapping is applied to 2D and 3D OCT datasets composed of two steps, one for partitioning the data into important and less important sections, and another one for localization of internal ",
        "submission_date": "2012-10-01T00:00:00",
        "last_modified_date": "2012-10-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1210.0347",
        "title": "Enhanced Techniques for PDF Image Segmentation and Text Extraction",
        "authors": [
            "D. Sasirekha",
            "E. Chandra"
        ],
        "abstract": "Extracting text objects from the PDF images is a challenging problem. The text data present in the PDF images contain certain useful information for automatic annotation, indexing etc. However variations of the text due to differences in text style, font, size, orientation, alignment as well as complex structure make the problem of automatic text extraction extremely difficult and challenging job. This paper presents two techniques under block-based classification. After a brief introduction of the classification methods, two methods were enhanced and results were evaluated. The performance metrics for segmentation and time consumption are tested for both the models.\n    ",
        "submission_date": "2012-10-01T00:00:00",
        "last_modified_date": "2012-10-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1210.0386",
        "title": "Combined Descriptors in Spatial Pyramid Domain for Image Classification",
        "authors": [
            "Junlin Hu",
            "Ping Guo"
        ],
        "abstract": "Recently spatial pyramid matching (SPM) with scale invariant feature transform (SIFT) descriptor has been successfully used in image classification. Unfortunately, the codebook generation and feature quantization procedures using SIFT feature have the high complexity both in time and space. To address this problem, in this paper, we propose an approach which combines local binary patterns (LBP) and three-patch local binary patterns (TPLBP) in spatial pyramid domain. The proposed method does not need to learn the codebook and feature quantization processing, hence it becomes very efficient. Experiments on two popular benchmark datasets demonstrate that the proposed method always significantly outperforms the very popular SPM based SIFT descriptor method both in time and classification accuracy.\n    ",
        "submission_date": "2012-10-01T00:00:00",
        "last_modified_date": "2012-10-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1210.0528",
        "title": "Band Selection and Classification of Hyperspectral Images using Mutual Information: An algorithm based on minimizing the error probability using the inequality of Fano",
        "authors": [
            "Elkebir Sarhrouni",
            "Ahmed Hammouch",
            "Driss Aboutajdine"
        ],
        "abstract": "Hyperspectral image is a substitution of more than a hundred images, called bands, of the same region. They are taken at juxtaposed frequencies. The reference image of the region is called Ground Truth map (GT). the problematic is how to find the good bands to classify the pixels of regions; because the bands can be not only redundant, but a source of confusion, and decreasing so the accuracy of classification. Some methods use Mutual Information (MI) and threshold, to select relevant bands. Recently there's an algorithm selection based on mutual information, using bandwidth rejection and a threshold to control and eliminate redundancy. The band top ranking the MI is selected, and if its neighbors have sensibly the same MI with the GT, they will be considered redundant and so discarded. This is the most inconvenient of this method, because this avoids the advantage of hyperspectral images: some precious information can be discarded. In this paper we'll make difference between useful and useless redundancy. A band contains useful redundancy if it contributes to decreasing error probability. According to this scheme, we introduce new algorithm using also mutual information, but it retains only the bands minimizing the error probability of classification. To control redundancy, we introduce a complementary threshold. So the good band candidate must contribute to decrease the last error probability augmented by the threshold. This process is a wrapper strategy; it gets high performance of classification accuracy but it is expensive than filter strategy.\n    ",
        "submission_date": "2012-09-28T00:00:00",
        "last_modified_date": "2012-09-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1210.0564",
        "title": "Super-resolution using Sparse Representations over Learned Dictionaries: Reconstruction of Brain Structure using Electron Microscopy",
        "authors": [
            "Tao Hu",
            "Juan Nunez-Iglesias",
            "Shiv Vitaladevuni",
            "Lou Scheffer",
            "Shan Xu",
            "Mehdi Bolorizadeh",
            "Harald Hess",
            "Richard Fetter",
            "Dmitri Chklovskii"
        ],
        "abstract": "A central problem in neuroscience is reconstructing neuronal circuits on the synapse level. Due to a wide range of scales in brain architecture such reconstruction requires imaging that is both high-resolution and high-throughput. Existing electron microscopy (EM) techniques possess required resolution in the lateral plane and either high-throughput or high depth resolution but not both. Here, we exploit recent advances in unsupervised learning and signal processing to obtain high depth-resolution EM images computationally without sacrificing throughput. First, we show that the brain tissue can be represented as a sparse linear combination of localized basis functions that are learned using high-resolution datasets. We then develop compressive sensing-inspired techniques that can reconstruct the brain tissue from very few (typically 5) tomographic views of each section. This enables tracing of neuronal processes and, hence, high throughput reconstruction of neural circuits on the level of individual synapses.\n    ",
        "submission_date": "2012-10-01T00:00:00",
        "last_modified_date": "2012-10-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1210.0818",
        "title": "Multibiometric: Feature Level Fusion Using FKP Multi-Instance biometric",
        "authors": [
            "Harbi AlMahafzah",
            "Mohammad Imran",
            "H.S. Sheshadri"
        ],
        "abstract": "This paper proposed the use of multi-instance feature level fusion as a means to improve the performance of Finger Knuckle Print (FKP) verification. A log-Gabor filter has been used to extract the image local orientation information, and represent the FKP features. Experiments are performed using the FKP database, which consists of 7,920 images. Results indicate that the multi-instance verification approach outperforms higher performance than using any single instance. The influence on biometric performance using feature level fusion under different fusion rules have been demonstrated in this paper.\n    ",
        "submission_date": "2012-10-02T00:00:00",
        "last_modified_date": "2012-10-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1210.0829",
        "title": "A Survey of Multibiometric Systems",
        "authors": [
            "Harbi AlMahafzah",
            "Maen Zaid AlRwashdeh"
        ],
        "abstract": "Most biometric systems deployed in real-world applications are unimodal. Using unimodal biometric systems have to contend with a variety of problems such as: Noise in sensed data; Intra-class variations; Inter-class similarities; Non-universality; Spoof attacks. These problems have addressed by using multibiometric systems, which expected to be more reliable due to the presence of multiple, independent pieces of evidence.\n    ",
        "submission_date": "2012-10-02T00:00:00",
        "last_modified_date": "2012-10-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1210.0866",
        "title": "Classification of Hepatic Lesions using the Matching Metric",
        "authors": [
            "Aaron Adcock",
            "Daniel Rubin",
            "Gunnar Carlsson"
        ],
        "abstract": "In this paper we present a methodology of classifying hepatic (liver) lesions using multidimensional persistent homology, the matching metric (also called the bottleneck distance), and a support vector machine. We present our classification results on a dataset of 132 lesions that have been outlined and annotated by radiologists. We find that topological features are useful in the classification of hepatic lesions. We also find that two-dimensional persistent homology outperforms one-dimensional persistent homology in this application.\n    ",
        "submission_date": "2012-10-02T00:00:00",
        "last_modified_date": "2012-10-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1210.0880",
        "title": "Schr\u00f6dinger Diffusion for Shape Analysis with Texture",
        "authors": [
            "Jose A. Iglesias",
            "Ron Kimmel"
        ],
        "abstract": "In recent years, quantities derived from the heat equation have become popular in shape processing and analysis of triangulated surfaces. Such measures are often robust with respect to different kinds of perturbations, including near-isometries, topological noise and partialities. Here, we propose to exploit the semigroup of a Schr\u00f6dinger operator in order to deal with texture data, while maintaining the desirable properties of the heat kernel. We define a family of Schr\u00f6dinger diffusion distances analogous to the ones associated to the heat kernels, and show that they are continuous under perturbations of the data. As an application, we introduce a method for retrieval of textured shapes through comparison of Schr\u00f6dinger diffusion distance histograms with the earth's mover distance, and present some numerical experiments showing superior performance compared to an analogous method that ignores the texture.\n    ",
        "submission_date": "2012-10-02T00:00:00",
        "last_modified_date": "2012-10-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1210.1029",
        "title": "Blurred Image Classification based on Adaptive Dictionary",
        "authors": [
            "Guangling Sun",
            "Guoqing Li",
            "Jie Yin"
        ],
        "abstract": "Two types of framework for blurred image classification based on adaptive dictionary are proposed. Given a blurred image, instead of image deblurring, the semantic category of the image is determined by blur insensitive sparse coefficients calculated depending on an adaptive dictionary. The dictionary is adaptive to the Point Spread Function (PSF) estimated from input blurred image. The PSF is assumed to be space invariant and inferred separately in one framework or updated combining with sparse coefficients calculation in an alternative and iterative algorithm in the other framework. The experiment has evaluated three types of blur, naming defocus blur, simple motion blur and camera shake blur. The experiment results confirm the effectiveness of the proposed frameworks.\n    ",
        "submission_date": "2012-10-03T00:00:00",
        "last_modified_date": "2012-10-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1210.1033",
        "title": "Robust Degraded Face Recognition Using Enhanced Local Frequency Descriptor and Multi-scale Competition",
        "authors": [
            "Guangling Sun",
            "Guoqing Li",
            "Xinpeng Zhang"
        ],
        "abstract": "Recognizing degraded faces from low resolution and blurred images are common yet challenging task. Local Frequency Descriptor (LFD) has been proved to be effective for this task yet it is extracted from a spatial neighborhood of a pixel of a frequency plane independently regardless of correlations between frequencies. In addition, it uses a fixed window size named single scale of short-term Frequency transform (STFT). To explore the frequency correlations and preserve low resolution and blur insensitive simultaneously, we propose Enhanced LFD in which information in space and frequency is jointly utilized so as to be more descriptive and discriminative than LFD. The multi-scale competition strategy that extracts multiple descriptors corresponding to multiple window sizes of STFT and take one corresponding to maximum confidence as the final recognition result. The experiments conducted on Yale and FERET databases demonstrate that promising results have been achieved by the proposed Enhanced LFD and multi-scale competition strategy.\n    ",
        "submission_date": "2012-10-03T00:00:00",
        "last_modified_date": "2012-10-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1210.1230",
        "title": "Evaluating Discussion Boards on BlackBoard as a Collaborative Learning Tool A Students Survey and Reflections",
        "authors": [
            "AbdelHameed A. Badawy",
            "Michelle M. Hugue"
        ],
        "abstract": "In this paper, we investigate how the students think of their experience in a junior level course that has a blackboard course presence where the students use the discussion boards extensively. A survey is set up through blackboard as a voluntary quiz and the student who participated were given a freebie point. The results and the participation were very interesting in terms of the feedback we got via open comments from the students as well as the statistics we gathered from the answers to the questions. The students have shown understanding and willingness to participate in pedagogy-enhancing endeavors.\n    ",
        "submission_date": "2012-10-03T00:00:00",
        "last_modified_date": "2012-10-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1210.1316",
        "title": "Learning Locality-Constrained Collaborative Representation for Face Recognition",
        "authors": [
            "Xi Peng",
            "Lei Zhang",
            "Zhang Yi",
            "Kok Kiong Tan"
        ],
        "abstract": "The model of low-dimensional manifold and sparse representation are two well-known concise models that suggest each data can be described by a few characteristics. Manifold learning is usually investigated for dimension reduction by preserving some expected local geometric structures from the original space to a low-dimensional one. The structures are generally determined by using pairwise distance, e.g., Euclidean distance. Alternatively, sparse representation denotes a data point as a linear combination of the points from the same subspace. In practical applications, however, the nearby points in terms of pairwise distance may not belong to the same subspace, and vice versa. Consequently, it is interesting and important to explore how to get a better representation by integrating these two models together. To this end, this paper proposes a novel coding algorithm, called Locality-Constrained Collaborative Representation (LCCR), which improves the robustness and discrimination of data representation by introducing a kind of local consistency. The locality term derives from a biologic observation that the similar inputs have similar code. The objective function of LCCR has an analytical solution, and it does not involve local minima. The empirical studies based on four public facial databases, ORL, AR, Extended Yale B, and Multiple PIE, show that LCCR is promising in recognizing human faces from frontal views with varying expression and illumination, as well as various corruptions and occlusions.\n    ",
        "submission_date": "2012-10-04T00:00:00",
        "last_modified_date": "2013-03-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1210.1916",
        "title": "A comparative study on face recognition techniques and neural network",
        "authors": [
            "Meftah Ur Rahman"
        ],
        "abstract": "In modern times, face recognition has become one of the key aspects of computer vision. There are at least two reasons for this trend; the first is the commercial and law enforcement applications, and the second is the availability of feasible technologies after years of research. Due to the very nature of the problem, computer scientists, neuro-scientists and psychologists all share a keen interest in this field. In plain words, it is a computer application for automatically identifying a person from a still image or video frame. One of the ways to accomplish this is by comparing selected features from the image and a facial database. There are hundreds if not thousand factors associated with this. In this paper some of the most common techniques available including applications of neural network in facial recognition are studied and compared with respect to their performance.\n    ",
        "submission_date": "2012-10-06T00:00:00",
        "last_modified_date": "2012-10-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1210.2380",
        "title": "Stable and robust sampling strategies for compressive imaging",
        "authors": [
            "Felix Krahmer",
            "Rachel Ward"
        ],
        "abstract": "In many signal processing applications, one wishes to acquire images that are sparse in transform domains such as spatial finite differences or wavelets using frequency domain samples. For such applications, overwhelming empirical evidence suggests that superior image reconstruction can be obtained through variable density sampling strategies that concentrate on lower frequencies. The wavelet and Fourier transform domains are not incoherent because low-order wavelets and low-order frequencies are correlated, so compressive sensing theory does not immediately imply sampling strategies and reconstruction guarantees. In this paper we turn to a more refined notion of coherence -- the so-called local coherence -- measuring for each sensing vector separately how correlated it is to the sparsity basis. For Fourier measurements and Haar wavelet sparsity, the local coherence can be controlled and bounded explicitly, so for matrices comprised of frequencies sampled from a suitable inverse square power-law density, we can prove the restricted isometry property with near-optimal embedding dimensions. Consequently, the variable-density sampling strategy we provide allows for image reconstructions that are stable to sparsity defects and robust to measurement noise. Our results cover both reconstruction by $\\ell_1$-minimization and by total variation minimization. The local coherence framework developed in this paper should be of independent interest in sparse recovery problems more generally, as it implies that for optimal sparse recovery results, it suffices to have bounded \\emph{average} coherence from sensing basis to sparsity basis -- as opposed to bounded maximal coherence -- as long as the sampling strategy is adapted accordingly.\n    ",
        "submission_date": "2012-10-08T00:00:00",
        "last_modified_date": "2013-10-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1210.2388",
        "title": "Video De-fencing",
        "authors": [
            "Yadong Mu",
            "Wei Liu",
            "Shuicheng Yan"
        ],
        "abstract": "This paper describes and provides an initial solution to a novel video editing task, i.e., video de-fencing. It targets automatic restoration of the video clips that are corrupted by fence-like occlusions during capture. Our key observation lies in the visual parallax between fences and background scenes, which is caused by the fact that the former are typically closer to the camera. Unlike in traditional image inpainting, fence-occluded pixels in the videos tend to appear later in the temporal dimension and are therefore recoverable via optimized pixel selection from relevant frames. To eventually produce fence-free videos, major challenges include cross-frame sub-pixel image alignment under diverse scene depth, and \"correct\" pixel selection that is robust to dominating fence pixels. Several novel tools are developed in this paper, including soft fence detection, weighted truncated optical flow method and robust temporal median filter. The proposed algorithm is validated on several real-world video clips with fences.\n    ",
        "submission_date": "2012-10-08T00:00:00",
        "last_modified_date": "2012-10-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1210.2474",
        "title": "Level Set Estimation from Compressive Measurements using Box Constrained Total Variation Regularization",
        "authors": [
            "Akshay Soni",
            "Jarvis Haupt"
        ],
        "abstract": "Estimating the level set of a signal from measurements is a task that arises in a variety of fields, including medical imaging, astronomy, and digital elevation mapping. Motivated by scenarios where accurate and complete measurements of the signal may not available, we examine here a simple procedure for estimating the level set of a signal from highly incomplete measurements, which may additionally be corrupted by additive noise. The proposed procedure is based on box-constrained Total Variation (TV) regularization. We demonstrate the performance of our approach, relative to existing state-of-the-art techniques for level set estimation from compressive measurements, via several simulation examples.\n    ",
        "submission_date": "2012-10-09T00:00:00",
        "last_modified_date": "2012-10-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1210.2629",
        "title": "Optimization in Differentiable Manifolds in Order to Determine the Method of Construction of Prehistoric Wall-Paintings",
        "authors": [
            "Dimitris Arabadjis",
            "Panayiotis Rousopoulos",
            "Constantin Papaodysseus",
            "Michalis Exarhos",
            "Michalis Panagopoulos",
            "Lena Papazoglou-Manioudaki"
        ],
        "abstract": "In this paper a general methodology is introduced for the determination of potential prototype curves used for the drawing of prehistoric wall-paintings. The approach includes a) preprocessing of the wall-paintings contours to properly partition them, according to their curvature, b) choice of prototype curves families, c) analysis and optimization in 4-manifold for a first estimation of the form of these prototypes, d) clustering of the contour parts and the prototypes, to determine a minimal number of potential guides, e) further optimization in 4-manifold, applied to each cluster separately, in order to determine the exact functional form of the potential guides, together with the corresponding drawn contour parts. The introduced methodology simultaneously deals with two problems: a) the arbitrariness in data-points orientation and b) the determination of one proper form for a prototype curve that optimally fits the corresponding contour data. Arbitrariness in orientation has been dealt with a novel curvature based error, while the proper forms of curve prototypes have been exhaustively determined by embedding curvature deformations of the prototypes into 4-manifolds. Application of this methodology to celebrated wall-paintings excavated at Tyrins, Greece and the Greek island of Thera, manifests it is highly probable that these wall-paintings had been drawn by means of geometric guides that correspond to linear spirals and hyperbolae. These geometric forms fit the drawings' lines with an exceptionally low average error, less than 0.39mm. Hence, the approach suggests the existence of accurate realizations of complicated geometric entities, more than 1000 years before their axiomatic formulation in Classical Ages.\n    ",
        "submission_date": "2012-10-09T00:00:00",
        "last_modified_date": "2012-10-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1210.2646",
        "title": "A General Methodology for the Determination of 2D Bodies Elastic Deformation Invariants. Application to the Automatic Identification of Parasites",
        "authors": [
            "Dimitris Arabadjis",
            "Panayiotis Rousopoulos",
            "Constantin Papaodysseus",
            "Michalis Panagopoulos",
            "Panayiota Loumou",
            "Georgios Theodoropoulos"
        ],
        "abstract": "A novel methodology is introduced here that exploits 2D images of arbitrary elastic body deformation instances, so as to quantify mechano-elastic characteristics that are deformation invariant. Determination of such characteristics allows for developing methods offering an image of the undeformed body. General assumptions about the mechano-elastic properties of the bodies are stated, which lead to two different approaches for obtaining bodies' deformation invariants. One was developed to spot deformed body's neutral line and its cross sections, while the other solves deformation PDEs by performing a set of equivalent image operations on the deformed body images. Both these processes may furnish a body undeformed version from its deformed image. This was confirmed by obtaining the undeformed shape of deformed parasites, cells (protozoa), fibers and human lips. In addition, the method has been applied to the important problem of parasite automatic classification from their microscopic images. To achieve this, we first apply the previous method to straighten the highly deformed parasites and then we apply a dedicated curve classification method to the straightened parasite contours. It is demonstrated that essentially different deformations of the same parasite give rise to practically the same undeformed shape, thus confirming the consistency of the introduced methodology. Finally, the developed pattern recognition method classifies the unwrapped parasites into 6 families, with an accuracy rate of 97.6 %.\n    ",
        "submission_date": "2012-10-09T00:00:00",
        "last_modified_date": "2012-10-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1210.2826",
        "title": "An anisotropy preserving metric for DTI processing",
        "authors": [
            "Anne Collard",
            "Silv\u00e8re Bonnabel",
            "Christophe Phillips",
            "Rodolphe Sepulchre"
        ],
        "abstract": "Statistical analysis of Diffusion Tensor Imaging (DTI) data requires a computational framework that is both numerically tractable (to account for the high dimensional nature of the data) and geometric (to account for the nonlinear nature of diffusion tensors). Building upon earlier studies that have shown that a Riemannian framework is appropriate to address these challenges, the present paper proposes a novel metric and an accompanying computational framework for DTI data processing. The proposed metric retains the geometry and the computational tractability of earlier methods grounded in the affine invariant metric. In addition, and in contrast to earlier methods, it provides an interpolation method which preserves anisotropy, a central information carried by diffusion tensor data.\n    ",
        "submission_date": "2012-10-10T00:00:00",
        "last_modified_date": "2012-10-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1210.2838",
        "title": "Kinects and Human Kinetics: A New Approach for Studying Crowd Behavior",
        "authors": [
            "Stefan Seer",
            "Norbert Br\u00e4ndle",
            "Carlo Ratti"
        ],
        "abstract": "Modeling crowd behavior relies on accurate data of pedestrian movements at a high level of detail. Imaging sensors such as cameras provide a good basis for capturing such detailed pedestrian motion data. However, currently available computer vision technologies, when applied to conventional video footage, still cannot automatically unveil accurate motions of groups of people or crowds from the image sequences. We present a novel data collection approach for studying crowd behavior which uses the increasingly popular low-cost sensor Microsoft Kinect. The Kinect captures both standard camera data and a three-dimensional depth map. Our human detection and tracking algorithm is based on agglomerative clustering of depth data captured from an elevated view - in contrast to the lateral view used for gesture recognition in Kinect gaming applications. Our approach transforms local Kinect 3D data to a common world coordinate system in order to stitch together human trajectories from multiple Kinects, which allows for a scalable and flexible capturing area. At a testbed with real-world pedestrian traffic we demonstrate that our approach can provide accurate trajectories from three Kinects with a Pedestrian Detection Rate of up to 94% and a Multiple Object Tracking Precision of 4 cm. Using a comprehensive dataset of 2240 captured human trajectories we calibrate three variations of the Social Force model. The results of our model validations indicate their particular ability to reproduce the observed crowd behavior in microscopic simulations.\n    ",
        "submission_date": "2012-10-10T00:00:00",
        "last_modified_date": "2012-10-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1210.2877",
        "title": "Efficient Solution to the 3D Problem of Automatic Wall Paintings Reassembly",
        "authors": [
            "Constantin Papaodysseus",
            "Dimitris Arabadjis",
            "Michalis Exarhos",
            "Panayiotis Rousopoulos",
            "Solomon Zannos",
            "Michail Panagopoulos",
            "Lena Papazoglou-Manioudaki"
        ],
        "abstract": "This paper introduces a new approach for the automated reconstruction - reassembly of fragmented objects having one surface near to plane, on the basis of the 3D representation of their constituent fragments. The whole process starts by 3D scanning of the available fragments. The obtained representations are properly processed so that they can be tested for possible matches. Next, four novel criteria are introduced, that lead to the determination of pairs of matching fragments. These criteria have been chosen so as the whole process imitates the instinctive reassembling method dedicated scholars apply. The first criterion exploits the volume of the gap between two properly placed fragments. The second one considers the fragments' overlapping in each possible matching position. Criteria 3,4 employ principles from calculus of variations to obtain bounds for the area and the mean curvature of the contact surfaces and the length of contact curves, which must hold if the two fragments match. The method has been applied, with great success, both in the reconstruction of objects artificially broken by the authors and, most importantly, in the virtual reassembling of parts of wall paintings belonging to the Mycenaic civilization (c. 1300 B.C.), excavated in a highly fragmented condition in Tyrins, Greece.\n    ",
        "submission_date": "2012-10-10T00:00:00",
        "last_modified_date": "2012-10-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1210.3165",
        "title": "Computationally Efficient Implementation of Convolution-based Locally Adaptive Binarization Techniques",
        "authors": [
            "Ayatullah Faruk Mollah",
            "Subhadip Basu",
            "Mita Nasipuri"
        ],
        "abstract": "One of the most important steps of document image processing is binarization. The computational requirements of locally adaptive binarization techniques make them unsuitable for devices with limited computing facilities. In this paper, we have presented a computationally efficient implementation of convolution based locally adaptive binarization techniques keeping the performance comparable to the original implementation. The computational complexity has been reduced from O(W2N2) to O(WN2) where WxW is the window size and NxN is the image size. Experiments over benchmark datasets show that the computation time has been reduced by 5 to 15 times depending on the window size while memory consumption remains the same with respect to the state-of-the-art algorithmic implementation.\n    ",
        "submission_date": "2012-10-11T00:00:00",
        "last_modified_date": "2012-10-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1210.3350",
        "title": "Enhanced Compressed Sensing Recovery with Level Set Normals",
        "authors": [
            "Virginia Estellers",
            "Jean-Philippe Thiran",
            "Xavier Bresson"
        ],
        "abstract": "We propose a compressive sensing algorithm that exploits geometric properties of images to recover images of high quality from few measurements. The image reconstruction is done by iterating the two following steps: 1) estimation of normal vectors of the image level curves and 2) reconstruction of an image fitting the normal vectors, the compressed sensing measurements and the sparsity constraint. The proposed technique can naturally extend to non local operators and graphs to exploit the repetitive nature of textured images in order to recover fine detail structures. In both cases, the problem is reduced to a series of convex minimization problems that can be efficiently solved with a combination of variable splitting and augmented Lagrangian methods, leading to fast and easy-to-code algorithms. Extended experiments show a clear improvement over related state-of-the-art algorithms in the quality of the reconstructed images and the robustness of the proposed method to noise, different kind of images and reduced measurements.\n    ",
        "submission_date": "2012-10-11T00:00:00",
        "last_modified_date": "2012-10-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1210.3404",
        "title": "A polygon-based interpolation operator for super-resolution imaging",
        "authors": [
            "St\u00e9fan J. van der Walt",
            "B. M. Herbst"
        ],
        "abstract": "We outline the super-resolution reconstruction problem posed as a maximization of probability. We then introduce an interpolation method based on polygonal pixel overlap, express it as a linear operator, and use it to improve reconstruction. Polygon interpolation outperforms the simpler bilinear interpolation operator and, unlike Gaussian modeling of pixels, requires no parameter estimation. A free software implementation that reproduces the results shown is provided.\n    ",
        "submission_date": "2012-10-12T00:00:00",
        "last_modified_date": "2012-10-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1210.3448",
        "title": "Notes on image annotation",
        "authors": [
            "Adela Barriuso",
            "Antonio Torralba"
        ],
        "abstract": "We are under the illusion that seeing is effortless, but frequently the visual system is lazy and makes us believe that we understand something when in fact we don't. Labeling a picture forces us to become aware of the difficulties underlying scene understanding. Suddenly, the act of seeing is not effortless anymore. We have to make an effort in order to understand parts of the picture that we neglected at first glance.\n",
        "submission_date": "2012-10-12T00:00:00",
        "last_modified_date": "2012-10-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1210.3718",
        "title": "On the Role of Contrast and Regularity in Perceptual Boundary Saliency",
        "authors": [
            "Mariano Tepper",
            "Pablo Mus\u00e9",
            "Andr\u00e9s Almansa"
        ],
        "abstract": "Mathematical Morphology proposes to extract shapes from images as connected components of level sets. These methods prove very suitable for shape recognition and analysis. We present a method to select the perceptually significant (i.e., contrasted) level lines (boundaries of level sets), using the Helmholtz principle as first proposed by Desolneux et al. Contrarily to the classical formulation by Desolneux et al. where level lines must be entirely salient, the proposed method allows to detect partially salient level lines, thus resulting in more robust and more stable detections. We then tackle the problem of combining two gestalts as a measure of saliency and propose a method that reinforces detections. Results in natural images show the good performance of the proposed methods.\n    ",
        "submission_date": "2012-10-13T00:00:00",
        "last_modified_date": "2012-10-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1210.3832",
        "title": "Image Processing using Smooth Ordering of its Patches",
        "authors": [
            "Idan Ram",
            "Michael Elad",
            "Israel Cohen"
        ],
        "abstract": "We propose an image processing scheme based on reordering of its patches. For a given corrupted image, we extract all patches with overlaps, refer to these as coordinates in high-dimensional space, and order them such that they are chained in the \"shortest possible path\", essentially solving the traveling salesman problem. The obtained ordering applied to the corrupted image, implies a permutation of the image pixels to what should be a regular signal. This enables us to obtain good recovery of the clean image by applying relatively simple 1D smoothing operations (such as filtering or interpolation) to the reordered set of pixels. We explore the use of the proposed approach to image denoising and inpainting, and show promising results in both cases.\n    ",
        "submission_date": "2012-10-14T00:00:00",
        "last_modified_date": "2012-10-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1210.4481",
        "title": "Epitome for Automatic Image Colorization",
        "authors": [
            "Yingzhen Yang",
            "Xinqi Chu",
            "Tian-Tsong Ng",
            "Alex Yong-Sang Chia",
            "Shuicheng Yan",
            "Thomas S. Huang"
        ],
        "abstract": "Image colorization adds color to grayscale images. It not only increases the visual appeal of grayscale images, but also enriches the information contained in scientific images that lack color information. Most existing methods of colorization require laborious user interaction for scribbles or image segmentation. To eliminate the need for human labor, we develop an automatic image colorization method using epitome. Built upon a generative graphical model, epitome is a condensed image appearance and shape model which also proves to be an effective summary of color information for the colorization task. We train the epitome from the reference images and perform inference in the epitome to colorize grayscale images, rendering better colorization results than previous method in our experiments.\n    ",
        "submission_date": "2012-10-08T00:00:00",
        "last_modified_date": "2012-10-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1210.4863",
        "title": "DBN-Based Combinatorial Resampling for Articulated Object Tracking",
        "authors": [
            "Severine Dubuisson",
            "Christophe Gonzales",
            "Xuan Son NGuyen"
        ],
        "abstract": "Particle Filter is an effective solution to track objects in video sequences in complex situations. Its key idea is to estimate the density over the possible states of the object using a weighted sample whose elements are called particles. One of its crucial step is a resampling step in which particles are resampled to avoid some degeneracy problem. In this paper, we introduce a new resampling method called Combinatorial Resampling that exploits some features of articulated objects to resample over an implicitly created sample of an exponential size better representing the density to estimate. We prove that it is sound and, through experimentations both on challenging synthetic and real video sequences, we show that it outperforms all classical resampling methods both in terms of the quality of its results and in terms of response times.\n    ",
        "submission_date": "2012-10-16T00:00:00",
        "last_modified_date": "2012-10-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1210.5644",
        "title": "Efficient Inference in Fully Connected CRFs with Gaussian Edge Potentials",
        "authors": [
            "Philipp Kr\u00e4henb\u00fchl",
            "Vladlen Koltun"
        ],
        "abstract": "Most state-of-the-art techniques for multi-class image segmentation and labeling use conditional random fields defined over pixels or image regions. While region-level models often feature dense pairwise connectivity, pixel-level models are considerably larger and have only permitted sparse graph structures. In this paper, we consider fully connected CRF models defined on the complete set of pixels in an image. The resulting graphs have billions of edges, making traditional inference algorithms impractical. Our main contribution is a highly efficient approximate inference algorithm for fully connected CRF models in which the pairwise edge potentials are defined by a linear combination of Gaussian kernels. Our experiments demonstrate that dense connectivity at the pixel level substantially improves segmentation and labeling accuracy.\n    ",
        "submission_date": "2012-10-20T00:00:00",
        "last_modified_date": "2012-10-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1210.5653",
        "title": "Identifications of concealed weapon in a Human Body",
        "authors": [
            "Prof. Samir K. Bandyopadhyay",
            "Biswajita Datta",
            "Sudipta Roy"
        ],
        "abstract": "The detection of weapons concealed underneath a person cloths is very much important to the improvement of the security of the public as well as the safety of public assets like airports, buildings and railway stations etc.\n    ",
        "submission_date": "2012-10-20T00:00:00",
        "last_modified_date": "2012-10-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1210.5732",
        "title": "Developing ICC Profile Using Gray Level Control In Offset Printing Process",
        "authors": [
            "Jaswinder Singh Dilawari",
            "Ravinder Khanna"
        ],
        "abstract": "In prepress department RGB image has to be converted to CMYK image. To control that amount of black, cyan, magenta and yellow has to be controlled by using color separation method. Graycolor separation method is selected to control the amounts of these colors because it increase the quality of printing also. A single printer used for printing the same image on different paper also results in different printed images. To remove this problem a different ICC profile based on gray level control is developedand a sheet offset printer is calibrated using that profile and a subjective evaluation shows satisfactory results for different quality papers.\n    ",
        "submission_date": "2012-10-21T00:00:00",
        "last_modified_date": "2012-10-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1210.6157",
        "title": "Novel Architecture for 3D model in virtual communities from detected face",
        "authors": [
            "Vibekananda Dutta",
            "Dr Nishtha Kesswani",
            "Deepti Gahalot"
        ],
        "abstract": "In this research paper we suggest how to extract a face from an image, modify it, characterize it in terms of high-level properties, and apply it to the creation of a personalized avatar. In this research work we tested, we implemented the algorithm on several hundred facial images, including many taken under uncontrolled acquisition conditions, and found to exhibit satisfactory performance for immediate practical use.\n    ",
        "submission_date": "2012-10-23T00:00:00",
        "last_modified_date": "2012-10-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1210.6192",
        "title": "Textural Approach to Palmprint Identification",
        "authors": [
            "Rachita Misra",
            "Kasturika B ray"
        ],
        "abstract": "Biometrics which use of human physiological characteristics for identifying an individual is now a widespread method of identification and authentication. Biometric identification is a technology which uses several image processing techniques and describes the general procedure for identification and verification using feature extraction, storage and matching from the digitized image of biometric characters such as Finger Print, Face, Iris or Palm Print. The current paper uses palm print biometrics. Here we have presented an identification approach using textural properties of palm print images. The elegance of the method is that the conventional edge detection technique is extended to suitably describe the texture features. In this technique all the characteristics of the palm such as principal lines, edges and wrinkles are considered with equal importance.\n    ",
        "submission_date": "2012-10-23T00:00:00",
        "last_modified_date": "2012-10-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1210.7014",
        "title": "Computer vision tools for the non-invasive assessment of autism-related behavioral markers",
        "authors": [
            "Jordan Hashemi",
            "Thiago Vallin Spina",
            "Mariano Tepper",
            "Amy Esler",
            "Vassilios Morellas",
            "Nikolaos Papanikolopoulos",
            "Guillermo Sapiro"
        ],
        "abstract": "The early detection of developmental disorders is key to child outcome, allowing interventions to be initiated that promote development and improve prognosis. Research on autism spectrum disorder (ASD) suggests behavioral markers can be observed late in the first year of life. Many of these studies involved extensive frame-by-frame video observation and analysis of a child's natural behavior. Although non-intrusive, these methods are extremely time-intensive and require a high level of observer training; thus, they are impractical for clinical and large population research purposes. Diagnostic measures for ASD are available for infants but are only accurate when used by specialists experienced in early diagnosis. This work is a first milestone in a long-term multidisciplinary project that aims at helping clinicians and general practitioners accomplish this early detection/measurement task automatically. We focus on providing computer vision tools to measure and identify ASD behavioral markers based on components of the Autism Observation Scale for Infants (AOSI). In particular, we develop algorithms to measure three critical AOSI activities that assess visual attention. We augment these AOSI activities with an additional test that analyzes asymmetrical patterns in unsupported gait. The first set of algorithms involves assessing head motion by tracking facial features, while the gait analysis relies on joint foreground segmentation and 2D body pose estimation in video. We show results that provide insightful knowledge to augment the clinician's behavioral observations obtained from real in-clinic assessments.\n    ",
        "submission_date": "2012-10-25T00:00:00",
        "last_modified_date": "2012-11-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1210.7038",
        "title": "Full Object Boundary Detection by Applying Scale Invariant Features in a Region Merging Segmentation Algorithm",
        "authors": [
            "Reza Oji",
            "Farshad Tajeripour"
        ],
        "abstract": "Object detection is a fundamental task in computer vision and has many applications in image processing. This paper proposes a new approach for object detection by applying scale invariant feature transform (SIFT) in an automatic segmentation algorithm. SIFT is an invariant algorithm respect to scale, translation and rotation. The features are very distinct and provide stable keypoints that can be used for matching an object in different images. At first, an object is trained with different aspects for finding best keypoints. The object can be recognized in the other images by using achieved keypoints. Then, a robust segmentation algorithm is used to detect the object with full boundary based on SIFT keypoints. In segmentation algorithm, a merging role is defined to merge the regions in image with the assistance of keypoints. The results show that the proposed approach is reliable for object detection and can extract object boundary well.\n    ",
        "submission_date": "2012-10-26T00:00:00",
        "last_modified_date": "2012-10-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1210.7070",
        "title": "A Multiscale Framework for Challenging Discrete Optimization",
        "authors": [
            "Shai Bagon",
            "Meirav Galun"
        ],
        "abstract": "Current state-of-the-art discrete optimization methods struggle behind when it comes to challenging contrast-enhancing discrete energies (i.e., favoring different labels for neighboring variables). This work suggests a multiscale approach for these challenging problems. Deriving an algebraic representation allows us to coarsen any pair-wise energy using any interpolation in a principled algebraic manner. Furthermore, we propose an energy-aware interpolation operator that efficiently exposes the multiscale landscape of the energy yielding an effective coarse-to-fine optimization scheme. Results on challenging contrast-enhancing energies show significant improvement over state-of-the-art methods.\n    ",
        "submission_date": "2012-10-26T00:00:00",
        "last_modified_date": "2012-11-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1210.7102",
        "title": "3D Face Recognition using Significant Point based SULD Descriptor",
        "authors": [
            "B. H. Shekar",
            "N. Harivinod",
            "M. Sharmila Kumari",
            "K. Raghurama Holla"
        ],
        "abstract": "In this work, we present a new 3D face recognition method based on Speeded-Up Local Descriptor (SULD) of significant points extracted from the range images of faces. The proposed model consists of a method for extracting distinctive invariant features from range images of faces that can be used to perform reliable matching between different poses of range images of faces. For a given 3D face scan, range images are computed and the potential interest points are identified by searching at all scales. Based on the stability of the interest point, significant points are extracted. For each significant point we compute the SULD descriptor which consists of vector made of values from the convolved Haar wavelet responses located on concentric circles centred on the significant point, and where the amount of Gaussian smoothing is proportional to the radii of the circles. Experimental results show that the newly proposed method provides higher recognition rate compared to other existing contemporary models developed for 3D face recognition.\n    ",
        "submission_date": "2012-10-26T00:00:00",
        "last_modified_date": "2012-10-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1210.7362",
        "title": "Discrete Energy Minimization, beyond Submodularity: Applications and Approximations",
        "authors": [
            "Shai Bagon"
        ],
        "abstract": "In this thesis I explore challenging discrete energy minimization problems that arise mainly in the context of computer vision tasks. This work motivates the use of such \"hard-to-optimize\" non-submodular functionals, and proposes methods and algorithms to cope with the NP-hardness of their optimization. Consequently, this thesis revolves around two axes: applications and approximations. The applications axis motivates the use of such \"hard-to-optimize\" energies by introducing new tasks. As the energies become less constrained and structured one gains more expressive power for the objective function achieving more accurate models. Results show how challenging, hard-to-optimize, energies are more adequate for certain computer vision applications. To overcome the resulting challenging optimization tasks the second axis of this thesis proposes approximation algorithms to cope with the NP-hardness of the optimization. Experiments show that these new methods yield good results for representative challenging problems.\n    ",
        "submission_date": "2012-10-27T00:00:00",
        "last_modified_date": "2012-11-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1210.7403",
        "title": "Resolution Enhancement of Range Images via Color-Image Segmentation",
        "authors": [
            "Arnav Bhavsar"
        ],
        "abstract": "We report a method for super-resolution of range images. Our approach leverages the interpretation of LR image as sparse samples on the HR grid. Based on this interpretation, we demonstrate that our recently reported approach, which reconstructs dense range images from sparse range data by exploiting a registered colour image, can be applied for the task of resolution enhancement of range images. Our method only uses a single colour image in addition to the range observation in the super-resolution process. Using the proposed approach, we demonstrate super-resolution results for large factors (e.g. 4) with good localization accuracy.\n    ",
        "submission_date": "2012-10-28T00:00:00",
        "last_modified_date": "2012-10-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1210.7461",
        "title": "Recognizing Static Signs from the Brazilian Sign Language: Comparing Large-Margin Decision Directed Acyclic Graphs, Voting Support Vector Machines and Artificial Neural Networks",
        "authors": [
            "C\u00e9sar Roberto de Souza",
            "Ednaldo Brigante Pizzolato",
            "Mauro dos Santos Anjo"
        ],
        "abstract": "In this paper, we explore and detail our experiments in a high-dimensionality, multi-class image classification problem often found in the automatic recognition of Sign Languages. Here, our efforts are directed towards comparing the characteristics, advantages and drawbacks of creating and training Support Vector Machines disposed in a Directed Acyclic Graph and Artificial Neural Networks to classify signs from the Brazilian Sign Language (LIBRAS). We explore how the different heuristics, hyperparameters and multi-class decision schemes affect the performance, efficiency and ease of use for each classifier. We provide hyperparameter surface maps capturing accuracy and efficiency, comparisons between DDAGs and 1-vs-1 SVMs, and effects of heuristics when training ANNs with Resilient Backpropagation. We report statistically significant results using Cohen's Kappa statistic for contingency tables.\n    ",
        "submission_date": "2012-10-28T00:00:00",
        "last_modified_date": "2012-10-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1210.7631",
        "title": "The fortresses of Ejin: an example of outlining a site from satellite images",
        "authors": [
            "Amelia Carolina Sparavigna"
        ],
        "abstract": "From 1960's to 1970's, the Chinese Army built some fortified artificial hills. Some of them are located in the Inner Mongolia, Western China. These large fortresses are surrounded by moats. For some of them it is still possible to see earthworks, trenches and ditches, the planning of which could have a symbolic meaning. We can argue this result form their digital outlining, obtained after an image processing of satellite images, based on edge detection.\n    ",
        "submission_date": "2012-10-29T00:00:00",
        "last_modified_date": "2012-10-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1210.7669",
        "title": "Performance Evaluation of Different Techniques for texture Classification",
        "authors": [
            "Pooja Maknikar"
        ],
        "abstract": "Texture is the term used to characterize the surface of a given object or phenomenon and is an important feature used in image processing and pattern recognition. Our aim is to compare various Texture analyzing methods and compare the results based on time complexity and accuracy of classification. The project describes texture classification using Wavelet Transform and Co occurrence Matrix. Comparison of features of a sample texture with database of different textures is performed. In wavelet transform we use the Haar, Symlets and Daubechies wavelets. We find that, thee Haar wavelet proves to be the most efficient method in terms of performance assessment parameters mentioned above. Comparison of Haar wavelet and Co-occurrence matrix method of classification also goes in the favor of Haar. Though the time requirement is high in the later method, it gives excellent results for classification accuracy except if the image is rotated.\n    ",
        "submission_date": "2012-10-29T00:00:00",
        "last_modified_date": "2012-10-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1210.8262",
        "title": "On the Relation Between the Common Labelling and the Median Graph",
        "authors": [
            "Nicola Rebagliati",
            "Albert Sol\u00e9-Ribalta",
            "Marcello Pelillo",
            "Francesc Serratosa"
        ],
        "abstract": "In structural pattern recognition, given a set of graphs, the computation of a Generalized Median Graph is a well known problem. Some methods approach the problem by assuming a relation between the Generalized Median Graph and the Common Labelling problem. However, this relation has still not been formally proved. In this paper, we analyse such relation between both problems. The main result proves that the cost of the common labelling upper-bounds the cost of the median with respect to the given set. In addition, we show that the two problems are equivalent in some cases.\n    ",
        "submission_date": "2012-10-31T00:00:00",
        "last_modified_date": "2012-10-31T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1210.8318",
        "title": "Mugshot Identification from Manipulated Facial Images",
        "authors": [
            "H. R. Chennamma",
            "Lalitha Rangarajan"
        ],
        "abstract": "Editing on digital images is ubiquitous. Identification of deliberately modified facial images is a new challenge for face identification system. In this paper, we address the problem of identification of a face or person from heavily altered facial images. In this face identification problem, the input to the system is a manipulated or transformed face image and the system reports back the determined identity from a database of known individuals. Such a system can be useful in mugshot identification in which mugshot database contains two views (frontal and profile) of each criminal. We considered only frontal view from the available database for face identification and the query image is a manipulated face generated by face transformation software tool available online. We propose SIFT features for efficient face identification in this scenario. Further comparative analysis has been given with well known eigenface approach. Experiments have been conducted with real case images to evaluate the performance of both methods.\n    ",
        "submission_date": "2012-10-31T00:00:00",
        "last_modified_date": "2012-10-31T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1211.0055",
        "title": "Dimensionality Reduction and Classification Feature Using Mutual Information Applied to Hyperspectral Images: A Wrapper Strategy Algorithm Based on Minimizing the Error Probability Using the Inequality of Fano",
        "authors": [
            "Elkebir Sarhrouni",
            "Ahmed Hammouch",
            "Driss Aboutajdine"
        ],
        "abstract": "In the feature classification domain, the choice of data affects widely the results. For the Hyperspectral image, the bands dont all contain the information; some bands are irrelevant like those affected by various atmospheric effects, see Figure.4, and decrease the classification accuracy. And there exist redundant bands to complicate the learning system and product incorrect prediction [14]. Even the bands contain enough information about the scene they may can't predict the classes correctly if the dimension of space images, see Figure.3, is so large that needs many cases to detect the relationship between the bands and the scene (Hughes phenomenon) [10]. We can reduce the dimensionality of hyperspectral images by selecting only the relevant bands (feature selection or subset selection methodology), or extracting, from the original bands, new bands containing the maximal information about the classes, using any functions, logical or numerical (feature extraction methodology) [11][9]. Here we focus on the feature selection using mutual information. Hyperspectral images have three advantages regarding the multispectral images [6],\n    ",
        "submission_date": "2012-10-31T00:00:00",
        "last_modified_date": "2012-10-31T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1211.0191",
        "title": "Performance Evaluation of Random Set Based Pedestrian Tracking Algorithms",
        "authors": [
            "Branko Ristic",
            "Jamie Sherrah",
            "\u00c1ngel F. Garc\u00eda-Fern\u00e1ndez"
        ],
        "abstract": "The paper evaluates the error performance of three random finite set based multi-object trackers in the context of pedestrian video tracking. The evaluation is carried out using a publicly available video dataset of 4500 frames (town centre street) for which the ground truth is available. The input to all pedestrian tracking algorithms is an identical set of head and body detections, obtained using the Histogram of Oriented Gradients (HOG) detector. The tracking error is measured using the recently proposed OSPA metric for tracks, adopted as the only known mathematically rigorous metric for measuring the distance between two sets of tracks. A comparative analysis is presented under various conditions.\n    ",
        "submission_date": "2012-10-25T00:00:00",
        "last_modified_date": "2012-10-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1211.0602",
        "title": "Segmentation of ultrasound images of thyroid nodule for assisting fine needle aspiration cytology",
        "authors": [
            "Jie Zhao",
            "Wei Zheng",
            "Li Zhang",
            "Hua Tian"
        ],
        "abstract": "The incidence of thyroid nodule is very high and generally increases with the age. Thyroid nodule may presage the emergence of thyroid cancer. The thyroid nodule can be completely cured if detected early. Fine needle aspiration cytology is a recognized early diagnosis method of thyroid nodule. There are still some limitations in the fine needle aspiration cytology, and the ultrasound diagnosis of thyroid nodule has become the first choice for auxiliary examination of thyroid nodular disease. If we could combine medical imaging technology and fine needle aspiration cytology, the diagnostic rate of thyroid nodule would be improved significantly. The properties of ultrasound will degrade the image quality, which makes it difficult to recognize the edges for physicians. Image segmentation technique based on graph theory has become a research hotspot at present. Normalized cut (Ncut) is a representative one, which is suitable for segmentation of feature parts of medical image. However, how to solve the normalized cut has become a problem, which needs large memory capacity and heavy calculation of weight matrix. It always generates over segmentation or less segmentation which leads to inaccurate in the segmentation. The speckle noise in B ultrasound image of thyroid tumor makes the quality of the image deteriorate. In the light of this characteristic, we combine the anisotropic diffusion model with the normalized cut in this paper. After the enhancement of anisotropic diffusion model, it removes the noise in the B ultrasound image while preserves the important edges and local details. This reduces the amount of computation in constructing the weight matrix of the improved normalized cut and improves the accuracy of the final segmentation results. The feasibility of the method is proved by the experimental results.\n    ",
        "submission_date": "2012-11-03T00:00:00",
        "last_modified_date": "2012-11-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1211.0613",
        "title": "Application of Symmetric Uncertainty and Mutual Information to Dimensionality Reduction and Classification of Hyperspectral Images",
        "authors": [
            "ELkebir Sarhrouni",
            "Ahmed Hammouch",
            "Driss Aboutajdine"
        ],
        "abstract": "Remote sensing is a technology to acquire data for disatant substances, necessary to construct a model knowledge for applications as classification. Recently Hyperspectral Images (HSI) becomes a high technical tool that the main goal is to classify the point of a region. The HIS is more than a hundred bidirectional measures, called bands (or simply images), of the same region called Ground Truth Map (GT). But some bands are not relevant because they are affected by different atmospheric effects; others contain redundant information; and high dimensionality of HSI features make the accuracy of classification lower. All these bands can be important for some applications; but for the classification a small subset of these is relevant. The problematic related to HSI is the dimensionality reduction. Many studies use mutual information (MI) to select the relevant bands. Others studies use the MI normalized forms, like Symmetric Uncertainty, in medical imagery applications. In this paper we introduce an algorithm based also on MI to select relevant bands and it apply the Symmetric Uncertainty coefficient to control redundancy and increase the accuracy of classification. This algorithm is feature selection tool and a Filter strategy. We establish this study on HSI AVIRIS 92AV3C. This is an effectiveness, and fast scheme to control redundancy.\n    ",
        "submission_date": "2012-11-03T00:00:00",
        "last_modified_date": "2012-12-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1211.1127",
        "title": "Visual Transfer Learning: Informal Introduction and Literature Overview",
        "authors": [
            "Erik Rodner"
        ],
        "abstract": "Transfer learning techniques are important to handle small training sets and to allow for quick generalization even from only a few examples. The following paper is the introduction as well as the literature overview part of my thesis related to the topic of transfer learning for visual recognition problems.\n    ",
        "submission_date": "2012-11-06T00:00:00",
        "last_modified_date": "2012-11-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1211.1252",
        "title": "Implementation of Radon Transformation for Electrical Impedance Tomography (EIT)",
        "authors": [
            "Md. Ali Hossain",
            "Ahsan-Ul-Ambia",
            "Md.Aktaruzzaman",
            "Md. Ahaduzzaman Khan"
        ],
        "abstract": "Radon Transformation is generally used to construct optical image (like CT image) from the projection data in biomedical imaging. In this paper, the concept of Radon Transformation is implemented to reconstruct Electrical Impedance Topographic Image (conductivity or resistivity distribution) of a circular subject. A parallel resistance model of a subject is proposed for Electrical Impedance Topography(EIT) or Magnetic Induction Tomography(MIT). A circular subject with embedded circular objects is segmented into equal width slices from different angles. For each angle, Conductance and Conductivity of each slice is calculated and stored in an array. A back projection method is used to generate a two-dimensional image from one-dimensional projections. As a back projection method, Inverse Radon Transformation is applied on the calculated conductance and conductivity to reconstruct two dimensional images. These images are compared to the target image. In the time of image reconstruction, different filters are used and these images are compared with each other and target image.\n    ",
        "submission_date": "2012-10-16T00:00:00",
        "last_modified_date": "2012-10-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1211.1265",
        "title": "From Bits to Images: Inversion of Local Binary Descriptors",
        "authors": [
            "Emmanuel d'Angelo",
            "Laurent jacques",
            "Alexandre Alahi",
            "Pierre Vandergheynst"
        ],
        "abstract": "Local Binary Descriptors are becoming more and more popular for image matching tasks, especially when going mobile. While they are extensively studied in this context, their ability to carry enough information in order to infer the original image is seldom addressed.\n",
        "submission_date": "2012-11-06T00:00:00",
        "last_modified_date": "2012-11-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1211.1482",
        "title": "Gender Recognition in Walk Gait through 3D Motion by Quadratic Bezier Curve and Statistical Techniques",
        "authors": [
            "Sajid Ali"
        ],
        "abstract": "Motion capture is the process of recording the movement of objects or people. It is used in military, entertainment, sports, and medical applications, and for validation of computer vision[2] and robotics. In filmmaking and video game development, it refers to recording actions of human actors, and using that information to animate digital character models in 2D or 3D computer animation. When it includes face and fingers or captures subtle\n    ",
        "submission_date": "2012-11-07T00:00:00",
        "last_modified_date": "2013-01-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1211.1544",
        "title": "Image denoising with multi-layer perceptrons, part 1: comparison with existing algorithms and with bounds",
        "authors": [
            "Harold Christopher Burger",
            "Christian J. Schuler",
            "Stefan Harmeling"
        ],
        "abstract": "Image denoising can be described as the problem of mapping from a noisy image to a noise-free image. The best currently available denoising methods approximate this mapping with cleverly engineered algorithms. In this work we attempt to learn this mapping directly with plain multi layer perceptrons (MLP) applied to image patches. We will show that by training on large image databases we are able to outperform the current state-of-the-art image denoising methods. In addition, our method achieves results that are superior to one type of theoretical bound and goes a large way toward closing the gap with a second type of theoretical bound. Our approach is easily adapted to less extensively studied types of noise, such as mixed Poisson-Gaussian noise, JPEG artifacts, salt-and-pepper noise and noise resembling stripes, for which we achieve excellent results as well. We will show that combining a block-matching procedure with MLPs can further improve the results on certain images. In a second paper, we detail the training trade-offs and the inner mechanisms of our MLPs.\n    ",
        "submission_date": "2012-11-07T00:00:00",
        "last_modified_date": "2012-11-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1211.1552",
        "title": "Image denoising with multi-layer perceptrons, part 2: training trade-offs and analysis of their mechanisms",
        "authors": [
            "Harold Christopher Burger",
            "Christian J. Schuler",
            "Stefan Harmeling"
        ],
        "abstract": "Image denoising can be described as the problem of mapping from a noisy image to a noise-free image. In another paper, we show that multi-layer perceptrons can achieve outstanding image denoising performance for various types of noise (additive white Gaussian noise, mixed Poisson-Gaussian noise, JPEG artifacts, salt-and-pepper noise and noise resembling stripes). In this work we discuss in detail which trade-offs have to be considered during the training procedure. We will show how to achieve good results and which pitfalls to avoid. By analysing the activation patterns of the hidden units we are able to make observations regarding the functioning principle of multi-layer perceptrons trained for image denoising.\n    ",
        "submission_date": "2012-11-07T00:00:00",
        "last_modified_date": "2012-11-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1211.1650",
        "title": "Different Operating Systems Compatible for Image Prepress Process in Color Management: Analysis and Performance Testing",
        "authors": [
            "Jaswinder Singh Dilawari",
            "Ravinder Khanna"
        ],
        "abstract": "Image computing has become a real catchphrase over the past few years and the interpretations of the meaning of the term vary greatly. The Imagecomputing market is currently rapidly evolving with high growth prospects and almost daily announcements of new devices and application platforms, which results in an increasing diversification of devices, operating system and development platforms. Compared to more traditional information technology markets like the one of desktop computing, mobile computing is much less consolidated and neither standards nor even industry standards have yet been established. There are various platforms and interfaces which may be used to perform the desired tasks through the device. We have tried to compare the various mobile operating systems and their trade-offs.\n    ",
        "submission_date": "2012-11-07T00:00:00",
        "last_modified_date": "2012-11-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1211.1656",
        "title": "James-Stein Type Center Pixel Weights for Non-Local Means Image Denoising",
        "authors": [
            "Yue Wu",
            "Brian Tracey",
            "Joseph P. Noonan"
        ],
        "abstract": "Non-Local Means (NLM) and variants have been proven to be effective and robust in many image denoising tasks. In this letter, we study the parameter selection problem of center pixel weights (CPW) in NLM. Our key contributions are: 1) we give a novel formulation of the CPW problem from the statistical shrinkage perspective; 2) we introduce the James-Stein type CPWs for NLM; and 3) we propose a new adaptive CPW that is locally tuned for each image pixel. Our experimental results showed that compared to existing CPW solutions, the new proposed CPWs are more robust and effective under various noise levels. In particular, the NLM with the James-Stein type CPWs attain higher means with smaller variances in terms of the peak signal and noise ratio, implying they improve the NLM robustness and make it less sensitive to parameter selection.\n    ",
        "submission_date": "2012-11-07T00:00:00",
        "last_modified_date": "2012-11-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1211.1752",
        "title": "3D Scene Grammar for Parsing RGB-D Pointclouds",
        "authors": [
            "Abhishek Anand",
            "Sherwin Li"
        ],
        "abstract": "We pose 3D scene-understanding as a problem of parsing in a grammar. A grammar helps us capture the compositional structure of real-word objects, e.g., a chair is composed of a seat, a back-rest and some legs. Having multiple rules for an object helps us capture structural variations in objects, e.g., a chair can optionally also have arm-rests. Finally, having rules to capture composition at different levels helps us formulate the entire scene-processing pipeline as a single problem of finding most likely parse-tree---small segments combine to form parts of objects, parts to objects and objects to a scene. We attach a generative probability model to our grammar by having a feature-dependent probability function for every rule. We evaluated it by extracting labels for every segment and comparing the results with the state-of-the-art segment-labeling algorithm. Our algorithm was outperformed by the state-or-the-art method. But, Our model can be trained very efficiently (within seconds), and it scales only linearly in with the number of rules in the grammar. Also, we think that this is an important problem for the 3D vision community. So, we are releasing our dataset and related code.\n    ",
        "submission_date": "2012-11-08T00:00:00",
        "last_modified_date": "2012-11-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1211.1800",
        "title": "A Comparative study of Arabic handwritten characters invariant feature",
        "authors": [
            "Hamdi Hassen",
            "Maher khemakhem"
        ],
        "abstract": "This paper is practically interested in the unchangeable feature of Arabic handwritten character. It presents results of comparative study achieved on certain features extraction techniques of handwritten character, based on Hough transform, Fourier transform, Wavelet transform and Gabor Filter. Obtained results show that Hough Transform and Gabor filter are insensible to the rotation and translation, Fourier Transform is sensible to the rotation but insensible to the translation, in contrast to Hough Transform and Gabor filter, Wavelets Transform is sensitive to the rotation as well as to the translation.\n    ",
        "submission_date": "2012-11-08T00:00:00",
        "last_modified_date": "2012-11-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1211.1968",
        "title": "Fourier-Bessel rotational invariant eigenimages",
        "authors": [
            "Zhizhen Zhao",
            "Amit Singer"
        ],
        "abstract": "We present an efficient and accurate algorithm for principal component analysis (PCA) of a large set of two dimensional images, and, for each image, the set of its uniform rotations in the plane and its reflection. The algorithm starts by expanding each image, originally given on a Cartesian grid, in the Fourier-Bessel basis for the disk. Because the images are bandlimited in the Fourier domain, we use a sampling criterion to truncate the Fourier-Bessel expansion such that the maximum amount of information is preserved without the effect of aliasing. The constructed covariance matrix is invariant to rotation and reflection and has a special block diagonal structure. PCA is efficiently done for each block separately. This Fourier-Bessel based PCA detects more meaningful eigenimages and has improved denoising capability compared to traditional PCA for a finite number of noisy images.\n    ",
        "submission_date": "2012-11-08T00:00:00",
        "last_modified_date": "2013-02-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1211.2007",
        "title": "Multi-input Multi-output Beta Wavelet Network: Modeling of Acoustic Units for Speech Recognition",
        "authors": [
            "Ridha Ejbali",
            "Mourad Zaied",
            "Chokri Ben Amar"
        ],
        "abstract": "In this paper, we propose a novel architecture of wavelet network called Multi-input Multi-output Wavelet Network MIMOWN as a generalization of the old architecture of wavelet network. This newel prototype was applied to speech recognition application especially to model acoustic unit of speech. The originality of our work is the proposal of MIMOWN to model acoustic unit of speech. This approach was proposed to overcome limitation of old wavelet network model. The use of the multi-input multi-output architecture will allows training wavelet network on various examples of acoustic units.\n    ",
        "submission_date": "2012-11-08T00:00:00",
        "last_modified_date": "2012-11-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1211.2037",
        "title": "Time Complexity Analysis of Binary Space Partitioning Scheme for Image Compression",
        "authors": [
            "Rehna V. J.",
            "M. K. Jeyakumar"
        ],
        "abstract": "Segmentation-based image coding methods provide high compression ratios when compared with traditional image coding approaches like the transform and sub band coding for low bit-rate compression applications. In this paper, a segmentation-based image coding method, namely the Binary Space Partition scheme, that divides the desired image using a recursive procedure for coding is presented. The BSP approach partitions the desired image recursively by using bisecting lines, selected from a collection of discrete optional lines, in a hierarchical manner. This partitioning procedure generates a binary tree, which is referred to as the BSP-tree representation of the desired image. The algorithm is extremely complex in computation and has high execution time. The time complexity of the BSP scheme is explored in this work.\n    ",
        "submission_date": "2012-11-09T00:00:00",
        "last_modified_date": "2012-11-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1211.2082",
        "title": "3D Surface Reconstruction of Underwater Objects",
        "authors": [
            "C. J. Prabhakar",
            "P. U. Praveen Kumar"
        ],
        "abstract": "In this paper, we propose a novel technique to reconstruct 3D surface of an underwater object using stereo images. Reconstructing the 3D surface of an underwater object is really a challenging task due to degraded quality of underwater images. There are various reason of quality degradation of underwater images i.e., non-uniform illumination of light on the surface of objects, scattering and absorption effects. Floating particles present in underwater produces Gaussian noise on the captured underwater images which degrades the quality of images. The degraded underwater images are preprocessed by applying homomorphic, wavelet denoising and anisotropic filtering sequentially. The uncalibrated rectification technique is applied to preprocessed images to rectify the left and right images. The rectified left and right image lies on a common plane. To find the correspondence points in a left and right images, we have applied dense stereo matching technique i.e., graph cut method. Finally, we estimate the depth of images using triangulation technique. The experimental result shows that the proposed method reconstruct 3D surface of underwater objects accurately using captured underwater stereo images.\n    ",
        "submission_date": "2012-11-09T00:00:00",
        "last_modified_date": "2012-11-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1211.2116",
        "title": "Localisation of Numerical Date Field in an Indian Handwritten Document",
        "authors": [
            "S Arunkumar",
            "Pallab Kumar Sahu",
            "Sudeep Gorai",
            "Kalyan Ghosh"
        ],
        "abstract": "This paper describes a method to localise all those areas which may constitute the date field in an Indian handwritten document. Spatial patterns of the date field are studied from various handwritten documents and an algorithm is developed through statistical analysis to identify those sets of connected components which may constitute the date. Common date patterns followed in India are considered to classify the date formats in different classes. Reported results demonstrate promising performance of the proposed approach\n    ",
        "submission_date": "2012-11-09T00:00:00",
        "last_modified_date": "2012-11-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1211.2150",
        "title": "NF-SAVO: Neuro-Fuzzy system for Arabic Video OCR",
        "authors": [
            "Mohamed Ben Halima",
            "Hichem karray",
            "Adel. M. Alimi",
            "Ana Fern\u00e1ndez Vila"
        ],
        "abstract": "In this paper we propose a robust approach for text extraction and recognition from video clips which is called Neuro-Fuzzy system for Arabic Video OCR. In Arabic video text recognition, a number of noise components provide the text relatively more complicated to separate from the background. Further, the characters can be moving or presented in a diversity of colors, sizes and fonts that are not uniform. Added to this, is the fact that the background is usually moving making text extraction a more intricate process. Video include two kinds of text, scene text and artificial text. Scene text is usually text that becomes part of the scene itself as it is recorded at the time of filming the scene. But artificial text is produced separately and away from the scene and is laid over it at a later stage or during the post processing time. The emergence of artificial text is consequently vigilantly directed. This type of text carries with it important information that helps in video referencing, indexing and retrieval.\n    ",
        "submission_date": "2012-11-09T00:00:00",
        "last_modified_date": "2012-11-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1211.2500",
        "title": "A New Algorithm Based Entropic Threshold for Edge Detection in Images",
        "authors": [
            "Mohamed A. El-Sayed"
        ],
        "abstract": "Edge detection is one of the most critical tasks in automatic image analysis. There exists no universal edge detection method which works well under all conditions. This paper shows the new approach based on the one of the most efficient techniques for edge detection, which is entropy-based thresholding. The main advantages of the proposed method are its robustness and its flexibility. We present experimental results for this method, and compare results of the algorithm against several leading edge detection methods, such as Canny, LOG, and Sobel. Experimental results demonstrate that the proposed method achieves better result than some classic methods and the quality of the edge detector of the output images is robust and decrease the computation time.\n    ",
        "submission_date": "2012-11-12T00:00:00",
        "last_modified_date": "2012-11-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1211.2502",
        "title": "New Edge Detection Technique based on the Shannon Entropy in Gray Level Images",
        "authors": [
            "Mohamed A. El-Sayed",
            "Tarek Abd-El Hafeez"
        ],
        "abstract": "Edge detection is an important field in image processing. Edges characterize object boundaries and are therefore useful for segmentation, registration, feature extraction, and identification of objects in a scene. In this paper, an approach utilizing an improvement of Baljit and Amar method which uses Shannon entropy other than the evaluation of derivatives of the image in detecting edges in gray level images has been proposed. The proposed method can reduce the CPU time required for the edge detection process and the quality of the edge detector of the output images is robust. A standard test images, the real-world and synthetic images are used to compare the results of the proposed edge detector with the Baljit and Amar edge detector method. In order to validate the results, the run time of the proposed method and the pervious method are presented. It has been observed that the proposed edge detector works effectively for different gray scale digital images. The performance evaluation of the proposed technique in terms of the measured CPU time and the quality of edge detector method are presented. Experimental results demonstrate that the proposed method achieve better result than the relevant classic method.\n    ",
        "submission_date": "2012-11-12T00:00:00",
        "last_modified_date": "2012-11-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1211.2742",
        "title": "Sketch Recognition using Domain Classification",
        "authors": [
            "Vasudha Vashisht",
            "Tanupriya Choudhury",
            "T. V. Prasad"
        ],
        "abstract": "Conceptualizing away the sketch processing details in a user interface will enable general users and domain experts to create more complex sketches. There are many domains for which sketch recognition systems are being developed. But they entail image-processing skill if they are to handle the details of each domain, and also they are lengthy to build. The implemented system goal is to enable user interface designers and domain experts who may not have proficiency in sketch recognition to be able to construct these sketch systems. This sketch recognition system takes in rough sketches from user drawn with the help of mouse as its input. It then recognizes the sketch using segmentation and domain classification, the properties of the user drawn sketch and segments are searched heuristically in the domains and each figures of each domain, and finally it shows its domain, the figure name and properties. It also draws the sketch smoothly. The work is resulted through extensive research and study of many existing image processing and pattern matching algorithms.\n    ",
        "submission_date": "2012-11-12T00:00:00",
        "last_modified_date": "2012-11-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1211.2863",
        "title": "Multi-Sensor Fusion via Reduction of Dimensionality",
        "authors": [
            "Alon Schclar"
        ],
        "abstract": "Large high-dimensional datasets are becoming more and more popular in an increasing number of research areas. Processing the high dimensional data incurs a high computational cost and is inherently inefficient since many of the values that describe a data object are redundant due to noise and inner correlations. Consequently, the dimensionality, i.e. the number of values that are used to describe a data object, needs to be reduced prior to any other processing of the data. The dimensionality reduction removes, in most cases, noise from the data and reduces substantially the computational cost of algorithms that are applied to the data.\n",
        "submission_date": "2012-11-13T00:00:00",
        "last_modified_date": "2012-11-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1211.2881",
        "title": "Deep Attribute Networks",
        "authors": [
            "Junyoung Chung",
            "Donghoon Lee",
            "Youngjoo Seo",
            "Chang D. Yoo"
        ],
        "abstract": "Obtaining compact and discriminative features is one of the major challenges in many of the real-world image classification tasks such as face verification and object recognition. One possible approach is to represent input image on the basis of high-level features that carry semantic meaning which humans can understand. In this paper, a model coined deep attribute network (DAN) is proposed to address this issue. For an input image, the model outputs the attributes of the input image without performing any classification. The efficacy of the proposed model is evaluated on unconstrained face verification and real-world object recognition tasks using the LFW and the a-PASCAL datasets. We demonstrate the potential of deep learning for attribute-based classification by showing comparable results with existing state-of-the-art results. Once properly trained, the DAN is fast and does away with calculating low-level features which are maybe unreliable and computationally expensive.\n    ",
        "submission_date": "2012-11-13T00:00:00",
        "last_modified_date": "2012-11-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1211.3901",
        "title": "Visual Recognition of Isolated Swedish Sign Language Signs",
        "authors": [
            "Saad Akram",
            "Jonas Beskow",
            "Hedvig Kjellstrom"
        ],
        "abstract": "We present a method for recognition of isolated Swedish Sign Language signs. The method will be used in a game intended to help children training signing at home, as a complement to training with a teacher. The target group is not primarily deaf children, but children with language disorders. Using sign language as a support in conversation has been shown to greatly stimulate the speech development of such children. The signer is captured with an RGB-D (Kinect) sensor, which has three advantages over a regular RGB camera. Firstly, it allows complex backgrounds to be removed easily. We segment the hands and face based on skin color and depth information. Secondly, it helps with the resolution of hand over face occlusion. Thirdly, signs take place in 3D; some aspects of the signs are defined by hand motion vertically to the image plane. This motion can be estimated if the depth is observable. The 3D motion of the hands relative to the torso are used as a cue together with the hand shape, and HMMs trained with this input are used for classification. To obtain higher robustness towards differences across signers, Fisher Linear Discriminant Analysis is used to find the combinations of features that are most descriptive for each sign, regardless of signer. Experiments show that the system can distinguish signs from a challenging 94 word vocabulary with a precision of up to 94% in the signer dependent case and up to 47% in the signer independent case.\n    ",
        "submission_date": "2012-11-16T00:00:00",
        "last_modified_date": "2012-11-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1211.4264",
        "title": "Non-Local Patch Regression: Robust Image Denoising in Patch Space",
        "authors": [
            "Kunal N. Chaudhury",
            "Amit Singer"
        ],
        "abstract": "It was recently demonstrated in [Chaudhury et al.,Non-Local Euclidean Medians,2012] that the denoising performance of Non-Local Means (NLM) can be improved at large noise levels by replacing the mean by the robust Euclidean median. Numerical experiments on synthetic and natural images showed that the latter consistently performed better than NLM beyond a certain noise level, and significantly so for images with sharp edges. The Euclidean mean and median can be put into a common regression (on the patch space) framework, in which the l_2 norm of the residuals is considered in the former, while the l_1 norm is considered in the latter. The natural question then is what happens if we consider l_p (0<p<1) regression? We investigate this possibility in this paper.\n    ",
        "submission_date": "2012-11-18T00:00:00",
        "last_modified_date": "2012-11-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1211.4307",
        "title": "Efficient Superimposition Recovering Algorithm",
        "authors": [
            "Han Li",
            "Kun Gai",
            "Pinghua Gong",
            "Changshui Zhang"
        ],
        "abstract": "In this article, we address the issue of recovering latent transparent layers from superimposition images. Here, we assume we have the estimated transformations and extracted gradients of latent layers. To rapidly recover high-quality image layers, we propose an Efficient Superimposition Recovering Algorithm (ESRA) by extending the framework of accelerated gradient method. In addition, a key building block (in each iteration) in our proposed method is the proximal operator calculating. Here we propose to employ a dual approach and present our Parallel Algorithm with Constrained Total Variation (PACTV) method. Our recovering method not only reconstructs high-quality layers without color-bias problem, but also theoretically guarantees good convergence performance.\n    ",
        "submission_date": "2012-11-19T00:00:00",
        "last_modified_date": "2012-11-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1211.4385",
        "title": "Artificial Neural Network Based Optical Character Recognition",
        "authors": [
            "Vivek Shrivastava",
            "Navdeep Sharma"
        ],
        "abstract": "Optical Character Recognition deals in recognition and classification of characters from an image. For the recognition to be accurate, certain topological and geometrical properties are calculated, based on which a character is classified and recognized. Also, the Human psychology perceives characters by its overall shape and features such as strokes, curves, protrusions, enclosures etc. These properties, also called Features are extracted from the image by means of spatial pixel-based calculation. A collection of such features, called Vectors, help in defining a character uniquely, by means of an Artificial Neural Network that uses these Feature Vectors.\n    ",
        "submission_date": "2012-11-19T00:00:00",
        "last_modified_date": "2012-11-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1211.4499",
        "title": "Rate-Distortion Analysis of Multiview Coding in a DIBR Framework",
        "authors": [
            "Boshra Rajaei",
            "Thomas Maugey",
            "Hamid-Reza Pourreza",
            "Pascal Frossard"
        ],
        "abstract": "Depth image based rendering techniques for multiview applications have been recently introduced for efficient view generation at arbitrary camera positions. Encoding rate control has thus to consider both texture and depth data. Due to different structures of depth and texture images and their different roles on the rendered views, distributing the available bit budget between them however requires a careful analysis. Information loss due to texture coding affects the value of pixels in synthesized views while errors in depth information lead to shift in objects or unexpected patterns at their boundaries. In this paper, we address the problem of efficient bit allocation between textures and depth data of multiview video sequences. We adopt a rate-distortion framework based on a simplified model of depth and texture images. Our model preserves the main features of depth and texture images. Unlike most recent solutions, our method permits to avoid rendering at encoding time for distortion estimation so that the encoding complexity is not augmented. In addition to this, our model is independent of the underlying inpainting method that is used at decoder. Experiments confirm our theoretical results and the efficiency of our rate allocation strategy.\n    ",
        "submission_date": "2012-11-19T00:00:00",
        "last_modified_date": "2012-11-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1211.4503",
        "title": "An Effective Fingerprint Classification and Search Method",
        "authors": [
            "Monowar H. Bhuyan",
            "D. K. Bhattacharyya"
        ],
        "abstract": "This paper presents an effective fingerprint classification method designed based on a hierarchical agglomerative clustering technique. The performance of the technique was evaluated in terms of several real-life datasets and a significant improvement in reducing the misclassification error has been noticed. This paper also presents a query based faster fingerprint search method over the clustered fingerprint databases. The retrieval accuracy of the search method has been found effective in light of several real-life databases.\n    ",
        "submission_date": "2012-11-19T00:00:00",
        "last_modified_date": "2012-11-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1211.4524",
        "title": "Applying Dynamic Model for Multiple Manoeuvring Target Tracking Using Particle Filtering",
        "authors": [
            "Mohammad Javad Parseh",
            "Saeid Pashazadeh"
        ],
        "abstract": "In this paper, we applied a dynamic model for manoeuvring targets in SIR particle filter algorithm for improving tracking accuracy of multiple manoeuvring targets. In our proposed approach, a color distribution model is used to detect changes of target's model . Our proposed approach controls deformation of target's model. If deformation of target's model is larger than a predetermined threshold, then the model will be updated. Global Nearest Neighbor (GNN) algorithm is used as data association algorithm. We named our proposed method as Deformation Detection Particle Filter (DDPF) . DDPF approach is compared with basic SIR-PF algorithm on real airshow videos. Comparisons results show that, the basic SIR-PF algorithm is not able to track the manoeuvring targets when the rotation or scaling is occurred in target' s model. However, DDPF approach updates target's model when the rotation or scaling is occurred. Thus, the proposed approach is able to track the manoeuvring targets more efficiently and accurately.\n    ",
        "submission_date": "2012-11-19T00:00:00",
        "last_modified_date": "2012-11-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1211.4591",
        "title": "Five Modulus Method For Image Compression",
        "authors": [
            "Firas A. Jassim",
            "Hind E. Qassim"
        ],
        "abstract": "Data is compressed by reducing its redundancy, but this also makes the data less reliable, more prone to errors. In this paper a novel approach of image compression based on a new method that has been created for image compression which is called Five Modulus Method (FMM). The new method consists of converting each pixel value in an 8-by-8 block into a multiple of 5 for each of the R, G and B arrays. After that, the new values could be divided by 5 to get new values which are 6-bit length for each pixel and it is less in storage space than the original value which is 8-bits. Also, a new protocol for compression of the new values as a stream of bits has been presented that gives the opportunity to store and transfer the new compressed image easily.\n    ",
        "submission_date": "2012-11-19T00:00:00",
        "last_modified_date": "2012-11-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1211.4658",
        "title": "An Effective Method for Fingerprint Classification",
        "authors": [
            "Monowar H. Bhuyan",
            "Sarat Saharia",
            "Dhruba Kr Bhattacharyya"
        ],
        "abstract": "This paper presents an effective method for fingerprint classification using data mining approach. Initially, it generates a numeric code sequence for each fingerprint image based on the ridge flow patterns. Then for each class, a seed is selected by using a frequent itemsets generation technique. These seeds are subsequently used for clustering the fingerprint images. The proposed method was tested and evaluated in terms of several real-life datasets and a significant improvement in reducing the misclassification errors has been noticed in comparison to its other counterparts.\n    ",
        "submission_date": "2012-11-20T00:00:00",
        "last_modified_date": "2012-11-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1211.4771",
        "title": "Matching Through Features and Features Through Matching",
        "authors": [
            "Ganesh Sundaramoorthi",
            "Yanchao Yang"
        ],
        "abstract": "This paper addresses how to construct features for the problem of image correspondence, in particular, the paper addresses how to construct features so as to maintain the right level of invariance versus discriminability. We show that without additional prior knowledge of the 3D scene, the right tradeoff cannot be established in a pre-processing step of the images as is typically done in most feature-based matching methods. However, given knowledge of the second image to match, the tradeoff between invariance and discriminability of features in the first image is less ambiguous. This suggests to setup the problem of feature extraction and matching as a joint estimation problem. We develop a possible mathematical framework, a possible computational algorithm, and we give example demonstration on finding correspondence on images related by a scene that undergoes large 3D deformation of non-planar objects and camera viewpoint change.\n    ",
        "submission_date": "2012-11-20T00:00:00",
        "last_modified_date": "2012-11-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1211.4860",
        "title": "Domain Adaptations for Computer Vision Applications",
        "authors": [
            "Oscar Beijbom"
        ],
        "abstract": "A basic assumption of statistical learning theory is that train and test data are drawn from the same underlying distribution. Unfortunately, this assumption doesn't hold in many applications. Instead, ample labeled data might exist in a particular `source' domain while inference is needed in another, `target' domain. Domain adaptation methods leverage labeled data from both domains to improve classification on unseen data in the target domain. In this work we survey domain transfer learning methods for various application domains with focus on recent work in Computer Vision.\n    ",
        "submission_date": "2012-11-20T00:00:00",
        "last_modified_date": "2012-11-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1211.4907",
        "title": "Mahotas: Open source software for scriptable computer vision",
        "authors": [
            "Luis Pedro Coelho"
        ],
        "abstract": "Mahotas is a computer vision library for Python. It contains traditional image processing functionality such as filtering and morphological operations as well as more modern computer vision functions for feature computation, including interest point detection and local descriptors.\n",
        "submission_date": "2012-11-21T00:00:00",
        "last_modified_date": "2013-01-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1211.5355",
        "title": "Cobb Angle Measurement of Scoliosis with Reduced Variability",
        "authors": [
            "Raka Kundu",
            "Amlan Chakrabarti",
            "Prasanna K. Lenka"
        ],
        "abstract": "Cobb angle, which is a measure of spinal curvature is the standard method for quantifying the magnitude of Scoliosis related to spinal deformity in orthopedics. Determining the Cobb angle through manual process is subject to human errors. In this work, we propose a methodology to measure the magnitude of Cobb angle, which appreciably reduces the variability related to its measurement compared to the related works. The proposed methodology is facilitated by using a suitable new improved version of Non-Local Means for image denoisation and Otsus automatic threshold selection for Canny edge detection. We have selected NLM for preprocessing of the image as it is one of the fine states of art for image denoisation and helps in retaining the image quality. Trimmedmean, median are more robust to outliners than mean and following this concept we observed that NLM denoising quality performance can be enhanced by using Euclidean trimmed-mean replacing the mean. To prove the better performance of the Non-Local Euclidean Trimmed-mean denoising filter, we have provided some comparative study results of the proposed denoising technique with traditional NLM and NonLocal Euclidean Medians. The experimental results for Cobb angle measurement over intra observer and inter observer experimental data reveals the better performance and superiority of the proposed approach compared to the related works. MATLAB2009b image processing toolbox was used for the purpose of simulation and verification of the proposed methodology.\n    ",
        "submission_date": "2012-11-22T00:00:00",
        "last_modified_date": "2012-11-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1211.5556",
        "title": "Improving Perceptual Color Difference using Basic Color Terms",
        "authors": [
            "Ofir Pele",
            "Michael Werman"
        ],
        "abstract": "We suggest a new color distance based on two observations. First, perceptual color differences were designed to be used to compare very similar colors. They do not capture human perception for medium and large color differences well. Thresholding was proposed to solve the problem for large color differences, i.e. two totally different colors are always the same distance apart. We show that thresholding alone cannot improve medium color differences. We suggest to alleviate this problem using basic color terms. Second, when a color distance is used for edge detection, many small distances around the just noticeable difference may account for false edges. We suggest to reduce the effect of small distances.\n    ",
        "submission_date": "2012-11-23T00:00:00",
        "last_modified_date": "2012-11-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1211.5712",
        "title": "Detection of elliptical shapes via cross-entropy clustering",
        "authors": [
            "Jacek Tabor",
            "Krzysztof Misztal"
        ],
        "abstract": "The problem of finding elliptical shapes in an image will be considered. We discuss the solution which uses cross-entropy clustering. The proposed method allows the search for ellipses with predefined sizes and position in the space. Moreover, it works well for search of ellipsoids in higher dimensions.\n    ",
        "submission_date": "2012-11-24T00:00:00",
        "last_modified_date": "2012-11-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1211.6675",
        "title": "Nonlinear Dynamic Field Embedding: On Hyperspectral Scene Visualization",
        "authors": [
            "Dalton Lunga 'and' Okan Ersoy"
        ],
        "abstract": "Graph embedding techniques are useful to characterize spectral signature relations for hyperspectral images. However, such images consists of disjoint classes due to spatial details that are often ignored by existing graph computing tools. Robust parameter estimation is a challenge for kernel functions that compute such graphs. Finding a corresponding high quality coordinate system to map signature relations remains an open research question. We answer positively on these challenges by first proposing a kernel function of spatial and spectral information in computing neighborhood graphs. Secondly, the study exploits the force field interpretation from mechanics and devise a unifying nonlinear graph embedding framework. The generalized framework leads to novel unsupervised multidimensional artificial field embedding techniques that rely on the simple additive assumption of pair-dependent attraction and repulsion functions. The formulations capture long range and short range distance related effects often associated with living organisms and help to establish algorithmic properties that mimic mutual behavior for the purpose of dimensionality reduction. The main benefits from the proposed models includes the ability to preserve the local topology of data and produce quality visualizations i.e. maintaining disjoint meaningful neighborhoods. As part of evaluation, visualization, gradient field trajectories, and semisupervised classification experiments are conducted for image scenes acquired by multiple sensors at various spatial resolutions over different types of objects. The results demonstrate the superiority of the proposed embedding framework over various widely used methods.\n    ",
        "submission_date": "2012-11-28T00:00:00",
        "last_modified_date": "2012-11-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1211.6971",
        "title": "A New Automatic Method to Adjust Parameters for Object Recognition",
        "authors": [
            "Issam Qaffou",
            "Mohamed Sadgal",
            "Aziz Elfazziki"
        ],
        "abstract": "To recognize an object in an image, the user must apply a combination of operators, where each operator has a set of parameters. These parameters must be well adjusted in order to reach good results. Usually, this adjustment is made manually by the user. In this paper we propose a new method to automate the process of parameter adjustment for an object recognition task. Our method is based on reinforcement learning, we use two types of agents: User Agent that gives the necessary information and Parameter Agent that adjusts the parameters of each operator. Due to the nature of reinforcement learning the results do not depend only on the system characteristics but also on the user favorite choices.\n    ",
        "submission_date": "2012-11-29T00:00:00",
        "last_modified_date": "2012-11-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1211.7102",
        "title": "SVD Based Image Processing Applications: State of The Art, Contributions and Research Challenges",
        "authors": [
            "Rowayda A. Sadek"
        ],
        "abstract": "Singular Value Decomposition (SVD) has recently emerged as a new paradigm for processing different types of images. SVD is an attractive algebraic transform for image processing applications. The paper proposes an experimental survey for the SVD as an efficient transform in image processing applications. Despite the well-known fact that SVD offers attractive properties in imaging, the exploring of using its properties in various image applications is currently at its infancy. Since the SVD has many attractive properties have not been utilized, this paper contributes in using these generous properties in newly image applications and gives a highly recommendation for more research challenges. In this paper, the SVD properties for images are experimentally presented to be utilized in developing new SVD-based image processing applications. The paper offers survey on the developed SVD based image applications. The paper also proposes some new contributions that were originated from SVD properties analysis in different image processing. The aim of this paper is to provide a better understanding of the SVD in image processing and identify important various applications and open research directions in this increasingly important area; SVD based image processing in the future research.\n    ",
        "submission_date": "2012-11-29T00:00:00",
        "last_modified_date": "2012-11-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1211.7219",
        "title": "A recursive divide-and-conquer approach for sparse principal component analysis",
        "authors": [
            "Qian Zhao",
            "Deyu Meng",
            "Zongben Xu"
        ],
        "abstract": "In this paper, a new method is proposed for sparse PCA based on the recursive divide-and-conquer methodology. The main idea is to separate the original sparse PCA problem into a series of much simpler sub-problems, each having a closed-form solution. By recursively solving these sub-problems in an analytical way, an efficient algorithm is constructed to solve the sparse PCA problem. The algorithm only involves simple computations and is thus easy to implement. The proposed method can also be very easily extended to other sparse PCA problems with certain constraints, such as the nonnegative sparse PCA problem. Furthermore, we have shown that the proposed algorithm converges to a stationary point of the problem, and its computational complexity is approximately linear in both data size and dimensionality. The effectiveness of the proposed method is substantiated by extensive experiments implemented on a series of synthetic and real data in both reconstruction-error-minimization and data-variance-maximization viewpoints.\n    ",
        "submission_date": "2012-11-30T00:00:00",
        "last_modified_date": "2012-11-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1212.0030",
        "title": "Viewpoint Invariant Object Detector",
        "authors": [
            "Osama Khalil",
            "Andrew Habib"
        ],
        "abstract": "Object Detection is the task of identifying the existence of an object class instance and locating it within an image. Difficulties in handling high intra-class variations constitute major obstacles to achieving high performance on standard benchmark datasets (scale, viewpoint, lighting conditions and orientation variations provide good examples). Suggested model aims at providing more robustness to detecting objects suffering severe distortion due to < 60\u00b0 viewpoint changes. In addition, several model computational bottlenecks have been resolved leading to a significant increase in the model performance (speed and space) without compromising the resulting accuracy. Finally, we produced two illustrative applications showing the potential of the object detection technology being deployed in real life applications; namely content-based image search and content-based video search.\n    ",
        "submission_date": "2012-11-30T00:00:00",
        "last_modified_date": "2012-11-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1212.0059",
        "title": "Artificial Neural Network Fuzzy Inference System (ANFIS) For Brain Tumor Detection",
        "authors": [
            "Minakshi Sharma"
        ],
        "abstract": "Detection and segmentation of Brain tumor is very important because it provides anatomical information of normal and abnormal tissues which helps in treatment planning and patient follow-up. There are number of techniques for image segmentation. Proposed research work uses ANFIS (Artificial Neural Network Fuzzy Inference System) for image classification and then compares the results with FCM (Fuzzy C means) and K-NN (K-nearest neighbor). ANFIS includes benefits of both ANN and the fuzzy logic systems. A comprehensive feature set and fuzzy rules are selected to classify an abnormal image to the corresponding tumor type. Experimental results illustrate promising results in terms of classification accuracy. A comparative analysis is performed with the FCM and K-NN to show the superior nature of ANFIS systems.\n    ",
        "submission_date": "2012-12-01T00:00:00",
        "last_modified_date": "2012-12-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1212.0134",
        "title": "Fingertip Detection: A Fast Method with Natural Hand",
        "authors": [
            "J.L.Raheja",
            "Karen Das",
            "Ankit Chaudhary"
        ],
        "abstract": "Many vision based applications have used fingertips to track or manipulate gestures in their applications. Gesture identification is a natural way to pass the signals to the machine, as the human express its feelings most of the time with hand expressions. Here a novel time efficient algorithm has been described for fingertip detection. This method is invariant to hand direction and in preprocessing it cuts only hand part from the full image, hence further computation would be much faster than processing full image. Binary silhouette of the input image is generated using HSV color space based skin filter and hand cropping done based on intensity histogram of the hand image\n    ",
        "submission_date": "2012-12-01T00:00:00",
        "last_modified_date": "2012-12-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1212.0142",
        "title": "Pedestrian Detection with Unsupervised Multi-Stage Feature Learning",
        "authors": [
            "Pierre Sermanet",
            "Koray Kavukcuoglu",
            "Soumith Chintala",
            "Yann LeCun"
        ],
        "abstract": "Pedestrian detection is a problem of considerable practical interest. Adding to the list of successful applications of deep learning methods to vision, we report state-of-the-art and competitive results on all major pedestrian datasets with a convolutional network model. The model uses a few new twists, such as multi-stage features, connections that skip layers to integrate global shape information with local distinctive motif information, and an unsupervised method based on convolutional sparse coding to pre-train the filters at each stage.\n    ",
        "submission_date": "2012-12-01T00:00:00",
        "last_modified_date": "2013-04-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1212.0291",
        "title": "An Image Based Technique for Enhancement of Underwater Images",
        "authors": [
            "C. J. Prabhakar",
            "P. U. Praveen Kumar"
        ],
        "abstract": "The underwater images usually suffers from non-uniform lighting, low contrast, blur and diminished colors. In this paper, we proposed an image based preprocessing technique to enhance the quality of the underwater images. The proposed technique comprises a combination of four filters such as homomorphic filtering, wavelet denoising, bilateral filter and contrast equalization. These filters are applied sequentially on degraded underwater images. The literature survey reveals that image based preprocessing algorithms uses standard filter techniques with various combinations. For smoothing the image, the image based preprocessing algorithms uses the anisotropic filter. The main drawback of the anisotropic filter is that iterative in nature and computation time is high compared to bilateral filter. In the proposed technique, in addition to other three filters, we employ a bilateral filter for smoothing the image. The experimentation is carried out in two stages. In the first stage, we have conducted various experiments on captured images and estimated optimal parameters for bilateral filter. Similarly, optimal filter bank and optimal wavelet shrinkage function are estimated for wavelet denoising. In the second stage, we conducted the experiments using estimated optimal parameters, optimal filter bank and optimal wavelet shrinkage function for evaluating the proposed technique. We evaluated the technique using quantitative based criteria such as a gradient magnitude histogram and Peak Signal to Noise Ratio (PSNR). Further, the results are qualitatively evaluated based on edge detection results. The proposed technique enhances the quality of the underwater images and can be employed prior to apply computer vision techniques.\n    ",
        "submission_date": "2012-12-03T00:00:00",
        "last_modified_date": "2012-12-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1212.0318",
        "title": "Comparison of Fuzzy and Neuro Fuzzy Image Fusion Techniques and its Applications",
        "authors": [
            "D. Srinivasa Rao",
            "M. Seetha",
            "M. H. M. Krishna Prasad"
        ],
        "abstract": "Image fusion is the process of integrating multiple images of the same scene into a single fused image to reduce uncertainty and minimizing redundancy while extracting all the useful information from the source images. Image fusion process is required for different applications like medical imaging, remote sensing, medical imaging, machine vision, biometrics and military applications where quality and critical information is required. In this paper, image fusion using fuzzy and neuro fuzzy logic approaches utilized to fuse images from different sensors, in order to enhance visualization. The proposed work further explores comparison between fuzzy based image fusion and neuro fuzzy fusion technique along with quality evaluation indices for image fusion like image quality index, mutual information measure, fusion factor, fusion symmetry, fusion index, root mean square error, peak signal to noise ratio, entropy, correlation coefficient and spatial frequency. Experimental results obtained from fusion process prove that the use of the neuro fuzzy based image fusion approach shows better performance in first two test cases while in the third test case fuzzy based image fusion technique gives better results.\n    ",
        "submission_date": "2012-12-03T00:00:00",
        "last_modified_date": "2012-12-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1212.0383",
        "title": "GLCM-based chi-square histogram distance for automatic detection of defects on patterned textures",
        "authors": [
            "V. Asha",
            "N. U. Bhajantri",
            "P. Nagabhushan"
        ],
        "abstract": "Chi-square histogram distance is one of the distance measures that can be used to find dissimilarity between two histograms. Motivated by the fact that texture discrimination by human vision system is based on second-order statistics, we make use of histogram of gray-level co-occurrence matrix (GLCM) that is based on second-order statistics and propose a new machine vision algorithm for automatic defect detection on patterned textures. Input defective images are split into several periodic blocks and GLCMs are computed after quantizing the gray levels from 0-255 to 0-63 to keep the size of GLCM compact and to reduce computation time. Dissimilarity matrix derived from chi-square distances of the GLCMs is subjected to hierarchical clustering to automatically identify defective and defect-free blocks. Effectiveness of the proposed method is demonstrated through experiments on defective real-fabric images of 2 major wallpaper groups (pmm and p4m groups).\n    ",
        "submission_date": "2012-12-03T00:00:00",
        "last_modified_date": "2012-12-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1212.0402",
        "title": "UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild",
        "authors": [
            "Khurram Soomro",
            "Amir Roshan Zamir",
            "Mubarak Shah"
        ],
        "abstract": "We introduce UCF101 which is currently the largest dataset of human actions. It consists of 101 action classes, over 13k clips and 27 hours of video data. The database consists of realistic user uploaded videos containing camera motion and cluttered background. Additionally, we provide baseline action recognition results on this new dataset using standard bag of words approach with overall performance of 44.5%. To the best of our knowledge, UCF101 is currently the most challenging dataset of actions due to its large number of classes, large number of clips and also unconstrained nature of such clips.\n    ",
        "submission_date": "2012-12-03T00:00:00",
        "last_modified_date": "2012-12-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1212.0433",
        "title": "Compressive Schlieren Deflectometry",
        "authors": [
            "Prasad Sudhakar",
            "Laurent Jacques",
            "Xavier Dubois",
            "Philippe Antoine",
            "Luc Joannes"
        ],
        "abstract": "Schlieren deflectometry aims at characterizing the deflections undergone by refracted incident light rays at any surface point of a transparent object. For smooth surfaces, each surface location is actually associated with a sparse deflection map (or spectrum). This paper presents a novel method to compressively acquire and reconstruct such spectra. This is achieved by altering the way deflection information is captured in a common Schlieren Deflectometer, i.e., the deflection spectra are indirectly observed by the principle of spread spectrum compressed sensing. These observations are realized optically using a 2-D Spatial Light Modulator (SLM) adjusted to the corresponding sensing basis and whose modulations encode the light deviation subsequently recorded by a CCD camera. The efficiency of this approach is demonstrated experimentally on the observation of few test objects. Further, using a simple parametrization of the deflection spectra we show that relevant key parameters can be directly computed using the measurements, avoiding full reconstruction.\n    ",
        "submission_date": "2012-12-03T00:00:00",
        "last_modified_date": "2012-12-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1212.0819",
        "title": "A Topological Code for Plane Images",
        "authors": [
            "Evgeny Shchepin"
        ],
        "abstract": "It is proposed a new code for contours of plane images. This code was applied for optical character recognition of printed and handwritten characters. One can apply it to recognition of any visual images.\n    ",
        "submission_date": "2012-12-04T00:00:00",
        "last_modified_date": "2012-12-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1212.0888",
        "title": "Unmixing of Hyperspectral Data Using Robust Statistics-based NMF",
        "authors": [
            "Roozbeh Rajabi",
            "Hassan Ghassemian"
        ],
        "abstract": "Mixed pixels are presented in hyperspectral images due to low spatial resolution of hyperspectral sensors. Spectral unmixing decomposes mixed pixels spectra into endmembers spectra and abundance fractions. In this paper using of robust statistics-based nonnegative matrix factorization (RNMF) for spectral unmixing of hyperspectral data is investigated. RNMF uses a robust cost function and iterative updating procedure, so is not sensitive to outliers. This method has been applied to simulated data using USGS spectral library, AVIRIS and ROSIS datasets. Unmixing results are compared to traditional NMF method based on SAD and AAD measures. Results demonstrate that this method can be used efficiently for hyperspectral unmixing purposes.\n    ",
        "submission_date": "2012-12-04T00:00:00",
        "last_modified_date": "2012-12-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1212.1073",
        "title": "Kernel Estimation from Salient Structure for Robust Motion Deblurring",
        "authors": [
            "Jinshan Pan",
            "Risheng Liu",
            "Zhixun Su",
            "Xianfeng Gu"
        ],
        "abstract": "Blind image deblurring algorithms have been improving steadily in the past years. Most state-of-the-art algorithms, however, still cannot perform perfectly in challenging cases, especially in large blur setting. In this paper, we focus on how to estimate a good kernel estimate from a single blurred image based on the image structure. We found that image details caused by blurring could adversely affect the kernel estimation, especially when the blur kernel is large. One effective way to eliminate these details is to apply image denoising model based on the Total Variation (TV). First, we developed a novel method for computing image structures based on TV model, such that the structures undermining the kernel estimation will be removed. Second, to mitigate the possible adverse effect of salient edges and improve the robustness of kernel estimation, we applied a gradient selection method. Third, we proposed a novel kernel estimation method, which is capable of preserving the continuity and sparsity of the kernel and reducing the noises. Finally, we developed an adaptive weighted spatial prior, for the purpose of preserving sharp edges in latent image restoration. The effectiveness of our method is demonstrated by experiments on various kinds of challenging examples.\n    ",
        "submission_date": "2012-12-05T00:00:00",
        "last_modified_date": "2014-05-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1212.1313",
        "title": "Autonomous Navigation by Robust Scan Matching Technique",
        "authors": [
            "Debajyoti Banerji",
            "Ranjit Ray",
            "Jhankar Basu",
            "Indrajit Basak"
        ],
        "abstract": "For effective autonomous navigation,estimation of the pose of the robot is essential at every sampling time. For computing an accurate estimation,odometric error needs to be reduced with the help of data from external sensor. In this work, a technique has been developed for accurate pose estimation of mobile robot by using Laser Range data. The technique is robust to noisy data, which may contain considerable amount of outliers. A grey image is formed from laser range data and the key points from this image are extracted by Harris corner detector. The matching of the key points from consecutive data sets have been done while outliers have been rejected by RANSAC method. Robot state is measured by the correspondence between the two sets of keypoints. Finally, optimal robot state is estimated by Extended Kalman Filter. The technique has been applied to an operational robot in the laboratory environment to show the robustness of the technique in presence of noisy sensor data. The performance of this new technique has been compared with that of conventional ICP method. Through this method, effective and accurate navigation has been achieved even in presence of substantial noise in the sensor data at the cost of a small amount of additional computational complexity.\n    ",
        "submission_date": "2012-12-06T00:00:00",
        "last_modified_date": "2012-12-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1212.1329",
        "title": "Automatic Detection of Texture Defects Using Texture-Periodicity and Gabor Wavelets",
        "authors": [
            "V. Asha",
            "N. U. Bhajantri",
            "P. Nagabhushan"
        ],
        "abstract": "In this paper, we propose a machine vision algorithm for automatically detecting defects in textures belonging to 16 out of 17 wallpaper groups using texture-periodicity and a family of Gabor wavelets. Input defective images are subjected to Gabor wavelet transformation in multi-scales and multi-orientations and a resultant image is obtained in L2 norm. The resultant image is split into several periodic blocks and energy of each block is used as a feature space to automatically identify defective and defect-free blocks using Ward's hierarchical clustering. Experiments on defective fabric images of three major wallpaper groups, namely, pmm, p2 and p4m, show that the proposed method is robust in finding fabric defects without human intervention and can be used for automatic defect detection in fabric industries.\n    ",
        "submission_date": "2012-12-06T00:00:00",
        "last_modified_date": "2012-12-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1212.1819",
        "title": "A fair comparison of many max-tree computation algorithms (Extended version of the paper submitted to ISMM 2013",
        "authors": [
            "Edwin Carlinet",
            "Thierry G\u00e9raud"
        ],
        "abstract": "With the development of connected filters for the last decade, many algorithms have been proposed to compute the max-tree. Max-tree allows to compute the most advanced connected operators in a simple way. However, no fair comparison of algorithms has been proposed yet and the choice of an algorithm over an other depends on many parameters. Since the need of fast algorithms is obvious for production code, we present an in depth comparison of five algorithms and some variations of them in a unique framework. Finally, a decision tree will be proposed to help user in choosing the right algorithm with respect to their data.\n    ",
        "submission_date": "2012-12-08T00:00:00",
        "last_modified_date": "2013-01-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1212.2245",
        "title": "Fast and Robust Linear Motion Deblurring",
        "authors": [
            "Martin Welk",
            "Patrik Raudaschl",
            "Thomas Schwarzbauer",
            "Martin Erler",
            "Martin L\u00e4uter"
        ],
        "abstract": "We investigate efficient algorithmic realisations for robust deconvolution of grey-value images with known space-invariant point-spread function, with emphasis on 1D motion blur scenarios. The goal is to make deconvolution suitable as preprocessing step in automated image processing environments with tight time constraints. Candidate deconvolution methods are selected for their restoration quality, robustness and efficiency. Evaluation of restoration quality and robustness on synthetic and real-world test images leads us to focus on a combination of Wiener filtering with few iterations of robust and regularised Richardson-Lucy deconvolution. We discuss algorithmic optimisations for specific scenarios. In the case of uniform linear motion blur in coordinate direction, it is possible to achieve real-time performance (less than 50 ms) in single-threaded CPU computation on images of $256\\times256$ pixels. For more general space-invariant blur settings, still favourable computation times are obtained. Exemplary parallel implementations demonstrate that the proposed method also achieves real-time performance for general 1D motion blurs in a multi-threaded CPU setting, and for general 2D blurs on a GPU.\n    ",
        "submission_date": "2012-12-10T00:00:00",
        "last_modified_date": "2012-12-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1212.2278",
        "title": "Inverting and Visualizing Features for Object Detection",
        "authors": [
            "Carl Vondrick",
            "Aditya Khosla",
            "Tomasz Malisiewicz",
            "Antonio Torralba"
        ],
        "abstract": "We introduce algorithms to visualize feature spaces used by object detectors. The tools in this paper allow a human to put on `HOG goggles' and perceive the visual world as a HOG based object detector sees it. We found that these visualizations allow us to analyze object detection systems in new ways and gain new insight into the detector's failures. For example, when we visualize the features for high scoring false alarms, we discovered that, although they are clearly wrong in image space, they do look deceptively similar to true positives in feature space. This result suggests that many of these false alarms are caused by our choice of feature space, and indicates that creating a better learning algorithm or building bigger datasets is unlikely to correct these errors. By visualizing feature spaces, we can gain a more intuitive understanding of our detection systems.\n    ",
        "submission_date": "2012-12-11T00:00:00",
        "last_modified_date": "2013-05-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1212.2546",
        "title": "A Learning Framework for Morphological Operators using Counter-Harmonic Mean",
        "authors": [
            "Jonathan Masci",
            "Jes\u00fas Angulo",
            "J\u00fcrgen Schmidhuber"
        ],
        "abstract": "We present a novel framework for learning morphological operators using counter-harmonic mean. It combines concepts from morphology and convolutional neural networks. A thorough experimental validation analyzes basic morphological operators dilation and erosion, opening and closing, as well as the much more complex top-hat transform, for which we report a real-world application from the steel industry. Using online learning and stochastic gradient descent, our system learns both the structuring element and the composition of operators. It scales well to large datasets and online settings.\n    ",
        "submission_date": "2012-12-11T00:00:00",
        "last_modified_date": "2012-12-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1212.2692",
        "title": "Enhanced skin colour classifier using RGB Ratio model",
        "authors": [
            "Ghazali Osman",
            "Muhammad Suzuri Hitam",
            "Mohd Nasir Ismail"
        ],
        "abstract": "Skin colour detection is frequently been used for searching people, face detection, pornographic filtering and hand tracking. The presence of skin or non-skin in digital image can be determined by manipulating pixels colour or pixels texture. The main problem in skin colour detection is to represent the skin colour distribution model that is invariant or least sensitive to changes in illumination condition. Another problem comes from the fact that many objects in the real world may possess almost similar skin-tone colour such as wood, leather, skin-coloured clothing, hair and sand. Moreover, skin colour is different between races and can be different from a person to another, even with people of the same ethnicity. Finally, skin colour will appear a little different when different types of camera are used to capture the object or scene. The objective in this study is to develop a skin colour classifier based on pixel-based using RGB ratio model. The RGB ratio model is a newly proposed method that belongs under the category of an explicitly defined skin region model. This skin classifier was tested with SIdb dataset and two benchmark datasets; UChile and TDSD datasets to measure classifier performance. The performance of skin classifier was measured based on true positive (TF) and false positive (FP) indicator. This newly proposed model was compared with Kovac, Saleh and Swift models. The experimental results showed that the RGB ratio model outperformed all the other models in term of detection rate. The RGB ratio model is able to reduce FP detection that caused by reddish objects colour as well as be able to detect darkened skin and skin covered by shadow.\n    ",
        "submission_date": "2012-12-12T00:00:00",
        "last_modified_date": "2012-12-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1212.2823",
        "title": "Tracking Revisited using RGBD Camera: Baseline and Benchmark",
        "authors": [
            "Shuran Song",
            "Jianxiong Xiao"
        ],
        "abstract": "Although there has been significant progress in the past decade,tracking is still a very challenging computer vision task, due to problems such as occlusion and model ",
        "submission_date": "2012-12-12T00:00:00",
        "last_modified_date": "2012-12-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1212.2860",
        "title": "Pituitary Adenoma Volumetry with 3D Slicer",
        "authors": [
            "Jan Egger",
            "Tina Kapur",
            "Christopher Nimsky",
            "Ron Kikinis"
        ],
        "abstract": "In this study, we present pituitary adenoma volumetry using the free and open source medical image computing platform for biomedical research: (3D) Slicer. Volumetric changes in cerebral pathologies like pituitary adenomas are a critical factor in treatment decisions by physicians and in general the volume is acquired manually. Therefore, manual slice-by-slice segmentations in magnetic resonance imaging (MRI) data, which have been obtained at regular intervals, are performed. In contrast to this manual time consuming slice-by-slice segmentation process Slicer is an alternative which can be significantly faster and less user intensive. In this contribution, we compare pure manual segmentations of ten pituitary adenomas with semi-automatic segmentations under Slicer. Thus, physicians drew the boundaries completely manually on a slice-by-slice basis and performed a Slicer-enhanced segmentation using the competitive region-growing based module of Slicer named GrowCut. Results showed that the time and user effort required for GrowCut-based segmentations were on average about thirty percent less than the pure manual segmentations. Furthermore, we calculated the Dice Similarity Coefficient (DSC) between the manual and the Slicer-based segmentations to proof that the two are comparable yielding an average DSC of 81.97\\pm3.39%.\n    ",
        "submission_date": "2012-12-12T00:00:00",
        "last_modified_date": "2012-12-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1212.3034",
        "title": "Multi-target tracking algorithms in 3D",
        "authors": [
            "Rastislav Telgarsky"
        ],
        "abstract": "Ladars provide a unique capability for identification of objects and motions in scenes with fixed 3D field of view (FOV). This paper describes algorithms for multi-target tracking in 3D scenes including the preprocessing (mathematical morphology and Parzen windows), labeling of connected components, sorting of targets by selectable attributes (size, length of track, velocity), and handling of target states (acquired, coasting, re-acquired and tracked) in order to assemble the target trajectories. This paper is derived from working algorithms coded in Matlab, which were tested and reviewed by others, and does not speculate about usage of general formulas or frameworks.\n    ",
        "submission_date": "2012-12-13T00:00:00",
        "last_modified_date": "2012-12-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1212.3268",
        "title": "Robust image reconstruction from multi-view measurements",
        "authors": [
            "Gilles Puy",
            "Pierre Vandergheynst"
        ],
        "abstract": "We propose a novel method to accurately reconstruct a set of images representing a single scene from few linear multi-view measurements. Each observed image is modeled as the sum of a background image and a foreground one. The background image is common to all observed images but undergoes geometric transformations, as the scene is observed from different viewpoints. In this paper, we assume that these geometric transformations are represented by a few parameters, e.g., translations, rotations, affine transformations, etc.. The foreground images differ from one observed image to another, and are used to model possible occlusions of the scene. The proposed reconstruction algorithm estimates jointly the images and the transformation parameters from the available multi-view measurements. The ideal solution of this multi-view imaging problem minimizes a non-convex functional, and the reconstruction technique is an alternating descent method built to minimize this functional. The convergence of the proposed algorithm is studied, and conditions under which the sequence of estimated images and parameters converges to a critical point of the non-convex functional are provided. Finally, the efficiency of the algorithm is demonstrated using numerical simulations for applications such as compressed sensing or super-resolution.\n    ",
        "submission_date": "2012-12-13T00:00:00",
        "last_modified_date": "2013-09-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1212.3373",
        "title": "A Novel Directional Weighted Minimum Deviation (DWMD) Based Filter for Removal of Random Valued Impulse Noise",
        "authors": [
            "J. K. Mandal",
            "Somnath Mukhopadhyay"
        ],
        "abstract": "The most median-based de noising methods works fine for restoring the images corrupted by Randomn Valued Impulse Noise with low noise level but very poor with highly corrupted images. In this paper a directional weighted minimum deviation (DWMD) based filter has been proposed for removal of high random valued impulse noise (RVIN). The proposed approach based on Standard Deviation (SD) works in two phases. The first phase detects the contaminated pixels by differencing between the test pixel and its neighbor pixels aligned with four main directions. The second phase filters only those pixels keeping others intact. The filtering scheme is based on minimum standard deviation of the four directional pixels. Extensive simulations show that the proposed filter not only provide better performance of de noising RVIN but can preserve more details features even thin lines or dots. This technique shows better performance in terms of PSNR, Image Fidelity and Computational Cost compared to the existing filters.\n    ",
        "submission_date": "2012-12-14T00:00:00",
        "last_modified_date": "2012-12-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1212.3530",
        "title": "A Multi-Orientation Analysis Approach to Retinal Vessel Tracking",
        "authors": [
            "Erik Bekkers",
            "Remco Duits",
            "Tos Berendschot",
            "Bart ter Haar Romeny"
        ],
        "abstract": "This paper presents a method for retinal vasculature extraction based on biologically inspired multi-orientation analysis. We apply multi-orientation analysis via so-called invertible orientation scores, modeling the cortical columns in the visual system of higher mammals. This allows us to generically deal with many hitherto complex problems inherent to vessel tracking, such as crossings, bifurcations, parallel vessels, vessels of varying widths and vessels with high curvature. Our approach applies tracking in invertible orientation scores via a novel geometrical principle for curve optimization in the Euclidean motion group SE(2). The method runs fully automatically and provides a detailed model of the retinal vasculature, which is crucial as a sound basis for further quantitative analysis of the retina, especially in screening applications.\n    ",
        "submission_date": "2012-12-14T00:00:00",
        "last_modified_date": "2013-12-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1212.3767",
        "title": "Visual Objects Classification with Sliding Spatial Pyramid Matching",
        "authors": [
            "Hao Wooi Lim",
            "Yong Haur Tay"
        ],
        "abstract": "We present a method for visual object classification using only a single feature, transformed color SIFT with a variant of Spatial Pyramid Matching (SPM) that we called Sliding Spatial Pyramid Matching (SSPM), trained with an ensemble of linear regression (provided by LINEAR) to obtained state of the art result on Caltech-101 of 83.46%. SSPM is a special version of SPM where instead of dividing an image into K number of regions, a subwindow of fixed size is slide around the image with a fixed step size. For each subwindow, a histogram of visual words is generated. To obtained the visual vocabulary, instead of performing K-means clustering, we randomly pick N exemplars from the training set and encode them with a soft non-linear mapping method. We then trained 15 models, each with a different visual word size with linear regression. All 15 models are then averaged together to form a single strong model.\n    ",
        "submission_date": "2012-12-16T00:00:00",
        "last_modified_date": "2012-12-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1212.3913",
        "title": "Group Component Analysis for Multiblock Data: Common and Individual Feature Extraction",
        "authors": [
            "Guoxu Zhou",
            "Andrzej Cichocki",
            "Yu Zhang",
            "Danilo Mandic"
        ],
        "abstract": "Very often data we encounter in practice is a collection of matrices rather than a single matrix. These multi-block data are naturally linked and hence often share some common features and at the same time they have their own individual features, due to the background in which they are measured and collected. In this study we proposed a new scheme of common and individual feature analysis (CIFA) that processes multi-block data in a linked way aiming at discovering and separating their common and individual features. According to whether the number of common features is given or not, two efficient algorithms were proposed to extract the common basis which is shared by all data. Then feature extraction is performed on the common and the individual spaces separately by incorporating the techniques such as dimensionality reduction and blind source separation. We also discussed how the proposed CIFA can significantly improve the performance of classification and clustering tasks by exploiting common and individual features of samples respectively. Our experimental results show some encouraging features of the proposed methods in comparison to the state-of-the-art methods on synthetic and real data.\n    ",
        "submission_date": "2012-12-17T00:00:00",
        "last_modified_date": "2017-03-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1212.4522",
        "title": "A Multi-View Embedding Space for Modeling Internet Images, Tags, and their Semantics",
        "authors": [
            "Yunchao Gong",
            "Qifa Ke",
            "Michael Isard",
            "Svetlana Lazebnik"
        ],
        "abstract": "This paper investigates the problem of modeling Internet images and associated text or tags for tasks such as image-to-image search, tag-to-image search, and image-to-tag search (image annotation). We start with canonical correlation analysis (CCA), a popular and successful approach for mapping visual and textual features to the same latent space, and incorporate a third view capturing high-level image semantics, represented either by a single category or multiple non-mutually-exclusive concepts. We present two ways to train the three-view embedding: supervised, with the third view coming from ground-truth labels or search keywords; and unsupervised, with semantic themes automatically obtained by clustering the tags. To ensure high accuracy for retrieval tasks while keeping the learning process scalable, we combine multiple strong visual features and use explicit nonlinear kernel mappings to efficiently approximate kernel CCA. To perform retrieval, we use a specially designed similarity function in the embedded space, which substantially outperforms the Euclidean distance. The resulting system produces compelling qualitative results and outperforms a number of two-view baselines on retrieval tasks on three large-scale Internet image datasets.\n    ",
        "submission_date": "2012-12-18T00:00:00",
        "last_modified_date": "2013-09-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1212.4527",
        "title": "GMM-Based Hidden Markov Random Field for Color Image and 3D Volume Segmentation",
        "authors": [
            "Quan Wang"
        ],
        "abstract": "In this project, we first study the Gaussian-based hidden Markov random field (HMRF) model and its expectation-maximization (EM) algorithm. Then we generalize it to Gaussian mixture model-based hidden Markov random field. The algorithm is implemented in MATLAB. We also apply this algorithm to color image segmentation problems and 3D volume segmentation problems.\n    ",
        "submission_date": "2012-12-18T00:00:00",
        "last_modified_date": "2012-12-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1212.4608",
        "title": "Perceptually Motivated Shape Context Which Uses Shape Interiors",
        "authors": [
            "Vittal Premachandran",
            "Ramakrishna Kakarala"
        ],
        "abstract": "In this paper, we identify some of the limitations of current-day shape matching techniques. We provide examples of how contour-based shape matching techniques cannot provide a good match for certain visually similar shapes. To overcome this limitation, we propose a perceptually motivated variant of the well-known shape context descriptor. We identify that the interior properties of the shape play an important role in object recognition and develop a descriptor that captures these interior properties. We show that our method can easily be augmented with any other shape matching algorithm. We also show from our experiments that the use of our descriptor can significantly improve the retrieval rates.\n    ",
        "submission_date": "2012-12-19T00:00:00",
        "last_modified_date": "2012-12-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1212.4920",
        "title": "Automatic landmark annotation and dense correspondence registration for 3D human facial images",
        "authors": [
            "Jianya Guo",
            "Xi Mei",
            "Kun Tang"
        ],
        "abstract": "Dense surface registration of three-dimensional (3D) human facial images holds great potential for studies of human trait diversity, disease genetics, and forensics. Non-rigid registration is particularly useful for establishing dense anatomical correspondences between faces. Here we describe a novel non-rigid registration method for fully automatic 3D facial image mapping. This method comprises two steps: first, seventeen facial landmarks are automatically annotated, mainly via PCA-based feature recognition following 3D-to-2D data transformation. Second, an efficient thin-plate spline (TPS) protocol is used to establish the dense anatomical correspondence between facial images, under the guidance of the predefined landmarks. We demonstrate that this method is robust and highly accurate, even for different ethnicities. The average face is calculated for individuals of Han Chinese and Uyghur origins. While fully automatic and computationally efficient, this method enables high-throughput analysis of human facial feature variation.\n    ",
        "submission_date": "2012-12-20T00:00:00",
        "last_modified_date": "2012-12-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1212.5352",
        "title": "On the Adaptability of Neural Network Image Super-Resolution",
        "authors": [
            "Kah Keong Chua",
            "Yong Haur Tay"
        ],
        "abstract": "In this paper, we described and developed a framework for Multilayer Perceptron (MLP) to work on low level image processing, where MLP will be used to perform image super-resolution. Meanwhile, MLP are trained with different types of images from various categories, hence analyse the behaviour and performance of the neural network. The tests are carried out using qualitative test, in which Mean Squared Error (MSE), Peak Signal-to-Noise Ratio (PSNR) and Structural Similarity Index (SSIM). The results showed that MLP trained with single image category can perform reasonably well compared to methods proposed by other researchers.\n    ",
        "submission_date": "2012-12-21T00:00:00",
        "last_modified_date": "2012-12-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1212.5454",
        "title": "In Vivo Quantification of Clot Formation in Extracorporeal Circuits",
        "authors": [
            "Omid David",
            "Rabin Gerrah"
        ],
        "abstract": "Clot formation is a common complication in extracorporeal circuits. In this paper we describe a novel method for clot formation analysis using image processing. We assembled a closed extracorporeal circuit and circulated blood at varying speeds. Blood filters were placed in downstream of the flow, and clotting agents were added to the circuit. Digital images of the filter were subsequently taken, and image analysis was applied to calculate the density of the clot. Our results show a significant correlation between the cumulative size of the clots, the density measure of the clot based on image analysis, and flow duration in the system.\n    ",
        "submission_date": "2012-12-21T00:00:00",
        "last_modified_date": "2012-12-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1212.5656",
        "title": "High-precision camera distortion measurements with a \"calibration harp\"",
        "authors": [
            "Zhongwei Tang",
            "Rafael Grompone von Gioi",
            "Pascal Monasse",
            "Jean-Michel Morel"
        ],
        "abstract": "This paper addresses the high precision measurement of the distortion of a digital camera from photographs. Traditionally, this distortion is measured from photographs of a flat pattern which contains aligned elements. Nevertheless, it is nearly impossible to fabricate a very flat pattern and to validate its flatness. This fact limits the attainable measurable precisions. In contrast, it is much easier to obtain physically very precise straight lines by tightly stretching good quality strings on a frame. Taking literally \"plumb-line methods\", we built a \"calibration harp\" instead of the classic flat patterns to obtain a high precision measurement tool, demonstrably reaching 2/100 pixel precisions. The harp is complemented with the algorithms computing automatically from harp photographs two different and complementary lens distortion measurements. The precision of the method is evaluated on images corrected by state-of-the-art distortion correction algorithms, and by popular software. Three applications are shown: first an objective and reliable measurement of the result of any distortion correction. Second, the harp permits to control state-of-the art global camera calibration algorithms: It permits to select the right distortion model, thus avoiding internal compensation errors inherent to these methods. Third, the method replaces manual procedures in other distortion correction methods, makes them fully automatic, and increases their reliability and precision.\n    ",
        "submission_date": "2012-12-22T00:00:00",
        "last_modified_date": "2012-12-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1212.5711",
        "title": "Normalized Compression Distance of Multisets with Applications",
        "authors": [
            "Andrew R. Cohen",
            "Paul M. B. Vitanyi"
        ],
        "abstract": "Normalized compression distance (NCD) is a parameter-free, feature-free, alignment-free, similarity measure between a pair of finite objects based on compression. However, it is not sufficient for all applications. We propose an NCD of finite multisets (a.k.a. multiples) of finite objects that is also a metric. Previously, attempts to obtain such an NCD failed. We cover the entire trajectory from theoretical underpinning to feasible practice. The new NCD for multisets is applied to retinal progenitor cell classification questions and to related synthetically generated data that were earlier treated with the pairwise NCD. With the new method we achieved significantly better results. Similarly for questions about axonal organelle transport. We also applied the new NCD to handwritten digit recognition and improved classification accuracy significantly over that of pairwise NCD by incorporating both the pairwise and NCD for multisets. In the analysis we use the incomputable Kolmogorov complexity that for practical purposes is approximated from above by the length of the compressed version of the file involved, using a real-world compression program.\n",
        "submission_date": "2012-12-22T00:00:00",
        "last_modified_date": "2013-03-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1212.5720",
        "title": "Hierarchical Graphical Models for Multigroup Shape Analysis using Expectation Maximization with Sampling in Kendall's Shape Space",
        "authors": [
            "Yen-Yun Yu",
            "P. Thomas Fletcher",
            "Suyash P. Awate"
        ],
        "abstract": "This paper proposes a novel framework for multi-group shape analysis relying on a hierarchical graphical statistical model on shapes within a ",
        "submission_date": "2012-12-22T00:00:00",
        "last_modified_date": "2013-01-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1212.5877",
        "title": "Blinking Molecule Tracking",
        "authors": [
            "Andreas Karrenbauer",
            "Dominik W\u00f6ll"
        ],
        "abstract": "We discuss a method for tracking individual molecules which globally optimizes the likelihood of the connections between molecule positions fast and with high reliability even for high spot densities and blinking molecules. Our method works with cost functions which can be freely chosen to combine costs for distances between spots in space and time and which can account for the reliability of positioning a molecule. To this end, we describe a top-down polyhedral approach to the problem of tracking many individual molecules. This immediately yields an effective implementation using standard linear programming solvers. Our method can be applied to 2D and 3D tracking.\n    ",
        "submission_date": "2012-12-24T00:00:00",
        "last_modified_date": "2013-03-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1212.6094",
        "title": "Large Scale Strongly Supervised Ensemble Metric Learning, with Applications to Face Verification and Retrieval",
        "authors": [
            "Chang Huang",
            "Shenghuo Zhu",
            "Kai Yu"
        ],
        "abstract": "Learning Mahanalobis distance metrics in a high- dimensional feature space is very difficult especially when structural sparsity and low rank are enforced to improve com- putational efficiency in testing phase. This paper addresses both aspects by an ensemble metric learning approach that consists of sparse block diagonal metric ensembling and join- t metric learning as two consecutive steps. The former step pursues a highly sparse block diagonal metric by selecting effective feature groups while the latter one further exploits correlations between selected feature groups to obtain an accurate and low rank metric. Our algorithm considers all pairwise or triplet constraints generated from training samples with explicit class labels, and possesses good scala- bility with respect to increasing feature dimensionality and growing data volumes. Its applications to face verification and retrieval outperform existing state-of-the-art methods in accuracy while retaining high efficiency.\n    ",
        "submission_date": "2012-12-25T00:00:00",
        "last_modified_date": "2012-12-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1212.6933",
        "title": "On Automation and Medical Image Interpretation, With Applications for Laryngeal Imaging",
        "authors": [
            "H. J. Moukalled"
        ],
        "abstract": "Indeed, these are exciting times. We are in the heart of a digital renaissance. Automation and computer technology allow engineers and scientists to fabricate processes that amalgamate quality of life. We anticipate much growth in medical image interpretation and understanding, due to the influx of computer technologies. This work should serve as a guide to introduce the reader to core themes in theoretical computer science, as well as imaging applications for understanding vocal-fold vibrations. In this work, we motivate the use of automation, review some mathematical models of computation. We present a proof of a classical problem in image analysis that cannot be automated by means of algorithms. Furthermore, discuss some applications for processing medical images of the vocal folds, and discuss some of the exhilarating directions the art of automation will take vocal-fold image interpretation and quite possibly other areas of biomedical image analysis.\n    ",
        "submission_date": "2012-12-31T00:00:00",
        "last_modified_date": "2013-01-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1201.0022",
        "title": "Spatio-temporal wavelet regularization for parallel MRI reconstruction: application to functional MRI",
        "authors": [
            "Lotfi Chaari",
            "S\u00e9bastien M\u00e9riaux",
            "Jean-Christophe Pesquet",
            "Philippe Ciuciu"
        ],
        "abstract": "Parallel MRI is a fast imaging technique that enables the acquisition of highly resolved images in space or/and in time. The performance of parallel imaging strongly depends on the reconstruction algorithm, which can proceed either in the original k-space (GRAPPA, SMASH) or in the image domain (SENSE-like methods). To improve the performance of the widely used SENSE algorithm, 2D- or slice-specific regularization in the wavelet domain has been deeply investigated. In this paper, we extend this approach using 3D-wavelet representations in order to handle all slices together and address reconstruction artifacts which propagate across adjacent slices. The gain induced by such extension (3D-Unconstrained Wavelet Regularized -SENSE: 3D-UWR-SENSE) is validated on anatomical image reconstruction where no temporal acquisition is considered. Another important extension accounts for temporal correlations that exist between successive scans in functional MRI (fMRI). In addition to the case of 2D+t acquisition schemes addressed by some other methods like kt-FOCUSS, our approach allows us to deal with 3D+t acquisition schemes which are widely used in neuroimaging. The resulting 3D-UWR-SENSE and 4D-UWR-SENSE reconstruction schemes are fully unsupervised in the sense that all regularization parameters are estimated in the maximum likelihood sense on a reference scan. The gain induced by such extensions is illustrated on both anatomical and functional image reconstruction, and also measured in terms of statistical sensitivity for the 4D-UWR-SENSE approach during a fast event-related fMRI protocol. Our 4D-UWR-SENSE algorithm outperforms the SENSE reconstruction at the subject and group levels (15 subjects) for different contrasts of interest (eg, motor or computation tasks) and using different parallel acceleration factors (R=2 and R=4) on 2x2x3mm3 EPI images.\n    ",
        "submission_date": "2011-12-23T00:00:00",
        "last_modified_date": "2013-10-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1201.0925",
        "title": "On The Convergence of Gradient Descent for Finding the Riemannian Center of Mass",
        "authors": [
            "Bijan Afsari",
            "Roberto Tron",
            "Ren\u00e9 Vidal"
        ],
        "abstract": "We study the problem of finding the global Riemannian center of mass of a set of data points on a Riemannian manifold. Specifically, we investigate the convergence of constant step-size gradient descent algorithms for solving this problem. The challenge is that often the underlying cost function is neither globally differentiable nor convex, and despite this one would like to have guaranteed convergence to the global minimizer. After some necessary preparations we state a conjecture which we argue is the best (in a sense described) convergence condition one can hope for. The conjecture specifies conditions on the spread of the data points, step-size range, and the location of the initial condition (i.e., the region of convergence) of the algorithm. These conditions depend on the topology and the curvature of the manifold and can be conveniently described in terms of the injectivity radius and the sectional curvatures of the manifold. For manifolds of constant nonnegative curvature (e.g., the sphere and the rotation group in $\\mathbb{R}^{3}$) we show that the conjecture holds true (we do this by proving and using a comparison theorem which seems to be of a different nature from the standard comparison theorems in Riemannian geometry). For manifolds of arbitrary curvature we prove convergence results which are weaker than the conjectured one (but still superior over the available results). We also briefly study the effect of the configuration of the data points on the speed of convergence.\n    ",
        "submission_date": "2011-12-30T00:00:00",
        "last_modified_date": "2011-12-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1201.2395",
        "title": "Polynomial Regression on Riemannian Manifolds",
        "authors": [
            "Jacob Hinkle",
            "Prasanna Muralidharan",
            "P. Thomas Fletcher",
            "Sarang Joshi"
        ],
        "abstract": "In this paper we develop the theory of parametric polynomial regression in Riemannian manifolds and Lie groups. We show application of Riemannian polynomial regression to shape analysis in Kendall shape space. Results are presented, showing the power of polynomial regression on the classic rat skull growth data of Bookstein as well as the analysis of the shape changes associated with aging of the corpus callosum from the OASIS Alzheimer's study.\n    ",
        "submission_date": "2012-01-11T00:00:00",
        "last_modified_date": "2012-03-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1201.2542",
        "title": "An efficient FPGA implementation of MRI image filtering and tumor characterization using Xilinx system generator",
        "authors": [
            "S. Allin Christe",
            "M.Vignesh",
            "A.Kandaswamy"
        ],
        "abstract": "This paper presents an efficient architecture for various image filtering algorithms and tumor characterization using Xilinx System Generator (XSG). This architecture offers an alternative through a graphical user interface that combines MATLAB, Simulink and XSG and explores important aspects concerned to hardware implementation. Performance of this architecture implemented in SPARTAN-3E Starter kit (XC3S500E-FG320) exceeds those of similar or greater resources architectures. The proposed architecture reduces the resources available on target device by 50%.\n    ",
        "submission_date": "2012-01-12T00:00:00",
        "last_modified_date": "2012-01-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1201.3118",
        "title": "Shape analysis using fractal dimension: a curvature based approach",
        "authors": [
            "Andr\u00e9 R. Backes",
            "Jo\u00e3o B. Florindo",
            "Odemir M. Bruno"
        ],
        "abstract": "The present work shows a novel fractal dimension method for shape analysis. The proposed technique extracts descriptors from the shape by applying a multiscale approach to the calculus of the fractal dimension of that shape. The fractal dimension is obtained by the application of the curvature scale-space technique to the original shape. Through the application of a multiscale transform to the dimension calculus, it is obtained a set of numbers (descriptors) capable of describing with a high precision the shape in analysis. The obtained descriptors are validated in a classification process. The results demonstrate that the novel technique provides descriptors highly reliable, confirming the precision of the proposed method.\n    ",
        "submission_date": "2012-01-15T00:00:00",
        "last_modified_date": "2012-01-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1201.3133",
        "title": "Fractal Descriptors in the Fourier Domain Applied to Color Texture Analysis",
        "authors": [
            "Jo\u00e3o Batista Florindo",
            "Odemir Martinez Bruno"
        ],
        "abstract": "The present work proposes the development of a novel method to provide descriptors for colored texture images. The method consists in two steps. In the first, we apply a linear transform in the color space of the image aiming at highlighting spatial structuring relations among the color of pixels. In a second moment, we apply a multiscale approach to the calculus of fractal dimension based on Fourier transform. From this multiscale operation, we extract the descriptors used to discriminate the texture represented in digital images. The accuracy of the method is verified in the classification of two color texture datasets, by comparing the performance of the proposed technique to other classical and state-of-the-art methods for color texture analysis. The results showed an advantage of almost 3% of the proposed technique over the second best approach.\n    ",
        "submission_date": "2012-01-15T00:00:00",
        "last_modified_date": "2012-02-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1201.3172",
        "title": "Assessing the Value of 3D Reconstruction in Building Construction",
        "authors": [
            "Uma Murthy",
            "David Boardman",
            "Chirag Garg"
        ],
        "abstract": "3-dimensional (3D) reconstruction is an emerging field in image processing and computer vision that aims to create 3D visualizations/ models of objects/ scenes from image sets. However, its commercial applications and benefits are yet to be fully explored. In this paper, we describe ongoing work towards assessing the value of 3D reconstruction in the building construction domain. We present preliminary results from a user study, where our objective is to understand the use of visual information in building construction in order to determine problems with the use of visual information and identify potential benefits and scenarios for the use of 3D reconstruction.\n    ",
        "submission_date": "2012-01-16T00:00:00",
        "last_modified_date": "2012-02-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1201.3410",
        "title": "Multiscale Fractal Descriptors Applied to Nanoscale Images",
        "authors": [
            "Jo\u00e3o B. Florindo",
            "Mariana S. Sikora",
            "Ernesto C. Pereira",
            "Odemir M. Bruno"
        ],
        "abstract": "This work proposes the application of fractal descriptors to the analysis of nanoscale materials under different experimental conditions. We obtain descriptors for images from the sample applying a multiscale transform to the calculation of fractal dimension of a surface map of such image. Particularly, we have used the}Bouligand-Minkowski fractal dimension. We applied these descriptors to discriminate between two titanium oxide films prepared under different experimental conditions. Results demonstrate the discrimination power of proposed descriptors in such kind of application.\n    ",
        "submission_date": "2012-01-17T00:00:00",
        "last_modified_date": "2012-01-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1201.4597",
        "title": "Fractal Descriptors Based on Fourier Spectrum Applied to Texture Analysis",
        "authors": [
            "Jo\u00e3o Batista Florindo",
            "Odemir Martinez Bruno"
        ],
        "abstract": "This work proposes the development and study of a novel technique for the generation of fractal descriptors used in texture analysis. The novel descriptors are obtained from a multiscale transform applied to the Fourier technique of fractal dimension calculus. The power spectrum of the Fourier transform of the image is plotted against the frequency in a log- log scale and a multiscale transform is applied to this curve. The obtained values are taken as the fractal descriptors of the image. The validation of the propose is performed by the use of the descriptors for the classification of a dataset of texture images whose real classes are previously known. The classification precision is compared to other fractal descriptors known in the literature. The results confirm the efficiency of the proposed method.\n    ",
        "submission_date": "2012-01-22T00:00:00",
        "last_modified_date": "2012-01-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1201.5943",
        "title": "Cognitive Memory Network",
        "authors": [
            "Alex Pappachen James",
            "Sima Dimitrijev"
        ],
        "abstract": "A resistive memory network that has no crossover wiring is proposed to overcome the hardware limitations to size and functional complexity that is associated with conventional analogue neural networks. The proposed memory network is based on simple network cells that are arranged in a hierarchical modular architecture. Cognitive functionality of this network is demonstrated by an example of character recognition. The network is trained by an evolutionary process to completely recognise characters deformed by random noise, rotation, scaling and shifting\n    ",
        "submission_date": "2012-01-28T00:00:00",
        "last_modified_date": "2012-01-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1202.0940",
        "title": "Improving feature selection algorithms using normalised feature histograms",
        "authors": [
            "Alex Pappachen James",
            "Akshay Maan"
        ],
        "abstract": "The proposed feature selection method builds a histogram of the most stable features from random subsets of a training set and ranks the features based on a classifier based cross-validation. This approach reduces the instability of features obtained by conventional feature selection methods that occur with variation in training data and selection criteria. Classification results on four microarray and three image datasets using three major feature selection criteria and a naive Bayes classifier show considerable improvement over benchmark results.\n    ",
        "submission_date": "2012-02-05T00:00:00",
        "last_modified_date": "2012-02-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1202.1808",
        "title": "Personalised product design using virtual interactive techniques",
        "authors": [
            "Kurien Zacharia",
            "Eldo P. Elias",
            "Surekha Mariam Varghese"
        ],
        "abstract": "Use of Virtual Interactive Techniques for personalized product design is described in this paper. Usually products are designed and built by considering general usage patterns and Prototyping is used to mimic the static or working behaviour of an actual product before manufacturing the product. The user does not have any control on the design of the product. Personalized design postpones design to a later stage. It allows for personalized selection of individual components by the user. This is implemented by displaying the individual components over a physical model constructed using Cardboard or Thermocol in the actual size and shape of the original product. The components of the equipment or product such as screen, buttons etc. are then projected using a projector connected to the computer into the physical model. Users can interact with the prototype like the original working equipment and they can select, shape, position the individual components displayed on the interaction panel using simple hand gestures. Computer Vision techniques as well as sound processing techniques are used to detect and recognize the user gestures captured using a web camera and microphone.\n    ",
        "submission_date": "2012-02-08T00:00:00",
        "last_modified_date": "2012-02-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1202.2564",
        "title": "A better Beta for the H measure of classification performance",
        "authors": [
            "David J. Hand",
            "Christoforos Anagnostopoulos"
        ],
        "abstract": "The area under the ROC curve is widely used as a measure of performance of classification rules. However, it has recently been shown that the measure is fundamentally incoherent, in the sense that it treats the relative severities of misclassifications differently when different classifiers are used. To overcome this, Hand (2009) proposed the $H$ measure, which allows a given researcher to fix the distribution of relative severities to a classifier-independent setting on a given problem. This note extends the discussion, and proposes a modified standard distribution for the $H$ measure, which better matches the requirements of researchers, in particular those faced with heavily unbalanced datasets, the $Beta(\\pi_1+1,\\pi_0+1)$ distribution. [Preprint submitted at Pattern Recognition Letters]\n    ",
        "submission_date": "2012-02-12T00:00:00",
        "last_modified_date": "2013-08-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1202.4387",
        "title": "Locally Linear Embedding Clustering Algorithm for Natural Imagery",
        "authors": [
            "Lori Ziegelmeier",
            "Michael Kirby",
            "Chris Peterson"
        ],
        "abstract": "The ability to characterize the color content of natural imagery is an important application of image processing. The pixel by pixel coloring of images may be viewed naturally as points in color space, and the inherent structure and distribution of these points affords a quantization, through clustering, of the color information in the image. In this paper, we present a novel topologically driven clustering algorithm that permits segmentation of the color features in a digital image. The algorithm blends Locally Linear Embedding (LLE) and vector quantization by mapping color information to a lower dimensional space, identifying distinct color regions, and classifying pixels together based on both a proximity measure and color content. It is observed that these techniques permit a significant reduction in color resolution while maintaining the visually important features of images.\n    ",
        "submission_date": "2012-02-20T00:00:00",
        "last_modified_date": "2012-02-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1202.4743",
        "title": "Real-time detection and tracking of multiple objects with partial decoding in H.264/AVC bitstream domain",
        "authors": [
            "Wonsang You",
            "M. S. Houari Sabirin",
            "Munchurl Kim"
        ],
        "abstract": "In this paper, we show that we can apply probabilistic spatiotemporal macroblock filtering (PSMF) and partial decoding processes to effectively detect and track multiple objects in real time in H.264|AVC bitstreams with stationary background. Our contribution is that our method cannot only show fast processing time but also handle multiple moving objects that are articulated, changing in size or internally have monotonous color, even though they contain a chaotic set of non-homogeneous motion vectors inside. In addition, our partial decoding process for H.264|AVC bitstreams enables to improve the accuracy of object trajectories and overcome long occlusion by using extracted color information.\n    ",
        "submission_date": "2012-02-21T00:00:00",
        "last_modified_date": "2012-02-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1202.4871",
        "title": "Multilevel Image Encryption",
        "authors": [
            "S. Rakesh",
            "Ajitkumar A Kaller",
            "B. C. Shadakshari",
            "B. Annappa"
        ],
        "abstract": "With the fast evolution of digital data exchange and increased usage of multi media images, it is essential to protect the confidential image data from unauthorized access. In natural images the values and position of the neighbouring pixels are strongly correlated. The method proposed in this paper, breaks this correlation increasing entropy of the position and entropy of pixel values using block shuffling and encryption by chaotic sequence respectively. The plain-image is initially row wise shuffled and first level of encryption is performed using addition modulo operation. The image is divided into blocks and then block based shuffling is performed using Arnold Cat transformation, further the blocks are uniformly scrambled across the image. Finally the shuffled image undergoes second level of encryption by bitwise XOR operation, and then the image as a whole is shuffled column wise to produce the ciphered image for transmission. The experimental results show that the proposed algorithm can successfully encrypt or decrypt the image with the secret keys, and the analysis of the algorithm also demonstrates that the encrypted image has good information entropy and low correlation coefficients.\n    ",
        "submission_date": "2012-02-22T00:00:00",
        "last_modified_date": "2012-02-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1202.4943",
        "title": "A new hybrid jpeg image compression scheme using symbol reduction technique",
        "authors": [
            "Bheshaj Kumar",
            "Kavita Thakur",
            "G. R. Sinha"
        ],
        "abstract": "Lossy JPEG compression is a widely used compression technique. Normally the JPEG standard technique uses three process mapping reduces interpixel redundancy, quantization, which is lossy process and entropy encoding, which is considered lossless process. In this paper, a new technique has been proposed by combining the JPEG algorithm and Symbol Reduction Huffman technique for achieving more compression ratio. The symbols reduction technique reduces the number of symbols by combining together to form a new symbol. As a result of this technique the number of Huffman code to be generated also reduced. It is simple fast and easy to implement. The result shows that the performance of standard JPEG method can be improved by proposed method. This hybrid approach achieves about 20% more compression ratio than the Standard JPEG.\n    ",
        "submission_date": "2012-02-22T00:00:00",
        "last_modified_date": "2012-02-22T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1202.5414",
        "title": "Left-Invariant Diffusion on the Motion Group in terms of the Irreducible Representations of SO(3)",
        "authors": [
            "Marco Reisert",
            "Henrik Skibbe"
        ],
        "abstract": "In this work we study the formulation of convection/diffusion equations on the 3D motion group SE(3) in terms of the irreducible representations of SO(3). Therefore, the left-invariant vector-fields on SE(3) are expressed as linear operators, that are differential forms in the translation coordinate and algebraic in the rotation. In the context of 3D image processing this approach avoids the explicit discretization of SO(3) or $S_2$, respectively. This is particular important for SO(3), where a direct discretization is infeasible due to the enormous memory consumption. We show two applications of the framework: one in the context of diffusion-weighted magnetic resonance imaging and one in the context of object detection.\n    ",
        "submission_date": "2012-02-24T00:00:00",
        "last_modified_date": "2012-02-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1202.5844",
        "title": "Divide-and-Conquer Method for L1 Norm Matrix Factorization in the Presence of Outliers and Missing Data",
        "authors": [
            "Deyu Meng",
            "Zongben Xu"
        ],
        "abstract": "The low-rank matrix factorization as a L1 norm minimization problem has recently attracted much attention due to its intrinsic robustness to the presence of outliers and missing data. In this paper, we propose a new method, called the divide-and-conquer method, for solving this problem. The main idea is to break the original problem into a series of smallest possible sub-problems, each involving only unique scalar parameter. Each of these subproblems is proved to be convex and has closed-form solution. By recursively optimizing these small problems in an analytical way, efficient algorithm, entirely avoiding the time-consuming numerical optimization as an inner loop, for solving the original problem can naturally be constructed. The computational complexity of the proposed algorithm is approximately linear in both data size and dimensionality, making it possible to handle large-scale L1 norm matrix factorization problems. The algorithm is also theoretically proved to be convergent. Based on a series of experiment results, it is substantiated that our method always achieves better results than the current state-of-the-art methods on $L1$ matrix factorization calculation in both computational time and accuracy, especially on large-scale applications such as face recognition and structure from motion.\n    ",
        "submission_date": "2012-02-27T00:00:00",
        "last_modified_date": "2012-04-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1202.6037",
        "title": "Compressed Beamforming in Ultrasound Imaging",
        "authors": [
            "Noam Wagner",
            "Yonina C. Eldar",
            "Zvi Friedman"
        ],
        "abstract": "Emerging sonography techniques often require increasing the number of transducer elements involved in the imaging process. Consequently, larger amounts of data must be acquired and processed. The significant growth in the amounts of data affects both machinery size and power consumption. Within the classical sampling framework, state of the art systems reduce processing rates by exploiting the bandpass bandwidth of the detected signals. It has been recently shown, that a much more significant sample-rate reduction may be obtained, by treating ultrasound signals within the Finite Rate of Innovation framework. These ideas follow the spirit of Xampling, which combines classic methods from sampling theory with recent developments in Compressed Sensing. Applying such low-rate sampling schemes to individual transducer elements, which detect energy reflected from biological tissues, is limited by the noisy nature of the signals. This often results in erroneous parameter extraction, bringing forward the need to enhance the SNR of the low-rate samples. In our work, we achieve SNR enhancement, by beamforming the sub-Nyquist samples obtained from multiple elements. We refer to this process as \"compressed beamforming\". Applying it to cardiac ultrasound data, we successfully image macroscopic perturbations, while achieving a nearly eight-fold reduction in sample-rate, compared to standard techniques.\n    ",
        "submission_date": "2012-02-09T00:00:00",
        "last_modified_date": "2012-04-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1202.6517",
        "title": "Eye Pupil Location Using Webcam",
        "authors": [
            "Michal Ciesla",
            "Przemyslaw Koziol"
        ],
        "abstract": "Three different algorithms used for eye pupil location were described and tested. Algorithm efficiency comparison was based on human faces images taken from the BioID database. Moreover all the eye localisation methods were implemented in a dedicated application supporting eye movement based computer control. In this case human face images were acquired by a webcam and processed in a real-time.\n    ",
        "submission_date": "2012-02-29T00:00:00",
        "last_modified_date": "2012-02-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1202.6666",
        "title": "Perturbation of the Eigenvectors of the Graph Laplacian: Application to Image Denoising",
        "authors": [
            "Francois G. Meyer",
            "Xilin Shen"
        ],
        "abstract": "The original contributions of this paper are twofold: a new understanding of the influence of noise on the eigenvectors of the graph Laplacian of a set of image patches, and an algorithm to estimate a denoised set of patches from a noisy image. The algorithm relies on the following two observations: (1) the low-index eigenvectors of the diffusion, or graph Laplacian, operators are very robust to random perturbations of the weights and random changes in the connections of the patch-graph; and (2) patches extracted from smooth regions of the image are organized along smooth low-dimensional structures in the patch-set, and therefore can be reconstructed with few eigenvectors. Experiments demonstrate that our denoising algorithm outperforms the denoising gold-standards.\n    ",
        "submission_date": "2012-02-29T00:00:00",
        "last_modified_date": "2012-02-29T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1203.1793",
        "title": "Using Hausdorff Distance for New Medical Image Annotation",
        "authors": [
            "Riadh Bouslimi",
            "Jalel Akaichi"
        ],
        "abstract": "Medical images annotation is most of the time a repetitive hard task. Collecting old similar annotations and assigning them to new medical images may not only enhance the annotation process, but also reduce ambiguity caused by repetitive annotations. The goal of this work is to propose an approach based on Hausdorff distance able to compute similarity between a new medical image and old stored images. User has to choose then one of the similar images and annotations related to the selected one are assigned to the new one.\n    ",
        "submission_date": "2012-03-08T00:00:00",
        "last_modified_date": "2012-03-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1203.2992",
        "title": "Hybrid Poisson and multi-Bernoulli filters",
        "authors": [
            "Jason L. Williams"
        ],
        "abstract": "The probability hypothesis density (PHD) and multi-target multi-Bernoulli (MeMBer) filters are two leading algorithms that have emerged from random finite sets (RFS). In this paper we study a method which combines these two approaches. Our work is motivated by a sister paper, which proves that the full Bayes RFS filter naturally incorporates a Poisson component representing targets that have never been detected, and a linear combination of multi-Bernoulli components representing targets under track. Here we demonstrate the benefit (in speed of track initiation) that maintenance of a Poisson component of undetected targets provides. Subsequently, we propose a method of recycling, which projects Bernoulli components with a low probability of existence onto the Poisson component (as opposed to deleting them). We show that this allows us to achieve similar tracking performance using a fraction of the number of Bernoulli components (i.e., tracks).\n    ",
        "submission_date": "2012-03-14T00:00:00",
        "last_modified_date": "2012-03-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1203.2995",
        "title": "Marginal multi-Bernoulli filters: RFS derivation of MHT, JIPDA and association-based MeMBer",
        "authors": [
            "Jason L. Williams"
        ],
        "abstract": "Recent developments in random finite sets (RFSs) have yielded a variety of tracking methods that avoid data association. This paper derives a form of the full Bayes RFS filter and observes that data association is implicitly present, in a data structure similar to MHT. Subsequently, algorithms are obtained by approximating the distribution of associations. Two algorithms result: one nearly identical to JIPDA, and another related to the MeMBer filter. Both improve performance in challenging environments.\n    ",
        "submission_date": "2012-03-14T00:00:00",
        "last_modified_date": "2016-08-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1203.3512",
        "title": "Exact and Approximate Inference in Associative Hierarchical Networks using Graph Cuts",
        "authors": [
            "Chris Russell",
            "L'ubor Ladicky",
            "Pushmeet Kohli",
            "Philip H.S. Torr"
        ],
        "abstract": "Markov Networks are widely used through out computer vision and machine learning. An important subclass are the Associative Markov Networks which are used in a wide variety of applications. For these networks a good approximate minimum cost solution can be found efficiently using graph cut based move making algorithms such as alpha-expansion. Recently a related model has been proposed, the associative hierarchical network, which provides a natural generalisation of the Associative Markov Network for higher order cliques (i.e. clique size greater than two). This method provides a good model for object class segmentation problem in computer vision. Within this paper we briefly describe the associative hierarchical network and provide a computationally efficient method for approximate inference based on graph cuts. Our method performs well for networks containing hundreds of thousand of variables, and higher order potentials are defined over cliques containing tens of thousands of variables. Due to the size of these problems standard linear programming techniques are inapplicable. We show that our method has a bound of 4 for the solution of general associative hierarchical network with arbitrary clique size noting that few results on bounds exist for the solution of labelling of Markov Networks with higher order cliques.\n    ",
        "submission_date": "2012-03-15T00:00:00",
        "last_modified_date": "2012-03-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1203.3530",
        "title": "Hybrid Generative/Discriminative Learning for Automatic Image Annotation",
        "authors": [
            "Shuang Hong Yang",
            "Jiang Bian",
            "Hongyuan Zha"
        ],
        "abstract": "Automatic image annotation (AIA) raises tremendous challenges to machine learning as it requires modeling of data that are both ambiguous in input and output, e.g., images containing multiple objects and labeled with multiple semantic tags. Even more challenging is that the number of candidate tags is usually huge (as large as the vocabulary size) yet each image is only related to a few of them. This paper presents a hybrid generative-discriminative classifier to simultaneously address the extreme data-ambiguity and overfitting-vulnerability issues in tasks such as AIA. Particularly: (1) an Exponential-Multinomial Mixture (EMM) model is established to capture both the input and output ambiguity and in the meanwhile to encourage prediction sparsity; and (2) the prediction ability of the EMM model is explicitly maximized through discriminative learning that integrates variational inference of graphical models and the pairwise formulation of ordinal regression. Experiments show that our approach achieves both superior annotation performance and better tag scalability.\n    ",
        "submission_date": "2012-03-15T00:00:00",
        "last_modified_date": "2012-03-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1203.3537",
        "title": "Automatic Tuning of Interactive Perception Applications",
        "authors": [
            "Qian Zhu",
            "Branislav Kveton",
            "Lily Mummert",
            "Padmanabhan Pillai"
        ],
        "abstract": "Interactive applications incorporating high-data rate sensing and computer vision are becoming possible due to novel runtime systems and the use of parallel computation resources. To allow interactive use, such applications require careful tuning of multiple application parameters to meet required fidelity and latency bounds. This is a nontrivial task, often requiring expert knowledge, which becomes intractable as resources and application load characteristics change. This paper describes a method for automatic performance tuning that learns application characteristics and effects of tunable parameters online, and constructs models that are used to maximize fidelity for a given latency constraint. The paper shows that accurate latency models can be learned online, knowledge of application structure can be used to reduce the complexity of the learning task, and operating points can be found that achieve 90% of the optimal fidelity by exploring the parameter space only 3% of the time.\n    ",
        "submission_date": "2012-03-15T00:00:00",
        "last_modified_date": "2012-03-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1203.4009",
        "title": "Scilab and SIP for Image Processing",
        "authors": [
            "Ricardo Fabbri",
            "Odemir Martinez Bruno",
            "Luciano da Fontoura Costa"
        ],
        "abstract": "This paper is an overview of Image Processing and Analysis using Scilab, a free prototyping environment for numerical calculations similar to Matlab. We demonstrate the capabilities of SIP -- the Scilab Image Processing Toolbox -- which extends Scilab with many functions to read and write images in over 100 major file formats, including PNG, JPEG, BMP, and TIFF. It also provides routines for image filtering, edge detection, blurring, segmentation, shape analysis, and image recognition. Basic directions to install Scilab and SIP are given, and also a mini-tutorial on Scilab. Three practical examples of image analysis are presented, in increasing degrees of complexity, showing how advanced image analysis techniques seems uncomplicated in this environment.\n    ",
        "submission_date": "2012-03-18T00:00:00",
        "last_modified_date": "2012-03-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1203.4176",
        "title": "SignsWorld; Deeping Into the Silence World and Hearing Its Signs (State of the Art)",
        "authors": [
            "A.M. Riad",
            "Hamdy K.Elmonier",
            "Samaa. M. Shohieb",
            "A.S. Asem"
        ],
        "abstract": "Automatic speech processing systems are employed more and more often in real environments. Although the underlying speech technology is mostly language independent, differences between languages with respect to their structure and grammar have substantial effect on the recognition systems performance. In this paper, we present a review of the latest developments in the sign language recognition research in general and in the Arabic sign language (ArSL) in specific. This paper also presents a general framework for improving the deaf community communication with the hearing people that is called SignsWorld. The overall goal of the SignsWorld project is to develop a vision-based technology for recognizing and translating continuous Arabic sign language ArSL.\n    ",
        "submission_date": "2012-03-10T00:00:00",
        "last_modified_date": "2012-03-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1203.4280",
        "title": "Reconstruction of hidden 3D shapes using diffuse reflections",
        "authors": [
            "Otkrist Gupta",
            "Andreas Velten",
            "Thomas Willwacher",
            "Ashok Veeraraghavan",
            "Ramesh Raskar"
        ],
        "abstract": "We analyze multi-bounce propagation of light in an unknown hidden volume and demonstrate that the reflected light contains sufficient information to recover the 3D structure of the hidden scene. We formulate the forward and inverse theory of secondary and tertiary scattering reflection using ideas from energy front propagation and tomography. We show that using careful choice of approximations, such as Fresnel approximation, greatly simplifies this problem and the inversion can be achieved via a backpropagation process. We provide a theoretical analysis of the invertibility, uniqueness and choices of space-time-angle dimensions using synthetic examples. We show that a 2D streak camera can be used to discover and reconstruct hidden geometry. Using a 1D high speed time of flight camera, we show that our method can be used recover 3D shapes of objects \"around the corner\".\n    ",
        "submission_date": "2012-03-19T00:00:00",
        "last_modified_date": "2012-03-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1203.5914",
        "title": "A Framework for Automated Cell Tracking in Phase Contrast Microscopic Videos based on Normal Velocities",
        "authors": [
            "Michael Moeller",
            "Martin Burger",
            "Peter Dieterich",
            "Albrecht Schwab"
        ],
        "abstract": "This paper introduces a novel framework for the automated tracking of cells, with a particular focus on the challenging situation of phase contrast microscopic videos. Our framework is based on a topology preserving variational segmentation approach applied to normal velocity components obtained from optical flow computations, which appears to yield robust tracking and automated extraction of cell trajectories. In order to obtain improved trackings of local shape features we discuss an additional correction step based on active contours and the image Laplacian which we optimize for an example class of transformed renal epithelial (MDCK-F) cells. We also test the framework for human melanoma cells and murine neutrophil granulocytes that were seeded on different types of extracellular matrices. The results are validated with manual tracking results.\n    ",
        "submission_date": "2012-03-27T00:00:00",
        "last_modified_date": "2012-03-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1204.0171",
        "title": "A New Fuzzy Stacked Generalization Technique and Analysis of its Performance",
        "authors": [
            "Mete Ozay",
            "Fatos T. Yarman Vural"
        ],
        "abstract": "In this study, a new Stacked Generalization technique called Fuzzy Stacked Generalization (FSG) is proposed to minimize the difference between N -sample and large-sample classification error of the Nearest Neighbor classifier. The proposed FSG employs a new hierarchical distance learning strategy to minimize the error difference. For this purpose, we first construct an ensemble of base-layer fuzzy k- Nearest Neighbor (k-NN) classifiers, each of which receives a different feature set extracted from the same sample set. The fuzzy membership values computed at the decision space of each fuzzy k-NN classifier are concatenated to form the feature vectors of a fusion space. Finally, the feature vectors are fed to a meta-layer classifier to learn the degree of accuracy of the decisions of the base-layer classifiers for meta-layer classification. Rather than the power of the individual base layer-classifiers, diversity and cooperation of the classifiers become an important issue to improve the overall performance of the proposed FSG. A weak base-layer classifier may boost the overall performance more than a strong classifier, if it is capable of recognizing the samples, which are not recognized by the rest of the classifiers, in its own feature space. The experiments explore the type of the collaboration among the individual classifiers required for an improved performance of the suggested architecture. Experiments on multiple feature real-world datasets show that the proposed FSG performs better than the state of the art ensemble learning algorithms such as Adaboost, Random Subspace and Rotation Forest. On the other hand, compatible performances are observed in the experiments on single feature multi-attribute datasets.\n    ",
        "submission_date": "2012-04-01T00:00:00",
        "last_modified_date": "2013-08-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1204.0684",
        "title": "Validation of nonlinear PCA",
        "authors": [
            "Matthias Scholz"
        ],
        "abstract": "Linear principal component analysis (PCA) can be extended to a nonlinear PCA by using artificial neural networks. But the benefit of curved components requires a careful control of the model complexity. Moreover, standard techniques for model selection, including cross-validation and more generally the use of an independent test set, fail when applied to nonlinear PCA because of its inherent unsupervised characteristics. This paper presents a new approach for validating the complexity of nonlinear PCA models by using the error in missing data estimation as a criterion for model selection. It is motivated by the idea that only the model of optimal complexity is able to predict missing values with the highest accuracy. While standard test set validation usually favours over-fitted nonlinear PCA models, the proposed model validation approach correctly selects the optimal model complexity.\n    ",
        "submission_date": "2012-04-03T00:00:00",
        "last_modified_date": "2012-04-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1204.1277",
        "title": "Mouse Simulation Using Two Coloured Tapes",
        "authors": [
            "Vikram Kumar",
            "Kamran Niyazi",
            "Swapnil Mahe",
            "Swapnil Vyawahare"
        ],
        "abstract": "In this paper, we present a novel approach for Human Computer Interaction (HCI) where, we control cursor movement using a real-time camera. Current methods involve changing mouse parts such as adding more buttons or changing the position of the tracking ball. Instead, our method is to use a camera and computer vision technology, such as image segmentation and gesture recognition, to control mouse tasks (left and right clicking, double-clicking, and scrolling) and we show how it can perform everything as current mouse devices can. The software will be developed in JAVA language. Recognition and pose estimation in this system are user independent and robust as we will be using colour tapes on our finger to perform actions. The software can be used as an intuitive input interface to applications that require multi-dimensional control e.g. computer games etc.\n    ",
        "submission_date": "2012-04-05T00:00:00",
        "last_modified_date": "2012-04-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1204.2311",
        "title": "Robust Nonnegative Matrix Factorization via $L_1$ Norm Regularization",
        "authors": [
            "Bin Shen",
            "Luo Si",
            "Rongrong Ji",
            "Baodi Liu"
        ],
        "abstract": "Nonnegative Matrix Factorization (NMF) is a widely used technique in many applications such as face recognition, motion segmentation, etc. It approximates the nonnegative data in an original high dimensional space with a linear representation in a low dimensional space by using the product of two nonnegative matrices. In many applications data are often partially corrupted with large additive noise. When the positions of noise are known, some existing variants of NMF can be applied by treating these corrupted entries as missing values. However, the positions are often unknown in many real world applications, which prevents the usage of traditional NMF or other existing variants of NMF. This paper proposes a Robust Nonnegative Matrix Factorization (RobustNMF) algorithm that explicitly models the partial corruption as large additive noise without requiring the information of positions of noise. In practice, large additive noise can be used to model outliers. In particular, the proposed method jointly approximates the clean data matrix with the product of two nonnegative matrices and estimates the positions and values of outliers/noise. An efficient iterative optimization algorithm with a solid theoretical justification has been proposed to learn the desired matrix factorization. Experimental results demonstrate the advantages of the proposed algorithm.\n    ",
        "submission_date": "2012-04-11T00:00:00",
        "last_modified_date": "2012-04-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1204.3748",
        "title": "Statistical Multiresolution Estimation for Variational Imaging: With an Application in Poisson-Biophotonics",
        "authors": [
            "Klaus Frick",
            "Philipp Marnitz",
            "Axel Munk"
        ],
        "abstract": "In this paper we present a spatially-adaptive method for image reconstruction that is based on the concept of statistical multiresolution estimation as introduced in [Frick K, Marnitz P, and Munk A. \"Statistical multiresolution Dantzig estimation in imaging: Fundamental concepts and algorithmic framework\". Electron. J. Stat., 6:231-268, 2012]. It constitutes a variational regularization technique that uses an supremum-type distance measure as data-fidelity combined with a convex cost functional. The resulting convex optimization problem is approached by a combination of an inexact alternating direction method of multipliers and Dykstra's projection algorithm. We describe a novel method for balancing data-fit and regularity that is fully automatic and allows for a sound statistical interpretation. The performance of our estimation approach is studied for various problems in imaging. Among others, this includes deconvolution problems that arise in Poisson nanoscale fluorescence microscopy.\n    ",
        "submission_date": "2012-04-17T00:00:00",
        "last_modified_date": "2012-04-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1204.4294",
        "title": "Learning in Riemannian Orbifolds",
        "authors": [
            "Brijnesh J. Jain",
            "Klaus Obermayer"
        ],
        "abstract": "Learning in Riemannian orbifolds is motivated by existing machine learning algorithms that directly operate on finite combinatorial structures such as point patterns, trees, and graphs. These methods, however, lack statistical justification. This contribution derives consistency results for learning problems in structured domains and thereby generalizes learning in vector spaces and manifolds.\n    ",
        "submission_date": "2012-04-19T00:00:00",
        "last_modified_date": "2012-04-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1204.4521",
        "title": "A Privacy-Aware Bayesian Approach for Combining Classifier and Cluster Ensembles",
        "authors": [
            "Ayan Acharya",
            "Eduardo R. Hruschka",
            "Joydeep Ghosh"
        ],
        "abstract": "This paper introduces a privacy-aware Bayesian approach that combines ensembles of classifiers and clusterers to perform semi-supervised and transductive learning. We consider scenarios where instances and their classification/clustering results are distributed across different data sites and have sharing restrictions. As a special case, the privacy aware computation of the model when instances of the target data are distributed across different data sites, is also discussed. Experimental results show that the proposed approach can provide good classification accuracies while adhering to the data/model sharing constraints.\n    ",
        "submission_date": "2012-04-20T00:00:00",
        "last_modified_date": "2012-04-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1204.5309",
        "title": "Analysis Operator Learning and Its Application to Image Reconstruction",
        "authors": [
            "Simon Hawe",
            "Martin Kleinsteuber",
            "Klaus Diepold"
        ],
        "abstract": "Exploiting a priori known structural information lies at the core of many image reconstruction methods that can be stated as inverse problems. The synthesis model, which assumes that images can be decomposed into a linear combination of very few atoms of some dictionary, is now a well established tool for the design of image reconstruction algorithms. An interesting alternative is the analysis model, where the signal is multiplied by an analysis operator and the outcome is assumed to be the sparse. This approach has only recently gained increasing interest. The quality of reconstruction methods based on an analysis model severely depends on the right choice of the suitable operator.\n",
        "submission_date": "2012-04-24T00:00:00",
        "last_modified_date": "2013-03-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1205.1144",
        "title": "Rakeness in the design of Analog-to-Information Conversion of Sparse and Localized Signals",
        "authors": [
            "Mauro Mangia",
            "Riccardo Rovatti",
            "Gianluca Setti"
        ],
        "abstract": "Design of Random Modulation Pre-Integration systems based on the restricted-isometry property may be suboptimal when the energy of the signals to be acquired is not evenly distributed, i.e. when they are both sparse and localized. To counter this, we introduce an additional design criterion, that we call rakeness, accounting for the amount of energy that the measurements capture from the signal to be acquired. Hence, for localized signals a proper system tuning increases the rakeness as well as the average SNR of the samples used in its reconstruction. Yet, maximizing average SNR may go against the need of capturing all the components that are potentially non-zero in a sparse signal, i.e., against the restricted isometry requirement ensuring reconstructability. What we propose is to administer the trade-off between rakeness and restricted isometry in a statistical way by laying down an optimization problem. The solution of such an optimization problem is the statistic of the process generating the random waveforms onto which the signal is projected to obtain the measurements. The formal definition of such a problems is given as well as its solution for signals that are either localized in frequency or in more generic domain. Sample applications, to ECG signals and small images of printed letters and numbers, show that rakeness-based design leads to non-negligible improvements in both cases.\n    ",
        "submission_date": "2012-05-05T00:00:00",
        "last_modified_date": "2012-05-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1205.1225",
        "title": "Volumetric Mapping of Genus Zero Objects via Mass Preservation",
        "authors": [
            "Romeil Sandhu",
            "Ayelet Dominitz",
            "Yi Gao",
            "Allen Tannenbaum"
        ],
        "abstract": "In this work, we present a technique to map any genus zero solid object onto a hexahedral decomposition of a solid cube. This problem appears in many applications ranging from finite element methods to visual tracking. From this, one can then hopefully utilize the proposed technique for shape analysis, registration, as well as other related computer graphics tasks. More importantly, given that we seek to establish a one-to-one correspondence of an input volume to that of a solid cube, our algorithm can naturally generate a quality hexahedral mesh as an output. In addition, we constrain the mapping itself to be volume preserving allowing for the possibility of further mesh simplification. We demonstrate our method both qualitatively and quantitatively on various 3D solid models\n    ",
        "submission_date": "2012-05-06T00:00:00",
        "last_modified_date": "2012-05-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1205.1365",
        "title": "Image Enhancement with Statistical Estimation",
        "authors": [
            "Aroop Mukherjee",
            "Soumen Kanrar"
        ],
        "abstract": "Contrast enhancement is an important area of research for the image analysis. Over the decade, the researcher worked on this domain to develop an efficient and adequate algorithm. The proposed method will enhance the contrast of image using Binarization method with the help of Maximum Likelihood Estimation (MLE). The paper aims to enhance the image contrast of bimodal and multi-modal images. The proposed methodology use to collect mathematical information retrieves from the image. In this paper, we are using binarization method that generates the desired histogram by separating image nodes. It generates the enhanced image using histogram specification with binarization method. The proposed method has showed an improvement in the image contrast enhancement compare with the other image.\n    ",
        "submission_date": "2012-05-07T00:00:00",
        "last_modified_date": "2012-05-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1205.1639",
        "title": "Spectral Analysis of Projection Histogram for Enhancing Close matching character Recognition in Malayalam",
        "authors": [
            "Sajilal Divakaran"
        ],
        "abstract": "The success rates of Optical Character Recognition (OCR) systems for printed Malayalam documents is quite impressive with the state of the art accuracy levels in the range of 85-95% for various. However for real applications, further enhancement of this accuracy levels are required. One of the bottle necks in further enhancement of the accuracy is identified as close-matching characters. In this paper, we delineate the close matching characters in Malayalam and report the development of a specialised classifier for these close-matching characters. The output of a state of the art of OCR is taken and characters falling into the close-matching character set is further fed into this specialised classifier for enhancing the accuracy. The classifier is based on support vector machine algorithm and uses feature vectors derived out of spectral coefficients of projection histogram signals of close-matching characters.\n    ",
        "submission_date": "2012-05-08T00:00:00",
        "last_modified_date": "2012-05-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1205.2382",
        "title": "Mesh Learning for Classifying Cognitive Processes",
        "authors": [
            "Mete Ozay",
            "Ilke \u00d6ztekin",
            "Uygar \u00d6ztekin",
            "Fatos T. Yarman Vural"
        ],
        "abstract": "A relatively recent advance in cognitive neuroscience has been multi-voxel pattern analysis (MVPA), which enables researchers to decode brain states and/or the type of information represented in the brain during a cognitive operation. MVPA methods utilize machine learning algorithms to distinguish among types of information or cognitive states represented in the brain, based on distributed patterns of neural activity. In the current investigation, we propose a new approach for representation of neural data for pattern analysis, namely a Mesh Learning Model. In this approach, at each time instant, a star mesh is formed around each voxel, such that the voxel corresponding to the center node is surrounded by its p-nearest neighbors. The arc weights of each mesh are estimated from the voxel intensity values by least squares method. The estimated arc weights of all the meshes, called Mesh Arc Descriptors (MADs), are then used to train a classifier, such as Neural Networks, k-Nearest Neighbor, Na\u00efve Bayes and Support Vector Machines. The proposed Mesh Model was tested on neuroimaging data acquired via functional magnetic resonance imaging (fMRI) during a recognition memory experiment using categorized word lists, employing a previously established experimental paradigm (\u00d6ztekin & Badre, 2011). Results suggest that the proposed Mesh Learning approach can provide an effective algorithm for pattern analysis of brain activity during cognitive processing.\n    ",
        "submission_date": "2012-05-10T00:00:00",
        "last_modified_date": "2015-02-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1205.2631",
        "title": "Multi-Task Feature Learning Via Efficient l2,1-Norm Minimization",
        "authors": [
            "Jun Liu",
            "Shuiwang Ji",
            "Jieping Ye"
        ],
        "abstract": "The problem of joint feature selection across a group of related tasks has applications in many areas including biomedical informatics and computer vision. We consider the l2,1-norm regularized regression model for joint feature selection from multiple tasks, which can be derived in the probabilistic framework by assuming a suitable prior from the exponential family. One appealing feature of the l2,1-norm regularization is that it encourages multiple predictors to share similar sparsity patterns. However, the resulting optimization problem is challenging to solve due to the non-smoothness of the l2,1-norm regularization. In this paper, we propose to accelerate the computation by reformulating it as two equivalent smooth convex optimization problems which are then solved via the Nesterov's method-an optimal first-order black-box method for smooth convex optimization. A key building block in solving the reformulations is the Euclidean projection. We show that the Euclidean projection for the first reformulation can be analytically computed, while the Euclidean projection for the second one can be computed in linear time. Empirical evaluations on several data sets verify the efficiency of the proposed algorithms.\n    ",
        "submission_date": "2012-05-09T00:00:00",
        "last_modified_date": "2012-05-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1205.2821",
        "title": "Texture Analysis And Characterization Using Probability Fractal Descriptors",
        "authors": [
            "J. B. Florindo",
            "O. M. Bruno"
        ],
        "abstract": "A gray-level image texture descriptors based on fractal dimension estimation is proposed in this work. The proposed method estimates the fractal dimension using probability (Voss) method. The descriptors are computed applying a multiscale transform to the fractal dimension curves of the texture image. The proposed texture descriptor method is evaluated in a classification task of well known benchmark texture datasets. The results show the great performance of the proposed method as a tool for texture images analysis and characterization.\n    ",
        "submission_date": "2012-05-13T00:00:00",
        "last_modified_date": "2012-05-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1205.3336",
        "title": "Distribution of the search of evolutionary product unit neural networks for classification",
        "authors": [
            "A.J. Tall\u00f3n-Ballesteros",
            "P.A. Guti\u00e9rrez-Pe\u00f1a",
            "C. Herv\u00e1s-Mart\u00ednez"
        ],
        "abstract": "This paper deals with the distributed processing in the search for an optimum classification model using evolutionary product unit neural networks. For this distributed search we used a cluster of computers. Our objective is to obtain a more efficient design than those net architectures which do not use a distributed process and which thus result in simpler designs. In order to get the best classification models we use evolutionary algorithms to train and design neural networks, which require a very time consuming computation. The reasons behind the need for this distribution are various. It is complicated to train this type of nets because of the difficulty entailed in determining their architecture due to the complex error surface. On the other hand, the use of evolutionary algorithms involves running a great number of tests with different seeds and parameters, thus resulting in a high computational cost\n    ",
        "submission_date": "2012-05-15T00:00:00",
        "last_modified_date": "2012-05-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1205.3776",
        "title": "The ideal of the trifocal variety",
        "authors": [
            "Chris Aholt",
            "Luke Oeding"
        ],
        "abstract": "Techniques from representation theory, symbolic computational algebra, and numerical algebraic geometry are used to find the minimal generators of the ideal of the trifocal variety. An effective test for determining whether a given tensor is a trifocal tensor is also given.\n    ",
        "submission_date": "2012-05-16T00:00:00",
        "last_modified_date": "2012-05-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1205.3966",
        "title": "Neural Networks for Handwritten English Alphabet Recognition",
        "authors": [
            "Yusuf Perwej",
            "Ashish Chaturvedi"
        ],
        "abstract": "This paper demonstrates the use of neural networks for developing a system that can recognize hand-written English alphabets. In this system, each English alphabet is represented by binary values that are used as input to a simple feature extraction system, whose output is fed to our neural network system.\n    ",
        "submission_date": "2012-05-17T00:00:00",
        "last_modified_date": "2012-05-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1205.5012",
        "title": "Learning Mixed Graphical Models",
        "authors": [
            "Jason D. Lee",
            "Trevor J. Hastie"
        ],
        "abstract": "We consider the problem of learning the structure of a pairwise  graphical model over continuous and discrete variables. We present a  new pairwise model for graphical models with both continuous and  discrete variables that is amenable to structure learning. In  previous work, authors have considered structure learning of  Gaussian graphical models and structure learning of discrete  models. Our approach is a natural generalization of these two lines  of work to the mixed case. The penalization scheme involves a novel  symmetric use of the group-lasso norm and follows naturally from a  particular parametrization of the model.\n    ",
        "submission_date": "2012-05-22T00:00:00",
        "last_modified_date": "2013-07-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1205.6154",
        "title": "Potentials and Limits of Super-Resolution Algorithms and Signal Reconstruction from Sparse Data",
        "authors": [
            "Gil Shabat"
        ],
        "abstract": "A common distortion in videos is image instability in the form of chaotic (global and local displacements). Those instabilities can be used to enhance image resolution by using subpixel elastic registration. In this work, we investigate the performance of such methods over the ability to improve the resolution by accumulating several frames. The second part of this work deals with reconstruction of discrete signals from a subset of samples under different basis functions such as DFT, Haar, Walsh, Daubechies wavelets and CT (Radon) projections.\n    ",
        "submission_date": "2012-05-28T00:00:00",
        "last_modified_date": "2012-05-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1206.2061",
        "title": "Comments on \"On Approximating Euclidean Metrics by Weighted t-Cost Distances in Arbitrary Dimension\"",
        "authors": [
            "M. Emre Celebi",
            "Hassan A. Kingravi",
            "Fatih Celiker"
        ],
        "abstract": "Mukherjee (Pattern Recognition Letters, vol. 32, pp. 824-831, 2011) recently introduced a class of distance functions called weighted t-cost distances that generalize m-neighbor, octagonal, and t-cost distances. He proved that weighted t-cost distances form a family of metrics and derived an approximation for the Euclidean norm in $\\mathbb{Z}^n$. In this note we compare this approximation to two previously proposed Euclidean norm approximations and demonstrate that the empirical average errors given by Mukherjee are significantly optimistic in $\\mathbb{R}^n$. We also propose a simple normalization scheme that improves the accuracy of his approximation substantially with respect to both average and maximum relative errors.\n    ",
        "submission_date": "2012-06-10T00:00:00",
        "last_modified_date": "2012-06-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1206.3564",
        "title": "Functional Currents : a new mathematical tool to model and analyse functional shapes",
        "authors": [
            "Nicolas Charon",
            "Alain Trouv\u00e9"
        ],
        "abstract": "This paper introduces the concept of functional current as a mathematical framework to represent and treat functional shapes, i.e. sub-manifold supported signals. It is motivated by the growing occurrence, in medical imaging and computational anatomy, of what can be described as geometrico-functional data, that is a data structure that involves a deformable shape (roughly a finite dimensional sub manifold) together with a function defined on this shape taking value in another manifold.\n",
        "submission_date": "2012-06-15T00:00:00",
        "last_modified_date": "2012-06-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1206.3975",
        "title": "The Ultrasound Visualization Pipeline - A Survey",
        "authors": [
            "\u00c5smund Birkeland",
            "Veronika Solteszova",
            "Dieter H\u00f6nigmann",
            "Odd Helge Gilja",
            "Svein Brekke",
            "Timo Ropinski",
            "Ivan Viola"
        ],
        "abstract": "Ultrasound is one of the most frequently used imaging modality in medicine. The high spatial resolution, its interactive nature and non-invasiveness makes it the first choice in many examinations. Image interpretation is one of ultrasound's main challenges. Much training is required to obtain a confident skill level in ultrasound-based diagnostics. State-of-the-art graphics techniques is needed to provide meaningful visualizations of ultrasound in real-time. In this paper we present the process-pipeline for ultrasound visualization, including an overview of the tasks performed in the specific steps. To provide an insight into the trends of ultrasound visualization research, we have selected a set of significant publications and divided them into a technique-based taxonomy covering the topics pre-processing, segmentation, registration, rendering and augmented reality. For the different technique types we discuss the difference between ultrasound-based techniques and techniques for other modalities.\n    ",
        "submission_date": "2012-06-18T00:00:00",
        "last_modified_date": "2012-06-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1206.4074",
        "title": "A Linear Approximation to the chi^2 Kernel with Geometric Convergence",
        "authors": [
            "Fuxin Li",
            "Guy Lebanon",
            "Cristian Sminchisescu"
        ],
        "abstract": "We propose a new analytical approximation to the $\\chi^2$ kernel that converges geometrically. The analytical approximation is derived with elementary methods and adapts to the input distribution for optimal convergence rate. Experiments show the new approximation leads to improved performance in image classification and semantic segmentation tasks using a random Fourier feature approximation of the $\\exp-\\chi^2$ kernel. Besides, out-of-core principal component analysis (PCA) methods are introduced to reduce the dimensionality of the approximation and achieve better performance at the expense of only an additional constant factor to the time complexity. Moreover, when PCA is performed jointly on the training and unlabeled testing data, further performance improvements can be obtained. Experiments conducted on the PASCAL VOC 2010 segmentation and the ImageNet ILSVRC 2010 datasets show statistically significant improvements over alternative approximation methods.\n    ",
        "submission_date": "2012-06-18T00:00:00",
        "last_modified_date": "2013-06-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1206.4326",
        "title": "Joint Reconstruction of Multi-view Compressed Images",
        "authors": [
            "Vijayaraghavan Thirumalai",
            "Pascal Frossard"
        ],
        "abstract": "The distributed representation of correlated multi-view images is an important problem that arise in vision sensor networks. This paper concentrates on the joint reconstruction problem where the distributively compressed correlated images are jointly decoded in order to improve the reconstruction quality of all the compressed images. We consider a scenario where the images captured at different viewpoints are encoded independently using common coding solutions (e.g., JPEG, H.264 intra) with a balanced rate distribution among different cameras. A central decoder first estimates the underlying correlation model from the independently compressed images which will be used for the joint signal recovery. The joint reconstruction is then cast as a constrained convex optimization problem that reconstructs total-variation (TV) smooth images that comply with the estimated correlation model. At the same time, we add constraints that force the reconstructed images to be consistent with their compressed versions. We show by experiments that the proposed joint reconstruction scheme outperforms independent reconstruction in terms of image quality, for a given target bit rate. In addition, the decoding performance of our proposed algorithm compares advantageously to state-of-the-art distributed coding schemes based on disparity learning and on the DISCOVER.\n    ",
        "submission_date": "2012-06-19T00:00:00",
        "last_modified_date": "2012-06-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1206.4610",
        "title": "Manifold Relevance Determination",
        "authors": [
            "Andreas Damianou",
            "Carl Ek",
            "Michalis Titsias",
            "Neil Lawrence"
        ],
        "abstract": "In this paper we present a fully Bayesian latent variable model which exploits conditional nonlinear(in)-dependence structures to learn an efficient latent representation. The latent space is factorized to represent shared and private information from multiple views of the data. In contrast to previous approaches, we introduce a relaxation to the discrete segmentation and allow for a \"softly\" shared latent space. Further, Bayesian techniques allow us to automatically estimate the dimensionality of the latent spaces. The model is capable of capturing structure underlying extremely high dimensional spaces. This is illustrated by modelling unprocessed images with tenths of thousands of pixels. This also allows us to directly generate novel images from the trained model by sampling from the discovered latent spaces. We also demonstrate the model by prediction of human pose in an ambiguous setting. Our Bayesian framework allows us to perform disambiguation in a principled manner by including latent space priors which incorporate the dynamic nature of the data.\n    ",
        "submission_date": "2012-06-18T00:00:00",
        "last_modified_date": "2012-06-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1206.4636",
        "title": "Modeling Latent Variable Uncertainty for Loss-based Learning",
        "authors": [
            "M. Pawan Kumar",
            "Ben Packer",
            "Daphne Koller"
        ],
        "abstract": "We consider the problem of parameter estimation using weakly supervised datasets, where a training sample consists of the input and a partially specified annotation, which we refer to as the output. The missing information in the annotation is modeled using latent variables. Previous methods overburden a single distribution with two separate tasks: (i) modeling the uncertainty in the latent variables during training; and (ii) making accurate predictions for the output and the latent variables during testing. We propose a novel framework that separates the demands of the two tasks using two distributions: (i) a conditional distribution to model the uncertainty of the latent variables for a given input-output pair; and (ii) a delta distribution to predict the output and the latent variables for a given input. During learning, we encourage agreement between the two distributions by minimizing a loss-based dissimilarity coefficient. Our approach generalizes latent SVM in two important ways: (i) it models the uncertainty over latent variables instead of relying on a pointwise estimate; and (ii) it allows the use of loss functions that depend on latent variables, which greatly increases its applicability. We demonstrate the efficacy of our approach on two challenging problems---object detection and action detection---using publicly available datasets.\n    ",
        "submission_date": "2012-06-18T00:00:00",
        "last_modified_date": "2012-06-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1206.4641",
        "title": "Total Variation and Euler's Elastica for Supervised Learning",
        "authors": [
            "Tong Lin",
            "Hanlin Xue",
            "Ling Wang",
            "Hongbin Zha"
        ],
        "abstract": "In recent years, total variation (TV) and Euler's elastica (EE) have been successfully applied to image processing tasks such as denoising and inpainting. This paper investigates how to extend TV and EE to the supervised learning settings on high dimensional data. The supervised learning problem can be formulated as an energy functional minimization under Tikhonov regularization scheme, where the energy is composed of a squared loss and a total variation smoothing (or Euler's elastica smoothing). Its solution via variational principles leads to an Euler-Lagrange PDE. However, the PDE is always high-dimensional and cannot be directly solved by common methods. Instead, radial basis functions are utilized to approximate the target function, reducing the problem to finding the linear coefficients of basis functions. We apply the proposed methods to supervised learning tasks (including binary classification, multi-class classification, and regression) on benchmark data sets. Extensive experiments have demonstrated promising results of the proposed methods.\n    ",
        "submission_date": "2012-06-18T00:00:00",
        "last_modified_date": "2012-06-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1206.4649",
        "title": "Learning Efficient Structured Sparse Models",
        "authors": [
            "Alex Bronstein",
            "Pablo Sprechmann",
            "Guillermo Sapiro"
        ],
        "abstract": "We present a comprehensive framework for structured sparse coding and modeling extending the recent ideas of using learnable fast regressors to approximate exact sparse codes. For this purpose, we develop a novel block-coordinate proximal splitting method for the iterative solution of hierarchical sparse coding problems, and show an efficient feed forward architecture derived from its iteration. This architecture faithfully approximates the exact structured sparse codes with a fraction of the complexity of the standard optimization methods. We also show that by using different training objective functions, learnable sparse encoders are no longer restricted to be mere approximants of the exact sparse code for a pre-given dictionary, as in earlier formulations, but can be rather used as full-featured sparse encoders or even modelers. A simple implementation shows several orders of magnitude speedup compared to the state-of-the-art at minimal performance degradation, making the proposed framework suitable for real time and large-scale applications.\n    ",
        "submission_date": "2012-06-18T00:00:00",
        "last_modified_date": "2012-06-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1206.4651",
        "title": "Is margin preserved after random projection?",
        "authors": [
            "Qinfeng Shi",
            "Chunhua Shen",
            "Rhys Hill",
            "Anton van den Hengel"
        ],
        "abstract": "Random projections have been applied in many machine learning algorithms. However, whether margin is preserved after random projection is non-trivial and not well studied. In this paper we analyse margin distortion after random projection, and give the conditions of margin preservation for binary classification problems. We also extend our analysis to margin for multiclass problems, and provide theoretical bounds on multiclass margin on the projected data.\n    ",
        "submission_date": "2012-06-18T00:00:00",
        "last_modified_date": "2012-06-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1206.4653",
        "title": "Dimensionality Reduction by Local Discriminative Gaussians",
        "authors": [
            "Nathan Parrish",
            "Maya Gupta"
        ],
        "abstract": "We present local discriminative Gaussian (LDG) dimensionality reduction, a supervised dimensionality reduction technique for classification. The LDG objective function is an approximation to the leave-one-out training error of a local quadratic discriminant analysis classifier, and thus acts locally to each training point in order to find a mapping where similar data can be discriminated from dissimilar data. While other state-of-the-art linear dimensionality reduction methods require gradient descent or iterative solution approaches, LDG is solved with a single eigen-decomposition. Thus, it scales better for datasets with a large number of feature dimensions or training examples. We also adapt LDG to the transfer learning setting, and show that it achieves good performance when the test data distribution differs from that of the training data.\n    ",
        "submission_date": "2012-06-18T00:00:00",
        "last_modified_date": "2012-06-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1206.4676",
        "title": "Clustering by Low-Rank Doubly Stochastic Matrix Decomposition",
        "authors": [
            "Zhirong Yang",
            "Erkki Oja"
        ],
        "abstract": "Clustering analysis by nonnegative low-rank approximations has achieved remarkable progress in the past decade. However, most approximation approaches in this direction are still restricted to matrix factorization. We propose a new low-rank learning method to improve the clustering performance, which is beyond matrix factorization. The approximation is based on a two-step bipartite random walk through virtual cluster nodes, where the approximation is formed by only cluster assigning probabilities. Minimizing the approximation error measured by Kullback-Leibler divergence is equivalent to maximizing the likelihood of a discriminative model, which endows our method with a solid probabilistic interpretation. The optimization is implemented by a relaxed Majorization-Minimization algorithm that is advantageous in finding good local minima. Furthermore, we point out that the regularized algorithm with Dirichlet prior only serves as initialization. Experimental results show that the new method has strong performance in clustering purity for various datasets, especially for large-scale manifold data.\n    ",
        "submission_date": "2012-06-18T00:00:00",
        "last_modified_date": "2012-06-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1206.5248",
        "title": "Statistical Translation, Heat Kernels and Expected Distances",
        "authors": [
            "Joshua Dillon",
            "Yi Mao",
            "Guy Lebanon",
            "Jian Zhang"
        ],
        "abstract": "High dimensional structured data such as text and images is often poorly understood and misrepresented in statistical modeling. The standard histogram representation suffers from high variance and performs poorly in general. We explore novel connections between statistical translation, heat kernels on manifolds and graphs, and expected distances. These connections provide a new framework for unsupervised metric learning for text documents. Experiments indicate that the resulting distances are generally superior to their more standard counterparts.\n    ",
        "submission_date": "2012-06-20T00:00:00",
        "last_modified_date": "2012-06-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1206.6418",
        "title": "Learning Invariant Representations with Local Transformations",
        "authors": [
            "Kihyuk Sohn",
            "Honglak Lee"
        ],
        "abstract": "Learning invariant representations is an important problem in machine learning and pattern recognition. In this paper, we present a novel framework of transformation-invariant feature learning by incorporating linear transformations into the feature learning algorithms. For example, we present the transformation-invariant restricted Boltzmann machine that compactly represents data by its weights and their transformations, which achieves invariance of the feature representation via probabilistic max pooling. In addition, we show that our transformation-invariant feature learning framework can also be extended to other unsupervised learning methods, such as autoencoders or sparse coding. We evaluate our method on several image classification benchmark datasets, such as MNIST variations, CIFAR-10, and STL-10, and show competitive or superior classification performance when compared to the state-of-the-art. Furthermore, our method achieves state-of-the-art performance on phone classification tasks with the TIMIT dataset, which demonstrates wide applicability of our proposed algorithms to other domains.\n    ",
        "submission_date": "2012-06-27T00:00:00",
        "last_modified_date": "2012-06-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1206.6429",
        "title": "Incorporating Domain Knowledge in Matching Problems via Harmonic Analysis",
        "authors": [
            "Deepti Pachauri",
            "Maxwell Collins",
            "Vikas SIngh",
            "Risi Kondor"
        ],
        "abstract": "Matching one set of objects to another is a ubiquitous task in machine learning and computer vision that often reduces to some form of the quadratic assignment problem (QAP). The QAP is known to be notoriously hard, both in theory and in practice. Here, we investigate if this difficulty can be mitigated when some additional piece of information is available: (a) that all QAP instances of interest come from the same application, and (b) the correct solution for a set of such QAP instances is given. We propose a new approach to accelerate the solution of QAPs based on learning parameters for a modified objective function from prior QAP instances. A key feature of our approach is that it takes advantage of the algebraic structure of permutations, in conjunction with special methods for optimizing functions over the symmetric group Sn in Fourier space. Experiments show that in practical domains the new method can outperform existing approaches.\n    ",
        "submission_date": "2012-06-27T00:00:00",
        "last_modified_date": "2012-06-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1206.6447",
        "title": "Small-sample Brain Mapping: Sparse Recovery on Spatially Correlated Designs with Randomization and Clustering",
        "authors": [
            "Gael Varoquaux",
            "Alexandre Gramfort",
            "Bertrand Thirion"
        ],
        "abstract": "Functional neuroimaging can measure the brain?s response to an external stimulus. It is used to perform brain mapping: identifying from these observations the brain regions involved. This problem can be cast into a linear supervised learning task where the neuroimaging data are used as predictors for the stimulus. Brain mapping is then seen as a support recovery problem. On functional MRI (fMRI) data, this problem is particularly challenging as i) the number of samples is small due to limited acquisition time and ii) the variables are strongly correlated. We propose to overcome these difficulties using sparse regression models over new variables obtained by clustering of the original variables. The use of randomization techniques, e.g. bootstrap samples, and clustering of the variables improves the recovery properties of sparse methods. We demonstrate the benefit of our approach on an extensive simulation study as well as two fMRI datasets.\n    ",
        "submission_date": "2012-06-27T00:00:00",
        "last_modified_date": "2012-06-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1206.6462",
        "title": "Learning Object Arrangements in 3D Scenes using Human Context",
        "authors": [
            "Yun Jiang",
            "Marcus Lim",
            "Ashutosh Saxena"
        ],
        "abstract": "We consider the problem of learning object arrangements in a 3D scene. The key idea here is to learn how objects relate to human poses based on their affordances, ease of use and reachability. In contrast to modeling object-object relationships, modeling human-object relationships scales linearly in the number of objects. We design appropriate density functions based on 3D spatial features to capture this. We learn the distribution of human poses in a scene using a variant of the Dirichlet process mixture model that allows sharing of the density function parameters across the same object types. Then we can reason about arrangements of the objects in the room based on these meaningful human poses. In our extensive experiments on 20 different rooms with a total of 47 objects, our algorithm predicted correct placements with an average error of 1.6 meters from ground truth. In arranging five real scenes, it received a score of 4.3/5 compared to 3.7 for the best baseline method.\n    ",
        "submission_date": "2012-06-27T00:00:00",
        "last_modified_date": "2012-06-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1206.6679",
        "title": "Fixed-Form Variational Posterior Approximation through Stochastic Linear Regression",
        "authors": [
            "Tim Salimans",
            "David A. Knowles"
        ],
        "abstract": "We propose a general algorithm for approximating nonstandard Bayesian posterior distributions. The algorithm minimizes the Kullback-Leibler divergence of an approximating distribution to the intractable posterior distribution. Our method can be used to approximate any posterior distribution, provided that it is given in closed form up to the proportionality constant. The approximation can be any distribution in the exponential family or any mixture of such distributions, which means that it can be made arbitrarily precise. Several examples illustrate the speed and accuracy of our approximation method in practice.\n    ",
        "submission_date": "2012-06-28T00:00:00",
        "last_modified_date": "2014-07-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1207.0170",
        "title": "Single parameter galaxy classification: The Principal Curve through the multi-dimensional space of galaxy properties",
        "authors": [
            "M. Taghizadeh-Popp",
            "S. Heinis",
            "A. S. Szalay"
        ],
        "abstract": "We propose to describe the variety of galaxies from SDSS by using only one affine parameter. To this aim, we build the Principal Curve (P-curve) passing through the spine of the data point cloud, considering the eigenspace derived from Principal Component Analysis of morphological, physical and photometric galaxy properties. Thus, galaxies can be labeled, ranked and classified by a single arc length value of the curve, measured at the unique closest projection of the data points on the P-curve. We find that the P-curve has a \"W\" letter shape with 3 turning points, defining 4 branches that represent distinct galaxy populations. This behavior is controlled mainly by 2 properties, namely u-r and SFR. We further present the variations of several galaxy properties as a function of arc length. Luminosity functions variate from steep Schechter fits at low arc length, to double power law and ending in Log-normal fits at high arc length. Galaxy clustering shows increasing autocorrelation power at large scales as arc length increases. PCA analysis allowed to find peculiar galaxy populations located apart from the main cloud of data points, such as small red galaxies dominated by a disk, of relatively high stellar mass-to-light ratio and surface mass density. The P-curve allows not only dimensionality reduction, but also provides supporting evidence for relevant physical models and scenarios in extragalactic astronomy: 1) Evidence for the hierarchical merging scenario in the formation of a selected group of red massive galaxies. These galaxies present a log-normal r-band luminosity function, which might arise from multiplicative processes involved in this scenario. 2) Connection between the onset of AGN activity and star formation quenching, which appears in green galaxies when transitioning from blue to red populations. (Full abstract in downloadable version)\n    ",
        "submission_date": "2012-07-01T00:00:00",
        "last_modified_date": "2012-07-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1207.0580",
        "title": "Improving neural networks by preventing co-adaptation of feature detectors",
        "authors": [
            "Geoffrey E. Hinton",
            "Nitish Srivastava",
            "Alex Krizhevsky",
            "Ilya Sutskever",
            "Ruslan R. Salakhutdinov"
        ],
        "abstract": "When a large feedforward neural network is trained on a small training set, it typically performs poorly on held-out test data. This \"overfitting\" is greatly reduced by randomly omitting half of the feature detectors on each training case. This prevents complex co-adaptations in which a feature detector is only helpful in the context of several other specific feature detectors. Instead, each neuron learns to detect a feature that is generally helpful for producing the correct answer given the combinatorially large variety of internal contexts in which it must operate. Random \"dropout\" gives big improvements on many benchmark tasks and sets new records for speech and object recognition.\n    ",
        "submission_date": "2012-07-03T00:00:00",
        "last_modified_date": "2012-07-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1207.0677",
        "title": "Local Water Diffusion Phenomenon Clustering From High Angular Resolution Diffusion Imaging (HARDI)",
        "authors": [
            "Romain Giot",
            "Christophe Charrier",
            "Maxime Descoteaux"
        ],
        "abstract": "The understanding of neurodegenerative diseases undoubtedly passes through the study of human brain white matter fiber tracts. To date, diffusion magnetic resonance imaging (dMRI) is the unique technique to obtain information about the neural architecture of the human brain, thus permitting the study of white matter connections and their integrity. However, a remaining challenge of the dMRI community is to better characterize complex fiber crossing configurations, where diffusion tensor imaging (DTI) is limited but high angular resolution diffusion imaging (HARDI) now brings solutions. This paper investigates the development of both identification and classification process of the local water diffusion phenomenon based on HARDI data to automatically detect imaging voxels where there are single and crossing fiber bundle populations. The technique is based on knowledge extraction processes and is validated on a dMRI phantom dataset with ground truth.\n    ",
        "submission_date": "2012-07-03T00:00:00",
        "last_modified_date": "2012-07-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1207.0704",
        "title": "Speckle Reduction using Stochastic Distances",
        "authors": [
            "Leonardo Torres",
            "Tamer Cavalcante",
            "Alejandro C. Frery"
        ],
        "abstract": "This paper presents a new approach for filter design based on stochastic distances and tests between distributions. A window is defined around each pixel, samples are compared and only those which pass a goodness-of-fit test are used to compute the filtered value. The technique is applied to intensity Synthetic Aperture Radar (SAR) data, using the Gamma model with varying number of looks allowing, thus, changes in heterogeneity. Modified Nagao-Matsuyama windows are used to define the samples. The proposal is compared with the Lee's filter which is considered a standard, using a protocol based on simulation. Among the criteria used to quantify the quality of filters, we employ the equivalent number of looks (related to the signal-to-noise ratio), line contrast, and edge preservation. Moreover, we also assessed the filters by the Universal Image Quality Index and the Pearson's correlation between edges.\n    ",
        "submission_date": "2012-07-03T00:00:00",
        "last_modified_date": "2012-07-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1207.0771",
        "title": "Polarimetric SAR Image Smoothing with Stochastic Distances",
        "authors": [
            "Leonardo Torres",
            "Antonio C. Medeiros",
            "Alejandro C. Frery"
        ],
        "abstract": "Polarimetric Synthetic Aperture Radar (PolSAR) images are establishing as an important source of information in remote sensing applications. The most complete format this type of imaging produces consists of complex-valued Hermitian matrices in every image coordinate and, as such, their visualization is challenging. They also suffer from speckle noise which reduces the signal-to-noise ratio. Smoothing techniques have been proposed in the literature aiming at preserving different features and, analogously, projections from the cone of Hermitian positive matrices to different color representation spaces are used for enhancing certain characteristics. In this work we propose the use of stochastic distances between models that describe this type of data in a Nagao-Matsuyama-type of smoothing technique. The resulting images are shown to present good visualization properties (noise reduction with preservation of fine details) in all the considered visualization spaces.\n    ",
        "submission_date": "2012-07-03T00:00:00",
        "last_modified_date": "2012-07-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1207.1019",
        "title": "PAC-Bayesian Majority Vote for Late Classifier Fusion",
        "authors": [
            "Emilie Morvant",
            "Amaury Habrard",
            "St\u00e9phane Ayache"
        ],
        "abstract": "A lot of attention has been devoted to multimedia indexing over the past few years. In the literature, we often consider two kinds of fusion schemes: The early fusion and the late fusion. In this paper we focus on late classifier fusion, where one combines the scores of each modality at the decision level. To tackle this problem, we investigate a recent and elegant well-founded quadratic program named MinCq coming from the Machine Learning PAC-Bayes theory. MinCq looks for the weighted combination, over a set of real-valued functions seen as voters, leading to the lowest misclassification rate, while making use of the voters' diversity. We provide evidence that this method is naturally adapted to late fusion procedure. We propose an extension of MinCq by adding an order- preserving pairwise loss for ranking, helping to improve Mean Averaged Precision measure. We confirm the good behavior of the MinCq-based fusion approaches with experiments on a real image benchmark.\n    ",
        "submission_date": "2012-07-04T00:00:00",
        "last_modified_date": "2012-07-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1207.1915",
        "title": "Nonparametric Edge Detection in Speckled Imagery",
        "authors": [
            "Edwin Gir\u00f3n",
            "Alejandro C. Frery",
            "Francisco Cribari-Neto"
        ],
        "abstract": "We address the issue of edge detection in Synthetic Aperture Radar imagery. In particular, we propose nonparametric methods for edge detection, and numerically compare them to an alternative method that has been recently proposed in the literature. Our results show that some of the proposed methods display superior results and are computationally simpler than the existing method. An application to real (not simulated) data is presented and discussed.\n    ",
        "submission_date": "2012-07-08T00:00:00",
        "last_modified_date": "2012-07-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1207.2268",
        "title": "Improvement of ISOM by using filter",
        "authors": [
            "Imen Chaabouni",
            "Wiem Fourati",
            "Med Salim Bouhlel"
        ],
        "abstract": "Image compression helps in storing the transmitted data in proficient way by decreasing its redundancy. This technique helps in transferring more digital or multimedia data over internet as it increases the storage space. It is important to maintain the image quality even if it is compressed to certain extent. Depend upon this the image compression is classified into two categories : lossy and lossless image compression. There are many lossy digital image compression techniques exists. Among this Incremental Self Organizing Map is a familiar one. The good pictures quality can be retrieved if image denoising technique is used for compression and also provides better compression ratio. Image denoising is an important pre-processing step for many image analysis and computer vision system. It refers to the task of recovering a good estimate of the true image from a degraded observation without altering and changing useful structure in the image such as discontinuities and edges. Many approaches have been proposed to remove the noise effectively while preserving the original image details and features as much as possible. This paper proposes a technique for image compression using Incremental Self Organizing Map (ISOM) with Discret Wavelet Transform (DWT) by applying filtering techniques which play a crucial role in enhancing the quality of a reconstructed image. The experimental result shows that the proposed technique obtained better compression ratio value.\n    ",
        "submission_date": "2012-07-10T00:00:00",
        "last_modified_date": "2012-07-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1207.2422",
        "title": "Dual-Space Analysis of the Sparse Linear Model",
        "authors": [
            "David Wipf",
            "Yi Wu"
        ],
        "abstract": "Sparse linear (or generalized linear) models combine a standard likelihood function with a sparse prior on the unknown coefficients. These priors can conveniently be expressed as a maximization over zero-mean Gaussians with different variance hyperparameters. Standard MAP estimation (Type I) involves maximizing over both the hyperparameters and coefficients, while an empirical Bayesian alternative (Type II) first marginalizes the coefficients and then maximizes over the hyperparameters, leading to a tractable posterior approximation. The underlying cost functions can be related via a dual-space framework from Wipf et al. (2011), which allows both the Type I or Type II objectives to be expressed in either coefficient or hyperparmeter space. This perspective is useful because some analyses or extensions are more conducive to development in one space or the other. Herein we consider the estimation of a trade-off parameter balancing sparsity and data fit. As this parameter is effectively a variance, natural estimators exist by assessing the problem in hyperparameter (variance) space, transitioning natural ideas from Type II to solve what is much less intuitive for Type I. In contrast, for analyses of update rules and sparsity properties of local and global solutions, as well as extensions to more general likelihood models, we can leverage coefficient-space techniques developed for Type I and apply them to Type II. For example, this allows us to prove that Type II-inspired techniques can be successful recovering sparse coefficients when unfavorable restricted isometry properties (RIP) lead to failure of popular L1 reconstructions. It also facilitates the analysis of Type II when non-Gaussian likelihood models lead to intractable integrations.\n    ",
        "submission_date": "2012-07-10T00:00:00",
        "last_modified_date": "2012-07-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1207.2440",
        "title": "Non-Convex Rank Minimization via an Empirical Bayesian Approach",
        "authors": [
            "David Wipf"
        ],
        "abstract": "In many applications that require matrix solutions of minimal rank, the underlying cost function is non-convex leading to an intractable, NP-hard optimization problem. Consequently, the convex nuclear norm is frequently used as a surrogate penalty term for matrix rank. The problem is that in many practical scenarios there is no longer any guarantee that we can correctly estimate generative low-rank matrices of interest, theoretical special cases notwithstanding. Consequently, this paper proposes an alternative empirical Bayesian procedure build upon a variational approximation that, unlike the nuclear norm, retains the same globally minimizing point estimate as the rank function under many useful constraints. However, locally minimizing solutions are largely smoothed away via marginalization, allowing the algorithm to succeed when standard convex relaxations completely fail. While the proposed methodology is generally applicable to a wide range of low-rank applications, we focus our attention on the robust principal component analysis problem (RPCA), which involves estimating an unknown low-rank matrix with unknown sparse corruptions. Theoretical and empirical evidence are presented to show that our method is potentially superior to related MAP-based approaches, for which the convex principle component pursuit (PCP) algorithm (Candes et al., 2011) can be viewed as a special case.\n    ",
        "submission_date": "2012-07-10T00:00:00",
        "last_modified_date": "2012-07-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1207.3394",
        "title": "Dimension Reduction by Mutual Information Feature Extraction",
        "authors": [
            "Ali Shadvar"
        ],
        "abstract": "During the past decades, to study high-dimensional data in a large variety of problems, researchers have proposed many Feature Extraction algorithms. One of the most effective approaches for optimal feature extraction is based on mutual information (MI). However it is not always easy to get an accurate estimation for high dimensional MI. In terms of MI, the optimal feature extraction is creating a feature set from the data which jointly have the largest dependency on the target class and minimum redundancy. In this paper, a component-by-component gradient ascent method is proposed for feature extraction which is based on one-dimensional MI estimates. We will refer to this algorithm as Mutual Information Feature Extraction (MIFX). The performance of this proposed method is evaluated using UCI databases. The results indicate that MIFX provides a robust performance over different data sets which are almost always the best or comparable to the best ones.\n    ",
        "submission_date": "2012-07-14T00:00:00",
        "last_modified_date": "2012-07-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1207.3598",
        "title": "Learning to rank from medical imaging data",
        "authors": [
            "Fabian Pedregosa",
            "Alexandre Gramfort",
            "Ga\u00ebl Varoquaux",
            "Elodie Cauvet",
            "Christophe Pallier",
            "Bertrand Thirion"
        ],
        "abstract": "Medical images can be used to predict a clinical score coding for the severity of a disease, a pain level or the complexity of a cognitive task. In all these cases, the predicted variable has a natural order. While a standard classifier discards this information, we would like to take it into account in order to improve prediction performance. A standard linear regression does model such information, however the linearity assumption is likely not be satisfied when predicting from pixel intensities in an image. In this paper we address these modeling challenges with a supervised learning procedure where the model aims to order or rank images. We use a linear model for its robustness in high dimension and its possible interpretation. We show on simulations and two fMRI datasets that this approach is able to predict the correct ordering on pairs of images, yielding higher prediction accuracy than standard regression and multiclass classification techniques.\n    ",
        "submission_date": "2012-07-16T00:00:00",
        "last_modified_date": "2012-09-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1207.3603",
        "title": "Qualitative Comparison of Community Detection Algorithms",
        "authors": [
            "G\u00fcnce Orman",
            "Vincent Labatut",
            "Hocine Cherifi"
        ],
        "abstract": "Community detection is a very active field in complex networks analysis, consisting in identifying groups of nodes more densely interconnected relatively to the rest of the network. The existing algorithms are usually tested and compared on real-world and artificial networks, their performance being assessed through some partition similarity measure. However, artificial networks realism can be questioned, and the appropriateness of those measures is not obvious. In this study, we take advantage of recent advances concerning the characterization of community structures to tackle these questions. We first generate networks thanks to the most realistic model available to date. Their analysis reveals they display only some of the properties observed in real-world community structures. We then apply five community detection algorithms on these networks and find out the performance assessed quantitatively does not necessarily agree with a qualitative analysis of the identified communities. It therefore seems both approaches should be applied to perform a relevant comparison of the algorithms.\n    ",
        "submission_date": "2012-07-16T00:00:00",
        "last_modified_date": "2012-07-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1207.3962",
        "title": "Computation of the Hausdorff distance between sets of line segments in parallel",
        "authors": [
            "Helmut Alt",
            "Ludmila Scharf"
        ],
        "abstract": "We show that the Hausdorff distance for two sets of non-intersecting line segments can be computed in parallel in $O(\\log^2 n)$ time using O(n) processors in a CREW-PRAM computation model. We discuss how some parts of the sequential algorithm can be performed in parallel using previously known parallel algorithms; and identify the so-far unsolved part of the problem for the parallel computation, which is the following: Given two sets of $x$-monotone curve segments, red and blue, for each red segment find its extremal intersection points with the blue set, i.e. points with the minimal and maximal $x$-coordinate. Each segment set is assumed to be intersection free. For this intersection problem we describe a parallel algorithm which completes the Hausdorff distance computation within the stated time and processor bounds.\n    ",
        "submission_date": "2012-07-17T00:00:00",
        "last_modified_date": "2012-07-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1207.4259",
        "title": "Content Based Multimedia Information Retrieval to Support Digital Libraries",
        "authors": [
            "Mohammad Nabil Almunawar"
        ],
        "abstract": "Content-based multimedia information retrieval is an interesting research area since it allows retrieval based on inherent characteristic of multimedia objects. For example retrieval based on visual characteristics such as colour, shapes or textures of objects in images or retrieval based on spatial relationships among objects in the media (images or video clips). This paper reviews some work done in image and video retrieval and then proposes an integrated model that can handle images and video clips uniformly. Using this model retrieval on images or video clips can be done based on the same framework.\n    ",
        "submission_date": "2012-07-18T00:00:00",
        "last_modified_date": "2012-07-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1207.5326",
        "title": "Guarantees of Augmented Trace Norm Models in Tensor Recovery",
        "authors": [
            "Ziqiang Shi",
            "Jiqing Han",
            "Tieran Zheng",
            "Shiwen Deng",
            "Ji Li"
        ],
        "abstract": "This paper studies the recovery guarantees of the models of minimizing $\\|\\mathcal{X}\\|_*+\\frac{1}{2\\alpha}\\|\\mathcal{X}\\|_F^2$ where $\\mathcal{X}$ is a tensor and $\\|\\mathcal{X}\\|_*$ and $\\|\\mathcal{X}\\|_F$ are the trace and Frobenius norm of respectively. We show that they can efficiently recover low-rank tensors. In particular, they enjoy exact guarantees similar to those known for minimizing $\\|\\mathcal{X}\\|_*$ under the conditions on the sensing operator such as its null-space property, restricted isometry property, or spherical section property. To recover a low-rank tensor $\\mathcal{X}^0$, minimizing $\\|\\mathcal{X}\\|_*+\\frac{1}{2\\alpha}\\|\\mathcal{X}\\|_F^2$ returns the same solution as minimizing $\\|\\mathcal{X}\\|_*$ almost whenever $\\alpha\\geq10\\mathop {\\max}\\limits_{i}\\|X^0_{(i)}\\|_2$.\n    ",
        "submission_date": "2012-07-23T00:00:00",
        "last_modified_date": "2012-07-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1207.5371",
        "title": "Towards a theory of statistical tree-shape analysis",
        "authors": [
            "Aasa Feragen",
            "Pechin Lo",
            "Marleen de Bruijne",
            "Mads Nielsen",
            "Francois Lauze"
        ],
        "abstract": "In order to develop statistical methods for shapes with a tree-structure, we construct a shape space framework for tree-like shapes and study metrics on the shape space. This shape space has singularities, corresponding to topological transitions in the represented trees. We study two closely related metrics on the shape space, TED and QED. QED is a quotient Euclidean distance arising naturally from the shape space formulation, while TED is the classical tree edit distance. Using Gromov's metric geometry we gain new insight into the geometries defined by TED and QED. We show that the new metric QED has nice geometric properties which facilitate statistical analysis, such as existence and local uniqueness of geodesics and averages. TED, on the other hand, does not share the geometric advantages of QED, but has nice algorithmic properties. We provide a theoretical framework and experimental results on synthetic data trees as well as airway trees from pulmonary CT scans. This way, we effectively illustrate that our framework has both the theoretical and qualitative properties necessary to build a theory of statistical tree-shape analysis.\n    ",
        "submission_date": "2012-07-23T00:00:00",
        "last_modified_date": "2012-07-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1207.7245",
        "title": "Autofocus Correction of Azimuth Phase Error and Residual Range Cell Migration in Spotlight SAR Polar Format Imagery",
        "authors": [
            "Xinhua Mao",
            "Daiyin Zhu",
            "Zhaoda Zhu"
        ],
        "abstract": "Synthetic aperture radar (SAR) images are often blurred by phase perturbations induced by uncompensated sensor motion and /or unknown propagation effects caused by turbulent media. To get refocused images, autofocus proves to be useful post-processing technique applied to estimate and compensate the unknown phase errors. However, a severe drawback of the conventional autofocus algorithms is that they are only capable of removing one-dimensional azimuth phase errors (APE). As the resolution becomes finer, residual range cell migration (RCM), which makes the defocus inherently two-dimensional, becomes a new challenge. In this paper, correction of APE and residual RCM are presented in the framework of polar format algorithm (PFA). First, an insight into the underlying mathematical mechanism of polar reformatting is presented. Then based on this new formulation, the effect of polar reformatting on the uncompensated APE and residual RCM is investigated in detail. By using the derived analytical relationship between APE and residual RCM, an efficient two-dimensional (2-D) autofocus method is proposed. Experimental results indicate the effectiveness of the proposed method.\n    ",
        "submission_date": "2012-07-16T00:00:00",
        "last_modified_date": "2012-07-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1208.0385",
        "title": "A phase-sensitive method for filtering on the sphere",
        "authors": [
            "Ramakrishna Kakarala",
            "Philip Ogunbona"
        ],
        "abstract": "This paper examines filtering on a sphere, by first examining the roles of spherical harmonic magnitude and phase. We show that phase is more important than magnitude in determining the structure of a spherical function. We examine the properties of linear phase shifts in the spherical harmonic domain, which suggest a mechanism for constructing finite-impulse-response (FIR) filters. We show that those filters have desirable properties, such as being associative, mapping spherical functions to spherical functions, allowing directional filtering, and being defined by relatively simple equations. We provide examples of the filters for both spherical and manifold data.\n    ",
        "submission_date": "2012-08-02T00:00:00",
        "last_modified_date": "2012-08-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1208.0803",
        "title": "A Novel Approach of Color Image Hiding using RGB Color planes and DWT",
        "authors": [
            "Nilanjan Dey",
            "Anamitra Bardhan Roy",
            "Sayantan Dey"
        ],
        "abstract": "This work proposes a wavelet based Steganographic technique for the color image. The true color cover image and the true color secret image both are decomposed into three separate color planes namely R, G and B. Each plane of the images is decomposed into four sub bands using DWT. Each color plane of the secret image is hidden by alpha blending technique in the corresponding sub bands of the respective color planes of the original image. During embedding, secret image is dispersed within the original image depending upon the alpha value. Extraction of the secret image varies according to the alpha value. In this approach the stego image generated is of acceptable level of imperceptibility and distortion compared to the cover image and the overall security is high.\n    ",
        "submission_date": "2012-08-03T00:00:00",
        "last_modified_date": "2012-08-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1208.0959",
        "title": "Recklessly Approximate Sparse Coding",
        "authors": [
            "Misha Denil",
            "Nando de Freitas"
        ],
        "abstract": "It has recently been observed that certain extremely simple feature encoding techniques are able to achieve state of the art performance on several standard image classification benchmarks including deep belief networks, convolutional nets, factored RBMs, mcRBMs, convolutional RBMs, sparse autoencoders and several others. Moreover, these \"triangle\" or \"soft threshold\" encodings are ex- tremely efficient to compute. Several intuitive arguments have been put forward to explain this remarkable performance, yet no mathematical justification has been offered.\n",
        "submission_date": "2012-08-04T00:00:00",
        "last_modified_date": "2013-01-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1208.1679",
        "title": "Color Assessment and Transfer for Web Pages",
        "authors": [
            "Ou Wu"
        ],
        "abstract": "Colors play a particularly important role in both designing and accessing Web pages. A well-designed color scheme improves Web pages' visual aesthetic and facilitates user interactions. As far as we know, existing color assessment studies focus on images; studies on color assessment and editing for Web pages are rare. This paper investigates color assessment for Web pages based on existing online color theme-rating data sets and applies this assessment to Web color edit. This study consists of three parts. First, we study the extraction of a Web page's color theme. Second, we construct color assessment models that score the color compatibility of a Web page by leveraging machine learning techniques. Third, we incorporate the learned color assessment model into a new application, namely, color transfer for Web pages. Our study combines techniques from computer graphics, Web mining, computer vision, and machine learning. Experimental results suggest that our constructed color assessment models are effective, and useful in the color transfer for Web pages, which has received little attention in both Web mining and computer graphics communities.\n    ",
        "submission_date": "2012-08-07T00:00:00",
        "last_modified_date": "2012-08-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1208.2092",
        "title": "A study on non-destructive method for detecting Toxin in pepper using Neural networks",
        "authors": [
            "M. Rajalakshmi",
            "P. Subashini"
        ],
        "abstract": "Mycotoxin contamination in certain agricultural systems have been a serious concern for human and animal health. Mycotoxins are toxic substances produced mostly as secondary metabolites by fungi that grow on seeds and feed in the field, or in storage. The food-borne Mycotoxins likely to be of greatest significance for human health in tropical developing countries are Aflatoxins and Fumonisins. Chili pepper is also prone to Aflatoxin contamination during harvesting, production and storage ",
        "submission_date": "2012-08-10T00:00:00",
        "last_modified_date": "2012-08-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1208.2651",
        "title": "A Plea for Neutral Comparison Studies in Computational Sciences",
        "authors": [
            "Anne-Laure Boulesteix",
            "Manuel J. A. Eugster"
        ],
        "abstract": "In a context where most published articles are devoted to the development of \"new methods\", comparison studies are generally appreciated by readers but surprisingly given poor consideration by many scientific journals. In connection with recent articles on over-optimism and epistemology published in Bioinformatics, this letter stresses the importance of neutral comparison studies for the objective evaluation of existing methods and the establishment of standards by drawing parallels with clinical research.\n    ",
        "submission_date": "2012-08-13T00:00:00",
        "last_modified_date": "2012-08-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1208.3845",
        "title": "Adaptive Graph via Multiple Kernel Learning for Nonnegative Matrix Factorization",
        "authors": [
            "Jing-Yan Wang",
            "Mustafa AbdulJabbar"
        ],
        "abstract": "Nonnegative Matrix Factorization (NMF) has been continuously evolving in several areas like pattern recognition and information retrieval methods. It factorizes a matrix into a product of 2 low-rank non-negative matrices that will define parts-based, and linear representation of nonnegative data. Recently, Graph regularized NMF (GrNMF) is proposed to find a compact representation,which uncovers the hidden semantics and simultaneously respects the intrinsic geometric structure. In GNMF, an affinity graph is constructed from the original data space to encode the geometrical information. In this paper, we propose a novel idea which engages a Multiple Kernel Learning approach into refining the graph structure that reflects the factorization of the matrix and the new data space. The GrNMF is improved by utilizing the graph refined by the kernel learning, and then a novel kernel learning method is introduced under the GrNMF framework. Our approach shows encouraging results of the proposed algorithm in comparison to the state-of-the-art clustering algorithms like NMF, GrNMF, SVD etc.\n    ",
        "submission_date": "2012-08-19T00:00:00",
        "last_modified_date": "2013-04-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1208.4662",
        "title": "Automatic Segmentation of Fluorescence Lifetime Microscopy Images of Cells Using Multi-Resolution Community Detection",
        "authors": [
            "Dandan Hu",
            "Pinaki Sarder",
            "Peter Ronhovde",
            "Sandra Orthaus",
            "Samuel Achilefu",
            "Zohar Nussinov"
        ],
        "abstract": "We have developed an automatic method for segmenting fluorescence lifetime (FLT) imaging microscopy (FLIM) images of cells inspired by a multi-resolution community detection (MCD) based network segmentation method. The image processing problem is framed as identifying segments with respective average FLTs against a background in FLIM images. The proposed method segments a FLIM image for a given resolution of the network composed using image pixels as the nodes and similarity between the pixels as the edges. In the resulting segmentation, low network resolution leads to larger segments and high network resolution leads to smaller segments. Further, the mean-square error (MSE) in estimating the FLT segments in a FLIM image using the proposed method was found to be consistently decreasing with increasing resolution of the corresponding network. The proposed MCD method outperformed a popular spectral clustering based method in performing FLIM image segmentation. The spectral segmentation method introduced noisy segments in its output at high resolution. It was unable to offer a consistent decrease in MSE with increasing resolution.\n    ",
        "submission_date": "2012-08-23T00:00:00",
        "last_modified_date": "2013-05-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1209.0196",
        "title": "Short-time homomorphic wavelet estimation",
        "authors": [
            "Roberto H. Herrera",
            "Mirko Van der Baan"
        ],
        "abstract": "Successful wavelet estimation is an essential step for seismic methods like impedance inversion, analysis of amplitude variations with offset and full waveform inversion. Homomorphic deconvolution has long intrigued as a potentially elegant solution to the wavelet estimation problem. Yet a successful implementation has proven difficult. Associated disadvantages like phase unwrapping and restrictions of sparsity in the reflectivity function limit its application. We explore short-time homomorphic wavelet estimation as a combination of the classical homomorphic analysis and log-spectral averaging. The introduced method of log-spectral averaging using a short-term Fourier transform increases the number of sample points, thus reducing estimation variances. We apply the developed method on synthetic and real data examples and demonstrate good performance.\n    ",
        "submission_date": "2012-09-02T00:00:00",
        "last_modified_date": "2013-01-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1209.0999",
        "title": "Visual Exploration of Simulated and Measured Blood Flow",
        "authors": [
            "Anna Vilanova",
            "Bernhard Preim",
            "Roy van Pelt",
            "Rocco Gasteiger",
            "Mathias Neugebauer",
            "Thomas Wischgoll"
        ],
        "abstract": "Morphology of cardiovascular tissue is influenced by the unsteady behavior of the blood flow and vice versa. Therefore, the pathogenesis of several cardiovascular diseases is directly affected by the blood-flow dynamics. Understanding flow behavior is of vital importance to understand the cardiovascular system and potentially harbors a considerable value for both diagnosis and risk assessment. The analysis of hemodynamic characteristics involves qualitative and quantitative inspection of the blood-flow field. Visualization plays an important role in the qualitative exploration, as well as the definition of relevant quantitative measures and its validation. There are two main approaches to obtain information about the blood flow: simulation by computational fluid dynamics, and in-vivo measurements. Although research on blood flow simulation has been performed for decades, many open problems remain concerning accuracy and patient-specific solutions. Possibilities for real measurement of blood flow have recently increased considerably by new developments in magnetic resonance imaging which enable the acquisition of 3D quantitative measurements of blood-flow velocity fields. This chapter presents the visualization challenges for both simulation and real measurements of unsteady blood-flow fields.\n    ",
        "submission_date": "2012-09-05T00:00:00",
        "last_modified_date": "2012-09-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1209.1048",
        "title": "Performance Analysis Of Neuro Genetic Algorithm Applied On Detecting Proportion Of Components In Manhole Gas Mixture",
        "authors": [
            "Varun Kumar Ojha",
            "Paramartha Dutta",
            "Hiranmay Saha"
        ],
        "abstract": "The article presents performance analysis of a real valued neuro genetic algorithm applied for the detection of proportion of the gases found in manhole gas mixture. The neural network (NN) trained using genetic algorithm (GA) leads to concept of neuro genetic algorithm, which is used for implementing an intelligent sensory system for the detection of component gases present in manhole gas mixture Usually a manhole gas mixture contains several toxic gases like Hydrogen Sulfide, Ammonia, Methane, Carbon Dioxide, Nitrogen Oxide, and Carbon Monoxide. A semiconductor based gas sensor array used for sensing manhole gas components is an integral part of the proposed intelligent system. It consists of many sensor elements, where each sensor element is responsible for sensing particular gas component. Multiple sensors of different gases used for detecting gas mixture of multiple gases, results in cross-sensitivity. The cross-sensitivity is a major issue and the problem is viewed as pattern recognition problem. The objective of this article is to present performance analysis of the real valued neuro genetic algorithm which is applied for multiple gas detection.\n    ",
        "submission_date": "2012-08-15T00:00:00",
        "last_modified_date": "2012-08-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1209.1125",
        "title": "Video Data Visualization System: Semantic Classification And Personalization",
        "authors": [
            "Jamel Slimi",
            "Anis Ben Ammar",
            "Adel M. Alimi"
        ],
        "abstract": "We present in this paper an intelligent video data visualization tool, based on semantic classification, for retrieving and exploring a large scale corpus of videos. Our work is based on semantic classification resulting from semantic analysis of video. The obtained classes will be projected in the visualization space. The graph is represented by nodes and edges, the nodes are the keyframes of video documents and the edges are the relation between documents and the classes of documents. Finally, we construct the user's profile, based on the interaction with the system, to render the system more adequate to its references.\n    ",
        "submission_date": "2012-09-05T00:00:00",
        "last_modified_date": "2012-09-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1209.1826",
        "title": "A spatio-spectral hybridization for edge preservation and noisy image restoration via local parametric mixtures and Lagrangian relaxation",
        "authors": [
            "Kinjal Basu",
            "Debapriya Sengupta"
        ],
        "abstract": "This paper investigates a fully unsupervised statistical method for edge preserving image restoration and compression using a spatial decomposition scheme. Smoothed maximum likelihood is used for local estimation of edge pixels from mixture parametric models of local templates. For the complementary smooth part the traditional L2-variational problem is solved in the Fourier domain with Thin Plate Spline (TPS) regularization. It is well known that naive Fourier compression of the whole image fails to restore a piece-wise smooth noisy image satisfactorily due to Gibbs phenomenon. Images are interpreted as relative frequency histograms of samples from bi-variate densities where the sample sizes might be unknown. The set of discontinuities is assumed to be completely unsupervised Lebesgue-null, compact subset of the plane in the continuous formulation of the problem. Proposed spatial decomposition uses a widely used topological concept, partition of unity. The decision on edge pixel neighborhoods are made based on the multiple testing procedure of Holms. Statistical summary of the final output is decomposed into two layers of information extraction, one for the subset of edge pixels and the other for the smooth region. Robustness is also demonstrated by applying the technique on noisy degradation of clean images.\n    ",
        "submission_date": "2012-09-09T00:00:00",
        "last_modified_date": "2012-09-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1209.1960",
        "title": "A Comparative Study of Efficient Initialization Methods for the K-Means Clustering Algorithm",
        "authors": [
            "M. Emre Celebi",
            "Hassan A. Kingravi",
            "Patricio A. Vela"
        ],
        "abstract": "K-means is undoubtedly the most widely used partitional clustering algorithm. Unfortunately, due to its gradient descent nature, this algorithm is highly sensitive to the initial placement of the cluster centers. Numerous initialization methods have been proposed to address this problem. In this paper, we first present an overview of these methods with an emphasis on their computational efficiency. We then compare eight commonly used linear time complexity initialization methods on a large and diverse collection of data sets using various performance criteria. Finally, we analyze the experimental results using non-parametric statistical tests and provide recommendations for practitioners. We demonstrate that popular initialization methods often perform poorly and that there are in fact strong alternatives to these methods.\n    ",
        "submission_date": "2012-09-10T00:00:00",
        "last_modified_date": "2012-09-10T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1209.2657",
        "title": "Sparse Representation of Astronomical Images",
        "authors": [
            "Laura Rebollo-Neira",
            "James Bowley"
        ],
        "abstract": "Sparse representation of astronomical images is discussed. It is shown that a significant gain in sparsity is achieved when particular mixed dictionaries are used for approximating these types of images with greedy selection strategies. Experiments are conducted to confirm: i)Effectiveness at producing sparse representations. ii)Competitiveness, with respect to the time required to process large ",
        "submission_date": "2012-09-12T00:00:00",
        "last_modified_date": "2012-09-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1209.3318",
        "title": "Hessian Schatten-Norm Regularization for Linear Inverse Problems",
        "authors": [
            "Stamatios Lefkimmiatis",
            "John Paul Ward",
            "Michael Unser"
        ],
        "abstract": "We introduce a novel family of invariant, convex, and non-quadratic functionals that we employ to derive regularized solutions of ill-posed linear inverse imaging problems. The proposed regularizers involve the Schatten norms of the Hessian matrix, computed at every pixel of the image. They can be viewed as second-order extensions of the popular total-variation (TV) semi-norm since they satisfy the same invariance properties. Meanwhile, by taking advantage of second-order derivatives, they avoid the staircase effect, a common artifact of TV-based reconstructions, and perform well for a wide range of applications. To solve the corresponding optimization problems, we propose an algorithm that is based on a primal-dual formulation. A fundamental ingredient of this algorithm is the projection of matrices onto Schatten norm balls of arbitrary radius. This operation is performed efficiently based on a direct link we provide between vector projections onto $\\ell_q$ norm balls and matrix projections onto Schatten norm balls. Finally, we demonstrate the effectiveness of the proposed methods through experimental results on several inverse imaging problems with real and simulated data.\n    ",
        "submission_date": "2012-09-14T00:00:00",
        "last_modified_date": "2013-02-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1209.4233",
        "title": "Writing Reusable Digital Geometry Algorithms in a Generic Image Processing Framework",
        "authors": [
            "Roland Levillain",
            "Thierry G\u00e9raud",
            "Laurent Najman"
        ],
        "abstract": "Digital Geometry software should reflect the generality of the underlying mathe- matics: mapping the latter to the former requires genericity. By designing generic solutions, one can effectively reuse digital geometry data structures and algorithms. We propose an image processing framework focused on the Generic Programming paradigm in which an algorithm on the paper can be turned into a single code, written once and usable with various input types. This approach enables users to design and implement new methods at a lower cost, try cross-domain experiments and help generalize results\n    ",
        "submission_date": "2012-09-18T00:00:00",
        "last_modified_date": "2012-09-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1209.4850",
        "title": "The Pascal Triangle of a Discrete Image: Definition, Properties and Application to Shape Analysis",
        "authors": [
            "Mireille Boutin",
            "Shanshan Huang"
        ],
        "abstract": "We define the Pascal triangle of a discrete (gray scale) image as a pyramidal arrangement of complex-valued moments and we explore its geometric significance. In particular, we show that the entries of row k of this triangle correspond to the Fourier series coefficients of the moment of order k of the Radon transform of the image. Group actions on the plane can be naturally prolonged onto the entries of the Pascal triangle. We study the prolongation of some common group actions, such as rotations and reflections, and we propose simple tests for detecting equivalences and self-equivalences under these group actions. The motivating application of this work is the problem of characterizing the geometry of objects on images, for example by detecting approximate symmetries.\n    ",
        "submission_date": "2012-09-21T00:00:00",
        "last_modified_date": "2013-04-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1209.5826",
        "title": "Refinability of splines from lattice Voronoi cells",
        "authors": [
            "Jorg Peters"
        ],
        "abstract": "Splines can be constructed by convolving the indicator function of the Voronoi cell of a lattice. This paper presents simple criteria that imply that only a small subset of such spline families can be refined: essentially the well-known box splines and tensor-product splines. Among the many non-refinable constructions are hex-splines and their generalization to non-Cartesian lattices. An example shows how non-refinable splines can exhibit increased approximation error upon refinement of the lattice.\n    ",
        "submission_date": "2012-09-26T00:00:00",
        "last_modified_date": "2012-09-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1209.5982",
        "title": "PlaceRaider: Virtual Theft in Physical Spaces with Smartphones",
        "authors": [
            "Robert Templeman",
            "Zahid Rahman",
            "David Crandall",
            "Apu Kapadia"
        ],
        "abstract": "As smartphones become more pervasive, they are increasingly targeted by malware. At the same time, each new generation of smartphone features increasingly powerful onboard sensor suites. A new strain of sensor malware has been developing that leverages these sensors to steal information from the physical environment (e.g., researchers have recently demonstrated how malware can listen for spoken credit card numbers through the microphone, or feel keystroke vibrations using the accelerometer). Yet the possibilities of what malware can see through a camera have been understudied. This paper introduces a novel visual malware called PlaceRaider, which allows remote attackers to engage in remote reconnaissance and what we call virtual theft. Through completely opportunistic use of the camera on the phone and other sensors, PlaceRaider constructs rich, three dimensional models of indoor environments. Remote burglars can thus download the physical space, study the environment carefully, and steal virtual objects from the environment (such as financial documents, information on computer monitors, and personally identifiable information). Through two human subject studies we demonstrate the effectiveness of using mobile devices as powerful surveillance and virtual theft platforms, and we suggest several possible defenses against visual malware.\n    ",
        "submission_date": "2012-09-26T00:00:00",
        "last_modified_date": "2012-09-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1209.6299",
        "title": "Approximate evaluation of marginal association probabilities with belief propagation",
        "authors": [
            "Jason L. Williams",
            "Roslyn A. Lau"
        ],
        "abstract": "Data association, the problem of reasoning over correspondence between targets and measurements, is a fundamental problem in tracking. This paper presents a graphical model formulation of data association and applies an approximate inference method, belief propagation (BP), to obtain estimates of marginal association probabilities. We prove that BP is guaranteed to converge, and bound the number of iterations necessary. Experiments reveal a favourable comparison to prior methods in terms of accuracy and computational complexity.\n    ",
        "submission_date": "2012-09-12T00:00:00",
        "last_modified_date": "2014-11-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1209.6560",
        "title": "Sparse Modeling of Intrinsic Correspondences",
        "authors": [
            "J. Pokrass",
            "A. M. Bronstein",
            "M. M. Bronstein",
            "P. Sprechmann",
            "G. Sapiro"
        ],
        "abstract": "We present a novel sparse modeling approach to non-rigid shape matching using only the ability to detect repeatable regions. As the input to our algorithm, we are given only two sets of regions in two shapes; no descriptors are provided so the correspondence between the regions is not know, nor we know how many regions correspond in the two shapes. We show that even with such scarce information, it is possible to establish very accurate correspondence between the shapes by using methods from the field of sparse modeling, being this, the first non-trivial use of sparse models in shape correspondence. We formulate the problem of permuted sparse coding, in which we solve simultaneously for an unknown permutation ordering the regions on two shapes and for an unknown correspondence in functional representation. We also propose a robust variant capable of handling incomplete matches. Numerically, the problem is solved efficiently by alternating the solution of a linear assignment and a sparse coding problem. The proposed methods are evaluated qualitatively and quantitatively on standard benchmarks containing both synthetic and scanned objects.\n    ",
        "submission_date": "2012-09-28T00:00:00",
        "last_modified_date": "2012-09-28T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1210.0754",
        "title": "Invariance of visual operations at the level of receptive fields",
        "authors": [
            "Tony Lindeberg"
        ],
        "abstract": "Receptive field profiles registered by cell recordings have shown that mammalian vision has developed receptive fields tuned to different sizes and orientations in the image domain as well as to different image velocities in space-time. This article presents a theoretical model by which families of idealized receptive field profiles can be derived mathematically from a small set of basic assumptions that correspond to structural properties of the environment. The article also presents a theory for how basic invariance properties to variations in scale, viewing direction and relative motion can be obtained from the output of such receptive fields, using complementary selection mechanisms that operate over the output of families of receptive fields tuned to different parameters. Thereby, the theory shows how basic invariance properties of a visual system can be obtained already at the level of receptive fields, and we can explain the different shapes of receptive field profiles found in biological vision from a requirement that the visual system should be invariant to the natural types of image transformations that occur in its environment.\n    ",
        "submission_date": "2012-10-02T00:00:00",
        "last_modified_date": "2012-10-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1210.0822",
        "title": "Discrete geodesic calculus in the space of viscous fluidic objects",
        "authors": [
            "Martin Rumpf",
            "Benedikt Wirth"
        ],
        "abstract": "Based on a local approximation of the Riemannian distance on a manifold by a computationally cheap dissimilarity measure, a time discrete geodesic calculus is developed, and applications to shape space are explored. The dissimilarity measure is derived from a deformation energy whose Hessian reproduces the underlying Riemannian metric, and it is used to define length and energy of discrete paths in shape space. The notion of discrete geodesics defined as energy minimizing paths gives rise to a discrete logarithmic map, a variational definition of a discrete exponential map, and a time discrete parallel transport. This new concept is applied to a shape space in which shapes are considered as boundary contours of physical objects consisting of viscous material. The flexibility and computational efficiency of the approach is demonstrated for topology preserving shape morphing, the representation of paths in shape space via local shape variations as path generators, shape extrapolation via discrete geodesic flow, and the transfer of geometric features.\n    ",
        "submission_date": "2012-10-02T00:00:00",
        "last_modified_date": "2012-10-02T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1210.0999",
        "title": "Logical segmentation for article extraction in digitized old newspapers",
        "authors": [
            "Thomas Palfray",
            "David H\u00e9bert",
            "St\u00e9phane Nicolas",
            "Pierrick Tranouez",
            "Thierry Paquet"
        ],
        "abstract": "Newspapers are documents made of news item and informative articles. They are not meant to be red iteratively: the reader can pick his items in any order he fancies. Ignoring this structural property, most digitized newspaper archives only offer access by issue or at best by page to their content. We have built a digitization workflow that automatically extracts newspaper articles from images, which allows indexing and retrieval of information at the article level. Our back-end system extracts the logical structure of the page to produce the informative units: the articles. Each image is labelled at the pixel level, through a machine learning based method, then the page logical structure is constructed up from there by the detection of structuring entities such as horizontal and vertical separators, titles and text lines. This logical structure is stored in a METS wrapper associated to the ALTO file produced by the system including the OCRed text. Our front-end system provides a web high definition visualisation of images, textual indexing and retrieval facilities, searching and reading at the article level. Articles transcriptions can be collaboratively corrected, which as a consequence allows for better indexing. We are currently testing our system on the archives of the Journal de Rouen, one of France eldest local newspaper. These 250 years of publication amount to 300 000 pages of very variable image quality and layout complexity. Test year 1808 can be consulted at ",
        "submission_date": "2012-10-03T00:00:00",
        "last_modified_date": "2012-10-03T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1210.1207",
        "title": "Learning Human Activities and Object Affordances from RGB-D Videos",
        "authors": [
            "Hema Swetha Koppula",
            "Rudhir Gupta",
            "Ashutosh Saxena"
        ],
        "abstract": "Understanding human activities and object affordances are two very important skills, especially for personal robots which operate in human environments. In this work, we consider the problem of extracting a descriptive labeling of the sequence of sub-activities being performed by a human, and more importantly, of their interactions with the objects in the form of associated affordances. Given a RGB-D video, we jointly model the human activities and object affordances as a Markov random field where the nodes represent objects and sub-activities, and the edges represent the relationships between object affordances, their relations with sub-activities, and their evolution over time. We formulate the learning problem using a structural support vector machine (SSVM) approach, where labelings over various alternate temporal segmentations are considered as latent variables. We tested our method on a challenging dataset comprising 120 activity videos collected from 4 subjects, and obtained an accuracy of 79.4% for affordance, 63.4% for sub-activity and 75.0% for high-level activity labeling. We then demonstrate the use of such descriptive labeling in performing assistive tasks by a PR2 robot.\n    ",
        "submission_date": "2012-10-04T00:00:00",
        "last_modified_date": "2013-05-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1210.2162",
        "title": "Semisupervised Classifier Evaluation and Recalibration",
        "authors": [
            "Peter Welinder",
            "Max Welling",
            "Pietro Perona"
        ],
        "abstract": "How many labeled examples are needed to estimate a classifier's performance on a new dataset? We study the case where data is plentiful, but labels are expensive. We show that by making a few reasonable assumptions on the structure of the data, it is possible to estimate performance curves, with confidence bounds, using a small number of ground truth labels. Our approach, which we call Semisupervised Performance Evaluation (SPE), is based on a generative model for the classifier's confidence scores. In addition to estimating the performance of classifiers on new datasets, SPE can be used to recalibrate a classifier by re-estimating the class-conditional confidence distributions.\n    ",
        "submission_date": "2012-10-08T00:00:00",
        "last_modified_date": "2012-10-08T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1210.2352",
        "title": "A notion of continuity in discrete spaces and applications",
        "authors": [
            "Valerio Capraro"
        ],
        "abstract": "We propose a notion of continuous path for locally finite metric spaces, taking inspiration from the recent development of A-theory for locally finite connected graphs. We use this notion of continuity to derive an analogue in Z^2 of the Jordan curve theorem and to extend to a quite large class of locally finite metric spaces (containing all finite metric spaces) an inequality for the \\ell^p-distortion of a metric space that has been recently proved by Pierre-Nicolas Jolissaint and Alain Valette for finite connected graphs.\n    ",
        "submission_date": "2012-10-08T00:00:00",
        "last_modified_date": "2013-09-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1210.2687",
        "title": "Deconvolving Images with Unknown Boundaries Using the Alternating Direction Method of Multipliers",
        "authors": [
            "Mariana S. C. Almeida",
            "M\u00e1rio A. T. Figueiredo"
        ],
        "abstract": "The alternating direction method of multipliers (ADMM) has recently sparked interest as a flexible and efficient optimization tool for imaging inverse problems, namely deconvolution and reconstruction under non-smooth convex regularization. ADMM achieves state-of-the-art speed by adopting a divide and conquer strategy, wherein a hard problem is split into simpler, efficiently solvable sub-problems (e.g., using fast Fourier or wavelet transforms, or simple proximity operators). In deconvolution, one of these sub-problems involves a matrix inversion (i.e., solving a linear system), which can be done efficiently (in the discrete Fourier domain) if the observation operator is circulant, i.e., under periodic boundary conditions. This paper extends ADMM-based image deconvolution to the more realistic scenario of unknown boundary, where the observation operator is modeled as the composition of a convolution (with arbitrary boundary conditions) with a spatial mask that keeps only pixels that do not depend on the unknown boundary. The proposed approach also handles, at no extra cost, problems that combine the recovery of missing pixels (i.e., inpainting) with deconvolution. We show that the resulting algorithms inherit the convergence guarantees of ADMM and illustrate its performance on non-periodic deblurring (with and without inpainting of interior pixels) under total-variation and frame-based regularization.\n    ",
        "submission_date": "2012-10-09T00:00:00",
        "last_modified_date": "2013-03-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1210.3098",
        "title": "Near-optimal compressed sensing guarantees for total variation minimization",
        "authors": [
            "Deanna Needell",
            "Rachel Ward"
        ],
        "abstract": "Consider the problem of reconstructing a multidimensional signal from an underdetermined set of measurements, as in the setting of compressed sensing. Without any additional assumptions, this problem is ill-posed. However, for signals such as natural images or movies, the minimal total variation estimate consistent with the measurements often produces a good approximation to the underlying signal, even if the number of measurements is far smaller than the ambient dimensionality. This paper extends recent reconstruction guarantees for two-dimensional images to signals of arbitrary dimension d>1 and to isotropic total variation problems. To be precise, we show that a multidimensional signal x can be reconstructed from O(sd*log(N^d)) linear measurements using total variation minimization to within a factor of the best s-term approximation of its gradient. The reconstruction guarantees we provide are necessarily optimal up to polynomial factors in the spatial dimension d.\n    ",
        "submission_date": "2012-10-11T00:00:00",
        "last_modified_date": "2013-03-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1210.3288",
        "title": "Unsupervised Detection and Tracking of Arbitrary Objects with Dependent Dirichlet Process Mixtures",
        "authors": [
            "Willie Neiswanger",
            "Frank Wood"
        ],
        "abstract": "This paper proposes a technique for the unsupervised detection and tracking of arbitrary objects in videos. It is intended to reduce the need for detection and localization methods tailored to specific object types and serve as a general framework applicable to videos with varied objects, backgrounds, and image qualities. The technique uses a dependent Dirichlet process mixture (DDPM) known as the Generalized Polya Urn (GPUDDPM) to model image pixel data that can be easily and efficiently extracted from the regions in a video that represent objects. This paper describes a specific implementation of the model using spatial and color pixel data extracted via frame differencing and gives two algorithms for performing inference in the model to accomplish detection and tracking. This technique is demonstrated on multiple synthetic and benchmark video datasets that illustrate its ability to, without modification, detect and track objects with diverse physical characteristics moving over non-uniform backgrounds and through occlusion.\n    ",
        "submission_date": "2012-10-11T00:00:00",
        "last_modified_date": "2012-10-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1210.3326",
        "title": "Three dimensional tracking of gold nanoparticles using digital holographic microscopy",
        "authors": [
            "Fr\u00e9d\u00e9ric Verpillat",
            "Fadwa Joud",
            "Pierre Desbiolles",
            "Michel Gross"
        ],
        "abstract": "In this paper we present a digital holographic microscope to track gold colloids in three dimensions. We report observations of 100nm gold particles in motion in water. The expected signal and the chosen method of reconstruction are described. We also discuss about how to implement the numerical calculation to reach real-time 3D tracking.\n    ",
        "submission_date": "2012-10-11T00:00:00",
        "last_modified_date": "2012-10-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1210.3729",
        "title": "Inference of Fine-grained Attributes of Bengali Corpus for Stylometry Detection",
        "authors": [
            "Tanmoy Chakraborty",
            "Sivaji Bandyopadhyay"
        ],
        "abstract": "Stylometry, the science of inferring characteristics of the author from the characteristics of documents written by that author, is a problem with a long history and belongs to the core task of Text categorization that involves authorship identification, plagiarism detection, forensic investigation, computer security, copyright and estate disputes etc. In this work, we present a strategy for stylometry detection of documents written in Bengali. We adopt a set of fine-grained attribute features with a set of lexical markers for the analysis of the text and use three semi-supervised measures for making decisions. Finally, a majority voting approach has been taken for final classification. The system is fully automatic and language-independent. Evaluation results of our attempt for Bengali author's stylometry detection show reasonably promising accuracy in comparison to the baseline model.\n    ",
        "submission_date": "2012-10-13T00:00:00",
        "last_modified_date": "2012-10-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1210.4081",
        "title": "Getting Feasible Variable Estimates From Infeasible Ones: MRF Local Polytope Study",
        "authors": [
            "Bogdan Savchynskyy",
            "Stefan Schmidt"
        ],
        "abstract": "This paper proposes a method for construction of approximate feasible primal solutions from dual ones for large-scale optimization problems possessing certain separability properties. Whereas infeasible primal estimates can typically be produced from (sub-)gradients of the dual function, it is often not easy to project them to the primal feasible set, since the projection itself has a complexity comparable to the complexity of the initial problem. We propose an alternative efficient method to obtain feasibility and show that its properties influencing the convergence to the optimum are similar to the properties of the Euclidean projection. We apply our method to the local polytope relaxation of inference problems for Markov Random Fields and demonstrate its superiority over existing methods.\n    ",
        "submission_date": "2012-10-15T00:00:00",
        "last_modified_date": "2012-10-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1210.4855",
        "title": "A Slice Sampler for Restricted Hierarchical Beta Process with Applications to Shared Subspace Learning",
        "authors": [
            "Sunil Kumar Gupta",
            "Dinh Q. Phung",
            "Svetha Venkatesh"
        ],
        "abstract": "Hierarchical beta process has found interesting applications in recent years. In this paper we present a modified hierarchical beta process prior with applications to hierarchical modeling of multiple data sources. The novel use of the prior over a hierarchical factor model allows factors to be shared across different sources. We derive a slice sampler for this model, enabling tractable inference even when the likelihood and the prior over parameters are non-conjugate. This allows the application of the model in much wider contexts without restrictions. We present two different data generative models a linear GaussianGaussian model for real valued data and a linear Poisson-gamma model for count data. Encouraging transfer learning results are shown for two real world applications text modeling and content based image retrieval.\n    ",
        "submission_date": "2012-10-16T00:00:00",
        "last_modified_date": "2012-10-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1210.4872",
        "title": "Nested Dictionary Learning for Hierarchical Organization of Imagery and Text",
        "authors": [
            "Lingbo Li",
            "XianXing Zhang",
            "Mingyuan Zhou",
            "Lawrence Carin"
        ],
        "abstract": "A tree-based dictionary learning model is developed for joint analysis of imagery and associated text. The dictionary learning may be applied directly to the imagery from patches, or to general feature vectors extracted from patches or superpixels (using any existing method for image feature extraction). Each image is associated with a path through the tree (from root to a leaf), and each of the multiple patches in a given image is associated with one node in that path. Nodes near the tree root are shared between multiple paths, representing image characteristics that are common among different types of images. Moving toward the leaves, nodes become specialized, representing details in image classes. If available, words (text) are also jointly modeled, with a path-dependent probability over words. The tree structure is inferred via a nested Dirichlet process, and a retrospective stick-breaking sampler is used to infer the tree depth and width.\n    ",
        "submission_date": "2012-10-16T00:00:00",
        "last_modified_date": "2012-10-16T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1210.5034",
        "title": "Optimal Computational Trade-Off of Inexact Proximal Methods",
        "authors": [
            "Pierre Machart",
            "Sandrine Anthoine",
            "Luca Baldassarre"
        ],
        "abstract": "In this paper, we investigate the trade-off between convergence rate and computational cost when minimizing a composite functional with proximal-gradient methods, which are popular optimisation tools in machine learning. We consider the case when the proximity operator is computed via an iterative procedure, which provides an approximation of the exact proximity operator. In that case, we obtain algorithms with two nested loops. We show that the strategy that minimizes the computational cost to reach a solution with a desired accuracy in finite time is to set the number of inner iterations to a constant, which differs from the strategy indicated by a convergence rate analysis. In the process, we also present a new procedure called SIP (that is Speedy Inexact Proximal-gradient algorithm) that is both computationally efficient and easy to implement. Our numerical experiments confirm the theoretical findings and suggest that SIP can be a very competitive alternative to the standard procedure.\n    ",
        "submission_date": "2012-10-18T00:00:00",
        "last_modified_date": "2012-10-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1210.5041",
        "title": "Navigation domain representation for interactive multiview imaging",
        "authors": [
            "Thomas Maugey",
            "Ismael Daribo",
            "Gene Cheung",
            "Pascal Frossard"
        ],
        "abstract": "Enabling users to interactively navigate through different viewpoints of a static scene is a new interesting functionality in 3D streaming systems. While it opens exciting perspectives towards rich multimedia applications, it requires the design of novel representations and coding techniques in order to solve the new challenges imposed by interactive navigation. Interactivity clearly brings new design constraints: the encoder is unaware of the exact decoding process, while the decoder has to reconstruct information from incomplete subsets of data since the server can generally not transmit images for all possible viewpoints due to resource constrains. In this paper, we propose a novel multiview data representation that permits to satisfy bandwidth and storage constraints in an interactive multiview streaming system. In particular, we partition the multiview navigation domain into segments, each of which is described by a reference image and some auxiliary information. The auxiliary information enables the client to recreate any viewpoint in the navigation segment via view synthesis. The decoder is then able to navigate freely in the segment without further data request to the server; it requests additional data only when it moves to a different segment. We discuss the benefits of this novel representation in interactive navigation systems and further propose a method to optimize the partitioning of the navigation domain into independent segments, under bandwidth and storage constraints. Experimental results confirm the potential of the proposed representation; namely, our system leads to similar compression performance as classical inter-view coding, while it provides the high level of flexibility that is required for interactive streaming. Hence, our new framework represents a promising solution for 3D data representation in novel interactive multimedia services.\n    ",
        "submission_date": "2012-10-18T00:00:00",
        "last_modified_date": "2013-06-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1210.5502",
        "title": "OpenCFU, a New Free and Open-Source Software to Count Cell Colonies and Other Circular Objects",
        "authors": [
            "Quentin Geissmann"
        ],
        "abstract": "Counting circular objects such as cell colonies is an important source of information for biologists. Although this task is often time-consuming and subjective, it is still predominantly performed manually. The aim of the present work is to provide a new tool to enumerate circular objects from digital pictures and video streams. Here, I demonstrate that the created program, OpenCFU, is very robust, accurate and fast. In addition, it provides control over the processing parameters and is implemented in an in- tuitive and modern interface. OpenCFU is a cross-platform and open-source software freely available at ",
        "submission_date": "2012-10-18T00:00:00",
        "last_modified_date": "2012-11-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1210.6293",
        "title": "MLPACK: A Scalable C++ Machine Learning Library",
        "authors": [
            "Ryan R. Curtin",
            "James R. Cline",
            "N.P. Slagle",
            "William B. March",
            "Parikshit Ram",
            "Nishant A. Mehta",
            "Alexander G. Gray"
        ],
        "abstract": "MLPACK is a state-of-the-art, scalable, multi-platform C++ machine learning library released in late 2011 offering both a simple, consistent API accessible to novice users and high performance and flexibility to expert users by leveraging modern features of C++. MLPACK provides cutting-edge algorithms whose benchmarks exhibit far better performance than other leading machine learning libraries. MLPACK version 1.0.3, licensed under the LGPL, is available at ",
        "submission_date": "2012-10-23T00:00:00",
        "last_modified_date": "2012-10-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1210.6649",
        "title": "Extended object reconstruction in adaptive-optics imaging: the multiresolution approach",
        "authors": [
            "Roberto Baena Gall\u00e9",
            "Jorge N\u00fa\u00f1ez",
            "Szymon Gladysz"
        ],
        "abstract": "We propose the application of multiresolution transforms, such as wavelets (WT) and curvelets (CT), to the reconstruction of images of extended objects that have been acquired with adaptive optics (AO) systems. Such multichannel approaches normally make use of probabilistic tools in order to distinguish significant structures from noise and reconstruction residuals. Furthermore, we aim to check the historical assumption that image-reconstruction algorithms using static PSFs are not suitable for AO imaging. We convolve an image of Saturn taken with the Hubble Space Telescope (HST) with AO PSFs from the 5-m Hale telescope at the Palomar Observatory and add both shot and readout noise. Subsequently, we apply different approaches to the blurred and noisy data in order to recover the original object. The approaches include multi-frame blind deconvolution (with the algorithm IDAC), myopic deconvolution with regularization (with MISTRAL) and wavelets- or curvelets-based static PSF deconvolution (AWMLE and ACMLE algorithms). We used the mean squared error (MSE) and the structural similarity index (SSIM) to compare the results. We discuss the strengths and weaknesses of the two metrics. We found that CT produces better results than WT, as measured in terms of MSE and SSIM. Multichannel deconvolution with a static PSF produces results which are generally better than the results obtained with the myopic/blind approaches (for the images we tested) thus showing that the ability of a method to suppress the noise and to track the underlying iterative process is just as critical as the capability of the myopic/blind approaches to update the PSF.\n    ",
        "submission_date": "2012-10-25T00:00:00",
        "last_modified_date": "2012-10-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1210.6707",
        "title": "Clustering hidden Markov models with variational HEM",
        "authors": [
            "Emanuele Coviello",
            "Antoni B. Chan",
            "Gert R.G. Lanckriet"
        ],
        "abstract": "The hidden Markov model (HMM) is a widely-used generative model that copes with sequential data, assuming that each observation is conditioned on the state of a hidden Markov chain. In this paper, we derive a novel algorithm to cluster HMMs based on the hierarchical EM (HEM) algorithm. The proposed algorithm i) clusters a given collection of HMMs into groups of HMMs that are similar, in terms of the distributions they represent, and ii) characterizes each group by a \"cluster center\", i.e., a novel HMM that is representative for the group, in a manner that is consistent with the underlying generative model of the HMM. To cope with intractable inference in the E-step, the HEM algorithm is formulated as a variational optimization problem, and efficiently solved for the HMM case by leveraging an appropriate variational approximation. The benefits of the proposed algorithm, which we call variational HEM (VHEM), are demonstrated on several tasks involving time-series data, such as hierarchical clustering of motion capture sequences, and automatic annotation and retrieval of music and of online hand-writing data, showing improvements over current methods. In particular, our variational HEM algorithm effectively leverages large amounts of data when learning annotation models by using an efficient hierarchical estimation procedure, which reduces learning times and memory requirements, while improving model robustness through better regularization.\n    ",
        "submission_date": "2012-10-24T00:00:00",
        "last_modified_date": "2012-10-24T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1210.7053",
        "title": "Managing sparsity, time, and quality of inference in topic models",
        "authors": [
            "Khoat Than",
            "Tu Bao Ho"
        ],
        "abstract": "Inference is an integral part of probabilistic topic models, but is often non-trivial to derive an efficient algorithm for a specific model. It is even much more challenging when we want to find a fast inference algorithm which always yields sparse latent representations of documents. In this article, we introduce a simple framework for inference in probabilistic topic models, denoted by FW. This framework is general and flexible enough to be easily adapted to mixture models. It has a linear convergence rate, offers an easy way to incorporate prior knowledge, and provides us an easy way to directly trade off sparsity against quality and time. We demonstrate the goodness and flexibility of FW over existing inference methods by a number of tasks. Finally, we show how inference in topic models with nonconjugate priors can be done efficiently.\n    ",
        "submission_date": "2012-10-26T00:00:00",
        "last_modified_date": "2013-04-15T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1210.7956",
        "title": "Implementation of a Vision System for a Landmine Detecting Robot Using Artificial Neural Network",
        "authors": [
            "Roger Achkar",
            "Michel Owayjan"
        ],
        "abstract": "Landmines, specifically anti-tank mines, cluster bombs, and unexploded ordnance form a serious problem in many countries. Several landmine sweeping techniques are used for minesweeping. This paper presents the design and the implementation of the vision system of an autonomous robot for landmines localization. The proposed work develops state-of-the-art techniques in digital image processing for pre-processing captured images of the contaminated area. After enhancement, Artificial Neural Network (ANN) is used in order to identify, recognize and classify the landmines' make and model. The Back-Propagation algorithm is used for training the network. The proposed work proved to be able to identify and classify different types of landmines under various conditions (rotated landmine, partially covered landmine) with a success rate of up to 90%.\n    ",
        "submission_date": "2012-10-30T00:00:00",
        "last_modified_date": "2012-10-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1211.0135",
        "title": "Sampling and Reconstruction of Spatial Fields using Mobile Sensors",
        "authors": [
            "Jayakrishnan Unnikrishnan",
            "Martin Vetterli"
        ],
        "abstract": "Spatial sampling is traditionally studied in a static setting where static sensors scattered around space take measurements of the spatial field at their locations. In this paper we study the emerging paradigm of sampling and reconstructing spatial fields using sensors that move through space. We show that mobile sensing offers some unique advantages over static sensing in sensing time-invariant bandlimited spatial fields. Since a moving sensor encounters such a spatial field along its path as a time-domain signal, a time-domain anti-aliasing filter can be employed prior to sampling the signal received at the sensor. Such a filtering procedure, when used by a configuration of sensors moving at constant speeds along equispaced parallel lines, leads to a complete suppression of spatial aliasing in the direction of motion of the sensors. We analytically quantify the advantage of using such a sampling scheme over a static sampling scheme by computing the reduction in sampling noise due to the filter. We also analyze the effects of non-uniform sensor speeds on the reconstruction accuracy. Using simulation examples we demonstrate the advantages of mobile sampling over static sampling in practical problems.\n",
        "submission_date": "2012-11-01T00:00:00",
        "last_modified_date": "2012-11-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1211.0757",
        "title": "Efficient Point-to-Subspace Query in $\\ell^1$: Theory and Applications in Computer Vision",
        "authors": [
            "Ju Sun",
            "Yuqian Zhang",
            "John Wright"
        ],
        "abstract": "Motivated by vision tasks such as robust face and object recognition, we consider the following general problem: given a collection of low-dimensional linear subspaces in a high-dimensional ambient (image) space and a query point (image), efficiently determine the nearest subspace to the query in $\\ell^1$ distance. We show in theory that Cauchy random embedding of the objects into significantly-lower-dimensional spaces helps preserve the identity of the nearest subspace with constant probability. This offers the possibility of efficiently selecting several candidates for accurate search. We sketch preliminary experiments on robust face and digit recognition to corroborate our theory.\n    ",
        "submission_date": "2012-11-05T00:00:00",
        "last_modified_date": "2012-11-05T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1211.1255",
        "title": "Handwritten digit recognition by bio-inspired hierarchical networks",
        "authors": [
            "Antonio G. Zippo",
            "Giuliana Gelsomino",
            "Sara Nencini",
            "Gabriele E. M. Biella"
        ],
        "abstract": "The human brain processes information showing learning and prediction abilities but the underlying neuronal mechanisms still remain unknown. Recently, many studies prove that neuronal networks are able of both generalizations and associations of sensory inputs. In this paper, following a set of neurophysiological evidences, we propose a learning framework with a strong biological plausibility that mimics prominent functions of cortical circuitries. We developed the Inductive Conceptual Network (ICN), that is a hierarchical bio-inspired network, able to learn invariant patterns by Variable-order Markov Models implemented in its nodes. The outputs of the top-most node of ICN hierarchy, representing the highest input generalization, allow for automatic classification of inputs. We found that the ICN clusterized MNIST images with an error of 5.73% and USPS images with an error of 12.56%.\n    ",
        "submission_date": "2012-11-06T00:00:00",
        "last_modified_date": "2012-11-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1211.1654",
        "title": "A New Randomness Evaluation Method with Applications to Image Shuffling and Encryption",
        "authors": [
            "Yue Wu",
            "Sos Agaian",
            "Joseph P. Noonan"
        ],
        "abstract": "This letter discusses the problem of testing the degree of randomness within an image, particularly for a shuffled or encrypted image. Its key contributions are: 1) a mathematical model of perfectly shuffled images; 2) the derivation of the theoretical distribution of pixel differences; 3) a new $Z$-test based approach to differentiate whether or not a test image is perfectly shuffled; and 4) a randomized algorithm to unbiasedly evaluate the degree of randomness within a given image. Simulation results show that the proposed method is robust and effective in evaluating the degree of randomness within an image, and may often be more suitable for image applications than commonly used testing schemes designed for binary data like NIST 800-22. The developed method may be also useful as a first step in determining whether or not a shuffling or encryption scheme is suitable for a particular cryptographic application.\n    ",
        "submission_date": "2012-11-07T00:00:00",
        "last_modified_date": "2012-11-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1211.1690",
        "title": "Learning Monocular Reactive UAV Control in Cluttered Natural Environments",
        "authors": [
            "Stephane Ross",
            "Narek Melik-Barkhudarov",
            "Kumar Shaurya Shankar",
            "Andreas Wendel",
            "Debadeepta Dey",
            "J. Andrew Bagnell",
            "Martial Hebert"
        ],
        "abstract": "Autonomous navigation for large Unmanned Aerial Vehicles (UAVs) is fairly straight-forward, as expensive sensors and monitoring devices can be employed. In contrast, obstacle avoidance remains a challenging task for Micro Aerial Vehicles (MAVs) which operate at low altitude in cluttered environments. Unlike large vehicles, MAVs can only carry very light sensors, such as cameras, making autonomous navigation through obstacles much more challenging. In this paper, we describe a system that navigates a small quadrotor helicopter autonomously at low altitude through natural forest environments. Using only a single cheap camera to perceive the environment, we are able to maintain a constant velocity of up to 1.5m/s. Given a small set of human pilot demonstrations, we use recent state-of-the-art imitation learning techniques to train a controller that can avoid trees by adapting the MAVs heading. We demonstrate the performance of our system in a more controlled environment indoors, and in real natural forest environments outdoors.\n    ",
        "submission_date": "2012-11-07T00:00:00",
        "last_modified_date": "2012-11-07T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1211.1893",
        "title": "Tangent-based manifold approximation with locally linear models",
        "authors": [
            "Sofia Karygianni",
            "Pascal Frossard"
        ],
        "abstract": "In this paper, we consider the problem of manifold approximation with affine subspaces. Our objective is to discover a set of low dimensional affine subspaces that represents manifold data accurately while preserving the manifold's structure. For this purpose, we employ a greedy technique that partitions manifold samples into groups that can be each approximated by a low dimensional subspace. We start by considering each manifold sample as a different group and we use the difference of tangents to determine appropriate group mergings. We repeat this procedure until we reach the desired number of sample groups. The best low dimensional affine subspaces corresponding to the final groups constitute our approximate manifold representation. Our experiments verify the effectiveness of the proposed scheme and show its superior performance compared to state-of-the-art methods for manifold approximation.\n    ",
        "submission_date": "2012-11-06T00:00:00",
        "last_modified_date": "2012-11-06T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1211.2556",
        "title": "A Comparative Study of Gaussian Mixture Model and Radial Basis Function for Voice Recognition",
        "authors": [
            "Fatai Adesina Anifowose"
        ],
        "abstract": "A comparative study of the application of Gaussian Mixture Model (GMM) and Radial Basis Function (RBF) in biometric recognition of voice has been carried out and presented. The application of machine learning techniques to biometric authentication and recognition problems has gained a widespread acceptance. In this research, a GMM model was trained, using Expectation Maximization (EM) algorithm, on a dataset containing 10 classes of vowels and the model was used to predict the appropriate classes using a validation dataset. For experimental validity, the model was compared to the performance of two different versions of RBF model using the same learning and validation datasets. The results showed very close recognition accuracy between the GMM and the standard RBF model, but with GMM performing better than the standard RBF by less than 1% and the two models outperformed similar models reported in literature. The DTREG version of RBF outperformed the other two models by producing 94.8% recognition accuracy. In terms of recognition time, the standard RBF was found to be the fastest among the three models.\n    ",
        "submission_date": "2012-11-12T00:00:00",
        "last_modified_date": "2012-11-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1211.2699",
        "title": "A Non-Blind Watermarking Scheme for Gray Scale Images in Discrete Wavelet Transform Domain using Two Subbands",
        "authors": [
            "Abdur Shahid",
            "Shahriar Badsha",
            "Md. Rethwan Kabeer",
            "Junaid Ahsan",
            "Mufti Mahmud"
        ],
        "abstract": "Digital watermarking is the process to hide digital pattern directly into a digital content. Digital watermarking techniques are used to address digital rights management, protect information and conceal secrets. An invisible non-blind watermarking approach for gray scale images is proposed in this paper. The host image is decomposed into 3-levels using Discrete Wavelet Transform. Based on the parent-child relationship between the wavelet coefficients the Set Partitioning in Hierarchical Trees (SPIHT) compression algorithm is performed on the LH3, LH2, HL3 and HL2 subbands to find out the significant coefficients. The most significant coefficients of LH2 and HL2 bands are selected to embed a binary watermark image. The selected significant coefficients are modulated using Noise Visibility Function, which is considered as the best strength to ensure better imperceptibility. The approach is tested against various image processing attacks such as addition of noise, filtering, cropping, JPEG compression, histogram equalization and contrast adjustment. The experimental results reveal the high effectiveness of the method.\n    ",
        "submission_date": "2012-11-12T00:00:00",
        "last_modified_date": "2012-11-12T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1211.4657",
        "title": "Forest Sparsity for Multi-channel Compressive Sensing",
        "authors": [
            "Chen Chen",
            "Yeqing Li",
            "Junzhou Huang"
        ],
        "abstract": "In this paper, we investigate a new compressive sensing model for multi-channel sparse data where each channel can be represented as a hierarchical tree and different channels are highly correlated. Therefore, the full data could follow the forest structure and we call this property as \\emph{forest sparsity}. It exploits both intra- and inter- channel correlations and enriches the family of existing model-based compressive sensing theories. The proposed theory indicates that only $\\mathcal{O}(Tk+\\log(N/k))$ measurements are required for multi-channel data with forest sparsity, where $T$ is the number of channels, $N$ and $k$ are the length and sparsity number of each channel respectively. This result is much better than $\\mathcal{O}(Tk+T\\log(N/k))$ of tree sparsity, $\\mathcal{O}(Tk+k\\log(N/k))$ of joint sparsity, and far better than $\\mathcal{O}(Tk+Tk\\log(N/k))$ of standard sparsity. In addition, we extend the forest sparsity theory to the multiple measurement vectors problem, where the measurement matrix is a block-diagonal matrix. The result shows that the required measurement bound can be the same as that for dense random measurement matrix, when the data shares equal energy in each channel. A new algorithm is developed and applied on four example applications to validate the benefit of the proposed model. Extensive experiments demonstrate the effectiveness and efficiency of the proposed theory and algorithm.\n    ",
        "submission_date": "2012-11-20T00:00:00",
        "last_modified_date": "2014-05-01T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1211.4683",
        "title": "Content based video retrieval",
        "authors": [
            "B. V. Patel",
            "B. B. Meshram"
        ],
        "abstract": "Content based video retrieval is an approach for facilitating the searching and browsing of large image collections over World Wide Web. In this approach, video analysis is conducted on low level visual properties extracted from video frame. We believed that in order to create an effective video retrieval system, visual perception must be taken into account. We conjectured that a technique which employs multiple features for indexing and retrieval would be more effective in the discrimination and search tasks of videos. In order to validate this claim, content based indexing and retrieval systems were implemented using color histogram, various texture features and other approaches. Videos were stored in Oracle 9i Database and a user study measured correctness of response.\n    ",
        "submission_date": "2012-11-20T00:00:00",
        "last_modified_date": "2012-11-20T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1211.5614",
        "title": "A Hash based Approach for Secure Keyless Steganography in Lossless RGB Images",
        "authors": [
            "Ankit Chaudhary",
            "J. Vasavada",
            "J.L. Raheja",
            "S. Kumar",
            "M. Sharma"
        ],
        "abstract": "This paper proposes an improved steganography approach for hiding text messages in lossless RGB images. The objective of this work is to increase the security level and to improve the storage capacity with compression techniques. The security level is increased by randomly distributing the text message over the entire image instead of clustering within specific image portions. Storage capacity is increased by utilizing all the color channels for storing information and providing the source text message compression. The degradation of the images can be minimized by changing only one least significant bit per color channel for hiding the message, incurring a very little change in the original image. Using steganography alone with simple LSB has a potential problem that the secret message is easily detectable from the histogram analysis method. To improve the security as well as the image embedding capacity indirectly, a compression based scheme is introduced. Various tests have been done to check the storage capacity and message distribution. These testes show the superiority of the proposed approach with respect to other existing approaches.\n    ",
        "submission_date": "2012-11-23T00:00:00",
        "last_modified_date": "2013-04-17T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1211.5829",
        "title": "An Automatic Algorithm for Object Recognition and Detection Based on ASIFT Keypoints",
        "authors": [
            "Reza Oji"
        ],
        "abstract": "Object recognition is an important task in image processing and computer vision. This paper presents a perfect method for object recognition with full boundary detection by combining affine scale invariant feature transform (ASIFT) and a region merging algorithm. ASIFT is a fully affine invariant algorithm that means features are invariant to six affine parameters namely translation (2 parameters), zoom, rotation and two camera axis orientations. The features are very reliable and give us strong keypoints that can be used for matching between different images of an object. We trained an object in several images with different aspects for finding best keypoints of it. Then, a robust region merging algorithm is used to recognize and detect the object with full boundary in the other images based on ASIFT keypoints and a similarity measure for merging regions in the image. Experimental results show that the presented method is very efficient and powerful to recognize the object and detect it with high accuracy.\n    ",
        "submission_date": "2012-11-26T00:00:00",
        "last_modified_date": "2012-11-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1211.7180",
        "title": "Multislice Modularity Optimization in Community Detection and Image Segmentation",
        "authors": [
            "Huiyi Hu",
            "Yves van Gennip",
            "Blake Hunter",
            "Mason A. Porter",
            "Andrea L. Bertozzi"
        ],
        "abstract": "Because networks can be used to represent many complex systems, they have attracted considerable attention in physics, computer science, sociology, and many other disciplines. One of the most important areas of network science is the algorithmic detection of cohesive groups (i.e., \"communities\") of nodes. In this paper, we algorithmically detect communities in social networks and image data by optimizing multislice modularity. A key advantage of modularity optimization is that it does not require prior knowledge of the number or sizes of communities, and it is capable of finding network partitions that are composed of communities of different sizes. By optimizing multislice modularity and subsequently calculating diagnostics on the resulting network partitions, it is thereby possible to obtain information about network structure across multiple system scales. We illustrate this method on data from both social networks and images, and we find that optimization of multislice modularity performs well on these two tasks without the need for extensive problem-specific adaptation. However, improving the computational speed of this method remains a challenging open problem.\n    ",
        "submission_date": "2012-11-30T00:00:00",
        "last_modified_date": "2012-11-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1212.0042",
        "title": "Secure voice based authentication for mobile devices: Vaulted Voice Verification",
        "authors": [
            "R.C. Johnson",
            "Walter J. Scheirer",
            "Terrance E. Boult"
        ],
        "abstract": "As the use of biometrics becomes more wide-spread, the privacy concerns that stem from the use of biometrics are becoming more apparent. As the usage of mobile devices grows, so does the desire to implement biometric identification into such devices. A large majority of mobile devices being used are mobile phones. While work is being done to implement different types of biometrics into mobile phones, such as photo based biometrics, voice is a more natural choice. The idea of voice as a biometric identifier has been around a long time. One of the major concerns with using voice as an identifier is the instability of voice. We have developed a protocol that addresses those instabilities and preserves privacy. This paper describes a novel protocol that allows a user to authenticate using voice on a mobile/remote device without compromising their privacy. We first discuss the \\vv protocol, which has recently been introduced in research literature, and then describe its limitations. We then introduce a novel adaptation and extension of the vaulted verification protocol to voice, dubbed $V^3$. Following that we show a performance evaluation and then conclude with a discussion of security and future work.\n    ",
        "submission_date": "2012-11-30T00:00:00",
        "last_modified_date": "2012-11-30T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1212.0655",
        "title": "G-invariant Persistent Homology",
        "authors": [
            "Patrizio Frosini"
        ],
        "abstract": "Classical persistent homology is a powerful mathematical tool for shape comparison. Unfortunately, it is not tailored to study the action of transformation groups that are different from the group Homeo(X) of all self-homeomorphisms of a topological space X. This fact restricts its use in applications. In order to obtain better lower bounds for the natural pseudo-distance d_G associated with a subgroup G of Homeo(X), we need to adapt persistent homology and consider G-invariant persistent homology. Roughly speaking, the main idea consists in defining persistent homology by means of a set of chains that is invariant under the action of G. In this paper we formalize this idea, and prove the stability of the persistent Betti number functions in G-invariant persistent homology with respect to the natural pseudo-distance d_G. We also show how G-invariant persistent homology could be used in applications concerning shape comparison, when the invariance group is a proper subgroup of the group of all self-homeomorphisms of a topological space. In this paper we will assume that the space X is triangulable, in order to guarantee that the persistent Betti number functions are finite without using any tameness assumption.\n    ",
        "submission_date": "2012-12-04T00:00:00",
        "last_modified_date": "2013-12-21T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1212.0695",
        "title": "Training Support Vector Machines Using Frank-Wolfe Optimization Methods",
        "authors": [
            "Emanuele Frandi",
            "Ricardo Nanculef",
            "Maria Grazia Gasparo",
            "Stefano Lodi",
            "Claudio Sartori"
        ],
        "abstract": "Training a Support Vector Machine (SVM) requires the solution of a quadratic programming problem (QP) whose computational complexity becomes prohibitively expensive for large scale datasets. Traditional optimization methods cannot be directly applied in these cases, mainly due to memory restrictions.\n",
        "submission_date": "2012-12-04T00:00:00",
        "last_modified_date": "2012-12-04T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1212.0935",
        "title": "Computing Consensus Curves",
        "authors": [
            "Livio De La Cruz",
            "Stephen Kobourov",
            "Sergey Pupyrev",
            "Paul Shen",
            "Sankar Veeramoni"
        ],
        "abstract": "We consider the problem of extracting accurate average ant trajectories from many (possibly inaccurate) input trajectories contributed by citizen scientists. Although there are many generic software tools for motion tracking and specific ones for insect tracking, even untrained humans are much better at this task, provided a robust method to computing the average trajectories. We implemented and tested several local (one ant at a time) and global (all ants together) method. Our best performing algorithm uses a novel global method, based on finding edge-disjoint paths in an ant-interaction graph constructed from the input trajectories. The underlying optimization problem is a new and interesting variant of network flow. Even though the problem is NP-hard, we implemented two heuristics, which work very well in practice, outperforming all other approaches, including the best automated system.\n    ",
        "submission_date": "2012-12-05T00:00:00",
        "last_modified_date": "2014-05-14T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1212.1617",
        "title": "Similarity of Polygonal Curves in the Presence of Outliers",
        "authors": [
            "Jean-Lou De Carufel",
            "Amin Gheibi",
            "Anil Maheshwari",
            "J\u00f6rg-R\u00fcdiger Sack",
            "Christian Scheffer"
        ],
        "abstract": "The Fr\u00e9chet distance is a well studied and commonly used measure to capture the similarity of polygonal curves. Unfortunately, it exhibits a high sensitivity to the presence of outliers. Since the presence of outliers is a frequently occurring phenomenon in practice, a robust variant of Fr\u00e9chet distance is required which absorbs outliers. We study such a variant here. In this modified variant, our objective is to minimize the length of subcurves of two polygonal curves that need to be ignored (MinEx problem), or alternately, maximize the length of subcurves that are preserved (MaxIn problem), to achieve a given Fr\u00e9chet distance. An exact solution to one problem would imply an exact solution to the other problem. However, we show that these problems are not solvable by radicals over $\\mathbb{Q}$ and that the degree of the polynomial equations involved is unbounded in general. This motivates the search for approximate solutions. We present an algorithm, which approximates, for a given input parameter $\\delta$, optimal solutions for the \\MinEx\\ and \\MaxIn\\ problems up to an additive approximation error $\\delta$ times the length of the input curves. The resulting running time is upper bounded by $\\mathcal{O} \\left(\\frac{n^3}{\\delta} \\log \\left(\\frac{n}{\\delta} \\right)\\right)$, where $n$ is the complexity of the input polygonal curves.\n    ",
        "submission_date": "2012-12-07T00:00:00",
        "last_modified_date": "2013-04-23T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1212.1863",
        "title": "Self Authentication of image through Daubechies Transform technique (SADT)",
        "authors": [
            "Madhumita Sengupta",
            "J. K. Mandal"
        ],
        "abstract": "In this paper a 4 x 4 Daubechies transform based authentication technique termed as SADT has been proposed to authenticate gray scale images. The cover image is transformed into the frequency domain using 4 x 4 mask in a row major order using Daubechies transform technique, resulting four frequency subbands AF, HF, VF and DF. One byte of every band in a mask is embedding with two or four bits of secret information. Experimental results are computed and compared with the existing authentication techniques like Li s method [5], SCDFT [6], Region-Based method [7] and other similar techniques based on Mean Square Error (MSE), Peak Signal to Noise Ratio (PSNR) and Image Fidelity (IF), which shows better performance in SADT.\n    ",
        "submission_date": "2012-12-09T00:00:00",
        "last_modified_date": "2012-12-09T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1212.2415",
        "title": "Robust Face Recognition using Local Illumination Normalization and Discriminant Feature Point Selection",
        "authors": [
            "Song Han",
            "Jinsong Kim",
            "Cholhun Kim",
            "Jongchol Jo",
            "Sunam Han"
        ],
        "abstract": "Face recognition systems must be robust to the variation of various factors such as facial expression, illumination, head pose and aging. Especially, the robustness against illumination variation is one of the most important problems to be solved for the practical use of face recognition systems. Gabor wavelet is widely used in face detection and recognition because it gives the possibility to simulate the function of human visual system. In this paper, we propose a method for extracting Gabor wavelet features which is stable under the variation of local illumination and show experiment results demonstrating its effectiveness.\n    ",
        "submission_date": "2012-12-11T00:00:00",
        "last_modified_date": "2012-12-11T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1212.3385",
        "title": "Approximating rational Bezier curves by constrained Bezier curves of arbitrary degree",
        "authors": [
            "Mao Shi",
            "Jiansong Deng"
        ],
        "abstract": "In this paper, we propose a method to obtain a constrained approximation of a rational B\u00e9zier curve by a polynomial B\u00e9zier curve. This problem is reformulated as an approximation problem between two polynomial B\u00e9zier curves based on weighted least-squares method, where weight functions $\\rho(t)=\\omega(t)$ and $\\rho(t)=\\omega(t)^{2}$ are studied respectively. The efficiency of the proposed method is tested using some examples.\n    ",
        "submission_date": "2012-12-14T00:00:00",
        "last_modified_date": "2014-09-13T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1212.4490",
        "title": "Sketch-to-Design: Context-based Part Assembly",
        "authors": [
            "Xiaohua Xie",
            "Kai Xu",
            "Niloy J. Mitra",
            "Daniel Cohen-Or",
            "Baoquan Chen"
        ],
        "abstract": "Designing 3D objects from scratch is difficult, especially when the user intent is fuzzy without a clear target form. In the spirit of modeling-by-example, we facilitate design by providing reference and inspiration from existing model contexts. We rethink model design as navigating through different possible combinations of part assemblies based on a large collection of pre-segmented 3D models. We propose an interactive sketch-to-design system, where the user sketches prominent features of parts to combine. The sketched strokes are analyzed individually and in context with the other parts to generate relevant shape suggestions via a design gallery interface. As the session progresses and more parts get selected, contextual cues becomes increasingly dominant and the system quickly converges to a final design. As a key enabler, we use pre-learned part-based contextual information to allow the user to quickly explore different combinations of parts. Our experiments demonstrate the effectiveness of our approach for efficiently designing new variations from existing shapes.\n    ",
        "submission_date": "2012-12-18T00:00:00",
        "last_modified_date": "2012-12-18T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1212.4871",
        "title": "Automatic post-picking using MAPPOS improves particle image detection from Cryo-EM micrographs",
        "authors": [
            "Ramin Norousi",
            "Stephan Wickles",
            "Christoph Leidig",
            "Thomas Becker",
            "Volker J. Schmid",
            "Roland Beckmann",
            "Achim Tresch"
        ],
        "abstract": "Cryo-electron microscopy (cryo-EM) studies using single particle reconstruction are extensively used to reveal structural information on macromolecular complexes. Aiming at the highest achievable resolution, state of the art electron microscopes automatically acquire thousands of high-quality micrographs. Particles are detected on and boxed out from each micrograph using fully- or semi-automated approaches. However, the obtained particles still require laborious manual post-picking classification, which is one major bottleneck for single particle analysis of large datasets. We introduce MAPPOS, a supervised post-picking strategy for the classification of boxed particle images, as additional strategy adding to the already efficient automated particle picking routines. MAPPOS employs machine learning techniques to train a robust classifier from a small number of characteristic image features. In order to accurately quantify the performance of MAPPOS we used simulated particle and non-particle images. In addition, we verified our method by applying it to an experimental cryo-EM dataset and comparing the results to the manual classification of the same dataset. Comparisons between MAPPOS and manual post-picking classification by several human experts demonstrated that merely a few hundred sample images are sufficient for MAPPOS to classify an entire dataset with a human-like performance. MAPPOS was shown to greatly accelerate the throughput of large datasets by reducing the manual workload by orders of magnitude while maintaining a reliable identification of non-particle images.\n    ",
        "submission_date": "2012-12-19T00:00:00",
        "last_modified_date": "2012-12-19T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1212.6058",
        "title": "High Quality Image Interpolation via Local Autoregressive and Nonlocal 3-D Sparse Regularization",
        "authors": [
            "Xinwei Gao",
            "Jian Zhang",
            "Feng Jiang",
            "Xiaopeng Fan",
            "Siwei Ma",
            "Debin Zhao"
        ],
        "abstract": "In this paper, we propose a novel image interpolation algorithm, which is formulated via combining both the local autoregressive (AR) model and the nonlocal adaptive 3-D sparse model as regularized constraints under the regularization framework. Estimating the high-resolution image by the local AR regularization is different from these conventional AR models, which weighted calculates the interpolation coefficients without considering the rough structural similarity between the low-resolution (LR) and high-resolution (HR) images. Then the nonlocal adaptive 3-D sparse model is formulated to regularize the interpolated HR image, which provides a way to modify these pixels with the problem of numerical stability caused by AR model. In addition, a new Split-Bregman based iterative algorithm is developed to solve the above optimization problem iteratively. Experiment results demonstrate that the proposed algorithm achieves significant performance improvements over the traditional algorithms in terms of both objective quality and visual perception\n    ",
        "submission_date": "2012-12-25T00:00:00",
        "last_modified_date": "2012-12-25T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1212.6209",
        "title": "Efficient Multiple Object Tracking Using Mutually Repulsive Active Membranes",
        "authors": [
            "Yi Deng",
            "Philip Coen",
            "Mingzhai Sun",
            "Joshua W. Shaevitz"
        ],
        "abstract": "Studies of social and group behavior in interacting organisms require high-throughput analysis of the motion of a large number of individual subjects. Computer vision techniques offer solutions to specific tracking problems, and allow automated and efficient tracking with minimal human intervention. In this work, we adopt the open active contour model to track the trajectories of moving objects at high density. We add repulsive interactions between open contours to the original model, treat the trajectories as an extrusion in the temporal dimension, and show applications to two tracking problems. The walking behavior of Drosophila is studied at different population density and gender composition. We demonstrate that individual male flies have distinct walking signatures, and that the social interaction between flies in a mixed gender arena is gender specific. We also apply our model to studies of trajectories of gliding Myxococcus xanthus bacteria at high density. We examine the individual gliding behavioral statistics in terms of the gliding speed distribution. Using these two examples at very distinctive spatial scales, we illustrate the use of our algorithm on tracking both short rigid bodies (Drosophila) and long flexible objects (Myxococcus xanthus). Our repulsive active membrane model reaches error rates better than $5\\times 10^{-6}$ per fly per second for Drosophila tracking and comparable results for Myxococcus xanthus.\n    ",
        "submission_date": "2012-12-26T00:00:00",
        "last_modified_date": "2012-12-26T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1212.6303",
        "title": "A brief experience on journey through hardware developments for image processing and its applications on Cryptography",
        "authors": [
            "Sangeet Saha",
            "Chandrajit pal",
            "Rourab paul",
            "Satyabrata Maity",
            "Suman Sau"
        ],
        "abstract": "The importance of embedded applications on image and video processing,communication and cryptography domain has been taking a larger space in current research era. Improvement of pictorial information for betterment of human perception like deblurring, de-noising in several fields such as satellite imaging, medical imaging etc are renewed research thrust. Specifically we would like to elaborate our experience on the significance of computer vision as one of the domains where hardware implemented algorithms perform far better than those implemented through software. So far embedded design engineers have successfully implemented their designs by means of Application Specific Integrated Circuits (ASICs) and/or Digital Signal Processors (DSP), however with the advancement of VLSI technology a very powerful hardware device namely the Field Programmable Gate Array (FPGA) combining the key advantages of ASICs and DSPs was developed which have the possibility of reprogramming making them a very attractive device for rapid ",
        "submission_date": "2012-12-27T00:00:00",
        "last_modified_date": "2012-12-27T00:00:00"
    },
    {
        "url": "https://arxiv.org/abs/1212.6837",
        "title": "Autonomously Learning to Visually Detect Where Manipulation Will Succeed",
        "authors": [
            "Hai Nguyen",
            "Charles C. Kemp"
        ],
        "abstract": "Visual features can help predict if a manipulation behavior will succeed at a given location. For example, the success of a behavior that flips light switches depends on the location of the switch. Within this paper, we present methods that enable a mobile manipulator to autonomously learn a function that takes an RGB image and a registered 3D point cloud as input and returns a 3D location at which a manipulation behavior is likely to succeed. Given a pair of manipulation behaviors that can change the state of the world between two sets (e.g., light switch up and light switch down), classifiers that detect when each behavior has been successful, and an initial hint as to where one of the behaviors will be successful, the robot autonomously trains a pair of support vector machine (SVM) classifiers by trying out the behaviors at locations in the world and observing the results. When an image feature vector associated with a 3D location is provided as input to one of the SVMs, the SVM predicts if the associated manipulation behavior will be successful at the 3D location. To evaluate our approach, we performed experiments with a PR2 robot from Willow Garage in a simulated home using behaviors that flip a light switch, push a rocker-type light switch, and operate a drawer. By using active learning, the robot efficiently learned SVMs that enabled it to consistently succeed at these tasks. After training, the robot also continued to learn in order to adapt in the event of failure.\n    ",
        "submission_date": "2012-12-31T00:00:00",
        "last_modified_date": "2012-12-31T00:00:00"
    }
]